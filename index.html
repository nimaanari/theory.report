<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2022-12-13T01:30:21Z">Tuesday, December 13 2022, 01:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, December 12
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/12/assistant-professor-in-computer-science-at-hse-university-apply-by-january-15-2023/'>Assistant Professor in Computer Science at HSE University (apply by January 15, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Faculty of Computer Science, HSE University invites applications for positions of assistant [professor in all areas of computer science including theoretical CS. Candidates must hold a recent PhD in computer science, mathematics or related fields, posess teaching experience and speak fluent English. Tenure track positions are only available on a full-time, residential basis in [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Faculty of Computer Science, HSE University invites applications for positions of assistant [professor in all areas of computer science including theoretical CS.<br />
Candidates must hold a recent PhD in computer science, mathematics or related fields, posess teaching experience and speak fluent English.<br />
Tenure track positions are only available on a full-time, residential basis in Moscow, Russia.</p>
<p>Website: <a href="https://iri.hse.ru/ru/TTCS2223">https://iri.hse.ru/ru/TTCS2223</a><br />
Email: iri@hse.ru</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T11:11:39Z">Monday, December 12 2022, 11:11</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://decentralizedthoughts.github.io/2022-12-12-what-about-validity/'>What about Validity?</a></h3>
        <p class='tr-article-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Perhaps the architipical trilemma is consensus - it requires three properties: agreement, liveness, and validity. Getting any two is easy, but all three together is what makes consensus such a facinating problem that continues to create new challenges even after 40 years of research. A lot of research focuses on...
        
        </div>

        <div class='tr-article-summary'>
        
          
          Perhaps the architipical trilemma is consensus - it requires three properties: agreement, liveness, and validity. Getting any two is easy, but all three together is what makes consensus such a facinating problem that continues to create new challenges even after 40 years of research. A lot of research focuses on...
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T09:00:00Z">Monday, December 12 2022, 09:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/12/commercials-are-not-logical-ftx-edition.html'>Commercials are not logical.  FTX edition.</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Some people asked me to comment on FTX since I teach Crypto. My insights are no better than anyone else; however, I have wanted to do a blog post about the illogic of commercials, so I will do that with FTX as an example.&nbsp;</p><p>ALL conversations in the post are fictional.</p><p>------------------------------------</p><p>Alice: Bob,&nbsp; why did you invest $1,000,000 with FTX?</p><p>Bob: Because Tom Brady endorsed it. (See&nbsp;here)</p><p>Alice: But Tom Brady is a football player, not a finance person.&nbsp;</p><p>Bob: Well... I know that now.&nbsp;</p><p>------------------------------------------------------------</p><p>The people in commercials&nbsp; paid to hawk the product.&nbsp;</p><p>a) Are they experts? In the above case about about FTX&nbsp; NO, they are not. So this should not work.&nbsp;</p><p>b) There are commercials where the people ARE experts. For example, a basketball player endorsing Sneaker brand (not quite an expert, but they DO use the product). But even this should not work since the viewers KNOW that the person is being PAID to tell us it's a good product.&nbsp;</p><p>c) Commercial spokesman (Geico-Gecko, Progressive-Flo, Dos&nbsp; XX- the worlds most interesting man, see his commercial&nbsp;here&nbsp;and a Ramsey Meme based on it&nbsp;here) are even stranger- they are fictional characters who are urging me to buy something.&nbsp; So the question are they experts? doesn't even make sense. Someone pretending to be someone they are not is pretending to like a product they do not use.&nbsp;</p><p>d) Some commercials pretend to be&nbsp; informative but are not. For example, the Insurance Companies seem to brag about something that ALL of the insurance companies do (bundling, not-paying-for-what-you-don't-need).&nbsp;</p><p>e) A truly new product may have an informative commercial, just to tell me that its out there. For example. Stephen Colbert's Americone Dream Ice Cream which is awesome. (My spellchecker thinks Americone is not a word. This time they are probably right.)&nbsp;</p><p>f) SO, if I did a commercial for Stephen Colbert's Americone Dream Ice Cream would you try it? Lets say I wasn't being paid and I truly did it for my love of that ice cream. STILL doesn't make sense- my tastes and yours may differ. However, you can try it and decide, and&nbsp; it costs far less than $1,000,000.</p><p>---------------------------------------</p><p>So what are we left with? The only commercials that make logical sense would be those where&nbsp;</p><p>a) the person is an expert</p><p>b) the person is not being paid</p><p>c) the person is telling you something about the product that distinguishes it from its competitors OR p its a new product</p><p>d) Its not a matter of taste- there is an absolute standard that is easily understood.&nbsp;</p><p><br></p><p>Do you know of ANY commercials like that? Influencers who are NOT paid by the people whose product they are hawking (are there such influencers?) might begin to qualify.&nbsp;</p><p>------------------------------------------------------</p><p>So LOGICALLY commercials should not work. So why do they?</p><p>a) They don't. Its possible they just are not that effective. See&nbsp;here&nbsp;for DON"T WORK and&nbsp;here&nbsp;for 8 times when it did work. I think&nbsp;this&nbsp;is a great commercial (watch it to the end) but it does not make me want to out and buy soup. (Stan Freberg wrote some GREAT commercials. They are on You Tube and I recommend them highly for entertainment. He also has several great novelty-song albums.)&nbsp;</p><p>b) Indirectly. They build brand awareness.</p><p>c) Because people are stupid. This is not an interesting answer since I still want to know what their reasoning is, whether or not its faulty.</p><p>d) Because you are part of a movement. Drink the Uncola (7UP) to be rebellious! Or the 1984-Apple commercial (see&nbsp;here). These are both odd since drinking 7UP or having an Apple Computer seem to me to be the opposite of rebellious.&nbsp;</p><p>e) Buying the product to express your philosophy:&nbsp;</p><p>Ted: Carol, why did you invest in $1,000,000 in FTX?&nbsp;</p><p>Carol: Because I believe in effective altruism.</p><p>Ted: Do you still?</p><p>Carol: This might need a rethink. But for now I'll&nbsp; invest by getting a Freedom Unlimited credit card that gets cash back since Kevin Hart says I should (see&nbsp;here).</p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Some people asked me to comment on FTX since I teach Crypto. My insights are no better than anyone else; however, I have wanted to do a blog post about the illogic of commercials, so I will do that with FTX as an example.&nbsp;</p><p>ALL conversations in the post are fictional.</p><p>------------------------------------</p><p>Alice: Bob,&nbsp; why did you invest $1,000,000 with FTX?</p><p>Bob: Because Tom Brady endorsed it. (See&nbsp;<a href="https://nypost.com/2022/11/22/tom-brady-stephen-curry-larry-david-probed-over-ftx-endorsements/">here</a>)</p><p>Alice: But Tom Brady is a football player, not a finance person.&nbsp;</p><p>Bob: Well... I know that now.&nbsp;</p><p>------------------------------------------------------------</p><p>The people in commercials&nbsp; paid to hawk the product.&nbsp;</p><p>a) Are they experts? In the above case about about FTX&nbsp; NO, they are not. So this should not work.&nbsp;</p><p>b) There are commercials where the people ARE experts. For example, a basketball player endorsing Sneaker brand (not quite an expert, but they DO use the product). But even this should not work since the viewers KNOW that the person is being PAID to tell us it's a good product.&nbsp;</p><p>c) Commercial spokesman (Geico-Gecko, Progressive-Flo, Dos&nbsp; XX- the worlds most interesting man, see his commercial&nbsp;<a href="https://www.youtube.com/watch?v=n5HX7y1yDi4">here</a>&nbsp;and a Ramsey Meme based on it&nbsp;<a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/idont.jpg">here</a>) are even stranger- they are fictional characters who are urging me to buy something.&nbsp; So the question <i>are they experts? </i>doesn't even make sense. Someone pretending to be someone they are not is pretending to like a product they do not use.&nbsp;</p><p>d) Some commercials pretend to be&nbsp; informative but are not. For example, the Insurance Companies seem to brag about something that ALL of the insurance companies do (bundling, not-paying-for-what-you-don't-need).&nbsp;</p><p>e) A truly new product may have an informative commercial, just to tell me that its out there. For example. <i>Stephen Colbert's Americone Dream Ice Cream</i> which is awesome. (My spellchecker thinks <i>Americone</i> is not a word. This time they are probably right.)&nbsp;</p><p>f) SO, if I did a commercial for <i>Stephen Colbert's Americone Dream Ice Cream</i> would you try it? Lets say I wasn't being paid and I truly did it for my love of that ice cream. STILL doesn't make sense- my tastes and yours may differ. However, you can try it and decide, and&nbsp; it costs far less than $1,000,000.</p><p>---------------------------------------</p><p>So what are we left with? The only commercials that make logical sense would be those where&nbsp;</p><p>a) the person is an expert</p><p>b) the person is not being paid</p><p>c) the person is telling you something about the product that distinguishes it from its competitors OR p its a new product</p><p>d) Its not a matter of taste- there is an absolute standard that is easily understood.&nbsp;</p><p><br /></p><p>Do you know of ANY commercials like that? Influencers who are NOT paid by the people whose product they are hawking (are there such influencers?) might begin to qualify.&nbsp;</p><p>------------------------------------------------------</p><p>So LOGICALLY commercials should not work. So why do they?</p><p>a) They don't. Its possible they just are not that effective. See&nbsp;<a href="https://insight.kellogg.northwestern.edu/article/tv-advertising-is-usually-not-worth-it">here</a>&nbsp;for DON"T WORK and&nbsp;<a href="https://www.investopedia.com/financial-edge/1111/8-of-the-most-successful-ad-campaigns-of-all-time.aspx">here</a>&nbsp;for 8 times when it did work. I think&nbsp;<a href="https://www.google.com/search?q=you+tube+soup+commercial+stan+freberg&amp;rlz=1C1EJFC_enUS884US884&amp;ei=gaiWY7iVAqae5NoPgum46Ac&amp;ved=0ahUKEwj42avlmfP7AhUmD1kFHYI0Dn0Q4dUDCA8&amp;uact=5&amp;oq=you+tube+soup+commercial+stan+freberg&amp;gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIFCCEQqwI6CggAEEcQ1gQQsAM6BggAEBYQHjoFCAAQhgM6BwghEKABEAo6CAghEBYQHhAdSgQIQRgASgQIRhgAUNkDWOoWYOgXaAFwAXgAgAFyiAH7CJIBBDEwLjOYAQCgAQHIAQi4AQPAAQE&amp;sclient=gws-wiz-serp#fpstate=ive&amp;vld=cid:cf8fea70,vid:lZN86IOv79k">this</a>&nbsp;is a great commercial (watch it to the end) but it does not make me want to out and buy soup. (Stan Freberg wrote some GREAT commercials. They are on You Tube and I recommend them highly for entertainment. He also has several great novelty-song albums.)&nbsp;</p><p>b) Indirectly. They build brand awareness.</p><p>c) Because people are stupid. This is not an interesting answer since I still want to know what their reasoning is, whether or not its faulty.</p><p>d) Because you are part of a movement. Drink the Uncola (7UP) to be rebellious! Or the 1984-Apple commercial (see&nbsp;<a href="https://www.youtube.com/watch?v=zIE-5hg7FoA">here</a>). These are both odd since drinking 7UP or having an Apple Computer seem to me to be the opposite of rebellious.&nbsp;</p><p>e) Buying the product to express your philosophy:&nbsp;</p><p>Ted: Carol, why did you invest in $1,000,000 in FTX?&nbsp;</p><p>Carol: Because I believe in effective altruism.</p><p>Ted: Do you still?</p><p>Carol: This might need a rethink. But for now I'll&nbsp; invest by getting a Freedom Unlimited credit card that gets cash back since Kevin Hart says I should (see&nbsp;<a href="https://www.google.com/search?q=you+tube+kevin+hart+credit+card&amp;rlz=1C1EJFC_enUS884US884&amp;oq=you+tube+kevin+hart+credit+card&amp;aqs=chrome..69i57j69i64.12160j1j4&amp;sourceid=chrome&amp;ie=UTF-8#fpstate=ive&amp;vld=cid:e977cbbb,vid:m3TSpuaQvDo">here</a>).</p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T04:03:00Z">Monday, December 12 2022, 04:03</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04703'>Implementing Neural Network-Based Equalizers in a Coherent Optical Transmission System Using Field-Programmable Gate Arrays</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pedro J. Freire, Sasipim Srivallapanondh, Michael Anderson, Bernhard Spinnler, Thomas Bex, Tobias A. Eriksson, Antonio Napoli, Wolfgang Schairer, Nelson Costa, Michaela Blott, Sergei K. Turitsyn, Jaroslaw E. Prilepsky</p><p>In this work, we demonstrate the offline FPGA realization of both recurrent
and feedforward neural network (NN)-based equalizers for nonlinearity
compensation in coherent optical transmission systems. First, we present a
realization pipeline showing the conversion of the models from Python libraries
to the FPGA chip synthesis and implementation. Then, we review the main
alternatives for the hardware implementation of nonlinear activation functions.
The main results are divided into three parts: a performance comparison, an
analysis of how activation functions are implemented, and a report on the
complexity of the hardware. The performance in Q-factor is presented for the
cases of bidirectional long-short-term memory coupled with convolutional NN
(biLSTM + CNN) equalizer, CNN equalizer, and standard 1-StpS digital
back-propagation (DBP) for the simulation and experiment propagation of a
single channel dual-polarization (SC-DP) 16QAM at 34 GBd along 17x70km of LEAF.
The biLSTM+CNN equalizer provides a similar result to DBP and a 1.7 dB Q-factor
gain compared with the chromatic dispersion compensation baseline in the
experimental dataset. After that, we assess the Q-factor and the impact of
hardware utilization when approximating the activation functions of NN using
Taylor series, piecewise linear, and look-up table (LUT) approximations. We
also show how to mitigate the approximation errors with extra training and
provide some insights into possible gradient problems in the LUT approximation.
Finally, to evaluate the complexity of hardware implementation to achieve 400G
throughput, fixed-point NN-based equalizers with approximated activation
functions are developed and implemented in an FPGA.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/eess/1/au:+Freire_P/0/1/0/all/0/1">Pedro J. Freire</a>, <a href="http://arxiv.org/find/eess/1/au:+Srivallapanondh_S/0/1/0/all/0/1">Sasipim Srivallapanondh</a>, <a href="http://arxiv.org/find/eess/1/au:+Anderson_M/0/1/0/all/0/1">Michael Anderson</a>, <a href="http://arxiv.org/find/eess/1/au:+Spinnler_B/0/1/0/all/0/1">Bernhard Spinnler</a>, <a href="http://arxiv.org/find/eess/1/au:+Bex_T/0/1/0/all/0/1">Thomas Bex</a>, <a href="http://arxiv.org/find/eess/1/au:+Eriksson_T/0/1/0/all/0/1">Tobias A. Eriksson</a>, <a href="http://arxiv.org/find/eess/1/au:+Napoli_A/0/1/0/all/0/1">Antonio Napoli</a>, <a href="http://arxiv.org/find/eess/1/au:+Schairer_W/0/1/0/all/0/1">Wolfgang Schairer</a>, <a href="http://arxiv.org/find/eess/1/au:+Costa_N/0/1/0/all/0/1">Nelson Costa</a>, <a href="http://arxiv.org/find/eess/1/au:+Blott_M/0/1/0/all/0/1">Michaela Blott</a>, <a href="http://arxiv.org/find/eess/1/au:+Turitsyn_S/0/1/0/all/0/1">Sergei K. Turitsyn</a>, <a href="http://arxiv.org/find/eess/1/au:+Prilepsky_J/0/1/0/all/0/1">Jaroslaw E. Prilepsky</a></p><p>In this work, we demonstrate the offline FPGA realization of both recurrent
and feedforward neural network (NN)-based equalizers for nonlinearity
compensation in coherent optical transmission systems. First, we present a
realization pipeline showing the conversion of the models from Python libraries
to the FPGA chip synthesis and implementation. Then, we review the main
alternatives for the hardware implementation of nonlinear activation functions.
The main results are divided into three parts: a performance comparison, an
analysis of how activation functions are implemented, and a report on the
complexity of the hardware. The performance in Q-factor is presented for the
cases of bidirectional long-short-term memory coupled with convolutional NN
(biLSTM + CNN) equalizer, CNN equalizer, and standard 1-StpS digital
back-propagation (DBP) for the simulation and experiment propagation of a
single channel dual-polarization (SC-DP) 16QAM at 34 GBd along 17x70km of LEAF.
The biLSTM+CNN equalizer provides a similar result to DBP and a 1.7 dB Q-factor
gain compared with the chromatic dispersion compensation baseline in the
experimental dataset. After that, we assess the Q-factor and the impact of
hardware utilization when approximating the activation functions of NN using
Taylor series, piecewise linear, and look-up table (LUT) approximations. We
also show how to mitigate the approximation errors with extra training and
provide some insights into possible gradient problems in the LUT approximation.
Finally, to evaluate the complexity of hardware implementation to achieve 400G
throughput, fixed-point NN-based equalizers with approximated activation
functions are developed and implemented in an FPGA.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T01:30:00Z">Monday, December 12 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04718'>Controllability of complex networks: input node placement restricting the longest control chain</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samie Alizadeh, M&#xe1;rton P&#xf3;sfai, Abdorasoul Ghasemi</p><p>The minimum number of inputs needed to control a network is frequently used
to quantify its controllability. Control of linear dynamics through a minimum
set of inputs, however, often has prohibitively large energy requirements and
there is an inherent trade-off between minimizing the number of inputs and
control energy. To better understand this trade-off, we study the problem of
identifying a minimum set of input nodes such that controllabililty is ensured
while restricting the length of the longest control chain. The longest control
chain is the maximum distance from input nodes to any network node, and recent
work found that reducing its length significantly reduces control energy. We
map the longest control chain-constraint minimum input problem to finding a
joint maximum matching and minimum dominating set. We show that this graph
combinatorial problem is NP-complete, and we introduce and validate a heuristic
approximation. Applying this algorithm to a collection of real and model
networks, we investigate how network structure affects the minimum number of
inputs, revealing, for example, that for many real networks reducing the
longest control chain requires only few or no additional inputs, only the
rearrangement of the input nodes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alizadeh_S/0/1/0/all/0/1">Samie Alizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Posfai_M/0/1/0/all/0/1">M&#xe1;rton P&#xf3;sfai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghasemi_A/0/1/0/all/0/1">Abdorasoul Ghasemi</a></p><p>The minimum number of inputs needed to control a network is frequently used
to quantify its controllability. Control of linear dynamics through a minimum
set of inputs, however, often has prohibitively large energy requirements and
there is an inherent trade-off between minimizing the number of inputs and
control energy. To better understand this trade-off, we study the problem of
identifying a minimum set of input nodes such that controllabililty is ensured
while restricting the length of the longest control chain. The longest control
chain is the maximum distance from input nodes to any network node, and recent
work found that reducing its length significantly reduces control energy. We
map the longest control chain-constraint minimum input problem to finding a
joint maximum matching and minimum dominating set. We show that this graph
combinatorial problem is NP-complete, and we introduce and validate a heuristic
approximation. Applying this algorithm to a collection of real and model
networks, we investigate how network structure affects the minimum number of
inputs, revealing, for example, that for many real networks reducing the
longest control chain requires only few or no additional inputs, only the
rearrangement of the input nodes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T01:30:00Z">Monday, December 12 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04659'>A refinement on the structure of vertex-critical ($P_5$, gem)-free graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ben Cameron, Ch&#xed;nh T. Ho&#xe0;ng</p><p>We give a new, stronger proof that there are only finitely many
$k$-vertex-critical ($P_5$,~gem)-free graphs for all $k$. Our proof further
refines the structure of these graphs and allows for the implementation of a
simple exhaustive computer search to completely list all $6$- and
$7$-vertex-critical $(P_5$, gem)-free graphs. Our results imply the existence
of polynomial-time certifying algorithms to decide the $k$-colourability of
$(P_5$, gem)-free graphs for all $k$ where the certificate is either a
$k$-colouring or a $(k+1)$-vertex-critical induced subgraph. Our complete lists
for $k\le 7$ allow for the implementation of these algorithms for all $k\le 6$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Cameron_B/0/1/0/all/0/1">Ben Cameron</a>, <a href="http://arxiv.org/find/math/1/au:+Hoang_C/0/1/0/all/0/1">Ch&#xed;nh T. Ho&#xe0;ng</a></p><p>We give a new, stronger proof that there are only finitely many
$k$-vertex-critical ($P_5$,~gem)-free graphs for all $k$. Our proof further
refines the structure of these graphs and allows for the implementation of a
simple exhaustive computer search to completely list all $6$- and
$7$-vertex-critical $(P_5$, gem)-free graphs. Our results imply the existence
of polynomial-time certifying algorithms to decide the $k$-colourability of
$(P_5$, gem)-free graphs for all $k$ where the certificate is either a
$k$-colouring or a $(k+1)$-vertex-critical induced subgraph. Our complete lists
for $k\le 7$ allow for the implementation of these algorithms for all $k\le 6$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T01:30:00Z">Monday, December 12 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04726'>Breaking the Barrier $2^k$ for Subset Feedback Vertex Set in Chordal Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tian Bai, Mingyu Xiao</p><p>The Subset Feedback Vertex Set problem (SFVS), to delete $k$ vertices from a
given graph such that any vertex in a vertex subset (called a terminal set) is
not in a cycle in the remaining graph, generalizes the famous Feedback Vertex
Set problem and Multiway Cut problem. SFVS remains $\mathrm{NP}$-hard even in
split and chordal graphs, and SFVS in Chordal Graphs can be considered as a
special case of the 3-Hitting Set problem. However, it is not easy to solve
SFVS in Chordal Graphs faster than 3-Hitting Set. In 2019, Philip, Rajan,
Saurabh, and Tale (Algorithmica 2019) proved that SFVS in Chordal Graphs can be
solved in $2^k n^{\mathcal{O}(1)}$, slightly improving the best result $2.076^k
n^{\mathcal{O}(1)}$ for 3-Hitting Set. In this paper, we break the
"$2^k$-barrier" for SFVS in Chordal Graphs by giving a $1.619^k
n^{\mathcal{O}(1)}$-time algorithm. Our algorithm uses reduction and branching
rules based on the Dulmage-Mendelsohn decomposition and a divide-and-conquer
method.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bai_T/0/1/0/all/0/1">Tian Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1">Mingyu Xiao</a></p><p>The Subset Feedback Vertex Set problem (SFVS), to delete $k$ vertices from a
given graph such that any vertex in a vertex subset (called a terminal set) is
not in a cycle in the remaining graph, generalizes the famous Feedback Vertex
Set problem and Multiway Cut problem. SFVS remains $\mathrm{NP}$-hard even in
split and chordal graphs, and SFVS in Chordal Graphs can be considered as a
special case of the 3-Hitting Set problem. However, it is not easy to solve
SFVS in Chordal Graphs faster than 3-Hitting Set. In 2019, Philip, Rajan,
Saurabh, and Tale (Algorithmica 2019) proved that SFVS in Chordal Graphs can be
solved in $2^k n^{\mathcal{O}(1)}$, slightly improving the best result $2.076^k
n^{\mathcal{O}(1)}$ for 3-Hitting Set. In this paper, we break the
"$2^k$-barrier" for SFVS in Chordal Graphs by giving a $1.619^k
n^{\mathcal{O}(1)}$-time algorithm. Our algorithm uses reduction and branching
rules based on the Dulmage-Mendelsohn decomposition and a divide-and-conquer
method.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T01:30:00Z">Monday, December 12 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04880'>A Polynomial-Time Algorithm for MCS Partial Search Order on Chordal Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guozhen Rong, Yongjie Yang, Wenjun Li</p><p>We study the partial search order problem (PSOP) proposed recently by
Scheffler [WG 2022]. Given a graph $G$ together with a partial order over the
vertices of $G$, this problem determines if there is an $\mathcal{S}$-ordering
that is consistent with the given partial order, where $\mathcal{S}$ is a graph
search paradigm like BFS, DFS, etc. This problem naturally generalizes the
end-vertex problem which has received much attention over the past few years.
It also generalizes the so-called ${\mathcal{F}}$-tree recognition problem
which has just been studied in the literature recently. Our main contribution
is a polynomial-time dynamic programming algorithm for the PSOP on chordal
graphs with respect to the maximum cardinality search (MCS). This resolves one
of the most intriguing open questions left in the work of Sheffler [WG 2022].
To obtain our result, we propose the notion of layer structure and study
numerous related structural properties which might be of independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rong_G/0/1/0/all/0/1">Guozhen Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yongjie Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenjun Li</a></p><p>We study the partial search order problem (PSOP) proposed recently by
Scheffler [WG 2022]. Given a graph $G$ together with a partial order over the
vertices of $G$, this problem determines if there is an $\mathcal{S}$-ordering
that is consistent with the given partial order, where $\mathcal{S}$ is a graph
search paradigm like BFS, DFS, etc. This problem naturally generalizes the
end-vertex problem which has received much attention over the past few years.
It also generalizes the so-called ${\mathcal{F}}$-tree recognition problem
which has just been studied in the literature recently. Our main contribution
is a polynomial-time dynamic programming algorithm for the PSOP on chordal
graphs with respect to the maximum cardinality search (MCS). This resolves one
of the most intriguing open questions left in the work of Sheffler [WG 2022].
To obtain our result, we propose the notion of layer structure and study
numerous related structural properties which might be of independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T01:30:00Z">Monday, December 12 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.05015'>Robustness Implies Privacy in Statistical Estimation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samuel B. Hopkins, Gautam Kamath, Mahbod Majid, Shyam Narayanan</p><p>We study the relationship between adversarial robustness and differential
privacy in high-dimensional algorithmic statistics. We give the first black-box
reduction from privacy to robustness which can produce private estimators with
optimal tradeoffs among sample complexity, accuracy, and privacy for a wide
range of fundamental high-dimensional parameter estimation problems, including
mean and covariance estimation. We show that this reduction can be implemented
in polynomial time in some important special cases. In particular, using
nearly-optimal polynomial-time robust estimators for the mean and covariance of
high-dimensional Gaussians which are based on the Sum-of-Squares method, we
design the first polynomial-time private estimators for these problems with
nearly-optimal samples-accuracy-privacy tradeoffs. Our algorithms are also
robust to a constant fraction of adversarially-corrupted samples.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hopkins_S/0/1/0/all/0/1">Samuel B. Hopkins</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamath_G/0/1/0/all/0/1">Gautam Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Majid_M/0/1/0/all/0/1">Mahbod Majid</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1">Shyam Narayanan</a></p><p>We study the relationship between adversarial robustness and differential
privacy in high-dimensional algorithmic statistics. We give the first black-box
reduction from privacy to robustness which can produce private estimators with
optimal tradeoffs among sample complexity, accuracy, and privacy for a wide
range of fundamental high-dimensional parameter estimation problems, including
mean and covariance estimation. We show that this reduction can be implemented
in polynomial time in some important special cases. In particular, using
nearly-optimal polynomial-time robust estimators for the mean and covariance of
high-dimensional Gaussians which are based on the Sum-of-Squares method, we
design the first polynomial-time private estimators for these problems with
nearly-optimal samples-accuracy-privacy tradeoffs. Our algorithms are also
robust to a constant fraction of adversarially-corrupted samples.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T01:30:00Z">Monday, December 12 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, December 11
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/11/postdocs-in-tcs-at-university-of-copenhagen-apply-by-january-10-2023/'>Postdocs in TCS at University of Copenhagen (apply by January 10, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The CS department at the University of Copenhagen invites applications for postdocs in TCS. The application deadline is January 10, 2023. See www.jakobnordstrom.se/openings/Postdoc-UCPH-230110.html for more information and instructions how to apply. Informal enquiries are welcome to Mikkel Abrahamsen (miab@di.ku.dk), Jakob Nordstrom (jn@di.ku.dk), or Rasmus Pagh (pagh@di.ku.dk). Website: www.jakobnordstrom.se/openings/Postdoc-UCPH-230110.html Email: jn@di.ku.dk
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The CS department at the University of Copenhagen invites applications for postdocs in TCS. The application deadline is January 10, 2023. See <a href="http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230110.html">http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230110.html</a> for more information and instructions how to apply. Informal enquiries are welcome to Mikkel Abrahamsen (miab@di.ku.dk), Jakob Nordstrom (jn@di.ku.dk), or Rasmus Pagh (pagh@di.ku.dk).</p>
<p>Website: <a href="http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230110.html">http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230110.html</a><br />
Email: jn@di.ku.dk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-11T01:24:45Z">Sunday, December 11 2022, 01:24</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, December 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/10/phd-position-at-u-of-rochester-apply-by-december-15-2022/'>PhD position at U of Rochester (apply by December 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We invite Ph.D. applicants in theoretical computer science. There is no application fee. Late applications will be considered. Several open positions in many areas such as: computational complexity, approximation and randomized algorithms, pseudorandomness, theoretical machine learning, combinatorics and additive combinatorics, game theory and economics, and computational social choice. Website: www.cs.rochester.edu/research/theory/ Email: robin.clark@rochester.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We invite Ph.D. applicants in theoretical computer science. There is no application fee. Late applications will be considered.</p>
<p>Several open positions in many areas such as:<br />
computational complexity, approximation and randomized algorithms, pseudorandomness, theoretical machine learning, combinatorics and additive combinatorics, game theory and economics, and computational social choice.</p>
<p>Website: <a href="https://www.cs.rochester.edu/research/theory/">https://www.cs.rochester.edu/research/theory/</a><br />
Email: robin.clark@rochester.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-10T16:47:48Z">Saturday, December 10 2022, 16:47</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://dstheory.wordpress.com/2022/12/10/wednesday-dec-14th-2022-omri-ben-eliezer-from-mit/'>Wednesday, Dec 14th, 2022 â Omri Ben-Eliezer from MIT</a></h3>
        <p class='tr-article-feed'>from <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next Foundations of Data Science virtual talk series on recent advances in adversarially robust streaming will take place on Wednesday, December 14th at 1:00 PM Pacific Time (16:00 Eastern Time, 22:00 Central European Time, 20:00 UTC). Omri Ben-Eliezer from MIT will talk about âRobust sampling and online learningâ Details of the talk (Zoom link)Continue reading "Wednesday, Dec 14th, 2022 â Omri Ben-Eliezer from&#160;MIT"
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="has-text-align-justify">The next <a rel="noreferrer noopener" href="https://sites.google.com/view/dstheory/home" target="_blank">Foundations of Data Science</a> virtual talk series on recent advances in <em>adversarially robust streaming</em> will take place on <strong>Wednesday, December 14th</strong> at <strong>1:00 PM Pacific Time</strong> (16:00 Eastern Time, 22:00 Central European Time, 20:00 UTC). <strong>Omri Ben-Eliezer</strong> from<strong> MIT</strong> will talk about <em>âRobust sampling and online learningâ</em></p>



<p><a href="https://sites.google.com/view/dstheory">Details of the talk (Zoom link) are available here.</a></p>



<p class="has-text-align-justify"><strong>Abstract</strong>:  Random sampling is a fundamental primitive in modern algorithms, statistics and machine learning, used as a generic method to obtain a small yet ârepresentativeâ subset of the data. In this talk we shall explore to what extent random sampling is robust to adaptive inputs in a streaming setting, proposing and studying a model for sampling against a white-box adaptive adversary (where future inputs generated by the adversary are allowed to depend on the current internal state of the sampler). I will demonstrate scenarios where the adaptive sample complexity can be much larger than in the static world, but argue that these scenarios are not entirely realistic. I will then reveal a deep connection between our setting and online learning. As it turns out, the sample complexity in our sampling setting is captured by a sequential version of Rademacher complexity, a notion that is also known to capture the regret in online classification problems. Leveraging this connection, one can bound the sample complexity using the Littlestone dimension of the relevant concept class. The obtained bounds are tight in many regimes, and lead us to resolve a classical open problem on optimal regret bounds in online learning.</p>



<p>Based on joint works with Noga Alon, Yuval Dagan, Shay Moran, Moni Naor, and Eylon Yogev.</p>



<p>&nbsp;The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p>
<p class="authors">By dstheory</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-10T04:13:32Z">Saturday, December 10 2022, 04:13</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, December 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/'>Thanks</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Thanks to you all. I must explain why I have not been active in the last six months. I have had several illnesses. I had a broken hip that needed surgery I also had several COVID related illnesses, and some terrible GI issues. I am trying to get better. Thanks to my dear wife Kathryn [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Thanks to you all. I must explain why I have not been active in the last six months. I have had several illnesses. I had a broken hip that needed surgery</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/bed-4/" rel="attachment wp-att-20604"><img data-attachment-id="20604" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/bed-4/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?fit=480%2C640&amp;ssl=1" data-orig-size="480,640" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="bed" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?fit=480%2C640&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?resize=300%2C400&#038;ssl=1" alt="" width="300" height="400" class="aligncenter wp-image-20604" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?w=480&amp;ssl=1 480w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?resize=300%2C400&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?resize=150%2C200&amp;ssl=1 150w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1" /></a></p>
<p><P><br />
I also had several COVID related illnesses, and some terrible GI issues. I am trying to get better. Thanks to my dear wife Kathryn Farley I have finally started to get better. I cannot ever thank her enough.  Kenneth Regan and Rich DeMillo and many others have also helped me. Thanks to you all. </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/kkrr/" rel="attachment wp-att-20607"><img data-attachment-id="20607" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/kkrr/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/KKRR.png?fit=739%2C299&amp;ssl=1" data-orig-size="739,299" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="KKRR" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/KKRR.png?fit=300%2C121&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/KKRR.png?fit=600%2C243&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/KKRR.png?resize=550%2C223&#038;ssl=1" alt="" width="550" height="223" class="aligncenter wp-image-20607" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/KKRR.png?w=739&amp;ssl=1 739w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/KKRR.png?resize=300%2C121&amp;ssl=1 300w" sizes="(max-width: 550px) 100vw, 550px" data-recalc-dims="1" /></a></p>
<p><P><br />
I have dodged emails and phone calls in the interim. I feel often that I am overcome with my illnesses. I am finally making some progress and I hope that I will be able to respond to you.</p>
<p>
I also plan on working more on the blog and hope you all will enjoy reading it again. Thanks for your support in the past and hope you enjoy it again.  I have been able to get out more in the past six weeks.</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/coney2/" rel="attachment wp-att-20612"><img data-attachment-id="20612" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/coney2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?fit=1260%2C427&amp;ssl=1" data-orig-size="1260,427" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Coney2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?fit=300%2C102&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?fit=600%2C203&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?resize=600%2C203&#038;ssl=1" alt="" width="600" height="203" class="aligncenter size-large wp-image-20612" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?resize=1024%2C347&amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?resize=300%2C102&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?resize=768%2C260&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?resize=1200%2C407&amp;ssl=1 1200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?w=1260&amp;ssl=1 1260w" sizes="(max-width: 600px) 100vw, 600px" data-recalc-dims="1" /></a></p>
<p><P><br />
Thanks to all your your support over the many years. It means the world to me. Happy holidays to all and a wonderful fruitful 2023 to everyone. (2023 is not a prime by the way.)</p>
<p>
Finally thanks to Kathryn once again. </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/card2/" rel="attachment wp-att-20610"><img data-attachment-id="20610" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/card2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/card2.jpeg?fit=640%2C427&amp;ssl=1" data-orig-size="640,427" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="card2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/card2.jpeg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/card2.jpeg?fit=600%2C400&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/card2.jpeg?resize=400%2C267&#038;ssl=1" alt="" width="400" height="267" class="aligncenter wp-image-20610" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/card2.jpeg?w=640&amp;ssl=1 640w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/card2.jpeg?resize=300%2C200&amp;ssl=1 300w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1" /></a></p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T23:25:51Z">Friday, December 09 2022, 23:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/09/faculty-at-university-of-southern-california-apply-by-january-6-2023/'>Faculty at University of Southern California (apply by January 6, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Computer Science Department of the University of Southern California invites applications for multiple positions for tenure-track positions at all ranks. The department is looking for exceptional candidates in all areas of computer science. One or two positions will prioritize candidates in security, privacy, and cryptography. Website: usccareers.usc.edu/job/los-angeles/open-rank-assistant-associate-full-professor-of-computer-science/1209/36964536288 Email: jiapengz@usc.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Computer Science Department of the University of Southern California invites applications for multiple positions for tenure-track positions at all ranks. The department is looking for exceptional candidates in all areas of computer science. One or two positions will prioritize candidates in security, privacy, and cryptography.</p>
<p>Website: <a href="https://usccareers.usc.edu/job/los-angeles/open-rank-assistant-associate-full-professor-of-computer-science/1209/36964536288">https://usccareers.usc.edu/job/los-angeles/open-rank-assistant-associate-full-professor-of-computer-science/1209/36964536288</a><br />
Email: jiapengz@usc.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T18:27:16Z">Friday, December 09 2022, 18:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://processalgebra.blogspot.com/2022/12/report-on-formative-research-evaluation.html'>Report on the formative research evaluation of the Department of Computer Science at Reykjavik University</a></h3>
        <p class='tr-article-feed'>from <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p><br>I am pleased to share with you the report I received yesterday from the panel that carried out a formative research evaluation review for the Department of Computer Science at Reykjavik University last month. (See below for some excerpts from the report.) The (IMHO, stellar) review panel consisted of Geraldine Fitzpatrick (TU Wien, Austria),  Kim Guldstrand Larsen (Aalborg University, Denmark) and Michael Wooldridge (University of Oxford, United Kingdom). </p><p>Our evaluators have given us a lot of food for thought, have identified several challenges for the department and have given us many recommendations we might follow to improve our research environment and work, as well as its impact. I trust that some of those remarks will be useful for the university as a whole.&nbsp;</p><p>Our next task as a department will be to do justice to the work of the review panel and build on it to improve our research environment and output.</p><p>I thank all my colleagues at the department, including postdocs and PhD students of course, whose creativity, drive, enthusiasm and research work have contributed to building a research environment that, in my admittedly very biassed opinion, punches well above its weight. I am very proud of their work.&nbsp;</p><p>However, we have to keep our feet on the ground and realise that, as the challenges identified by the review panel indicate, we are just starting our journey.<br>&nbsp;</p><p>Excerpts from the formative review report</p><p>"Overall we were pleased and impressed to find that a department which is very young in international terms has succeeded in establishing itself as an internationally competitive hub for Computer Science research. This is a noteworthy achievement by any measure, but is particularly impressive when considering the highly competitive culture of international computer science research, where world-class researchers are very highly-sought after and are able to demand highly lucrative packages.</p><p><br>We repeatedly heard that the department is a highly collegial environment, and has largely avoided the curse of factionalism that taints so many university departments.<br>&nbsp;</p><p>We were impressed by the international links that the department has been able to establish, with many visitors who clearly contribute to the research culture of the department at all levels. We saw evidence that directly experiencing this culture has been instrumental in a number of hires and in attracting PhD students.<br>&nbsp;</p><p>The self-evaluation report we were provided with gave a number of key performance indicators, such as volume of publications in internationally competitive journal and conference venues, research awards such as best-paper prizes, and the acquisition of research funding. We were pleased to note that, modulo some expected minor year-on-year variations, all of these measures seem to be on a positive upward trajectory.<br>&nbsp;</p><p>We noted that much of the Departmentâs research portfolio is strongly interdisciplinary, and addresses key societal challenges with demonstrable national impact.<br>&nbsp;</p><p>Finally, we noted that the Department does well in terms of diversity at faculty level, with an increased number of female staff. Other aspects of diversity are less clear, though this perhaps represents Icelandâs racial demographic."</p><p>With my ICE-TCS glasses on, I was delighted to read the panel's opinion on our centre:</p><p>"We were truly impressed by ICE-TCS that in a short span of time (inaugurated in 2005) has established itself as a world-class center within Theoretical Computer Science (TCS). In particular, we find that the center has been extremely successful combining Track A and Track B of TCS with notable research contributions within and recognitions from the sub-fields of Concurrency Theory, Logic, Programming Languages, Combinatorics and Algorithms."</p><p>As a centre, we will strive to improve following the panel's recommendations and to develop a crisp, overarching research vision for the coming few years, which may help us keep spreading the TCS gospel in Iceland and attract talent to the country. <br></p><p>By Luca Aceto</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><br />I am pleased to share with you the <a href="http://icetcs.ru.is/DCS-Reykjavik-Formative-Research-Review-November2022.pdf" target="_blank">report</a> I received yesterday from the panel that carried out a formative research evaluation review for the Department of Computer Science at Reykjavik University last month. (See below for some excerpts from the report.) The (IMHO, stellar) review panel consisted of <a href="http://igw.tuwien.ac.at/hci/people/gfitzpatrick">Geraldine Fitzpatrick</a> (TU Wien, Austria),  <a href="https://homes.cs.aau.dk/~kgl/">Kim Guldstrand Larsen</a> (Aalborg University, Denmark) and <a href="https://www.cs.ox.ac.uk/people/michael.wooldridge/">Michael Wooldridge</a> (University of Oxford, United Kingdom). </p><p>Our evaluators have given us a lot of food for thought, have identified several challenges for the department and have given us many recommendations we might follow to improve our research environment and work, as well as its impact. I trust that some of those remarks will be useful for the university as a whole.&nbsp;</p><p>Our next task as a department will be to do justice to the work of the review panel and build on it to improve our research environment and output.</p><p>I thank all my colleagues at the department, including postdocs and PhD students of course, whose creativity, drive, enthusiasm and research work have contributed to building a research environment that, in my admittedly very biassed opinion, punches well above its weight. I am very proud of their work.&nbsp;</p><p>However, we have to keep our feet on the ground and realise that, as the challenges identified by the review panel indicate, we are just starting our journey.<br />&nbsp;</p><p><b>Excerpts from the formative review report</b></p><p style="margin-left: 40px; text-align: left;">"Overall we were pleased and impressed to find that a department which is very young in international terms has succeeded in establishing itself as an internationally competitive hub for Computer Science research. This is a noteworthy achievement by any measure, but is particularly impressive when considering the highly competitive culture of international computer science research, where world-class researchers are very highly-sought after and are able to demand highly lucrative packages.</p><p style="margin-left: 40px; text-align: left;"><br />We repeatedly heard that the department is a highly collegial environment, and has largely avoided the curse of factionalism that taints so many university departments.<br />&nbsp;</p><p style="margin-left: 40px; text-align: left;">We were impressed by the international links that the department has been able to establish, with many visitors who clearly contribute to the research culture of the department at all levels. We saw evidence that directly experiencing this culture has been instrumental in a number of hires and in attracting PhD students.<br />&nbsp;</p><p style="margin-left: 40px; text-align: left;">The self-evaluation report we were provided with gave a number of key performance indicators, such as volume of publications in internationally competitive journal and conference venues, research awards such as best-paper prizes, and the acquisition of research funding. We were pleased to note that, modulo some expected minor year-on-year variations, all of these measures seem to be on a positive upward trajectory.<br />&nbsp;</p><p style="margin-left: 40px; text-align: left;">We noted that much of the Departmentâs research portfolio is strongly interdisciplinary, and addresses key societal challenges with demonstrable national impact.<br />&nbsp;</p><p style="margin-left: 40px; text-align: left;">Finally, we noted that the Department does well in terms of diversity at faculty level, with an increased number of female staff. Other aspects of diversity are less clear, though this perhaps represents Icelandâs racial demographic."</p><p>With my <a href="http://www.icetcs.ru.is/" target="_blank">ICE-TCS</a> glasses on, I was delighted to read the panel's opinion on our centre:</p><p style="margin-left: 40px; text-align: left;">"We were truly impressed by ICE-TCS that in a short span of time (inaugurated in 2005) has established itself as a world-class center within Theoretical Computer Science (TCS). In particular, we find that the center has been extremely successful combining Track A and Track B of TCS with notable research contributions within and recognitions from the sub-fields of Concurrency Theory, Logic, Programming Languages, Combinatorics and Algorithms."</p><p>As a centre, we will strive to improve following the panel's recommendations and to develop a crisp, overarching research vision for the coming few years, which may help us keep spreading the TCS gospel in Iceland and attract talent to the country. <br /></p><p class="authors">By Luca Aceto</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T10:17:00Z">Friday, December 09 2022, 10:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/09/faculty-at-georgia-tech-apply-by-december-31-2022/'>Faculty at Georgia Tech (apply by December 31, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Faculty Position at Georgia Tech SCS. Website: academicjobsonline.org/ajo/jobs/23304 Email: ssingla@gatech.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Faculty Position at Georgia Tech SCS.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/23304">https://academicjobsonline.org/ajo/jobs/23304</a><br />
Email: ssingla@gatech.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T08:23:00Z">Friday, December 09 2022, 08:23</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04166'>On the strong metric dimension of composed graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marcel Wagner, Yannick Schmitz, Egon Wanke</p><p>Two vertices $u$ and $v$ of an undirected graph $G$ are strongly resolved by
a vertex $w$ if there is a shortest path between $w$ and $u$ containing $v$ or
a shortest path between $w$ and $v$ containing $u$. A vertex set $R$ is a
strong resolving set for $G$ if for each pair of vertices there is a vertex in
$R$ that strongly resolves them. The strong metric dimension of $G$ is the size
of a minimum strong resolving set for $G$. We show that a minimum strong
resolving set for an undirected graph $G$ can be computed efficiently if and
only if a minimum strong resolving set for each biconnected component of $G$
can be computed efficiently.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wagner_M/0/1/0/all/0/1">Marcel Wagner</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmitz_Y/0/1/0/all/0/1">Yannick Schmitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Wanke_E/0/1/0/all/0/1">Egon Wanke</a></p><p>Two vertices $u$ and $v$ of an undirected graph $G$ are strongly resolved by
a vertex $w$ if there is a shortest path between $w$ and $u$ containing $v$ or
a shortest path between $w$ and $v$ containing $u$. A vertex set $R$ is a
strong resolving set for $G$ if for each pair of vertices there is a vertex in
$R$ that strongly resolves them. The strong metric dimension of $G$ is the size
of a minimum strong resolving set for $G$. We show that a minimum strong
resolving set for an undirected graph $G$ can be computed efficiently if and
only if a minimum strong resolving set for each biconnected component of $G$
can be computed efficiently.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T01:30:00Z">Friday, December 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04207'>Gap Preserving Reductions between Reconfiguration Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Naoto Ohsaka</p><p>Combinatorial reconfiguration is a growing research field studying problems
on the transformability between a pair of solutions of a search problem. We
consider the approximability of optimization variants of reconfiguration
problems; e.g., for a Boolean formula $\varphi$ and two satisfying truth
assignments $\sigma_{\sf s}$ and $\sigma_{\sf t}$ for $\varphi$, Maxmin SAT
Reconfiguration requires to maximize the minimum fraction of satisfied clauses
of $\varphi$ during transformation from $\sigma_{\sf s}$ to $\sigma_{\sf t}$.
Solving such optimization variants approximately, we may obtain a
reconfiguration sequence comprising almost-satisfying truth assignments.
</p>
<p>In this study, we prove a series of gap-preserving reductions to give
evidence that a host of reconfiguration problems are PSPACE-hard to
approximate, under some plausible assumption. Our starting point is a new
working hypothesis called the Reconfiguration Inapproximability Hypothesis
(RIH), which asserts that a gap version of Maxmin CSP Reconfiguration is
PSPACE-hard. This hypothesis may be thought of as a reconfiguration analogue of
the PCP theorem. Our main result is PSPACE-hardness of approximating Maxmin
$3$-SAT Reconfiguration of bounded occurrence under RIH. The crux of its proof
is a gap-preserving reduction from Maxmin Binary CSP Reconfiguration to itself
of bounded degree. Because a simple application of the degree reduction
technique using expander graphs due to Papadimitriou and Yannakakis does not
preserve the perfect completeness, we modify the alphabet as if each vertex
could take a pair of values simultaneously. To accomplish the soundness
requirement, we further apply an explicit family of near-Ramanujan graphs and
the expander mixing lemma. As an application of the main result, we demonstrate
that under RIH, optimization variants of popular reconfiguration problems are
PSPACE-hard to approximate.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ohsaka_N/0/1/0/all/0/1">Naoto Ohsaka</a></p><p>Combinatorial reconfiguration is a growing research field studying problems
on the transformability between a pair of solutions of a search problem. We
consider the approximability of optimization variants of reconfiguration
problems; e.g., for a Boolean formula $\varphi$ and two satisfying truth
assignments $\sigma_{\sf s}$ and $\sigma_{\sf t}$ for $\varphi$, Maxmin SAT
Reconfiguration requires to maximize the minimum fraction of satisfied clauses
of $\varphi$ during transformation from $\sigma_{\sf s}$ to $\sigma_{\sf t}$.
Solving such optimization variants approximately, we may obtain a
reconfiguration sequence comprising almost-satisfying truth assignments.
</p>
<p>In this study, we prove a series of gap-preserving reductions to give
evidence that a host of reconfiguration problems are PSPACE-hard to
approximate, under some plausible assumption. Our starting point is a new
working hypothesis called the Reconfiguration Inapproximability Hypothesis
(RIH), which asserts that a gap version of Maxmin CSP Reconfiguration is
PSPACE-hard. This hypothesis may be thought of as a reconfiguration analogue of
the PCP theorem. Our main result is PSPACE-hardness of approximating Maxmin
$3$-SAT Reconfiguration of bounded occurrence under RIH. The crux of its proof
is a gap-preserving reduction from Maxmin Binary CSP Reconfiguration to itself
of bounded degree. Because a simple application of the degree reduction
technique using expander graphs due to Papadimitriou and Yannakakis does not
preserve the perfect completeness, we modify the alphabet as if each vertex
could take a pair of values simultaneously. To accomplish the soundness
requirement, we further apply an explicit family of near-Ramanujan graphs and
the expander mixing lemma. As an application of the main result, we demonstrate
that under RIH, optimization variants of popular reconfiguration problems are
PSPACE-hard to approximate.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T01:30:00Z">Friday, December 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04117'>Coloring Inside the Lines: The Jagged Legacy of the HOLC Neighborhood Risk Maps</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arunav Gupta</p><p>There has been a large body of work exploring the discriminatory nature of
the home mortgage risk maps produced by the Home Owners' Loan Corporation in
the late 1930s. However, little attention has been paid to the question of
whether these maps are still descriptive of racial residential boundaries in
their cities 80 years after their creation. To address this gap, Markov Chain
Monte Carlo, previously unutilized in the relevant literature, is employed to
randomly generate many plausible alternative mortgage security maps. Then, the
racial evenness of the HOLC maps and the generated maps is compared using
Shannon's entropy. These findings indicate that the HOLC maps are significantly
descriptive of the precise racial residential boundaries prevalent across
eleven US cities in 2010. The methodology used here is highly modular and
reproducible, allowing for future work measuring different outcome statistics,
locations, and time periods.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Gupta_A/0/1/0/all/0/1">Arunav Gupta</a></p><p>There has been a large body of work exploring the discriminatory nature of
the home mortgage risk maps produced by the Home Owners' Loan Corporation in
the late 1930s. However, little attention has been paid to the question of
whether these maps are still descriptive of racial residential boundaries in
their cities 80 years after their creation. To address this gap, Markov Chain
Monte Carlo, previously unutilized in the relevant literature, is employed to
randomly generate many plausible alternative mortgage security maps. Then, the
racial evenness of the HOLC maps and the generated maps is compared using
Shannon's entropy. These findings indicate that the HOLC maps are significantly
descriptive of the precise racial residential boundaries prevalent across
eleven US cities in 2010. The methodology used here is highly modular and
reproducible, allowing for future work measuring different outcome statistics,
locations, and time periods.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T01:30:00Z">Friday, December 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03906'>Quantum Lower Bounds for Finding Stationary Points of Nonconvex Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chenyi Zhang, Tongyang Li</p><p>Quantum algorithms for optimization problems are of general interest. Despite
recent progress in classical lower bounds for nonconvex optimization under
different settings and quantum lower bounds for convex optimization, quantum
lower bounds for nonconvex optimization are still widely open. In this paper,
we conduct a systematic study of quantum query lower bounds on finding
$\epsilon$-approximate stationary points of nonconvex functions, and we
consider the following two important settings: 1) having access to $p$-th order
derivatives; or 2) having access to stochastic gradients. The classical query
lower bounds is $\Omega\big(\epsilon^{-\frac{1+p}{p}}\big)$ regarding the first
setting, and $\Omega(\epsilon^{-4})$ regarding the second setting (or
$\Omega(\epsilon^{-3})$ if the stochastic gradient function is mean-squared
smooth). In this paper, we extend all these classical lower bounds to the
quantum setting. They match the classical algorithmic results respectively,
demonstrating that there is no quantum speedup for finding
$\epsilon$-stationary points of nonconvex functions with $p$-th order
derivative inputs or stochastic gradient inputs, whether with or without the
mean-squared smoothness assumption. Technically, our quantum lower bounds are
obtained by showing that the sequential nature of classical hard instances in
all these settings also applies to quantum queries, preventing any quantum
speedup other than revealing information of the stationary points sequentially.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Zhang_C/0/1/0/all/0/1">Chenyi Zhang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Li_T/0/1/0/all/0/1">Tongyang Li</a></p><p>Quantum algorithms for optimization problems are of general interest. Despite
recent progress in classical lower bounds for nonconvex optimization under
different settings and quantum lower bounds for convex optimization, quantum
lower bounds for nonconvex optimization are still widely open. In this paper,
we conduct a systematic study of quantum query lower bounds on finding
$\epsilon$-approximate stationary points of nonconvex functions, and we
consider the following two important settings: 1) having access to $p$-th order
derivatives; or 2) having access to stochastic gradients. The classical query
lower bounds is $\Omega\big(\epsilon^{-\frac{1+p}{p}}\big)$ regarding the first
setting, and $\Omega(\epsilon^{-4})$ regarding the second setting (or
$\Omega(\epsilon^{-3})$ if the stochastic gradient function is mean-squared
smooth). In this paper, we extend all these classical lower bounds to the
quantum setting. They match the classical algorithmic results respectively,
demonstrating that there is no quantum speedup for finding
$\epsilon$-stationary points of nonconvex functions with $p$-th order
derivative inputs or stochastic gradient inputs, whether with or without the
mean-squared smoothness assumption. Technically, our quantum lower bounds are
obtained by showing that the sequential nature of classical hard instances in
all these settings also applies to quantum queries, preventing any quantum
speedup other than revealing information of the stationary points sequentially.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T01:30:00Z">Friday, December 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03945'>Fast and Practical DAG Decomposition with Reachability Applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Giorgos Kritikakis, Ioannis G. Tollis</p><p>We present practical linear and almost linear-time algorithms to compute a
chain decomposition of a directed acyclic graph (DAG), $G=(V,E)$. The number of
vertex-disjoint chains computed is very close to the minimum. The time
complexity of our algorithm is $O(|E|+c*l)$, where $c$ is the number of path
concatenations and $l$ is the length of a longest path of the graph. We give a
comprehensive explanation on factors $c$ and $l$ in the following sections. Our
techniques have important applications in many areas, including the design of
faster practical transitive closure algorithms. We observe that $|E_{red}|\leq
width*|V|$ ($E_{red}$: non-transitive edges) and show how to find a
substantially large subset of $E_{tr}$ (transitive edges) using a chain
decomposition in linear time, without calculating the transitive closure. Our
extensive experimental results show the interplay between the width, $E_{red}$,
$E_{tr}$ in various models of graphs. We show how to compute a reachability
indexing scheme in $O(k_c*|E_{red}|)$ time, where $k_c$ is the number of chains
and $|E_{red}|$ is the number of non-transitive edges. This scheme can answer
reachabilitiy queries in constant time. The space complexity of the scheme is
$O(k_c*|V|)$. The experimental results reveal that our methods are even better
in practice than the theoretical bounds imply, indicating how fast chain
decomposition algorithms can be applied to the transitive closure problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kritikakis_G/0/1/0/all/0/1">Giorgos Kritikakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tollis_I/0/1/0/all/0/1">Ioannis G. Tollis</a></p><p>We present practical linear and almost linear-time algorithms to compute a
chain decomposition of a directed acyclic graph (DAG), $G=(V,E)$. The number of
vertex-disjoint chains computed is very close to the minimum. The time
complexity of our algorithm is $O(|E|+c*l)$, where $c$ is the number of path
concatenations and $l$ is the length of a longest path of the graph. We give a
comprehensive explanation on factors $c$ and $l$ in the following sections. Our
techniques have important applications in many areas, including the design of
faster practical transitive closure algorithms. We observe that $|E_{red}|\leq
width*|V|$ ($E_{red}$: non-transitive edges) and show how to find a
substantially large subset of $E_{tr}$ (transitive edges) using a chain
decomposition in linear time, without calculating the transitive closure. Our
extensive experimental results show the interplay between the width, $E_{red}$,
$E_{tr}$ in various models of graphs. We show how to compute a reachability
indexing scheme in $O(k_c*|E_{red}|)$ time, where $k_c$ is the number of chains
and $|E_{red}|$ is the number of non-transitive edges. This scheme can answer
reachabilitiy queries in constant time. The space complexity of the scheme is
$O(k_c*|V|)$. The experimental results reveal that our methods are even better
in practice than the theoretical bounds imply, indicating how fast chain
decomposition algorithms can be applied to the transitive closure problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T01:30:00Z">Friday, December 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03957'>DeMEtRIS: Counting (near)-Cliques by Crawling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Suman K.Bera, Jayesh Choudhari, Shahrzad Haddadan, Sara Ahmadian</p><p>We study the problem of approximately counting cliques and near cliques in a
graph, where the access to the graph is only available through crawling its
vertices; thus typically seeing only a small portion of it. This model, known
as the random walk model or the neighborhood query model has been introduced
recently and captures real-life scenarios in which the entire graph is too
massive to be stored as a whole or be scanned entirely and sampling vertices
independently is non-trivial in it. We introduce DeMEtRIS: Dense Motif
Estimation through Random Incident Sampling. This method provides a scalable
algorithm for clique and near clique counting in the random walk model. We
prove the correctness of our algorithm through rigorous mathematical analysis
and extensive experiments. Both our theoretical results and our experiments
show that DeMEtRIS obtains a high precision estimation by only crawling a
sub-linear portion on vertices, thus we demonstrate a significant improvement
over previously known results.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bera_S/0/1/0/all/0/1">Suman K.Bera</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhari_J/0/1/0/all/0/1">Jayesh Choudhari</a>, <a href="http://arxiv.org/find/cs/1/au:+Haddadan_S/0/1/0/all/0/1">Shahrzad Haddadan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmadian_S/0/1/0/all/0/1">Sara Ahmadian</a></p><p>We study the problem of approximately counting cliques and near cliques in a
graph, where the access to the graph is only available through crawling its
vertices; thus typically seeing only a small portion of it. This model, known
as the random walk model or the neighborhood query model has been introduced
recently and captures real-life scenarios in which the entire graph is too
massive to be stored as a whole or be scanned entirely and sampling vertices
independently is non-trivial in it. We introduce DeMEtRIS: Dense Motif
Estimation through Random Incident Sampling. This method provides a scalable
algorithm for clique and near clique counting in the random walk model. We
prove the correctness of our algorithm through rigorous mathematical analysis
and extensive experiments. Both our theoretical results and our experiments
show that DeMEtRIS obtains a high precision estimation by only crawling a
sub-linear portion on vertices, thus we demonstrate a significant improvement
over previously known results.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T01:30:00Z">Friday, December 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, December 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://ptreview.sublinear.info/2022/12/news-for-october-2022-2/'>News for November 2022</a></h3>
        <p class='tr-article-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          All the best to everyone for a Happy 2023. The holiday season is ripe with lots of papers to engage our readers. So, we have nine papers and we hope some of those will catch your fancy. As a new year treat, we also feature Gilmer&#8217;s constant lower bound on the union-closed sets problem of [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>All the best to everyone for a Happy 2023. The holiday season is ripe with lots of papers to engage our readers. So, we have nine papers and we hope some of those will catch your fancy. As a new year treat, we also feature Gilmer&#8217;s constant lower bound on the union-closed sets problem of Frankl. On we go.</p>



<p></p>



<p><strong>Sublinear Time Algorithms and Complexity of Approximate Maximum Matching</strong> by Soheil Behnezhad, Mohammad Roghani, Aviad Rubinstein (<a href="https://arxiv.org/abs/2211.15843">arXiv</a>) This paper makes significantly advances our understanding of the maximum matching problem in the sublinear regime. Your goal is to estimate the size of the maximum matching and you may assume that you have query access to the adjacency list of your graph. Our posts from <a href="https://ptreview.sublinear.info/2021/12/">Dec 2021</a> and <a href="https://ptreview.sublinear.info/2022/07/news-for-june-2022/">June 2022</a> reported some impressive progress on this problem. The upshot from these works essentially said that you can beat greedy matching and obtain a \(\frac{1}{2} + \Omega(1)\) approximate maximum matching in sublinear time. Let me first go over the algorithmic results from the current paper. The paper shows the following two algorithmic results:</p>



<p>(1) An algorithm that runs in time \(n^{2 &#8211; \Omega_{\varepsilon}(1)}\) and returns a \(2/3 &#8211; \varepsilon\) approximation to maximum matching in general graphs, and </p>



<p>(2) An algorithm that runs in time \(n^{2 &#8211; \Omega_{\varepsilon}(1)}\) and returns a \(2/3 + \varepsilon\) approximation to maximum matching size in <em>bipartite</em> graphs. </p>



<p>The question remained &#8212; can we show a lower bound that grows superlinearly with \(n\). The current work achieves this and shows that <em>even on bipartite graphs</em>, you must make at least \(n^{1.2 &#8211; o(1)}\) <em>queries </em>to the adjacency list to get a better than \(2/3 + \Omega(1)\) approximation.  Thus, you cannot shoot for a bonafide quadratic lower bound on the number of queries to beat a two-thirds approximation to the maximum matching size.  (An aside: A concurrent work by <a href="https://arxiv.org/abs/2212.00189">Bhattacharya-Kiss-Saranurak</a> from December also obtains similar algorithmic results for approximating the maximum matching size in general graphs). </p>



<p><strong>Directed Isoperimetric Theorems for Boolean Functions on the Hypergrid and an \(\widetilde{O}(n \sqrt d)\) Monotonicity Tester</strong> by Hadley Black, Deeparnab Chakrabarty, C. Seshadhri (<a href="https://arxiv.org/abs/2211.05281">arXiv</a>) Boolean Monotonicity testing is as classic as classic gets in property testing. Encouraged by the success of isoperimetric theorems over the hypercube domain and the monotonicity testers powered by these isoperimetries (over the hypercube), one may wish to obtain efficient monotonicity testers for the hypergrid \([n]^d\). Indeed, the same gang of authors as above showed in a previous work that a Margulis style directed isoperimetry can be extended from the lowly hypercube to the hypergrid. This resulted in a tester with \(\widetilde{O}(d^{5/6})\) queries. The more intricate task of proving a directed Talagrand style isoperimetry that underlies the Khot-Minzer-Safra breakthrough was a challenge. Was. The featured work extends this isoperimetry from the hypercube to the hypergrid and this gives a tester with query complexity \(\widetilde{O}(n \sqrt d)\) which is an improvement over the \(d^{5/6}\) bound for domains where \(n\) is (say) some small constant. But as they say, when it rains, it pours. This brings us to a concurrent paper with the same result.</p>



<p></p>



<p><strong>Improved Monotonicity Testers via Hypercube Embeddings</strong> by Mark Braverman, Subhash Khot, Guy Kindler, Dor Minzer (<a href="https://arxiv.org/abs/2211.09229">arXiv</a>) Similar to the paper above, this paper also obtains monotonicity testers over the hypergrid domain, \([n]^d\), with \(\widetilde{O}(n^3 \sqrt d)\) queries. This paper also presents monotonicity testers over the standard hypercube domain &#8212; \(\{0,1\}^d\) in the \(p\)-biased setting. In particular, their tester issues \(\widetilde{O}(\sqrt d)\) queries to successfully test monotonicity on the \(p\)-biased cube. Coolly enough, this paper also proves directed Talagrand style isoperimetric inequalities both over the hypergrid and the \(p\)-biased hypercube domains.</p>



<p><strong>Toeplitz Low-Rank Approximation with Sublinear Query Complexity</strong> by Michael Kapralov, Hannah Lawrence, Mikhail Makarov, Cameron Musco, Kshiteej Sheth (<a href="https://arxiv.org/abs/2211.11328">arXiv</a>) Another intriguing paper for the holiday month. So, take a <a href="https://en.wikipedia.org/wiki/Toeplitz_matrix">Toeplitz matrix</a>. Did you know that any <em>psd</em> Toeplitz matrix admits a (near-optimal in the Frobenius norm) low-rank approximation which is itself Toeplitz? This is a remarkable statement. The featured paper proves this result and uses it to get more algorithmic mileage. In particular, suppose you are given a \(d \times d\) Toeplitz matrix \(T\). Armed with the techniques from the paper you get algorithms that return a Toeplitz matrix \(\widetilde{T}\) with rank slightly bigger than \(rank(T)\) which is a very good approximation to \(T\) in the Frobenius norm. Moreover, the algorithm only issues a number of queries sublinear in the size of \(T\).</p>



<p></p>



<p><strong>Sampling an Edge in Sublinear Time Exactly and Optimally</strong> by Talya Eden, Shyam Narayanan and Jakub TÄtek (<a href="https://arxiv.org/abs/2211.04981">arXiv</a>) Regular readers of PTReview are no strangers to the fundamental task of sampling a random edge from a graph which you can access via query access to its vertices. Of course, you don&#8217;t have direct access to the edges of this graph. This paper considers the task of sampling a truly uniform edge from the graph \(G = (V,E)\) with \(|V| = n, |E| = m\). In STOC 22, TÄtek and Thorup presented an algorithm for a relaxation of this problem where you want an \(\varepsilon\)-approximately unifrom edge. This algorithm runs in time \(O\left(\frac{n}{\sqrt{m}} \cdot \log(1/\varepsilon) \right)\). The featured paper presents an algorithm that samples an honest to goodness uniform edge in expected time \(O(n/\sqrt{m})\). This closes the problem as we already know a matching lower bound. Indeed, just consider a graph with \(O(\sqrt m)\) vertices which induce a clique and all the remaining components are singletons. You need to sample at least \(\Omega(n/\sqrt m)\) vertices before you see any edge.</p>



<p></p>



<p><strong>Support Size Estimation: The Power of Conditioning</strong> by Diptarka Chakraborty, Gunjan Kumar, Kuldeep S. Meel (<a href="https://arxiv.org/abs/2211.11967">arXiv</a>) This work considers the classic problem of support size estimation with a slight twist. You are given access to a stronger (conditioning based) sampling oracle. Let me highlight one of the results from this paper. So, you are given a distribution \(D\) where \(supp(D) \subseteq [n]\). You want to obtain an estimate to \(supp(D)\) that lies within \(supp(D) \pm \varepsilon n\) with high probability. Suppose you are also given access to the following sampling oracle. You may choose any subset \(S \subseteq [n]\) and you may request a sample \(x \sim D\vert_S\). An element \(x \in S\) is returned with probability \(D\vert_S(x) = D(x)/D(S)\) (for simplicity of this post, let us assume \(D(S) &gt; 0\)). In addition, this oracle also reveals for you the value \(D(x)\). The paper shows that the algorithmic task of obtaining a high probability estimate to the support size (to within \(\pm \varepsilon n\)) with this sampling oracle admits a lower bound of \(\Omega(\log (\log n)\) calls to the sampling oracle.</p>



<p><strong>Computing (1+epsilon)-Approximate Degeneracy in Sublinear Time</strong> by Valerie King, Alex Thomo, Quinton Yong (<a href="https://arxiv.org/abs/2211.04627">arXiv</a>) Degeneracy is one of the important graph parameters which is relevant to several problems in algorithmic graph theory. A graph \(G = (V,E)\) is \(\delta\)-degenerate if all induced subgraphs of \(G\) contain a vertex with degree at most \(\delta\). The featured paper presents algorithms for a \((1 + \varepsilon)\)-approximation to degeneracy of \(G\) where you are given access to \(G\) via its adjacency list. </p>



<p><strong>Learning and Testing Latent-Tree Ising Models Efficiently</strong> by Davin Choo, Yuval Dagan, Constantinos Daskalakis, Anthimos Vardis Kandiros (<a href="https://arxiv.org/abs/2211.13291">arXiv</a>) Ising models are emerging as a rich and fertile frontier for Property Testing and Learning Theory researchers (at least to the uninitiated ones like me). This paper considers latent-tree ising models. These are ising models that can only be observed at their leaf nodes. One of the results in this paper gives an algorithm for testing whether the leaf distributions attached to two latent-tree ising models are close or far in the TV distance.</p>



<p></p>



<p><strong>A constant lower bound for the union-closed sets conjecture</strong> by Justin Gilmer (<a href="https://arxiv.org/abs/2211.09055">arXiv</a>) The union-closed sets conjecture of Frankl states that for any union closed set system \(\mathcal{F} \subseteq 2^{[n]}\), it holds that there is a mysterious element \(i \in [n]\) that shows up in at least \(c = 1/2\) of the sets in \(\mathcal{F}\). Gilmer took a first swipe on this problem and gave a constant lower bound of \(c = 0.01\). This has already been improved by at least four different groups to \(\frac{3-\sqrt{5}}{2}\), a bound which is the limit of Gilmer&#8217;s method (which takes all of only 9 pages!). </p>



<p>The key lemma Gilmer proves is the following. Suppose you sample two sets: \(A, B \sim \mathcal{D}_n\) <em>(iid)</em> from some distribution \(\mathcal{D}_n\) over the subsets of \([n]\). Suppose for every index \(i \in [n]\), it holds that the probability that the element \(i\) shows up in the random set \(A\) is at most $0.01$. Then you have \(H(A \cup B) \geq 1.26 H(A)\). This is all you need to finish Gilmer&#8217;s proof (of \(c = 0.01\)). The remaining argument is as follows. Suppose, by the way of contradiction, that no element shows up in at least \(0.01\) fraction of sets in the union closed family \(\mathcal{F}\). An application of the key lemma would then give \(H(A \cup B) &gt; H(A)\) which is a contradiction if \(A,B\) are chosen uniformly from \(\mathcal{F}\). The proof of the key lemma is also fairly slick and uses pretty simple information theoretic tools.</p>
<p class="authors">By Akash</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T18:22:31Z">Thursday, December 08 2022, 18:22</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/12/harry-lewiss-talk-on-birth-of-binary-on.html'>Harry Lewis's talk  on The Birth of Binary on Dec 8 (Thats today!)</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;More on the information on Harry Lewis's&nbsp; talk is in his blog post about it:here</p><p><br></p><p>1) On Dec 8, 2022 Harry Lewis is giving the annual Thoraf Skolem Memorial Lecture on</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;The Birth of binary&nbsp;</p><p>Its in Oslo. BOO- I can't get there!</p><p>It will be on Zoom- YEAH I can see it! Here is the link:&nbsp;here</p>It will be at 7:15AM East Coast Time- BOO- I needs my sleep!(Plus, I am posting this after its over)<br>It will be recorded-YEAH I can see it later. CAVEAT- Will I?<br>(It will be linked to at the link in item 4 below.)<br><br>2) Lloyd Strickland and Harry Lewis have a book on the subject:&nbsp;here&nbsp;titled<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Leibniz on binary: The Invention of Computer Arithmetic.<br>3) Questions like who invented binary&nbsp; or who invented parallelism or&nbsp;who first proved the dual-muffin theorem&nbsp;can be hard to answer.&nbsp;First&nbsp; is an ill defined term. In the current era we can see who published first, which is usually well defined, though might not get at the heart of the issue.<br><br>Which brings us to Leibniz on Binary.&nbsp; He had lots of notes, not really intended for modern readers or even for readers in his own time. The notes lay out binary notation and some algorithms, but not in a modern way. Hence the book is quite valuable to tell a modern audience what Leibniz did. Leibniz published very little of it.&nbsp; Even so, seeing what he did, the statement&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Leibnitz invented binary is reasonable. Some of his notes dealt with what we would now call complexity, so I need to add him to my already-long list of people who had modern ideas about complexity.&nbsp;<br>4) For more on the Skolem Lecture, see&nbsp;here<p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;More on the information on Harry Lewis's&nbsp; talk is in his blog post about it:<a href="http://harry-lewis.blogspot.com/2022/11/skolem-lecture-on-birth-of-binary-8.html">here</a></p><p><br /></p><p>1) On Dec 8, 2022 Harry Lewis is giving the annual Thoraf Skolem Memorial Lecture on</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<i>The Birth of binary&nbsp;</i></p><p>Its in Oslo. BOO- I can't get there!</p><p>It will be on Zoom- YEAH I can see it! Here is the link:&nbsp;<a href="https://uio.zoom.us/j/63956167845">here</a></p><div><div>It will be at 7:15AM East Coast Time- BOO- I needs my sleep!</div><div>(Plus, I am posting this after its over)</div><div><br /></div><div>It will be recorded-YEAH I can see it later. CAVEAT- Will I?</div><div><br /></div><div>(It will be linked to at the link in item 4 below.)</div><div><br /></div><div><br /></div><div>2) Lloyd Strickland and Harry Lewis have a book on the subject:&nbsp;<a href="https://mitpress.mit.edu/9780262544344/leibniz-on-binary/">here</a>&nbsp;titled</div><div><br /></div><div><i>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Leibniz on binary: The Invention of Computer Arithmetic.</i></div></div><div><i><br /></i></div><div><div>3) Questions like <i>who invented binary&nbsp; </i>or <i>who invented parallelism</i> or&nbsp;<i>who first proved the dual-muffin theorem&nbsp;</i>can be hard to answer.&nbsp;<i>First</i>&nbsp; is an ill defined term. In the current era we can see who published first, which is usually well defined, though might not get at the heart of the issue.</div></div><div><br /></div><div><div><br /></div><div>Which brings us to Leibniz on Binary.&nbsp; He had lots of notes, not really intended for modern readers or even for readers in his own time. The notes lay out binary notation and some algorithms, but not in a modern way. Hence the book is quite valuable to tell a modern audience what Leibniz did. Leibniz published very little of it.&nbsp; Even so, seeing what he did, the statement</div><div><i>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Leibnitz invented binary</i></div><div> is reasonable. Some of his notes dealt with what we would now call complexity, so I need to add him to my already-long list of people who had modern ideas about complexity.&nbsp;</div><div><br /></div><div>4) For more on the Skolem Lecture, see&nbsp;<a href="https://www.hf.uio.no/ifikk/english/research/groups/logic/events/">here</a></div></div><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T15:38:00Z">Thursday, December 08 2022, 15:38</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2022/178'>TR22-178 |  A Strongly Polynomial Algorithm for Approximate Forster Transforms and its Application to Halfspace Learning | 

	Ilias Diakonikolas, 

	Christos Tzamos, 

	Daniel Kane</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Forster transform is a method of regularizing a dataset 
by placing it in {\em radial isotropic position}
while maintaining some of its essential properties.
Forster transforms have played a key role in a diverse range of settings
spanning computer science and functional analysis. Prior work had given
{\em weakly} polynomial time algorithms for computing Forster transforms, when they exist.
Our main result is the first {\em strongly polynomial time} algorithm to
compute an approximate Forster transform of a given dataset 
or certify that no such transformation exists. By leveraging our strongly polynomial Forster algorithm, 
we obtain the first strongly polynomial time algorithm for {\em distribution-free} PAC learning of halfspaces.
This learning result is surprising because {\em proper} PAC learning of halfspaces 
is {\em equivalent} to linear programming.
Our learning approach extends to give a strongly polynomial halfspace learner
in the presence of random classification noise and, more generally, Massart noise.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The Forster transform is a method of regularizing a dataset 
by placing it in {\em radial isotropic position}
while maintaining some of its essential properties.
Forster transforms have played a key role in a diverse range of settings
spanning computer science and functional analysis. Prior work had given
{\em weakly} polynomial time algorithms for computing Forster transforms, when they exist.
Our main result is the first {\em strongly polynomial time} algorithm to
compute an approximate Forster transform of a given dataset 
or certify that no such transformation exists. By leveraging our strongly polynomial Forster algorithm, 
we obtain the first strongly polynomial time algorithm for {\em distribution-free} PAC learning of halfspaces.
This learning result is surprising because {\em proper} PAC learning of halfspaces 
is {\em equivalent} to linear programming.
Our learning approach extends to give a strongly polynomial halfspace learner
in the presence of random classification noise and, more generally, Massart noise.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T13:27:12Z">Thursday, December 08 2022, 13:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03457'>Partial gathering of mobile agents in dynamic rings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Masahiro Shibataa, Yuichi Sudo, Junya Nakamura, Yonghwan Kim</p><p>In this paper, we consider the partial gathering problem of mobile agents in
synchronous dynamic bidirectional ring networks. When k agents are distributed
in the network, the partial gathering problem requires, for a given positive
integer g (&lt; k), that agents terminate in a configuration such that either at
least g agents or no agent exists at each node. So far, the partial gathering
problem has been considered in static graphs. In this paper, we start
considering partial gathering in dynamic graphs. As a first step, we consider
this problem in 1-interval connected rings, that is, one of the links in a ring
may be missing at each time step. In such networks, focusing on the
relationship between the values of k and g, we fully characterize the
solvability of the partial gathering problem and analyze the move complexity of
the proposed algorithms when the problem can be solved. First, we show that the
g-partial gathering problem is unsolvable when k &lt;= 2g. Second, we show that
the problem can be solved with O(n log g) time and the total number of O(gn log
g) moves when 2g + 1 &lt;= k &lt;= 3g - 2. Third, we show that the problem can be
solved with O(n) time and the total number of O(kn) moves when 3g - 1 &lt;= k &lt;=
8g - 4. Notice that since k = O(g) holds when 3g - 1 &lt;= k &lt;= 8g - 4, the move
complexity O(kn) in this case can be represented also as O(gn). Finally, we
show that the problem can be solved with O(n) time and the total number of
O(gn) moves when k &gt;= 8g - 3. These results mean that the partial gathering
problem can be solved also in dynamic rings when k &gt;= 2g + 1. In addition,
agents require a total number of \Omega(gn) moves to solve the partial (resp.,
total) gathering problem. Thus, when k &gt;= 3g - 1, agents can solve the partial
gathering problem with the asymptotically optimal total number of O(gn) moves.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Shibataa_M/0/1/0/all/0/1">Masahiro Shibataa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudo_Y/0/1/0/all/0/1">Yuichi Sudo</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakamura_J/0/1/0/all/0/1">Junya Nakamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Yonghwan Kim</a></p><p>In this paper, we consider the partial gathering problem of mobile agents in
synchronous dynamic bidirectional ring networks. When k agents are distributed
in the network, the partial gathering problem requires, for a given positive
integer g (&lt; k), that agents terminate in a configuration such that either at
least g agents or no agent exists at each node. So far, the partial gathering
problem has been considered in static graphs. In this paper, we start
considering partial gathering in dynamic graphs. As a first step, we consider
this problem in 1-interval connected rings, that is, one of the links in a ring
may be missing at each time step. In such networks, focusing on the
relationship between the values of k and g, we fully characterize the
solvability of the partial gathering problem and analyze the move complexity of
the proposed algorithms when the problem can be solved. First, we show that the
g-partial gathering problem is unsolvable when k &lt;= 2g. Second, we show that
the problem can be solved with O(n log g) time and the total number of O(gn log
g) moves when 2g + 1 &lt;= k &lt;= 3g - 2. Third, we show that the problem can be
solved with O(n) time and the total number of O(kn) moves when 3g - 1 &lt;= k &lt;=
8g - 4. Notice that since k = O(g) holds when 3g - 1 &lt;= k &lt;= 8g - 4, the move
complexity O(kn) in this case can be represented also as O(gn). Finally, we
show that the problem can be solved with O(n) time and the total number of
O(gn) moves when k &gt;= 8g - 3. These results mean that the partial gathering
problem can be solved also in dynamic rings when k &gt;= 2g + 1. In addition,
agents require a total number of \Omega(gn) moves to solve the partial (resp.,
total) gathering problem. Thus, when k &gt;= 3g - 1, agents can solve the partial
gathering problem with the asymptotically optimal total number of O(gn) moves.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T01:30:00Z">Thursday, December 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03521'>Recognizing when a preference system is close to admitting a master list</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ildik&#xf3; Schlotter</p><p>A preference system $\mathcal{I}$ is an undirected graph where vertices have
preferences over their neighbors, and $\mathcal{I}$ admits a master list if all
preferences can be derived from a single ordering over all vertices. We study
the problem of deciding whether a given preference system~$\mathcal{I}$ is
close to admitting a master list based on three different distance measures. We
determine the computational complexity of the following questions: can
$\mathcal{I}$ be modified by (i) $k$ swaps in the preferences, (ii) $k$ edge
deletions, or (iii) $k$ vertex deletions so that the resulting instance admits
a master list? We investigate these problems in detail from the viewpoint of
parameterized complexity and of approximation. We also present two applications
related to stable and popular matchings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Schlotter_I/0/1/0/all/0/1">Ildik&#xf3; Schlotter</a></p><p>A preference system $\mathcal{I}$ is an undirected graph where vertices have
preferences over their neighbors, and $\mathcal{I}$ admits a master list if all
preferences can be derived from a single ordering over all vertices. We study
the problem of deciding whether a given preference system~$\mathcal{I}$ is
close to admitting a master list based on three different distance measures. We
determine the computational complexity of the following questions: can
$\mathcal{I}$ be modified by (i) $k$ swaps in the preferences, (ii) $k$ edge
deletions, or (iii) $k$ vertex deletions so that the resulting instance admits
a master list? We investigate these problems in detail from the viewpoint of
parameterized complexity and of approximation. We also present two applications
related to stable and popular matchings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T01:30:00Z">Thursday, December 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03348'>Quantum Worst-Case to Average-Case Reductions for All Linear Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vahid R. Asadi, Alexander Golovnev, Tom Gur, Igor Shinkar, Sathyawageeswar Subramanian</p><p>We study the problem of designing worst-case to average-case reductions for
quantum algorithms. For all linear problems, we provide an explicit and
efficient transformation of quantum algorithms that are only correct on a small
(even sub-constant) fraction of their inputs into ones that are correct on all
inputs. This stands in contrast to the classical setting, where such results
are only known for a small number of specific problems or restricted
computational models. En route, we obtain a tight $\Omega(n^2)$ lower bound on
the average-case quantum query complexity of the Matrix-Vector Multiplication
problem.
</p>
<p>Our techniques strengthen and generalise the recently introduced additive
combinatorics framework for classical worst-case to average-case reductions
(STOC 2022) to the quantum setting. We rely on quantum singular value
transformations to construct quantum algorithms for linear verification in
superposition and learning Bogolyubov subspaces from noisy quantum oracles. We
use these tools to prove a quantum local correction lemma, which lies at the
heart of our reductions, based on a noise-robust probabilistic generalisation
of Bogolyubov's lemma from additive combinatorics.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Asadi_V/0/1/0/all/0/1">Vahid R. Asadi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Golovnev_A/0/1/0/all/0/1">Alexander Golovnev</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Gur_T/0/1/0/all/0/1">Tom Gur</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Shinkar_I/0/1/0/all/0/1">Igor Shinkar</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Subramanian_S/0/1/0/all/0/1">Sathyawageeswar Subramanian</a></p><p>We study the problem of designing worst-case to average-case reductions for
quantum algorithms. For all linear problems, we provide an explicit and
efficient transformation of quantum algorithms that are only correct on a small
(even sub-constant) fraction of their inputs into ones that are correct on all
inputs. This stands in contrast to the classical setting, where such results
are only known for a small number of specific problems or restricted
computational models. En route, we obtain a tight $\Omega(n^2)$ lower bound on
the average-case quantum query complexity of the Matrix-Vector Multiplication
problem.
</p>
<p>Our techniques strengthen and generalise the recently introduced additive
combinatorics framework for classical worst-case to average-case reductions
(STOC 2022) to the quantum setting. We rely on quantum singular value
transformations to construct quantum algorithms for linear verification in
superposition and learning Bogolyubov subspaces from noisy quantum oracles. We
use these tools to prove a quantum local correction lemma, which lies at the
heart of our reductions, based on a noise-robust probabilistic generalisation
of Bogolyubov's lemma from additive combinatorics.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T01:30:00Z">Thursday, December 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03394'>Extending Utility Functions on Arbitrary Sets</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pavel Chebotarev</p><p>We consider the problem of whether a function $f^{}_P$ defined on a subset
$P$ of an arbitrary set $X$ can be extended to $X$ monotonically with respect
to a preorder $\succcurlyeq$ defined on $X$. We prove that whenever
$\succcurlyeq$ has a utility representation, such an extension exists if and
only if $f^{}_P$ is gap-safe increasing. An explicit construction for a
monotone extension of this kind involving an arbitrary utility representation
of $\succcurlyeq$ is presented. The special case where $P$ is a Pareto subset
of $X$ is considered. The problem under study does not include continuity
constraints.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Chebotarev_P/0/1/0/all/0/1">Pavel Chebotarev</a></p><p>We consider the problem of whether a function $f^{}_P$ defined on a subset
$P$ of an arbitrary set $X$ can be extended to $X$ monotonically with respect
to a preorder $\succcurlyeq$ defined on $X$. We prove that whenever
$\succcurlyeq$ has a utility representation, such an extension exists if and
only if $f^{}_P$ is gap-safe increasing. An explicit construction for a
monotone extension of this kind involving an arbitrary utility representation
of $\succcurlyeq$ is presented. The special case where $P$ is a Pareto subset
of $X$ is considered. The problem under study does not include continuity
constraints.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T01:30:00Z">Thursday, December 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03684'>A Decision Diagram Operation for Reachability</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sebastiaan Brand, Thomas B&#xe4;ck, Alfons Laarman</p><p>Saturation is considered the state-of-the-art method for computing fixpoints
with decision diagrams. We present a relatively simple decision diagram
operation called REACH that also computes fixpoints. In contrast to saturation,
it does not require a partitioning of the transition relation. We give
sequential algorithms implementing the new operation for both binary and
multi-valued decision diagrams, and moreover provide parallel counterparts. We
implement these algorithms and experimentally compare their performance against
saturation on 692 model checking benchmarks in different languages. The results
show that the REACH operation often outperforms saturation, especially on
transition relations with low locality. In a comparison between parallelized
versions of REACH and saturation we find that REACH obtains comparable speedups
up to 16 cores, although falls behind saturation at 64 cores. Finally, in a
comparison with the state-of-the-art model checking tool ITS-tools we find that
REACH outperforms ITS-tools on 29% of models, suggesting that REACH can be
useful as a complementary method in an ensemble tool.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brand_S/0/1/0/all/0/1">Sebastiaan Brand</a>, <a href="http://arxiv.org/find/cs/1/au:+Back_T/0/1/0/all/0/1">Thomas B&#xe4;ck</a>, <a href="http://arxiv.org/find/cs/1/au:+Laarman_A/0/1/0/all/0/1">Alfons Laarman</a></p><p>Saturation is considered the state-of-the-art method for computing fixpoints
with decision diagrams. We present a relatively simple decision diagram
operation called REACH that also computes fixpoints. In contrast to saturation,
it does not require a partitioning of the transition relation. We give
sequential algorithms implementing the new operation for both binary and
multi-valued decision diagrams, and moreover provide parallel counterparts. We
implement these algorithms and experimentally compare their performance against
saturation on 692 model checking benchmarks in different languages. The results
show that the REACH operation often outperforms saturation, especially on
transition relations with low locality. In a comparison between parallelized
versions of REACH and saturation we find that REACH obtains comparable speedups
up to 16 cores, although falls behind saturation at 64 cores. Finally, in a
comparison with the state-of-the-art model checking tool ITS-tools we find that
REACH outperforms ITS-tools on 29% of models, suggesting that REACH can be
useful as a complementary method in an ensemble tool.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T01:30:00Z">Thursday, December 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03685'>Density Approximation for Kinetic Groups</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Max van Mulken, Bettina Speckmann, Kevin Verbeek</p><p>Sets of moving entities can form groups which travel together for significant
amounts of time. Tracking such groups is an important analysis task in a
variety of areas, such as wildlife ecology, urban transport, or sports
analysis. Correspondingly, recent years have seen a multitude of algorithms to
identify and track meaningful groups in sets of moving entities. However, not
only the mere existence of one or more groups is an important fact to discover;
in many application areas the actual shape of the group carries meaning as
well. In this paper we initiate the algorithmic study of the shape of a moving
group. We use kernel density estimation to model the density within a group and
show how to efficiently maintain an approximation of this density description
over time. Furthermore, we track persistent maxima which give a meaningful
first idea of the time-varying shape of the group. By combining several
approximation techniques, we obtain a kinetic data structure that can
approximately track persistent maxima efficiently.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mulken_M/0/1/0/all/0/1">Max van Mulken</a>, <a href="http://arxiv.org/find/cs/1/au:+Speckmann_B/0/1/0/all/0/1">Bettina Speckmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Verbeek_K/0/1/0/all/0/1">Kevin Verbeek</a></p><p>Sets of moving entities can form groups which travel together for significant
amounts of time. Tracking such groups is an important analysis task in a
variety of areas, such as wildlife ecology, urban transport, or sports
analysis. Correspondingly, recent years have seen a multitude of algorithms to
identify and track meaningful groups in sets of moving entities. However, not
only the mere existence of one or more groups is an important fact to discover;
in many application areas the actual shape of the group carries meaning as
well. In this paper we initiate the algorithmic study of the shape of a moving
group. We use kernel density estimation to model the density within a group and
show how to efficiently maintain an approximation of this density description
over time. Furthermore, we track persistent maxima which give a meaningful
first idea of the time-varying shape of the group. By combining several
approximation techniques, we obtain a kinetic data structure that can
approximately track persistent maxima efficiently.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T01:30:00Z">Thursday, December 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03776'>An improved approximation guarantee for Prize-Collecting TSP</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jannis Blauth, Martin N&#xe4;gele</p><p>We present a new approximation algorithm for the (metric) prize-collecting
traveling salesperson problem (PCTSP). In PCTSP, opposed to the classical
traveling salesperson problem (TSP), one may not include a vertex of the input
graph in the returned tour at the cost of a given vertex-dependent penalty, and
the objective is to balance the length of the tour and the incurred penalties
for omitted vertices by minimizing the sum of the two. We present an algorithm
that achieves an approximation guarantee of $1.774$ with respect to the natural
linear programming relaxation of the problem. This significantly reduces the
gap between the approximability of classical TSP and PCTSP, beating the
previously best known approximation factor of $1.915$. As a key ingredient of
our improvement, we present a refined decomposition technique for solutions of
the LP relaxation, and show how to leverage components of that decomposition as
building blocks for our tours.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blauth_J/0/1/0/all/0/1">Jannis Blauth</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagele_M/0/1/0/all/0/1">Martin N&#xe4;gele</a></p><p>We present a new approximation algorithm for the (metric) prize-collecting
traveling salesperson problem (PCTSP). In PCTSP, opposed to the classical
traveling salesperson problem (TSP), one may not include a vertex of the input
graph in the returned tour at the cost of a given vertex-dependent penalty, and
the objective is to balance the length of the tour and the incurred penalties
for omitted vertices by minimizing the sum of the two. We present an algorithm
that achieves an approximation guarantee of $1.774$ with respect to the natural
linear programming relaxation of the problem. This significantly reduces the
gap between the approximability of classical TSP and PCTSP, beating the
previously best known approximation factor of $1.915$. As a key ingredient of
our improvement, we present a refined decomposition technique for solutions of
the LP relaxation, and show how to leverage components of that decomposition as
building blocks for our tours.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T01:30:00Z">Thursday, December 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03786'>Why the equivalence problem for unambiguous grammars has not been solved back in 1966?</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vladislav Makarov</p><p>In 1966, Semenov, by using a technique based on power series, suggested an
algorithm that tells apart the languages described by an unambiguous grammar
and a DFA. At the first glance, it may appear that the algorithm can be easily
modified to yield a full solution of the equivalence problem for unambiguous
grammars. This article shows why this hunch is, in fact, incorrect.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Makarov_V/0/1/0/all/0/1">Vladislav Makarov</a></p><p>In 1966, Semenov, by using a technique based on power series, suggested an
algorithm that tells apart the languages described by an unambiguous grammar
and a DFA. At the first glance, it may appear that the algorithm can be easily
modified to yield a full solution of the equivalence problem for unambiguous
grammars. This article shows why this hunch is, in fact, incorrect.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T01:30:00Z">Thursday, December 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03851'>Computing linear sections of varieties: quantum entanglement, tensor decompositions and beyond</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nathaniel Johnston, Benjamin Lovitz, Aravindan Vijayaraghavan</p><p>We study the problem of finding elements in the intersection of an arbitrary
conic variety in $\mathbb{F}^n$ with a given linear subspace (where
$\mathbb{F}$ can be the real or complex field). This problem captures a rich
family of algorithmic problems under different choices of the variety. The
special case of the variety consisting of rank-1 matrices already has strong
connections to central problems in different areas like quantum information
theory and tensor decompositions. This problem is known to be NP-hard in the
worst-case, even for the variety of rank-1 matrices.
</p>
<p>Surprisingly, despite these hardness results we give efficient algorithms
that solve this problem for "typical" subspaces. Here, the subspace $U
\subseteq \mathbb{F}^n$ is chosen generically of a certain dimension,
potentially with some generic elements of the variety contained in it. Our main
algorithmic result is a polynomial time algorithm that recovers all the
elements of $U$ that lie in the variety, under some mild non-degeneracy
assumptions on the variety. As corollaries, we obtain the following results:
</p>
<p>$\bullet$ Uniqueness results and polynomial time algorithms for generic
instances of a broad class of low-rank decomposition problems that go beyond
tensor decompositions. Here, we recover a decomposition of the form
$\sum_{i=1}^R v_i \otimes w_i$, where the $v_i$ are elements of the given
variety $X$. This implies new algorithmic results even in the special case of
tensor decompositions.
</p>
<p>$\bullet$ Polynomial time algorithms for several entangled subspaces problems
in quantum entanglement, including determining $r$-entanglement, complete
entanglement, and genuine entanglement of a subspace. While all of these
problems are NP-hard in the worst case, our algorithm solves them in polynomial
time for generic subspaces of dimension up to a constant multiple of the
maximum possible.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Johnston_N/0/1/0/all/0/1">Nathaniel Johnston</a>, <a href="http://arxiv.org/find/cs/1/au:+Lovitz_B/0/1/0/all/0/1">Benjamin Lovitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Vijayaraghavan_A/0/1/0/all/0/1">Aravindan Vijayaraghavan</a></p><p>We study the problem of finding elements in the intersection of an arbitrary
conic variety in $\mathbb{F}^n$ with a given linear subspace (where
$\mathbb{F}$ can be the real or complex field). This problem captures a rich
family of algorithmic problems under different choices of the variety. The
special case of the variety consisting of rank-1 matrices already has strong
connections to central problems in different areas like quantum information
theory and tensor decompositions. This problem is known to be NP-hard in the
worst-case, even for the variety of rank-1 matrices.
</p>
<p>Surprisingly, despite these hardness results we give efficient algorithms
that solve this problem for "typical" subspaces. Here, the subspace $U
\subseteq \mathbb{F}^n$ is chosen generically of a certain dimension,
potentially with some generic elements of the variety contained in it. Our main
algorithmic result is a polynomial time algorithm that recovers all the
elements of $U$ that lie in the variety, under some mild non-degeneracy
assumptions on the variety. As corollaries, we obtain the following results:
</p>
<p>$\bullet$ Uniqueness results and polynomial time algorithms for generic
instances of a broad class of low-rank decomposition problems that go beyond
tensor decompositions. Here, we recover a decomposition of the form
$\sum_{i=1}^R v_i \otimes w_i$, where the $v_i$ are elements of the given
variety $X$. This implies new algorithmic results even in the special case of
tensor decompositions.
</p>
<p>$\bullet$ Polynomial time algorithms for several entangled subspaces problems
in quantum entanglement, including determining $r$-entanglement, complete
entanglement, and genuine entanglement of a subspace. While all of these
problems are NP-hard in the worst case, our algorithm solves them in polynomial
time for generic subspaces of dimension up to a constant multiple of the
maximum possible.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T01:30:00Z">Thursday, December 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03861'>Cocke--Younger--Kasami--Schwartz--Zippel algorithm and relatives</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vladislav Makarov</p><p>The equivalence problem for unambiguous grammars is an important, but very
difficult open question in formal language theory. Consider the \emph{limited}
equivalence problem for unambiguous grammars -- for two unambiguous grammars
$G_1$ and $G_2$, tell whether or not they describe the same set of words of
length $n$. Obviously, the naive approach requires exponential time with
respect to $n$. By combining two classic algorithmic ideas, I introduce a
$O({\rm poly}(n, |G_1|, |G_2|))$ algorithm for this problem. Moreover, the
ideas behind the algorithm prove useful in various other scenarious.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Makarov_V/0/1/0/all/0/1">Vladislav Makarov</a></p><p>The equivalence problem for unambiguous grammars is an important, but very
difficult open question in formal language theory. Consider the \emph{limited}
equivalence problem for unambiguous grammars -- for two unambiguous grammars
$G_1$ and $G_2$, tell whether or not they describe the same set of words of
length $n$. Obviously, the naive approach requires exponential time with
respect to $n$. By combining two classic algorithmic ideas, I introduce a
$O({\rm poly}(n, |G_1|, |G_2|))$ algorithm for this problem. Moreover, the
ideas behind the algorithm prove useful in various other scenarious.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T01:30:00Z">Thursday, December 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, December 07
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2022/12/07/quantum-circuits-in-the-new-york-times/'>Quantum Circuits in the New York Times</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Can quantum circuits have something to do with wormholes? Wikipedia src Maria Spiropulu, a physicist at the California Institute of Technology, is featured in an article in last week&#8217;s Tuesday Science section of the New York Times about teleporting qubits through what might be described as a wormhole. The article says that physicists such as [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>Can quantum circuits have something to do with wormholes?</em><br />
<font color="#000000"></p>
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/12/07/quantum-circuits-in-the-new-york-times/ms-3/" rel="attachment wp-att-20534"><img data-attachment-id="20534" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/07/quantum-circuits-in-the-new-york-times/ms-3/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/ms.jpeg?fit=259%2C194&amp;ssl=1" data-orig-size="259,194" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ms" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/ms.jpeg?fit=259%2C194&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/ms.jpeg?fit=259%2C194&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/ms.jpeg?resize=200%2C150&#038;ssl=1" alt="" width="200" height="150" class="alignright wp-image-20534" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/ms.jpeg?w=259&amp;ssl=1 259w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/ms.jpeg?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 200px) 100vw, 200px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Wikipedia <a href="https://en.wikipedia.org/wiki/Maria_Spiropulu">src</a></font></td>
</tr>
</tbody>
</table>
<p>
Maria Spiropulu, a physicist <a href="http://www.hep.caltech.edu/~smaria/">at</a> the California Institute of Technology, is featured in an <a href="https://www.nytimes.com/2022/11/30/science/physics-wormhole-quantum-computer.html">article</a> in last week&#8217;s Tuesday Science section of the New York Times about teleporting qubits through what might be described as a <a href="https://en.wikipedia.org/wiki/Wormhole">wormhole</a>. The article says that physicists such as she</p>
<blockquote><p><b> </b> <em> <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;dots}" class="latex" /> like to compare the teleportation process to two cups of tea. Drop a cube of sugar into one teacup, and it promptly dissolves&#8212;then, after a tick of the quantum clock, the cube reappears intact in the other teacup. </em>
</p></blockquote>
<p><p>
Today (yesterday? tomorrow? <a href="https://chadorzel.substack.com/p/wormhole-to-2006">years ago?</a>&#8212;with a quantum clock, does it <a href="https://phys.org/news/2019-03-physicists-reverse-quantum.html">matter</a>?) we ask what the paper referenced in the NYT story might really be about. This is after trying to work through a lot of hype and pushback.</p>
<p>
The first trouble is that we cannot tick a real quantum clock quite yet. But Spiropulu and her group were able to simulate a quantum clock via using a quantum computer. The group comprises: first author Daniel Jafferis, then Alexander Zlokapa, Joseph Lykken, David Kolchmeyer, Samantha Davis, Nikolai Lauk, Hartmut Neven, and then Spiropulu. Their <a href="https://www.nature.com/articles/s41586-022-05424-3">paper</a> was just reported in <em>Nature</em>. The whole buzz makes us recall an exchange that never took place:</p>
<blockquote><p><b> </b> <em> Albert Einstein: &#8220;Reality is merely an illusion, albeit a persistent one.&#8221; </p>
<p>
Woody Allen: &#8220;[If] everything is an illusion and nothing exists, [then] I definitely overpaid for my carpet.&#8221; </em>
</p></blockquote>
<p>
<p><H2> The Quantum Experiment </H2></p>
<p><p>
Spiropulu&#8217;s group could not build a quantum experiment to directly test this kind of teleportation. At least it seemed like that would be impossible. But they cleverly used the <a href="https://en.wikipedia.org/wiki/Sycamore_processor">Sycamore</a> chip developed by Google in 2019. It uses a type of quantum computing called superconducting qubits, which send electric currents flowing through superconducting materials to store and process information. Google created the chip to study &#8220;quantum supremacy&#8221; as we <a href="https://rjlipton.wpcomstaging.com/2019/10/27/quantum-supremacy-at-last/">covered</a> three years ago. A wonderful <a href="https://jonathan-hui.medium.com/quantum-supremacy-google-sycamore-processor-6f30073a17fa">article</a> on <em>Medium</em> by Jonathan Hui runs helpful commentary around circuit diagrams of the processor from the Google team&#8217;s original <a href="https://www.nature.com/articles/s41586-019-1666-5">paper</a>. Hui says:</p>
<blockquote><p><b> </b> <em> Regardless of other claims, Googleâs processor is a significant milestone because it demonstrates a problem with some real value. Whether classical computers will take 100,000 years or 2.5 days for the pseudo-random generator, this kind of speed improvement is rarely or never demonstrated with a general-purpose quantum computer. </em>
</p></blockquote>
<p><p>
What we find significant is that Google&#8217;s processor is not limited to the pseudo-randomness application to demonstrate what we&#8217;ll call <a href="https://www.ibm.com/blogs/research/tag/quantum-advantage/">advantage</a>. It has plug-and-play capabilities. Google may not have created Sycamore to study quantum teleportation. But it was possible to exploit its quantum ability to demonstrate teleportation. See their <a href="https://www.nature.com/articles/s41586-022-05424-3">Nature</a> paper for how. </p>
<p>
<p><H2> Wormholes and Their Duals </H2></p>
<p><p>
The NYT story and an <a href="https://www.quantamagazine.org/physicists-create-a-wormhole-using-a-quantum-computer-20221130/">article</a> by Natalie Wolchover in <em>Quanta</em> have some pithy quotes from people well-known to us:</p>
<ul>
<li>
John Preskill, about &#8216;the evolving system of qubits in the Sycamore chip&#8217;: &#8220;[It] has this really cool alternative description. You can think of the system in a very different language as being gravitational.&#8221; </p>
<li>
Leonard Susskind: &#8220;The really interesting thing here is the possibility of analyzing purely quantum phenomena using general relativity, and who knows where thatâs going to go.&#8221; </p>
<li>
Scott Aaronson: &#8220;If this experiment has brought a wormhole into actual physical existence, then a strong case could be made that you, too, bring a wormhole into actual physical existence every time you sketch one with pen and paper.&#8221; (See also Scott&#8217;s post <a href="https://scottaaronson.blog/?p=6871">here</a>.)
</ul>
<p>
These quotes allude to a duality, both ends of which connect Einstein and the Israeli-American physicist Nathan Rosen. Their 1935 paper, abbreviated ER, showed how a wormhole could arise in the specific form of an <a href="https://en.wikipedia.org/wiki/Wormhole">Einstein-Rosen bridge</a> according to the equations of general relativity. They were joined that same year by Boris Podolsky in a paper that described quantum <em>entanglement</em> via the so-called <a href="https://en.wikipedia.org/wiki/EPR_paradox">EPR paradox</a>. In 2013, Juan Maldacena wrote a <a href="https://arxiv.org/abs/1306.0533">paper</a> with Susskind claiming a correspondence between them. This was <a href="https://en.wikipedia.org/wiki/Sachdev-Ye-Kitaev_model">expanded</a> by Alexei Kitaev following work by Subir Sachdev and Jinwu Ye. All this draws on Maldacena&#8217;s work in the 1990s showing a duality between two cosmic models that have different dimensionalities, in the manner of a hologram. Maldacena and Susskind&#8217;s claim is pithily expressed as the title of section 3 of their paper: </p>
<p align=center><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BER+%3D+EPR%7D+&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle  &#92;mathsf{ER = EPR} " class="latex" /></p>
<p>Equality is enticing because this could effect the communion of relativity and quantum mechanics. This matter found its way into another New York Times <a href="https://www.nytimes.com/2022/10/10/science/black-holes-cosmology-hologram.html">story</a> in October, where Susskind is quoted as saying in 2017:</p>
<blockquote><p><b> </b> <em> &#8220;It may be too strong to say that gravity and quantum mechanics are exactly the same thing. But those of us who are paying attention may already sense that the two are inseparable, and that neither makes sense without the other.&#8221; </em>
</p></blockquote>
<p><p>
That story centered the duality on black holes, but Will Kinney, a colleague of Ken&#8217;s at Buffalo, <a href="https://twitter.com/WKCosmo/status/1600153143702016001">observed</a> that Maldacena and Susskind &#8220;conjectured that ANY entangled particle pair is dual to a wormhole solution.&#8221; Kinney also <a href="https://twitter.com/WKCosmo/status/1598323058476982273">quoted</a> <em>Quanta</em> editor Thomas Lin as saying,</p>
<blockquote><p><b> </b> <em> &#8220;In the context of the article, it should be clear that a quantum system was created that was dual to a holographic wormhole.&#8221; </em>
</p></blockquote>
<p><p>
What fascinates us is that the quantum system had the form of direct simulation of quantum circuitry. In fact, Spiropulu&#8217;s team used only 9 of 72 available qubits on a Sycamore chip. The NYT article has a big graphic on the role of ordinary quantum circuits, from which we snip this detail:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/12/07/quantum-circuits-in-the-new-york-times/nytcircuitdetail/" rel="attachment wp-att-20535"><img data-attachment-id="20535" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/07/quantum-circuits-in-the-new-york-times/nytcircuitdetail/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/NYTcircuitdetail.jpg?fit=794%2C466&amp;ssl=1" data-orig-size="794,466" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1670368563&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="NYTcircuitdetail" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/NYTcircuitdetail.jpg?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/NYTcircuitdetail.jpg?fit=600%2C352&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/NYTcircuitdetail.jpg?resize=450%2C264&#038;ssl=1" alt="" width="450" height="264" class="aligncenter wp-image-20535" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/NYTcircuitdetail.jpg?w=794&amp;ssl=1 794w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/NYTcircuitdetail.jpg?resize=300%2C176&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/NYTcircuitdetail.jpg?resize=768%2C451&amp;ssl=1 768w" sizes="(max-width: 450px) 100vw, 450px" data-recalc-dims="1" /></a></p>
<p><P><br />
This leads us to some speculations of our own.</p>
<p>
<p><H2> Dualling Quantum Circuits? </H2></p>
<p><p>
Setting aside the question of wormholes or their duals, Spiropulu&#8217;s team did observe behavior that could be forecasted only after running an exhaustive classical simulation tied to the Sachdev-Ye-Kitaev model on the 9-qubit scale. This is described in a <a href="https://www.youtube.com/watch?v=uOJCS1W1uzgstarting">video</a> by <em>Quanta</em> about their work, starting about <a href="https://youtu.be/uOJCS1W1uzg?t=660">11:00</a>. As Wolchover summarizes:</p>
<blockquote><p><b> </b> <em> &#8220;[A]n ineffable quantum phenomenon&#8212;information teleporting between particles&#8212;has a tangible interpretation as a particle receiving a kick of energy and moving at a calculable speed from A to B.&#8221; </em>
</p></blockquote>
<p><p>
Maybe there is no actual burst of energy, as Mateus Ara&uacute;jo <a href="https://mateusaraujo.info/2022/12/01/the-death-of-quanta-magazine/">underscored</a> while criticizing this segment of the video. But is the physical process in the circuit nevertheless subject to instability and noise? We reiterate a question that we <a href="https://rjlipton.wpcomstaging.com/2021/11/01/quantum-trick-or-treat/">posed</a> a year ago after describing how small quantum circuits can embody quantum walks that are <em>chaotic</em>:</p>
<blockquote><p><b> </b> <em> When a quantum circuit simulates an unstable physical process with full quantum advantage, what is the boundary between the simulation and the behavior being simulated?  Is potential bridging of this boundary a stumbling block to maintaining coherent operation while scaling up quantum hardware? </em>
</p></blockquote>
<p><p>
In the context of the November 2021 post, we noted that when one simulates chaotic physical systems in, say, FORTRAN or C++ or Python on a classical computer, one would not say the physical classical chips are themselves behaving chaotically. In the quantum case, we note Peter Shor&#8217;s response to Wolchover&#8217;s <a href="https://twitter.com/nattyover/status/1598476586164035585">referencing</a> a 2017 lecture video on simulating physical systems. Shor retorts that a quantum computer simulating fusion doesn&#8217;t shine like the sun, nor can quantum circuits both using and simulating superconductivity power the nation&#8217;s electric grid. But our instances of chaotic quantum walks, and now possibly wormhole duality, strike us as more closely attached to the relation of physical behavior to computation.</p>
<p>
The new question we have is even more speculative, but may work as a counterpoint to the current discussion of the new paper. If ER=EPR is correct, then ordinary entanglements are dual to wormholes. That maximal entanglements are <a href="https://en.wikipedia.org/wiki/Monogamy_of_entanglement">binary-only</a> may correspond to the simplest wormholes going only from a point A to a point B. Entanglements are bread-and-butter to quantum circuits, so if this duality has any force, it should extend to the circuits themselves:</p>
<blockquote><p><b> </b> <em> If the team could possibly create a theoretical dual to a wormhole in a quantum circuit, then does the correspondence in the other direction yield <b>duals to quantum circuits</b> that could house wormholes? Might the notion of such a circuit dual, expressed within general relativity, furnish an organizing principle about how the universe processes information to build structures on cosmic scales? </em>
</p></blockquote>
<p><p>
A 2018 <a href="https://arxiv.org/abs/1808.09072">paper</a> by Tadashi Takayanagi titled &#8220;Holographic Spacetimes as Quantum Circuits of Path-Integrations&#8221; seems to open at least one direction of a cosmos-to-quantum-circuits correspondence.  A very recent <a href="https://arxiv.org/abs/2210.15601">paper</a> by Scott with Jason Pollack, on how Maldacena&#8217;s correspondence treats quantum states, draws on earlier work by Takayanagi, but seems to stop short of such duality.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
What do you think of the questions raised by the new paper? As we highlighted at the start, it is couched in down-to-earth terms of quantum circuits. Setting aside the rampant controversy on the physics side&#8212;there are more <a href="https://www.math.columbia.edu/~woit/wordpress/?p=13181">links</a> collected by Peter Woit besides those we&#8217;ve used&#8212;what does this say about realizing the quantum circuit model?</p>
<p><P><br />
[some slight word changes]</p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T19:16:32Z">Wednesday, December 07 2022, 19:16</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2022/12/07/northeastern-simons-institute-10-exp-and-phd-in-complexity-theory/'>|Northeastern â Simons Institute| < 10, EXP, and PhD in complexity theory</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Northeastern recently merged with Mills College, in Oakland, California. The massive campus is less than 10 miles from the Simons Institute for the Theory of Computing. This is the n+1 growth in an amazing streak, including multiple campuses all over the world, naming gifts, and new buildings, including one named after a complexity class: EXP. [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Northeastern recently <a href="https://mills.northeastern.edu/merger/">merged with Mills College, in Oakland, California.  </a>The massive campus is less than 10 miles from the Simons Institute for the Theory of Computing.  This is the n+1 growth in an amazing streak, including <a href="https://www.northeastern.edu/graduate/our-campus-network/">multiple campuses all over the world, </a>naming <a href="https://www.bizjournals.com/boston/news/2018/12/17/northeastern-to-rename-computer-science-school.html">gifts</a>, and new buildings, including one named after a complexity class: <a href="https://facilities.northeastern.edu/exp/">EXP</a>.</p>



<p>This expansion puts Northeastern at the center of the two main hubs for theory in the U.S., the Bay State and the Bay Area.</p>



<p>If you want to work on theory apply to join our <a href="https://www2.ccs.neu.edu/theory/">theory group.</a>  I always have room for strong students.</p>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T13:32:01Z">Wednesday, December 07 2022, 13:32</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.02653'>Finite model theory for pseudovarieties and universal algebra: preservation, definability and complexity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lucy Ham, Marcel Jackson</p><p>We explore new interactions between finite model theory and a number of
classical streams of universal algebra and semigroup theory. After refocussing
some finite model theoretic tools in universal algebraic context, we present a
number of results. A key result is an example of a finite algebra whose variety
is not finitely axiomatisable in first order logic, but which has first order
definable finite membership problem. This algebra witnesses the simultaneous
failure of the {\L}os-Tarski Theorem, the SP-preservation theorem and
Birkhoff's HSP-preservation theorem at the finite level as well as providing a
negative solution to the first order formulation of the long-standing Eilenberg
Sch\"utzenberger problem. The example also shows that a pseudovariety without
any finite pseudo-identity basis may be finitely axiomatisable in first order
logic. Other results include the undecidability of deciding first order
definability of the pseudovariety of a finite algebra and a mapping from any
fixed template constraint satisfaction problem to a first order equivalent
variety membership problem, thereby providing examples of variety membership
problems complete in each of the classes $\texttt{L}$, $\texttt{NL}$,
$\texttt{Mod}_p(\texttt{L})$, $\texttt{P}$ (provided they are nonempty), and
infinitely many others (depending on complexity-theoretic assumptions).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Ham_L/0/1/0/all/0/1">Lucy Ham</a>, <a href="http://arxiv.org/find/math/1/au:+Jackson_M/0/1/0/all/0/1">Marcel Jackson</a></p><p>We explore new interactions between finite model theory and a number of
classical streams of universal algebra and semigroup theory. After refocussing
some finite model theoretic tools in universal algebraic context, we present a
number of results. A key result is an example of a finite algebra whose variety
is not finitely axiomatisable in first order logic, but which has first order
definable finite membership problem. This algebra witnesses the simultaneous
failure of the {\L}os-Tarski Theorem, the SP-preservation theorem and
Birkhoff's HSP-preservation theorem at the finite level as well as providing a
negative solution to the first order formulation of the long-standing Eilenberg
Sch\"utzenberger problem. The example also shows that a pseudovariety without
any finite pseudo-identity basis may be finitely axiomatisable in first order
logic. Other results include the undecidability of deciding first order
definability of the pseudovariety of a finite algebra and a mapping from any
fixed template constraint satisfaction problem to a first order equivalent
variety membership problem, thereby providing examples of variety membership
problems complete in each of the classes $\texttt{L}$, $\texttt{NL}$,
$\texttt{Mod}_p(\texttt{L})$, $\texttt{P}$ (provided they are nonempty), and
infinitely many others (depending on complexity-theoretic assumptions).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03121'>On the Size of Chromatic Delaunay Mosaics</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ranita Biswas, Sebastiano Cultrera di Montesano, Ond&#x159;ej Draganov, Herbert Edelsbrunner, Morteza Saghafian</p><p>Given a locally finite set $A \subseteq \mathbb{R}^d$ and a coloring $\chi
\colon A \to \{0,1,\ldots,s\}$, we introduce the chromatic Delaunay mosaic of
$\chi$, which is a Delaunay mosaic in $\mathbb{R}^{s+d}$ that represents how
points of different colors mingle. Our main results are bounds on the size of
the chromatic Delaunay mosaic, in which we assume that $d$ and $s$ are
constants. For example, if $A$ is finite with $n = \#{A}$, and the coloring is
random, then the chromatic Delaunay mosaic has $O(n^{\lceil{d/2}\rceil})$ cells
in expectation. In contrast, for Delone sets and Poisson point processes in
$\mathbb{R}^d$, the expected number of cells within a closed ball is only a
constant times the number of points in this ball. Furthermore, in
$\mathbb{R}^2$ all colorings of a dense set of $n$ points have chromatic
Delaunay mosaics of size $O(n)$. This encourages the use of chromatic Delaunay
mosaics in applications.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Biswas_R/0/1/0/all/0/1">Ranita Biswas</a>, <a href="http://arxiv.org/find/math/1/au:+Montesano_S/0/1/0/all/0/1">Sebastiano Cultrera di Montesano</a>, <a href="http://arxiv.org/find/math/1/au:+Draganov_O/0/1/0/all/0/1">Ond&#x159;ej Draganov</a>, <a href="http://arxiv.org/find/math/1/au:+Edelsbrunner_H/0/1/0/all/0/1">Herbert Edelsbrunner</a>, <a href="http://arxiv.org/find/math/1/au:+Saghafian_M/0/1/0/all/0/1">Morteza Saghafian</a></p><p>Given a locally finite set $A \subseteq \mathbb{R}^d$ and a coloring $\chi
\colon A \to \{0,1,\ldots,s\}$, we introduce the chromatic Delaunay mosaic of
$\chi$, which is a Delaunay mosaic in $\mathbb{R}^{s+d}$ that represents how
points of different colors mingle. Our main results are bounds on the size of
the chromatic Delaunay mosaic, in which we assume that $d$ and $s$ are
constants. For example, if $A$ is finite with $n = \#{A}$, and the coloring is
random, then the chromatic Delaunay mosaic has $O(n^{\lceil{d/2}\rceil})$ cells
in expectation. In contrast, for Delone sets and Poisson point processes in
$\mathbb{R}^d$, the expected number of cells within a closed ball is only a
constant times the number of points in this ball. Furthermore, in
$\mathbb{R}^2$ all colorings of a dense set of $n$ points have chromatic
Delaunay mosaics of size $O(n)$. This encourages the use of chromatic Delaunay
mosaics in applications.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03128'>Persistent Homology of Chromatic Alpha Complexes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sebastiano Cultrera di Montesano, Ond&#x159;ej Draganov, Herbert Edelsbrunner, Morteza Saghafian</p><p>Motivated by applications in medical sciences, we study finite chromatic sets
in Euclidean space from a topological perspective. Based on persistent homology
for images, kernels and cokernels, we design provably stable homological
quantifiers that describe the geometric micro- and macro-structure of how the
color classes mingle. These can be efficiently computed using chromatic
variants of Delaunay mosaics and Alpha complexes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Montesano_S/0/1/0/all/0/1">Sebastiano Cultrera di Montesano</a>, <a href="http://arxiv.org/find/math/1/au:+Draganov_O/0/1/0/all/0/1">Ond&#x159;ej Draganov</a>, <a href="http://arxiv.org/find/math/1/au:+Edelsbrunner_H/0/1/0/all/0/1">Herbert Edelsbrunner</a>, <a href="http://arxiv.org/find/math/1/au:+Saghafian_M/0/1/0/all/0/1">Morteza Saghafian</a></p><p>Motivated by applications in medical sciences, we study finite chromatic sets
in Euclidean space from a topological perspective. Based on persistent homology
for images, kernels and cokernels, we design provably stable homological
quantifiers that describe the geometric micro- and macro-structure of how the
color classes mingle. These can be efficiently computed using chromatic
variants of Delaunay mosaics and Alpha complexes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.02883'>Improved Approximation Schemes for (Un-)Bounded Subset-Sum and Partition</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiaoyu Wu, Lin Chen</p><p>We consider the SUBSET SUM problem and its important variants in this paper.
In the SUBSET SUM problem, a (multi-)set $X$ of $n$ positive numbers and a
target number $t$ are given, and the task is to find a subset of $X$ with the
maximal sum that does not exceed $t$. It is well known that this problem is
NP-hard and admits fully polynomial-time approximation schemes (FPTASs). In
recent years, it has been shown that there does not exist an FPTAS of running
time $\tilde\OO( 1/\epsilon^{2-\delta})$ for arbitrary small $\delta&gt;0$
assuming ($\min$,+)-convolution conjecture~\cite{bringmann2021fine}. However,
the lower bound can be bypassed if we relax the constraint such that the task
is to find a subset of $X$ that can slightly exceed the threshold $t$ by
$\epsilon$ times, and the sum of numbers within the subset is at least
$1-\tilde\OO(\epsilon)$ times the optimal objective value that respects the
constraint. Approximation schemes that may violate the constraint are also
known as weak approximation schemes. For the SUBSET SUM problem, there is a
randomized weak approximation scheme running in time $\tilde\OO(n+
1/\epsilon^{5/3})$ [Mucha et al.'19]. For the special case where the target $t$
is half of the summation of all input numbers, weak approximation schemes are
equivalent to approximation schemes that do not violate the constraint, and the
best-known algorithm runs in $\tilde\OO(n+1/\epsilon^{{3}/{2}})$ time
[Bringmann and Nakos'21].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiaoyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lin Chen</a></p><p>We consider the SUBSET SUM problem and its important variants in this paper.
In the SUBSET SUM problem, a (multi-)set $X$ of $n$ positive numbers and a
target number $t$ are given, and the task is to find a subset of $X$ with the
maximal sum that does not exceed $t$. It is well known that this problem is
NP-hard and admits fully polynomial-time approximation schemes (FPTASs). In
recent years, it has been shown that there does not exist an FPTAS of running
time $\tilde\OO( 1/\epsilon^{2-\delta})$ for arbitrary small $\delta&gt;0$
assuming ($\min$,+)-convolution conjecture~\cite{bringmann2021fine}. However,
the lower bound can be bypassed if we relax the constraint such that the task
is to find a subset of $X$ that can slightly exceed the threshold $t$ by
$\epsilon$ times, and the sum of numbers within the subset is at least
$1-\tilde\OO(\epsilon)$ times the optimal objective value that respects the
constraint. Approximation schemes that may violate the constraint are also
known as weak approximation schemes. For the SUBSET SUM problem, there is a
randomized weak approximation scheme running in time $\tilde\OO(n+
1/\epsilon^{5/3})$ [Mucha et al.'19]. For the special case where the target $t$
is half of the summation of all input numbers, weak approximation schemes are
equivalent to approximation schemes that do not violate the constraint, and the
best-known algorithm runs in $\tilde\OO(n+1/\epsilon^{{3}/{2}})$ time
[Bringmann and Nakos'21].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03008'>A Strongly Polynomial Algorithm for Approximate Forster Transforms and its Application to Halfspace Learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ilias Diakonikolas, Christos Tzamos, Daniel M. Kane</p><p>The Forster transform is a method of regularizing a dataset by placing it in
{\em radial isotropic position} while maintaining some of its essential
properties. Forster transforms have played a key role in a diverse range of
settings spanning computer science and functional analysis. Prior work had
given {\em weakly} polynomial time algorithms for computing Forster transforms,
when they exist. Our main result is the first {\em strongly polynomial time}
algorithm to compute an approximate Forster transform of a given dataset or
certify that no such transformation exists. By leveraging our strongly
polynomial Forster algorithm, we obtain the first strongly polynomial time
algorithm for {\em distribution-free} PAC learning of halfspaces. This learning
result is surprising because {\em proper} PAC learning of halfspaces is {\em
equivalent} to linear programming. Our learning approach extends to give a
strongly polynomial halfspace learner in the presence of random classification
noise and, more generally, Massart noise.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1">Ilias Diakonikolas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1">Christos Tzamos</a>, <a href="http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1">Daniel M. Kane</a></p><p>The Forster transform is a method of regularizing a dataset by placing it in
{\em radial isotropic position} while maintaining some of its essential
properties. Forster transforms have played a key role in a diverse range of
settings spanning computer science and functional analysis. Prior work had
given {\em weakly} polynomial time algorithms for computing Forster transforms,
when they exist. Our main result is the first {\em strongly polynomial time}
algorithm to compute an approximate Forster transform of a given dataset or
certify that no such transformation exists. By leveraging our strongly
polynomial Forster algorithm, we obtain the first strongly polynomial time
algorithm for {\em distribution-free} PAC learning of halfspaces. This learning
result is surprising because {\em proper} PAC learning of halfspaces is {\em
equivalent} to linear programming. Our learning approach extends to give a
strongly polynomial halfspace learner in the presence of random classification
noise and, more generally, Massart noise.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03072'>Inapproximability of counting independent sets in linear hypergraphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guoliang Qiu, Jiaheng Wang</p><p>It is shown in this note that approximating the number of independent sets in
a $k$-uniform linear hypergraph with maximum degree at most $\Delta$ is NP-hard
if $\Delta\geq 5\cdot 2^{k-1}+1$. This confirms that for the relevant sampling
and approximate counting problems, the regimes on the maximum degree where the
state-of-the-art algorithms work are tight, up to some small factors. These
algorithms include: the approximate sampler and randomised approximation scheme
by Hermon, Sly and Zhang (2019), the perfect sampler by Qiu, Wang and Zhang
(2022), and the deterministic approximation scheme by Feng, Guo, Wang, Wang and
Yin (2022).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Qiu_G/0/1/0/all/0/1">Guoliang Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiaheng Wang</a></p><p>It is shown in this note that approximating the number of independent sets in
a $k$-uniform linear hypergraph with maximum degree at most $\Delta$ is NP-hard
if $\Delta\geq 5\cdot 2^{k-1}+1$. This confirms that for the relevant sampling
and approximate counting problems, the regimes on the maximum degree where the
state-of-the-art algorithms work are tight, up to some small factors. These
algorithms include: the approximate sampler and randomised approximation scheme
by Hermon, Sly and Zhang (2019), the perfect sampler by Qiu, Wang and Zhang
(2022), and the deterministic approximation scheme by Feng, Guo, Wang, Wang and
Yin (2022).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.02913'>Higher Lower Bounds for Sparse Oblivious Subspace Embeddings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yi Li, Mingmou Liu</p><p>An oblivious subspace embedding (OSE), characterized by parameters
$m,n,d,\epsilon,\delta$, is a random matrix $\Pi\in \mathbb{R}^{m\times n}$
such that for any $d$-dimensional subspace $T\subseteq \mathbb{R}^n$,
$\Pr_\Pi[\forall x\in T, (1-\epsilon)\|x\|_2 \leq \|\Pi x\|_2\leq
(1+\epsilon)\|x\|_2] \geq 1-\delta$. When an OSE has $1/(9\epsilon)$ nonzero
entries in each column, we show it must hold that $m =
\Omega(d^2/\epsilon^{1-O(\delta)})$, which is the first lower bound with
multiplicative factors of $d^2$ and $1/\epsilon$, improving on the previous
$\Omega(\epsilon^{O(\delta)}d^2)$ lower bound due to Li and Liu (PODS 2022).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingmou Liu</a></p><p>An oblivious subspace embedding (OSE), characterized by parameters
$m,n,d,\epsilon,\delta$, is a random matrix $\Pi\in \mathbb{R}^{m\times n}$
such that for any $d$-dimensional subspace $T\subseteq \mathbb{R}^n$,
$\Pr_\Pi[\forall x\in T, (1-\epsilon)\|x\|_2 \leq \|\Pi x\|_2\leq
(1+\epsilon)\|x\|_2] \geq 1-\delta$. When an OSE has $1/(9\epsilon)$ nonzero
entries in each column, we show it must hold that $m =
\Omega(d^2/\epsilon^{1-O(\delta)})$, which is the first lower bound with
multiplicative factors of $d^2$ and $1/\epsilon$, improving on the previous
$\Omega(\epsilon^{O(\delta)}d^2)$ lower bound due to Li and Liu (PODS 2022).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03030'>Improved Algebraic Degeneracy Testing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jean Cardinal, Micha Sharir</p><p>In the classical linear degeneracy testing problem, we are given $n$ real
numbers and a $k$-variate linear polynomial $F$, for some constant $k$, and
have to determine whether there exist $k$ numbers $a_1,\ldots,a_k$ from the set
such that $F(a_1,\ldots,a_k) = 0$. We consider a generalization of this problem
in which $F$ is an arbitrary constant-degree polynomial, we are given $k$ sets
of $n$ numbers, and have to determine whether there exist a $k$-tuple of
numbers, one in each set, on which $F$ vanishes. We give the first improvement
over the na\"ive $O^*(n^{k-1})$ algorithm for this problem (where the
$O^*(\cdot)$ notation omits subpolynomial factors).
</p>
<p>We show that the problem can be solved in time $O^*\left( n^{k - 2 + \frac
4{k+2}}\right)$ for even $k$ and in time $O^*\left( n^{k - 2 +
\frac{4k-8}{k^2-5}}\right)$ for odd $k$ in the real RAM model of computation.
We also prove that for $k=4$, the problem can be solved in time
$O^*(n^{2.625})$ in the algebraic decision tree model, and for $k=5$ it can be
solved in time $O^*(n^{3.56})$ in the same model, both improving on the above
uniform bounds.
</p>
<p>All our results rely on an algebraic generalization of the standard
meet-in-the-middle algorithm for $k$-SUM, powered by recent algorithmic
advances in the polynomial method for semi-algebraic range searching. In fact,
our main technical result is much more broadly applicable, as it provides a
general tool for detecting incidences and other interactions between points and
algebraic surfaces in any dimension. In particular, it yields an efficient
algorithm for a general, algebraic version of Hopcroft's point-line incidence
detection problem in any dimension.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cardinal_J/0/1/0/all/0/1">Jean Cardinal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharir_M/0/1/0/all/0/1">Micha Sharir</a></p><p>In the classical linear degeneracy testing problem, we are given $n$ real
numbers and a $k$-variate linear polynomial $F$, for some constant $k$, and
have to determine whether there exist $k$ numbers $a_1,\ldots,a_k$ from the set
such that $F(a_1,\ldots,a_k) = 0$. We consider a generalization of this problem
in which $F$ is an arbitrary constant-degree polynomial, we are given $k$ sets
of $n$ numbers, and have to determine whether there exist a $k$-tuple of
numbers, one in each set, on which $F$ vanishes. We give the first improvement
over the na\"ive $O^*(n^{k-1})$ algorithm for this problem (where the
$O^*(\cdot)$ notation omits subpolynomial factors).
</p>
<p>We show that the problem can be solved in time $O^*\left( n^{k - 2 + \frac
4{k+2}}\right)$ for even $k$ and in time $O^*\left( n^{k - 2 +
\frac{4k-8}{k^2-5}}\right)$ for odd $k$ in the real RAM model of computation.
We also prove that for $k=4$, the problem can be solved in time
$O^*(n^{2.625})$ in the algebraic decision tree model, and for $k=5$ it can be
solved in time $O^*(n^{3.56})$ in the same model, both improving on the above
uniform bounds.
</p>
<p>All our results rely on an algebraic generalization of the standard
meet-in-the-middle algorithm for $k$-SUM, powered by recent algorithmic
advances in the polynomial method for semi-algebraic range searching. In fact,
our main technical result is much more broadly applicable, as it provides a
general tool for detecting incidences and other interactions between points and
algebraic surfaces in any dimension. In particular, it yields an efficient
algorithm for a general, algebraic version of Hopcroft's point-line incidence
detection problem in any dimension.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.02548'>Robustness of Quantum Algorithms for Nonconvex Optimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Weiyuan Gong, Chenyi Zhang, Tongyang Li</p><p>Recent results suggest that quantum computers possess the potential to speed
up nonconvex optimization problems. However, a crucial factor for the
implementation of quantum optimization algorithms is their robustness against
experimental and statistical noises. In this paper, we systematically study
quantum algorithms for finding an $\epsilon$-approximate second-order
stationary point ($\epsilon$-SOSP) of a $d$-dimensional nonconvex function, a
fundamental problem in nonconvex optimization, with noisy zeroth- or
first-order oracles as inputs. We first prove that, up to noise of
$O(\epsilon^{10}/d^5)$, accelerated perturbed gradient descent with quantum
gradient estimation takes $O(\log d/\epsilon^{1.75})$ quantum queries to find
an $\epsilon$-SOSP. We then prove that perturbed gradient descent is robust to
the noise of $O(\epsilon^6/d^4)$ and $O(\epsilon/d^{0.5+\zeta})$ for $\zeta&gt;0$
on the zeroth- and first-order oracles, respectively, which provides a quantum
algorithm with poly-logarithmic query complexity. We then propose a stochastic
gradient descent algorithm using quantum mean estimation on the Gaussian
smoothing of noisy oracles, which is robust to $O(\epsilon^{1.5}/d)$ and
$O(\epsilon/\sqrt{d})$ noise on the zeroth- and first-order oracles,
respectively. The quantum algorithm takes $O(d^{2.5}/\epsilon^{3.5})$ and
$O(d^2/\epsilon^3)$ queries to the two oracles, giving a polynomial speedup
over the classical counterparts. Moreover, we characterize the domains where
quantum algorithms can find an $\epsilon$-SOSP with poly-logarithmic,
polynomial, or exponential number of queries in $d$, or the problem is
information-theoretically unsolvable even by an infinite number of queries. In
addition, we prove an $\Omega(\epsilon^{-12/7})$ lower bound in $\epsilon$ for
any randomized classical and quantum algorithm to find an $\epsilon$-SOSP using
either noisy zeroth- or first-order oracles.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Gong_W/0/1/0/all/0/1">Weiyuan Gong</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhang_C/0/1/0/all/0/1">Chenyi Zhang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Li_T/0/1/0/all/0/1">Tongyang Li</a></p><p>Recent results suggest that quantum computers possess the potential to speed
up nonconvex optimization problems. However, a crucial factor for the
implementation of quantum optimization algorithms is their robustness against
experimental and statistical noises. In this paper, we systematically study
quantum algorithms for finding an $\epsilon$-approximate second-order
stationary point ($\epsilon$-SOSP) of a $d$-dimensional nonconvex function, a
fundamental problem in nonconvex optimization, with noisy zeroth- or
first-order oracles as inputs. We first prove that, up to noise of
$O(\epsilon^{10}/d^5)$, accelerated perturbed gradient descent with quantum
gradient estimation takes $O(\log d/\epsilon^{1.75})$ quantum queries to find
an $\epsilon$-SOSP. We then prove that perturbed gradient descent is robust to
the noise of $O(\epsilon^6/d^4)$ and $O(\epsilon/d^{0.5+\zeta})$ for $\zeta&gt;0$
on the zeroth- and first-order oracles, respectively, which provides a quantum
algorithm with poly-logarithmic query complexity. We then propose a stochastic
gradient descent algorithm using quantum mean estimation on the Gaussian
smoothing of noisy oracles, which is robust to $O(\epsilon^{1.5}/d)$ and
$O(\epsilon/\sqrt{d})$ noise on the zeroth- and first-order oracles,
respectively. The quantum algorithm takes $O(d^{2.5}/\epsilon^{3.5})$ and
$O(d^2/\epsilon^3)$ queries to the two oracles, giving a polynomial speedup
over the classical counterparts. Moreover, we characterize the domains where
quantum algorithms can find an $\epsilon$-SOSP with poly-logarithmic,
polynomial, or exponential number of queries in $d$, or the problem is
information-theoretically unsolvable even by an infinite number of queries. In
addition, we prove an $\Omega(\epsilon^{-12/7})$ lower bound in $\epsilon$ for
any randomized classical and quantum algorithm to find an $\epsilon$-SOSP using
either noisy zeroth- or first-order oracles.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.02618'>Collabs: Composable Collaborative Data Structures</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Matthew Weidner, Heather Miller, Huairui Qi, Maxime Kjaer, Ria Pradeep, Benito Geordie, Christopher Meiklejohn</p><p>Replicated data types (RDTs), such as Conflict-free Replicated Data Types
(CRDTs), provide an abstraction for reasoning about replication and consistency
in distributed systems. To make them as useful as ordinary, local data
structures, RDTs need to be both modular and composable, so that programmers
can create new app-specific RDTs by composing existing ones. However, no
existing RDT libraries combine these properties; either they use monolithic
architectures that rule out new RDTs or they do not support composition
techniques.
</p>
<p>In this work, we introduce the Collab (collaborative data structure), a novel
abstraction for modular and composable RDTs. We also describe the collabs
library, an open-source TypeScript library that we built around this
abstraction. Our library supports arbitrary programmer-added RDTs and includes
composition techniques that make them easier to implement. This allows
programmers to work at a higher level of abstraction: custom RDTs for arbitrary
concepts in their application, instead of just a fixed menu of generic RDTs. It
also allows programmers to extend the library with new RDT algorithms as they
are published, instead of waiting for the library to implement them. Our
library includes a collection of built-in op-based CRDT implementations,
including several that were not previously implemented. To demonstrate the
library, we built numerous apps on top of it, including decentralized
collaborative apps that can be deployed from a static web page. Benchmarks show
that its CRDTs have performance comparable to state-of-the-art CRDT libraries
for web apps, and that unlike existing libraries, it can support 100
simultaneous users with low latency in a geo-distributed collaborative app.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Weidner_M/0/1/0/all/0/1">Matthew Weidner</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_H/0/1/0/all/0/1">Heather Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1">Huairui Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kjaer_M/0/1/0/all/0/1">Maxime Kjaer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pradeep_R/0/1/0/all/0/1">Ria Pradeep</a>, <a href="http://arxiv.org/find/cs/1/au:+Geordie_B/0/1/0/all/0/1">Benito Geordie</a>, <a href="http://arxiv.org/find/cs/1/au:+Meiklejohn_C/0/1/0/all/0/1">Christopher Meiklejohn</a></p><p>Replicated data types (RDTs), such as Conflict-free Replicated Data Types
(CRDTs), provide an abstraction for reasoning about replication and consistency
in distributed systems. To make them as useful as ordinary, local data
structures, RDTs need to be both modular and composable, so that programmers
can create new app-specific RDTs by composing existing ones. However, no
existing RDT libraries combine these properties; either they use monolithic
architectures that rule out new RDTs or they do not support composition
techniques.
</p>
<p>In this work, we introduce the Collab (collaborative data structure), a novel
abstraction for modular and composable RDTs. We also describe the collabs
library, an open-source TypeScript library that we built around this
abstraction. Our library supports arbitrary programmer-added RDTs and includes
composition techniques that make them easier to implement. This allows
programmers to work at a higher level of abstraction: custom RDTs for arbitrary
concepts in their application, instead of just a fixed menu of generic RDTs. It
also allows programmers to extend the library with new RDT algorithms as they
are published, instead of waiting for the library to implement them. Our
library includes a collection of built-in op-based CRDT implementations,
including several that were not previously implemented. To demonstrate the
library, we built numerous apps on top of it, including decentralized
collaborative apps that can be deployed from a static web page. Benchmarks show
that its CRDTs have performance comparable to state-of-the-art CRDT libraries
for web apps, and that unlike existing libraries, it can support 100
simultaneous users with low latency in a geo-distributed collaborative app.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.02635'>Stars: Tera-Scale Graph Building for Clustering and Graph Learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: CJ Carey, Jonathan Halcrow, Rajesh Jayaram, Vahab Mirrokni, Warren Schudy, Peilin Zhong</p><p>A fundamental procedure in the analysis of massive datasets is the
construction of similarity graphs. Such graphs play a key role for many
downstream tasks, including clustering, classification, graph learning, and
nearest neighbor search. For these tasks, it is critical to build graphs which
are sparse yet still representative of the underlying data. The benefits of
sparsity are twofold: firstly, constructing dense graphs is infeasible in
practice for large datasets, and secondly, the runtime of downstream tasks is
directly influenced by the sparsity of the similarity graph. In this work, we
present $\textit{Stars}$: a highly scalable method for building extremely
sparse graphs via two-hop spanners, which are graphs where similar points are
connected by a path of length at most two. Stars can construct two-hop spanners
with significantly fewer similarity comparisons, which are a major bottleneck
for learning based models where comparisons are expensive to evaluate.
Theoretically, we demonstrate that Stars builds a graph in nearly-linear time,
where approximate nearest neighbors are contained within two-hop neighborhoods.
In practice, we have deployed Stars for multiple data sets allowing for graph
building at the $\textit{Tera-Scale}$, i.e., for graphs with tens of trillions
of edges. We evaluate the performance of Stars for clustering and graph
learning, and demonstrate 10~1000-fold improvements in pairwise similarity
comparisons compared to different baselines, and 2~10-fold improvement in
running time without quality loss.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Carey_C/0/1/0/all/0/1">CJ Carey</a>, <a href="http://arxiv.org/find/cs/1/au:+Halcrow_J/0/1/0/all/0/1">Jonathan Halcrow</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayaram_R/0/1/0/all/0/1">Rajesh Jayaram</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a>, <a href="http://arxiv.org/find/cs/1/au:+Schudy_W/0/1/0/all/0/1">Warren Schudy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_P/0/1/0/all/0/1">Peilin Zhong</a></p><p>A fundamental procedure in the analysis of massive datasets is the
construction of similarity graphs. Such graphs play a key role for many
downstream tasks, including clustering, classification, graph learning, and
nearest neighbor search. For these tasks, it is critical to build graphs which
are sparse yet still representative of the underlying data. The benefits of
sparsity are twofold: firstly, constructing dense graphs is infeasible in
practice for large datasets, and secondly, the runtime of downstream tasks is
directly influenced by the sparsity of the similarity graph. In this work, we
present $\textit{Stars}$: a highly scalable method for building extremely
sparse graphs via two-hop spanners, which are graphs where similar points are
connected by a path of length at most two. Stars can construct two-hop spanners
with significantly fewer similarity comparisons, which are a major bottleneck
for learning based models where comparisons are expensive to evaluate.
Theoretically, we demonstrate that Stars builds a graph in nearly-linear time,
where approximate nearest neighbors are contained within two-hop neighborhoods.
In practice, we have deployed Stars for multiple data sets allowing for graph
building at the $\textit{Tera-Scale}$, i.e., for graphs with tens of trillions
of edges. We evaluate the performance of Stars for clustering and graph
learning, and demonstrate 10~1000-fold improvements in pairwise similarity
comparisons compared to different baselines, and 2~10-fold improvement in
running time without quality loss.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.02640'>Low Power Mesh Algorithms for Image Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Quentin Stout</p><p>We analyze a physically motivated fine-grained mesh-connected computer model,
assuming that a word of information takes a fixed area and that it takes unit
time and unit energy to move a word unit distance. This is a representation of
computing on a chip with myriad tiny processors arranged as a mesh. While most
mesh algorithms assume all processors are active at all times, we give
algorithms that have only a few processors on at any one time, which reduces
the power required. We apply this approach to basic problems involving images,
showing that there can be dramatic reductions in the peak power with only
small, if any, changes in the time required. We also show that these algorithms
give a more efficient way to utilize power when more power is available.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Stout_Q/0/1/0/all/0/1">Quentin Stout</a></p><p>We analyze a physically motivated fine-grained mesh-connected computer model,
assuming that a word of information takes a fixed area and that it takes unit
time and unit energy to move a word unit distance. This is a representation of
computing on a chip with myriad tiny processors arranged as a mesh. While most
mesh algorithms assume all processors are active at all times, we give
algorithms that have only a few processors on at any one time, which reduces
the power required. We apply this approach to basic problems involving images,
showing that there can be dramatic reductions in the peak power with only
small, if any, changes in the time required. We also show that these algorithms
give a more efficient way to utilize power when more power is available.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03016'>Online Min-Max Paging</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ashish Chiplunkar, Monika Henzinger, Sagar Sudhir Kale, Maximilian V&#xf6;tsch</p><p>Motivated by fairness requirements in communication networks, we introduce a
natural variant of the online paging problem, called \textit{min-max} paging,
where the objective is to minimize the maximum number of faults on any page.
While the classical paging problem, whose objective is to minimize the total
number of faults, admits $k$-competitive deterministic and $O(\log
k)$-competitive randomized algorithms, we show that min-max paging does not
admit a $c(k)$-competitive algorithm for any function $c$. Specifically, we
prove that the randomized competitive ratio of min-max paging is
$\Omega(\log(n))$ and its deterministic competitive ratio is
$\Omega(k\log(n)/\log(k))$, where $n$ is the total number of pages ever
requested.
</p>
<p>We design a fractional algorithm for paging with a more general objective --
minimize the value of an $n$-variate differentiable convex function applied to
the vector of the number of faults on each page. This gives an
$O(\log(n)\log(k))$-competitive fractional algorithm for min-max paging. We
show how to round such a fractional algorithm with at most a $k$ factor loss in
the competitive ratio, resulting in a deterministic
$O(k\log(n)\log(k))$-competitive algorithm for min-max paging. This matches our
lower bound modulo a $\mathrm{poly}(\log(k))$ factor. We also give a randomized
rounding algorithm that results in a $O(\log^2 n \log k)$-competitive
algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chiplunkar_A/0/1/0/all/0/1">Ashish Chiplunkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1">Monika Henzinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Kale_S/0/1/0/all/0/1">Sagar Sudhir Kale</a>, <a href="http://arxiv.org/find/cs/1/au:+Votsch_M/0/1/0/all/0/1">Maximilian V&#xf6;tsch</a></p><p>Motivated by fairness requirements in communication networks, we introduce a
natural variant of the online paging problem, called \textit{min-max} paging,
where the objective is to minimize the maximum number of faults on any page.
While the classical paging problem, whose objective is to minimize the total
number of faults, admits $k$-competitive deterministic and $O(\log
k)$-competitive randomized algorithms, we show that min-max paging does not
admit a $c(k)$-competitive algorithm for any function $c$. Specifically, we
prove that the randomized competitive ratio of min-max paging is
$\Omega(\log(n))$ and its deterministic competitive ratio is
$\Omega(k\log(n)/\log(k))$, where $n$ is the total number of pages ever
requested.
</p>
<p>We design a fractional algorithm for paging with a more general objective --
minimize the value of an $n$-variate differentiable convex function applied to
the vector of the number of faults on each page. This gives an
$O(\log(n)\log(k))$-competitive fractional algorithm for min-max paging. We
show how to round such a fractional algorithm with at most a $k$ factor loss in
the competitive ratio, resulting in a deterministic
$O(k\log(n)\log(k))$-competitive algorithm for min-max paging. This matches our
lower bound modulo a $\mathrm{poly}(\log(k))$ factor. We also give a randomized
rounding algorithm that results in a $O(\log^2 n \log k)$-competitive
algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-07T01:30:00Z">Wednesday, December 07 2022, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
