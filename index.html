<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2022-10-21T11:39:53Z">Friday, October 21 2022, 11:39</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a> or <a href="rss20.xml">RSS feed</a> to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, October 21
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/21/postdoc-at-nanyang-technological-university-apply-by-december-31-2023/'>Postdoc at Nanyang Technological University (apply by December 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I&#8217;m looking for two postdocs to work with me on data stream algorithms, low distortion metric embeddings, randomized numerical linear algebra or other related topics. The starting date is flexible and will be from February 2023 onwards. The initial contract is for one year and an extension is possible based on performance and the funding [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I&#8217;m looking for two postdocs to work with me on data stream algorithms, low distortion metric embeddings, randomized numerical linear algebra or other related topics.</p>
<p>The starting date is flexible and will be from February 2023 onwards. The initial contract is for one year and an extension is possible based on performance and the funding situation.</p>
<p>Website: <a href="https://personal.ntu.edu.sg/yili/">https://personal.ntu.edu.sg/yili/</a><br />
Email: yili@ntu.edu.sg</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T04:49:58Z">Friday, October 21 2022, 04:49</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10917'>Substring Density Estimation from Traces</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kayvon Mazooji, Ilan Shomorony</p><p>In the trace reconstruction problem, one seeks to reconstruct a binary string
$s$ from a collection of traces, each of which is obtained by passing $s$
through a deletion channel. It is known that $\exp(\tilde O(n^{1/5}))$ traces
suffice to reconstruct any length-$n$ string with high probability. We consider
a variant of the trace reconstruction problem where the goal is to recover a
"density map" that indicates the locations of each length-$k$ substring
throughout $s$. We show that $\epsilon^{-2}\cdot \text{poly}(n)$ traces suffice
to recover the density map with error at most $\epsilon$. As a result, when
restricted to a set of source strings whose minimum "density map distance" is
at least $1/\text{poly}(n)$, the trace reconstruction problem can be solved
with polynomially many traces.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mazooji_K/0/1/0/all/0/1">Kayvon Mazooji</a>, <a href="http://arxiv.org/find/cs/1/au:+Shomorony_I/0/1/0/all/0/1">Ilan Shomorony</a></p><p>In the trace reconstruction problem, one seeks to reconstruct a binary string
$s$ from a collection of traces, each of which is obtained by passing $s$
through a deletion channel. It is known that $\exp(\tilde O(n^{1/5}))$ traces
suffice to reconstruct any length-$n$ string with high probability. We consider
a variant of the trace reconstruction problem where the goal is to recover a
"density map" that indicates the locations of each length-$k$ substring
throughout $s$. We show that $\epsilon^{-2}\cdot \text{poly}(n)$ traces suffice
to recover the density map with error at most $\epsilon$. As a result, when
restricted to a set of source strings whose minimum "density map distance" is
at least $1/\text{poly}(n)$, the trace reconstruction problem can be solved
with polynomially many traces.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10968'>Identities and periodic oscillations of divide-and-conquer recurrences splitting at half</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hsien-Kuei Hwang, Svante Janson, Tsung-Hsi Tsai</p><p>We study divide-and-conquer recurrences of the form \begin{equation*}
</p>
<p>f(n)
</p>
<p>= \alpha f(\lfloor \tfrac n2\rfloor)
</p>
<p>+ \beta f(\lceil \tfrac n2\rceil)
</p>
<p>+ g(n) \qquad(n\ge2), \end{equation*} with $g(n)$ and $f(1)$ given, where
$\alpha,\beta\ge0$ with $\alpha+\beta&gt;0$; such recurrences appear often in
analysis of computer algorithms, numeration systems, combinatorial sequences,
and related areas. We show that the solution satisfies always the simple
\emph{identity} \begin{equation*}
</p>
<p>f(n)
</p>
<p>= n^{\log_2(\alpha+\beta)} P(\log_2n) - Q(n) \end{equation*} under an optimum
(iff) condition on $g(n)$. This form is not only an identity but also an
asymptotic expansion because $Q(n)$ is of a smaller order. Explicit forms for
the \emph{continuity} of the periodic function $P$ are provided, together with
a few other smoothness properties. We show how our results can be easily
applied to many dozens of concrete examples collected from the literature, and
how they can be extended in various directions. Our method of proof is
surprisingly simple and elementary, but leads to the strongest types of results
for all examples to which our theory applies.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hwang_H/0/1/0/all/0/1">Hsien-Kuei Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Janson_S/0/1/0/all/0/1">Svante Janson</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_T/0/1/0/all/0/1">Tsung-Hsi Tsai</a></p><p>We study divide-and-conquer recurrences of the form \begin{equation*}
</p>
<p>f(n)
</p>
<p>= \alpha f(\lfloor \tfrac n2\rfloor)
</p>
<p>+ \beta f(\lceil \tfrac n2\rceil)
</p>
<p>+ g(n) \qquad(n\ge2), \end{equation*} with $g(n)$ and $f(1)$ given, where
$\alpha,\beta\ge0$ with $\alpha+\beta&gt;0$; such recurrences appear often in
analysis of computer algorithms, numeration systems, combinatorial sequences,
and related areas. We show that the solution satisfies always the simple
\emph{identity} \begin{equation*}
</p>
<p>f(n)
</p>
<p>= n^{\log_2(\alpha+\beta)} P(\log_2n) - Q(n) \end{equation*} under an optimum
(iff) condition on $g(n)$. This form is not only an identity but also an
asymptotic expansion because $Q(n)$ is of a smaller order. Explicit forms for
the \emph{continuity} of the periodic function $P$ are provided, together with
a few other smoothness properties. We show how our results can be easily
applied to many dozens of concrete examples collected from the literature, and
how they can be extended in various directions. Our method of proof is
surprisingly simple and elementary, but leads to the strongest types of results
for all examples to which our theory applies.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11132'>A general model-and-run solver for multistage robust discrete linear optimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Hartisch, Ulf Lorenz</p><p>The necessity to deal with uncertain data is a major challenge in decision
making. Robust optimization emerged as one of the predominant paradigms to
produce solutions that hedge against uncertainty. In order to obtain an even
more realistic description of the underlying problem where the decision maker
can react to newly disclosed information, multistage models can be used.
However, due to their computational difficulty, multistage problems beyond two
stages have received less attention and are often only addressed using
approximation rather than optimization schemes. Even less attention is paid to
the consideration of decision-dependent uncertainty in a multistage setting. We
explore multistage robust optimization via quantified linear programs, which
are linear programs with ordered variables that are either existentially or
universally quantified. Building upon a (mostly) discrete setting where the
uncertain parameters -- the universally quantified variables -- are only
restricted by their bounds, we present an augmented version that allows stating
the discrete uncertainty set via a linear constraint system that also can be
affected by decision variables. We present a general search-based solution
approach and introduce our solver Yasol that is able to deal with multistage
robust linear discrete optimization problems, with final mixed-integer recourse
actions and a discrete uncertainty set, which even can be decision-dependent.
In doing so, we provide a convenient model-and-run approach, that can serve as
baseline for computational experiments in the field of multistage robust
optimization, providing optimal solutions for problems with an arbitrary number
of decision stages.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Hartisch_M/0/1/0/all/0/1">Michael Hartisch</a>, <a href="http://arxiv.org/find/math/1/au:+Lorenz_U/0/1/0/all/0/1">Ulf Lorenz</a></p><p>The necessity to deal with uncertain data is a major challenge in decision
making. Robust optimization emerged as one of the predominant paradigms to
produce solutions that hedge against uncertainty. In order to obtain an even
more realistic description of the underlying problem where the decision maker
can react to newly disclosed information, multistage models can be used.
However, due to their computational difficulty, multistage problems beyond two
stages have received less attention and are often only addressed using
approximation rather than optimization schemes. Even less attention is paid to
the consideration of decision-dependent uncertainty in a multistage setting. We
explore multistage robust optimization via quantified linear programs, which
are linear programs with ordered variables that are either existentially or
universally quantified. Building upon a (mostly) discrete setting where the
uncertain parameters -- the universally quantified variables -- are only
restricted by their bounds, we present an augmented version that allows stating
the discrete uncertainty set via a linear constraint system that also can be
affected by decision variables. We present a general search-based solution
approach and introduce our solver Yasol that is able to deal with multistage
robust linear discrete optimization problems, with final mixed-integer recourse
actions and a discrete uncertainty set, which even can be decision-dependent.
In doing so, we provide a convenient model-and-run approach, that can serve as
baseline for computational experiments in the field of multistage robust
optimization, providing optimal solutions for problems with an arbitrary number
of decision stages.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11185'>Using Integer Programming Techniques in Real-Time Scheduling Analysis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Abhishek Singh</p><p>Real-time scheduling theory assists developers of embedded systems in
verifying that the timing constraints required by critical software tasks can
be feasibly met on a given hardware platform. Fundamental problems in the
theory are often formulated as search problems for fixed points of functions
and are solved by fixed-point iterations. These fixed-point methods are used
widely because they are simple to understand, simple to implement, and seem to
work well in practice. These fundamental problems can also be formulated as
integer programs and solved with algorithms that are based on theories of
linear programming and cutting planes amongst others. However, such algorithms
are harder to understand and implement than fixed-point iterations. In this
research, we show that ideas like linear programming duality and cutting planes
can be used to develop algorithms that are as easy to implement as existing
fixed-point iteration schemes but have better convergence properties. We
evaluate the algorithms on synthetically generated problem instances to
demonstrate that the new algorithms are faster than the existing algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Abhishek Singh</a></p><p>Real-time scheduling theory assists developers of embedded systems in
verifying that the timing constraints required by critical software tasks can
be feasibly met on a given hardware platform. Fundamental problems in the
theory are often formulated as search problems for fixed points of functions
and are solved by fixed-point iterations. These fixed-point methods are used
widely because they are simple to understand, simple to implement, and seem to
work well in practice. These fundamental problems can also be formulated as
integer programs and solved with algorithms that are based on theories of
linear programming and cutting planes amongst others. However, such algorithms
are harder to understand and implement than fixed-point iterations. In this
research, we show that ideas like linear programming duality and cutting planes
can be used to develop algorithms that are as easy to implement as existing
fixed-point iteration schemes but have better convergence properties. We
evaluate the algorithms on synthetically generated problem instances to
demonstrate that the new algorithms are faster than the existing algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11197'>Noisy Tree Data Structures and Quantum Applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kamil Khadiev, Nikita Savelyev, Mansur Ziatdinov</p><p>The paper presents a technique for constructing noisy data structures called
a walking tree. We apply it for a Red-Black tree (an implementation of a
Self-Balanced Binary Search Tree) and a segment tree. We obtain the same
complexity of the main operations for these data structures as in the case
without noise (asymptotically). We use these data structures in quantum
algorithms for two problems: the Exam Problem and the Largest File Problem.
</p>
<p>Finally, we suggest new quantum solution for strings sorting problem and show
the lower bound. The upper bound and lower bound for the problem are the same
up to log factor. At the same time, it is more effective than classical
counterparts.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Khadiev_K/0/1/0/all/0/1">Kamil Khadiev</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Savelyev_N/0/1/0/all/0/1">Nikita Savelyev</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ziatdinov_M/0/1/0/all/0/1">Mansur Ziatdinov</a></p><p>The paper presents a technique for constructing noisy data structures called
a walking tree. We apply it for a Red-Black tree (an implementation of a
Self-Balanced Binary Search Tree) and a segment tree. We obtain the same
complexity of the main operations for these data structures as in the case
without noise (asymptotically). We use these data structures in quantum
algorithms for two problems: the Exam Problem and the Largest File Problem.
</p>
<p>Finally, we suggest new quantum solution for strings sorting problem and show
the lower bound. The upper bound and lower bound for the problem are the same
up to log factor. At the same time, it is more effective than classical
counterparts.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11222'>Private Algorithms with Private Predictions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kareem Amin, Travis Dick, Mikhail Khodak, Sergei Vassilvitskii</p><p>When applying differential privacy to sensitive data, a common way of getting
improved performance is to use external information such as other sensitive
data, public data, or human priors. We propose to use the algorithms with
predictions framework -- previously applied largely to improve time complexity
or competitive ratios -- as a powerful way of designing and analyzing
privacy-preserving methods that can take advantage of such external information
to improve utility. For four important tasks -- quantile release, its extension
to multiple quantiles, covariance estimation, and data release -- we construct
prediction-dependent differentially private methods whose utility scales with
natural measures of prediction quality. The analyses enjoy several advantages,
including minimal assumptions about the data, natural ways of adding robustness
to noisy predictions, and novel "meta" algorithms that can learn predictions
from other (potentially sensitive) data. Overall, our results demonstrate how
to enable differentially private algorithms to make use of and learn noisy
predictions, which holds great promise for improving utility while preserving
privacy across a variety of tasks.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Amin_K/0/1/0/all/0/1">Kareem Amin</a>, <a href="http://arxiv.org/find/cs/1/au:+Dick_T/0/1/0/all/0/1">Travis Dick</a>, <a href="http://arxiv.org/find/cs/1/au:+Khodak_M/0/1/0/all/0/1">Mikhail Khodak</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilvitskii_S/0/1/0/all/0/1">Sergei Vassilvitskii</a></p><p>When applying differential privacy to sensitive data, a common way of getting
improved performance is to use external information such as other sensitive
data, public data, or human priors. We propose to use the algorithms with
predictions framework -- previously applied largely to improve time complexity
or competitive ratios -- as a powerful way of designing and analyzing
privacy-preserving methods that can take advantage of such external information
to improve utility. For four important tasks -- quantile release, its extension
to multiple quantiles, covariance estimation, and data release -- we construct
prediction-dependent differentially private methods whose utility scales with
natural measures of prediction quality. The analyses enjoy several advantages,
including minimal assumptions about the data, natural ways of adding robustness
to noisy predictions, and novel "meta" algorithms that can learn predictions
from other (potentially sensitive) data. Overall, our results demonstrate how
to enable differentially private algorithms to make use of and learn noisy
predictions, which holds great promise for improving utility while preserving
privacy across a variety of tasks.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11295'>Block subsampled randomized Hadamard transform for low-rank approximation on distributed architectures</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Oleg Balabanov, Matthias Beaupere, Laura Grigori, Victor Lederer</p><p>This article introduces a novel structured random matrix composed blockwise
from subsampled randomized Hadamard transforms (SRHTs). The block SRHT is
expected to outperform well-known dimension reduction maps, including SRHT and
Gaussian matrices, on distributed architectures with not too many cores
compared to the dimension. We prove that a block SRHT with enough rows is an
oblivious subspace embedding, i.e., an approximate isometry for an arbitrary
low-dimensional subspace with high probability. Our estimate of the required
number of rows is similar to that of the standard SRHT. This suggests that the
two transforms should provide the same accuracy of approximation in the
algorithms. The block SRHT can be readily incorporated into randomized methods,
for instance to compute a low-rank approximation of a large-scale matrix. For
completeness, we revisit some common randomized approaches for this problem
such as Randomized Singular Value Decomposition and Nystr\"{o}m approximation,
with a discussion of their accuracy and implementation on distributed
architectures.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Balabanov_O/0/1/0/all/0/1">Oleg Balabanov</a>, <a href="http://arxiv.org/find/math/1/au:+Beaupere_M/0/1/0/all/0/1">Matthias Beaupere</a>, <a href="http://arxiv.org/find/math/1/au:+Grigori_L/0/1/0/all/0/1">Laura Grigori</a>, <a href="http://arxiv.org/find/math/1/au:+Lederer_V/0/1/0/all/0/1">Victor Lederer</a></p><p>This article introduces a novel structured random matrix composed blockwise
from subsampled randomized Hadamard transforms (SRHTs). The block SRHT is
expected to outperform well-known dimension reduction maps, including SRHT and
Gaussian matrices, on distributed architectures with not too many cores
compared to the dimension. We prove that a block SRHT with enough rows is an
oblivious subspace embedding, i.e., an approximate isometry for an arbitrary
low-dimensional subspace with high probability. Our estimate of the required
number of rows is similar to that of the standard SRHT. This suggests that the
two transforms should provide the same accuracy of approximation in the
algorithms. The block SRHT can be readily incorporated into randomized methods,
for instance to compute a low-rank approximation of a large-scale matrix. For
completeness, we revisit some common randomized approaches for this problem
such as Randomized Singular Value Decomposition and Nystr\"{o}m approximation,
with a discussion of their accuracy and implementation on distributed
architectures.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11413'>Finding the smallest or largest element of a tensor from its low-rank factors</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicholas D. Sidiropoulos, Paris Karakasis, Aritra Konar</p><p>We consider the problem of finding the smallest or largest entry of a tensor
of order $N$ that is specified via its rank decomposition. Stated in a
different way, we are given $N$ sets of $R$-dimensional vectors and we wish to
select one vector from each set such that the sum of the Hadamard product of
the selected vectors is minimized or maximized. This is a fundamental tensor
problem with numerous applications in embedding similarity search, recommender
systems, graph mining, multivariate probability, and statistics. We show that
this discrete optimization problem is NP-hard for any tensor rank higher than
one, but also provide an equivalent continuous problem reformulation which is
amenable to disciplined non-convex optimization. We propose a suite of
gradient-based approximation algorithms whose performance in preliminary
experiments appears to be promising.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/eess/1/au:+Sidiropoulos_N/0/1/0/all/0/1">Nicholas D. Sidiropoulos</a>, <a href="http://arxiv.org/find/eess/1/au:+Karakasis_P/0/1/0/all/0/1">Paris Karakasis</a>, <a href="http://arxiv.org/find/eess/1/au:+Konar_A/0/1/0/all/0/1">Aritra Konar</a></p><p>We consider the problem of finding the smallest or largest entry of a tensor
of order $N$ that is specified via its rank decomposition. Stated in a
different way, we are given $N$ sets of $R$-dimensional vectors and we wish to
select one vector from each set such that the sum of the Hadamard product of
the selected vectors is minimized or maximized. This is a fundamental tensor
problem with numerous applications in embedding similarity search, recommender
systems, graph mining, multivariate probability, and statistics. We show that
this discrete optimization problem is NP-hard for any tensor rank higher than
one, but also provide an equivalent continuous problem reformulation which is
amenable to disciplined non-convex optimization. We propose a suite of
gradient-based approximation algorithms whose performance in preliminary
experiments appears to be promising.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, October 20
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/20/tenure-track-faculty-positions-at-simon-fraser-university-apply-by-december-15-2022/'>Tenure-track Faculty Positions at Simon Fraser University (apply by December 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The School of Computing Science at Simon Fraser University (SFU) invites applications for multiple tenure-track faculty positions. Website: www.sfu.ca/computing/job-opportunities.html Email: cs_faculty_affairs@sfu.ca
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The School of Computing Science at Simon Fraser University (SFU) invites applications for multiple tenure-track faculty positions.</p>
<p>Website: <a href="https://www.sfu.ca/computing/job-opportunities.html">https://www.sfu.ca/computing/job-opportunities.html</a><br />
Email: cs_faculty_affairs@sfu.ca</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T23:49:12Z">Thursday, October 20 2022, 23:49</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/20/faculty-tt-open-to-all-ranks-at-university-of-colorado-boulder-apply-by-december-5-2022/'>Faculty (TT, open to all ranks) at University of Colorado Boulder (apply by December 5, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The University of Colorado Boulder is seeking applications for a tenure-track faculty position at the Assistant Professor rank in theoretical computer science, broadly deﬁned. Associate &#38; Full Professor ranks may be considered for qualified candidates. All researchers working on topics within &#38; adjacent to the broad area of Computer Science Theory are encouraged to apply. [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The University of Colorado Boulder is seeking applications for a tenure-track faculty position at the Assistant Professor rank in theoretical computer science, broadly deﬁned. Associate &amp; Full Professor ranks may be considered for qualified candidates. All researchers working on topics within &amp; adjacent to the broad area of Computer Science Theory are encouraged to apply.</p>
<p>Website: <a href="https://jobs.colorado.edu/jobs/JobDetail/?jobId=43568">https://jobs.colorado.edu/jobs/JobDetail/?jobId=43568</a><br />
Email: jgrochow@colorado.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T18:53:34Z">Thursday, October 20 2022, 18:53</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/20/two-postdoc-positions-in-lisbon-at-university-of-lisbon-apply-by-january-1-2023/'>Two postdoc positions in Lisbon at University of Lisbon (apply by January 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I&#8217;m looking for two postdocs to join me as part of the ERC Starting Grant &#8220;The Hardness of Finding Good Algorithms&#8221;. The project focuses on metacomplexity and unconditional lower-bounds. The starting date is flexible, between March-October 2023. A decision on individual applicants will not be made before November 1, and I expect both positions to [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I&#8217;m looking for two postdocs to join me as part of the ERC Starting Grant &#8220;The Hardness of Finding Good Algorithms&#8221;. The project focuses on metacomplexity and unconditional lower-bounds.</p>
<p>The starting date is flexible, between March-October 2023. A decision on individual applicants will not be made before November 1, and I expect both positions to be filled by mid-late January.</p>
<p>Website: <a href="https://brunoloff.wordpress.com/hofga/">https://brunoloff.wordpress.com/hofga/</a><br />
Email: bruno.loff@gmail.com</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T17:30:08Z">Thursday, October 20 2022, 17:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/10/alpha-tensor.html'>Alpha Tensor</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>In a recent post, Bill used the announcement of a new AI multiplication algorithm to discuss the applications of Strassen's famous algorithm. For this post I'd like to focus on the new algorithm itself,&nbsp;Alpha Tensor, the algorithm behind the algorithm, what it has actually accomplished&nbsp;and what it means for us theorists.&nbsp;</p><p>To multiply two 2x2 matrices in the usual way you need eight multiplication steps. In 1969 Strassen surprised the world by showing how to multiply those matrices using only seven multiplications.</p><p>You can recurse on larger matrices. For 4x4 matrices you can use 72=49 multiplications instead of the naïve 64. In general for nxn matrices you need roughly nlog27 ≈ n2.81 multiplications.</p><p>No one has found an algorithm for 4x4 matrices that uses less than 49 from recursing on Strassen. Alpha Tensor does so for the special case of working over GF[2], where addition and subtraction are interchangeable. Their algorithm does not work for general fields such as the real numbers.</p><p>Here's the full table of Alpha Tensor results from the Nature paper for multiplying a nxm matrix by a mxp matrix. The Modular column is for GF[2] and the standard column is for general fields. Alpha tensor does improve on the best known for general fields for specific problems like multiplying a 3x4 matrix by a 4x5 matrix. Much of the press failed to make this distinction for 4x4 multiplication leading to some confusion.</p>♦<br>What does this mean for theory? Recursing on 4x4 matrices now reduces the time for matrix multiplication to roughly n2.78 nowhere close to the best theoretical upper bound of about n2.37. The Alpha tensor result may be more practical though time will tell.<br>Manuel Kauers and Jakob Moosbauer shortly after Alpha Tensor announcement, reduced the 5x5 case over GF[2] to 95 multiplications. Nice to see the last word isn't by machine (yet!) but that shouldn't reduce the excitement over Alpha Tensor. Often we see a breakthrough followed by a small improvement. Note that 95 multiplications for 5x5 matrices won't give a faster asymptotic algorithm for nxn multiplication than Strassen.<br>What excites me the most is not the algorithm, but the algorithm to find the algorithm. Alpha Tensor uses the tools that AlphaZero used to play Chess and Go to search the large search space of potential algorithms using Monte Carlo Tree search, basically searching at random and learning and updating the probabilities of the search. Before using machine learning, we had few good approaches to searching large combinatorial spaces of this nature.&nbsp;<br>In general, most new algorithms come from new approaches, not just from the structural decomposition we see in matrix multiplication so theorists won't be out of a job anytime soon. Nevertheless this is just another lesson that using ML has dramatically improved our ability to search through a large number of possibilities looking for a specific solution.&nbsp;<br>The Alpha Tensor Nature paper was submitted in October of 2021. A year is eternity in the ML world. I wonder what is happening now that we don't know about.<p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In a <a href="https://blog.computationalcomplexity.org/2022/10/will-strassens-matrix-mult-alg-ever-be.html">recent post</a>, Bill used the announcement of a new AI multiplication algorithm to discuss the applications of Strassen's famous algorithm. For this post I'd like to focus on the new algorithm itself,&nbsp;<a href="https://www.deepmind.com/blog/discovering-novel-algorithms-with-alphatensor">Alpha Tensor</a>, the algorithm behind the algorithm, what it has actually accomplished&nbsp;and what it means for us theorists.&nbsp;</p><p>To multiply two 2x2 matrices in the usual way you need eight multiplication steps. In 1969 Strassen surprised the world by showing how to <a href="https://en.wikipedia.org/wiki/Strassen_algorithm#Algorithm">multiply those matrices using only seven multiplications</a>.</p><p>You can recurse on larger matrices. For 4x4 matrices you can use 7<sup>2</sup>=49 multiplications instead of the naïve 64. In general for nxn matrices you need roughly n<sup>log<sub>2</sub>7</sup> ≈ n<sup>2.81</sup> multiplications.</p><p>No one has found an algorithm for 4x4 matrices that uses less than 49 from recursing on Strassen. Alpha Tensor does so for the special case of working over GF[2], where addition and subtraction are interchangeable. Their algorithm does not work for general fields such as the real numbers.</p><p>Here's the full table of Alpha Tensor results from the <a href="https://doi.org/10.1038/s41586-022-05172-4">Nature paper</a> for multiplying a nxm matrix by a mxp matrix. The Modular column is for GF[2] and the standard column is for general fields. Alpha tensor does improve on the best known for general fields for specific problems like multiplying a 3x4 matrix by a 4x5 matrix. Much of the press <a href="https://arstechnica.com/information-technology/2022/10/deepmind-breaks-50-year-math-record-using-ai-new-record-falls-a-week-later/">failed to make this distinction</a> for 4x4 multiplication leading to some confusion.</p><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj9-_aNBNNDkLCuUrz9Wz2dzgctRxEAk2Q8ptCHuk1SwBLyNrwentWYhpYulJX3VP64GE3UxlfaQlSHxm2faVnrh44MCnEyHSM2o-998w6P0_gKIk9fPScLQU9PtxKUPmfuFZR6SiYYlvuXw01FhP0Jg24ro1j0YCY99pxg7aTzMI7mzgWCfw/s833/IMG_0190.jpg" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="833" data-original-width="702" height="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj9-_aNBNNDkLCuUrz9Wz2dzgctRxEAk2Q8ptCHuk1SwBLyNrwentWYhpYulJX3VP64GE3UxlfaQlSHxm2faVnrh44MCnEyHSM2o-998w6P0_gKIk9fPScLQU9PtxKUPmfuFZR6SiYYlvuXw01FhP0Jg24ro1j0YCY99pxg7aTzMI7mzgWCfw/w540-h640/IMG_0190.jpg" width="540" /></a></div><br /><div class="separator" style="clear: both; text-align: left;">What does this mean for theory? Recursing on 4x4 matrices now reduces the time for matrix multiplication to roughly n<sup>2.78</sup> nowhere close to the best <a href="https://doi.org/10.1137/1.9781611976465.32">theoretical upper bound</a> of about n<sup>2.37</sup>. The Alpha tensor result may be more practical though time will tell.</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">Manuel Kauers and Jakob Moosbauer shortly after Alpha Tensor announcement, <a href="https://arxiv.org/abs/2210.04045">reduced</a> the 5x5 case over GF[2] to 95 multiplications. Nice to see the last word isn't by machine (yet!) but that shouldn't reduce the excitement over Alpha Tensor. Often we see a breakthrough followed by a small improvement. Note that 95 multiplications for 5x5 matrices won't give a faster asymptotic algorithm for nxn multiplication than Strassen.</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">What excites me the most is not the algorithm, but the algorithm to find the algorithm. Alpha Tensor uses the tools that AlphaZero used to play Chess and Go to search the large search space of potential algorithms using Monte Carlo Tree search, basically searching at random and learning and updating the probabilities of the search. Before using machine learning, we had few good approaches to searching large combinatorial spaces of this nature.&nbsp;</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">In general, most new algorithms come from new approaches, not just from the structural decomposition we see in matrix multiplication so theorists won't be out of a job anytime soon. Nevertheless this is just another lesson that using ML has dramatically improved our ability to search through a large number of possibilities looking for a specific solution.&nbsp;</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">The Alpha Tensor Nature paper was <a href="https://www.nature.com/articles/s41586-022-05172-4#article-info">submitted</a> in October of 2021. A year is eternity in the ML world. I wonder what is happening now that we don't know about.</div><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T14:27:00Z">Thursday, October 20 2022, 14:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2022/10/20/tcs-talk-wednesday-october-26-shay-moran-technion-and-google-research/'>TCS+ talk: Wednesday, October 26 — Shay Moran, Technion and Google Research</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, October 26th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Shay Moran from Technion and Google Research will speak about &#8220;A Characterization of Multiclass PAC Learning&#8221; (abstract below). You can reserve a spot as an individual or a [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The next TCS+ talk will take place this coming Wednesday, October 26th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Shay Moran</strong> from Technion and Google Research will speak about &#8220;<em>A Characterization of Multiclass PAC Learning</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: A seminal result in learning theory characterizes the PAC learnability of binary classes through the VC dimension. Extending this characterization to the general multiclass setting has been open since the late 1980s.</p>
<p>We resolve this problem by characterizing multiclass PAC learnability through the DS dimension, a combinatorial dimension defined by Daniely and Shalev-Shwartz (2014).</p>
<p>The classical characterization of the binary case boils down to empirical risk minimization. In contrast, our characterization of the multiclass case involves a variety of algorithmic ideas; these include a natural setting we call list PAC learning. In the list learning setting, instead of predicting the label of a given unseen input, the goal is to provide a short list of labels which contains the correct one with high probability.</p>
<p>Our second main result concerns the Natarajan dimension, which has been a central candidate for characterizing multiclass learnability. This dimension was introduced by Natarajan (1988) as a barrier for PAC learning. Whether the Natarajan dimension characterizes PAC learnability in general has been posed as an open question in several papers since. We provide a negative answer: we construct a non-learnable class with Natarajan dimension one.</p>
<p>For the construction, we identify a fundamental connection between concept classes and topology. We crucially rely on a deep and involved geometric-group-theoretic construction by Januszkiewicz and Swiatkowski. This proof provides another demonstration of the fruitful links learning theory has with different areas in mathematics.</p>
<p>Joint work with Nataly Brukhim, Daniel Carmon, Irit Dinur, and Amir Yehudayoff</p></blockquote>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T10:29:17Z">Thursday, October 20 2022, 10:29</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/20/teaching-faculty-open-rank-at-university-of-illinois-at-urbana-champaign-apply-by-november-15-2022/'>Teaching Faculty (Open Rank) at University of Illinois at Urbana-Champaign (apply by November 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Computer Science Department at the University of Illinois invites applications for multiple full-time teaching positions to support the continued expansion of our teaching activity in Urbana-Champaign, in Chicago, and online. We welcome applications from instructors able to teach across the computer science curriculum, including candidates who can teach algorithms and theory. Website: cs.illinois.edu/about/positions/faculty-positions/teaching-faculty Email: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Computer Science Department at the University of Illinois invites applications for multiple full-time teaching positions to support the continued expansion of our teaching activity in Urbana-Champaign, in Chicago, and online. We welcome applications from instructors able to teach across the computer science curriculum, including candidates who can teach algorithms and theory.</p>
<p>Website: <a href="https://cs.illinois.edu/about/positions/faculty-positions/teaching-faculty">https://cs.illinois.edu/about/positions/faculty-positions/teaching-faculty</a><br />
Email: facultysearch@cs.illinois.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T01:51:34Z">Thursday, October 20 2022, 01:51</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/20/professor-open-rank-at-university-of-illinois-at-urbana-champaign-apply-by-november-15-2022/'>Professor (Open Rank) at University of Illinois at Urbana-Champaign (apply by November 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Department of Computer Science at the University of Illinois Urbana-Champaign invites applications for full-time tenure-track faculty positions at all levels (Assistant Professor, Associate Professor, Full Professor). We particularly encourage applications from candidates working in quantum computing, but all areas of theory will be considered. Website: cs.illinois.edu/about/positions/faculty-positions/tenure-track Email: cs-facultysearch@illinois.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Department of Computer Science at the University of Illinois Urbana-Champaign invites applications for full-time tenure-track faculty positions at all levels (Assistant Professor, Associate Professor, Full Professor). We particularly encourage applications from candidates working in quantum computing, but all areas of theory will be considered.</p>
<p>Website: <a href="https://cs.illinois.edu/about/positions/faculty-positions/tenure-track">https://cs.illinois.edu/about/positions/faculty-positions/tenure-track</a><br />
Email: cs-facultysearch@illinois.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T01:45:15Z">Thursday, October 20 2022, 01:45</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10181'>Comparing Embedded Graphs Using Average Branching Distance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Levent Batakci, Abigail Branson, Bryan Castillo, Candace Todd, Erin Wolf Chambers, Elizabeth Munch</p><p>Graphs drawn in the plane are ubiquitous, arising from data sets through a
variety of methods ranging from GIS analysis to image classification to shape
analysis. A fundamental problem in this type of data is comparison: given a set
of such graphs, can we rank how similar they are, in such a way that we capture
their geometric "shape" in the plane? In this paper we explore a method to
compare two such embedded graphs, via a simplified combinatorial representation
called a tail-less merge tree which encodes the structure based on a fixed
direction. First, we examine the properties of a distance designed to compare
merge trees called the branching distance, and show that the distance as
defined in previous work fails to satisfy some of the requirements of a metric.
We incorporate this into a new distance function called average branching
distance to compare graphs by looking at the branching distance for merge trees
defined over many directions. Despite the theoretical issues, we show that the
definition is still quite useful in practice by using our open-source code to
cluster data sets of embedded graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Batakci_L/0/1/0/all/0/1">Levent Batakci</a>, <a href="http://arxiv.org/find/cs/1/au:+Branson_A/0/1/0/all/0/1">Abigail Branson</a>, <a href="http://arxiv.org/find/cs/1/au:+Castillo_B/0/1/0/all/0/1">Bryan Castillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Todd_C/0/1/0/all/0/1">Candace Todd</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambers_E/0/1/0/all/0/1">Erin Wolf Chambers</a>, <a href="http://arxiv.org/find/cs/1/au:+Munch_E/0/1/0/all/0/1">Elizabeth Munch</a></p><p>Graphs drawn in the plane are ubiquitous, arising from data sets through a
variety of methods ranging from GIS analysis to image classification to shape
analysis. A fundamental problem in this type of data is comparison: given a set
of such graphs, can we rank how similar they are, in such a way that we capture
their geometric "shape" in the plane? In this paper we explore a method to
compare two such embedded graphs, via a simplified combinatorial representation
called a tail-less merge tree which encodes the structure based on a fixed
direction. First, we examine the properties of a distance designed to compare
merge trees called the branching distance, and show that the distance as
defined in previous work fails to satisfy some of the requirements of a metric.
We incorporate this into a new distance function called average branching
distance to compare graphs by looking at the branching distance for merge trees
defined over many directions. Despite the theoretical issues, we show that the
definition is still quite useful in practice by using our open-source code to
cluster data sets of embedded graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10535'>Stability of Entropic Wasserstein Barycenters and application to random geometric graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marc Theveneau, Nicolas Keriven</p><p>As interest in graph data has grown in recent years, the computation of
various geometric tools has become essential. In some area such as mesh
processing, they often rely on the computation of geodesics and shortest paths
in discretized manifolds. A recent example of such a tool is the computation of
Wasserstein barycenters (WB), a very general notion of barycenters derived from
the theory of Optimal Transport, and their entropic-regularized variant. In
this paper, we examine how WBs on discretized meshes relate to the geometry of
the underlying manifold. We first provide a generic stability result with
respect to the input cost matrices. We then apply this result to random
geometric graphs on manifolds, whose shortest paths converge to geodesics,
hence proving the consistency of WBs computed on discretized shapes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Theveneau_M/0/1/0/all/0/1">Marc Theveneau</a>, <a href="http://arxiv.org/find/cs/1/au:+Keriven_N/0/1/0/all/0/1">Nicolas Keriven</a></p><p>As interest in graph data has grown in recent years, the computation of
various geometric tools has become essential. In some area such as mesh
processing, they often rely on the computation of geodesics and shortest paths
in discretized manifolds. A recent example of such a tool is the computation of
Wasserstein barycenters (WB), a very general notion of barycenters derived from
the theory of Optimal Transport, and their entropic-regularized variant. In
this paper, we examine how WBs on discretized meshes relate to the geometry of
the underlying manifold. We first provide a generic stability result with
respect to the input cost matrices. We then apply this result to random
geometric graphs on manifolds, whose shortest paths converge to geodesics,
hence proving the consistency of WBs computed on discretized shapes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10677'>List homomorphisms by deleting edges and vertices: tight complexity bounds for bounded-treewidth graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bar&#x131;&#x15f; Can Esmer, Jacob Focke, D&#xe1;niel Marx, Pawe&#x142; Rz&#x105;&#x17c;ewski</p><p>The goal of this paper is to investigate a family of optimization problems
arising from list homomorphisms, and to understand what the best possible
algorithms are if we restrict the problem to bounded-treewidth graphs. For a
fixed $H$, the input of the optimization problem LHomVD($H$) is a graph $G$
with lists $L(v)$, and the task is to find a set $X$ of vertices having minimum
size such that $(G-X,L)$ has a list homomorphism to $H$. We define analogously
the edge-deletion variant LHomED($H$). This expressive family of problems
includes members that are essentially equivalent to fundamental problems such
as Vertex Cover, Max Cut, Odd Cycle Transversal, and Edge/Vertex Multiway Cut.
</p>
<p>For both variants, we first characterize those graphs $H$ that make the
problem polynomial-time solvable and show that the problem is NP-hard for every
other fixed $H$. Second, as our main result, we determine for every graph $H$
for which the problem is NP-hard, the smallest possible constant $c_H$ such
that the problem can be solved in time $c^t_H\cdot n^{O(1)}$ if a tree
decomposition of $G$ having width $t$ is given in the input, assuming the SETH.
Let $i(H)$ be the maximum size of a set of vertices in $H$ that have pairwise
incomparable neighborhoods. For the vertex-deletion variant LHomVD($H$), we
show that the smallest possible constant is $i(H)+1$ for every $H$.
</p>
<p>The situation is more complex for the edge-deletion version. For every $H$,
one can solve LHomED($H$) in time $i(H)^t\cdot n^{O(1)}$ if a tree
decomposition of width $t$ is given. However, the existence of a specific type
of decomposition of $H$ shows that there are graphs $H$ where LHomED($H$) can
be solved significantly more efficiently and the best possible constant can be
arbitrarily smaller than $i(H)$. Nevertheless, we determine this best possible
constant and (assuming the SETH) prove tight bounds for every fixed $H$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Esmer_B/0/1/0/all/0/1">Bar&#x131;&#x15f; Can Esmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Focke_J/0/1/0/all/0/1">Jacob Focke</a>, <a href="http://arxiv.org/find/cs/1/au:+Marx_D/0/1/0/all/0/1">D&#xe1;niel Marx</a>, <a href="http://arxiv.org/find/cs/1/au:+Rzazewski_P/0/1/0/all/0/1">Pawe&#x142; Rz&#x105;&#x17c;ewski</a></p><p>The goal of this paper is to investigate a family of optimization problems
arising from list homomorphisms, and to understand what the best possible
algorithms are if we restrict the problem to bounded-treewidth graphs. For a
fixed $H$, the input of the optimization problem LHomVD($H$) is a graph $G$
with lists $L(v)$, and the task is to find a set $X$ of vertices having minimum
size such that $(G-X,L)$ has a list homomorphism to $H$. We define analogously
the edge-deletion variant LHomED($H$). This expressive family of problems
includes members that are essentially equivalent to fundamental problems such
as Vertex Cover, Max Cut, Odd Cycle Transversal, and Edge/Vertex Multiway Cut.
</p>
<p>For both variants, we first characterize those graphs $H$ that make the
problem polynomial-time solvable and show that the problem is NP-hard for every
other fixed $H$. Second, as our main result, we determine for every graph $H$
for which the problem is NP-hard, the smallest possible constant $c_H$ such
that the problem can be solved in time $c^t_H\cdot n^{O(1)}$ if a tree
decomposition of $G$ having width $t$ is given in the input, assuming the SETH.
Let $i(H)$ be the maximum size of a set of vertices in $H$ that have pairwise
incomparable neighborhoods. For the vertex-deletion variant LHomVD($H$), we
show that the smallest possible constant is $i(H)+1$ for every $H$.
</p>
<p>The situation is more complex for the edge-deletion version. For every $H$,
one can solve LHomED($H$) in time $i(H)^t\cdot n^{O(1)}$ if a tree
decomposition of width $t$ is given. However, the existence of a specific type
of decomposition of $H$ shows that there are graphs $H$ where LHomED($H$) can
be solved significantly more efficiently and the best possible constant can be
arbitrarily smaller than $i(H)$. Nevertheless, we determine this best possible
constant and (assuming the SETH) prove tight bounds for every fixed $H$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10172'>Simplex Range Searching Revisited: How to Shave Logs in Multi-Level Data Structures</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Timothy M. Chan, Da Wei Zheng</p><p>We revisit the classic problem of simplex range searching and related
problems in computational geometry. We present a collection of new results
which improve previous bounds by multiple logarithmic factors that were caused
by the use of multi-level data structures. Highlights include the following:
\begin{itemize} \item For a set of $n$ points in a constant dimension $d$, we
give data structures with $O(n^d)$ (or slightly better) space that can answer
simplex range counting queries in optimal $O(\log n)$ time and simplex range
reporting queries in optimal $O(\log n + k)$ time, where $k$ denotes the output
size. For semigroup range searching, we obtain $O(\log n)$ query time with
$O(n^d\mathop{\rm polylog}n)$ space. Previous data structures with similar
space bounds by Matou\v{s}ek from nearly three decades ago had $O(\log^{d+1}n)$
or $O(\log^{d+1}n + k)$ query time. \item For a set of $n$ simplices in a
constant dimension $d$, we give data structures with $O(n)$ space that can
answer stabbing counting queries (counting the number of simplices containing a
query point) in $O(n^{1-1/d})$ time, and stabbing reporting queries in
$O(n^{1-1/d}+k)$ time. Previous data structures had extra $\log^d n$ factors in
space and query time. \item For a set of $n$ (possibly intersecting) line
segments in 2D, we give a data structure with $O(n)$ space that can answer ray
shooting queries in $O(\sqrt{n})$ time. This improves Wang's recent data
structure [SoCG'20] with $O(n\log n)$ space and $O(\sqrt{n}\log n)$ query time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chan_T/0/1/0/all/0/1">Timothy M. Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1">Da Wei Zheng</a></p><p>We revisit the classic problem of simplex range searching and related
problems in computational geometry. We present a collection of new results
which improve previous bounds by multiple logarithmic factors that were caused
by the use of multi-level data structures. Highlights include the following:
\begin{itemize} \item For a set of $n$ points in a constant dimension $d$, we
give data structures with $O(n^d)$ (or slightly better) space that can answer
simplex range counting queries in optimal $O(\log n)$ time and simplex range
reporting queries in optimal $O(\log n + k)$ time, where $k$ denotes the output
size. For semigroup range searching, we obtain $O(\log n)$ query time with
$O(n^d\mathop{\rm polylog}n)$ space. Previous data structures with similar
space bounds by Matou\v{s}ek from nearly three decades ago had $O(\log^{d+1}n)$
or $O(\log^{d+1}n + k)$ query time. \item For a set of $n$ simplices in a
constant dimension $d$, we give data structures with $O(n)$ space that can
answer stabbing counting queries (counting the number of simplices containing a
query point) in $O(n^{1-1/d})$ time, and stabbing reporting queries in
$O(n^{1-1/d}+k)$ time. Previous data structures had extra $\log^d n$ factors in
space and query time. \item For a set of $n$ (possibly intersecting) line
segments in 2D, we give a data structure with $O(n)$ space that can answer ray
shooting queries in $O(\sqrt{n})$ time. This improves Wang's recent data
structure [SoCG'20] with $O(n\log n)$ space and $O(\sqrt{n}\log n)$ query time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10164'>Optimized Telecloning Circuits: Theory and Practice of Nine NISQ Clones</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Elijah Pelofske, Andreas B&#xe4;rtschi, Stephan Eidenbenz</p><p>Although perfect copying of an unknown quantum state is not possible,
approximate cloning is possible in quantum mechanics. Quantum telecloning is a
variant of approximate quantum cloning which uses quantum teleportation to
allow for the use of classical communication to create physically separate
clones of a quantum state. We present results of a of $1 \rightarrow 9$
universal, symmetric, optimal quantum telecloning implementation on a cloud
accessible quantum computer - the Quantinuum H1-1 device. The H1-1 device
allows direct creation of the telecloning protocol due to real time classical
if-statements that are conditional on the mid-circuit measurement outcome of a
Bell measurement. In this implementation, we also provide an improvement over
previous work for the circuit model description of quantum telecloning, which
reduces the required gate depth and gate count for an all-to-all connectivity.
The demonstration of creating $9$ approximate clones on a quantum processor is
the largest number of clones that has been generated, telecloning or otherwise.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Pelofske_E/0/1/0/all/0/1">Elijah Pelofske</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Bartschi_A/0/1/0/all/0/1">Andreas B&#xe4;rtschi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Eidenbenz_S/0/1/0/all/0/1">Stephan Eidenbenz</a></p><p>Although perfect copying of an unknown quantum state is not possible,
approximate cloning is possible in quantum mechanics. Quantum telecloning is a
variant of approximate quantum cloning which uses quantum teleportation to
allow for the use of classical communication to create physically separate
clones of a quantum state. We present results of a of $1 \rightarrow 9$
universal, symmetric, optimal quantum telecloning implementation on a cloud
accessible quantum computer - the Quantinuum H1-1 device. The H1-1 device
allows direct creation of the telecloning protocol due to real time classical
if-statements that are conditional on the mid-circuit measurement outcome of a
Bell measurement. In this implementation, we also provide an improvement over
previous work for the circuit model description of quantum telecloning, which
reduces the required gate depth and gate count for an all-to-all connectivity.
The demonstration of creating $9$ approximate clones on a quantum processor is
the largest number of clones that has been generated, telecloning or otherwise.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10173'>Faster Matrix Multiplication via Asymmetric Hashing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ran Duan, Hongxun Wu, Renfei Zhou</p><p>Fast matrix multiplication is one of the most fundamental problems in
algorithm research. The exponent of the optimal time complexity of matrix
multiplication is usually denoted by $\omega$. This paper discusses new ideas
for improving the laser method for fast matrix multiplication. We observe that
the analysis of higher powers of the Coppersmith-Winograd tensor [Coppersmith &amp;
Winograd 1990] incurs a "combination loss", and we partially compensate it by
using an asymmetric version of CW's hashing method. By analyzing the 8th power
of the CW tensor, we give a new bound of $\omega&lt;2.37188$, which improves the
previous best bound of $\omega&lt;2.37286$ [Alman &amp; V.Williams 2020]. Our result
breaks the lower bound of $2.3725$ in [Ambainis et al. 2014] because of the new
method for analyzing component (constituent) tensors.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Duan_R/0/1/0/all/0/1">Ran Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hongxun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1">Renfei Zhou</a></p><p>Fast matrix multiplication is one of the most fundamental problems in
algorithm research. The exponent of the optimal time complexity of matrix
multiplication is usually denoted by $\omega$. This paper discusses new ideas
for improving the laser method for fast matrix multiplication. We observe that
the analysis of higher powers of the Coppersmith-Winograd tensor [Coppersmith &amp;
Winograd 1990] incurs a "combination loss", and we partially compensate it by
using an asymmetric version of CW's hashing method. By analyzing the 8th power
of the CW tensor, we give a new bound of $\omega&lt;2.37188$, which improves the
previous best bound of $\omega&lt;2.37286$ [Alman &amp; V.Williams 2020]. Our result
breaks the lower bound of $2.3725$ in [Ambainis et al. 2014] because of the new
method for analyzing component (constituent) tensors.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10188'>On Hitting Times for General Quantum Markov Processes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lorenzo Laneve, Francesco Tacchino, Ivano Tavernelli</p><p>Random walks (or Markov chains) are models extensively used in theoretical
computer science. Several tools, including analysis of quantities such as
hitting and mixing times, are helpful for devising randomized algorithms. A
notable example is Sch\"oning's algorithm for the satisfiability (SAT) problem.
In this work, we use the density-matrix formalism to define a quantum Markov
chain model which directly generalizes classical walks, and we show that a
common tools such as hitting times can be computed with a similar formula as
the one found in the classical theory, which we then apply to known quantum
settings such as Grover's algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Laneve_L/0/1/0/all/0/1">Lorenzo Laneve</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tacchino_F/0/1/0/all/0/1">Francesco Tacchino</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tavernelli_I/0/1/0/all/0/1">Ivano Tavernelli</a></p><p>Random walks (or Markov chains) are models extensively used in theoretical
computer science. Several tools, including analysis of quantities such as
hitting and mixing times, are helpful for devising randomized algorithms. A
notable example is Sch\"oning's algorithm for the satisfiability (SAT) problem.
In this work, we use the density-matrix formalism to define a quantum Markov
chain model which directly generalizes classical walks, and we show that a
common tools such as hitting times can be computed with a similar formula as
the one found in the classical theory, which we then apply to known quantum
settings such as Grover's algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10370'>On the Perturbation Function of Ranking and Balance for Weighted Online Bipartite Matching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jingxun Liang, Zhihao Gavin Tang, Yixuan Xu, Yuhao Zhang, Renfei Zhou</p><p>Ranking and Balance are arguably the two most important algorithms in the
online matching literature. They achieve the same optimal competitive ratio of
$1-1/e$ for the integral version and fractional version of online bipartite
matching by Karp, Vazirani, and Vazirani (STOC 1990) respectively. The two
algorithms have been generalized to weighted online bipartite matching
problems, including vertex-weighted online bipartite matching and AdWords, by
utilizing a perturbation function. The canonical choice of the perturbation
function is $f(x)=1-e^{x-1}$ as it leads to the optimal competitive ratio of
$1-1/e$ in both settings.
</p>
<p>We advance the understanding of the weighted generalizations of Ranking and
Balance in this paper, with a focus on studying the effect of different
perturbation functions. First, we prove that the canonical perturbation
function is the \emph{unique} optimal perturbation function for vertex-weighted
online bipartite matching. In stark contrast, all perturbation functions
achieve the optimal competitive ratio of $1-1/e$ in the unweighted setting.
Second, we prove that the generalization of Ranking to AdWords with unknown
budgets using the canonical perturbation function is at most $0.624$
competitive, refuting a conjecture of Vazirani (2021). More generally, as an
application of the first result, we prove that no perturbation function leads
to the prominent competitive ratio of $1-1/e$ by establishing an upper bound of
$1-1/e-0.0003$.
</p>
<p>Finally, we propose the online budget-additive welfare maximization problem
that is intermediate between AdWords and AdWords with unknown budgets, and we
design an optimal $1-1/e$ competitive algorithm by generalizing Balance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jingxun Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhihao Gavin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yixuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1">Renfei Zhou</a></p><p>Ranking and Balance are arguably the two most important algorithms in the
online matching literature. They achieve the same optimal competitive ratio of
$1-1/e$ for the integral version and fractional version of online bipartite
matching by Karp, Vazirani, and Vazirani (STOC 1990) respectively. The two
algorithms have been generalized to weighted online bipartite matching
problems, including vertex-weighted online bipartite matching and AdWords, by
utilizing a perturbation function. The canonical choice of the perturbation
function is $f(x)=1-e^{x-1}$ as it leads to the optimal competitive ratio of
$1-1/e$ in both settings.
</p>
<p>We advance the understanding of the weighted generalizations of Ranking and
Balance in this paper, with a focus on studying the effect of different
perturbation functions. First, we prove that the canonical perturbation
function is the \emph{unique} optimal perturbation function for vertex-weighted
online bipartite matching. In stark contrast, all perturbation functions
achieve the optimal competitive ratio of $1-1/e$ in the unweighted setting.
Second, we prove that the generalization of Ranking to AdWords with unknown
budgets using the canonical perturbation function is at most $0.624$
competitive, refuting a conjecture of Vazirani (2021). More generally, as an
application of the first result, we prove that no perturbation function leads
to the prominent competitive ratio of $1-1/e$ by establishing an upper bound of
$1-1/e-0.0003$.
</p>
<p>Finally, we propose the online budget-additive welfare maximization problem
that is intermediate between AdWords and AdWords with unknown budgets, and we
design an optimal $1-1/e$ competitive algorithm by generalizing Balance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10394'>Near-optimal Coresets for Robust Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lingxiao Huang, Shaofeng H.-C. Jiang, Jianing Lou, Xuan Wu</p><p>We consider robust clustering problems in $\mathbb{R}^d$, specifically
$k$-clustering problems (e.g., $k$-Median and $k$-Means with $m$ outliers,
where the cost for a given center set $C \subset \mathbb{R}^d$ aggregates the
distances from $C$ to all but the furthest $m$ data points, instead of all
points as in classical clustering. We focus on the $\epsilon$-coreset for
robust clustering, a small proxy of the dataset that preserves the clustering
cost within $\epsilon$-relative error for all center sets. Our main result is
an $\epsilon$-coreset of size $O(m + \mathrm{poly}(k \epsilon^{-1}))$ that can
be constructed in near-linear time. This significantly improves previous
results, which either suffers an exponential dependence on $(m + k)$ [Feldman
and Schulman, SODA'12], or has a weaker bi-criteria guarantee [Huang et al.,
FOCS'18]. Furthermore, we show this dependence in $m$ is nearly-optimal, and
the fact that it is isolated from other factors may be crucial for dealing with
large number of outliers. We construct our coresets by adapting to the outlier
setting a recent framework [Braverman et al., FOCS'22] which was designed for
capacity-constrained clustering, overcoming a new challenge that the
participating terms in the cost, particularly the excluded $m$ outlier points,
are dependent on the center set $C$. We validate our coresets on various
datasets, and we observe a superior size-accuracy tradeoff compared with
popular baselines including uniform sampling and sensitivity sampling. We also
achieve a significant speedup of existing approximation algorithms for robust
clustering using our coresets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shaofeng H.-C. Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1">Jianing Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xuan Wu</a></p><p>We consider robust clustering problems in $\mathbb{R}^d$, specifically
$k$-clustering problems (e.g., $k$-Median and $k$-Means with $m$ outliers,
where the cost for a given center set $C \subset \mathbb{R}^d$ aggregates the
distances from $C$ to all but the furthest $m$ data points, instead of all
points as in classical clustering. We focus on the $\epsilon$-coreset for
robust clustering, a small proxy of the dataset that preserves the clustering
cost within $\epsilon$-relative error for all center sets. Our main result is
an $\epsilon$-coreset of size $O(m + \mathrm{poly}(k \epsilon^{-1}))$ that can
be constructed in near-linear time. This significantly improves previous
results, which either suffers an exponential dependence on $(m + k)$ [Feldman
and Schulman, SODA'12], or has a weaker bi-criteria guarantee [Huang et al.,
FOCS'18]. Furthermore, we show this dependence in $m$ is nearly-optimal, and
the fact that it is isolated from other factors may be crucial for dealing with
large number of outliers. We construct our coresets by adapting to the outlier
setting a recent framework [Braverman et al., FOCS'22] which was designed for
capacity-constrained clustering, overcoming a new challenge that the
participating terms in the cost, particularly the excluded $m$ outlier points,
are dependent on the center set $C$. We validate our coresets on various
datasets, and we observe a superior size-accuracy tradeoff compared with
popular baselines including uniform sampling and sensitivity sampling. We also
achieve a significant speedup of existing approximation algorithms for robust
clustering using our coresets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10583'>Community detection in edge-labeled graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Iiro Kumpulainen, Nikolaj Tatti</p><p>Finding dense communities in networks is a widely-used tool for analysis in
graph mining. A popular choice for finding such communities is to find
subgraphs with a high average degree. While useful, interpreting such subgraphs
may be difficult. On the other hand, many real-world networks have additional
information, and we are specifically interested in networks that have labels on
edges. In this paper, we study finding dense subgraphs that can be explained
with the labels on edges. More specifically, we are looking for a set of labels
so that the induced subgraph has a high average degree. There are many ways to
induce a subgraph from a set of labels, and we study two cases: First, we study
conjunctive-induced dense subgraphs, where the subgraph edges need to have all
labels. Secondly, we study disjunctive-induced dense subgraphs, where the
subgraph edges need to have at least one label. We show that both problems are
$\textbf{NP}$-hard. Because of the hardness, we resort to greedy heuristics. We
show that we can implement the greedy search efficiently: the respective
running times for finding conjunctive-induced and disjunctive-induced dense
subgraphs are in $\mathcal{O}(p \log k)$ and $\mathcal{O}(p \log^2 k)$, where
$p$ is the number of edge-label pairs and $k$ is the number of labels. Our
experimental evaluation demonstrates that we can find the ground truth in
synthetic graphs and that we can find interpretable subgraphs from real-world
networks.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kumpulainen_I/0/1/0/all/0/1">Iiro Kumpulainen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tatti_N/0/1/0/all/0/1">Nikolaj Tatti</a></p><p>Finding dense communities in networks is a widely-used tool for analysis in
graph mining. A popular choice for finding such communities is to find
subgraphs with a high average degree. While useful, interpreting such subgraphs
may be difficult. On the other hand, many real-world networks have additional
information, and we are specifically interested in networks that have labels on
edges. In this paper, we study finding dense subgraphs that can be explained
with the labels on edges. More specifically, we are looking for a set of labels
so that the induced subgraph has a high average degree. There are many ways to
induce a subgraph from a set of labels, and we study two cases: First, we study
conjunctive-induced dense subgraphs, where the subgraph edges need to have all
labels. Secondly, we study disjunctive-induced dense subgraphs, where the
subgraph edges need to have at least one label. We show that both problems are
$\textbf{NP}$-hard. Because of the hardness, we resort to greedy heuristics. We
show that we can implement the greedy search efficiently: the respective
running times for finding conjunctive-induced and disjunctive-induced dense
subgraphs are in $\mathcal{O}(p \log k)$ and $\mathcal{O}(p \log^2 k)$, where
$p$ is the number of edge-label pairs and $k$ is the number of labels. Our
experimental evaluation demonstrates that we can find the ground truth in
synthetic graphs and that we can find interpretable subgraphs from real-world
networks.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10662'>Towards Practical Explainability with Cluster Descriptors</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiaoyuan Liu, Ilya Tyagin, Hayato Ushijima-Mwesigwa, Indradeep Ghosh, Ilya Safro</p><p>With the rapid development of machine learning, improving its explainability
has become a crucial research goal. We study the problem of making the clusters
more explainable by investigating the cluster descriptors. Given a set of
objects $S$, a clustering of these objects $\pi$, and a set of tags $T$ that
have not participated in the clustering algorithm. Each object in $S$ is
associated with a subset of $T$. The goal is to find a representative set of
tags for each cluster, referred to as the cluster descriptors, with the
constraint that these descriptors we find are pairwise disjoint, and the total
size of all the descriptors is minimized. In general, this problem is NP-hard.
We propose a novel explainability model that reinforces the previous models in
such a way that tags that do not contribute to explainability and do not
sufficiently distinguish between clusters are not added to the optimal
descriptors. The proposed model is formulated as a quadratic unconstrained
binary optimization problem which makes it suitable for solving on modern
optimization hardware accelerators. We experimentally demonstrate how a
proposed explainability model can be solved on specialized hardware for
accelerating combinatorial optimization, the Fujitsu Digital Annealer, and use
real-life Twitter and PubMed datasets for use cases.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tyagin_I/0/1/0/all/0/1">Ilya Tyagin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ushijima_Mwesigwa_H/0/1/0/all/0/1">Hayato Ushijima-Mwesigwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_I/0/1/0/all/0/1">Indradeep Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Safro_I/0/1/0/all/0/1">Ilya Safro</a></p><p>With the rapid development of machine learning, improving its explainability
has become a crucial research goal. We study the problem of making the clusters
more explainable by investigating the cluster descriptors. Given a set of
objects $S$, a clustering of these objects $\pi$, and a set of tags $T$ that
have not participated in the clustering algorithm. Each object in $S$ is
associated with a subset of $T$. The goal is to find a representative set of
tags for each cluster, referred to as the cluster descriptors, with the
constraint that these descriptors we find are pairwise disjoint, and the total
size of all the descriptors is minimized. In general, this problem is NP-hard.
We propose a novel explainability model that reinforces the previous models in
such a way that tags that do not contribute to explainability and do not
sufficiently distinguish between clusters are not added to the optimal
descriptors. The proposed model is formulated as a quadratic unconstrained
binary optimization problem which makes it suitable for solving on modern
optimization hardware accelerators. We experimentally demonstrate how a
proposed explainability model can be solved on specialized hardware for
accelerating combinatorial optimization, the Fujitsu Digital Annealer, and use
real-life Twitter and PubMed datasets for use cases.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, October 19
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2022/10/19/james-davies-every-finite-colouring-of-the-plane-contains-a-monochromatic-pair-of-points-at-an-odd-distance-from-each-other/'>James Davies: Every finite colouring of the plane contains a monochromatic pair of points at an odd distance from each other.</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Here is a lovely piece of news: the following paper by James Davies was posted on the arXive a few weeks ago. The paper uses spectral methods to settle an old question, posed in 1994, by Moshe Rosenfeld. (See this &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Here is a lovely piece of news: the following paper by James Davies was posted on the arXive a few weeks ago. The paper uses spectral methods to settle an <strong>old question, posed in 1994, by Moshe Rosenfeld. </strong></p>
<p><strong>(</strong>See this <a href="https://gilkalai.wordpress.com/2009/02/21/rosenfelds-odd-distance-problem/">2009 post over here</a> and <a href="http://193.2.67.252/index.php/amc/article/view/25">this 2008 paper by Moshe</a>. Rosenfeld problem first appeared in print in a 1994 paper by Paul Erdos and<a href="https://asoifer.uccs.edu/"> Alexander Soifer</a> also wrote in several places about this problem.)</p>
<h3><a href="https://arxiv.org/abs/2209.15598">Odd distances in colorings of the plane</a></h3>
<p><strong>Theorem (Davies)</strong>:</p>
<blockquote><p><em>E</em><span id="2209.15598v2-abstract-short" class="abstract-short has-text-grey-dark mathjax"><em>very finite colouring of the plane contains a monochromatic pair of points at an odd (integral) distance from each other.</em></span></p></blockquote>
<p>The paper proves more general result and discover a new class of triangle free graphs with large chromatic number. Congratulations, James.</p>
<p><img data-attachment-id="23455" data-permalink="https://gilkalai.wordpress.com/2022/10/19/james-davies-every-finite-colouring-of-the-plane-contains-a-monochromatic-pair-of-points-at-an-odd-distance-from-each-other/soifer/" data-orig-file="https://gilkalai.files.wordpress.com/2022/10/soifer.jpg" data-orig-size="449,432" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-G986B&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1665136509&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.4&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.01&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="soifer" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/10/soifer.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/10/soifer.jpg?w=449" class="alignnone size-full wp-image-23455" src="https://gilkalai.files.wordpress.com/2022/10/soifer.jpg?w=640" alt="soifer" srcset="https://gilkalai.files.wordpress.com/2022/10/soifer.jpg 449w, https://gilkalai.files.wordpress.com/2022/10/soifer.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2022/10/soifer.jpg?w=300 300w" sizes="(max-width: 449px) 100vw, 449px"   /></p>
<p><span style="color:#ff0000;">Challenge: what is the smallest odd distance between a monochromatic pair in the Hoffman-Soifer coloring?</span></p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-19T12:17:10Z">Wednesday, October 19 2022, 12:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.09986'>Phase transition in the computational complexity of the shortest common superstring and genome assembly</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: L. A. Fernandez, V. Martin-Mayor, D. Yllanes</p><p>Genome assembly, the process of reconstructing a long genetic sequence by
aligning and merging short fragments, or reads, is known to be NP-hard, either
as a version of the shortest common superstring problem or in a
Hamiltonian-cycle formulation. That is, the computing time is believed to grow
exponentially with the the problem size in the worst case. Despite this fact,
high-throughput technologies and modern algorithms currently allow
bioinformaticians to produce and assemble datasets of billions of reads. Using
methods from statistical mechanics, we address this conundrum by demonstrating
the existence of a phase transition in the computational complexity of the
problem and showing that practical instances always fall in the `easy' phase
(solvable by polynomial-time algorithms). In addition, we propose a
Markov-chain Monte Carlo method that outperforms common deterministic
algorithms in the hard regime.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cond-mat/1/au:+Fernandez_L/0/1/0/all/0/1">L. A. Fernandez</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Martin_Mayor_V/0/1/0/all/0/1">V. Martin-Mayor</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Yllanes_D/0/1/0/all/0/1">D. Yllanes</a></p><p>Genome assembly, the process of reconstructing a long genetic sequence by
aligning and merging short fragments, or reads, is known to be NP-hard, either
as a version of the shortest common superstring problem or in a
Hamiltonian-cycle formulation. That is, the computing time is believed to grow
exponentially with the the problem size in the worst case. Despite this fact,
high-throughput technologies and modern algorithms currently allow
bioinformaticians to produce and assemble datasets of billions of reads. Using
methods from statistical mechanics, we address this conundrum by demonstrating
the existence of a phase transition in the computational complexity of the
problem and showing that practical instances always fall in the `easy' phase
(solvable by polynomial-time algorithms). In addition, we propose a
Markov-chain Monte Carlo method that outperforms common deterministic
algorithms in the hard regime.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-19T00:30:00Z">Wednesday, October 19 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.09899'>First Order Logic on Pathwidth Revisited Again</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Lampis</p><p>Courcelle's celebrated theorem states that all MSO-expressible properties can
be decided in linear time on graphs of bounded treewidth. Unfortunately, the
hidden constant implied by this theorem is a tower of exponentials whose height
increases with each quantifier alternation in the formula. More devastatingly,
this cannot be improved, under standard assumptions, even if we consider the
much more restricted problem of deciding FO-expressible properties on trees.
</p>
<p>In this paper we revisit this well-studied topic and identify a natural
special case where the dependence of Courcelle's theorem can, in fact, be
improved. Specifically, we show that all FO-expressible properties can be
decided with an elementary dependence on the input formula, if the input graph
has bounded pathwidth (rather than treewidth). This is a rare example of
treewidth and pathwidth having different complexity behaviors. Our result is
also in sharp contrast with MSO logic on graphs of bounded pathwidth, where it
is known that the dependence has to be non-elementary, under standard
assumptions. Our work builds upon, and generalizes, a corresponding
meta-theorem by Gajarsk{\'{y}} and Hlin{\v{e}}n{\'{y}} for the more restricted
class of graphs of bounded tree-depth.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lampis_M/0/1/0/all/0/1">Michael Lampis</a></p><p>Courcelle's celebrated theorem states that all MSO-expressible properties can
be decided in linear time on graphs of bounded treewidth. Unfortunately, the
hidden constant implied by this theorem is a tower of exponentials whose height
increases with each quantifier alternation in the formula. More devastatingly,
this cannot be improved, under standard assumptions, even if we consider the
much more restricted problem of deciding FO-expressible properties on trees.
</p>
<p>In this paper we revisit this well-studied topic and identify a natural
special case where the dependence of Courcelle's theorem can, in fact, be
improved. Specifically, we show that all FO-expressible properties can be
decided with an elementary dependence on the input formula, if the input graph
has bounded pathwidth (rather than treewidth). This is a rare example of
treewidth and pathwidth having different complexity behaviors. Our result is
also in sharp contrast with MSO logic on graphs of bounded pathwidth, where it
is known that the dependence has to be non-elementary, under standard
assumptions. Our work builds upon, and generalizes, a corresponding
meta-theorem by Gajarsk{\'{y}} and Hlin{\v{e}}n{\'{y}} for the more restricted
class of graphs of bounded tree-depth.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-19T00:30:00Z">Wednesday, October 19 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.09640'>Clustering Categorical Data: Soft Rounding k-modes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Surya Teja Gavva, Karthik C. S., Sharath Punna</p><p>Over the last three decades, researchers have intensively explored various
clustering tools for categorical data analysis. Despite the proposal of various
clustering algorithms, the classical k-modes algorithm remains a popular choice
for unsupervised learning of categorical data. Surprisingly, our first insight
is that in a natural generative block model, the k-modes algorithm performs
poorly for a large range of parameters. We remedy this issue by proposing a
soft rounding variant of the k-modes algorithm (SoftModes) and theoretically
prove that our variant addresses the drawbacks of the k-modes algorithm in the
generative model. Finally, we empirically verify that SoftModes performs well
on both synthetic and real-world datasets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gavva_S/0/1/0/all/0/1">Surya Teja Gavva</a>, <a href="http://arxiv.org/find/cs/1/au:+S%2E_K/0/1/0/all/0/1">Karthik C. S.</a>, <a href="http://arxiv.org/find/cs/1/au:+Punna_S/0/1/0/all/0/1">Sharath Punna</a></p><p>Over the last three decades, researchers have intensively explored various
clustering tools for categorical data analysis. Despite the proposal of various
clustering algorithms, the classical k-modes algorithm remains a popular choice
for unsupervised learning of categorical data. Surprisingly, our first insight
is that in a natural generative block model, the k-modes algorithm performs
poorly for a large range of parameters. We remedy this issue by proposing a
soft rounding variant of the k-modes algorithm (SoftModes) and theoretically
prove that our variant addresses the drawbacks of the k-modes algorithm in the
generative model. Finally, we empirically verify that SoftModes performs well
on both synthetic and real-world datasets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-19T00:30:00Z">Wednesday, October 19 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.09806'>Capacitated Vehicle Routing in Graphic Metrics</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tobias M&#xf6;mke, Hang Zhou</p><p>We study the capacitated vehicle routing problem in graphic metrics (graphic
CVRP). Our main contribution is a new lower bound on the cost of an optimal
solution. For graphic metrics, this lower bound is tight and significantly
stronger than the well-known bound for general metrics. The proof of the new
lower bound is simple and combinatorial. Using this lower bound, we analyze the
approximation ratio of the classical iterated tour partitioning algorithm
combined with the TSP algorithms for graphic metrics of Christofides [1976], of
M\"omke-Svensson [JACM 2016], and of Seb\H{o}-Vygen [Combinatorica 2014]. In
particular, we obtain a 1.95-approximation for the graphic CVRP.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Momke_T/0/1/0/all/0/1">Tobias M&#xf6;mke</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hang Zhou</a></p><p>We study the capacitated vehicle routing problem in graphic metrics (graphic
CVRP). Our main contribution is a new lower bound on the cost of an optimal
solution. For graphic metrics, this lower bound is tight and significantly
stronger than the well-known bound for general metrics. The proof of the new
lower bound is simple and combinatorial. Using this lower bound, we analyze the
approximation ratio of the classical iterated tour partitioning algorithm
combined with the TSP algorithms for graphic metrics of Christofides [1976], of
M\"omke-Svensson [JACM 2016], and of Seb\H{o}-Vygen [Combinatorica 2014]. In
particular, we obtain a 1.95-approximation for the graphic CVRP.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-19T00:30:00Z">Wednesday, October 19 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.09844'>Performance evaluation of approximation algorithms for the minimum size 2-vertex strongly connected subgraph problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Azzam Habib</p><p>Jaberi [7] presented approximation algorithms for the problem of computing a
minimum size 2-vertex strongly biconnected subgraph in directed graphs. We have
implemented approximation algorithms presented in [7] and we have tested the
implementation on some graphs. The experimental results show that these
algorithms work well in practice.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Habib_A/0/1/0/all/0/1">Azzam Habib</a></p><p>Jaberi [7] presented approximation algorithms for the problem of computing a
minimum size 2-vertex strongly biconnected subgraph in directed graphs. We have
implemented approximation algorithms presented in [7] and we have tested the
implementation on some graphs. The experimental results show that these
algorithms work well in practice.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-19T00:30:00Z">Wednesday, October 19 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.09914'>Computing MEMs on Repetitive Text Collections</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gonzalo Navarro</p><p>We consider the problem of computing the Maximal Exact Matches (MEMs) of a
given pattern $P[1..m]$ on a large repetitive text collection $T[1..n]$, which
is represented as a (hopefully much smaller) run-length context-free grammar of
size $g_{rl}$. We show that the problem can be solved in time $O(m^2
\log^\epsilon n)$, for any constant $\epsilon &gt; 0$, on a data structure of size
$O(g_{rl})$. Further, on a locally consistent grammar of size
$O(\delta\log\frac{n}{\delta})$, the time decreases to $O(m\log m(\log m +
\log^\epsilon n))$. The value $\delta$ is a function of the substring
complexity of $T$ and $\Omega(\delta\log\frac{n}{\delta})$ is a tight lower
bound on the compressibility of repetitive texts $T$, so our structure has
optimal size in terms of $n$ and $\delta$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Navarro_G/0/1/0/all/0/1">Gonzalo Navarro</a></p><p>We consider the problem of computing the Maximal Exact Matches (MEMs) of a
given pattern $P[1..m]$ on a large repetitive text collection $T[1..n]$, which
is represented as a (hopefully much smaller) run-length context-free grammar of
size $g_{rl}$. We show that the problem can be solved in time $O(m^2
\log^\epsilon n)$, for any constant $\epsilon &gt; 0$, on a data structure of size
$O(g_{rl})$. Further, on a locally consistent grammar of size
$O(\delta\log\frac{n}{\delta})$, the time decreases to $O(m\log m(\log m +
\log^\epsilon n))$. The value $\delta$ is a function of the substring
complexity of $T$ and $\Omega(\delta\log\frac{n}{\delta})$ is a tight lower
bound on the compressibility of repetitive texts $T$, so our structure has
optimal size in terms of $n$ and $\delta$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-19T00:30:00Z">Wednesday, October 19 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.09949'>SQ Lower Bounds for Learning Single Neurons with Massart Noise</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ilias Diakonikolas, Daniel M. Kane, Lisheng Ren, Yuxin Sun</p><p>We study the problem of PAC learning a single neuron in the presence of
Massart noise. Specifically, for a known activation function $f: \mathbb{R} \to
\mathbb{R}$, the learner is given access to labeled examples $(\mathbf{x}, y)
\in \mathbb{R}^d \times \mathbb{R}$, where the marginal distribution of
$\mathbf{x}$ is arbitrary and the corresponding label $y$ is a Massart
corruption of $f(\langle \mathbf{w}, \mathbf{x} \rangle)$. The goal of the
learner is to output a hypothesis $h: \mathbb{R}^d \to \mathbb{R}$ with small
squared loss. For a range of activation functions, including ReLUs, we
establish super-polynomial Statistical Query (SQ) lower bounds for this
learning problem. In more detail, we prove that no efficient SQ algorithm can
approximate the optimal error within any constant factor. Our main technical
contribution is a novel SQ-hard construction for learning $\{ \pm 1\}$-weight
Massart halfspaces on the Boolean hypercube that is interesting on its own
right.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1">Ilias Diakonikolas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1">Daniel M. Kane</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_L/0/1/0/all/0/1">Lisheng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuxin Sun</a></p><p>We study the problem of PAC learning a single neuron in the presence of
Massart noise. Specifically, for a known activation function $f: \mathbb{R} \to
\mathbb{R}$, the learner is given access to labeled examples $(\mathbf{x}, y)
\in \mathbb{R}^d \times \mathbb{R}$, where the marginal distribution of
$\mathbf{x}$ is arbitrary and the corresponding label $y$ is a Massart
corruption of $f(\langle \mathbf{w}, \mathbf{x} \rangle)$. The goal of the
learner is to output a hypothesis $h: \mathbb{R}^d \to \mathbb{R}$ with small
squared loss. For a range of activation functions, including ReLUs, we
establish super-polynomial Statistical Query (SQ) lower bounds for this
learning problem. In more detail, we prove that no efficient SQ algorithm can
approximate the optimal error within any constant factor. Our main technical
contribution is a novel SQ-hard construction for learning $\{ \pm 1\}$-weight
Massart halfspaces on the Boolean hypercube that is interesting on its own
right.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-19T00:30:00Z">Wednesday, October 19 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, October 18
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/18/tenure-track-faculty-at-northwestern-university-apply-by-december-10-2022/'>Tenure-track Faculty at Northwestern University (apply by December 10, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We invite candidates to apply for new positions as Assistant, Associate and Full Professor of Computer Science. We are interested in applications from outstanding candidates in all areas of Computer Science. The department is especially interested in the areas of quantum computing, complexity theory, parallel systems, global-scale networked systems as critical infrastructure, and machine learning. [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We invite candidates to apply for new positions as Assistant, Associate and Full Professor of Computer Science. We are interested in applications from outstanding candidates in all areas of Computer Science. The department is especially interested in the areas of quantum computing, complexity theory, parallel systems, global-scale networked systems as critical infrastructure, and machine learning.</p>
<p>Website: <a href="https://www.mccormick.northwestern.edu/computer-science/careers/">https://www.mccormick.northwestern.edu/computer-science/careers/</a><br />
Email: apply-facsearch@cs.northwestern.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-18T22:22:27Z">Tuesday, October 18 2022, 22:22</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/18/open-rank-faculty-at-utsa-apply-by-november-11-2022/'>Open Rank Faculty at UTSA (apply by November 11, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This is an open rank faculty search in algebraic and arithmetic algorithms, coding theory, and cryptography. The position is intended to be joint between Computer Science and Mathematics. There is preference to applicants with crypto track record due to funding source, but it is not a strict preference. Website: www.mathjobs.org/jobs/list/21044 Email: eduardo.duenez@utsa.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>This is an open rank faculty search in algebraic and arithmetic algorithms, coding theory, and cryptography. The position is intended to be joint between Computer Science and Mathematics. There is preference to applicants with crypto track record due to funding source, but it is not a strict preference.</p>
<p>Website: <a href="https://www.mathjobs.org/jobs/list/21044">https://www.mathjobs.org/jobs/list/21044</a><br />
Email: eduardo.duenez@utsa.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-18T20:55:37Z">Tuesday, October 18 2022, 20:55</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/18/faculty-at-stanford-apply-by-december-5-2022/'>Faculty at Stanford (apply by December 5, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Stanford Data Science and the School of Engineering (SoE) at Stanford University invite applications for a tenure-track appointment at the assistant professor or untenured associate professor level in SoE. We welcome candidates engaged in all aspects of data science and its applications. The primary departmental home of the appointee will be in one of the [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Stanford Data Science and the School of Engineering (SoE) at Stanford University invite applications for a tenure-track appointment at the assistant professor or untenured associate professor level in SoE. We welcome candidates engaged in all aspects of data science and its applications. The primary departmental home of the appointee will be in one of the departments in SoE.</p>
<p>Website: <a href="https://facultypositions.stanford.edu/en-us/listing/">https://facultypositions.stanford.edu/en-us/listing/</a><br />
Email: search@ee.stanford.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-18T16:30:33Z">Tuesday, October 18 2022, 16:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/10/byte-lynx-awesome-video-gameam-i.html'>BYTE LYNX- an awesome video game/Am I an influencer?</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p><br></p><p>Tucker Bane is a friend of mine who has an AWESOME video game available</p><p>that is called BYTE LYNX.</p><p>I am curious- Can I be an INFLUENCER!</p><p>Lets find out!</p><p><br></p><p>At the link below there are</p><p><br></p><p>a) Reviews of the game.</p><p>b) Videos of the game being played.</p><p>c) The ability to purchase and download the game.</p><p><br></p><p>Link is&nbsp;here</p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><br /></p><p>Tucker Bane is a friend of mine who has an AWESOME video game available</p><p>that is called BYTE LYNX.</p><p>I am curious- Can I be an INFLUENCER!</p><p>Lets find out!</p><p><br /></p><p>At the link below there are</p><p><br /></p><p>a) Reviews of the game.</p><p>b) Videos of the game being played.</p><p>c) The ability to purchase and download the game.</p><p><br /></p><p>Link is&nbsp;<a href="https://store.steampowered.com/app/1996600/Byte_Lynx/">here</a></p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-18T06:02:00Z">Tuesday, October 18 2022, 06:02</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.08293'>Approximate Graph Colouring and Crystals</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lorenzo Ciardo, Stanislav &#x17d;ivn&#xfd;</p><p>We show that approximate graph colouring is not solved by any level of the
affine integer programming (AIP) hierarchy. To establish the result, we
translate the problem of exhibiting a graph fooling a level of the AIP
hierarchy into the problem of constructing a highly symmetric crystal tensor.
In order to prove the existence of crystals in arbitrary dimension, we provide
a combinatorial characterisation for realisable systems of tensors; i.e., sets
of low-dimensional tensors that can be realised as the projections of a single
high-dimensional tensor.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ciardo_L/0/1/0/all/0/1">Lorenzo Ciardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zivny_S/0/1/0/all/0/1">Stanislav &#x17d;ivn&#xfd;</a></p><p>We show that approximate graph colouring is not solved by any level of the
affine integer programming (AIP) hierarchy. To establish the result, we
translate the problem of exhibiting a graph fooling a level of the AIP
hierarchy into the problem of constructing a highly symmetric crystal tensor.
In order to prove the existence of crystals in arbitrary dimension, we provide
a combinatorial characterisation for realisable systems of tensors; i.e., sets
of low-dimensional tensors that can be realised as the projections of a single
high-dimensional tensor.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-18T00:30:00Z">Tuesday, October 18 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.08300'>On depth-3 circuits and covering number: an explicit counter-example</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lianna Hambardzumyan, Hamed Hatami, Ndiam&#xe9; Ndiaye</p><p>We give a simple construction of $n\times n$ Boolean matrices with
$\Omega(n^{4/3})$ zero entries that are free of $2 \times 2$ all-zero
submatrices and have covering number $O(\log^4(n))$. This construction provides
an explicit counterexample to a conjecture of Pudl\'{a}k, R\"{o}dl and
Savick\'{y} and Research Problems 1.33, 4.9, 11.17 of Jukna [Boolean function
complexity]. These conjectures were previously refuted by Katz using a
probabilistic construction.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hambardzumyan_L/0/1/0/all/0/1">Lianna Hambardzumyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hatami_H/0/1/0/all/0/1">Hamed Hatami</a>, <a href="http://arxiv.org/find/cs/1/au:+Ndiaye_N/0/1/0/all/0/1">Ndiam&#xe9; Ndiaye</a></p><p>We give a simple construction of $n\times n$ Boolean matrices with
$\Omega(n^{4/3})$ zero entries that are free of $2 \times 2$ all-zero
submatrices and have covering number $O(\log^4(n))$. This construction provides
an explicit counterexample to a conjecture of Pudl\'{a}k, R\"{o}dl and
Savick\'{y} and Research Problems 1.33, 4.9, 11.17 of Jukna [Boolean function
complexity]. These conjectures were previously refuted by Katz using a
probabilistic construction.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-18T00:30:00Z">Tuesday, October 18 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.08312'>Disordered Systems Insights on Computational Hardness</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David Gamarnik, Cristopher Moore, Lenka Zdeborov&#xe1;</p><p>In this review article, we discuss connections between the physics of
disordered systems, phase transitions in inference problems, and computational
hardness. We introduce two models representing the behavior of glassy systems,
the spiked tensor model and the generalized linear model. We discuss the random
(non-planted) versions of these problems as prototypical optimization problems,
as well as the planted versions (with a hidden solution) as prototypical
problems in statistical inference and learning. Based on ideas from physics,
many of these problems have transitions where they are believed to jump from
easy (solvable in polynomial time) to hard (requiring exponential time). We
discuss several emerging ideas in theoretical computer science and statistics
that provide rigorous evidence for hardness by proving that large classes of
algorithms fail in the conjectured hard regime. This includes the overlap gap
property, a particular mathematization of clustering or dynamical
symmetry-breaking, which can be used to show that many algorithms that are
local or robust to changes in their input fail. We also discuss the
sum-of-squares hierarchy, which places bounds on proofs or algorithms that use
low-degree polynomials such as standard spectral methods and semidefinite
relaxations, including the Sherrington-Kirkpatrick model. Throughout the
manuscript, we present connections to the physics of disordered systems and
associated replica symmetry breaking properties.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cond-mat/1/au:+Gamarnik_D/0/1/0/all/0/1">David Gamarnik</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Moore_C/0/1/0/all/0/1">Cristopher Moore</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Zdeborova_L/0/1/0/all/0/1">Lenka Zdeborov&#xe1;</a></p><p>In this review article, we discuss connections between the physics of
disordered systems, phase transitions in inference problems, and computational
hardness. We introduce two models representing the behavior of glassy systems,
the spiked tensor model and the generalized linear model. We discuss the random
(non-planted) versions of these problems as prototypical optimization problems,
as well as the planted versions (with a hidden solution) as prototypical
problems in statistical inference and learning. Based on ideas from physics,
many of these problems have transitions where they are believed to jump from
easy (solvable in polynomial time) to hard (requiring exponential time). We
discuss several emerging ideas in theoretical computer science and statistics
that provide rigorous evidence for hardness by proving that large classes of
algorithms fail in the conjectured hard regime. This includes the overlap gap
property, a particular mathematization of clustering or dynamical
symmetry-breaking, which can be used to show that many algorithms that are
local or robust to changes in their input fail. We also discuss the
sum-of-squares hierarchy, which places bounds on proofs or algorithms that use
low-degree polynomials such as standard spectral methods and semidefinite
relaxations, including the Sherrington-Kirkpatrick model. Throughout the
manuscript, we present connections to the physics of disordered systems and
associated replica symmetry breaking properties.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-18T00:30:00Z">Tuesday, October 18 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.08104'>Gibbs Sampling of Periodic Potentials on a Quantum Computer</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arsalan Motamedi, Pooya Ronagh</p><p>Motivated by applications in machine learning, we present a quantum algorithm
for Gibbs sampling from a continuous real-valued function defined on a high
dimensional torus. Our algorithm relies on techniques for solving linear
systems and partial differential equations and performs zeroeth order queries
to a quantum oracle computing the energy function. We then analyze the query
and gate complexity of our algorithm and prove that the algorithm has a
polylogarithmic dependence on approximation error (in total variation distance)
and a polynomial dependence on the number of variables, although it suffers
from an exponentially poor dependence on temperature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Motamedi_A/0/1/0/all/0/1">Arsalan Motamedi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ronagh_P/0/1/0/all/0/1">Pooya Ronagh</a></p><p>Motivated by applications in machine learning, we present a quantum algorithm
for Gibbs sampling from a continuous real-valued function defined on a high
dimensional torus. Our algorithm relies on techniques for solving linear
systems and partial differential equations and performs zeroeth order queries
to a quantum oracle computing the energy function. We then analyze the query
and gate complexity of our algorithm and prove that the algorithm has a
polylogarithmic dependence on approximation error (in total variation distance)
and a polynomial dependence on the number of variables, although it suffers
from an exponentially poor dependence on temperature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-18T00:30:00Z">Tuesday, October 18 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, October 17
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/17/assistant-professor-at-massachusetts-institute-of-technology-apply-by-december-15-2022/'>Assistant Professor  at Massachusetts Institute of Technology (apply by December 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Mathematics Department at the Massachusetts Institute of Technology (MIT) together with the MIT Schwarzman College of Computing (SCC) is seeking to fill one position in Theoretical Aspects of Quantum Computing at the level of tenure-track Assistant Professor beginning July 1, 2023 (for the 2023-2024 academic year, or as soon thereafter as possible). Website: www.mathjobs.org/jobs/list/20993 [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Mathematics Department at the Massachusetts Institute of Technology (MIT) together with the MIT Schwarzman College of Computing (SCC) is seeking to fill one position in Theoretical Aspects of Quantum Computing at the level of tenure-track Assistant Professor beginning July 1, 2023 (for the 2023-2024 academic year, or as soon thereafter as possible).</p>
<p>Website: <a href="https://www.mathjobs.org/jobs/list/20993">https://www.mathjobs.org/jobs/list/20993</a><br />
Email: akuhl@mit.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-17T18:01:45Z">Monday, October 17 2022, 18:01</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/17/faculty-at-university-of-memphis-apply-by-november-28-2022/'>Faculty at University of Memphis (apply by November 28, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Department of Computer Science at the University of Memphis is seeking candidates for Assistant Professor position(s) beginning Fall 2023. Qualified candidates in all areas of computer science are invited, while candidates with core expertise in emerging areas of systems, software engineering, theory, and cybersecurity are particularly encouraged to apply. Website: workforum.memphis.edu/postings/33990 Email: cconnor2@memphis.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Department of Computer Science at the University of Memphis is seeking candidates for Assistant Professor position(s) beginning Fall 2023. Qualified candidates in all areas of computer science are invited, while candidates with core expertise in emerging areas of systems, software engineering, theory, and cybersecurity are particularly encouraged to apply.</p>
<p>Website: <a href="https://workforum.memphis.edu/postings/33990">https://workforum.memphis.edu/postings/33990</a><br />
Email: cconnor2@memphis.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-17T15:07:15Z">Monday, October 17 2022, 15:07</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.07383'>Notes on CSPs and Polymorphisms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zarathustra Brady</p><p>These are notes from a multi-year learning seminar on the algebraic approach
to Constraint Satisfaction Problems (CSPs). The main topics covered are the
theory of algebraic structures with few subpowers, the theory of absorbing
subalgebras and its applications to studying CSP templates which can be solved
by local consistency methods, and the dichotomy theorem for conservative CSP
templates. Subsections and appendices cover supplementary material.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Brady_Z/0/1/0/all/0/1">Zarathustra Brady</a></p><p>These are notes from a multi-year learning seminar on the algebraic approach
to Constraint Satisfaction Problems (CSPs). The main topics covered are the
theory of algebraic structures with few subpowers, the theory of absorbing
subalgebras and its applications to studying CSP templates which can be solved
by local consistency methods, and the dichotomy theorem for conservative CSP
templates. Subsections and appendices cover supplementary material.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.07754'>Zero-Rate Thresholds and New Capacity Bounds for List-Decoding and List-Recovery</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicolas Resch, Chen Yuan, Yihan Zhang</p><p>In this work we consider the list-decodability and list-recoverability of
arbitrary $q$-ary codes, for all integer values of $q\geq 2$. A code is called
$(p,L)_q$-list-decodable if every radius $pn$ Hamming ball contains less than
$L$ codewords; $(p,\ell,L)_q$-list-recoverability is a generalization where we
place radius $pn$ Hamming balls on every point of a combinatorial rectangle
with side length $\ell$ and again stipulate that there be less than $L$
codewords.
</p>
<p>Our main contribution is to precisely calculate the maximum value of $p$ for
which there exist infinite families of positive rate
$(p,\ell,L)_q$-list-recoverable codes, the quantity we call the zero-rate
threshold. Denoting this value by $p_*$, we in fact show that codes correcting
a $p_*+\varepsilon$ fraction of errors must have size $O_{\varepsilon}(1)$,
i.e., independent of $n$. Such a result is typically referred to as a ``Plotkin
bound.'' To complement this, a standard random code with expurgation
construction shows that there exist positive rate codes correcting a
$p_*-\varepsilon$ fraction of errors. We also follow a classical proof template
(typically attributed to Elias and Bassalygo) to derive from the zero-rate
threshold other tradeoffs between rate and decoding radius for list-decoding
and list-recovery.
</p>
<p>Technically, proving the Plotkin bound boils down to demonstrating the Schur
convexity of a certain function defined on the $q$-simplex as well as the
convexity of a univariate function derived from it. We remark that an earlier
argument claimed similar results for $q$-ary list-decoding; however, we point
out that this earlier proof is flawed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Resch_N/0/1/0/all/0/1">Nicolas Resch</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_C/0/1/0/all/0/1">Chen Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yihan Zhang</a></p><p>In this work we consider the list-decodability and list-recoverability of
arbitrary $q$-ary codes, for all integer values of $q\geq 2$. A code is called
$(p,L)_q$-list-decodable if every radius $pn$ Hamming ball contains less than
$L$ codewords; $(p,\ell,L)_q$-list-recoverability is a generalization where we
place radius $pn$ Hamming balls on every point of a combinatorial rectangle
with side length $\ell$ and again stipulate that there be less than $L$
codewords.
</p>
<p>Our main contribution is to precisely calculate the maximum value of $p$ for
which there exist infinite families of positive rate
$(p,\ell,L)_q$-list-recoverable codes, the quantity we call the zero-rate
threshold. Denoting this value by $p_*$, we in fact show that codes correcting
a $p_*+\varepsilon$ fraction of errors must have size $O_{\varepsilon}(1)$,
i.e., independent of $n$. Such a result is typically referred to as a ``Plotkin
bound.'' To complement this, a standard random code with expurgation
construction shows that there exist positive rate codes correcting a
$p_*-\varepsilon$ fraction of errors. We also follow a classical proof template
(typically attributed to Elias and Bassalygo) to derive from the zero-rate
threshold other tradeoffs between rate and decoding radius for list-decoding
and list-recovery.
</p>
<p>Technically, proving the Plotkin bound boils down to demonstrating the Schur
convexity of a certain function defined on the $q$-simplex as well as the
convexity of a univariate function derived from it. We remark that an earlier
argument claimed similar results for $q$-ary list-decoding; however, we point
out that this earlier proof is flawed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.07545'>Hypergraphs for multiscale cycles in structured data</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Agnese Barbensi, Hee Rhang Yoon, Christian Degnbol Madsen, Deborah O. Ajayi, Michael P.H. Stumpf, Heather A. Harrington</p><p>Scientific data has been growing in both size and complexity across the
modern physical, engineering, life and social sciences. Spatial structure, for
example, is a hallmark of many of the most important real-world complex
systems, but its analysis is fraught with statistical challenges. Topological
data analysis can provide a powerful computational window on complex systems.
Here we present a framework to extend and interpret persistent homology
summaries to analyse spatial data across multiple scales. We introduce
hyperTDA, a topological pipeline that unifies local (e.g. geodesic) and global
(e.g. Euclidean) metrics without losing spatial information, even in the
presence of noise. Homology generators offer an elegant and flexible
description of spatial structures and can capture the information computed by
persistent homology in an interpretable way. Here the information computed by
persistent homology is transformed into a weighted hypergraph, where hyperedges
correspond to homology generators. We consider different choices of generators
(e.g. matroid or minimal) and find that centrality and community detection are
robust to either choice. We compare hyperTDA to existing geometric measures and
validate its robustness to noise. We demonstrate the power of computing
higher-order topological structures on spatial curves arising frequently in
ecology, biophysics, and biology, but also in high-dimensional financial
datasets. We find that hyperTDA can select between synthetic trajectories from
the landmark 2020 AnDi challenge and quantifies movements of different animal
species, even when data is limited.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Barbensi_A/0/1/0/all/0/1">Agnese Barbensi</a>, <a href="http://arxiv.org/find/math/1/au:+Yoon_H/0/1/0/all/0/1">Hee Rhang Yoon</a>, <a href="http://arxiv.org/find/math/1/au:+Madsen_C/0/1/0/all/0/1">Christian Degnbol Madsen</a>, <a href="http://arxiv.org/find/math/1/au:+Ajayi_D/0/1/0/all/0/1">Deborah O. Ajayi</a>, <a href="http://arxiv.org/find/math/1/au:+Stumpf_M/0/1/0/all/0/1">Michael P.H. Stumpf</a>, <a href="http://arxiv.org/find/math/1/au:+Harrington_H/0/1/0/all/0/1">Heather A. Harrington</a></p><p>Scientific data has been growing in both size and complexity across the
modern physical, engineering, life and social sciences. Spatial structure, for
example, is a hallmark of many of the most important real-world complex
systems, but its analysis is fraught with statistical challenges. Topological
data analysis can provide a powerful computational window on complex systems.
Here we present a framework to extend and interpret persistent homology
summaries to analyse spatial data across multiple scales. We introduce
hyperTDA, a topological pipeline that unifies local (e.g. geodesic) and global
(e.g. Euclidean) metrics without losing spatial information, even in the
presence of noise. Homology generators offer an elegant and flexible
description of spatial structures and can capture the information computed by
persistent homology in an interpretable way. Here the information computed by
persistent homology is transformed into a weighted hypergraph, where hyperedges
correspond to homology generators. We consider different choices of generators
(e.g. matroid or minimal) and find that centrality and community detection are
robust to either choice. We compare hyperTDA to existing geometric measures and
validate its robustness to noise. We demonstrate the power of computing
higher-order topological structures on spatial curves arising frequently in
ecology, biophysics, and biology, but also in high-dimensional financial
datasets. We find that hyperTDA can select between synthetic trajectories from
the landmark 2020 AnDi challenge and quantifies movements of different animal
species, even when data is limited.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.07838'>Fields2Cover: An open-source coverage path planning library for unmanned agricultural vehicles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gonzalo Mier, Jo&#xe3;o Valente, Sytze de Bruin</p><p>This paper describes Fields2Cover, a novel open source library for coverage
path planning (CPP) for agricultural vehicles. While there are several CPP
solutions nowadays, there have been limited efforts to unify them into an open
source library and provide benchmarking tools to compare their performance.
Fields2Cover provides a framework for planning coverage paths, developing novel
techniques, and benchmarking state-of-the-art algorithms. The library features
a modular and extensible architecture that supports various vehicles and can be
used for a variety of applications, including farms. Its core modules are: a
headland generator, a swath generator, a route planner and a path planner. An
interface to the Robot Operating System (ROS) is also supplied as an add-on. In
this paper, the functionalities of the library for planning a coverage path in
agriculture are demonstrated using 8 state-of-the-art methods and 7 objective
functions in simulation and field experiments.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mier_G/0/1/0/all/0/1">Gonzalo Mier</a>, <a href="http://arxiv.org/find/cs/1/au:+Valente_J/0/1/0/all/0/1">Jo&#xe3;o Valente</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruin_S/0/1/0/all/0/1">Sytze de Bruin</a></p><p>This paper describes Fields2Cover, a novel open source library for coverage
path planning (CPP) for agricultural vehicles. While there are several CPP
solutions nowadays, there have been limited efforts to unify them into an open
source library and provide benchmarking tools to compare their performance.
Fields2Cover provides a framework for planning coverage paths, developing novel
techniques, and benchmarking state-of-the-art algorithms. The library features
a modular and extensible architecture that supports various vehicles and can be
used for a variety of applications, including farms. Its core modules are: a
headland generator, a swath generator, a route planner and a path planner. An
interface to the Robot Operating System (ROS) is also supplied as an add-on. In
this paper, the functionalities of the library for planning a coverage path in
agriculture are demonstrated using 8 state-of-the-art methods and 7 objective
functions in simulation and field experiments.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.07534'>Time-Space Tradeoffs for Element Distinctness and Set Intersection via Pseudorandomness</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xin Lyu, Weihao Zhu</p><p>In the Element Distinctness problem, one is given an array $a_1,\dots, a_n$
of integers from $[poly(n)]$ and is tasked to decide if $\{a_i\}$ are mutually
distinct. Beame, Clifford and Machmouchi (FOCS 2013) gave a low-space algorithm
for this problem running in space $S(n)$ and time $T(n)$ where $T(n) \le
\widetilde{O}(n^{3/2}/S(n)^{1/2})$, assuming a random oracle (i.e., random
access to polynomially many random bits). A recent breakthrough by Chen, Jin,
Williams and Wu (SODA 2022) showed how to remove the random oracle assumption
in the regime $S(n) = polylog(n)$ and $T(n) = \widetilde{O}(n^{3/2})$. They
designed the first truly $polylog(n)$-space, $\widetilde{O}(n^{3/2})$-time
algorithm by constructing a small family of hash functions $\mathcal{H}
\subseteq \{h | h:[poly(n)]\to [n]\}$ with a certain pseudorandom property.
</p>
<p>In this paper, we give a significantly simplified analysis of the
pseudorandom hash family by Chen et al. Our analysis clearly identifies the key
pseudorandom property required to fool the BCM algorithm, allowing us to
explore the full potential of this construction. As our main result, we show a
time-space tradeoff for Element Distinctness without random oracle. Namely, for
every $S(n),T(n)$ such that $T\approx \widetilde{O}(n^{3/2}/S(n)^{1/2})$, our
algorithm can solve the problem in space $S(n)$ and time $T(n)$. Our algorithm
also works for a related problem Set Intersection, for which this tradeoff is
tight due to a matching lower bound by Dinur (Eurocrypt 2020). As two
additional contributions, we show a more general pseudorandom property of the
hash family, and slightly improve the seed length to sample the pseudorandom
hash function.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1">Xin Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Weihao Zhu</a></p><p>In the Element Distinctness problem, one is given an array $a_1,\dots, a_n$
of integers from $[poly(n)]$ and is tasked to decide if $\{a_i\}$ are mutually
distinct. Beame, Clifford and Machmouchi (FOCS 2013) gave a low-space algorithm
for this problem running in space $S(n)$ and time $T(n)$ where $T(n) \le
\widetilde{O}(n^{3/2}/S(n)^{1/2})$, assuming a random oracle (i.e., random
access to polynomially many random bits). A recent breakthrough by Chen, Jin,
Williams and Wu (SODA 2022) showed how to remove the random oracle assumption
in the regime $S(n) = polylog(n)$ and $T(n) = \widetilde{O}(n^{3/2})$. They
designed the first truly $polylog(n)$-space, $\widetilde{O}(n^{3/2})$-time
algorithm by constructing a small family of hash functions $\mathcal{H}
\subseteq \{h | h:[poly(n)]\to [n]\}$ with a certain pseudorandom property.
</p>
<p>In this paper, we give a significantly simplified analysis of the
pseudorandom hash family by Chen et al. Our analysis clearly identifies the key
pseudorandom property required to fool the BCM algorithm, allowing us to
explore the full potential of this construction. As our main result, we show a
time-space tradeoff for Element Distinctness without random oracle. Namely, for
every $S(n),T(n)$ such that $T\approx \widetilde{O}(n^{3/2}/S(n)^{1/2})$, our
algorithm can solve the problem in space $S(n)$ and time $T(n)$. Our algorithm
also works for a related problem Set Intersection, for which this tradeoff is
tight due to a matching lower bound by Dinur (Eurocrypt 2020). As two
additional contributions, we show a more general pseudorandom property of the
hash family, and slightly improve the seed length to sample the pseudorandom
hash function.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
