<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>
  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel='stylesheet' type='text/css' href='css/font-awesome.css'>
  <link rel='stylesheet' type='text/css' href='css/blank.css'>
</head>
<body>
  <div id='navwrap'>
    <div id='nav'>
      <p>
        Last Update
      </p>
      <p class='small'>
        
          <time class='timeago' datetime="2022-09-30T17:06:08Z">Friday, September 30 2022, 17:06</time>
        
      </p>

      <p>Feeds</p>
      <ul class='subscriptions small' >
      
        <li>
          <a href='http://arxiv.org/rss/cs.CC'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.CG'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.DS'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
          
        </li>
      
        <li>
          <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
          
        </li>
      
        <li>
          <a href='https://adamsheffer.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
          
        </li>
      
        <li>
          <a href='https://adamdsmith.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
          
        </li>
      
        <li>
          <a href='https://polylogblog.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
          
        </li>
      
        <li>
          <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
          
        </li>
      
        <li>
          <a href='http://www.argmin.net/feed.xml'><img src='i/feed.png'></a>
          <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
          
        </li>
      
        <li>
          <a href='http://bit-player.org/feed/atom/'><img src='i/feed.png'></a>
          <a href='http://bit-player.org'>bit-player</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-jobs.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-jobs.org'>CCI: jobs</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-events.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-events.org'>CS Theory Events</a>
          
        </li>
      
        <li>
          <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='https://11011110.github.io/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='https://11011110.github.io/blog/'>David Eppstein</a>
          
        </li>
      
        <li>
          <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='i/feed.png'></a>
          <a href='https://daveagp.wordpress.com'>David Pritchard</a>
          
        </li>
      
        <li>
          <a href='https://decentdescent.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://decentdescent.org/'>Decent Descent</a>
          
        </li>
      
        <li>
          <a href='https://decentralizedthoughts.github.io/feed'><img src='i/feed.png'></a>
          <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
          
        </li>
      
        <li>
          <a href='https://differentialprivacy.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
          
        </li>
      
        <li>
          <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='i/feed.png'></a>
          <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
          
        </li>
      
        <li>
          <a href='https://emanueleviola.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
          
        </li>
      
        <li>
          <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='i/feed.png'></a>
          <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
          
        </li>
      
        <li>
          <a href='https://dstheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
          
        </li>
      
        <li>
          <a href='https://francisbach.com/feed/'><img src='i/feed.png'></a>
          <a href='https://francisbach.com'>Francis Bach</a>
          
        </li>
      
        <li>
          <a href='https://gilkalai.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
          
        </li>
      
        <li>
          <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
          
        </li>
      
        <li>
          <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='i/feed.png'></a>
          <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
          
        </li>
      
        <li>
          <a href='https://gradientscience.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://gradientscience.org/'>Gradient Science</a>
          
        </li>
      
        <li>
          <a href='http://grigory.us/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
          
        </li>
      
        <li>
          <a href='https://tcsmath.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
          
        </li>
      
        <li>
          <a href='https://kamathematics.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
          
        </li>
      
        <li>
          <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
          
        </li>
      
        <li>
          <a href='https://lucatrevisan.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
          
        </li>
      
        <li>
          <a href='https://mittheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
          
        </li>
      
        <li>
          <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
          
        </li>
      
        <li>
          <a href='http://blog.mrtz.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
          
        </li>
      
        <li>
          <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
          
        </li>
      
        <li>
          <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
          
        </li>
      
        <li>
          <a href='http://www.solipsistslog.com/feed/'><img src='i/feed.png'></a>
          <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
          
        </li>
      
        <li>
          <a href='http://www.offconvex.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://offconvex.github.io/'>Off the Convex Path</a>
          
        </li>
      
        <li>
          <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
          
        </li>
      
        <li>
          <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
          
        </li>
      
        <li>
          <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='i/feed.png'></a>
          <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
          
        </li>
      
        <li>
          <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
          
        </li>
      
        <li>
          <a href='https://scottaaronson.blog/?feed=atom'><img src='i/feed.png'></a>
          <a href='https://scottaaronson.blog'>Scott Aaronson</a>
          
        </li>
      
        <li>
          <a href='https://blog.simons.berkeley.edu/feed/'><img src='i/feed.png'></a>
          <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
          
        </li>
      
        <li>
          <a href='https://tcsplus.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
          
        </li>
      
        <li>
          <a href='https://toc4fairness.org/feed/'><img src='i/feed.png'></a>
          <a href='https://toc4fairness.org'>TOC for Fairness</a>
          
        </li>
      
        <li>
          <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='i/feed.png'></a>
          <a href='http://blog.geomblog.org/'>The Geomblog</a>
          
        </li>
      
        <li>
          <a href='https://www.let-all.com/blog/feed/'><img src='i/feed.png'></a>
          <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
          
        </li>
      
        <li>
          <a href='https://theorydish.blog/feed/'><img src='i/feed.png'></a>
          <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
          
        </li>
      
        <li>
          <a href='https://thmatters.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://thmatters.wordpress.com'>Theory Matters</a>
          
        </li>
      
        <li>
          <a href='https://mycqstate.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
          
        </li>
      
        <li>
          <a href='https://agtb.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
          
        </li>
      
        <li>
          <a href='https://windowsontheory.org/feed/'><img src='i/feed.png'></a>
          <a href='https://windowsontheory.org'>Windows on Theory</a>
          
        </li>
      
      </ul>

      <p class='small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
      <p class='small'>Subscribe to the <a href="atom.xml">Atom feed</a> or <a href="rss20.xml">RSS feed</a> to stay up to date.</p>
      <p class='small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
      <p class='small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
      <p class='small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
    </div>
  </div>

  <div id='opts'>
    <div style='width: 100%; text-align: right;'>
    <img src='i/view-headlines.png' id='show-headlines' title='Show Headlines Only' width='24' height='24'>
    <img src='i/view-snippets.png' id='show-snippets' title='Show Snippets' width='24' height='24'>
    <img src='i/view-standard.png' id='show-fulltext' title='Show Full Text' width='24' height='24'>
    </div>
  </div>

  <h1>
    Theory of Computing Report
  </h1>

  <div id="articles">
    
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Friday, September 30
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14530'>Low-Stabilizer-Complexity Quantum States Are Not Pseudorandom</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Sabee Grewal, Vishnu Iyer, William Kretschmer, Daniel Liang</p><p>We show that quantum states with "low stabilizer complexity" can be
efficiently distinguished from Haar-random. Specifically, given an $n$-qubit
pure state $|\psi\rangle$, we give an efficient algorithm that distinguishes
whether $|\psi\rangle$ is (i) Haar-random or (ii) a state with stabilizer
fidelity at least $\frac{1}{k}$ (i.e., has fidelity at least $\frac{1}{k}$ with
some stabilizer state), promised that one of these is the case. With black-box
access to $|\psi\rangle$, our algorithm uses $O\!\left( k^{12}
\log(1/\delta)\right)$ copies of $|\psi\rangle$ and $O\!\left(n k^{12}
\log(1/\delta)\right)$ time to succeed with probability at least $1-\delta$,
and, with access to a state preparation unitary for $|\psi\rangle$ (and its
inverse), $O\!\left( k^{3} \log(1/\delta)\right)$ queries and $O\!\left(n k^{3}
\log(1/\delta)\right)$ time suffice.
</p>
<p>As a corollary, we prove that $\omega(\log(n))$ $T$-gates are necessary for
any Clifford+$T$ circuit to prepare computationally pseudorandom quantum
states, a first-of-its-kind lower bound.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Grewal_S/0/1/0/all/0/1">Sabee Grewal</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Iyer_V/0/1/0/all/0/1">Vishnu Iyer</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kretschmer_W/0/1/0/all/0/1">William Kretschmer</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Liang_D/0/1/0/all/0/1">Daniel Liang</a></p><p>We show that quantum states with "low stabilizer complexity" can be
efficiently distinguished from Haar-random. Specifically, given an $n$-qubit
pure state $|\psi\rangle$, we give an efficient algorithm that distinguishes
whether $|\psi\rangle$ is (i) Haar-random or (ii) a state with stabilizer
fidelity at least $\frac{1}{k}$ (i.e., has fidelity at least $\frac{1}{k}$ with
some stabilizer state), promised that one of these is the case. With black-box
access to $|\psi\rangle$, our algorithm uses $O\!\left( k^{12}
\log(1/\delta)\right)$ copies of $|\psi\rangle$ and $O\!\left(n k^{12}
\log(1/\delta)\right)$ time to succeed with probability at least $1-\delta$,
and, with access to a state preparation unitary for $|\psi\rangle$ (and its
inverse), $O\!\left( k^{3} \log(1/\delta)\right)$ queries and $O\!\left(n k^{3}
\log(1/\delta)\right)$ time suffice.
</p>
<p>As a corollary, we prove that $\omega(\log(n))$ $T$-gates are necessary for
any Clifford+$T$ circuit to prepare computationally pseudorandom quantum
states, a first-of-its-kind lower bound.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14914'>Quantum invariants for the graph isomorphism problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Hern&#xe1;n I. de la Cruz, Fernando L. Pelayo, Vicente Pascual, Jose J. Paulet, Fernando Cuartero, Luis Llana, Mauro Mezzini</p><p>Graph Isomorphism is such an important problem in computer science, that it
has been widely studied over the last decades. It is well known that it belongs
to NP class, but is not NP-complete. It is thought to be of comparable
difficulty to integer factorisation. The best known proved algorithm to solve
this problem in general, was proposed by L\'aszl\'o Babai and Eugene Luks in
1983.
</p>
<p>Recently, there has been some research in the topic by using quantum
computing, that also leads the present piece of research. In fact, we present a
quantum computing algorithm that defines an invariant over Graph Isomorphism
characterisation. This quantum algorithm is able to distinguish more
non-isomorphic graphs than most of the known invariants so far. The proof of
correctness and some hints illustrating the extent and reason of the
improvement are also included in this paper.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cruz_H/0/1/0/all/0/1">Hern&#xe1;n I. de la Cruz</a>, <a href="http://arxiv.org/find/cs/1/au:+Pelayo_F/0/1/0/all/0/1">Fernando L. Pelayo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pascual_V/0/1/0/all/0/1">Vicente Pascual</a>, <a href="http://arxiv.org/find/cs/1/au:+Paulet_J/0/1/0/all/0/1">Jose J. Paulet</a>, <a href="http://arxiv.org/find/cs/1/au:+Cuartero_F/0/1/0/all/0/1">Fernando Cuartero</a>, <a href="http://arxiv.org/find/cs/1/au:+Llana_L/0/1/0/all/0/1">Luis Llana</a>, <a href="http://arxiv.org/find/cs/1/au:+Mezzini_M/0/1/0/all/0/1">Mauro Mezzini</a></p><p>Graph Isomorphism is such an important problem in computer science, that it
has been widely studied over the last decades. It is well known that it belongs
to NP class, but is not NP-complete. It is thought to be of comparable
difficulty to integer factorisation. The best known proved algorithm to solve
this problem in general, was proposed by L\'aszl\'o Babai and Eugene Luks in
1983.
</p>
<p>Recently, there has been some research in the topic by using quantum
computing, that also leads the present piece of research. In fact, we present a
quantum computing algorithm that defines an invariant over Graph Isomorphism
characterisation. This quantum algorithm is able to distinguish more
non-isomorphic graphs than most of the known invariants so far. The proof of
correctness and some hints illustrating the extent and reason of the
improvement are also included in this paper.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14778'>Batch Normalization Explained</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Randall Balestriero, Richard G. Baraniuk</p><p>A critically important, ubiquitous, and yet poorly understood ingredient in
modern deep networks (DNs) is batch normalization (BN), which centers and
normalizes the feature maps. To date, only limited progress has been made
understanding why BN boosts DN learning and inference performance; work has
focused exclusively on showing that BN smooths a DN's loss landscape. In this
paper, we study BN theoretically from the perspective of function
approximation; we exploit the fact that most of today's state-of-the-art DNs
are continuous piecewise affine (CPA) splines that fit a predictor to the
training data via affine mappings defined over a partition of the input space
(the so-called "linear regions"). {\em We demonstrate that BN is an
unsupervised learning technique that -- independent of the DN's weights or
gradient-based learning -- adapts the geometry of a DN's spline partition to
match the data.} BN provides a "smart initialization" that boosts the
performance of DN learning, because it adapts even a DN initialized with random
weights to align its spline partition with the data. We also show that the
variation of BN statistics between mini-batches introduces a dropout-like
random perturbation to the partition boundaries and hence the decision boundary
for classification problems. This per mini-batch perturbation reduces
overfitting and improves generalization by increasing the margin between the
training samples and the decision boundary.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1">Randall Balestriero</a>, <a href="http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1">Richard G. Baraniuk</a></p><p>A critically important, ubiquitous, and yet poorly understood ingredient in
modern deep networks (DNs) is batch normalization (BN), which centers and
normalizes the feature maps. To date, only limited progress has been made
understanding why BN boosts DN learning and inference performance; work has
focused exclusively on showing that BN smooths a DN's loss landscape. In this
paper, we study BN theoretically from the perspective of function
approximation; we exploit the fact that most of today's state-of-the-art DNs
are continuous piecewise affine (CPA) splines that fit a predictor to the
training data via affine mappings defined over a partition of the input space
(the so-called "linear regions"). {\em We demonstrate that BN is an
unsupervised learning technique that -- independent of the DN's weights or
gradient-based learning -- adapts the geometry of a DN's spline partition to
match the data.} BN provides a "smart initialization" that boosts the
performance of DN learning, because it adapts even a DN initialized with random
weights to align its spline partition with the data. We also show that the
variation of BN statistics between mini-batches introduces a dropout-like
random perturbation to the partition boundaries and hence the decision boundary
for classification problems. This per mini-batch perturbation reduces
overfitting and improves generalization by increasing the margin between the
training samples and the decision boundary.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14804'>Minimum Link Fencing</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Sujoy Bhore, Fabian Klute, Maarten L&#xf6;ffler, Martin N&#xf6;llenburg, Soeren Terziadis, Ana&#xef;s Villedieu</p><p>We study a variant of the geometric multicut problem, where we are given a
set $\mathcal{P}$ of colored and pairwise interior-disjoint polygons in the
plane. The objective is to compute a set of simple closed polygon boundaries
(fences) that separate the polygons in such a way that any two polygons that
are enclosed by the same fence have the same color, and the total number of
links of all fences is minimized. We call this the minimum link fencing (MLF)
problem and consider the natural case of bounded minimum link fencing (BMLF),
where $\mathcal{P}$ contains a polygon $Q$ that is unbounded in all directions
and can be seen as an outer polygon. We show that BMLF is NP-hard in general
and that it is XP-time solvable when each fence contains at most two polygons
and the number of segments per fence is the parameter. Finally, we present an
$O(n \log n)$-time algorithm for the case that the convex hull of $\mathcal{P}
\setminus \{Q\}$ does not intersect $Q$.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhore_S/0/1/0/all/0/1">Sujoy Bhore</a>, <a href="http://arxiv.org/find/cs/1/au:+Klute_F/0/1/0/all/0/1">Fabian Klute</a>, <a href="http://arxiv.org/find/cs/1/au:+Loffler_M/0/1/0/all/0/1">Maarten L&#xf6;ffler</a>, <a href="http://arxiv.org/find/cs/1/au:+Nollenburg_M/0/1/0/all/0/1">Martin N&#xf6;llenburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Terziadis_S/0/1/0/all/0/1">Soeren Terziadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Villedieu_A/0/1/0/all/0/1">Ana&#xef;s Villedieu</a></p><p>We study a variant of the geometric multicut problem, where we are given a
set $\mathcal{P}$ of colored and pairwise interior-disjoint polygons in the
plane. The objective is to compute a set of simple closed polygon boundaries
(fences) that separate the polygons in such a way that any two polygons that
are enclosed by the same fence have the same color, and the total number of
links of all fences is minimized. We call this the minimum link fencing (MLF)
problem and consider the natural case of bounded minimum link fencing (BMLF),
where $\mathcal{P}$ contains a polygon $Q$ that is unbounded in all directions
and can be seen as an outer polygon. We show that BMLF is NP-hard in general
and that it is XP-time solvable when each fence contains at most two polygons
and the number of segments per fence is the parameter. Finally, we present an
$O(n \log n)$-time algorithm for the case that the convex hull of $\mathcal{P}
\setminus \{Q\}$ does not intersect $Q$.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14993'>Discrete Microlocal Morse Theory</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Adam Brown, Ondrej Draganov</p><p>We establish several results combining discrete Morse theory and microlocal
sheaf theory in the setting of finite posets and simplicial complexes. Our
primary tool is a computationally tractable description of the bounded derived
category of sheaves on a poset with the Alexandrov topology. We prove that each
bounded complex of sheaves on a finite poset admits a unique (up to isomorphism
of complexes) minimal injective resolution, and we provide algorithms for
computing minimal injective resolutions, as well as several useful functors
between derived categories of sheaves. For the constant sheaf on a simplicial
complex, we give asymptotically tight bounds on the complexity of computing the
minimal injective resolution with this algorithm. Our main result is a novel
definition of the discrete microsupport of a bounded complex of sheaves on a
finite poset. We detail several foundational properties of the discrete
microsupport, as well as a microlocal generalization of the discrete
homological Morse theorem and Morse inequalities.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Brown_A/0/1/0/all/0/1">Adam Brown</a>, <a href="http://arxiv.org/find/math/1/au:+Draganov_O/0/1/0/all/0/1">Ondrej Draganov</a></p><p>We establish several results combining discrete Morse theory and microlocal
sheaf theory in the setting of finite posets and simplicial complexes. Our
primary tool is a computationally tractable description of the bounded derived
category of sheaves on a poset with the Alexandrov topology. We prove that each
bounded complex of sheaves on a finite poset admits a unique (up to isomorphism
of complexes) minimal injective resolution, and we provide algorithms for
computing minimal injective resolutions, as well as several useful functors
between derived categories of sheaves. For the constant sheaf on a simplicial
complex, we give asymptotically tight bounds on the complexity of computing the
minimal injective resolution with this algorithm. Our main result is a novel
definition of the discrete microsupport of a bounded complex of sheaves on a
finite poset. We detail several foundational properties of the discrete
microsupport, as well as a microlocal generalization of the discrete
homological Morse theorem and Morse inequalities.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14358'>The minimal canonical form of a tensor network</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Arturo Acuaviva, Visu Makam, Harold Nieuwboer, David P&#xe9;rez-Garc&#xed;a, Friedrich Sittner, Michael Walter, Freek Witteveen</p><p>Tensor networks have a gauge degree of freedom on the virtual degrees of
freedom that are contracted. A canonical form is a choice of fixing this degree
of freedom. For matrix product states, choosing a canonical form is a powerful
tool, both for theoretical and numerical purposes. On the other hand, for
tensor networks in dimension two or greater there is only limited understanding
of the gauge symmetry. Here we introduce a new canonical form, the minimal
canonical form, which applies to projected entangled pair states (PEPS) in any
dimension, and prove a corresponding fundamental theorem. Already for matrix
product states this gives a new canonical form, while in higher dimensions it
is the first rigorous definition of a canonical form valid for any choice of
tensor. We show that two tensors have the same minimal canonical forms if and
only if they are gauge equivalent up to taking limits; moreover, this is the
case if and only if they give the same quantum state for any geometry. In
particular, this implies that the latter problem is decidable - in contrast to
the well-known undecidability for PEPS on grids. We also provide rigorous
algorithms for computing minimal canonical forms. To achieve this we draw on
geometric invariant theory and recent progress in theoretical computer science
in non-commutative group optimization.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Acuaviva_A/0/1/0/all/0/1">Arturo Acuaviva</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Makam_V/0/1/0/all/0/1">Visu Makam</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nieuwboer_H/0/1/0/all/0/1">Harold Nieuwboer</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Perez_Garcia_D/0/1/0/all/0/1">David P&#xe9;rez-Garc&#xed;a</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sittner_F/0/1/0/all/0/1">Friedrich Sittner</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Walter_M/0/1/0/all/0/1">Michael Walter</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Witteveen_F/0/1/0/all/0/1">Freek Witteveen</a></p><p>Tensor networks have a gauge degree of freedom on the virtual degrees of
freedom that are contracted. A canonical form is a choice of fixing this degree
of freedom. For matrix product states, choosing a canonical form is a powerful
tool, both for theoretical and numerical purposes. On the other hand, for
tensor networks in dimension two or greater there is only limited understanding
of the gauge symmetry. Here we introduce a new canonical form, the minimal
canonical form, which applies to projected entangled pair states (PEPS) in any
dimension, and prove a corresponding fundamental theorem. Already for matrix
product states this gives a new canonical form, while in higher dimensions it
is the first rigorous definition of a canonical form valid for any choice of
tensor. We show that two tensors have the same minimal canonical forms if and
only if they are gauge equivalent up to taking limits; moreover, this is the
case if and only if they give the same quantum state for any geometry. In
particular, this implies that the latter problem is decidable - in contrast to
the well-known undecidability for PEPS on grids. We also provide rigorous
algorithms for computing minimal canonical forms. To achieve this we draw on
geometric invariant theory and recent progress in theoretical computer science
in non-commutative group optimization.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14368'>Repeated Prophet Inequality with Near-optimal Bounds</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Krishnendu Chatterjee, Mona Mohammadi, Raimundo Saona</p><p>In modern sample-driven Prophet Inequality, an adversary chooses a sequence
of $n$ items with values $v_1, v_2, \ldots, v_n$ to be presented to a decision
maker (DM). The process follows in two phases. In the first phase (sampling
phase), some items, possibly selected at random, are revealed to the DM, but
she can never accept them. In the second phase, the DM is presented with the
other items in a random order and online fashion. For each item, she must make
an irrevocable decision to either accept the item and stop the process or
reject the item forever and proceed to the next item. The goal of the DM is to
maximize the expected value as compared to a Prophet (or offline algorithm)
that has access to all information. In this setting, the sampling phase has no
cost and is not part of the optimization process. However, in many scenarios,
the samples are obtained as part of the decision-making process.
</p>
<p>We model this aspect as a two-phase Prophet Inequality where an adversary
chooses a sequence of $2n$ items with values $v_1, v_2, \ldots, v_{2n}$ and the
items are randomly ordered. Finally, there are two phases of the Prophet
Inequality problem with the first $n$-items and the rest of the items,
respectively. We show that some basic algorithms achieve a ratio of at most
$0.450$. We present an algorithm that achieves a ratio of at least $0.495$.
Finally, we show that for every algorithm the ratio it can achieve is at most
$0.502$. Hence our algorithm is near-optimal.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Chatterjee_K/0/1/0/all/0/1">Krishnendu Chatterjee</a>, <a href="http://arxiv.org/find/math/1/au:+Mohammadi_M/0/1/0/all/0/1">Mona Mohammadi</a>, <a href="http://arxiv.org/find/math/1/au:+Saona_R/0/1/0/all/0/1">Raimundo Saona</a></p><p>In modern sample-driven Prophet Inequality, an adversary chooses a sequence
of $n$ items with values $v_1, v_2, \ldots, v_n$ to be presented to a decision
maker (DM). The process follows in two phases. In the first phase (sampling
phase), some items, possibly selected at random, are revealed to the DM, but
she can never accept them. In the second phase, the DM is presented with the
other items in a random order and online fashion. For each item, she must make
an irrevocable decision to either accept the item and stop the process or
reject the item forever and proceed to the next item. The goal of the DM is to
maximize the expected value as compared to a Prophet (or offline algorithm)
that has access to all information. In this setting, the sampling phase has no
cost and is not part of the optimization process. However, in many scenarios,
the samples are obtained as part of the decision-making process.
</p>
<p>We model this aspect as a two-phase Prophet Inequality where an adversary
chooses a sequence of $2n$ items with values $v_1, v_2, \ldots, v_{2n}$ and the
items are randomly ordered. Finally, there are two phases of the Prophet
Inequality problem with the first $n$-items and the rest of the items,
respectively. We show that some basic algorithms achieve a ratio of at most
$0.450$. We present an algorithm that achieves a ratio of at least $0.495$.
Finally, we show that for every algorithm the ratio it can achieve is at most
$0.502$. Hence our algorithm is near-optimal.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14401'>Shortest Beer Path Queries in Interval Graphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Rathish Das, Meng He, Eitan Kondratovsky, J. Ian Munro, Anurag Murty Naredla, Kaiyu Wu</p><p>Our interest is in paths between pairs of vertices that go through at least
one of a subset of the vertices known as beer vertices. Such a path is called a
beer path, and the beer distance between two vertices is the length of the
shortest beer path.
</p>
<p>We show that we can represent unweighted interval graphs using $2n \log n +
O(n) + O(|B|\log n)$ bits where $|B|$ is the number of beer vertices. This data
structure answers beer distance queries in $O(\log^\varepsilon n)$ time for any
constant $\varepsilon &gt; 0$ and shortest beer path queries in
$O(\log^\varepsilon n + d)$ time, where $d$ is the beer distance between the
two nodes. We also show that proper interval graphs may be represented using
$3n + o(n)$ bits to support beer distance queries in $O(f(n)\log n)$ time for
any $f(n) \in \omega(1)$ and shortest beer path queries in $O(d)$ time. All of
these results also have time-space trade-offs.
</p>
<p>Lastly we show that the information theoretic lower bound for beer proper
interval graphs is very close to the space of our structure, namely
$\log(4+2\sqrt{3})n - o(n)$ (or about $ 2.9 n$) bits.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1">Rathish Das</a>, <a href="http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1">Meng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondratovsky_E/0/1/0/all/0/1">Eitan Kondratovsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Munro_J/0/1/0/all/0/1">J. Ian Munro</a>, <a href="http://arxiv.org/find/cs/1/au:+Naredla_A/0/1/0/all/0/1">Anurag Murty Naredla</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kaiyu Wu</a></p><p>Our interest is in paths between pairs of vertices that go through at least
one of a subset of the vertices known as beer vertices. Such a path is called a
beer path, and the beer distance between two vertices is the length of the
shortest beer path.
</p>
<p>We show that we can represent unweighted interval graphs using $2n \log n +
O(n) + O(|B|\log n)$ bits where $|B|$ is the number of beer vertices. This data
structure answers beer distance queries in $O(\log^\varepsilon n)$ time for any
constant $\varepsilon &gt; 0$ and shortest beer path queries in
$O(\log^\varepsilon n + d)$ time, where $d$ is the beer distance between the
two nodes. We also show that proper interval graphs may be represented using
$3n + o(n)$ bits to support beer distance queries in $O(f(n)\log n)$ time for
any $f(n) \in \omega(1)$ and shortest beer path queries in $O(d)$ time. All of
these results also have time-space trade-offs.
</p>
<p>Lastly we show that the information theoretic lower bound for beer proper
interval graphs is very close to the space of our structure, namely
$\log(4+2\sqrt{3})n - o(n)$ (or about $ 2.9 n$) bits.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14429'>Efficient parameterized algorithms on graphs with heterogeneous structure: Combining tree-depth and modular-width</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Stefan Kratsch, Florian Nelles</p><p>Many computational problems admit fast algorithms on special inputs, however,
the required properties might be quite restrictive. E.g., many graph problems
can be solved much faster on interval or cographs, or on graphs of small
modular-width or small tree-width, than on general graphs. One challenge is to
attain the greatest generality of such results, i.e., being applicable to less
restrictive input classes, without losing much in terms of running time.
</p>
<p>Building on the use of algebraic expressions we present a clean and robust
way of combining such homogeneous structure into more complex heterogeneous
structure, and we show-case this for the combination of modular-width,
tree-depth, and a natural notion of modular tree-depth. We give a generic
framework for designing efficient parameterized algorithms on the created graph
classes, aimed at getting competitive running times that match the homogeneous
cases. To show the applicability we give efficient parameterized algorithms for
Negative Cycle Detection, Vertex-Weighted All-Pairs Shortest Paths, and
Triangle Counting.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kratsch_S/0/1/0/all/0/1">Stefan Kratsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Nelles_F/0/1/0/all/0/1">Florian Nelles</a></p><p>Many computational problems admit fast algorithms on special inputs, however,
the required properties might be quite restrictive. E.g., many graph problems
can be solved much faster on interval or cographs, or on graphs of small
modular-width or small tree-width, than on general graphs. One challenge is to
attain the greatest generality of such results, i.e., being applicable to less
restrictive input classes, without losing much in terms of running time.
</p>
<p>Building on the use of algebraic expressions we present a clean and robust
way of combining such homogeneous structure into more complex heterogeneous
structure, and we show-case this for the combination of modular-width,
tree-depth, and a natural notion of modular tree-depth. We give a generic
framework for designing efficient parameterized algorithms on the created graph
classes, aimed at getting competitive running times that match the homogeneous
cases. To show the applicability we give efficient parameterized algorithms for
Negative Cycle Detection, Vertex-Weighted All-Pairs Shortest Paths, and
Triangle Counting.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14501'>On Quantum Speedups for Nonconvex Optimization via Quantum Tunneling Walks</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Yizhou Liu, Weijie J. Su, Tongyang Li</p><p>Classical algorithms are often not effective for solving nonconvex
optimization problems where local minima are separated by high barriers. In
this paper, we explore possible quantum speedups for nonconvex optimization by
leveraging the global effect of quantum tunneling. Specifically, we introduce a
quantum algorithm termed the quantum tunneling walk (QTW) and apply it to
nonconvex problems where local minima are approximately global minima. We show
that QTW achieves quantum speedup over classical stochastic gradient descents
(SGD) when the barriers between different local minima are high but thin and
the minima are flat. Based on this observation, we construct a specific
double-well landscape, where classical algorithms cannot efficiently hit one
target well knowing the other well but QTW can when given proper initial states
near the known well. Finally, we corroborate our findings with numerical
experiments.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Liu_Y/0/1/0/all/0/1">Yizhou Liu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Su_W/0/1/0/all/0/1">Weijie J. Su</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Li_T/0/1/0/all/0/1">Tongyang Li</a></p><p>Classical algorithms are often not effective for solving nonconvex
optimization problems where local minima are separated by high barriers. In
this paper, we explore possible quantum speedups for nonconvex optimization by
leveraging the global effect of quantum tunneling. Specifically, we introduce a
quantum algorithm termed the quantum tunneling walk (QTW) and apply it to
nonconvex problems where local minima are approximately global minima. We show
that QTW achieves quantum speedup over classical stochastic gradient descents
(SGD) when the barriers between different local minima are high but thin and
the minima are flat. Based on this observation, we construct a specific
double-well landscape, where classical algorithms cannot efficiently hit one
target well knowing the other well but QTW can when given proper initial states
near the known well. Finally, we corroborate our findings with numerical
experiments.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14516'>Matroid Intersection under Restricted Oracles</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Krist&#xf3;f B&#xe9;rczi, Tam&#xe1;s Kir&#xe1;ly, Yutaro Yamaguchi, Yu Yokoi</p><p>Matroid intersection is one of the most powerful frameworks of matroid theory
that generalizes various problems in combinatorial optimization. Edmonds'
fundamental theorem provides a min-max characterization for the unweighted
setting, while Frank's weight-splitting theorem provides one for the weighted
case. Several efficient algorithms were developed for these problems, all
relying on the usage of one of the conventional oracles for both matroids.
</p>
<p>In the present paper, we consider the tractability of the matroid
intersection problem under restricted oracles. In particular, we focus on the
rank sum, common independence, and maximum rank oracles. We give a strongly
polynomial-time algorithm for weighted matroid intersection under the rank sum
oracle. In the common independence oracle model, we prove that the unweighted
matroid intersection problem is tractable when one of the matroids is a
partition matroid, and that even the weighted case is solvable when one of the
matroids is an elementary split matroid. Finally, we show that the common
independence and maximum rank oracles together are strong enough to realize the
steps of our algorithm under the rank sum oracle.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berczi_K/0/1/0/all/0/1">Krist&#xf3;f B&#xe9;rczi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiraly_T/0/1/0/all/0/1">Tam&#xe1;s Kir&#xe1;ly</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamaguchi_Y/0/1/0/all/0/1">Yutaro Yamaguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yokoi_Y/0/1/0/all/0/1">Yu Yokoi</a></p><p>Matroid intersection is one of the most powerful frameworks of matroid theory
that generalizes various problems in combinatorial optimization. Edmonds'
fundamental theorem provides a min-max characterization for the unweighted
setting, while Frank's weight-splitting theorem provides one for the weighted
case. Several efficient algorithms were developed for these problems, all
relying on the usage of one of the conventional oracles for both matroids.
</p>
<p>In the present paper, we consider the tractability of the matroid
intersection problem under restricted oracles. In particular, we focus on the
rank sum, common independence, and maximum rank oracles. We give a strongly
polynomial-time algorithm for weighted matroid intersection under the rank sum
oracle. In the common independence oracle model, we prove that the unweighted
matroid intersection problem is tractable when one of the matroids is a
partition matroid, and that even the weighted case is solvable when one of the
matroids is an elementary split matroid. Finally, we show that the common
independence and maximum rank oracles together are strong enough to realize the
steps of our algorithm under the rank sum oracle.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14637'>Tensor-Based Sketching Method for the Low-Rank Approximation of Data Streams</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Cuiyu Liu, Chuanfu Xiao, Mingshuo Ding, Chao Yang</p><p>Low-rank approximation in data streams is a fundamental and significant task
in computing science, machine learning and statistics. Multiple streaming
algorithms have emerged over years and most of them are inspired by randomized
algorithms, more specifically, sketching methods. However, many algorithms are
not able to leverage information of data streams and consequently suffer from
low accuracy. Existing data-driven methods improve accuracy but the training
cost is expensive in practice. In this paper, from a subspace perspective, we
propose a tensor-based sketching method for low-rank approximation of data
streams. The proposed algorithm fully exploits the structure of data streams
and obtains quasi-optimal sketching matrices by performing tensor decomposition
on training data. A series of experiments are carried out and show that the
proposed tensor-based method can be more accurate and much faster than the
previous work.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Cuiyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chuanfu Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1">Mingshuo Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao Yang</a></p><p>Low-rank approximation in data streams is a fundamental and significant task
in computing science, machine learning and statistics. Multiple streaming
algorithms have emerged over years and most of them are inspired by randomized
algorithms, more specifically, sketching methods. However, many algorithms are
not able to leverage information of data streams and consequently suffer from
low accuracy. Existing data-driven methods improve accuracy but the training
cost is expensive in practice. In this paper, from a subspace perspective, we
propose a tensor-based sketching method for low-rank approximation of data
streams. The proposed algorithm fully exploits the structure of data streams
and obtains quasi-optimal sketching matrices by performing tensor decomposition
on training data. A series of experiments are carried out and show that the
proposed tensor-based method can be more accurate and much faster than the
previous work.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14662'>A dichotomy for succinct representations of homomorphisms</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Christoph Berkholz, Harry Vinall-Smeeth</p><p>The task of computing homomorphisms between two finite relational structures
$\mathcal{A}$ and $\mathcal{B}$ is a well-studied question with numerous
applications. Since the set $\operatorname{Hom}(\mathcal{A},\mathcal{B})$ of
all homomorphisms may be very large having a method of representing it in a
succinct way, especially one which enables us to perform efficient enumeration
and counting, could be extremely useful.
</p>
<p>One simple yet powerful way of doing so is to decompose
$\operatorname{Hom}(\mathcal{A},\mathcal{B})$ using union and Cartesian
product. Such data structures, called d-representations, have been introduced
by Olteanu and Zavodny in the context of database theory. Their results also
imply that if the treewidth of the left-hand side structure $\mathcal{A}$ is
bounded, then a d-representation of polynomial size can be found in polynomial
time. We show that for structures of bounded arity this is optimal: if the
treewidth is unbounded then there are instances where the size of any
d-representation is superpolynomial. Along the way we develop tools for proving
lower bounds on the size of d-representations, in particular we define a notion
of reduction suitable for this context and prove an almost tight lower bound on
the size of d-representations of all $k$-cliques in a graph.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berkholz_C/0/1/0/all/0/1">Christoph Berkholz</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinall_Smeeth_H/0/1/0/all/0/1">Harry Vinall-Smeeth</a></p><p>The task of computing homomorphisms between two finite relational structures
$\mathcal{A}$ and $\mathcal{B}$ is a well-studied question with numerous
applications. Since the set $\operatorname{Hom}(\mathcal{A},\mathcal{B})$ of
all homomorphisms may be very large having a method of representing it in a
succinct way, especially one which enables us to perform efficient enumeration
and counting, could be extremely useful.
</p>
<p>One simple yet powerful way of doing so is to decompose
$\operatorname{Hom}(\mathcal{A},\mathcal{B})$ using union and Cartesian
product. Such data structures, called d-representations, have been introduced
by Olteanu and Zavodny in the context of database theory. Their results also
imply that if the treewidth of the left-hand side structure $\mathcal{A}$ is
bounded, then a d-representation of polynomial size can be found in polynomial
time. We show that for structures of bounded arity this is optimal: if the
treewidth is unbounded then there are instances where the size of any
d-representation is superpolynomial. Along the way we develop tools for proving
lower bounds on the size of d-representations, in particular we define a notion
of reduction suitable for this context and prove an almost tight lower bound on
the size of d-representations of all $k$-cliques in a graph.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14703'>Lattice Linear Algorithms</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Arya Tanmay Gupta, Sandeep S Kulkarni</p><p>This paper focuses on analyzing and differentiating between lattice linear
problems and algorithms. It introduces a new class of algorithms called
\textit{(fully) lattice linear algorithms}. A property of these algorithms is
that they induce a partial order among all states and form \textit{multiple
lattices}. An initial state locks in one of these lattices. We present a
lattice linear self-stabilizing algorithm for minimal dominating set.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Arya Tanmay Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_S/0/1/0/all/0/1">Sandeep S Kulkarni</a></p><p>This paper focuses on analyzing and differentiating between lattice linear
problems and algorithms. It introduces a new class of algorithms called
\textit{(fully) lattice linear algorithms}. A property of these algorithms is
that they induce a partial order among all states and form \textit{multiple
lattices}. An initial state locks in one of these lattices. We present a
lattice linear self-stabilizing algorithm for minimal dominating set.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14775'>On Constructing Spanners from Random Gaussian Projections</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Sepehr Assadi, Michael Kapralov, Huacheng Yu</p><p>Graph sketching is a powerful paradigm for analyzing graph structure via
linear measurements introduced by Ahn, Guha, and McGregor (SODA'12) that has
since found numerous applications in streaming, distributed computing, and
massively parallel algorithms, among others. Graph sketching has proven to be
quite successful for various problems such as connectivity, minimum spanning
trees, edge or vertex connectivity, and cut or spectral sparsifiers. Yet, the
problem of approximating shortest path metric of a graph, and specifically
computing a spanner, is notably missing from the list of successes. This has
turned the status of this fundamental problem into one of the most longstanding
open questions in this area.
</p>
<p>We present a partial explanation of this lack of success by proving a strong
lower bound for a large family of graph sketching algorithms that encompasses
prior work on spanners and many (but importantly not also all) related
cut-based problems mentioned above. Our lower bound matches the algorithmic
bounds of the recent result of Filtser, Kapralov, and Nouri (SODA'21), up to
lower order terms, for constructing spanners via the same graph sketching
family. This establishes near-optimality of these bounds, at least restricted
to this family of graph sketching techniques, and makes progress on a
conjecture posed in this latter work.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Assadi_S/0/1/0/all/0/1">Sepehr Assadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kapralov_M/0/1/0/all/0/1">Michael Kapralov</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Huacheng Yu</a></p><p>Graph sketching is a powerful paradigm for analyzing graph structure via
linear measurements introduced by Ahn, Guha, and McGregor (SODA'12) that has
since found numerous applications in streaming, distributed computing, and
massively parallel algorithms, among others. Graph sketching has proven to be
quite successful for various problems such as connectivity, minimum spanning
trees, edge or vertex connectivity, and cut or spectral sparsifiers. Yet, the
problem of approximating shortest path metric of a graph, and specifically
computing a spanner, is notably missing from the list of successes. This has
turned the status of this fundamental problem into one of the most longstanding
open questions in this area.
</p>
<p>We present a partial explanation of this lack of success by proving a strong
lower bound for a large family of graph sketching algorithms that encompasses
prior work on spanners and many (but importantly not also all) related
cut-based problems mentioned above. Our lower bound matches the algorithmic
bounds of the recent result of Filtser, Kapralov, and Nouri (SODA'21), up to
lower order terms, for constructing spanners via the same graph sketching
family. This establishes near-optimality of these bounds, at least restricted
to this family of graph sketching techniques, and makes progress on a
conjecture posed in this latter work.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14827'>On the Convergence of AdaGrad on $\R^{d}$: Beyond Convexity, Non-Asymptotic Rate and Acceleration</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Zijian Liu, Ta Duy Nguyen, Alina Ene, Huy L. Nguyen</p><p>Existing analysis of AdaGrad and other adaptive methods for smooth convex
optimization is typically for functions with bounded domain diameter. In
unconstrained problems, previous works guarantee an asymptotic convergence rate
without an explicit constant factor that holds true for the entire function
class. Furthermore, in the stochastic setting, only a modified version of
AdaGrad, different from the one commonly used in practice, in which the latest
gradient is not used to update the stepsize, has been analyzed. Our paper aims
at bridging these gaps and developing a deeper understanding of AdaGrad and its
variants in the standard setting of smooth convex functions as well as the more
general setting of quasar convex functions. First, we demonstrate new
techniques to explicitly bound the convergence rate of the vanilla AdaGrad for
unconstrained problems in both deterministic and stochastic settings. Second,
we propose a variant of AdaGrad for which we can show the convergence of the
last iterate, instead of the average iterate. Finally, we give new accelerated
adaptive algorithms and their convergence guarantee in the deterministic
setting with explicit dependency on the problem parameters, improving upon the
asymptotic rate shown in previous works.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zijian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Ta Duy Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ene_A/0/1/0/all/0/1">Alina Ene</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Huy L. Nguyen</a></p><p>Existing analysis of AdaGrad and other adaptive methods for smooth convex
optimization is typically for functions with bounded domain diameter. In
unconstrained problems, previous works guarantee an asymptotic convergence rate
without an explicit constant factor that holds true for the entire function
class. Furthermore, in the stochastic setting, only a modified version of
AdaGrad, different from the one commonly used in practice, in which the latest
gradient is not used to update the stepsize, has been analyzed. Our paper aims
at bridging these gaps and developing a deeper understanding of AdaGrad and its
variants in the standard setting of smooth convex functions as well as the more
general setting of quasar convex functions. First, we demonstrate new
techniques to explicitly bound the convergence rate of the vanilla AdaGrad for
unconstrained problems in both deterministic and stochastic settings. Second,
we propose a variant of AdaGrad for which we can show the convergence of the
last iterate, instead of the average iterate. Finally, we give new accelerated
adaptive algorithms and their convergence guarantee in the deterministic
setting with explicit dependency on the problem parameters, improving upon the
asymptotic rate shown in previous works.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14853'>META-STORM: Generalized Fully-Adaptive Variance Reduced SGD for Unbounded Functions</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Zijian Liu, Ta Duy Nguyen, Thien Hang Nguyen, Alina Ene, Huy L. Nguyen</p><p>We study the application of variance reduction (VR) techniques to general
non-convex stochastic optimization problems. In this setting, the recent work
STORM [Cutkosky-Orabona '19] overcomes the drawback of having to compute
gradients of "mega-batches" that earlier VR methods rely on. There, STORM
utilizes recursive momentum to achieve the VR effect and is then later made
fully adaptive in STORM+ [Levy et al., '21], where full-adaptivity removes the
requirement for obtaining certain problem-specific parameters such as the
smoothness of the objective and bounds on the variance and norm of the
stochastic gradients in order to set the step size. However, STORM+ crucially
relies on the assumption that the function values are bounded, excluding a
large class of useful functions. In this work, we propose META-STORM, a
generalized framework of STORM+ that removes this bounded function values
assumption while still attaining the optimal convergence rate for non-convex
optimization. META-STORM not only maintains full-adaptivity, removing the need
to obtain problem specific parameters, but also improves the convergence rate's
dependency on the problem parameters. Furthermore, META-STORM can utilize a
large range of parameter settings that subsumes previous methods allowing for
more flexibility in a wider range of settings. Finally, we demonstrate the
effectiveness of META-STORM through experiments across common deep learning
tasks. Our algorithm improves upon the previous work STORM+ and is competitive
with widely used algorithms after the addition of per-coordinate update and
exponential moving average heuristics.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zijian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Ta Duy Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thien Hang Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ene_A/0/1/0/all/0/1">Alina Ene</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Huy L. Nguyen</a></p><p>We study the application of variance reduction (VR) techniques to general
non-convex stochastic optimization problems. In this setting, the recent work
STORM [Cutkosky-Orabona '19] overcomes the drawback of having to compute
gradients of "mega-batches" that earlier VR methods rely on. There, STORM
utilizes recursive momentum to achieve the VR effect and is then later made
fully adaptive in STORM+ [Levy et al., '21], where full-adaptivity removes the
requirement for obtaining certain problem-specific parameters such as the
smoothness of the objective and bounds on the variance and norm of the
stochastic gradients in order to set the step size. However, STORM+ crucially
relies on the assumption that the function values are bounded, excluding a
large class of useful functions. In this work, we propose META-STORM, a
generalized framework of STORM+ that removes this bounded function values
assumption while still attaining the optimal convergence rate for non-convex
optimization. META-STORM not only maintains full-adaptivity, removing the need
to obtain problem specific parameters, but also improves the convergence rate's
dependency on the problem parameters. Furthermore, META-STORM can utilize a
large range of parameter settings that subsumes previous methods allowing for
more flexibility in a wider range of settings. Finally, we demonstrate the
effectiveness of META-STORM through experiments across common deep learning
tasks. Our algorithm improves upon the previous work STORM+ and is competitive
with widely used algorithms after the addition of per-coordinate update and
exponential moving average heuristics.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14878'>Enumerating Regular Languages in Constant Delay</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Antoine Amarilli, Mika&#xeb;l Monet</p><p>We study the task, for a given language $L$, of enumerating the (generally
infinite) sequence of its words, without repetitions, while bounding the delay
between two consecutive words. To allow for constant delay bounds, we assume a
model where we produce each word by editing the preceding word with a small
edit script, rather than writing out the word from scratch. In particular, this
witnesses that the language is orderable, i.e., we can write its words as an
infinite sequence such that the Levenshtein edit distance between any two
consecutive words is bounded by a constant. For instance, $(a+b)^*$ is
orderable (with a variant of the Gray code), but $a^* + b^*$ is not.
</p>
<p>We characterize which regular languages are enumerable in this sense, and
show that this can be decided in PTIME in an input deterministic finite
automaton (DFA) for the language. In fact, we show that, given a DFA $A$
recognizing a language $L$, we can compute in PTIME automata $A_1, \ldots, A_t$
such that $L$ is partitioned as $L(A_1) \sqcup \ldots \sqcup L(A_t)$ and every
$L(A_i)$ is orderable in this sense. Further, we show that this is optimal,
i.e., we cannot partition $L$ into less than $t$ orderable languages.
</p>
<p>In the case where $L$ is orderable, we show that the ordering can be computed
as a constant-delay algorithm: specifically, the algorithm runs in a suitable
pointer machine model, and produces a sequence of constant-length edit scripts
to visit the words of $L$ without repetitions, with constant delay between each
script. In fact, we show that we can achieve this while only allowing the edit
operations push and pop at the beginning and end of the word, which implies
that the word can in fact be maintained in a double-ended queue.
</p>
<p>We also show results on the complexity of a related problem, and study the
model where push-pop edits are only allowed at the end of the word.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Amarilli_A/0/1/0/all/0/1">Antoine Amarilli</a>, <a href="http://arxiv.org/find/cs/1/au:+Monet_M/0/1/0/all/0/1">Mika&#xeb;l Monet</a></p><p>We study the task, for a given language $L$, of enumerating the (generally
infinite) sequence of its words, without repetitions, while bounding the delay
between two consecutive words. To allow for constant delay bounds, we assume a
model where we produce each word by editing the preceding word with a small
edit script, rather than writing out the word from scratch. In particular, this
witnesses that the language is orderable, i.e., we can write its words as an
infinite sequence such that the Levenshtein edit distance between any two
consecutive words is bounded by a constant. For instance, $(a+b)^*$ is
orderable (with a variant of the Gray code), but $a^* + b^*$ is not.
</p>
<p>We characterize which regular languages are enumerable in this sense, and
show that this can be decided in PTIME in an input deterministic finite
automaton (DFA) for the language. In fact, we show that, given a DFA $A$
recognizing a language $L$, we can compute in PTIME automata $A_1, \ldots, A_t$
such that $L$ is partitioned as $L(A_1) \sqcup \ldots \sqcup L(A_t)$ and every
$L(A_i)$ is orderable in this sense. Further, we show that this is optimal,
i.e., we cannot partition $L$ into less than $t$ orderable languages.
</p>
<p>In the case where $L$ is orderable, we show that the ordering can be computed
as a constant-delay algorithm: specifically, the algorithm runs in a suitable
pointer machine model, and produces a sequence of constant-length edit scripts
to visit the words of $L$ without repetitions, with constant delay between each
script. In fact, we show that we can achieve this while only allowing the edit
operations push and pop at the beginning and end of the word, which implies
that the word can in fact be maintained in a double-ended queue.
</p>
<p>We also show results on the complexity of a related problem, and study the
model where push-pop edits are only allowed at the end of the word.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-30T00:30:00Z">Friday, September 30 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Thursday, September 29
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://blog.computationalcomplexity.org/2022/09/machine-learning-and-complexity.html'>Machine Learning and Complexity</a></h3>
          <p class='item-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>&nbsp;</p>♦Schloss Dagstuhl by Monet by Dall-E<br><p></p><p>At Dagstuhl earlier this month, I hung out for a little bit&nbsp;with the participants of the other seminar,&nbsp;Knowledge Graphs and their Role in the Knowledge Engineering of the 21st Century. Knowledge graphs are what you would expect them to be, nodes are objects like "Berlin" and "Germany" with directed edges with labels like "capital". Think of having knowledge graphs of hundreds of millions of nodes and how that could help answer queries about the world. These secondary workshops are shorter and focus on creating a new vision, in this case how to maximize the importance of knowledge graphs in an increasing ML-focused world.</p><p>Perhaps we need such a visioning seminar for complexity. While we often get lost in the mathematical questions and techniques in our field, computational complexity is designed to understand the difficulty of solving various problems. Machine learning and advances in optimization should be changing that conversation. If you imagine a world where P = NP (and I did exactly that in chapter 2 of my 2013 book) much of what you consider is starting to happen anyway.&nbsp;ML does fail to break cryptography but then again, isn't this the best of all possible worlds?&nbsp;</p><p>Look at what Scott Aaronson said back in 2006.</p><blockquote>If P=NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in “creative leaps,” no fundamental gap between solving a problem and recognizing the solution once it’s found. Everyone who could appreciate a symphony would be Mozart; everyone who could follow a step-by-step argument would be Gauss; everyone who could recognize a good investment strategy would be Warren Buffett.&nbsp;</blockquote><p>If I can be a Monet, can Mozart be far behind? ML trading by some hedge funds are beating Warren Buffett but remember if everyone trades perfectly, no one beats the average. Gauss is going to be trickier but it's coming. There's a reason Scott is&nbsp;spending a year at OpenAI&nbsp;to understand "what, if anything, can computational complexity contribute to a principled understanding of how to get an AI to do what we want and not do what we don’t want".</p><p></p><p>By Lance Fortnow</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>&nbsp;</p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjB-e4HIPenlJclDSenALB6otAw1Nga8deJ3zx3JoMuf41bWFlfy6u4fi-agHPIClWKvkOGcuQRyXbfXXI__l8YpgFjXBY17Y05mdXCMT6bZUbgoILvkQ7D2t4JRNvqFuG-LNaQMRC0HphwBVu3DoVnnHj1ojqbfCXov8yZaRNlj9hoGpqBAQ/s1024/DALL%C2%B7E%202022-09-17%2014.00.36%20-%20Schloss%20Dagstuhl%20in%20the%20style%20of%20monet.png" style="margin-left: auto; margin-right: auto;"><img border="0" data-original-height="1024" data-original-width="1024" height="400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjB-e4HIPenlJclDSenALB6otAw1Nga8deJ3zx3JoMuf41bWFlfy6u4fi-agHPIClWKvkOGcuQRyXbfXXI__l8YpgFjXBY17Y05mdXCMT6bZUbgoILvkQ7D2t4JRNvqFuG-LNaQMRC0HphwBVu3DoVnnHj1ojqbfCXov8yZaRNlj9hoGpqBAQ/w400-h400/DALL%C2%B7E%202022-09-17%2014.00.36%20-%20Schloss%20Dagstuhl%20in%20the%20style%20of%20monet.png" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Schloss Dagstuhl by Monet by Dall-E</td></tr></tbody></table><br /><p></p><p>At Dagstuhl <a href="https://blog.computationalcomplexity.org/2022/09/thirty-years-of-dagstuhl.html">earlier this month</a>, I hung out for a little bit&nbsp;with the participants of the other seminar,&nbsp;<a href="https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=22372">Knowledge Graphs and their Role in the Knowledge Engineering of the 21st Century</a>. Knowledge graphs are what you would expect them to be, nodes are objects like "Berlin" and "Germany" with directed edges with labels like "capital". Think of having knowledge graphs of hundreds of millions of nodes and how that could help answer queries about the world. These secondary workshops are shorter and focus on creating a new vision, in this case how to maximize the importance of knowledge graphs in an increasing ML-focused world.</p><p>Perhaps we need such a visioning seminar for complexity. While we often get lost in the mathematical questions and techniques in our field, computational complexity is designed to understand the difficulty of solving various problems. Machine learning and advances in optimization should be changing that conversation. If you imagine a world where P = NP (and I did exactly that in chapter 2 of <a href="https://goldenticket.fortnow.com/">my 2013 book</a>) much of what you consider is <a href="https://blog.computationalcomplexity.org/2020/12/optiland.html">starting to happen anyway</a>.&nbsp;ML does fail to break cryptography but then again, isn't this the best of all possible worlds?&nbsp;</p><p>Look at what Scott Aaronson <a href="https://scottaaronson.blog/?p=122#:~:text=If%20P%3DNP%2C%20then%20the,strategy%20would%20be%20Warren%20Buffett.">said back in 2006</a>.</p><blockquote>If P=NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in “creative leaps,” no fundamental gap between solving a problem and recognizing the solution once it’s found. Everyone who could appreciate a symphony would be Mozart; everyone who could follow a step-by-step argument would be Gauss; everyone who could recognize a good investment strategy would be Warren Buffett.&nbsp;</blockquote><p>If I can be a Monet, can Mozart be far behind? ML trading by some hedge funds are beating Warren Buffett but remember if everyone trades perfectly, no one beats the average. Gauss is going to be trickier but <a href="https://www.quantamagazine.org/in-new-math-proofs-artificial-intelligence-plays-to-win-20220307/">it's coming</a>. There's a reason Scott is&nbsp;<a href="https://scottaaronson.blog/?p=6484">spending a year at OpenAI</a>&nbsp;to understand "what, if anything, can computational complexity contribute to a principled understanding of how to get an AI to do what we want and not do what we don’t want".</p><p></p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T14:35:00Z">Thursday, September 29 2022, 14:35</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13599'>A characterization of polynomial time computable functions from the integers to the reals using discrete ordinary differential equations</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Manon Blanc, Olivier Bournez</p><p>In a recent article, the class of functions from the integers to the integers
computable in polynomial time has been characterized using discrete ordinary
differential equations (ODE), also known as finite differences. Doing so, we
pointed out the fundamental role of linear (discrete) ODEs and classical ODE
tools such as changes of variables to capture computability and complexity
measures, or as a tool for programming. In this article, we extend the approach
to a characterization of functions from the integers to the reals computable in
polynomial time in the sense of computable analysis. In particular, we provide
a characterization of such functions in terms of the smallest class of
functions that contains some basic functions, and that is closed by
composition, linear length ODEs, and a natural effective limit schema.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blanc_M/0/1/0/all/0/1">Manon Blanc</a>, <a href="http://arxiv.org/find/cs/1/au:+Bournez_O/0/1/0/all/0/1">Olivier Bournez</a></p><p>In a recent article, the class of functions from the integers to the integers
computable in polynomial time has been characterized using discrete ordinary
differential equations (ODE), also known as finite differences. Doing so, we
pointed out the fundamental role of linear (discrete) ODEs and classical ODE
tools such as changes of variables to capture computability and complexity
measures, or as a tool for programming. In this article, we extend the approach
to a characterization of functions from the integers to the reals computable in
polynomial time in the sense of computable analysis. In particular, we provide
a characterization of such functions in terms of the smallest class of
functions that contains some basic functions, and that is closed by
composition, linear length ODEs, and a natural effective limit schema.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13725'>On the Descriptive Complexity of Groups without Abelian Normal Subgroups</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Joshua A. Grochow, Michael Levet</p><p>In this paper, we explore the descriptive complexity theory of finite groups
by examining the power of the second Ehrenfeucht-Fra\"iss\'e bijective pebble
game in Hella's (Ann. Pure Appl. Log., 1989) heirarchy. This is a
Spoiler-Duplicator game in which Spoiler can place up to two pebbles each
round. While it trivially solves graph isomorphism, it may be nontrivial for
finite groups, and other ternary relational structures. We first provide a
novel generalization of Weisfeiler-Leman (WL) coloring, which we call 2-ary WL.
We then show that the 2-ary WL is equivalent to the second
Ehrenfeucht-Fra\"iss\'e bijective pebble game in Hella's heirarchy.
</p>
<p>Our main result is that, in the pebble game characterization, only $O(1)$
pebbles and $O(1)$ rounds are sufficient to identify all groups without Abelian
normal subgroups (a class of groups for which isomorphism testing is known to
be in $\mathsf{P}$; Babai, Codenotti, &amp; Qiao, ICALP 2012). In particular, we
show that within the first few rounds, Spoiler can force Duplicator to select
an isomorphism between two such groups at each subsequent round. By Hella's
results (\emph{ibid.}), this is equivalent to saying that these groups are
identified by formulas in first-order logic with generalized 2-ary quantifiers,
using only $O(1)$ variables and $O(1)$ quantifier depth.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Grochow_J/0/1/0/all/0/1">Joshua A. Grochow</a>, <a href="http://arxiv.org/find/cs/1/au:+Levet_M/0/1/0/all/0/1">Michael Levet</a></p><p>In this paper, we explore the descriptive complexity theory of finite groups
by examining the power of the second Ehrenfeucht-Fra\"iss\'e bijective pebble
game in Hella's (Ann. Pure Appl. Log., 1989) heirarchy. This is a
Spoiler-Duplicator game in which Spoiler can place up to two pebbles each
round. While it trivially solves graph isomorphism, it may be nontrivial for
finite groups, and other ternary relational structures. We first provide a
novel generalization of Weisfeiler-Leman (WL) coloring, which we call 2-ary WL.
We then show that the 2-ary WL is equivalent to the second
Ehrenfeucht-Fra\"iss\'e bijective pebble game in Hella's heirarchy.
</p>
<p>Our main result is that, in the pebble game characterization, only $O(1)$
pebbles and $O(1)$ rounds are sufficient to identify all groups without Abelian
normal subgroups (a class of groups for which isomorphism testing is known to
be in $\mathsf{P}$; Babai, Codenotti, &amp; Qiao, ICALP 2012). In particular, we
show that within the first few rounds, Spoiler can force Duplicator to select
an isomorphism between two such groups at each subsequent round. By Hella's
results (\emph{ibid.}), this is equivalent to saying that these groups are
identified by formulas in first-order logic with generalized 2-ary quantifiers,
using only $O(1)$ variables and $O(1)$ quantifier depth.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14094'>Dynamic Embeddings of Dynamic Single-Source Upward Planar Graphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Ivor van der Hoog, Irene Parada, Eva Rotenberg</p><p>A directed graph $G$ is upward planar if it admits a planar embedding such
that each edge is $y$-monotone. Unlike planarity testing, upward planarity
testing is NP-hard except in restricted cases, such as when the graph has the
single-source property (i.e. each connected component only has one source).
</p>
<p>In this paper, we present a dynamic algorithm for maintaining a combinatorial
embedding $\mathcal{E}(G)$ of a single-source upward planar graph subject to
edge deletions, edge contractions, edge insertions upwards across a face, and
single-source-preserving vertex splits through specified corners. We
furthermore support changes to the embedding $\mathcal{E}(G)$ on the form of
subgraph flips that mirror or slide the placement of a subgraph that is
connected to the rest of the graph via at most two vertices.
</p>
<p>All update operations are supported as long as the graph remains upward
planar, and all queries are supported as long as the graph remains
single-source. Updates that violate upward planarity are identified as such and
rejected by our update algorithm. We dynamically maintain a linear-size data
structure on $G$ which supports incidence queries between a vertex and a face,
and upward-linkability of vertex pairs. If a pair of vertices are not
upwards-linkable, we facilitate one-flip-linkable queries that point to a
subgraph flip that makes them linkable, if any such flip exists.
</p>
<p>We support all updates and queries in $O(\log^2 n)$ time.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hoog_I/0/1/0/all/0/1">Ivor van der Hoog</a>, <a href="http://arxiv.org/find/cs/1/au:+Parada_I/0/1/0/all/0/1">Irene Parada</a>, <a href="http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1">Eva Rotenberg</a></p><p>A directed graph $G$ is upward planar if it admits a planar embedding such
that each edge is $y$-monotone. Unlike planarity testing, upward planarity
testing is NP-hard except in restricted cases, such as when the graph has the
single-source property (i.e. each connected component only has one source).
</p>
<p>In this paper, we present a dynamic algorithm for maintaining a combinatorial
embedding $\mathcal{E}(G)$ of a single-source upward planar graph subject to
edge deletions, edge contractions, edge insertions upwards across a face, and
single-source-preserving vertex splits through specified corners. We
furthermore support changes to the embedding $\mathcal{E}(G)$ on the form of
subgraph flips that mirror or slide the placement of a subgraph that is
connected to the rest of the graph via at most two vertices.
</p>
<p>All update operations are supported as long as the graph remains upward
planar, and all queries are supported as long as the graph remains
single-source. Updates that violate upward planarity are identified as such and
rejected by our update algorithm. We dynamically maintain a linear-size data
structure on $G$ which supports incidence queries between a vertex and a face,
and upward-linkability of vertex pairs. If a pair of vertices are not
upwards-linkable, we facilitate one-flip-linkable queries that point to a
subgraph flip that makes them linkable, if any such flip exists.
</p>
<p>We support all updates and queries in $O(\log^2 n)$ time.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13712'>A Quantum Optimization Algorithm for Single Machine Total Weighted Tardiness Minimization</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Youhao Steve Wang, Julian Cheng</p><p>A single machine total weighted tardiness minimization (TWTM) problem in
operational planning is considered. The problem is formulated as an NP-hard
constrained combinatorial problem, which has no known deterministic polynomial
complexity solution using classical computing. Based on efficient Grover's
quantum search and Trugenberger's quantum optimization algorithms, a novel
efficient quantum optimization algorithm is proposed to solve the NP-hard
single machine TWTM problem, which makes the desired solution satisfying the
searching constraints and showing the minimal TWT value be measured with the
highest probability.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Youhao Steve Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Julian Cheng</a></p><p>A single machine total weighted tardiness minimization (TWTM) problem in
operational planning is considered. The problem is formulated as an NP-hard
constrained combinatorial problem, which has no known deterministic polynomial
complexity solution using classical computing. Based on efficient Grover's
quantum search and Trugenberger's quantum optimization algorithms, a novel
efficient quantum optimization algorithm is proposed to solve the NP-hard
single machine TWTM problem, which makes the desired solution satisfying the
searching constraints and showing the minimal TWT value be measured with the
highest probability.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13878'>Near-Optimal Adaptive Policies for Serving Stochastically Departing Customers</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Danny Segev</p><p>We consider a multi-stage stochastic optimization problem originally
introduced by Cygan et al. (2013), studying how a single server should
prioritize stochastically departing customers. In this setting, our objective
is to determine an adaptive service policy that maximizes the expected total
reward collected along a discrete planning horizon, in the presence of
customers who are independently departing between one stage and the next with
known stationary probabilities. In spite of its deceiving structural
simplicity, we are unaware of non-trivial results regarding the rigorous design
of optimal or truly near-optimal policies at present time.
</p>
<p>Our main contribution resides in proposing a quasi-polynomial-time
approximation scheme for adaptively serving impatient customers. Specifically,
letting $n$ be the number of underlying customers, our algorithm identifies in
$O( n^{ O_{ \epsilon }( \log^2 n ) } )$ time an adaptive service policy whose
expected reward is within factor $1 - \epsilon$ of the optimal adaptive reward.
Our method for deriving this approximation scheme synthesizes various
stochastic analyses in order to investigate how the adaptive optimum is
affected by alteration to several instance parameters, including the reward
values, the departure probabilities, and the collection of customers itself.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Segev_D/0/1/0/all/0/1">Danny Segev</a></p><p>We consider a multi-stage stochastic optimization problem originally
introduced by Cygan et al. (2013), studying how a single server should
prioritize stochastically departing customers. In this setting, our objective
is to determine an adaptive service policy that maximizes the expected total
reward collected along a discrete planning horizon, in the presence of
customers who are independently departing between one stage and the next with
known stationary probabilities. In spite of its deceiving structural
simplicity, we are unaware of non-trivial results regarding the rigorous design
of optimal or truly near-optimal policies at present time.
</p>
<p>Our main contribution resides in proposing a quasi-polynomial-time
approximation scheme for adaptively serving impatient customers. Specifically,
letting $n$ be the number of underlying customers, our algorithm identifies in
$O( n^{ O_{ \epsilon }( \log^2 n ) } )$ time an adaptive service policy whose
expected reward is within factor $1 - \epsilon$ of the optimal adaptive reward.
Our method for deriving this approximation scheme synthesizes various
stochastic analyses in order to investigate how the adaptive optimum is
affected by alteration to several instance parameters, including the reward
values, the departure probabilities, and the collection of customers itself.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14079'>Worst-case Deterministic Fully-Dynamic Planar 2-vertex Connectivity</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Jacob Holm, Ivor van der Hoog, Eva Rotenberg</p><p>We study dynamic planar graphs with $n$ vertices, subject to edge deletion,
edge contraction, edge insertion across a face, and the splitting of a vertex
in specified corners. We dynamically maintain a combinatorial embedding of such
a planar graph, subject to connectivity and $2$-vertex-connectivity
(biconnectivity) queries between pairs of vertices. Whenever a query pair is
connected and not biconnected, we find the first and last cutvertex separating
them.
</p>
<p>Additionally, we allow local changes to the embedding by flipping the
embedding of a subgraph that is connected by at most two vertices to the rest
of the graph.
</p>
<p>We support all queries and updates in deterministic, worst-case, $O(\log^2
n)$ time, using an $O(n)$-sized data structure.
</p>
<p>Previously, the best bound for fully-dynamic planar biconnectivity (subject
to our set of operations) was an amortised $\tilde{O}(\log^3 n)$ for general
graphs, and algorithms with worst-case polylogarithmic update times were known
only in the partially dynamic (insertion-only or deletion-only) setting.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Holm_J/0/1/0/all/0/1">Jacob Holm</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoog_I/0/1/0/all/0/1">Ivor van der Hoog</a>, <a href="http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1">Eva Rotenberg</a></p><p>We study dynamic planar graphs with $n$ vertices, subject to edge deletion,
edge contraction, edge insertion across a face, and the splitting of a vertex
in specified corners. We dynamically maintain a combinatorial embedding of such
a planar graph, subject to connectivity and $2$-vertex-connectivity
(biconnectivity) queries between pairs of vertices. Whenever a query pair is
connected and not biconnected, we find the first and last cutvertex separating
them.
</p>
<p>Additionally, we allow local changes to the embedding by flipping the
embedding of a subgraph that is connected by at most two vertices to the rest
of the graph.
</p>
<p>We support all queries and updates in deterministic, worst-case, $O(\log^2
n)$ time, using an $O(n)$-sized data structure.
</p>
<p>Previously, the best bound for fully-dynamic planar biconnectivity (subject
to our set of operations) was an amortised $\tilde{O}(\log^3 n)$ for general
graphs, and algorithms with worst-case polylogarithmic update times were known
only in the partially dynamic (insertion-only or deletion-only) setting.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14087'>Adaptive Out-Orientations with Applications</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Aleksander B. G. Christiansen, Jacob Holm, Ivor van der Hoog, Eva Rotenberg, Chris Schwiegelshohn</p><p>We give simple algorithms for maintaining edge-orientations of a
fully-dynamic graph, such that the out-degree of each vertex is bounded. On one
hand, we show how to orient the edges such that the out-degree of each vertex
is proportional to the arboricity $\alpha$ of the graph, in a worst-case update
time of $O(\log^2 n \log \alpha)$. On the other hand, motivated by applications
in dynamic maximal matching, we obtain a different trade-off, namely the
improved worst case update time of $O(\log n \log \alpha)$ for the problem of
maintaining an edge-orientation with at most $O(\alpha + \log n)$ out-edges per
vertex. Since our algorithms have update times with worst-case guarantees, the
number of changes to the solution (i.e. the recourse) is naturally limited.
</p>
<p>Our algorithms make choices based entirely on local information, which makes
them automatically adaptive to the current arboricity of the graph. In other
words, they are arboricity-oblivious, while they are arboricity-sensitive. This
both simplifies and improves upon previous work, by having fewer assumptions or
better asymptotic guarantees.
</p>
<p>As a consequence, one obtains an algorithm with improved efficiency for
maintaining a $(1+\varepsilon)$ approximation of the maximum subgraph density,
and an algorithm for dynamic maximal matching whose worst-case update time is
guaranteed to be upper bounded by $O(\alpha + \log n\log \alpha)$, where
$\alpha$ is the arboricity at the time of the update.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Christiansen_A/0/1/0/all/0/1">Aleksander B. G. Christiansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Holm_J/0/1/0/all/0/1">Jacob Holm</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoog_I/0/1/0/all/0/1">Ivor van der Hoog</a>, <a href="http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1">Eva Rotenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwiegelshohn_C/0/1/0/all/0/1">Chris Schwiegelshohn</a></p><p>We give simple algorithms for maintaining edge-orientations of a
fully-dynamic graph, such that the out-degree of each vertex is bounded. On one
hand, we show how to orient the edges such that the out-degree of each vertex
is proportional to the arboricity $\alpha$ of the graph, in a worst-case update
time of $O(\log^2 n \log \alpha)$. On the other hand, motivated by applications
in dynamic maximal matching, we obtain a different trade-off, namely the
improved worst case update time of $O(\log n \log \alpha)$ for the problem of
maintaining an edge-orientation with at most $O(\alpha + \log n)$ out-edges per
vertex. Since our algorithms have update times with worst-case guarantees, the
number of changes to the solution (i.e. the recourse) is naturally limited.
</p>
<p>Our algorithms make choices based entirely on local information, which makes
them automatically adaptive to the current arboricity of the graph. In other
words, they are arboricity-oblivious, while they are arboricity-sensitive. This
both simplifies and improves upon previous work, by having fewer assumptions or
better asymptotic guarantees.
</p>
<p>As a consequence, one obtains an algorithm with improved efficiency for
maintaining a $(1+\varepsilon)$ approximation of the maximum subgraph density,
and an algorithm for dynamic maximal matching whose worst-case update time is
guaranteed to be upper bounded by $O(\alpha + \log n\log \alpha)$, where
$\alpha$ is the arboricity at the time of the update.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14140'>Time and Energy Efficient Contention Resolution in Asynchronous Shared Channels</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Gianluca De Marco, Dariusz R. Kowalski, Grzegorz Stachowiak</p><p>A number of stations, independently activated over time, is able to
communicate by transmitting and listening to a shared channel in discrete time
slots, and a message is successfully delivered to all stations if and only if
its source station is the only transmitter at a time. Despite a vast amount of
work in the last decades, many fundamental questions remain open in the
realistic situation where stations do not start synchronously but are awaken in
arbitrary times. In this work we present a broad picture of results for the
fundamental problem of Contention resolution, in which each of the contending
stations needs to broadcast successfully its message.
</p>
<p>We show that adaptive algorithms or algorithms with the knowledge of the
contention size $k$ achieve a linear $O(k)$ message latency even if the channel
feedback is restricted to simple acknowledgements in case of successful
transmissions and in the absence of synchronization. This asymptotically
optimal performance cannot be extended to other settings: we prove that there
is no non-adaptive algorithm without the knowledge of contention size $k$
admitting latency $o(k\log k/(\log\log k)^2)$. This means, in particular, that
coding (even random) with acknowledgements is not very efficient on a shared
channel without synchronization or an estimate of the contention size. We also
present a non-adaptive algorithm with no knowledge of contention size that
almost matches the lower bound on latency.
</p>
<p>Finally, despite the absence of a collision detection mechanism, we show that
our algorithms are also efficient in terms of energy, understood as the total
number of transmissions performed by the stations during the execution.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Marco_G/0/1/0/all/0/1">Gianluca De Marco</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowalski_D/0/1/0/all/0/1">Dariusz R. Kowalski</a>, <a href="http://arxiv.org/find/cs/1/au:+Stachowiak_G/0/1/0/all/0/1">Grzegorz Stachowiak</a></p><p>A number of stations, independently activated over time, is able to
communicate by transmitting and listening to a shared channel in discrete time
slots, and a message is successfully delivered to all stations if and only if
its source station is the only transmitter at a time. Despite a vast amount of
work in the last decades, many fundamental questions remain open in the
realistic situation where stations do not start synchronously but are awaken in
arbitrary times. In this work we present a broad picture of results for the
fundamental problem of Contention resolution, in which each of the contending
stations needs to broadcast successfully its message.
</p>
<p>We show that adaptive algorithms or algorithms with the knowledge of the
contention size $k$ achieve a linear $O(k)$ message latency even if the channel
feedback is restricted to simple acknowledgements in case of successful
transmissions and in the absence of synchronization. This asymptotically
optimal performance cannot be extended to other settings: we prove that there
is no non-adaptive algorithm without the knowledge of contention size $k$
admitting latency $o(k\log k/(\log\log k)^2)$. This means, in particular, that
coding (even random) with acknowledgements is not very efficient on a shared
channel without synchronization or an estimate of the contention size. We also
present a non-adaptive algorithm with no knowledge of contention size that
almost matches the lower bound on latency.
</p>
<p>Finally, despite the absence of a collision detection mechanism, we show that
our algorithms are also efficient in terms of energy, understood as the total
number of transmissions performed by the stations during the execution.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14146'>Quantum Subroutine Composition</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Stacey Jeffery</p><p>An important tool in algorithm design is the ability to build algorithms from
other algorithms that run as subroutines. In the case of quantum algorithms, a
subroutine may be called on a superposition of different inputs, which
complicates things. For example, a classical algorithm that calls a subroutine
$Q$ times, where the average probability of querying the subroutine on input
$i$ is $p_i$, and the cost of the subroutine on input $i$ is $T_i$, incurs
expected cost $Q\sum_i p_i E[T_i]$ from all subroutine queries. While this
statement is obvious for classical algorithms, for quantum algorithms, it is
much less so, since naively, if we run a quantum subroutine on a superposition
of inputs, we need to wait for all branches of the superposition to terminate
before we can apply the next operation. We nonetheless show an analogous
quantum statement (*): If $q_i$ is the average query weight on $i$ over all
queries, the cost from all quantum subroutine queries is $Q\sum_i q_i E[T_i]$.
Here the query weight on $i$ for a particular query is the probability of
measuring $i$ in the input register if we were to measure right before the
query.
</p>
<p>We prove this result using the technique of multidimensional quantum walks,
recently introduced in arXiv:2208.13492. We present a more general version of
their quantum walk edge composition result, which yields variable-time quantum
walks, generalizing variable-time quantum search, by, for example, replacing
the update cost with $\sqrt{\sum_{u,v}\pi_u P_{u,v} E[T_{u,v}^2]}$, where
$T_{u,v}$ is the cost to move from vertex $u$ to vertex $v$. The same technique
that allows us to compose quantum subroutines in quantum walks can also be used
to compose in any quantum algorithm, which is how we prove (*).
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Jeffery_S/0/1/0/all/0/1">Stacey Jeffery</a></p><p>An important tool in algorithm design is the ability to build algorithms from
other algorithms that run as subroutines. In the case of quantum algorithms, a
subroutine may be called on a superposition of different inputs, which
complicates things. For example, a classical algorithm that calls a subroutine
$Q$ times, where the average probability of querying the subroutine on input
$i$ is $p_i$, and the cost of the subroutine on input $i$ is $T_i$, incurs
expected cost $Q\sum_i p_i E[T_i]$ from all subroutine queries. While this
statement is obvious for classical algorithms, for quantum algorithms, it is
much less so, since naively, if we run a quantum subroutine on a superposition
of inputs, we need to wait for all branches of the superposition to terminate
before we can apply the next operation. We nonetheless show an analogous
quantum statement (*): If $q_i$ is the average query weight on $i$ over all
queries, the cost from all quantum subroutine queries is $Q\sum_i q_i E[T_i]$.
Here the query weight on $i$ for a particular query is the probability of
measuring $i$ in the input register if we were to measure right before the
query.
</p>
<p>We prove this result using the technique of multidimensional quantum walks,
recently introduced in <a href="/abs/2208.13492">arXiv:2208.13492</a>. We present a more general version of
their quantum walk edge composition result, which yields variable-time quantum
walks, generalizing variable-time quantum search, by, for example, replacing
the update cost with $\sqrt{\sum_{u,v}\pi_u P_{u,v} E[T_{u,v}^2]}$, where
$T_{u,v}$ is the cost to move from vertex $u$ to vertex $v$. The same technique
that allows us to compose quantum subroutines in quantum walks can also be used
to compose in any quantum algorithm, which is how we prove (*).
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14197'>On Computing Exact Means of Time Series Using the Move-Split-Merge Metric</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Jana Holznigenkemper, Christian Komusiewicz, Bernhard Seeger</p><p>Computing an accurate mean of a set of time series is a critical task in
applications like nearest-neighbor classification and clustering of time
series. While there are many distance functions for time series, the most
popular distance function used for the computation of time series means is the
non-metric dynamic time warping (DTW) distance. A recent algorithm for the
exact computation of a DTW-Mean has a running time of
$\mathcal{O}(n^{2k+1}2^kk)$, where $k$ denotes the number of time series and
$n$ their maximum length. In this paper, we study the mean problem for the
move-split-merge (MSM) metric that not only offers high practical accuracy for
time series classification but also carries of the advantages of the metric
properties that enable further diverse applications. The main contribution of
this paper is an exact and efficient algorithm for the MSM-Mean problem of time
series. The running time of our algorithm is $\mathcal{O}(n^{k+3}2^k k^3 )$,
and thus better than the previous DTW-based algorithm. The results of an
experimental comparison confirm the running time superiority of our algorithm
in comparison to the DTW-Mean competitor. Moreover, we introduce a heuristic to
improve the running time significantly without sacrificing much accuracy.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Holznigenkemper_J/0/1/0/all/0/1">Jana Holznigenkemper</a>, <a href="http://arxiv.org/find/cs/1/au:+Komusiewicz_C/0/1/0/all/0/1">Christian Komusiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Seeger_B/0/1/0/all/0/1">Bernhard Seeger</a></p><p>Computing an accurate mean of a set of time series is a critical task in
applications like nearest-neighbor classification and clustering of time
series. While there are many distance functions for time series, the most
popular distance function used for the computation of time series means is the
non-metric dynamic time warping (DTW) distance. A recent algorithm for the
exact computation of a DTW-Mean has a running time of
$\mathcal{O}(n^{2k+1}2^kk)$, where $k$ denotes the number of time series and
$n$ their maximum length. In this paper, we study the mean problem for the
move-split-merge (MSM) metric that not only offers high practical accuracy for
time series classification but also carries of the advantages of the metric
properties that enable further diverse applications. The main contribution of
this paper is an exact and efficient algorithm for the MSM-Mean problem of time
series. The running time of our algorithm is $\mathcal{O}(n^{k+3}2^k k^3 )$,
and thus better than the previous DTW-based algorithm. The results of an
experimental comparison confirm the running time superiority of our algorithm
in comparison to the DTW-Mean competitor. Moreover, we introduce a heuristic to
improve the running time significantly without sacrificing much accuracy.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Wednesday, September 28
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/09/28/phd-and-postdoc-at-irif-apply-by-november-1-2022/'>PhD and postdoc at IRIF (apply by November 1, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The Algorithms &#38; Complexity group at IRIF (CNRS, Université Paris-Cité) in Paris offers multiple PhD and postdoc positions on the theory of quantum computing. The group has expertise in quantum algorithms and quantum complexity theory, with permanent members S. Apers, I. Kerenidis, S. Laplante and F. Magniez. Soft deadline: November 1st, 2022. Website: irif.fr/en/equipes/algocomp/ Email: [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The Algorithms &amp; Complexity group at IRIF (CNRS, Université Paris-Cité) in Paris offers multiple PhD and postdoc positions on the theory of quantum computing. The group has expertise in quantum algorithms and quantum complexity theory, with permanent members S. Apers, I. Kerenidis, S. Laplante and F. Magniez.</p>
<p>Soft deadline: November 1st, 2022.</p>
<p>Website: irif.fr/en/equipes/algocomp/<br />
Email: apers@irif.fr</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T10:12:03Z">Wednesday, September 28 2022, 10:12</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13148'>Strategyproofness-Exposing Mechanism Descriptions</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Yannai A. Gonczarowski, Ori Heffetz, Clayton Thomas</p><p>A menu description defines a mechanism to player $i$ in two steps. Step (1)
uses the reports of other players to describe $i$'s menu: the set of $i$'s
potential outcomes. Step (2) uses $i$'s report to select $i$'s favorite outcome
from her menu. Can menu descriptions better expose strategyproofness, without
sacrificing simplicity? We propose a new, simple menu description of Deferred
Acceptance. We prove that -- in contrast with other common matching mechanisms
-- this menu description must differ substantially from the corresponding
traditional description. We demonstrate, with a lab experiment on two simple
mechanisms, the promise and challenges of menu descriptions.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/econ/1/au:+Gonczarowski_Y/0/1/0/all/0/1">Yannai A. Gonczarowski</a>, <a href="http://arxiv.org/find/econ/1/au:+Heffetz_O/0/1/0/all/0/1">Ori Heffetz</a>, <a href="http://arxiv.org/find/econ/1/au:+Thomas_C/0/1/0/all/0/1">Clayton Thomas</a></p><p>A menu description defines a mechanism to player $i$ in two steps. Step (1)
uses the reports of other players to describe $i$'s menu: the set of $i$'s
potential outcomes. Step (2) uses $i$'s report to select $i$'s favorite outcome
from her menu. Can menu descriptions better expose strategyproofness, without
sacrificing simplicity? We propose a new, simple menu description of Deferred
Acceptance. We prove that -- in contrast with other common matching mechanisms
-- this menu description must differ substantially from the corresponding
traditional description. We demonstrate, with a lab experiment on two simple
mechanisms, the promise and challenges of menu descriptions.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13404'>Polynomial time computable functions over the reals characterized using discrete ordinary differential equations</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Manon Blanc, Olivier Bournez</p><p>The class of functions from the integers to the integers computable in
polynomial time has been characterized recently using discrete ordinary
differential equations (ODE), also known as finite differences. In the
framework of ordinary differential equations, this is very natural to try to
extend the approach to classes of functions over the reals, and not only over
the integers. Recently, an extension of previous characterization was obtained
for functions from the integers to the reals, but the method used in the proof,
based on the existence of a continuous function from the integers to a suitable
discrete set of reals, cannot extend to functions from the reals to the reals,
as such a function cannot exist for clear topological reasons. In this article,
we prove that this is indeed possible to provide an elegant and simple
algebraic characterization of functions from the reals to the reals: we provide
a characterization of such functions as the smallest class of functions that
contains some basic functions, and that is closed by composition, linear length
ODEs, and a natural effective limit schema. This is obtained using an
alternative proof technique based on the construction of specific suitable
functions defined recursively, and a barycentric method. Furthermore, we also
extend previous characterizations in several directions: First, we prove that
there is no need of multiplication. We prove a normal form theorem, with a nice
side effect related to formal neural networks. Indeed, given some fixed error
and some polynomial time t(n), our settings produce effectively some neural
network that computes the function over its domain with the given precision,
for any t(n)-polynomial time computable function f .
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blanc_M/0/1/0/all/0/1">Manon Blanc</a>, <a href="http://arxiv.org/find/cs/1/au:+Bournez_O/0/1/0/all/0/1">Olivier Bournez</a></p><p>The class of functions from the integers to the integers computable in
polynomial time has been characterized recently using discrete ordinary
differential equations (ODE), also known as finite differences. In the
framework of ordinary differential equations, this is very natural to try to
extend the approach to classes of functions over the reals, and not only over
the integers. Recently, an extension of previous characterization was obtained
for functions from the integers to the reals, but the method used in the proof,
based on the existence of a continuous function from the integers to a suitable
discrete set of reals, cannot extend to functions from the reals to the reals,
as such a function cannot exist for clear topological reasons. In this article,
we prove that this is indeed possible to provide an elegant and simple
algebraic characterization of functions from the reals to the reals: we provide
a characterization of such functions as the smallest class of functions that
contains some basic functions, and that is closed by composition, linear length
ODEs, and a natural effective limit schema. This is obtained using an
alternative proof technique based on the construction of specific suitable
functions defined recursively, and a barycentric method. Furthermore, we also
extend previous characterizations in several directions: First, we prove that
there is no need of multiplication. We prove a normal form theorem, with a nice
side effect related to formal neural networks. Indeed, given some fixed error
and some polynomial time t(n), our settings produce effectively some neural
network that computes the function over its domain with the given precision,
for any t(n)-polynomial time computable function f .
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13024'>Improved and Generalized Algorithms for Burning a Planar Point Set</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Prashant Gokhale, J. Mark Keil, Debajyoti Mondal</p><p>Given a set $P$ of points in the plane, a point burning process is a discrete
time process to burn all the points of $P$ where fires must be initiated at the
given points. Specifically, the point burning process starts with a single
burnt point from $P$, and at each subsequent step, burns all the points in the
plane that are within one unit distance from the currently burnt points, as
well as one other unburnt point of $P$ (if exists). The point burning number of
$P$ is the smallest number of steps required to burn all the points of $P$. If
we allow the fire to be initiated anywhere, then the burning process is called
an anywhere burning process, and the corresponding burning number is called
anywhere burning number. Computing the point and anywhere burning number is
known to be NP-hard. In this paper we show that both these problems admit PTAS
in one dimension. We then show that in two dimensions, point burning and
anywhere burning are $(1.96296+\varepsilon)$ and $(1.92188+\varepsilon)$
approximable, respectively, for every $\varepsilon&gt;0$, which improves the
previously known $(2+\varepsilon)$ factor for these problems. We also observe
that a known result on set cover problem can be leveraged to obtain a
2-approximation for burning the maximum number of points in a given number of
steps. We show how the results generalize if we allow the points to have
different fire spreading rates. Finally, we prove that even if the burning
sources are given as input, finding a point burning sequence itself is NP-hard.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gokhale_P/0/1/0/all/0/1">Prashant Gokhale</a>, <a href="http://arxiv.org/find/cs/1/au:+Keil_J/0/1/0/all/0/1">J. Mark Keil</a>, <a href="http://arxiv.org/find/cs/1/au:+Mondal_D/0/1/0/all/0/1">Debajyoti Mondal</a></p><p>Given a set $P$ of points in the plane, a point burning process is a discrete
time process to burn all the points of $P$ where fires must be initiated at the
given points. Specifically, the point burning process starts with a single
burnt point from $P$, and at each subsequent step, burns all the points in the
plane that are within one unit distance from the currently burnt points, as
well as one other unburnt point of $P$ (if exists). The point burning number of
$P$ is the smallest number of steps required to burn all the points of $P$. If
we allow the fire to be initiated anywhere, then the burning process is called
an anywhere burning process, and the corresponding burning number is called
anywhere burning number. Computing the point and anywhere burning number is
known to be NP-hard. In this paper we show that both these problems admit PTAS
in one dimension. We then show that in two dimensions, point burning and
anywhere burning are $(1.96296+\varepsilon)$ and $(1.92188+\varepsilon)$
approximable, respectively, for every $\varepsilon&gt;0$, which improves the
previously known $(2+\varepsilon)$ factor for these problems. We also observe
that a known result on set cover problem can be leveraged to obtain a
2-approximation for burning the maximum number of points in a given number of
steps. We show how the results generalize if we allow the points to have
different fire spreading rates. Finally, we prove that even if the burning
sources are given as input, finding a point burning sequence itself is NP-hard.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13311'>Optimal Placement of Base Stations in Border Surveillance using Limited Capacity Drones</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: S. Bereg, J.M. D&#xed;az-B&#xe1;&#xf1;ez, M. Haghpanah, P. Horn, M.A. Lopez, N. Mar&#xed;n, A. Ram&#xed;rez-Vigueras, F. Rodr&#xed;guez, O. Sol&#xe9;-Pi, A. Stevens, J. Urrutia</p><p>Imagine an island modeled as a simple polygon $\P$ with $n$ vertices whose
coastline we wish to monitor. We consider the problem of building the minimum
number of refueling stations along the boundary of $\P$ in such a way that a
drone can follow a polygonal route enclosing the island without running out of
fuel. A drone can fly a maximum distance $d$ between consecutive stations and
is restricted to move either along the boundary of $\P$ or its exterior (i.e.,
over water). We present an algorithm that, given $\mathcal P$, finds the
locations for a set of refueling stations whose cardinality is at most the
optimal plus one. The time complexity of this algorithm is $O(n^2 + \frac{L}{d}
n)$, where $L$ is the length of $\mathcal P$. We also present an algorithm that
returns an additive $\epsilon$-approximation for the problem of minimizing the
fuel capacity required for the drones when we are allowed to place $k$ base
stations around the boundary of the island; this algorithm also finds the
locations of these refueling stations. Finally, we propose a practical
discretization heuristic which, under certain conditions, can be used to
certify optimality of the results.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bereg_S/0/1/0/all/0/1">S. Bereg</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1">J.M. D&#xed;az-B&#xe1;&#xf1;ez</a>, <a href="http://arxiv.org/find/cs/1/au:+Haghpanah_M/0/1/0/all/0/1">M. Haghpanah</a>, <a href="http://arxiv.org/find/cs/1/au:+Horn_P/0/1/0/all/0/1">P. Horn</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_M/0/1/0/all/0/1">M.A. Lopez</a>, <a href="http://arxiv.org/find/cs/1/au:+Marin_N/0/1/0/all/0/1">N. Mar&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramirez_Vigueras_A/0/1/0/all/0/1">A. Ram&#xed;rez-Vigueras</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_F/0/1/0/all/0/1">F. Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Sole_Pi_O/0/1/0/all/0/1">O. Sol&#xe9;-Pi</a>, <a href="http://arxiv.org/find/cs/1/au:+Stevens_A/0/1/0/all/0/1">A. Stevens</a>, <a href="http://arxiv.org/find/cs/1/au:+Urrutia_J/0/1/0/all/0/1">J. Urrutia</a></p><p>Imagine an island modeled as a simple polygon $\P$ with $n$ vertices whose
coastline we wish to monitor. We consider the problem of building the minimum
number of refueling stations along the boundary of $\P$ in such a way that a
drone can follow a polygonal route enclosing the island without running out of
fuel. A drone can fly a maximum distance $d$ between consecutive stations and
is restricted to move either along the boundary of $\P$ or its exterior (i.e.,
over water). We present an algorithm that, given $\mathcal P$, finds the
locations for a set of refueling stations whose cardinality is at most the
optimal plus one. The time complexity of this algorithm is $O(n^2 + \frac{L}{d}
n)$, where $L$ is the length of $\mathcal P$. We also present an algorithm that
returns an additive $\epsilon$-approximation for the problem of minimizing the
fuel capacity required for the drones when we are allowed to place $k$ base
stations around the boundary of the island; this algorithm also finds the
locations of these refueling stations. Finally, we propose a practical
discretization heuristic which, under certain conditions, can be used to
certify optimality of the results.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13538'>Mathematics and Flamenco: An Unexpected Partnership</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Jos&#xe9;-Miguel D&#xed;az-B&#xe1;&#xf1;ez</p><p>In this paper, we present a series of mathematical problems which throw
interesting lights on flamenco music. More specifically, these are problems in
discrete and computational mathematics suggested by an analytical (not
compositional) examination of flamenco ``cante'' (singing). As a consequence,
since the problems are taken from a culturally specific context, the examples
can make more effective mathematics education.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1">Jos&#xe9;-Miguel D&#xed;az-B&#xe1;&#xf1;ez</a></p><p>In this paper, we present a series of mathematical problems which throw
interesting lights on flamenco music. More specifically, these are problems in
discrete and computational mathematics suggested by an analytical (not
compositional) examination of flamenco ``cante'' (singing). As a consequence,
since the problems are taken from a culturally specific context, the examples
can make more effective mathematics education.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13028'>How to Sample From The Limiting Distribution of a Continuous-Time Quantum Walk</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Javad Doliskani</p><p>We introduce $\varepsilon$-projectors, using which we can sample from
limiting distributions of continuous-time quantum walks. The standard algorithm
for sampling from a distribution that is close to the limiting distribution of
a given quantum walk is to run the quantum walk for a time chosen uniformly at
random from a large interval, and measure the resulting quantum state. This
approach usually results in an exponential running time.
</p>
<p>We show that, using $\varepsilon$-projectors, we can sample exactly from the
limiting distribution. In the black-box setting, where we only have query
access to the adjacency matrix of the graph, our sampling algorithm runs in
time proportional to $\Delta^{-1}$, where $\Delta$ is the minimum spacing
between the distinct eigenvalues of the graph. In the non-black-box setting, we
give examples of graphs for which our algorithm runs exponentially faster than
the standard sampling algorithm.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Doliskani_J/0/1/0/all/0/1">Javad Doliskani</a></p><p>We introduce $\varepsilon$-projectors, using which we can sample from
limiting distributions of continuous-time quantum walks. The standard algorithm
for sampling from a distribution that is close to the limiting distribution of
a given quantum walk is to run the quantum walk for a time chosen uniformly at
random from a large interval, and measure the resulting quantum state. This
approach usually results in an exponential running time.
</p>
<p>We show that, using $\varepsilon$-projectors, we can sample exactly from the
limiting distribution. In the black-box setting, where we only have query
access to the adjacency matrix of the graph, our sampling algorithm runs in
time proportional to $\Delta^{-1}$, where $\Delta$ is the minimum spacing
between the distinct eigenvalues of the graph. In the non-black-box setting, we
give examples of graphs for which our algorithm runs exponentially faster than
the standard sampling algorithm.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13063'>Quantum-Inspired Perfect Matching under Vertex-Color Constraints</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Moshe Y. Vardi, Zhiwei Zhang</p><p>We propose and study the graph-theoretical problem PM-VC: perfect matching
under vertex-color constraints on graphs with bi-colored edges. PM-VC is of
special interest because of its motivation from quantum-state identification
and quantum-experiment design, as well as its rich expressiveness, i.e., PM-VC
subsumes many constrained matching problems naturally, such as exact perfect
matching. We give complexity and algorithmic results for PM-VC under two types
of vertex color constraints: 1) symmetric constraints (PM-VC-Sym) and 2)
decision-diagram constraints (PM-VC-DD).
</p>
<p>We prove that PM-VC-Sym is in RNC via a symbolic determinant algorithm, which
can be derandomized on planar graphs. Moreover, PM-VC-Sym can be expressed in
extended MSO, which encourages our design of an efficient dynamic programming
algorithm for PM-VC-Sym on bounded-treewidth graphs. For PM-VC-DD, we reveal
its NP-hardness by a graph-gadget technique. Our novel results for PM-VC
provide insights to both constrained matching and scalable quantum experiment
design.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Vardi_M/0/1/0/all/0/1">Moshe Y. Vardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiwei Zhang</a></p><p>We propose and study the graph-theoretical problem PM-VC: perfect matching
under vertex-color constraints on graphs with bi-colored edges. PM-VC is of
special interest because of its motivation from quantum-state identification
and quantum-experiment design, as well as its rich expressiveness, i.e., PM-VC
subsumes many constrained matching problems naturally, such as exact perfect
matching. We give complexity and algorithmic results for PM-VC under two types
of vertex color constraints: 1) symmetric constraints (PM-VC-Sym) and 2)
decision-diagram constraints (PM-VC-DD).
</p>
<p>We prove that PM-VC-Sym is in RNC via a symbolic determinant algorithm, which
can be derandomized on planar graphs. Moreover, PM-VC-Sym can be expressed in
extended MSO, which encourages our design of an efficient dynamic programming
algorithm for PM-VC-Sym on bounded-treewidth graphs. For PM-VC-DD, we reveal
its NP-hardness by a graph-gadget technique. Our novel results for PM-VC
provide insights to both constrained matching and scalable quantum experiment
design.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13134'>An $O(3.82^k)$ Time FPT Algorithm for Convex Flip Distance</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Haohong Li, Ge Xia</p><p>Let ${\cal P}$ be a convex polygon in the plane, and let ${\cal T}$ be a
triangulation of ${\cal P}$. An edge $e$ in ${\cal T}$ is called a diagonal if
it is shared by two triangles in ${\cal T}$. A {\em flip} of a diagonal $e$ is
the operation of removing $e$ and adding the opposite diagonal of the resulting
quadrilateral to obtain a new triangulation of ${\cal P}$ from ${\cal T}$. The
{\em flip distance} between two triangulations of ${\cal P}$ is the minimum
number of flips needed to transform one triangulation into the other. The {\sc
Convex Flip Distance} problem asks if the flip distance between two given
triangulations of ${\cal P}$ is at most $k$, for some given parameter $k$.
</p>
<p>We present an FPT algorithm for the {\sc Convex Flip Distance} problem that
runs in time $O(3.82^{k})$ and uses polynomial space, where $k$ is the number
of flips. This algorithm significantly improves the previous best FPT
algorithms for the problem.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haohong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1">Ge Xia</a></p><p>Let ${\cal P}$ be a convex polygon in the plane, and let ${\cal T}$ be a
triangulation of ${\cal P}$. An edge $e$ in ${\cal T}$ is called a diagonal if
it is shared by two triangles in ${\cal T}$. A {\em flip} of a diagonal $e$ is
the operation of removing $e$ and adding the opposite diagonal of the resulting
quadrilateral to obtain a new triangulation of ${\cal P}$ from ${\cal T}$. The
{\em flip distance} between two triangulations of ${\cal P}$ is the minimum
number of flips needed to transform one triangulation into the other. The {\sc
Convex Flip Distance} problem asks if the flip distance between two given
triangulations of ${\cal P}$ is at most $k$, for some given parameter $k$.
</p>
<p>We present an FPT algorithm for the {\sc Convex Flip Distance} problem that
runs in time $O(3.82^{k})$ and uses polynomial space, where $k$ is the number
of flips. This algorithm significantly improves the previous best FPT
algorithms for the problem.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13175'>Partial and Simultaneous Transitive Orientations via Modular Decomposition</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Miriam M&#xfc;nch, Ignaz Rutter, Peter Stumpf</p><p>A natural generalization of the recognition problem for a geometric graph
class is the problem of extending a representation of a subgraph to a
representation of the whole graph. A related problem is to find representations
for multiple input graphs that coincide on subgraphs shared by the input
graphs. A common restriction is the sunflower case where the shared graph is
the same for each pair of input graphs. These problems translate to the setting
of comparability graphs where the representations correspond to transitive
orientations of their edges. We use modular decompositions to improve the
runtime for the orientation extension problem and the sunflower orientation
problem to linear time. We apply these results to improve the runtime for the
partial representation problem and the sunflower case of the simultaneous
representation problem for permutation graphs to linear time. We also give the
first efficient algorithms for these problems on circular permutation graphs.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Munch_M/0/1/0/all/0/1">Miriam M&#xfc;nch</a>, <a href="http://arxiv.org/find/cs/1/au:+Rutter_I/0/1/0/all/0/1">Ignaz Rutter</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpf_P/0/1/0/all/0/1">Peter Stumpf</a></p><p>A natural generalization of the recognition problem for a geometric graph
class is the problem of extending a representation of a subgraph to a
representation of the whole graph. A related problem is to find representations
for multiple input graphs that coincide on subgraphs shared by the input
graphs. A common restriction is the sunflower case where the shared graph is
the same for each pair of input graphs. These problems translate to the setting
of comparability graphs where the representations correspond to transitive
orientations of their edges. We use modular decompositions to improve the
runtime for the orientation extension problem and the sunflower orientation
problem to linear time. We apply these results to improve the runtime for the
partial representation problem and the sunflower case of the simultaneous
representation problem for permutation graphs to linear time. We also give the
first efficient algorithms for these problems on circular permutation graphs.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13355'>Algorithms for Large-scale Network Analysis and the NetworKit Toolkit</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Eugenio Angriman, Alexander van der Grinten, Michael Hamann, Henning Meyerhenke, Manuel Penschuck</p><p>The abundance of massive network data in a plethora of applications makes
scalable analysis algorithms and software tools necessary to generate knowledge
from such data in reasonable time. Addressing scalability as well as other
requirements such as good usability and a rich feature set, the open-source
software NetworKit has established itself as a popular tool for large-scale
network analysis. This chapter provides a brief overview of the contributions
to NetworKit made by the DFG Priority Programme SPP 1736 Algorithms for Big
Data. Algorithmic contributions in the areas of centrality computations,
community detection, and sparsification are in the focus, but we also mention
several other aspects -- such as current software engineering principles of the
project and ways to visualize network data within a NetworKit-based workflow.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Angriman_E/0/1/0/all/0/1">Eugenio Angriman</a>, <a href="http://arxiv.org/find/cs/1/au:+Grinten_A/0/1/0/all/0/1">Alexander van der Grinten</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamann_M/0/1/0/all/0/1">Michael Hamann</a>, <a href="http://arxiv.org/find/cs/1/au:+Meyerhenke_H/0/1/0/all/0/1">Henning Meyerhenke</a>, <a href="http://arxiv.org/find/cs/1/au:+Penschuck_M/0/1/0/all/0/1">Manuel Penschuck</a></p><p>The abundance of massive network data in a plethora of applications makes
scalable analysis algorithms and software tools necessary to generate knowledge
from such data in reasonable time. Addressing scalability as well as other
requirements such as good usability and a rich feature set, the open-source
software NetworKit has established itself as a popular tool for large-scale
network analysis. This chapter provides a brief overview of the contributions
to NetworKit made by the DFG Priority Programme SPP 1736 Algorithms for Big
Data. Algorithmic contributions in the areas of centrality computations,
community detection, and sparsification are in the focus, but we also mention
several other aspects -- such as current software engineering principles of the
project and ways to visualize network data within a NetworKit-based workflow.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Tuesday, September 27
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://blog.simons.berkeley.edu/2022/09/the-blooming-of-the-c3-ltc-flowers/'>The Blooming of the \(c^3\) LTC Flowers</a></h3>
          <p class='item-feed'>from <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          by Prahladh Harsha The last year (2021–22) has seen some amazing new constructions of locally testable codes with constant rate and constant fractional distance and testable with a constant number of queries, sometimes referred to as \(c^3\) LTCs [DELLM22, PK22]. &#8230; Continue reading &#8594;<p>By Simons Institute Editor</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          by Prahladh Harsha The last year (2021–22) has seen some amazing new constructions of locally testable codes with constant rate and constant fractional distance and testable with a constant number of queries, sometimes referred to as \(c^3\) LTCs [DELLM22, PK22]. &#8230; <a href="https://blog.simons.berkeley.edu/2022/09/the-blooming-of-the-c3-ltc-flowers/">Continue reading <span class="meta-nav">&#8594;</span></a><p class="authors">By Simons Institute Editor</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T17:51:01Z">Tuesday, September 27 2022, 17:51</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/09/27/postdoc-in-quantum-algorithms-complexity-at-university-of-warwick-apply-by-october-18-2022/'>Postdoc in Quantum Algorithms & Complexity at University of Warwick (apply by October 18, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          We seek to appoint a postdoc for 24 months starting in March 2023 or as soon as possible thereafter. The aim is to study property testing algorithms for quantum channels as part of a collaboration between CS &#38; Physics at Warwick, led by Animesh Datta and Tom Gur. For informal enquires, email your CV, explaining [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>We seek to appoint a postdoc for 24 months starting in March 2023 or as soon as possible thereafter. The aim is to study property testing algorithms for quantum channels as part of a collaboration between CS &amp; Physics at Warwick, led by Animesh Datta and Tom Gur.</p>
<p>For informal enquires, email your CV, explaining your suitability for the position.</p>
<p>Website: <a href="https://atsv7.wcn.co.uk/search_engine/jobs.cgi?owner=5062452&amp;ownertype=fair&amp;jcode=1888004&amp;vt_template=1457&amp;adminview=1">https://atsv7.wcn.co.uk/search_engine/jobs.cgi?owner=5062452&amp;ownertype=fair&amp;jcode=1888004&amp;vt_template=1457&amp;adminview=1</a><br />
Email: animesh.datta@warwick.ac.uk; tom.gur@warwick.ac.uk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T15:22:22Z">Tuesday, September 27 2022, 15:22</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://eccc.weizmann.ac.il/report/2022/137'>TR22-137 |  On blocky ranks of matrices | 

	Daniel Avraham , 

	Amir Yehudayoff</a></h3>
          <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          A matrix is blocky if it is a blowup of a permutation matrix. The blocky rank of a matrix M is the minimum number of blocky matrices that linearly span M. Hambardzumyan, Hatami and Hatami defined blocky rank and showed that it is connected to communication complexity and operator theory. We describe additional connections to circuit complexity and combinatorics, and we prove upper and lower bounds on blocky rank in various contexts.
        
        </div>

        <div class='item-content item-summary'>
        
          
          A matrix is blocky if it is a blowup of a permutation matrix. The blocky rank of a matrix M is the minimum number of blocky matrices that linearly span M. Hambardzumyan, Hatami and Hatami defined blocky rank and showed that it is connected to communication complexity and operator theory. We describe additional connections to circuit complexity and combinatorics, and we prove upper and lower bounds on blocky rank in various contexts.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T12:24:21Z">Tuesday, September 27 2022, 12:24</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://blog.computationalcomplexity.org/2022/09/is-complexity-of-vertex-cover-of-degree.html'>Is the complexity of approximating Vertex Cover of degree 3 open? (ADDED LATER-NO)</a></h3>
          <p class='item-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>&nbsp;RECALL:</p><p>A max-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that</p><p>&nbsp;ALG(\epsilon) \ge (1-\epsilon)f(x).</p><p><br></p><p>A min-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that</p><p>&nbsp;ALG(\epsilon) \le (1+\epsilon)f(x).</p><p><br></p><p>(Note that the poly can depend on epsilon so it may be something like n^{1/epsilon}.)</p><p><br></p><p>MAX3SAT is, given a formula with \le 3 literals per clause, find an assignment</p><p>that maximized the number of clauses satisfied.</p><p><br></p><p>VCB-a is Vertex cover where graphs have degree \le a</p><p><br></p><p>The following are known:</p><p>0) MAX3SAT is in APX.</p><p>1) The PCP paper,&nbsp;here, showed that if MAX3SAT has a PTAS then P=NP.</p><p>2) Papadimitriou and Yannakakis (here)&nbsp; had showed much earlier that MAX3SAT \le VCB-4 with an approx preserving reduction.</p><p>3) From (1) and (2) we have that VCB-4 has a PTAS then P=NP. (VC is in APX by an easy 2-approx).</p><p>4) Clearly VCB-2 is in P.</p><p>The following seems to be open, though if you know otherwise pleae leave a comment:</p><p><br></p><p>Is VCB-3 a) in P? b) NPC? (ADDED LATER- NPC- See comments.)&nbsp;</p><p>Is the following true: if VCB-3 has a PTAS then P=NP. (ADDED LATER- NO PTAS-See Comments)</p><p><br></p><p>NOTE- all of the above is true for Ind Set-4 and Dom Set-4. So that leads to more open problems.</p><br><p>By gasarch</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>&nbsp;RECALL:</p><p>A max-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that</p><p>&nbsp;ALG(\epsilon) \ge (1-\epsilon)f(x).</p><p><br /></p><p>A min-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that</p><p>&nbsp;ALG(\epsilon) \le (1+\epsilon)f(x).</p><p><br /></p><p>(Note that the poly can depend on epsilon so it may be something like n^{1/epsilon}.)</p><p><br /></p><p>MAX3SAT is, given a formula with \le 3 literals per clause, find an assignment</p><p>that maximized the number of clauses satisfied.</p><p><br /></p><p>VCB-a is Vertex cover where graphs have degree \le a</p><p><br /></p><p>The following are known:</p><p>0) MAX3SAT is in APX.</p><p>1) The PCP paper,&nbsp;<a href="https://doi.org/10.1145/278298.278306">here</a>, showed that if MAX3SAT has a PTAS then P=NP.</p><p>2) Papadimitriou and Yannakakis (<a href="https://doi.org/10.1016/0022-0000(91)90023-X">here</a>)&nbsp; had showed much earlier that MAX3SAT \le VCB-4 with an approx preserving reduction.</p><p>3) From (1) and (2) we have that VCB-4 has a PTAS then P=NP. (VC is in APX by an easy 2-approx).</p><p>4) Clearly VCB-2 is in P.</p><p>The following seems to be open, though if you know otherwise pleae leave a comment:</p><p><br /></p><p>Is VCB-3 a) in P? b) NPC? (ADDED LATER- NPC- See comments.)&nbsp;</p><p>Is the following true: if VCB-3 has a PTAS then P=NP. (ADDED LATER- NO PTAS-See Comments)</p><p><br /></p><p>NOTE- all of the above is true for Ind Set-4 and Dom Set-4. So that leads to more open problems.</p><div><br /></div><p class="authors">By gasarch</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T02:02:00Z">Tuesday, September 27 2022, 02:02</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12168'>A characterization of functions over the integers computable in polynomial time using discrete differential equations</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Olivier Bournez, Arnaud Durand</p><p>This paper studies the expressive and computational power of discrete
Ordinary Differential Equations (ODEs), a.k.a. (Ordinary) Difference Equations.
It presents a new framework using these equations as a central tool for
computation and algorithm design. We present the general theory of discrete
ODEs for computation theory, we illustrate this with various examples of
algorithms, and we provide several implicit characterizations of complexity and
computability classes.
</p>
<p>The proposed framework presents an original point of view on complexity and
computation classes. It unifies several constructions that have been proposed
for characterizing these classes including classical approaches in implicit
complexity using restricted recursion schemes, as well as recent
characterizations of computability and complexity by classes of continuous
ordinary differential equations. It also helps understanding the relationships
between analog computations and classical discrete models of computation
theory.
</p>
<p>At a more technical point of view, this paper points out the fundamental role
of linear (discrete) ODEs and classical ODE tools such as changes of variables
to capture computability and complexity measures, or as a tool for programming
many algorithms.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bournez_O/0/1/0/all/0/1">Olivier Bournez</a>, <a href="http://arxiv.org/find/cs/1/au:+Durand_A/0/1/0/all/0/1">Arnaud Durand</a></p><p>This paper studies the expressive and computational power of discrete
Ordinary Differential Equations (ODEs), a.k.a. (Ordinary) Difference Equations.
It presents a new framework using these equations as a central tool for
computation and algorithm design. We present the general theory of discrete
ODEs for computation theory, we illustrate this with various examples of
algorithms, and we provide several implicit characterizations of complexity and
computability classes.
</p>
<p>The proposed framework presents an original point of view on complexity and
computation classes. It unifies several constructions that have been proposed
for characterizing these classes including classical approaches in implicit
complexity using restricted recursion schemes, as well as recent
characterizations of computability and complexity by classes of continuous
ordinary differential equations. It also helps understanding the relationships
between analog computations and classical discrete models of computation
theory.
</p>
<p>At a more technical point of view, this paper points out the fundamental role
of linear (discrete) ODEs and classical ODE tools such as changes of variables
to capture computability and complexity measures, or as a tool for programming
many algorithms.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11817'>An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Matthew Jones, Huy L&#xea; Nguyen, Thy Nguyen</p><p>Recently a multi-agent variant of the classical multi-armed bandit was
proposed to tackle fairness issues in online learning. Inspired by a long line
of work in social choice and economics, the goal is to optimize the Nash social
welfare instead of the total utility. Unfortunately previous algorithms either
are not efficient or achieve sub-optimal regret in terms of the number of
rounds $T$. We propose a new efficient algorithm with lower regret than even
previous inefficient ones. For $N$ agents, $K$ arms, and $T$ rounds, our
approach has a regret bound of $\tilde{O}(\sqrt{NKT} + NK)$. This is an
improvement to the previous approach, which has regret bound of $\tilde{O}(
\min(NK, \sqrt{N} K^{3/2})\sqrt{T})$. We also complement our efficient
algorithm with an inefficient approach with $\tilde{O}(\sqrt{KT} + N^2K)$
regret. The experimental findings confirm the effectiveness of our efficient
algorithm compared to the previous approaches.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1">Matthew Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Huy L&#xea; Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thy Nguyen</a></p><p>Recently a multi-agent variant of the classical multi-armed bandit was
proposed to tackle fairness issues in online learning. Inspired by a long line
of work in social choice and economics, the goal is to optimize the Nash social
welfare instead of the total utility. Unfortunately previous algorithms either
are not efficient or achieve sub-optimal regret in terms of the number of
rounds $T$. We propose a new efficient algorithm with lower regret than even
previous inefficient ones. For $N$ agents, $K$ arms, and $T$ rounds, our
approach has a regret bound of $\tilde{O}(\sqrt{NKT} + NK)$. This is an
improvement to the previous approach, which has regret bound of $\tilde{O}(
\min(NK, \sqrt{N} K^{3/2})\sqrt{T})$. We also complement our efficient
algorithm with an inefficient approach with $\tilde{O}(\sqrt{KT} + N^2K)$
regret. The experimental findings confirm the effectiveness of our efficient
algorithm compared to the previous approaches.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11934'>The Online Knapsack Problem with Departures</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Bo Sun, Lin Yang, Mohammad Hajiesmaili, Adam Wierman, John C.S. Lui, Don Towsley, Danny H.K. Tsang</p><p>The online knapsack problem is a classic online resource allocation problem
in networking and operations research. Its basic version studies how to pack
online arriving items of different sizes and values into a capacity-limited
knapsack. In this paper, we study a general version that includes item
departures, while also considering multiple knapsacks and multi-dimensional
item sizes. We design a threshold-based online algorithm and prove that the
algorithm can achieve order-optimal competitive ratios. Beyond worst-case
performance guarantees, we also aim to achieve near-optimal average performance
under typical instances. Towards this goal, we propose a data-driven online
algorithm that learns within a policy-class that guarantees a worst-case
performance bound. In trace-driven experiments, we show that our data-driven
algorithm outperforms other benchmark algorithms in an application of online
knapsack to job scheduling for cloud computing.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1">Bo Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajiesmaili_M/0/1/0/all/0/1">Mohammad Hajiesmaili</a>, <a href="http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1">Adam Wierman</a>, <a href="http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1">John C.S. Lui</a>, <a href="http://arxiv.org/find/cs/1/au:+Towsley_D/0/1/0/all/0/1">Don Towsley</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsang_D/0/1/0/all/0/1">Danny H.K. Tsang</a></p><p>The online knapsack problem is a classic online resource allocation problem
in networking and operations research. Its basic version studies how to pack
online arriving items of different sizes and values into a capacity-limited
knapsack. In this paper, we study a general version that includes item
departures, while also considering multiple knapsacks and multi-dimensional
item sizes. We design a threshold-based online algorithm and prove that the
algorithm can achieve order-optimal competitive ratios. Beyond worst-case
performance guarantees, we also aim to achieve near-optimal average performance
under typical instances. Towards this goal, we propose a data-driven online
algorithm that learns within a policy-class that guarantees a worst-case
performance bound. In trace-driven experiments, we show that our data-driven
algorithm outperforms other benchmark algorithms in an application of online
knapsack to job scheduling for cloud computing.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11936'>Online Admission Control and Rebalancing in Payment Channel Networks</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mahsa Bastankhah, Krishnendu Chatterjee, Mohammad Ali Maddah-Ali, Stefan Schmid, Jakub Svoboda, Michelle Yeo</p><p>Payment channel networks (PCNs) are a promising technology to improve the
scalability of cryptocurrencies. PCNs, however, face the challenge that the
frequent usage of certain routes may deplete channels in one direction, and
hence prevent further transactions. In order to reap the full potential of
PCNs, recharging and rebalancing mechanisms are required to provision channels,
as well as an admission control logic to decide which transactions to reject in
case capacity is insufficient. This paper presents a formal model of this
optimisation problem. In particular, we consider an online algorithms
perspective, where transactions arrive over time in an unpredictable manner.
Our main contributions are competitive online algorithms which come with
provable guarantees over time. We empirically evaluate our algorithms on
randomly generated transactions to compare the average performance of our
algorithms to our theoretical bounds. We also show how this model and approach
differs from related problems in classic communication networks.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bastankhah_M/0/1/0/all/0/1">Mahsa Bastankhah</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_K/0/1/0/all/0/1">Krishnendu Chatterjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Maddah_Ali_M/0/1/0/all/0/1">Mohammad Ali Maddah-Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Svoboda_J/0/1/0/all/0/1">Jakub Svoboda</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_M/0/1/0/all/0/1">Michelle Yeo</a></p><p>Payment channel networks (PCNs) are a promising technology to improve the
scalability of cryptocurrencies. PCNs, however, face the challenge that the
frequent usage of certain routes may deplete channels in one direction, and
hence prevent further transactions. In order to reap the full potential of
PCNs, recharging and rebalancing mechanisms are required to provision channels,
as well as an admission control logic to decide which transactions to reject in
case capacity is insufficient. This paper presents a formal model of this
optimisation problem. In particular, we consider an online algorithms
perspective, where transactions arrive over time in an unpredictable manner.
Our main contributions are competitive online algorithms which come with
provable guarantees over time. We empirically evaluate our algorithms on
randomly generated transactions to compare the average performance of our
algorithms to our theoretical bounds. We also show how this model and approach
differs from related problems in classic communication networks.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12013'>Non-monotonic Resource Utilization in the Bandits with Knapsacks Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Raunak Kumar, Robert Kleinberg</p><p>Bandits with knapsacks (BwK) is an influential model of sequential
decision-making under uncertainty that incorporates resource consumption
constraints. In each round, the decision-maker observes an outcome consisting
of a reward and a vector of nonnegative resource consumptions, and the budget
of each resource is decremented by its consumption. In this paper we introduce
a natural generalization of the stochastic BwK problem that allows
non-monotonic resource utilization. In each round, the decision-maker observes
an outcome consisting of a reward and a vector of resource drifts that can be
positive, negative or zero, and the budget of each resource is incremented by
its drift. Our main result is a Markov decision process (MDP) policy that has
constant regret against a linear programming (LP) relaxation when the
decision-maker knows the true outcome distributions. We build upon this to
develop a learning algorithm that has logarithmic regret against the same LP
relaxation when the decision-maker does not know the true outcome
distributions. We also present a reduction from BwK to our model that shows our
regret bound matches existing results.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Raunak Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleinberg_R/0/1/0/all/0/1">Robert Kleinberg</a></p><p>Bandits with knapsacks (BwK) is an influential model of sequential
decision-making under uncertainty that incorporates resource consumption
constraints. In each round, the decision-maker observes an outcome consisting
of a reward and a vector of nonnegative resource consumptions, and the budget
of each resource is decremented by its consumption. In this paper we introduce
a natural generalization of the stochastic BwK problem that allows
non-monotonic resource utilization. In each round, the decision-maker observes
an outcome consisting of a reward and a vector of resource drifts that can be
positive, negative or zero, and the budget of each resource is incremented by
its drift. Our main result is a Markov decision process (MDP) policy that has
constant regret against a linear programming (LP) relaxation when the
decision-maker knows the true outcome distributions. We build upon this to
develop a learning algorithm that has logarithmic regret against the same LP
relaxation when the decision-maker does not know the true outcome
distributions. We also present a reduction from BwK to our model that shows our
regret bound matches existing results.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12021'>Improving the Bounds of the Online Dynamic Power Management Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Ya-Chun Liang, Kazuo Iwama, Chung-Shou Liao</p><p>We investigate the {\em power-down mechanism} which decides when a machine
transitions between states such that the total energy consumption,
characterized by execution cost, idle cost and switching cost, is minimized. In
contrast to most of the previous studies on the offline model, we focus on the
online model in which a sequence of jobs with their release time, execution
time and deadline, arrive in an online fashion. More precisely, we exploit a
different switching on and off strategy and present an upper bound of 3, and
further show a lower bound of 2.1, in a dual-machine model, introduced by Chen
et al. in 2014 [STACS 2014: 226-238], both of which beat the currently best
result.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Ya-Chun Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwama_K/0/1/0/all/0/1">Kazuo Iwama</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1">Chung-Shou Liao</a></p><p>We investigate the {\em power-down mechanism} which decides when a machine
transitions between states such that the total energy consumption,
characterized by execution cost, idle cost and switching cost, is minimized. In
contrast to most of the previous studies on the offline model, we focus on the
online model in which a sequence of jobs with their release time, execution
time and deadline, arrive in an online fashion. More precisely, we exploit a
different switching on and off strategy and present an upper bound of 3, and
further show a lower bound of 2.1, in a dual-machine model, introduced by Chen
et al. in 2014 [STACS 2014: 226-238], both of which beat the currently best
result.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
  </div>

  <script src='js/jquery-2.0.3.min.js'></script>
  <script src="js/jquery.timeago.js" type="text/javascript"></script>
  <script>
    jQuery(document).ready(function() {
      jQuery("time.timeago").timeago();
    });
  </script>
  <script src='js/blank.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
