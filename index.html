<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-04-27T04:31:45Z">Thursday, April 27 2023, 04:31</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, April 27
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13605'>On the Order of Power Series and the Sum of Square Roots Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Louis Gaillard, Gorav Jindal</p><p>This paper focuses on the study of the order of power series that are linear
combinations of a given finite set of power series. The order of a formal power
series, known as $\textrm{ord}(f)$, is defined as the minimum exponent of $x$
that has a non-zero coefficient in $f(x)$. Our first result is that the order
of the Wronskian of these power series is equivalent up to a polynomial factor,
to the maximum order which occurs in the linear combination of these power
series. This implies that the Wronskian approach used in (Kayal and Saha,
TOCT'2012) to upper bound the order of sum of square roots is optimal up to a
polynomial blowup. We also demonstrate similar upper bounds, similar to those
of (Kayal and Saha, TOCT'2012), for the order of power series in a variety of
other scenarios. We also solve a special case of the inequality testing problem
outlined in (Etessami et al., TOCT'2014).
</p>
<p>In the second part of the paper, we study the equality variant of the sum of
square roots problem, which is decidable in polynomial time due to (Bl\"omer,
FOCS'1991). We investigate a natural generalization of this problem when the
input integers are given as straight line programs. Under the assumption of the
Generalized Riemann Hypothesis (GRH), we show that this problem can be reduced
to the so-called ``one dimensional'' variant. We identify the key mathematical
challenges for solving this ``one dimensional'' variant.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gaillard_L/0/1/0/all/0/1">Louis Gaillard</a>, <a href="http://arxiv.org/find/cs/1/au:+Jindal_G/0/1/0/all/0/1">Gorav Jindal</a></p><p>This paper focuses on the study of the order of power series that are linear
combinations of a given finite set of power series. The order of a formal power
series, known as $\textrm{ord}(f)$, is defined as the minimum exponent of $x$
that has a non-zero coefficient in $f(x)$. Our first result is that the order
of the Wronskian of these power series is equivalent up to a polynomial factor,
to the maximum order which occurs in the linear combination of these power
series. This implies that the Wronskian approach used in (Kayal and Saha,
TOCT'2012) to upper bound the order of sum of square roots is optimal up to a
polynomial blowup. We also demonstrate similar upper bounds, similar to those
of (Kayal and Saha, TOCT'2012), for the order of power series in a variety of
other scenarios. We also solve a special case of the inequality testing problem
outlined in (Etessami et al., TOCT'2014).
</p>
<p>In the second part of the paper, we study the equality variant of the sum of
square roots problem, which is decidable in polynomial time due to (Bl\"omer,
FOCS'1991). We investigate a natural generalization of this problem when the
input integers are given as straight line programs. Under the assumption of the
Generalized Riemann Hypothesis (GRH), we show that this problem can be reduced
to the so-called ``one dimensional'' variant. We identify the key mathematical
challenges for solving this ``one dimensional'' variant.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13094'>Simply Realising an Imprecise Polyline is NP-hard</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Thijs van der Horst, Tim Ophelders, Bart van der Steenhoven</p><p>We consider the problem of deciding, given a sequence of regions, if there is
a choice of points, one for each region, such that the induced polyline is
simple or weakly simple, meaning that it can touch but not cross itself.
Specifically, we consider the case where each region is a translate of the same
shape. We show that the problem is NP-hard when the shape is a unit-disk or
unit-square. We argue that the problem is NP-complete when the shape is a
vertical unit-segment.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Horst_T/0/1/0/all/0/1">Thijs van der Horst</a>, <a href="http://arxiv.org/find/cs/1/au:+Ophelders_T/0/1/0/all/0/1">Tim Ophelders</a>, <a href="http://arxiv.org/find/cs/1/au:+Steenhoven_B/0/1/0/all/0/1">Bart van der Steenhoven</a></p><p>We consider the problem of deciding, given a sequence of regions, if there is
a choice of points, one for each region, such that the induced polyline is
simple or weakly simple, meaning that it can touch but not cross itself.
Specifically, we consider the case where each region is a translate of the same
shape. We show that the problem is NP-hard when the shape is a unit-disk or
unit-square. We argue that the problem is NP-complete when the shape is a
vertical unit-segment.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13699'>Covering simple orthogonal polygons with $r$-stars</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tam&#xe1;s R&#xf3;bert Mezei</p><p>We solve the $r$-star covering problem in simple orthogonal polygons, also
known as the point guard problem in simple orthogonal polygons with rectangular
vision, in quadratic time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Mezei_T/0/1/0/all/0/1">Tam&#xe1;s R&#xf3;bert Mezei</a></p><p>We solve the $r$-star covering problem in simple orthogonal polygons, also
known as the point guard problem in simple orthogonal polygons with rectangular
vision, in quadratic time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13228'>An Approximation Algorithm for Two-Edge-Connected Subgraph Problem via Triangle-free Two-Edge-Cover</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yusuke Kobayashi, Takashi Noguchi</p><p>The $2$-Edge-Connected Spanning Subgraph problem (2-ECSS) is one of the most
fundamental and well-studied problems in the context of network design. In the
problem, we are given an undirected graph $G$, and the objective is to find a
$2$-edge-connected spanning subgraph $H$ of $G$ with the minimum number of
edges. For this problem, a lot of approximation algorithms have been proposed
in the literature. In particular, very recently, Garg, Grandoni, and Ameli gave
an approximation algorithm for 2-ECSS with factor $1.326$, which was the best
approximation ratio. In this paper, we give a $(1.3+\varepsilon)$-approximation
algorithm for 2-ECSS, where $\varepsilon$ is an arbitrary positive fixed
constant, which improves the previously known best approximation ratio. In our
algorithm, we compute a minimum triangle-free $2$-edge-cover in $G$ with the
aid of the algorithm for finding a maximum triangle-free $2$-matching given by
Hartvigsen. Then, with the obtained triangle-free $2$-edge-cover, we apply the
arguments by Garg, Grandoni, and Ameli.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1">Yusuke Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Noguchi_T/0/1/0/all/0/1">Takashi Noguchi</a></p><p>The $2$-Edge-Connected Spanning Subgraph problem (2-ECSS) is one of the most
fundamental and well-studied problems in the context of network design. In the
problem, we are given an undirected graph $G$, and the objective is to find a
$2$-edge-connected spanning subgraph $H$ of $G$ with the minimum number of
edges. For this problem, a lot of approximation algorithms have been proposed
in the literature. In particular, very recently, Garg, Grandoni, and Ameli gave
an approximation algorithm for 2-ECSS with factor $1.326$, which was the best
approximation ratio. In this paper, we give a $(1.3+\varepsilon)$-approximation
algorithm for 2-ECSS, where $\varepsilon$ is an arbitrary positive fixed
constant, which improves the previously known best approximation ratio. In our
algorithm, we compute a minimum triangle-free $2$-edge-cover in $G$ with the
aid of the algorithm for finding a maximum triangle-free $2$-matching given by
Hartvigsen. Then, with the obtained triangle-free $2$-edge-cover, we apply the
arguments by Garg, Grandoni, and Ameli.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13398'>Acceleration for Timing-Aware Gate-Level Logic Simulation with One-Pass GPU Parallelism</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Weijie Fang, Yanggeng Fu, Jiaquan Gao, Longkun Guo, Gregory Gutin, Xiaoyan Zhang</p><p>Witnessing the advancing scale and complexity of chip design and benefiting
from high-performance computation technologies, the simulation of Very Large
Scale Integration (VLSI) Circuits imposes an increasing requirement for
acceleration through parallel computing with GPU devices. However, the
conventional parallel strategies do not fully align with modern GPU abilities,
leading to new challenges in the parallelism of VLSI simulation when using GPU,
despite some previous successful demonstrations of significant acceleration. In
this paper, we propose a novel approach to accelerate 4-value logic
timing-aware gate-level logic simulation using waveform-based GPU parallelism.
Our approach utilizes a new strategy that can effectively handle the dependency
between tasks during the parallelism, reducing the synchronization requirement
between CPU and GPU when parallelizing the simulation on combinational
circuits. This approach requires only one round of data transfer and hence
achieves one-pass parallelism. Moreover, to overcome the difficulty within the
adoption of our strategy in GPU devices, we design a series of data structures
and tune them to dynamically allocate and store new-generated output with
uncertain scale. Finally, experiments are carried out on industrial-scale
open-source benchmarks to demonstrate the performance gain of our approach
compared to several state-of-the-art baselines.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1">Weijie Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yanggeng Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jiaquan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1">Longkun Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutin_G/0/1/0/all/0/1">Gregory Gutin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoyan Zhang</a></p><p>Witnessing the advancing scale and complexity of chip design and benefiting
from high-performance computation technologies, the simulation of Very Large
Scale Integration (VLSI) Circuits imposes an increasing requirement for
acceleration through parallel computing with GPU devices. However, the
conventional parallel strategies do not fully align with modern GPU abilities,
leading to new challenges in the parallelism of VLSI simulation when using GPU,
despite some previous successful demonstrations of significant acceleration. In
this paper, we propose a novel approach to accelerate 4-value logic
timing-aware gate-level logic simulation using waveform-based GPU parallelism.
Our approach utilizes a new strategy that can effectively handle the dependency
between tasks during the parallelism, reducing the synchronization requirement
between CPU and GPU when parallelizing the simulation on combinational
circuits. This approach requires only one round of data transfer and hence
achieves one-pass parallelism. Moreover, to overcome the difficulty within the
adoption of our strategy in GPU devices, we design a series of data structures
and tune them to dynamically allocate and store new-generated output with
uncertain scale. Finally, experiments are carried out on industrial-scale
open-source benchmarks to demonstrate the performance gain of our approach
compared to several state-of-the-art baselines.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13496'>An Improved Modular Addition Checksum Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Philip Koopman</p><p>This paper introduces a checksum algorithm that provides a new point in the
performance/complexity/effectiveness checksum tradeoff space. It has better
fault detection properties than single-sum and dual-sum modular addition
checksums. It is also simpler to compute efficiently than a cyclic redundancy
check (CRC) due to exploiting commonly available hardware and programming
language support for unsigned integer division. The key idea is to compute a
single running sum, but introduce a left shift by the size (in bits) of the
modulus before performing the modular reduction after each addition step. This
approach provides a Hamming Distance of 3 for longer data word lengths than
dual-sum approaches such as the Fletcher checksum. Moreover, it provides this
capability using a single running sum that is only twice the size of the final
computed check value, while providing fault detection capabilities even better
than large-block variants of dual-sum approaches that require larger division
operations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Koopman_P/0/1/0/all/0/1">Philip Koopman</a></p><p>This paper introduces a checksum algorithm that provides a new point in the
performance/complexity/effectiveness checksum tradeoff space. It has better
fault detection properties than single-sum and dual-sum modular addition
checksums. It is also simpler to compute efficiently than a cyclic redundancy
check (CRC) due to exploiting commonly available hardware and programming
language support for unsigned integer division. The key idea is to compute a
single running sum, but introduce a left shift by the size (in bits) of the
modulus before performing the modular reduction after each addition step. This
approach provides a Hamming Distance of 3 for longer data word lengths than
dual-sum approaches such as the Fletcher checksum. Moreover, it provides this
capability using a single running sum that is only twice the size of the final
computed check value, while providing fault detection capabilities even better
than large-block variants of dual-sum approaches that require larger division
operations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13695'>Hitting Subgraphs in Sparse Graphs and Geometric Intersection Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Lokshtanov, Fahad Panolan, Saket Saurabh, Jie Xue, Meirav Zehavi</p><p>We investigate a fundamental vertex-deletion problem called (Induced)
Subgraph Hitting: given a graph $G$ and a set $\mathcal{F}$ of forbidden
graphs, the goal is to compute a minimum-sized set $S$ of vertices of $G$ such
that $G-S$ does not contain any graph in $\mathcal{F}$ as an (induced)
subgraph. This is a generic problem that encompasses many well-known problems
that were extensively studied on their own, particularly (but not only) from
the perspectives of both approximation and parameterization. We focus on the
design of efficient approximation schemes, i.e., with running time
$f(\varepsilon,\mathcal{F}) \cdot n^{O(1)}$, which are also of significant
interest to both communities. Technically, our main contribution is a
linear-time approximation-preserving reduction from (Induced) Subgraph Hitting
on any graph class $\mathcal{G}$ of bounded expansion to the same problem on
bounded degree graphs within $\mathcal{G}$. This yields a novel algorithmic
technique to design (efficient) approximation schemes for the problem on very
broad graph classes, well beyond the state-of-the-art. Specifically, applying
this reduction, we derive approximation schemes with (almost) linear running
time for the problem on any graph classes that have strongly sublinear
separators and many important classes of geometric intersection graphs (such as
fat-object graphs, pseudo-disk graphs, etc.). Our proofs introduce novel
concepts and combinatorial observations that may be of independent interest
(and, which we believe, will find other uses) for studies of approximation
algorithms, parameterized complexity, sparse graph classes, and geometric
intersection graphs. As a byproduct, we also obtain the first robust algorithm
for $k$-Subgraph Isomorphism on intersection graphs of fat objects and
pseudo-disks, with running time $f(k) \cdot n \log n + O(m)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lokshtanov_D/0/1/0/all/0/1">Daniel Lokshtanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Panolan_F/0/1/0/all/0/1">Fahad Panolan</a>, <a href="http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1">Saket Saurabh</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1">Jie Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zehavi_M/0/1/0/all/0/1">Meirav Zehavi</a></p><p>We investigate a fundamental vertex-deletion problem called (Induced)
Subgraph Hitting: given a graph $G$ and a set $\mathcal{F}$ of forbidden
graphs, the goal is to compute a minimum-sized set $S$ of vertices of $G$ such
that $G-S$ does not contain any graph in $\mathcal{F}$ as an (induced)
subgraph. This is a generic problem that encompasses many well-known problems
that were extensively studied on their own, particularly (but not only) from
the perspectives of both approximation and parameterization. We focus on the
design of efficient approximation schemes, i.e., with running time
$f(\varepsilon,\mathcal{F}) \cdot n^{O(1)}$, which are also of significant
interest to both communities. Technically, our main contribution is a
linear-time approximation-preserving reduction from (Induced) Subgraph Hitting
on any graph class $\mathcal{G}$ of bounded expansion to the same problem on
bounded degree graphs within $\mathcal{G}$. This yields a novel algorithmic
technique to design (efficient) approximation schemes for the problem on very
broad graph classes, well beyond the state-of-the-art. Specifically, applying
this reduction, we derive approximation schemes with (almost) linear running
time for the problem on any graph classes that have strongly sublinear
separators and many important classes of geometric intersection graphs (such as
fat-object graphs, pseudo-disk graphs, etc.). Our proofs introduce novel
concepts and combinatorial observations that may be of independent interest
(and, which we believe, will find other uses) for studies of approximation
algorithms, parameterized complexity, sparse graph classes, and geometric
intersection graphs. As a byproduct, we also obtain the first robust algorithm
for $k$-Subgraph Isomorphism on intersection graphs of fat objects and
pseudo-disks, with running time $f(k) \cdot n \log n + O(m)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, April 26
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/04/comic-book-alignment.html'>Comic Book Alignment</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Talk about AI "alignment" makes me think of a time in the 1950s that a group of companies decided to</p>♦create an industry organization to self-govern their work to make sure that they were following the values of the time and avoid government oversight. Of course, I'm talking about the Comics Code Authority (CCA).&nbsp;<p></p><p>Fueled by psychiatrist Fredric Wertham's book&nbsp;Seduction of the Innocent&nbsp;and a series of U.S. Congressional hearings, the comic publishers realized they needed to police themselves and formed a trade group, the Comics Magazine Association of America (CMAA). The CMAA created the Comics Code Authority (CCA) in 1954 to enforce a code of content guidelines that comic book publishers would adhere to. The Comics Code prohibited explicit violence, sexual content, and other adult themes in comic books, as well as a promoting a "positive portrayal" of authority figures and institutions. The CCA seal, which was a small stamp indicating that a comic book had been reviewed and approved by the organization, became a requirement for distribution by most newsstands and retailers pushing many publishers to follow the code.</p><p>I started reading comic books in the 1970s with the code in full swing. It was not a golden time for comic books with mostly bland, straightforward stories, and I gave it up as I went into high school. In college in the '80s, a friend brought me back into comics with some series, like Watchmen, having given up the code and the seal. I started reading comics voraciously, so much that I had to go cold turkey in grad school so I could focus on research. The code itself was abandoned in 2011 after even Archie Comics gave up using the seal.</p><p>There's not a direct parallel between comic book writers and large language models, but the principle is the same. If you try to enforce a collection of values, you will get blander, less interesting output. I'm not saying that all alignment is a bad idea, but that you need to realize you will lose something when you do.</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Talk about AI "alignment" makes me think of a time in the 1950s that a group of companies decided to</p><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiOJyHIQsK2gmTZrReKtomoONYxMochTlBFA2aG4vRoMaixDHYVo34nRw7jK6zJLd3h2ur4Q5siUgsCqZ9luhIooNr43H-KFP7Ui-1TmN14ZZTBSMtD0BhXOndA3lPXGr9rL_J-nu0YihbC9V7-qiqMn8yxUnIqplSFfkMtKOFBF2Y9L9nO0A/s209/Approved_by_the_Comics_Code_Authority.gif" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" data-original-height="209" data-original-width="172" height="200" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiOJyHIQsK2gmTZrReKtomoONYxMochTlBFA2aG4vRoMaixDHYVo34nRw7jK6zJLd3h2ur4Q5siUgsCqZ9luhIooNr43H-KFP7Ui-1TmN14ZZTBSMtD0BhXOndA3lPXGr9rL_J-nu0YihbC9V7-qiqMn8yxUnIqplSFfkMtKOFBF2Y9L9nO0A/w165-h200/Approved_by_the_Comics_Code_Authority.gif" width="165" /></a></div>create an industry organization to self-govern their work to make sure that they were following the values of the time and avoid government oversight. Of course, I'm talking about the <a href="https://en.wikipedia.org/wiki/Comics_Code_Authority">Comics Code Authority</a> (CCA).&nbsp;<p></p><p>Fueled by psychiatrist Fredric Wertham's book&nbsp;<a href="https://en.wikipedia.org/wiki/Seduction_of_the_Innocent">Seduction of the Innocent</a>&nbsp;and a series of U.S. Congressional hearings, the comic publishers realized they needed to police themselves and formed a trade group, the Comics Magazine Association of America (CMAA). The CMAA created the Comics Code Authority (CCA) in 1954 to enforce a code of content guidelines that comic book publishers would adhere to. The Comics Code prohibited explicit violence, sexual content, and other adult themes in comic books, as well as a promoting a "positive portrayal" of authority figures and institutions. The CCA seal, which was a small stamp indicating that a comic book had been reviewed and approved by the organization, became a requirement for distribution by most newsstands and retailers pushing many publishers to follow the code.</p><p>I started reading comic books in the 1970s with the code in full swing. It was not a golden time for comic books with mostly bland, straightforward stories, and I gave it up as I went into high school. In college in the '80s, a friend brought me back into comics with some series, like <a href="https://en.wikipedia.org/wiki/Watchmen">Watchmen</a>, having given up the code and the seal. I started reading comics voraciously, so much that I had to go cold turkey in grad school so I could focus on research. The code itself was abandoned in 2011 after even Archie Comics gave up using the seal.</p><p>There's not a direct parallel between comic book writers and large language models, but the principle is the same. If you try to enforce a collection of values, you will get blander, less interesting output. I'm not saying that all alignment is a bad idea, but that you need to realize you will lose something when you do.</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T20:59:00Z">Wednesday, April 26 2023, 20:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/04/26/postdoc-at-yale-university-apply-by-may-12-2023/'>Postdoc at Yale University (apply by May 12, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Applications are solicited for a postdoctoral position at Yale in Theoretical Computer Science and Machine Learning including (but not limited to) applications to Fairness and Privacy. Applicants should have an exceptional math background and a proven record. They should have their CV, research statement, and three letters emailed directly to Nisheeth Vishnoi Website: www.cs.yale.edu/homes/vishnoi/Home.html Email: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Applications are solicited for a postdoctoral position at Yale in Theoretical Computer Science and Machine Learning including (but not limited to) applications to Fairness and Privacy. Applicants should have an exceptional math background and a proven record. They should have their CV, research statement, and three letters emailed directly to Nisheeth Vishnoi</p>
<p>Website: <a href="http://www.cs.yale.edu/homes/vishnoi/Home.html">http://www.cs.yale.edu/homes/vishnoi/Home.html</a><br />
Email: nisheeth.vishnoi@gmail.com</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T18:16:33Z">Wednesday, April 26 2023, 18:16</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/056'>TR23-056 |  Approximate Locally Decodable Codes with Constant Query Complexity and Nearly Optimal Rate | 

	Geoffrey Mon, 

	Dana Moshkovitz, 

	Justin Oh</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We present simple constructions of good approximate locally decodable codes (ALDCs) in the presence of a $\delta$-fraction of errors for $\delta&amp;lt;1/2$. In a standard locally decodable code $C \colon \Sigma_1^k \to \Sigma_2^n$, there is a decoder $M$ that on input $i \in [k]$ correctly outputs the $i$-th symbol of a message $x$ (with high probability) using only $q$ queries to a given string $w$ that is $\delta$-close to $C(x)$. In an ALDC, the decoder $M$ only needs to be correct on $1-\epsilon$ fraction of $i\in [k]$ for $\epsilon$ much smaller than $\delta$. We present a construction of explicit ALDCs for all constants $1/2&gt;\delta&gt;\epsilon$ with a constant number of queries $q$ and with constant, near-optimal rate. Standard LDCs with constant number of queries and any constant rate are known to be impossible. Past constructions of ALDCs had vanishingly small rate or a large super-constant number of queries.

Our constructions can be adapted to admit a weak notion of list decoding. In a weak approximate locally list decodable code $C \colon \Sigma_1^k \to \Sigma_2^n$, there is a decoder $M$ that on input $i \in [k]$, makes at most $q$ queries to a string $w \in \Sigma_2^n$ and outputs a list of symbols $M(i) \subset \Sigma_1$ with $|M(i)| \ll |\Sigma_1|$. For any codeword $C(x)$ that is $\delta$-close to $w$, $x_i \in M(i)$ for at least $1-\epsilon$ fraction of $i \in [k]$. We provide constructions of weak approximate locally list decodable codes with a constant number of queries and with rate approaching that of random (standard) list decodable codes.

We additionally explore what is the lowest error probability $\epsilon$ one can achieve for fixed $\delta$ and $q$. We show that for any ALDC, $\epsilon = \Omega(\delta^{\lceil q/2\rceil})$. We then show that there exist explicit constant rate ALDCs for any constant $q$ that achieve $\epsilon = O(\delta^{\lceil q/2\rceil})$. In particular, for $q = 3$, we have a constant rate ALDC with error probability $\epsilon = O(\delta^2)$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We present simple constructions of good approximate locally decodable codes (ALDCs) in the presence of a $\delta$-fraction of errors for $\delta&amp;lt;1/2$. In a standard locally decodable code $C \colon \Sigma_1^k \to \Sigma_2^n$, there is a decoder $M$ that on input $i \in [k]$ correctly outputs the $i$-th symbol of a message $x$ (with high probability) using only $q$ queries to a given string $w$ that is $\delta$-close to $C(x)$. In an ALDC, the decoder $M$ only needs to be correct on $1-\epsilon$ fraction of $i\in [k]$ for $\epsilon$ much smaller than $\delta$. We present a construction of explicit ALDCs for all constants $1/2&gt;\delta&gt;\epsilon$ with a constant number of queries $q$ and with constant, near-optimal rate. Standard LDCs with constant number of queries and any constant rate are known to be impossible. Past constructions of ALDCs had vanishingly small rate or a large super-constant number of queries.

Our constructions can be adapted to admit a weak notion of list decoding. In a weak approximate locally list decodable code $C \colon \Sigma_1^k \to \Sigma_2^n$, there is a decoder $M$ that on input $i \in [k]$, makes at most $q$ queries to a string $w \in \Sigma_2^n$ and outputs a list of symbols $M(i) \subset \Sigma_1$ with $|M(i)| \ll |\Sigma_1|$. For any codeword $C(x)$ that is $\delta$-close to $w$, $x_i \in M(i)$ for at least $1-\epsilon$ fraction of $i \in [k]$. We provide constructions of weak approximate locally list decodable codes with a constant number of queries and with rate approaching that of random (standard) list decodable codes.

We additionally explore what is the lowest error probability $\epsilon$ one can achieve for fixed $\delta$ and $q$. We show that for any ALDC, $\epsilon = \Omega(\delta^{\lceil q/2\rceil})$. We then show that there exist explicit constant rate ALDCs for any constant $q$ that achieve $\epsilon = O(\delta^{\lceil q/2\rceil})$. In particular, for $q = 3$, we have a constant rate ALDC with error probability $\epsilon = O(\delta^2)$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T08:57:40Z">Wednesday, April 26 2023, 08:57</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/04/26/postdoc-at-idsia-dalle-molle-institute-for-artificial-intelligence-usi-supsi-apply-by-may-26-2023/'>Postdoc at IDSIA – Dalle Molle Institute for Artificial Intelligence (USI-SUPSI) (apply by May 26, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          One postdoc position for up to 4 years is available at IDSIA (Switzerland). The gross salary is around 80.000 CHF per year, with low taxes (~12%). Candidates with strong background in math or theoretical computer science will be considered. The positions will be filled as soon as eligible candidates with an appropriate background apply. Website: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>One postdoc position for up to 4 years is available at IDSIA (Switzerland). The gross salary is around 80.000 CHF per year, with low taxes (~12%). Candidates with strong background in math or theoretical computer science will be considered.<br />
The positions will be filled as soon as eligible candidates with an appropriate background apply.</p>
<p>Website: <a href="https://people.idsia.ch/~monaldo/positions/positions.html">https://people.idsia.ch/~monaldo/positions/positions.html</a><br />
Email: monaldo@idsia.ch</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T07:18:06Z">Wednesday, April 26 2023, 07:18</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12517'>The 2-MAXSAT Problem Can Be Solved in Polynomial Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yangjun Chen</p><p>By the MAXSAT problem, we are given a set $V$ of $m$ variables and a
collection $C$ of $n$ clauses over $V$. We will seek a truth assignment to
maximize the number of satisfied clauses. This problem is $\textit{NP}$-hard
even for its restricted version, the 2-MAXSAT problem by which every clause
contains at most 2 literals. In this paper, we discuss a polynomial time
algorithm to solve this problem. Its time complexity is bounded by O($n^2m^3$).
Hence, we provide a proof of $P$ = $\textit{NP}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yangjun Chen</a></p><p>By the MAXSAT problem, we are given a set $V$ of $m$ variables and a
collection $C$ of $n$ clauses over $V$. We will seek a truth assignment to
maximize the number of satisfied clauses. This problem is $\textit{NP}$-hard
even for its restricted version, the 2-MAXSAT problem by which every clause
contains at most 2 literals. In this paper, we discuss a polynomial time
algorithm to solve this problem. Its time complexity is bounded by O($n^2m^3$).
Hence, we provide a proof of $P$ = $\textit{NP}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12871'>Network Satisfaction Problems Solved by k-Consistency</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Manuel Bodirsky, Simon Kn&#xe4;uer</p><p>We show that the problem of deciding for a given finite relation algebra A
whether the network satisfaction problem for A can be solved by the
k-consistency procedure, for some natural number k, is undecidable. For the
important class of finite relation algebras A with a normal representation,
however, the decidability of this problem remains open. We show that if A is
symmetric and has a flexible atom, then the question whether NSP(A) can be
solved by k-consistency, for some natural number k, is decidable (even in
polynomial time in the number of atoms of A). This result follows from a more
general sufficient condition for the correctness of the k-consistency procedure
for finite symmetric relation algebras. In our proof we make use of a result of
Alexandr Kazda about finite binary conservative structures.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Bodirsky_M/0/1/0/all/0/1">Manuel Bodirsky</a>, <a href="http://arxiv.org/find/math/1/au:+Knauer_S/0/1/0/all/0/1">Simon Kn&#xe4;uer</a></p><p>We show that the problem of deciding for a given finite relation algebra A
whether the network satisfaction problem for A can be solved by the
k-consistency procedure, for some natural number k, is undecidable. For the
important class of finite relation algebras A with a normal representation,
however, the decidability of this problem remains open. We show that if A is
symmetric and has a flexible atom, then the question whether NSP(A) can be
solved by k-consistency, for some natural number k, is decidable (even in
polynomial time in the number of atoms of A). This result follows from a more
general sufficient condition for the correctness of the k-consistency procedure
for finite symmetric relation algebras. In our proof we make use of a result of
Alexandr Kazda about finite binary conservative structures.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12948'>Simulating Logspace-Recursion with Logarithmic Quantifier Depth</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Steffen van Bergerem, Martin Grohe, Sandra Kiefer, Luca Oeljeklaus</p><p>The fixed-point logic LREC= was developed by Grohe et al. (CSL 2011) in the
quest for a logic to capture all problems decidable in logarithmic space. It
extends FO+C, first-order logic with counting, by an operator that formalises a
limited form of recursion. We show that for every LREC=-definable property on
relational structures, there is a constant k such that the k-variable fragment
of first-order logic with counting quantifiers expresses the property via
formulae of logarithmic quantifier depth. This yields that any pair of graphs
separable by the property can be distinguished with the k-dimensional
Weisfeiler-Leman algorithm in a logarithmic number of iterations. In
particular, it implies that a constant dimension of the algorithm identifies
every interval graph and every chordal claw-free graph in logarithmically many
iterations, since every such graph admits LREC=-definable canonisation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bergerem_S/0/1/0/all/0/1">Steffen van Bergerem</a>, <a href="http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1">Martin Grohe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiefer_S/0/1/0/all/0/1">Sandra Kiefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Oeljeklaus_L/0/1/0/all/0/1">Luca Oeljeklaus</a></p><p>The fixed-point logic LREC= was developed by Grohe et al. (CSL 2011) in the
quest for a logic to capture all problems decidable in logarithmic space. It
extends FO+C, first-order logic with counting, by an operator that formalises a
limited form of recursion. We show that for every LREC=-definable property on
relational structures, there is a constant k such that the k-variable fragment
of first-order logic with counting quantifiers expresses the property via
formulae of logarithmic quantifier depth. This yields that any pair of graphs
separable by the property can be distinguished with the k-dimensional
Weisfeiler-Leman algorithm in a logarithmic number of iterations. In
particular, it implies that a constant dimension of the algorithm identifies
every interval graph and every chordal claw-free graph in logarithmically many
iterations, since every such graph admits LREC=-definable canonisation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12435'>Computing Circuit Polynomials in the Algebraic Rigidity Matroid</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Goran Malic, Ileana Streinu</p><p>We present an algorithm for computing circuit polynomials in the algebraic
rigidity matroid $\mathcal{A}(\text{CM}_n)$ associated to the Cayley-Menger
ideal CM$_n$ for $n$ points in 2D. It relies on combinatorial resultants, a new
operation on graphs that captures properties of the Sylvester resultant of two
polynomials in this ideal. We show that every rigidity circuit has a
construction tree from K4 graphs based on this operation. Our algorithm
performs an algebraic elimination guided by such a construction tree, and uses
classical resultants, factorization and ideal membership. To highlight its
effectiveness, we implemented the algorithm in Mathematica: it took less than
15 seconds on an example where a Gr\"obner Basis calculation took 5 days and 6
hrs. Additional speed-ups are obtained using non-$K_4$ generators of the
Cayley-Menger ideal and simple variations on our main algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Malic_G/0/1/0/all/0/1">Goran Malic</a>, <a href="http://arxiv.org/find/math/1/au:+Streinu_I/0/1/0/all/0/1">Ileana Streinu</a></p><p>We present an algorithm for computing circuit polynomials in the algebraic
rigidity matroid $\mathcal{A}(\text{CM}_n)$ associated to the Cayley-Menger
ideal CM$_n$ for $n$ points in 2D. It relies on combinatorial resultants, a new
operation on graphs that captures properties of the Sylvester resultant of two
polynomials in this ideal. We show that every rigidity circuit has a
construction tree from K4 graphs based on this operation. Our algorithm
performs an algebraic elimination guided by such a construction tree, and uses
classical resultants, factorization and ideal membership. To highlight its
effectiveness, we implemented the algorithm in Mathematica: it took less than
15 seconds on an example where a Gr\"obner Basis calculation took 5 days and 6
hrs. Additional speed-ups are obtained using non-$K_4$ generators of the
Cayley-Menger ideal and simple variations on our main algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12381'>Recognizing and generating unswitchable graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Asish Mukhopadhyay, Daniel John, Srivatsan Vasudevan</p><p>In this paper, we show that unswitchable graphs are a proper subclass of
split graphs, and exploit this fact to propose efficient algorithms for their
recognition and generation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mukhopadhyay_A/0/1/0/all/0/1">Asish Mukhopadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+John_D/0/1/0/all/0/1">Daniel John</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasudevan_S/0/1/0/all/0/1">Srivatsan Vasudevan</a></p><p>In this paper, we show that unswitchable graphs are a proper subclass of
split graphs, and exploit this fact to propose efficient algorithms for their
recognition and generation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12610'>Fast Continuous Subgraph Matching over Streaming Graphs via Backtracking Reduction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rongjian Yang, Zhijie Zhang, Weiguo Zheng, Jeffery Xu Yu</p><p>Streaming graphs are drawing increasing attention in both academic and
industrial communities as many graphs in real applications evolve over time.
Continuous subgraph matching (shorted as CSM) aims to report the incremental
matches of a query graph in such streaming graphs. It involves two major steps,
i.e., candidate maintenance and incremental match generation, to answer CSM.
Throughout the course of continuous subgraph matching, incremental match
generation backtracking over the search space dominates the total cost.
However, most previous approaches focus on developing techniques for efficient
candidate maintenance, while incremental match generation receives less
attention despite its importance in CSM. Aiming to minimize the overall cost,
we propose two techniques to reduce backtrackings in this paper. We present a
cost-effective index CaLiG that yields tighter candidate maintenance, shrinking
the search space of backtracking. In addition, we develop a novel incremental
matching paradigm KSS that decomposes the query vertices into conditional
kernel vertices and shell vertices. With the matches of kernel vertices, the
incremental matches can be produced immediately by joining the candidates of
shell vertices without any backtrackings. Benefiting from reduced
backtrackings, the elapsed time of CSM decreases significantly. Extensive
experiments over real graphs show that our method runs faster than the
state-of-the-art algorithm orders of magnitude.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Rongjian Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhijie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Weiguo Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jeffery Xu Yu</a></p><p>Streaming graphs are drawing increasing attention in both academic and
industrial communities as many graphs in real applications evolve over time.
Continuous subgraph matching (shorted as CSM) aims to report the incremental
matches of a query graph in such streaming graphs. It involves two major steps,
i.e., candidate maintenance and incremental match generation, to answer CSM.
Throughout the course of continuous subgraph matching, incremental match
generation backtracking over the search space dominates the total cost.
However, most previous approaches focus on developing techniques for efficient
candidate maintenance, while incremental match generation receives less
attention despite its importance in CSM. Aiming to minimize the overall cost,
we propose two techniques to reduce backtrackings in this paper. We present a
cost-effective index CaLiG that yields tighter candidate maintenance, shrinking
the search space of backtracking. In addition, we develop a novel incremental
matching paradigm KSS that decomposes the query vertices into conditional
kernel vertices and shell vertices. With the matches of kernel vertices, the
incremental matches can be produced immediately by joining the candidates of
shell vertices without any backtrackings. Benefiting from reduced
backtrackings, the elapsed time of CSM decreases significantly. Extensive
experiments over real graphs show that our method runs faster than the
state-of-the-art algorithm orders of magnitude.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12656'>Towards Generating Hop-constrained s-t Simple Path Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuzheng Cai, Siyuan Liu, Weiguo Zheng, Xuemin Lin</p><p>Graphs have been widely used in real-world applications, in which
investigating relations between vertices is an important task. In this paper,
we study the problem of generating the k-hop-constrained s-t simple path graph,
i.e., the subgraph consisting of all simple paths from vertex s to vertex t of
length no larger than k. To our best knowledge, we are the first to formalize
this problem and prove its NP-hardness on directed graphs. To tackle this
challenging problem, we propose an efficient algorithm named EVE, which
exploits the paradigm of edge-wise examination rather than exhaustively
enumerating all paths. Powered by essential vertices appearing in all simple
paths between vertex pairs, EVE distinguishes the edges that are definitely (or
not) contained in the desired simple path graph, producing a tight upper-bound
graph in the time cost $\mathcal{O}(k^2|E|)$. Each remaining undetermined edge
is further verified to deliver the exact answer. Extensive experiments are
conducted on 15 real networks. The results show that EVE significantly
outperforms all baselines by several orders of magnitude. Moreover, by taking
EVE as a built-in block, state-of-the-art for hop-constrained simple path
enumeration can be accelerated by up to an order of magnitude.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yuzheng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Siyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Weiguo Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xuemin Lin</a></p><p>Graphs have been widely used in real-world applications, in which
investigating relations between vertices is an important task. In this paper,
we study the problem of generating the k-hop-constrained s-t simple path graph,
i.e., the subgraph consisting of all simple paths from vertex s to vertex t of
length no larger than k. To our best knowledge, we are the first to formalize
this problem and prove its NP-hardness on directed graphs. To tackle this
challenging problem, we propose an efficient algorithm named EVE, which
exploits the paradigm of edge-wise examination rather than exhaustively
enumerating all paths. Powered by essential vertices appearing in all simple
paths between vertex pairs, EVE distinguishes the edges that are definitely (or
not) contained in the desired simple path graph, producing a tight upper-bound
graph in the time cost $\mathcal{O}(k^2|E|)$. Each remaining undetermined edge
is further verified to deliver the exact answer. Extensive experiments are
conducted on 15 real networks. The results show that EVE significantly
outperforms all baselines by several orders of magnitude. Moreover, by taking
EVE as a built-in block, state-of-the-art for hop-constrained simple path
enumeration can be accelerated by up to an order of magnitude.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12779'>An Approximation Algorithm for Covering Vertices by 4^+-Paths</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mingyang Gong, Zhi-Zhong Chen, Guohui Lin, Zhaohui Zhan</p><p>This paper deals with the problem of finding a collection of vertex-disjoint
paths in a given graph G=(V,E) such that each path has at least four vertices
and the total number of vertices in these paths is maximized. The problem is
NP-hard and admits an approximation algorithm which achieves a ratio of 2 and
runs in O(|V|^8) time. The known algorithm is based on time-consuming local
search, and its authors ask whether one can design a better approximation
algorithm by a completely different approach. In this paper, we answer their
question in the affirmative by presenting a new approximation algorithm for the
problem. Our algorithm achieves a ratio of 1.874 and runs in O(min{|E|^2|V|^2,
|V|^5}) time. Unlike the previously best algorithm, ours starts with a maximum
matching M of G and then tries to transform M into a solution by utilizing a
maximum-weight path-cycle cover in a suitably constructed graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1">Mingyang Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhi-Zhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guohui Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_Z/0/1/0/all/0/1">Zhaohui Zhan</a></p><p>This paper deals with the problem of finding a collection of vertex-disjoint
paths in a given graph G=(V,E) such that each path has at least four vertices
and the total number of vertices in these paths is maximized. The problem is
NP-hard and admits an approximation algorithm which achieves a ratio of 2 and
runs in O(|V|^8) time. The known algorithm is based on time-consuming local
search, and its authors ask whether one can design a better approximation
algorithm by a completely different approach. In this paper, we answer their
question in the affirmative by presenting a new approximation algorithm for the
problem. Our algorithm achieves a ratio of 1.874 and runs in O(min{|E|^2|V|^2,
|V|^5}) time. Unlike the previously best algorithm, ours starts with a maximum
matching M of G and then tries to transform M into a solution by utilizing a
maximum-weight path-cycle cover in a suitably constructed graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12872'>Anti-crossings occurrence as exponentially closing gaps in Quantum Annealing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arthur Braida, Simon Martiel, Ioan Todinca</p><p>This paper explores the phenomenon of avoided level crossings in quantum
annealing, a promising framework for quantum computing that may provide a
quantum advantage for certain tasks. Quantum annealing involves letting a
quantum system evolve according to the Schr\"odinger equation, with the goal of
obtaining the optimal solution to an optimization problem through measurements
of the final state. However, the continuous nature of quantum annealing makes
analytical analysis challenging, particularly with regard to the instantaneous
eigenenergies. The adiabatic theorem provides a theoretical result for the
annealing time required to obtain the optimal solution with high probability,
which is inversely proportional to the square of the minimum spectral gap.
Avoided level crossings can create exponentially closing gaps, which can lead
to exponentially long running times for optimization problems. In this paper,
we use a perturbative expansion to derive a condition for the occurrence of an
avoided level crossing during the annealing process. We then apply this
condition to the MaxCut problem on bipartite graphs. We show that no
exponentially small gaps arise for regular bipartite graphs, implying that QA
can efficiently solve MaxCut in that case. On the other hand, we show that
irregularities in the vertex degrees can lead to the satisfaction of the
avoided level crossing occurrence condition. We provide numerical evidence to
support this theoretical development, and discuss the relation between the
presence of exponentially closing gaps and the failure of quantum annealing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Braida_A/0/1/0/all/0/1">Arthur Braida</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Martiel_S/0/1/0/all/0/1">Simon Martiel</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Todinca_I/0/1/0/all/0/1">Ioan Todinca</a></p><p>This paper explores the phenomenon of avoided level crossings in quantum
annealing, a promising framework for quantum computing that may provide a
quantum advantage for certain tasks. Quantum annealing involves letting a
quantum system evolve according to the Schr\"odinger equation, with the goal of
obtaining the optimal solution to an optimization problem through measurements
of the final state. However, the continuous nature of quantum annealing makes
analytical analysis challenging, particularly with regard to the instantaneous
eigenenergies. The adiabatic theorem provides a theoretical result for the
annealing time required to obtain the optimal solution with high probability,
which is inversely proportional to the square of the minimum spectral gap.
Avoided level crossings can create exponentially closing gaps, which can lead
to exponentially long running times for optimization problems. In this paper,
we use a perturbative expansion to derive a condition for the occurrence of an
avoided level crossing during the annealing process. We then apply this
condition to the MaxCut problem on bipartite graphs. We show that no
exponentially small gaps arise for regular bipartite graphs, implying that QA
can efficiently solve MaxCut in that case. On the other hand, we show that
irregularities in the vertex degrees can lead to the satisfaction of the
avoided level crossing occurrence condition. We provide numerical evidence to
support this theoretical development, and discuss the relation between the
presence of exponentially closing gaps and the failure of quantum annealing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12875'>Alternating Local Enumeration (TnALE): Solving Tensor Network Structure Search with Fewer Evaluations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chao Li, Junhua Zeng, Chunmei Li, Cesar Caiafa, Qibin Zhao</p><p>Tensor network (TN) is a powerful framework in machine learning, but
selecting a good TN model, known as TN structure search (TN-SS), is a
challenging and computationally intensive task. The recent approach
TNLS~\cite{li2022permutation} showed promising results for this task, however,
its computational efficiency is still unaffordable, requiring too many
evaluations of the objective function. We propose TnALE, a new algorithm that
updates each structure-related variable alternately by local enumeration,
\emph{greatly} reducing the number of evaluations compared to TNLS. We
theoretically investigate the descent steps for TNLS and TnALE, proving that
both algorithms can achieve linear convergence up to a constant if a sufficient
reduction of the objective is \emph{reached} in each neighborhood. We also
compare the evaluation efficiency of TNLS and TnALE, revealing that
$\Omega(2^N)$ evaluations are typically required in TNLS for \emph{reaching}
the objective reduction in the neighborhood, while ideally $O(N^2R)$
evaluations are sufficient in TnALE, where $N$ denotes the tensor order and $R$
reflects the \emph{``low-rankness''} of the neighborhood. Experimental results
verify that TnALE can find practically good TN-ranks and permutations with
vastly fewer evaluations than the state-of-the-art algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1">Junhua Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunmei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Caiafa_C/0/1/0/all/0/1">Cesar Caiafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qibin Zhao</a></p><p>Tensor network (TN) is a powerful framework in machine learning, but
selecting a good TN model, known as TN structure search (TN-SS), is a
challenging and computationally intensive task. The recent approach
TNLS~\cite{li2022permutation} showed promising results for this task, however,
its computational efficiency is still unaffordable, requiring too many
evaluations of the objective function. We propose TnALE, a new algorithm that
updates each structure-related variable alternately by local enumeration,
\emph{greatly} reducing the number of evaluations compared to TNLS. We
theoretically investigate the descent steps for TNLS and TnALE, proving that
both algorithms can achieve linear convergence up to a constant if a sufficient
reduction of the objective is \emph{reached} in each neighborhood. We also
compare the evaluation efficiency of TNLS and TnALE, revealing that
$\Omega(2^N)$ evaluations are typically required in TNLS for \emph{reaching}
the objective reduction in the neighborhood, while ideally $O(N^2R)$
evaluations are sufficient in TnALE, where $N$ denotes the tensor order and $R$
reflects the \emph{``low-rankness''} of the neighborhood. Experimental results
verify that TnALE can find practically good TN-ranks and permutations with
vastly fewer evaluations than the state-of-the-art algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12967'>The Incremental Knapsack Problem with Monotone Submodular All-or-Nothing Profits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Federico D&#x27;Onofrio, Yuri Faenza, Lingyi Zhang</p><p>We study incremental knapsack problems with profits given by a special class
of monotone submodular functions, that we dub all-or-nothing. We show that
these problems are not harder to approximate than a less general class of
modular incremental knapsack problems, that have been investigated in the
literature. We also show that certain extensions to more general submodular
functions are APX-hard.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+DOnofrio_F/0/1/0/all/0/1">Federico D&#x27;Onofrio</a>, <a href="http://arxiv.org/find/cs/1/au:+Faenza_Y/0/1/0/all/0/1">Yuri Faenza</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lingyi Zhang</a></p><p>We study incremental knapsack problems with profits given by a special class
of monotone submodular functions, that we dub all-or-nothing. We show that
these problems are not harder to approximate than a less general class of
modular incremental knapsack problems, that have been investigated in the
literature. We also show that certain extensions to more general submodular
functions are APX-hard.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12992'>Faster High Accuracy Multi-Commodity Flow from Single-Commodity Techniques</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jan van den Brand, Daniel Zhang</p><p>Since the development of efficient linear program solvers in the 80s, all
major improvements for solving multi-commodity flows to high accuracy came from
improvements to general linear program solvers. This differs from the single
commodity problem (e.g.~maximum flow) where all recent improvements also rely
on graph specific techniques such as graph decompositions or the Laplacian
paradigm (see e.g.~[CMSV17,KLS20,BLL+21,CKL+22]).
</p>
<p>This phenomenon sparked research to understand why these graph techniques are
unlikely to help for multi-commodity flow. [Kyng, Zhang'20] reduced solving
multi-commodity Laplacians to general linear systems and [Ding, Kyng, Zhang'22]
showed that general linear programs can be reduced to 2-commodity flow.
However, the reductions create sparse graph instances, so improvement to
multi-commodity flows on denser graphs might exist.
</p>
<p>We show that one can indeed speed up multi-commodity flow algorithms on
non-sparse graphs using graph techniques from single-commodity flow algorithms.
This is the first improvement to high accuracy multi-commodity flow algorithms
that does not just stem from improvements to general linear program solvers. In
particular, using graph data structures from recent min-cost flow algorithm by
[BLL+21] based on the celebrated expander decomposition framework, we show that
2-commodity flow on an $n$-vertex $m$-edge graph can be solved in
$\tilde{O}(\sqrt{m}n^{\omega-1/2})$ time for current bounds on fast matrix
multiplication $\omega \approx 2.373$, improving upon the previous fastest
algorithms with $\tilde{O}(m^\omega)$ [CLS19] and $\tilde{O}(\sqrt{m}n^2)$
[KV96] time complexity. For general $k$ commodities, our algorithm runs in
$\tilde{O}(k^{2.5}\sqrt{m}n^{\omega-1/2})$ time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brand_J/0/1/0/all/0/1">Jan van den Brand</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Daniel Zhang</a></p><p>Since the development of efficient linear program solvers in the 80s, all
major improvements for solving multi-commodity flows to high accuracy came from
improvements to general linear program solvers. This differs from the single
commodity problem (e.g.~maximum flow) where all recent improvements also rely
on graph specific techniques such as graph decompositions or the Laplacian
paradigm (see e.g.~[CMSV17,KLS20,BLL+21,CKL+22]).
</p>
<p>This phenomenon sparked research to understand why these graph techniques are
unlikely to help for multi-commodity flow. [Kyng, Zhang'20] reduced solving
multi-commodity Laplacians to general linear systems and [Ding, Kyng, Zhang'22]
showed that general linear programs can be reduced to 2-commodity flow.
However, the reductions create sparse graph instances, so improvement to
multi-commodity flows on denser graphs might exist.
</p>
<p>We show that one can indeed speed up multi-commodity flow algorithms on
non-sparse graphs using graph techniques from single-commodity flow algorithms.
This is the first improvement to high accuracy multi-commodity flow algorithms
that does not just stem from improvements to general linear program solvers. In
particular, using graph data structures from recent min-cost flow algorithm by
[BLL+21] based on the celebrated expander decomposition framework, we show that
2-commodity flow on an $n$-vertex $m$-edge graph can be solved in
$\tilde{O}(\sqrt{m}n^{\omega-1/2})$ time for current bounds on fast matrix
multiplication $\omega \approx 2.373$, improving upon the previous fastest
algorithms with $\tilde{O}(m^\omega)$ [CLS19] and $\tilde{O}(\sqrt{m}n^2)$
[KV96] time complexity. For general $k$ commodities, our algorithm runs in
$\tilde{O}(k^{2.5}\sqrt{m}n^{\omega-1/2})$ time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, April 25
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11325'>Deterministic identity testing paradigms for bounded top-fanin depth-4 circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pranjal Dutta, Prateek Dwivedi, Nitin Saxena</p><p>Polynomial Identity Testing (PIT) is a fundamental computational problem. The
famous depth-$4$ reduction result by Agrawal and Vinay (FOCS 2008) has made PIT
for depth-$4$ circuits an enticing pursuit. A restricted depth-4 circuit
computing a $n$-variate degree-$d$ polynomial of the form $\sum_{i = 1}^{k}
\prod_{j} g_{ij}$, where $\deg g_{ij} \leq \delta$ is called
$\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ circuit. On further restricting $g_{ij}$
to be sum of univariates we obtain $\Sigma^{[k]}\Pi\Sigma\wedge$ circuits. The
largely open, special-cases of $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ for
constant $k$ and $\delta$, and $\Sigma^{[k]}\Pi\Sigma\wedge$ have been a source
of many great ideas in the last two decades. For eg. depth-$3$ ideas of Dvir
and Shpilka (STOC 2005), Kayal and Saxena (CCC 2006), and Saxena and Seshadhri
(FOCS 2010 and STOC 2011). Further, depth-$4$ ideas of Beecken, Mittmann and
Saxena (ICALP 2011), Saha, Saxena and Saptharishi (Comput.Compl. 2013), Forbes
(FOCS 2015), and Kumar and Saraf (CCC 2016). Additionally, geometric
Sylvester-Gallai ideas of Kayal and Saraf (FOCS 2009), Shpilka (STOC 2019), and
Peleg and Shpilka (CCC 2020, STOC 2021). Very recently, a subexponential-time
blackbox PIT algorithm for constant-depth circuits was obtained via lower bound
breakthrough of Limaye, Srinivasan, Tavenas (FOCS 2021). We solve two of the
basic underlying open problems in this work.
</p>
<p>We give the first polynomial-time PIT for $\Sigma^{[k]}\Pi\Sigma\wedge$. We
also give the first quasipolynomial time blackbox PIT for both
$\Sigma^{[k]}\Pi\Sigma\wedge$ and $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$. A key
technical ingredient in all the three algorithms is how the logarithmic
derivative, and its power-series, modify the top $\Pi$-gate to $\wedge$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dutta_P/0/1/0/all/0/1">Pranjal Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Dwivedi_P/0/1/0/all/0/1">Prateek Dwivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxena_N/0/1/0/all/0/1">Nitin Saxena</a></p><p>Polynomial Identity Testing (PIT) is a fundamental computational problem. The
famous depth-$4$ reduction result by Agrawal and Vinay (FOCS 2008) has made PIT
for depth-$4$ circuits an enticing pursuit. A restricted depth-4 circuit
computing a $n$-variate degree-$d$ polynomial of the form $\sum_{i = 1}^{k}
\prod_{j} g_{ij}$, where $\deg g_{ij} \leq \delta$ is called
$\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ circuit. On further restricting $g_{ij}$
to be sum of univariates we obtain $\Sigma^{[k]}\Pi\Sigma\wedge$ circuits. The
largely open, special-cases of $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ for
constant $k$ and $\delta$, and $\Sigma^{[k]}\Pi\Sigma\wedge$ have been a source
of many great ideas in the last two decades. For eg. depth-$3$ ideas of Dvir
and Shpilka (STOC 2005), Kayal and Saxena (CCC 2006), and Saxena and Seshadhri
(FOCS 2010 and STOC 2011). Further, depth-$4$ ideas of Beecken, Mittmann and
Saxena (ICALP 2011), Saha, Saxena and Saptharishi (Comput.Compl. 2013), Forbes
(FOCS 2015), and Kumar and Saraf (CCC 2016). Additionally, geometric
Sylvester-Gallai ideas of Kayal and Saraf (FOCS 2009), Shpilka (STOC 2019), and
Peleg and Shpilka (CCC 2020, STOC 2021). Very recently, a subexponential-time
blackbox PIT algorithm for constant-depth circuits was obtained via lower bound
breakthrough of Limaye, Srinivasan, Tavenas (FOCS 2021). We solve two of the
basic underlying open problems in this work.
</p>
<p>We give the first polynomial-time PIT for $\Sigma^{[k]}\Pi\Sigma\wedge$. We
also give the first quasipolynomial time blackbox PIT for both
$\Sigma^{[k]}\Pi\Sigma\wedge$ and $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$. A key
technical ingredient in all the three algorithms is how the logarithmic
derivative, and its power-series, modify the top $\Pi$-gate to $\wedge$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11495'>Explicit Directional Affine Extractors and Improved Hardness for Linear Branching Programs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xin Li, Yan Zhong</p><p>In a recent work, Gryaznov, Pudl\'{a}k, and Talebanfard (CCC' 22) introduced
a stronger version of affine extractors known as directional affine extractors,
together with a generalization of $\mathsf{ROBP}$s where each node can make
linear queries, and showed that the former implies strong lower bound for a
certain type of the latter known as strongly read-once linear branching
programs ($\mathsf{SROLBP}$s). Their main result gives explicit constructions
of directional affine extractors for entropy $k &gt; 2n/3$, which implies
average-case complexity $2^{n/3-o(n)}$ against $\mathsf{SROLBP}$s with
exponentially small correlation. A follow-up work by Chattopadhyay and Liao
(ECCC' 22) improves the hardness to $2^{n-o(n)}$ at the price of increasing the
correlation to polynomially large.
</p>
<p>This paper provides a much more in-depth study of directional affine
extractors, $\mathsf{SROLBP}$s, and $\mathsf{ROBP}$s. Our main results include:
</p>
<p>A formal separation between $\mathsf{SROLBP}$ and $\mathsf{ROBP}$, showing
that $\mathsf{SROLBP}$s can be exponentially more powerful than
$\mathsf{ROBP}$s.
</p>
<p>An explicit construction of directional affine extractors with $k=o(n)$ and
exponentially small error, which gives average-case complexity $2^{n-o(n)}$
against $\mathsf{SROLBP}$s with exponentially small correlation, thus answering
the two open questions raised in previous works.
</p>
<p>An explicit function in $\mathsf{AC}^0$ that gives average-case complexity
$2^{(1-\delta)n}$ against $\mathsf{ROBP}$s with negligible correlation, for any
constant $\delta&gt;0$. Previously, the best size lower bound for any function in
$\mathsf{AC}^0$ against $\mathsf{ROBP}$s is only $2^{\Omega(\sqrt{n})}$.
</p>
<p>One of the key ingredients in our constructions is a new linear somewhere
condenser for affine sources.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yan Zhong</a></p><p>In a recent work, Gryaznov, Pudl\'{a}k, and Talebanfard (CCC' 22) introduced
a stronger version of affine extractors known as directional affine extractors,
together with a generalization of $\mathsf{ROBP}$s where each node can make
linear queries, and showed that the former implies strong lower bound for a
certain type of the latter known as strongly read-once linear branching
programs ($\mathsf{SROLBP}$s). Their main result gives explicit constructions
of directional affine extractors for entropy $k &gt; 2n/3$, which implies
average-case complexity $2^{n/3-o(n)}$ against $\mathsf{SROLBP}$s with
exponentially small correlation. A follow-up work by Chattopadhyay and Liao
(ECCC' 22) improves the hardness to $2^{n-o(n)}$ at the price of increasing the
correlation to polynomially large.
</p>
<p>This paper provides a much more in-depth study of directional affine
extractors, $\mathsf{SROLBP}$s, and $\mathsf{ROBP}$s. Our main results include:
</p>
<p>A formal separation between $\mathsf{SROLBP}$ and $\mathsf{ROBP}$, showing
that $\mathsf{SROLBP}$s can be exponentially more powerful than
$\mathsf{ROBP}$s.
</p>
<p>An explicit construction of directional affine extractors with $k=o(n)$ and
exponentially small error, which gives average-case complexity $2^{n-o(n)}$
against $\mathsf{SROLBP}$s with exponentially small correlation, thus answering
the two open questions raised in previous works.
</p>
<p>An explicit function in $\mathsf{AC}^0$ that gives average-case complexity
$2^{(1-\delta)n}$ against $\mathsf{ROBP}$s with negligible correlation, for any
constant $\delta&gt;0$. Previously, the best size lower bound for any function in
$\mathsf{AC}^0$ against $\mathsf{ROBP}$s is only $2^{\Omega(\sqrt{n})}$.
</p>
<p>One of the key ingredients in our constructions is a new linear somewhere
condenser for affine sources.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11429'>The Voronoi Diagram of Rotating Rays with applications to Floodlight Illumination</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Carlos Alegr&#xed;a, Ioannis Mantas, Evanthia Papadopoulou, Marko Savi&#x107;, Carlos Seara, Martin Suderland</p><p>We study the Voronoi Diagram of Rotating Rays, a Voronoi structure where the
input sites are rays and the distance function between a point and a site/ray,
is the counterclockwise angular distance. This novel Voronoi diagram is
motivated by illumination or coverage problems, where a domain must be covered
by floodlights/wedges of uniform angle, and the goal is to find the minimum
angle necessary to cover the domain. We study the diagram in the plane, and we
present structural properties, combinatorial complexity bounds, and a
construction algorithm. If the rays are induced by a convex polygon, we show
how to construct the Voronoi diagram within this polygon in linear time. Using
this information, we can find in optimal linear time the Brocard angle, the
minimum angle required to illuminate a convex polygon with floodlights of
uniform angle.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alegria_C/0/1/0/all/0/1">Carlos Alegr&#xed;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Mantas_I/0/1/0/all/0/1">Ioannis Mantas</a>, <a href="http://arxiv.org/find/cs/1/au:+Papadopoulou_E/0/1/0/all/0/1">Evanthia Papadopoulou</a>, <a href="http://arxiv.org/find/cs/1/au:+Savic_M/0/1/0/all/0/1">Marko Savi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Seara_C/0/1/0/all/0/1">Carlos Seara</a>, <a href="http://arxiv.org/find/cs/1/au:+Suderland_M/0/1/0/all/0/1">Martin Suderland</a></p><p>We study the Voronoi Diagram of Rotating Rays, a Voronoi structure where the
input sites are rays and the distance function between a point and a site/ray,
is the counterclockwise angular distance. This novel Voronoi diagram is
motivated by illumination or coverage problems, where a domain must be covered
by floodlights/wedges of uniform angle, and the goal is to find the minimum
angle necessary to cover the domain. We study the diagram in the plane, and we
present structural properties, combinatorial complexity bounds, and a
construction algorithm. If the rays are induced by a convex polygon, we show
how to construct the Voronoi diagram within this polygon in linear time. Using
this information, we can find in optimal linear time the Brocard angle, the
minimum angle required to illuminate a convex polygon with floodlights of
uniform angle.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11252'>High-Accuracy Multicommodity Flows via Iterative Refinement</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Li Chen, Mingquan Ye</p><p>The multicommodity flow problem is a classic problem in network flow and
combinatorial optimization, with applications in transportation, communication,
logistics, and supply chain management, etc. Existing algorithms often focus on
low-accuracy approximate solutions, while high-accuracy algorithms typically
rely on general linear program solvers. In this paper, we present efficient
high-accuracy algorithms for a broad family of multicommodity flow problems on
undirected graphs, demonstrating improved running times compared to general
linear program solvers. Our main result shows that we can solve the $\ell_{q,
p}$-norm multicommodity flow problem to a $(1 + \varepsilon)$ approximation in
time $O_{q, p}(m^{1+o(1)} k^2 \log(1 / \varepsilon))$, where $k$ is the number
of commodities, and $O_{q, p}(\cdot)$ hides constants depending only on $q$ or
$p$. As $q$ and $p$ approach to $1$ and infinity respectively, $\ell_{q,
p}$-norm flow tends to maximum concurrent flow.
</p>
<p>We introduce the first iterative refinement framework for $\ell_{q, p}$-norm
minimization problems, which reduces the problem to solving a series of
decomposable residual problems. In the case of $k$-commodity flow, each
residual problem can be decomposed into $k$ single commodity convex flow
problems, each of which can be solved in almost-linear time. As many classical
variants of multicommodity flows were shown to be complete for linear programs
in the high-accuracy regime [Ding-Kyng-Zhang, ICALP'22], our result provides
new directions for studying more efficient high-accuracy multicommodity flow
algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Mingquan Ye</a></p><p>The multicommodity flow problem is a classic problem in network flow and
combinatorial optimization, with applications in transportation, communication,
logistics, and supply chain management, etc. Existing algorithms often focus on
low-accuracy approximate solutions, while high-accuracy algorithms typically
rely on general linear program solvers. In this paper, we present efficient
high-accuracy algorithms for a broad family of multicommodity flow problems on
undirected graphs, demonstrating improved running times compared to general
linear program solvers. Our main result shows that we can solve the $\ell_{q,
p}$-norm multicommodity flow problem to a $(1 + \varepsilon)$ approximation in
time $O_{q, p}(m^{1+o(1)} k^2 \log(1 / \varepsilon))$, where $k$ is the number
of commodities, and $O_{q, p}(\cdot)$ hides constants depending only on $q$ or
$p$. As $q$ and $p$ approach to $1$ and infinity respectively, $\ell_{q,
p}$-norm flow tends to maximum concurrent flow.
</p>
<p>We introduce the first iterative refinement framework for $\ell_{q, p}$-norm
minimization problems, which reduces the problem to solving a series of
decomposable residual problems. In the case of $k$-commodity flow, each
residual problem can be decomposed into $k$ single commodity convex flow
problems, each of which can be solved in almost-linear time. As many classical
variants of multicommodity flows were shown to be complete for linear programs
in the high-accuracy regime [Ding-Kyng-Zhang, ICALP'22], our result provides
new directions for studying more efficient high-accuracy multicommodity flow
algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11281'>Euclidean Capacitated Vehicle Routing in Random Setting: A $1.55$-Approximation Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zipei Nie, Hang Zhou</p><p>We study the unit-demand capacitated vehicle routing problem in the random
setting of the Euclidean plane. The objective is to visit $n$ random terminals
in a square using a set of tours of minimum total length, such that each tour
visits the depot and at most $k$ terminals.
</p>
<p>We design an elegant algorithm combining the classical sweep heuristic and
Arora's framework for the Euclidean traveling salesman problem [Journal of the
ACM 1998]. We show that our algorithm is a polynomial-time approximation of
ratio at most $1.55$ asymptotically almost surely. This improves on previous
approximation ratios of $1.995$ due to Bompadre, Dror, and Orlin [Journal of
Applied Probability 2007] and $1.915$ due to Mathieu and Zhou [Random
Structures and Algorithms 2022]. In addition, we conjecture that, for any
$\varepsilon&gt;0$, our algorithm is a $(1+\varepsilon)$-approximation
asymptotically almost surely.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nie_Z/0/1/0/all/0/1">Zipei Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hang Zhou</a></p><p>We study the unit-demand capacitated vehicle routing problem in the random
setting of the Euclidean plane. The objective is to visit $n$ random terminals
in a square using a set of tours of minimum total length, such that each tour
visits the depot and at most $k$ terminals.
</p>
<p>We design an elegant algorithm combining the classical sweep heuristic and
Arora's framework for the Euclidean traveling salesman problem [Journal of the
ACM 1998]. We show that our algorithm is a polynomial-time approximation of
ratio at most $1.55$ asymptotically almost surely. This improves on previous
approximation ratios of $1.995$ due to Bompadre, Dror, and Orlin [Journal of
Applied Probability 2007] and $1.915$ due to Mathieu and Zhou [Random
Structures and Algorithms 2022]. In addition, we conjecture that, for any
$\varepsilon&gt;0$, our algorithm is a $(1+\varepsilon)$-approximation
asymptotically almost surely.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11691'>Covering multigraphs with bipartite graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jaehoon Kim, Hyunwoo Lee</p><p>Hansel's lemma states that $\sum_{H\in \mathcal{H}}|H| \geq n \log_2 n$ holds
where $\mathcal{H}$ is a collection of bipartite graphs covering all the edges
of $K_n$. We generalize this lemma to the corresponding multigraph covering
problem and the graphon covering problem. We also prove an upper bound on
$\sum_{H\in \mathcal{H}}|H|$ which shows that our generalization is
asymptotically tight in some sense.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Kim_J/0/1/0/all/0/1">Jaehoon Kim</a>, <a href="http://arxiv.org/find/math/1/au:+Lee_H/0/1/0/all/0/1">Hyunwoo Lee</a></p><p>Hansel's lemma states that $\sum_{H\in \mathcal{H}}|H| \geq n \log_2 n$ holds
where $\mathcal{H}$ is a collection of bipartite graphs covering all the edges
of $K_n$. We generalize this lemma to the corresponding multigraph covering
problem and the graphon covering problem. We also prove an upper bound on
$\sum_{H\in \mathcal{H}}|H|$ which shows that our generalization is
asymptotically tight in some sense.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, April 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10570'>Geometry of Tensors: Open problems and research directions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fulvio Gesmundo</p><p>This is a collection of open problems and research ideas following the
presentations and the discussions of the AGATES Kickoff Workshop held at the
Institute of Mathematics of the Polish Academy of Sciences (IMPAN) and at the
Department of Mathematics of University of Warsaw (MIM UW), September 19-26,
2022.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gesmundo_F/0/1/0/all/0/1">Fulvio Gesmundo</a></p><p>This is a collection of open problems and research ideas following the
presentations and the discussions of the AGATES Kickoff Workshop held at the
Institute of Mathematics of the Polish Academy of Sciences (IMPAN) and at the
Department of Mathematics of University of Warsaw (MIM UW), September 19-26,
2022.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10594'>Comparative Analysis of Deterministic and Nondeterministic Decision Trees for Decision Tables from Closed Classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Azimkhon Ostonov, Mikhail Moshkov</p><p>In this paper, we consider classes of decision tables with many-valued
decisions closed under operations of removal of columns, changing of decisions,
permutation of columns, and duplication of columns. We study relationships
among three parameters of these tables: the complexity of a decision table (if
we consider the depth of decision trees, then the complexity of a decision
table is the number of columns in it), the minimum complexity of a
deterministic decision tree, and the minimum complexity of a nondeterministic
decision tree. We consider rough classification of functions characterizing
relationships and enumerate all possible seven types of the relationships.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ostonov_A/0/1/0/all/0/1">Azimkhon Ostonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshkov_M/0/1/0/all/0/1">Mikhail Moshkov</a></p><p>In this paper, we consider classes of decision tables with many-valued
decisions closed under operations of removal of columns, changing of decisions,
permutation of columns, and duplication of columns. We study relationships
among three parameters of these tables: the complexity of a decision table (if
we consider the depth of decision trees, then the complexity of a decision
table is the number of columns in it), the minimum complexity of a
deterministic decision tree, and the minimum complexity of a nondeterministic
decision tree. We consider rough classification of functions characterizing
relationships and enumerate all possible seven types of the relationships.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10661'>A Conjecture Related to the Traveling Salesman Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jian Yang</p><p>We show that certain ways of solving some combinatorial optimization problems
can be understood as using query planes to divide the space of problem
instances into polyhedra that could fit into those that characterize the
problem's various solutions. This viewpoint naturally leads to a
splinter-proneness property that is then shown to be responsible for the
hardness of the concerned problem. We conjecture that the $NP$-equivalent
traveling salesman problem (TSP) has this property and hence is hard to solve
to a certain extent.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jian Yang</a></p><p>We show that certain ways of solving some combinatorial optimization problems
can be understood as using query planes to divide the space of problem
instances into polyhedra that could fit into those that characterize the
problem's various solutions. This viewpoint naturally leads to a
splinter-proneness property that is then shown to be responsible for the
hardness of the concerned problem. We conjecture that the $NP$-equivalent
traveling salesman problem (TSP) has this property and hence is hard to solve
to a certain extent.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11017'>Breaking the Log Barrier: a Novel Universal Restart Strategy for Faster Las Vegas Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kevin Scaman</p><p>Let $\mathcal{A}$ be a Las Vegas algorithm, i.e. an algorithm whose running
time $T$ is a random variable drawn according to a certain probability
distribution $p$. In 1993, Luby, Sinclair and Zuckerman [LSZ93] proved that a
simple universal restart strategy can, for any probability distribution $p$,
provide an algorithm executing $\mathcal{A}$ and whose expected running time is
$O(\ell^\star_p\log\ell^\star_p)$, where $\ell^\star_p=\Theta\left(\inf_{q\in
(0,1]}Q_p(q)/q\right)$ is the minimum expected running time achievable with
full prior knowledge of the probability distribution $p$, and $Q_p(q)$ is the
$q$-quantile of $p$. Moreover, the authors showed that the logarithmic term
could not be removed for universal restart strategies and was, in a certain
sense, optimal. In this work, we show that, quite surprisingly, the logarithmic
term can be replaced by a smaller quantity, thus reducing the expected running
time in practical settings of interest. More precisely, we propose a novel
restart strategy that executes $\mathcal{A}$ and whose expected running time is
$O\big(\inf_{q\in (0,1]}\frac{Q_p(q)}{q}\,\psi\big(\log Q_p(q),\,\log
(1/q)\big)\big)$ where $\psi(a,b)=1+\min\left\{a+b,a\log^2 a,\,b\log^2
b\right\}$. This quantity is, up to a multiplicative factor, better than: 1)
the universal restart strategy of [LSZ93], 2) any $q$-quantile of $p$ for
$q\in(0,1]$, 3) the original algorithm, and 4) any quantity of the form
$\phi^{-1}(\mathbb{E}[\phi(T)])$ for a large class of concave functions $\phi$.
The latter extends the recent restart strategy of [Zam22] achieving
$O\left(e^{\mathbb{E}[\ln(T)]}\right)$, and can be thought of as algorithmic
reverse Jensen's inequalities. Finally, we show that the behavior of
$\frac{t\phi''(t)}{\phi'(t)}$ at infinity controls the existence of reverse
Jensen's inequalities by providing a necessary and a sufficient condition for
these inequalities to hold.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Scaman_K/0/1/0/all/0/1">Kevin Scaman</a></p><p>Let $\mathcal{A}$ be a Las Vegas algorithm, i.e. an algorithm whose running
time $T$ is a random variable drawn according to a certain probability
distribution $p$. In 1993, Luby, Sinclair and Zuckerman [LSZ93] proved that a
simple universal restart strategy can, for any probability distribution $p$,
provide an algorithm executing $\mathcal{A}$ and whose expected running time is
$O(\ell^\star_p\log\ell^\star_p)$, where $\ell^\star_p=\Theta\left(\inf_{q\in
(0,1]}Q_p(q)/q\right)$ is the minimum expected running time achievable with
full prior knowledge of the probability distribution $p$, and $Q_p(q)$ is the
$q$-quantile of $p$. Moreover, the authors showed that the logarithmic term
could not be removed for universal restart strategies and was, in a certain
sense, optimal. In this work, we show that, quite surprisingly, the logarithmic
term can be replaced by a smaller quantity, thus reducing the expected running
time in practical settings of interest. More precisely, we propose a novel
restart strategy that executes $\mathcal{A}$ and whose expected running time is
$O\big(\inf_{q\in (0,1]}\frac{Q_p(q)}{q}\,\psi\big(\log Q_p(q),\,\log
(1/q)\big)\big)$ where $\psi(a,b)=1+\min\left\{a+b,a\log^2 a,\,b\log^2
b\right\}$. This quantity is, up to a multiplicative factor, better than: 1)
the universal restart strategy of [LSZ93], 2) any $q$-quantile of $p$ for
$q\in(0,1]$, 3) the original algorithm, and 4) any quantity of the form
$\phi^{-1}(\mathbb{E}[\phi(T)])$ for a large class of concave functions $\phi$.
The latter extends the recent restart strategy of [Zam22] achieving
$O\left(e^{\mathbb{E}[\ln(T)]}\right)$, and can be thought of as algorithmic
reverse Jensen's inequalities. Finally, we show that the behavior of
$\frac{t\phi''(t)}{\phi'(t)}$ at infinity controls the existence of reverse
Jensen's inequalities by providing a necessary and a sufficient condition for
these inequalities to hold.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11102'>Solid angle measure of polyhedral cones</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Allison Fitisone, Yuan Zhou</p><p>This paper addresses the computation of normalized solid angle measure of
polyhedral cones. This is well understood in dimensions two and three. For
higher dimensions, assuming that a positive-definite criterion is met, the
measure can be computed via a multivariable hypergeometric series. We present
two decompositions of full-dimensional simplicial cones into finite families of
cones satisfying the positive-definite criterion, enabling the use of the
hypergeometric series to compute the solid angle measure of any polyhedral
cone. Additionally, our second decomposition method yields cones with a special
tridiagonal structure, reducing the number of required coordinates for the
hypergeometric series formula. Furthermore, we investigate the convergence of
the hypergeometric series for this case. Our findings provide a powerful tool
for computing solid angle measures in high-dimensional spaces.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Fitisone_A/0/1/0/all/0/1">Allison Fitisone</a>, <a href="http://arxiv.org/find/math/1/au:+Zhou_Y/0/1/0/all/0/1">Yuan Zhou</a></p><p>This paper addresses the computation of normalized solid angle measure of
polyhedral cones. This is well understood in dimensions two and three. For
higher dimensions, assuming that a positive-definite criterion is met, the
measure can be computed via a multivariable hypergeometric series. We present
two decompositions of full-dimensional simplicial cones into finite families of
cones satisfying the positive-definite criterion, enabling the use of the
hypergeometric series to compute the solid angle measure of any polyhedral
cone. Additionally, our second decomposition method yields cones with a special
tridiagonal structure, reducing the number of required coordinates for the
hypergeometric series formula. Furthermore, we investigate the convergence of
the hypergeometric series for this case. Our findings provide a powerful tool
for computing solid angle measures in high-dimensional spaces.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10647'>New Lower Bounds for Adaptive Tolerant Junta Testing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xi Chen, Shyamal Patel</p><p>We prove a $k^{-\Omega(\log(\varepsilon_2 - \varepsilon_1))}$ lower bound for
adaptively testing whether a Boolean function is $\varepsilon_1$-close to or
$\varepsilon_2$-far from $k$-juntas. Our results provide the first
superpolynomial separation between tolerant and non-tolerant testing for a
natural property of boolean functions under the adaptive setting. Furthermore,
our techniques generalize to show that adaptively testing whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from $(k +
o(k))$-juntas cannot be done with $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries. This is in contrast to an algorithm by Iyer, Tal
and Whitmeyer [CCC 2021] which uses $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries to test whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from
$O(k/(\varepsilon_2-\varepsilon_1)^2)$-juntas.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1">Shyamal Patel</a></p><p>We prove a $k^{-\Omega(\log(\varepsilon_2 - \varepsilon_1))}$ lower bound for
adaptively testing whether a Boolean function is $\varepsilon_1$-close to or
$\varepsilon_2$-far from $k$-juntas. Our results provide the first
superpolynomial separation between tolerant and non-tolerant testing for a
natural property of boolean functions under the adaptive setting. Furthermore,
our techniques generalize to show that adaptively testing whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from $(k +
o(k))$-juntas cannot be done with $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries. This is in contrast to an algorithm by Iyer, Tal
and Whitmeyer [CCC 2021] which uses $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries to test whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from
$O(k/(\varepsilon_2-\varepsilon_1)^2)$-juntas.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10848'>How Well Does the Metropolis Algorithm Cope With Local Optima?</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Benjamin Doerr, Taha El Ghazi El Houssaini, Amirhossein Rajabi, Carsten Wit</p><p>The Metropolis algorithm (MA) is a classic stochastic local search heuristic.
It avoids getting stuck in local optima by occasionally accepting inferior
solutions. To better and in a rigorous manner understand this ability, we
conduct a mathematical runtime analysis of the MA on the CLIFF benchmark. Apart
from one local optimum, cliff functions are monotonically increasing towards
the global optimum. Consequently, to optimize a cliff function, the MA only
once needs to accept an inferior solution. Despite seemingly being an ideal
benchmark for the MA to profit from its main working principle, our
mathematical runtime analysis shows that this hope does not come true. Even
with the optimal temperature (the only parameter of the MA), the MA optimizes
most cliff functions less efficiently than simple elitist evolutionary
algorithms (EAs), which can only leave the local optimum by generating a
superior solution possibly far away. This result suggests that our
understanding of why the MA is often very successful in practice is not yet
complete. Our work also suggests to equip the MA with global mutation
operators, an idea supported by our preliminary experiments.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Doerr_B/0/1/0/all/0/1">Benjamin Doerr</a>, <a href="http://arxiv.org/find/cs/1/au:+Houssaini_T/0/1/0/all/0/1">Taha El Ghazi El Houssaini</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajabi_A/0/1/0/all/0/1">Amirhossein Rajabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wit_C/0/1/0/all/0/1">Carsten Wit</a></p><p>The Metropolis algorithm (MA) is a classic stochastic local search heuristic.
It avoids getting stuck in local optima by occasionally accepting inferior
solutions. To better and in a rigorous manner understand this ability, we
conduct a mathematical runtime analysis of the MA on the CLIFF benchmark. Apart
from one local optimum, cliff functions are monotonically increasing towards
the global optimum. Consequently, to optimize a cliff function, the MA only
once needs to accept an inferior solution. Despite seemingly being an ideal
benchmark for the MA to profit from its main working principle, our
mathematical runtime analysis shows that this hope does not come true. Even
with the optimal temperature (the only parameter of the MA), the MA optimizes
most cliff functions less efficiently than simple elitist evolutionary
algorithms (EAs), which can only leave the local optimum by generating a
superior solution possibly far away. This result suggests that our
understanding of why the MA is often very successful in practice is not yet
complete. Our work also suggests to equip the MA with global mutation
operators, an idea supported by our preliminary experiments.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10962'>Faster Prefix-Sorting Algorithms for Deterministic Finite Automata</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sung-Hwan Kim, Francisco Olivares, Nicola Prezza</p><p>Sorting is a fundamental algorithmic pre-processing technique which often
allows to represent data more compactly and, at the same time, speeds up search
queries on it. In this paper, we focus on the well-studied problem of sorting
and indexing string sets. Since the introduction of suffix trees in 1973,
dozens of suffix sorting algorithms have been described in the literature. In
2017, these techniques were extended to sets of strings described by means of
finite automata: the theory of Wheeler graphs [Gagie et al., TCS'17] introduced
automata whose states can be totally-sorted according to the co-lexicographic
(co-lex in the following) order of the prefixes of words accepted by the
automaton. More recently, in [Cotumaccio, Prezza, SODA'21] it was shown how to
extend these ideas to arbitrary automata by means of partial co-lex orders.
This work showed that a co-lex order of minimum width (thus optimizing search
query times) on deterministic finite automata (DFAs) can be computed in $O(m^2
+ n^{5/2})$ time, $m$ being the number of transitions and $n$ the number of
states of the input DFA.
</p>
<p>In this paper, we exhibit new combinatorial properties of the minimum-width
co-lex order of DFAs and exploit them to design faster prefix sorting
algorithms. In particular, we describe two algorithms sorting arbitrary DFAs in
$O(mn)$ and $O(n^2\log n)$ time, respectively, and an algorithm sorting acyclic
DFAs in $O(m\log n)$ time. Within these running times, all algorithms compute
also a smallest chain partition of the partial order (required to index the
DFA). We present an experiment result to show that an optimized implementation
of the $O(n^2\log n)$-time algorithm exhibits a nearly-linear behaviour on
large deterministic pan-genomic graphs and is thus also of practical interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sung-Hwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Olivares_F/0/1/0/all/0/1">Francisco Olivares</a>, <a href="http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1">Nicola Prezza</a></p><p>Sorting is a fundamental algorithmic pre-processing technique which often
allows to represent data more compactly and, at the same time, speeds up search
queries on it. In this paper, we focus on the well-studied problem of sorting
and indexing string sets. Since the introduction of suffix trees in 1973,
dozens of suffix sorting algorithms have been described in the literature. In
2017, these techniques were extended to sets of strings described by means of
finite automata: the theory of Wheeler graphs [Gagie et al., TCS'17] introduced
automata whose states can be totally-sorted according to the co-lexicographic
(co-lex in the following) order of the prefixes of words accepted by the
automaton. More recently, in [Cotumaccio, Prezza, SODA'21] it was shown how to
extend these ideas to arbitrary automata by means of partial co-lex orders.
This work showed that a co-lex order of minimum width (thus optimizing search
query times) on deterministic finite automata (DFAs) can be computed in $O(m^2
+ n^{5/2})$ time, $m$ being the number of transitions and $n$ the number of
states of the input DFA.
</p>
<p>In this paper, we exhibit new combinatorial properties of the minimum-width
co-lex order of DFAs and exploit them to design faster prefix sorting
algorithms. In particular, we describe two algorithms sorting arbitrary DFAs in
$O(mn)$ and $O(n^2\log n)$ time, respectively, and an algorithm sorting acyclic
DFAs in $O(m\log n)$ time. Within these running times, all algorithms compute
also a smallest chain partition of the partial order (required to index the
DFA). We present an experiment result to show that an optimized implementation
of the $O(n^2\log n)$-time algorithm exhibits a nearly-linear behaviour on
large deterministic pan-genomic graphs and is thus also of practical interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10995'>Solving the List Coloring Problem through a Branch-and-Price algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mauro Lucci, Daniel Severin, Graciela Nasini</p><p>In this work, we present a branch-and-price algorithm to solve the weighted
version of the List Coloring Problem, based on a vertex cover formulation by
stable sets. This problem is interesting for its applications and also for the
many other problems that it generalizes, including the well-known Graph
Coloring Problem. With the introduction of the concept of indistinguishable
colors, some theoretical results are presented which are later incorporated
into the algorithm. We propose two branching strategies based on others for the
Graph Coloring Problem, the first is an adaptation of the one used by Mehrotra
and Trick in their pioneering branch-and-price algorithm, and the other is
inspired by the one used by M\'endez-D\'iaz and Zabala in their branch-and-cut
algorithm. The rich structure of this problem makes both branching strategies
robust. Extended computation experimentation on a wide variety of instances
shows the effectiveness of this approach and evidences the different behaviors
that the algorithm can have according to the structure of each type of
instance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lucci_M/0/1/0/all/0/1">Mauro Lucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Severin_D/0/1/0/all/0/1">Daniel Severin</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasini_G/0/1/0/all/0/1">Graciela Nasini</a></p><p>In this work, we present a branch-and-price algorithm to solve the weighted
version of the List Coloring Problem, based on a vertex cover formulation by
stable sets. This problem is interesting for its applications and also for the
many other problems that it generalizes, including the well-known Graph
Coloring Problem. With the introduction of the concept of indistinguishable
colors, some theoretical results are presented which are later incorporated
into the algorithm. We propose two branching strategies based on others for the
Graph Coloring Problem, the first is an adaptation of the one used by Mehrotra
and Trick in their pioneering branch-and-price algorithm, and the other is
inspired by the one used by M\'endez-D\'iaz and Zabala in their branch-and-cut
algorithm. The rich structure of this problem makes both branching strategies
robust. Extended computation experimentation on a wide variety of instances
shows the effectiveness of this approach and evidences the different behaviors
that the algorithm can have according to the structure of each type of
instance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11012'>Learned Monotone Minimal Perfect Hashing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Paolo Ferragina, Hans-Peter Lehmann, Peter Sanders, Giorgio Vinciguerra</p><p>A Monotone Minimal Perfect Hash Function (MMPHF) constructed on a set S of
keys is a function that maps each key in S to its rank. On keys not in S, the
function returns an arbitrary value. Applications range from databases, search
engines, data encryption, to pattern-matching algorithms.
</p>
<p>In this paper, we describe LeMonHash, a new technique for constructing MMPHFs
for integers. The core idea of LeMonHash is surprisingly simple and effective:
we learn a monotone mapping from keys to their rank via an error-bounded
piecewise linear model (the PGM-index), and then we solve the collisions that
might arise among keys mapping to the same rank estimate by associating small
integers with them in a retrieval data structure (BuRR). On synthetic random
datasets, LeMonHash needs 35% less space than the next best competitor, while
achieving about 16 times faster queries. On real-world datasets, the space
usage is very close to or much better than the best competitors, while
achieving up to 19 times faster queries than the next larger competitor. As far
as the construction of LeMonHash is concerned, we get an improvement by a
factor of up to 2, compared to the competitor with the next best space usage.
</p>
<p>We also investigate the case of keys being variable-length strings,
introducing the so-called LeMonHash-VL: it needs space within 10% of the best
competitors while achieving up to 3 times faster queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ferragina_P/0/1/0/all/0/1">Paolo Ferragina</a>, <a href="http://arxiv.org/find/cs/1/au:+Lehmann_H/0/1/0/all/0/1">Hans-Peter Lehmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanders_P/0/1/0/all/0/1">Peter Sanders</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinciguerra_G/0/1/0/all/0/1">Giorgio Vinciguerra</a></p><p>A Monotone Minimal Perfect Hash Function (MMPHF) constructed on a set S of
keys is a function that maps each key in S to its rank. On keys not in S, the
function returns an arbitrary value. Applications range from databases, search
engines, data encryption, to pattern-matching algorithms.
</p>
<p>In this paper, we describe LeMonHash, a new technique for constructing MMPHFs
for integers. The core idea of LeMonHash is surprisingly simple and effective:
we learn a monotone mapping from keys to their rank via an error-bounded
piecewise linear model (the PGM-index), and then we solve the collisions that
might arise among keys mapping to the same rank estimate by associating small
integers with them in a retrieval data structure (BuRR). On synthetic random
datasets, LeMonHash needs 35% less space than the next best competitor, while
achieving about 16 times faster queries. On real-world datasets, the space
usage is very close to or much better than the best competitors, while
achieving up to 19 times faster queries than the next larger competitor. As far
as the construction of LeMonHash is concerned, we get an improvement by a
factor of up to 2, compared to the competitor with the next best space usage.
</p>
<p>We also investigate the case of keys being variable-length strings,
introducing the so-called LeMonHash-VL: it needs space within 10% of the best
competitors while achieving up to 3 times faster queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, April 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/04/thoughts-on-gordon-moore.html'>Thoughts on Gordon Moore</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;Gordon Moore passed away on March 24, 2023. He was 94 years old.&nbsp;</p><p>He is best known for the article&nbsp;</p><p><br></p><p>Cramming more components onto integrated circuits.&nbsp;</p><p>It appeared in the magazine Electronics (it is now defunct), Volume 38, No. 8, April 19, 1965. Do you need to track it down in the basement of your library. No. Its&nbsp;here&nbsp;and here.&nbsp;I wonder if Moore would have predicted that his article would be available easily over 50 years later. Or is it? Link rot is a serious problem so you might want to download it to your local files. Note that the first link is some sort of official version and the second version is my local version. Not clear which link will rot first. The article also has an addition which is an interview with Moore that was done later.</p><p>In the article Moore said that the number of components-per-circuit (I think that means chip) will double every year. Moore credits Dave House with modifying it to `doubling every 18 months' and Carver Mead with calling it `Moore's Law'.&nbsp; Later it came to be quoted as computer SPEED would double every 18 months. We will take this to be Moore's Law in this blog post.&nbsp;</p><p>Is Moore's law dead? Browsing Google the answer seems to be that it is slowing down but not dead yet. (IDEA for a comedy sketch: Redo the Monty Python Dead Parrot sketch about the death of Moore's law.)&nbsp;</p><p>If Moore had 1 penny in April 1965 and it doubled every 18 months then how rich would he be now? How rich was he in April 2022? Compare the two numbers.&nbsp;</p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;Gordon Moore passed away on March 24, 2023. He was 94 years old.&nbsp;</p><p>He is best known for the article&nbsp;</p><p><br /></p><p><i>Cramming more components onto integrated circuits.&nbsp;</i></p><p>It appeared in the magazine Electronics (it is now defunct), Volume 38, No. 8, April 19, 1965. Do you need to track it down in the basement of your library. No. Its&nbsp;<a href="https://hasler.ece.gatech.edu/Published_papers/Technology_overview/gordon_moore_1965_article.pdf">here</a>&nbsp;and <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/gmoore.pdf">here</a>.&nbsp;I wonder if Moore would have predicted that his article would be available easily over 50 years later. Or is it? Link rot is a serious problem so you might want to download it to your local files. Note that the first link is some sort of official version and the second version is my local version. Not clear which link will rot first. The article also has an addition which is an interview with Moore that was done later.</p><p>In the article Moore said that the number of components-per-circuit (I think that means chip) will double every year. Moore credits Dave House with modifying it to `doubling every 18 months' and Carver Mead with calling it `Moore's Law'.&nbsp; Later it came to be quoted as computer SPEED would double every 18 months. We will take this to be Moore's Law in this blog post.&nbsp;</p><p>Is Moore's law dead? Browsing Google the answer seems to be that it is slowing down but not dead yet. (IDEA for a comedy sketch: Redo the Monty Python Dead Parrot sketch about the death of Moore's law.)&nbsp;</p><p>If Moore had 1 penny in April 1965 and it doubled every 18 months then how rich would he be now? How rich was he in April 2022? Compare the two numbers.&nbsp;</p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-23T20:05:00Z">Sunday, April 23 2023, 20:05</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, April 22
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/'>Some Rice News</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Lydia Kavraki is the Noah Harding Professor of Computer Science at Rice University. She is also professor of Bioengineering, professor of Electrical and Computer Engineering, and professor of Mechanical Engineering at Rice. She is the current Director of the Ken Kennedy Institute at Rice. Today we congratulate her on being elected to the American Academy [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
Lydia Kavraki is the Noah Harding Professor of Computer Science at Rice University. She is also professor of Bioengineering, professor of Electrical and Computer Engineering, and professor of Mechanical Engineering at Rice. She is the current Director of the <a href="https://kenkennedy.rice.edu">Ken Kennedy Institute</a> at Rice. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/lk2/" rel="attachment wp-att-21504"><img data-attachment-id="21504" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/lk2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/lk2.jpeg?fit=192%2C241&amp;ssl=1" data-orig-size="192,241" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="lk2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/lk2.jpeg?fit=192%2C241&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/lk2.jpeg?fit=192%2C241&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/lk2.jpeg?resize=192%2C241&#038;ssl=1" alt="" width="192" height="241" class="aligncenter size-full wp-image-21504" data-recalc-dims="1" /></a></p>
<p>
Today we congratulate her on being elected to the American Academy of Arts and Sciences (<a href="https://www.amacad.org">AAAS</a>). </p>
<p>
Kavraki has multiple other affiliations listed on her <a href="https://www.cs.rice.edu/~kavraki/">home page</a>, including her own <a href="https://www.kavrakilab.org/">laboratory</a> on computational robotics and biomedicine. Now with AAAS, she acquires one more. It is enough to make us wonder whether her growth-of-affiliations function per year is additive or multiplicative. </p>
<p>
If the latter, then it would call to mind the story of rice grains on a chessboard. The emperor thinks it would be trivial to grant a reward of one grain of rice on the first square, two on the second square, four on the third square, eight on the fourth, and so on. It does not take many doublings for the number of grains to grow far in excess of this picture:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/rice/" rel="attachment wp-att-21494"><img data-attachment-id="21494" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/rice/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?fit=302%2C167&amp;ssl=1" data-orig-size="302,167" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rice" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?fit=300%2C166&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?fit=302%2C167&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?resize=302%2C167&#038;ssl=1" alt="" width="302" height="167" class="aligncenter size-full wp-image-21494" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?w=302&amp;ssl=1 302w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?resize=300%2C167&amp;ssl=1 300w" sizes="(max-width: 302px) 100vw, 302px" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Brief Roadmap to Her Work </H2></p>
<p><p>
Suppose a chess queen has outstretched arms that made it difficult to move her on a board without knocking over other pieces. We will require her to make a legal move in chess, but not necessarily take the direct route to her destination square. If a roundabout route through a less-crowded area of the board can get her safely to her goal, we will allow our player to move her that way. Naturally, the player could be a robot arm that can picture the whole board but may only slide the queen, not hoist her vertically to hop her to a square.</p>
<p>
What&#8217;s the best way in practice to find a route, if one exists? We could try all possible paths, but here is where the grains-of-rice factor comes in. This is not because there are many squares, but because the queen&#8217;s arms may leave her little wiggle room on a square. She may have to shimmy to get by the nose of an enemy knight, but then find herself unable to twist around a chain of pawns. To avoid such backtracks, we&#8217;d need to make a roadmap of the entire board not in the space of squares, but in the possible <em>configuration space</em> of the queen, given the positioning of other pieces as obstacles. That space can be too large to map exhaustively.</p>
<p>
In work with her PhD adviser Jean-Clause Latombe and others, Kavraki was the guiding force in discovering that random sampling of the configuration space almost always efficiently finds a route when one exists. The sampling grows progressively longer transitions between configurations that the queen is able to make, and proclaims success when the goal configuration is connected to the origin. Then a deterministic shortest-path algorithm can be run on the resulting graph&#8212;a manageable subset of the whole configuration space&#8212;to find an optimal route through that graph. By the nature of physical space, this is usually optimum overall.</p>
<p>
Kavraki&#8217;s <a href="https://en.wikipedia.org/wiki/Probabilistic_roadmap">probabilistic roadmap</a> <em>paradigm</em> extends to many other settings besides moving robots. In biomedicine it applies to how a drug molecule can be designed to maximize its expectation of finding configurations that will combat a pathogen. Her 2017 ACM Athena Lecturer Award <a href="https://www.acm.org/articles/bulletins/2017/april/athena-2017-kavraki">citation</a> notes how her work has found paths into &#8220;an impressively wide range of areas.&#8221;</p>
<p>
<p><H2> Ken Kennedy&#8217;s Institute </H2></p>
<p><p>
Rice University is one of the top university especially when we look at its computer science <a href="https://csweb.rice.edu">program</a>. This historically was thanks to Ken Kennedy who sadly died years ago on 2007 February 7th. Ken was one of the world&#8217;s foremost experts on high-performance computing. He attended Rice University, receiving a B.A. in mathematics (summa cum laude) in 1967. He pursued graduate studies at New York University, where he earned a M.S. in mathematics in 1969 and a Ph.D. in computer science in 1971. Then he returned to Rice.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/kk-2/" rel="attachment wp-att-21495"><img data-attachment-id="21495" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/kk-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kk.jpeg?fit=140%2C158&amp;ssl=1" data-orig-size="140,158" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kk" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kk.jpeg?fit=140%2C158&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kk.jpeg?fit=140%2C158&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kk.jpeg?resize=140%2C158&#038;ssl=1" alt="" width="140" height="158" class="aligncenter size-full wp-image-21495" data-recalc-dims="1" /></a></p>
<p>
Rice president David Leebron said: </p>
<blockquote><p>
&#8220;In Ken Kennedy, Rice has lost one of its great intellectual leaders and a great human being.  [He] early on realized the power of computers to address real problems that confront people and the Earth. Ken leaves a great legacy for Rice and for mankind. He will be missed.&#8221;
</p></blockquote>
<p><a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/owls2/" rel="attachment wp-att-21496"><img data-attachment-id="21496" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/owls2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/owls2.jpeg?fit=253%2C199&amp;ssl=1" data-orig-size="253,199" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="owls2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/owls2.jpeg?fit=253%2C199&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/owls2.jpeg?fit=253%2C199&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/owls2.jpeg?resize=253%2C199&#038;ssl=1" alt="" width="253" height="199" class="aligncenter size-full wp-image-21496" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Previous Leader </H2></p>
<p>
<p>
A previous leader of the Kennedy Institute is Moshe Vardi, an old friend whose work we first covered <a href="https://rjlipton.wpcomstaging.com/2011/07/28/logic-in-action/">here</a> and whom we&#8217;ve mentioned numerous times since, including about <a href="https://rjlipton.wpcomstaging.com/2020/09/10/hybrid-versus-remote-teaching/">teaching</a> during the pandemic. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/mv2/" rel="attachment wp-att-21499"><img data-attachment-id="21499" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/mv2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?fit=240%2C240&amp;ssl=1" data-orig-size="240,240" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mv2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?fit=240%2C240&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?fit=240%2C240&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?resize=160%2C160&#038;ssl=1" alt="" width="160" height="160" class="aligncenter wp-image-21499" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?w=240&amp;ssl=1 240w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 160px) 100vw, 160px" data-recalc-dims="1" /></a></p>
<p>
He also has a bunch of titles, including Professor of Computer Science, University Professor, the Karen Ostrum George Professor in Computational Engineering, and Distinguished Service Professor&#8212;but more notable is that he <a href="https://www.cs.rice.edu/~vardi/long-bio.html">has</a> even more honorary doctorates than affiliations:</p>
<blockquote>
<p>
He holds honorary doctorates from the University of Saarland, Germany, the University of Orleans in France, UFRGS in Brazil, the University of Liege in Belgium, the Technical University of Vienna, Austria, the University of Edinburgh in Scotland, the University of Grenoble-Alpes, and Gothenburg University in Sweden.
</p></blockquote>
<p>
<p>
<p><H2> AAAS </H2></p>
<p><p>
David Oxtoby is the current President of the American Academy of Arts and <a href="https://www.amacad.org">Sciences</a>. In his annoucement of the new class he says:</p>
<blockquote><p><b> </b> <em></p>
<p>
The very first class of members elected to the Academy in 1781 included Benjamin Franklin and George Washington, and today I&#8217;m pleased to announce the new members elected to the American Academy of Arts and Sciences this year.<br />
</em>
</p></blockquote>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/do/" rel="attachment wp-att-21500"><img data-attachment-id="21500" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/do/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/do.jpeg?fit=216%2C233&amp;ssl=1" data-orig-size="216,233" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="do" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/do.jpeg?fit=216%2C233&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/do.jpeg?fit=216%2C233&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/do.jpeg?resize=144%2C158&#038;ssl=1" alt="" width="144" height="158" class="aligncenter wp-image-21500" data-recalc-dims="1" /></a></p>
<p><p>
The new computer science electees are listed <a href="https://www.amacad.org/new-members-2023">here</a> and include several others we know well and whose work we have covered. We list Kavraki again in case this list is taken as &#8220;the&#8221; list.</p>
<ul>
<p><li>
Michael Franklin <a href="https://cs.uchicago.edu/people/michael-franklin/">MF</a>, University of Chicago </p>
<p><li>
Xuedong Huang <a href="https://www.microsoft.com/en-us/research/people/xdh/">XH</a>, Microsoft Corporation</p>
<p><li>
Piotr Indyk <a href="https://people.csail.mit.edu/indyk/">PI</a>, Massachusetts Institute of Technology</p>
<p><li>
Lydia Kavraki <a href="https://www.cs.rice.edu/~kavraki/">LK</a>, Rice University</p>
<p><li>
Marta Kwiatkowska <a href="https://www.trinity.ox.ac.uk/people/marta-kwiatkowska">MK</a>, University of Oxford (international honorary member)</p>
<p><li>
Maja Mataric <a href="https://viterbi.usc.edu/directory/faculty/Mataric/Maja">MM</a>, University of Southern California Viterbi School of Engineering</p>
<p><li>
Kathryn McKinley <a href="https://thenewstack.io/google-cloud-engineer-kathryn-s-mckinley-on-leadership-mentoring-garbage-collection-and-rust/">KM</a>, Google LLC</p>
<p><li>
Gordon Plotkin (IHM) <a href="https://www.research.ed.ac.uk/en/persons/gordon-plotkin">GP</a>, University of Edinburgh</p>
<p><li>
Moti Yung <a href="https://www.researchgate.net/profile/Moti-Yung">MY</a>, Google LLC</p>
</ul>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Our congratulations again to all those just elected. </p>
<p><P><br />
[Words &#8220;for Information Technology&#8221; from previous name of the Ken Kennedy Institute deleted from intro]</p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-22T15:22:28Z">Saturday, April 22 2023, 15:22</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, April 21
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10106'>No Where to Go But High: A Perspective on High Dimensional Expanders</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Roy Gotlib, Tali Kaufman</p><p>"No Where to go but in" is a well known statement of Osho. Osho meant to say
that the answers to all our questions should be obtained by looking into
ourselves. In a paraphrase to Osho's statement we say "No Where to go but
high". This meant to demonstrate that for various seemingly unrelated topics
and questions the only way to get significant progress is via the prism of a
new philosophy (new field) called high dimensional expansion. In this note we
give an introduction \footnote{This introduction reflects the authors'
interests and by no mean claim to represent the field in a through way} to the
high dimensional expansion philosophy, and how it has been useful recently in
obtaining progress in various questions in seemingly unrelated fields.
</p>
<p>This exposition is dedicated to the memory of my mother, Sarah Kaufman, who
was always trying to understand the reason why things behave in a certain way.
It is also dedicated to the memory of my father Eliezer Kaufman.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gotlib_R/0/1/0/all/0/1">Roy Gotlib</a>, <a href="http://arxiv.org/find/math/1/au:+Kaufman_T/0/1/0/all/0/1">Tali Kaufman</a></p><p>"No Where to go but in" is a well known statement of Osho. Osho meant to say
that the answers to all our questions should be obtained by looking into
ourselves. In a paraphrase to Osho's statement we say "No Where to go but
high". This meant to demonstrate that for various seemingly unrelated topics
and questions the only way to get significant progress is via the prism of a
new philosophy (new field) called high dimensional expansion. In this note we
give an introduction \footnote{This introduction reflects the authors'
interests and by no mean claim to represent the field in a through way} to the
high dimensional expansion philosophy, and how it has been useful recently in
obtaining progress in various questions in seemingly unrelated fields.
</p>
<p>This exposition is dedicated to the memory of my mother, Sarah Kaufman, who
was always trying to understand the reason why things behave in a certain way.
It is also dedicated to the memory of my father Eliezer Kaufman.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09990'>Reconfiguration of 3D Pivoting Modular Robots</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hugo A. Akitaya, Frederick Stock</p><p>We study a new model of 3-dimensional modular self-reconfigurable robots
Rhombic Dodecahedral (RD). By extending results on the 2D analog of this model
we characterize the free space requirements for a pivoting move and investigate
the $\textit{reconfiguration problem}$, that is, given two configurations $s$
and $t$ is there a sequence of moves that transforms $s$ into $t$? We show
reconfiguration is PSPACE-hard for RD modules in a restricted pivoting model.
In a more general model, we show that RD configurations are not universally
reconfigurable despite the fact that their 2D analog is [Akitaya et al., SoCG
2021]. Additionally, we present a new class of RD configurations that we call
$\textit{super-rigid}$. Such a configuration remains rigid even as a subset of
any larger configuration, which does not exist in the 2D setting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Akitaya_H/0/1/0/all/0/1">Hugo A. Akitaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Stock_F/0/1/0/all/0/1">Frederick Stock</a></p><p>We study a new model of 3-dimensional modular self-reconfigurable robots
Rhombic Dodecahedral (RD). By extending results on the 2D analog of this model
we characterize the free space requirements for a pivoting move and investigate
the $\textit{reconfiguration problem}$, that is, given two configurations $s$
and $t$ is there a sequence of moves that transforms $s$ into $t$? We show
reconfiguration is PSPACE-hard for RD modules in a restricted pivoting model.
In a more general model, we show that RD configurations are not universally
reconfigurable despite the fact that their 2D analog is [Akitaya et al., SoCG
2021]. Additionally, we present a new class of RD configurations that we call
$\textit{super-rigid}$. Such a configuration remains rigid even as a subset of
any larger configuration, which does not exist in the 2D setting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10028'>Minimizing the Size of the Uncertainty Regions for Centers of Moving Entities</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: William Evans, Seyed Ali Tabatabaee</p><p>In this paper, we study the problems of computing the 1-center, centroid, and
1-median of objects moving with bounded speed in Euclidean space. We can
acquire the exact location of only a constant number of objects (usually one)
per unit time, but for every other object, its set of potential locations,
called the object's uncertainty region, grows subject only to the speed limit.
As a result, the center of the objects may be at several possible locations,
called the center's uncertainty region. For each of these center problems, we
design query strategies to minimize the size of the center's uncertainty region
and compare its performance to an optimal query strategy that knows the
trajectories of the objects, but must still query to reduce their uncertainty.
For the static case of the 1-center problem in R^1, we show an algorithm that
queries four objects per unit time and works as well as the optimal algorithm
with one query per unit time. For the general case of the 1-center problem in
R^1, the centroid problem in R^d, and the 1-median problem in R^1, we prove
that the Round-robin scheduling algorithm is the best possible competitive
algorithm. For the center of mass problem in R^d, we provide an O(log
n)-competitive algorithm. In addition, for the general case of the 1-center
problem in R^d (d &gt;= 2), we argue that no algorithm can guarantee a bounded
competitive ratio against the optimal algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Evans_W/0/1/0/all/0/1">William Evans</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabatabaee_S/0/1/0/all/0/1">Seyed Ali Tabatabaee</a></p><p>In this paper, we study the problems of computing the 1-center, centroid, and
1-median of objects moving with bounded speed in Euclidean space. We can
acquire the exact location of only a constant number of objects (usually one)
per unit time, but for every other object, its set of potential locations,
called the object's uncertainty region, grows subject only to the speed limit.
As a result, the center of the objects may be at several possible locations,
called the center's uncertainty region. For each of these center problems, we
design query strategies to minimize the size of the center's uncertainty region
and compare its performance to an optimal query strategy that knows the
trajectories of the objects, but must still query to reduce their uncertainty.
For the static case of the 1-center problem in R^1, we show an algorithm that
queries four objects per unit time and works as well as the optimal algorithm
with one query per unit time. For the general case of the 1-center problem in
R^1, the centroid problem in R^d, and the 1-median problem in R^1, we prove
that the Round-robin scheduling algorithm is the best possible competitive
algorithm. For the center of mass problem in R^d, we provide an O(log
n)-competitive algorithm. In addition, for the general case of the 1-center
problem in R^d (d &gt;= 2), we argue that no algorithm can guarantee a bounded
competitive ratio against the optimal algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10078'>High-Performance and Flexible Parallel Algorithms for Semisort and Related Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiaojun Dong, Yunshu Wu, Zhongqi Wang, Laxman Dhulipala, Yan Gu, Yihan Sun</p><p>Semisort is a fundamental algorithmic primitive widely used in the design and
analysis of efficient parallel algorithms. It takes input as an array of
records and a function extracting a \emph{key} per record, and reorders them so
that records with equal keys are contiguous. Since many applications only
require collecting equal values, but not fully sorting the input, semisort is
broadly applicable, e.g., in string algorithms, graph analytics, and geometry
processing, among many other domains. However, despite dozens of recent papers
that use semisort in their theoretical analysis and the existence of an
asymptotically optimal parallel semisort algorithm, most implementations of
these parallel algorithms choose to implement semisort by using comparison or
integer sorting in practice, due to potential performance issues in existing
semisort implementations.
</p>
<p>In this paper, we revisit the semisort problem, with the goal of achieving a
high-performance parallel semisort implementation with a flexible interface.
Our approach can easily extend to two related problems, \emph{histogram} and
\emph{collect-reduce}. Our algorithms achieve strong speedups in practice, and
importantly, outperform state-of-the-art parallel sorting and semisorting
methods for almost all settings we tested, with varying input sizes,
distribution, and key types. We also test two important applications with
real-world data, and show that our algorithms improve the performance over
existing approaches. We believe that many other parallel algorithm
implementations can be accelerated using our results.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaojun Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yunshu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1">Laxman Dhulipala</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yihan Sun</a></p><p>Semisort is a fundamental algorithmic primitive widely used in the design and
analysis of efficient parallel algorithms. It takes input as an array of
records and a function extracting a \emph{key} per record, and reorders them so
that records with equal keys are contiguous. Since many applications only
require collecting equal values, but not fully sorting the input, semisort is
broadly applicable, e.g., in string algorithms, graph analytics, and geometry
processing, among many other domains. However, despite dozens of recent papers
that use semisort in their theoretical analysis and the existence of an
asymptotically optimal parallel semisort algorithm, most implementations of
these parallel algorithms choose to implement semisort by using comparison or
integer sorting in practice, due to potential performance issues in existing
semisort implementations.
</p>
<p>In this paper, we revisit the semisort problem, with the goal of achieving a
high-performance parallel semisort implementation with a flexible interface.
Our approach can easily extend to two related problems, \emph{histogram} and
\emph{collect-reduce}. Our algorithms achieve strong speedups in practice, and
importantly, outperform state-of-the-art parallel sorting and semisorting
methods for almost all settings we tested, with varying input sizes,
distribution, and key types. We also test two important applications with
real-world data, and show that our algorithms improve the performance over
existing approaches. We believe that many other parallel algorithm
implementations can be accelerated using our results.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10350'>Polylog-Competitive Algorithms for Dynamic Balanced Graph Partitioning for Ring Demands</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Harald R&#xe4;cke, Stefan Schmid, Ruslan Zabrodin</p><p>The performance of many large-scale and data-intensive distributed systems
critically depends on the capacity of the interconnecting network. This paper
is motivated by the vision of self-adjusting infrastructures whose resources
can be adjusted according to the workload they currently serve, in a
demand-aware manner. Such dynamic adjustments can be exploited to improve
network utilization and hence performance, by dynamically moving frequently
interacting communication partners closer, e.g., collocating them in the same
server or datacenter rack.
</p>
<p>In particular, we revisit the online balanced graph partitioning problem
which captures the fundamental tradeoff between the benefits and costs of
dynamically collocating communication partners. The demand is modelled as a
sequence $\sigma$ (revealed in an online manner) of communication requests
between $n$ processes, each of which is running on one of the $\ell$ servers.
Each server has capacity $k=n/\ell$, hence, the processes have to be scheduled
in a balanced manner across the servers. A request incurs cost $1$, if the
requested processes are located on different servers, otherwise the cost is 0.
A process can be migrated to a different server at cost $1$.
</p>
<p>This paper presents the first online algorithm for online balanced graph
partitioning achieving a polylogarithmic competitive ratio for the fundamental
case of ring communication patterns. Specifically, our main contribution is a
$O(\log^3 n)$-competitive randomized online algorithm for this problem. We
further present a randomized online algorithm which is $O(\log^2
n)$-competitive when compared to a static optimal solution. Our two results
rely on different algorithms and techniques and hence are of independent
interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Racke_H/0/1/0/all/0/1">Harald R&#xe4;cke</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Zabrodin_R/0/1/0/all/0/1">Ruslan Zabrodin</a></p><p>The performance of many large-scale and data-intensive distributed systems
critically depends on the capacity of the interconnecting network. This paper
is motivated by the vision of self-adjusting infrastructures whose resources
can be adjusted according to the workload they currently serve, in a
demand-aware manner. Such dynamic adjustments can be exploited to improve
network utilization and hence performance, by dynamically moving frequently
interacting communication partners closer, e.g., collocating them in the same
server or datacenter rack.
</p>
<p>In particular, we revisit the online balanced graph partitioning problem
which captures the fundamental tradeoff between the benefits and costs of
dynamically collocating communication partners. The demand is modelled as a
sequence $\sigma$ (revealed in an online manner) of communication requests
between $n$ processes, each of which is running on one of the $\ell$ servers.
Each server has capacity $k=n/\ell$, hence, the processes have to be scheduled
in a balanced manner across the servers. A request incurs cost $1$, if the
requested processes are located on different servers, otherwise the cost is 0.
A process can be migrated to a different server at cost $1$.
</p>
<p>This paper presents the first online algorithm for online balanced graph
partitioning achieving a polylogarithmic competitive ratio for the fundamental
case of ring communication patterns. Specifically, our main contribution is a
$O(\log^3 n)$-competitive randomized online algorithm for this problem. We
further present a randomized online algorithm which is $O(\log^2
n)$-competitive when compared to a static optimal solution. Our two results
rely on different algorithms and techniques and hence are of independent
interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10414'>How the Move Acceptance Hyper-Heuristic Copes With Local Optima: Drastic Differences Between Jumps and Cliffs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Benjamin Doerr, Arthur Dremaux, Johannes Lutzeyer, Aur&#xe9;lien Stumpf</p><p>In recent work, Lissovoi, Oliveto, and Warwicker (Artificial Intelligence
(2023)) proved that the Move Acceptance Hyper-Heuristic (MAHH) leaves the local
optimum of the multimodal cliff benchmark with remarkable efficiency. With its
$O(n^3)$ runtime, for almost all cliff widths $d,$ the MAHH massively
outperforms the $\Theta(n^d)$ runtime of simple elitist evolutionary algorithms
(EAs). For the most prominent multimodal benchmark, the jump functions, the
given runtime estimates of $O(n^{2m} m^{-\Theta(m)})$ and
$\Omega(2^{\Omega(m)})$, for gap size $m \ge 2$, are far apart and the real
performance of MAHH is still an open question.
</p>
<p>In this work, we resolve this question. We prove that for any choice of the
MAHH selection parameter~$p$, the expected runtime of the MAHH on a jump
function with gap size $m = o(n^{1/2})$ is at least $\Omega(n^{2m-1} /
(2m-1)!)$. This renders the MAHH much slower than simple elitist evolutionary
algorithms with their typical $O(n^m)$ runtime.
</p>
<p>We also show that the MAHH with the global bit-wise mutation operator instead
of the local one-bit operator optimizes jump functions in time $O(\min\{m
n^m,\frac{n^{2m-1}}{m!\Omega(m)^{m-2}}\})$, essentially the minimum of the
optimization times of the $(1+1)$ EA and the MAHH. This suggests that combining
several ways to cope with local optima can be a fruitful approach.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Doerr_B/0/1/0/all/0/1">Benjamin Doerr</a>, <a href="http://arxiv.org/find/cs/1/au:+Dremaux_A/0/1/0/all/0/1">Arthur Dremaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Lutzeyer_J/0/1/0/all/0/1">Johannes Lutzeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpf_A/0/1/0/all/0/1">Aur&#xe9;lien Stumpf</a></p><p>In recent work, Lissovoi, Oliveto, and Warwicker (Artificial Intelligence
(2023)) proved that the Move Acceptance Hyper-Heuristic (MAHH) leaves the local
optimum of the multimodal cliff benchmark with remarkable efficiency. With its
$O(n^3)$ runtime, for almost all cliff widths $d,$ the MAHH massively
outperforms the $\Theta(n^d)$ runtime of simple elitist evolutionary algorithms
(EAs). For the most prominent multimodal benchmark, the jump functions, the
given runtime estimates of $O(n^{2m} m^{-\Theta(m)})$ and
$\Omega(2^{\Omega(m)})$, for gap size $m \ge 2$, are far apart and the real
performance of MAHH is still an open question.
</p>
<p>In this work, we resolve this question. We prove that for any choice of the
MAHH selection parameter~$p$, the expected runtime of the MAHH on a jump
function with gap size $m = o(n^{1/2})$ is at least $\Omega(n^{2m-1} /
(2m-1)!)$. This renders the MAHH much slower than simple elitist evolutionary
algorithms with their typical $O(n^m)$ runtime.
</p>
<p>We also show that the MAHH with the global bit-wise mutation operator instead
of the local one-bit operator optimizes jump functions in time $O(\min\{m
n^m,\frac{n^{2m-1}}{m!\Omega(m)^{m-2}}\})$, essentially the minimum of the
optimization times of the $(1+1)$ EA and the MAHH. This suggests that combining
several ways to cope with local optima can be a fruitful approach.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10524'>Learning Narrow One-Hidden-Layer ReLU Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sitan Chen, Zehao Dou, Surbhi Goel, Adam R Klivans, Raghu Meka</p><p>We consider the well-studied problem of learning a linear combination of $k$
ReLU activations with respect to a Gaussian distribution on inputs in $d$
dimensions. We give the first polynomial-time algorithm that succeeds whenever
$k$ is a constant. All prior polynomial-time learners require additional
assumptions on the network, such as positive combining coefficients or the
matrix of hidden weight vectors being well-conditioned.
</p>
<p>Our approach is based on analyzing random contractions of higher-order moment
tensors. We use a multi-scale analysis to argue that sufficiently close neurons
can be collapsed together, sidestepping the conditioning issues present in
prior work. This allows us to design an iterative procedure to discover
individual neurons.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Sitan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zehao Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1">Surbhi Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Klivans_A/0/1/0/all/0/1">Adam R Klivans</a>, <a href="http://arxiv.org/find/cs/1/au:+Meka_R/0/1/0/all/0/1">Raghu Meka</a></p><p>We consider the well-studied problem of learning a linear combination of $k$
ReLU activations with respect to a Gaussian distribution on inputs in $d$
dimensions. We give the first polynomial-time algorithm that succeeds whenever
$k$ is a constant. All prior polynomial-time learners require additional
assumptions on the network, such as positive combining coefficients or the
matrix of hidden weight vectors being well-conditioned.
</p>
<p>Our approach is based on analyzing random contractions of higher-order moment
tensors. We use a multi-scale analysis to argue that sufficiently close neurons
can be collapsed together, sidestepping the conditioning issues present in
prior work. This allows us to design an iterative procedure to discover
individual neurons.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, April 20
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/055'>TR23-055 |  On Approximability of Satisfiable $k$-CSPs: II | 

	Amey Bhangale, 

	Subhash Khot, 

	Dor Minzer</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Let $\Sigma$ be an alphabet and $\mu$ be a distribution on $\Sigma^k$ for some $k \geq 2$. Let $\alpha &gt; 0$ be the minimum probability of a tuple in the support of $\mu$ (denoted by $supp(\mu)$). Here, the support of $\mu$ is the set of all tuples in $\Sigma^k$ that have a positive probability mass under $\mu$. We treat the parameters $\Sigma, k, \mu, \alpha$ as fixed and constant.

We say that the distribution $\mu$ has a  linear embedding if there exist an Abelian group $G$ (with the identity element $0_G$) and mappings $\sigma_i : \Sigma \rightarrow G$, $1 \leq i \leq k$, such that  at least one of the mappings is non-constant and for every $(a_1, a_2, \ldots, a_k)\in supp(\mu)$, $\sum_{i=1}^k \sigma_i(a_i) = 0_G$. In [Bhangale-Khot-Minzer, STOC 2022], the authors asked the following analytical question.

Let $f_i: \Sigma^n\rightarrow [-1,1]$ be bounded functions, such that at least one of the functions $f_i$ essentially has degree at least $d$, meaning that the Fourier mass of $f_i$ on terms of degree less than $d$ is negligible, say at most $\delta$. In particular, $|\mathbb{E}[f_i]| \leq \delta$. The Fourier representation is w.r.t. the marginal of $\mu$ on the $i^{th}$ co-ordinate, denoted $(\Sigma, \mu_i)$. If $\mu$ has no linear embedding (over any Abelian group), then is it necessarily the case that

$$|\mathbb{E}_{(x_1, x_2, \ldots, x_k)\sim \mu^{\otimes n}}[f_1(x_1)f_2(x_2)\cdots f_k(x_k)]   = o_{d, \delta}(1),$$

where the right hand side $\to 0$ as the degree $d \to \infty$  and $\delta \to 0$?


In this paper, we answer this analytical question fully and in the affirmative for $k=3$. We also show the following two applications of the result.

1. The first application is related to hardness of approximation. Using the reduction from [Bhangale-Khot-Minzer, STOC 2022], we show that for every $3$-ary predicate $P:\Sigma^3 \to \{0,1\}$ such that $P$ has no linear embedding, an SDP integrality gap instance of a $P$-CSP instance with gap $(1,s)$ can be translated into a dictatorship test with completeness $1$ and soundness $s+o(1)$, under certain additional conditions on the instance.

2. The second application is related to additive combinatorics. We show that if the distribution $\mu$ on $\Sigma^3$ has no linear embedding, marginals of $\mu$ are uniform on $\Sigma$, and $(a,a,a)\in supp(\mu)$ for every $a\in \Sigma$, then every large enough subset of $\Sigma^n$ contains a triple $(x_1, x_2,x_3)$ from $\mu^{\otimes n}$ (and in fact a significant density of such triples).
        
        </div>

        <div class='tr-article-summary'>
        
          
          Let $\Sigma$ be an alphabet and $\mu$ be a distribution on $\Sigma^k$ for some $k \geq 2$. Let $\alpha &gt; 0$ be the minimum probability of a tuple in the support of $\mu$ (denoted by $supp(\mu)$). Here, the support of $\mu$ is the set of all tuples in $\Sigma^k$ that have a positive probability mass under $\mu$. We treat the parameters $\Sigma, k, \mu, \alpha$ as fixed and constant.

We say that the distribution $\mu$ has a  linear embedding if there exist an Abelian group $G$ (with the identity element $0_G$) and mappings $\sigma_i : \Sigma \rightarrow G$, $1 \leq i \leq k$, such that  at least one of the mappings is non-constant and for every $(a_1, a_2, \ldots, a_k)\in supp(\mu)$, $\sum_{i=1}^k \sigma_i(a_i) = 0_G$. In [Bhangale-Khot-Minzer, STOC 2022], the authors asked the following analytical question.

Let $f_i: \Sigma^n\rightarrow [-1,1]$ be bounded functions, such that at least one of the functions $f_i$ essentially has degree at least $d$, meaning that the Fourier mass of $f_i$ on terms of degree less than $d$ is negligible, say at most $\delta$. In particular, $|\mathbb{E}[f_i]| \leq \delta$. The Fourier representation is w.r.t. the marginal of $\mu$ on the $i^{th}$ co-ordinate, denoted $(\Sigma, \mu_i)$. If $\mu$ has no linear embedding (over any Abelian group), then is it necessarily the case that

$$|\mathbb{E}_{(x_1, x_2, \ldots, x_k)\sim \mu^{\otimes n}}[f_1(x_1)f_2(x_2)\cdots f_k(x_k)]   = o_{d, \delta}(1),$$

where the right hand side $\to 0$ as the degree $d \to \infty$  and $\delta \to 0$?


In this paper, we answer this analytical question fully and in the affirmative for $k=3$. We also show the following two applications of the result.

1. The first application is related to hardness of approximation. Using the reduction from [Bhangale-Khot-Minzer, STOC 2022], we show that for every $3$-ary predicate $P:\Sigma^3 \to \{0,1\}$ such that $P$ has no linear embedding, an SDP integrality gap instance of a $P$-CSP instance with gap $(1,s)$ can be translated into a dictatorship test with completeness $1$ and soundness $s+o(1)$, under certain additional conditions on the instance.

2. The second application is related to additive combinatorics. We show that if the distribution $\mu$ on $\Sigma^3$ has no linear embedding, marginals of $\mu$ are uniform on $\Sigma$, and $(a,a,a)\in supp(\mu)$ for every $a\in \Sigma$, then every large enough subset of $\Sigma^n$ contains a triple $(x_1, x_2,x_3)$ from $\mu^{\otimes n}$ (and in fact a significant density of such triples).
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T22:00:35Z">Thursday, April 20 2023, 22:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/054'>TR23-054 |  On Approximability of Satisfiable $k$-CSPs: III | 

	Amey Bhangale, 

	Subhash Khot, 

	Dor Minzer</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this paper we study functions on the Boolean hypercube that have the property that after applying certain random restrictions, the restricted function is correlated to a linear function with non-negligible probability. If the given function is correlated with a linear function then this property clearly holds. Furthermore, the property also holds for low-degree functions as low-degree functions become a constant function under a random restriction with a non-negligible probability. We show that this essentially is the only possible reason.  More specifically, we show that the function must be correlated to a product of a linear function and a low-degree function. One of the main motivations of studying this question comes from the recent work of the authors [Bhangale, Khot and Minzer, STOC 2021] towards understanding approximability of satisfiable Constraint Satisfaction Problems.

Towards proving our structural theorem, we analyze a $2$-query direct product test for the table $F: {[n]\choose qn} \rightarrow \{0,1\}^{qn}$ where $q\in (0,1)$. We show that, for every constant $\varepsilon&gt;0$, if the test passes with probability $\varepsilon&gt;0$, then there is a global function such that for at least $\delta(\varepsilon)$ fraction of sets, the global function agrees with the given table on {\em all except $\alpha(\varepsilon)$ many locations}. The novelty of this result lies in the fact that $\alpha(\varepsilon)$ is independent of the set sizes. Prior to our work, such a conclusion (in fact, a stronger conclusion with $\alpha = 0$) was shown in [Dinur-Filmus-Harsha, SODA 2019] albeit when the test accepts with probability $1-\varepsilon$ for a small constant $\varepsilon&gt;0$. The setting of parameters in our direct product tests is fundamentally different compared to [Dinur-Goldenberg, FOCS 2008], [Impagliazzo-Kabanets-Wigderson, SIAM Journal of Computing 2012], [Dinur-Steurer, CCC 2014], [Dinur-Filmus-Harsha, SODA 2019]  and hence our analysis involves new techniques, including the use of the small-set expansion property of graphs defined on multi-slices. Such expansion property was recently shown in [Braverman-Khot-Lifshitz-Minzer, FOCS 2022].

As one application of our structural result, we give a $4$-query linearity test under the $p$-biased distribution. More specifically, for any $p\in (\frac{1}{3},\frac{2}{3})$, we give a test that queries a given function $f: \{0,1\}^n \rightarrow \{0,1\}$ at $4$ locations, where the marginal distribution of each query is $\mu_p^{\otimes n}$. The test has perfect completeness and soundness $\frac{1}{2}+\varepsilon$ -- in other words, for every constant $\varepsilon&gt;0$,  if the test passes with probability at least $\frac{1}{2}+\varepsilon$, then the function $f$ is correlated to a linear function under the $\mu_p^{\otimes n}$ measure. This qualitatively improves the results on the linearity testing under the $p$-biased distribution from the previous work [Kopparty-Saraf, APPROX/RANDOM 2009] and [Dinur-Filmus-Harsha, SODA 2019] in which the authors studied the test with soundness $1-\varepsilon$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In this paper we study functions on the Boolean hypercube that have the property that after applying certain random restrictions, the restricted function is correlated to a linear function with non-negligible probability. If the given function is correlated with a linear function then this property clearly holds. Furthermore, the property also holds for low-degree functions as low-degree functions become a constant function under a random restriction with a non-negligible probability. We show that this essentially is the only possible reason.  More specifically, we show that the function must be correlated to a product of a linear function and a low-degree function. One of the main motivations of studying this question comes from the recent work of the authors [Bhangale, Khot and Minzer, STOC 2021] towards understanding approximability of satisfiable Constraint Satisfaction Problems.

Towards proving our structural theorem, we analyze a $2$-query direct product test for the table $F: {[n]\choose qn} \rightarrow \{0,1\}^{qn}$ where $q\in (0,1)$. We show that, for every constant $\varepsilon&gt;0$, if the test passes with probability $\varepsilon&gt;0$, then there is a global function such that for at least $\delta(\varepsilon)$ fraction of sets, the global function agrees with the given table on {\em all except $\alpha(\varepsilon)$ many locations}. The novelty of this result lies in the fact that $\alpha(\varepsilon)$ is independent of the set sizes. Prior to our work, such a conclusion (in fact, a stronger conclusion with $\alpha = 0$) was shown in [Dinur-Filmus-Harsha, SODA 2019] albeit when the test accepts with probability $1-\varepsilon$ for a small constant $\varepsilon&gt;0$. The setting of parameters in our direct product tests is fundamentally different compared to [Dinur-Goldenberg, FOCS 2008], [Impagliazzo-Kabanets-Wigderson, SIAM Journal of Computing 2012], [Dinur-Steurer, CCC 2014], [Dinur-Filmus-Harsha, SODA 2019]  and hence our analysis involves new techniques, including the use of the small-set expansion property of graphs defined on multi-slices. Such expansion property was recently shown in [Braverman-Khot-Lifshitz-Minzer, FOCS 2022].

As one application of our structural result, we give a $4$-query linearity test under the $p$-biased distribution. More specifically, for any $p\in (\frac{1}{3},\frac{2}{3})$, we give a test that queries a given function $f: \{0,1\}^n \rightarrow \{0,1\}$ at $4$ locations, where the marginal distribution of each query is $\mu_p^{\otimes n}$. The test has perfect completeness and soundness $\frac{1}{2}+\varepsilon$ -- in other words, for every constant $\varepsilon&gt;0$,  if the test passes with probability at least $\frac{1}{2}+\varepsilon$, then the function $f$ is correlated to a linear function under the $\mu_p^{\otimes n}$ measure. This qualitatively improves the results on the linearity testing under the $p$-biased distribution from the previous work [Kopparty-Saraf, APPROX/RANDOM 2009] and [Dinur-Filmus-Harsha, SODA 2019] in which the authors studied the test with soundness $1-\varepsilon$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T22:00:22Z">Thursday, April 20 2023, 22:00</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
