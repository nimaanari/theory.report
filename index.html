<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-05-04T19:30:23Z">Thursday, May 04 2023, 19:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, May 04
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/065'>TR23-065 |  From Grassmannian to Simplicial High-Dimensional Expanders | 

	Louis Golowich</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this paper, we present a new construction of simplicial complexes of subpolynomial degree with arbitrarily good local spectral expansion. Previously, the only known high-dimensional expanders (HDXs) with arbitrarily good expansion and less than polynomial degree were based on one of two constructions, namely Ramanujan complexes and coset complexes. In contrast, our construction is a Cayley complex over the group $\mathbb{F}_2^k$, with Cayley generating set given by a Grassmannian HDX.

  Our construction is in part motivated by a coding-theoretic interpretation of Grassmannian HDXs that we present, which provides a formal connection between Grassmannian HDXs, simplicial HDXs, and LDPC codes. We apply this interpretation to prove a general characterization of the 1-homology groups over $\mathbb{F}_2$ of Cayley simplicial complexes over $\mathbb{F}_2^k$. Using this result, we construct simplicial complexes on $N$ vertices with arbitrarily good local expansion for which the dimension of the 1-homology group grows as $\Omega(\log^2N)$. No prior constructions in the literature have been shown to achieve as large a 1-homology group.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In this paper, we present a new construction of simplicial complexes of subpolynomial degree with arbitrarily good local spectral expansion. Previously, the only known high-dimensional expanders (HDXs) with arbitrarily good expansion and less than polynomial degree were based on one of two constructions, namely Ramanujan complexes and coset complexes. In contrast, our construction is a Cayley complex over the group $\mathbb{F}_2^k$, with Cayley generating set given by a Grassmannian HDX.

  Our construction is in part motivated by a coding-theoretic interpretation of Grassmannian HDXs that we present, which provides a formal connection between Grassmannian HDXs, simplicial HDXs, and LDPC codes. We apply this interpretation to prove a general characterization of the 1-homology groups over $\mathbb{F}_2$ of Cayley simplicial complexes over $\mathbb{F}_2^k$. Using this result, we construct simplicial complexes on $N$ vertices with arbitrarily good local expansion for which the dimension of the 1-homology group grows as $\Omega(\log^2N)$. No prior constructions in the literature have been shown to achieve as large a 1-homology group.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T13:54:49Z">Thursday, May 04 2023, 13:54</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/05/breaking-ground-in-isomorphism-testing.html'>Breaking Ground in Isomorphism Testing: A Leap Forward for a Bottleneck Case of Group Isomorphism</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Guest post by Josh Grochow and Youming Qiao</p><p>There has, quietly, been somewhat of a breakthrough in isomorphism testing. No, not as big as Babai's 2016 Graph Isomorphism in Quasipolynomial Time. But a first foothold in climbing a wall for which no one had gotten much off the ground before. The result, due to Xiaorui Sun in this year's STOC, is an algorithm for testing isomorphism of a certain class of groups - p-groups of class 2 and exponent p if you must know, but we'll get to that - in time \(n^{O(\log^{5/6} n)}\) where n is the order of the group. To understand why we're excited about this we have to tell a bit of a story.&nbsp;</p><p>In the 1970s, when Graph Isomorphism was still a mystery, people also thought more widely about isomorphism testing of other combinatorial and algebraic structures. For finite groups of order n, Robert Tarjan realized that there is an \(n^{\log n+O(1)}\)-time algorithm, simply because a group of order n has a generating set of size \(\log n\). This observation was recorded by Gary Miller in a paper in STOC'78, and independently realized by Felsch and Neubüser. A natural question is then whether Group Isomorphism can be solved in time poly(n) where n is the group order.</p><br><p>Not only is this question natural from the perspective of studying groups computationally, it is also natural from the perspective of Graph Isomorphism. For Group Isomorphism reduces to Graph Isomorphism in polynomial-time (as does the isomorphism problem for any finite algebraic or relational structure, see Zemlyachenko, Korneenko, &amp; Tyshkevich). While this has been known for a long time, Babai’s result on Graph Isomorphism brings the running times quite close: \(n^{O(\log^2 n)}\) for graphs, and \(n^{O(\log n)}\) for groups. So not only does Group Isomorphism stand in the way of getting Graph Isomorphism into P, but in our current state of knowledge, it even stands in the way of shaving off more than a single log in the exponent of the runtime.</p><br><p>Since the general Group Isomorphism problem seems difficult, attention turned to special classes of groups. It was not hard to see that isomorphism of Abelian groups could be computed in polynomial time. However, a group class that is just “one step away” from Abelian - groups G where, when you mod out by the center Z(G), what’s left is Abelian -&nbsp; turned out to be difficult. Such groups are called class-2 nilpotent, and in one sense, their&nbsp; group-theoretic structure is relatively straightforward: both G/Z(G) and Z(G) are Abelian. Yet, to devise an efficient isomorphism testing procedure turned out to be extremely difficult (see e.g. Garzon-Zalcstein, Rosenbaum-Wagner, O’Brien, Wilson), to the point that this is usually considered as a bottleneck for putting Group Isomorphism in P.&nbsp;</p><br><p>Among class-2 nilpotent groups, the “key case” to resolve is widely believed, for several reasons, to be p-groups of class 2 and exponent p. In such groups, both the center Z(G) and quotient G/Z(G) are elementary abelian, i.e., of the form \((Z_p)^d\). Despite having an even simpler group-theoretic structure, this group class still turns out to be difficult! For a long time, the asymptotic growth of the exponent of the runtime for solving this restricted problem has not improved over the \(n^{\log n+O(1)}\)-time algorithm, which works for all groups.1</p><br><p>Xiaorui Sun’s result represents the first substantial improvement, cracking open this decades-old quest. His algorithm runs in time \(n^{O(\log^{5/6} n)}\), and its techniques are indeed novel. The starting point of this algorithm is to consider the following equivalent problem in (multi)linear algebra: let \(f, g:Z_p^d \times Z_p^d \rightarrow Z_p^e\) be two skew-symmetric bilinear maps. Do there exist change of bases A in \(GL(d, p)\) and B in \(GL(e, p)\), such that for all \(u, v\) in \(Z_p^d\), \(f(A(u), A(v))=B(g(u, v))\)?</p><br><p>Baer’s Correspondence sets up an equivalence of categories between p-groups of class 2 and exponent p, and skew-symmetric bilinear maps over \(Z_p\). This viewpoint allows Xiaorui to use multilinear algebra to study the structure of these bilinear maps. He also crucially depends on a result of Ivanyos and Qiao, which built on Wilson’s use of involutive algebras in this context. He also uses the individualization-and-refinement technique (but for matrix spaces, not graphs!), a characterization of spaces of matrices of low rank, and reducing a tensor to a “semi-canonical” form part of which is somewhat reminiscent of the Tucker decomposition.</p><br><p>All this results in an algorithm which solves the above problem on bilinear maps in time \(p^{(d+e)^{1.8} \log p}\). For groups of order \(p^n\) with \(\log_p(n)\) larger than \(\log^5 p\), Baer’s Correspondence then says that this algorithm does it; when \(\log_p n\) is smaller than \(log^5 p,\) he can fall back on the generator-enumerator algorithm, since the number of generators is at most \(log_p n\).</p><br><p>For us, who have been working on Group Isomorphism for more than a decade, Xiaorui’s result represents an exciting development on this classic algorithmic problem, and we look forward to seeing more progress in this direction in the near future.&nbsp;</p><p></p>1Rosenbaum &amp; Wagner improved the exponent to \(\frac{1}{2}\log {p(n)} + O(1)\), and later improved to \(\frac{1}{4}\log {p(n)} + O(1)\) for all groups, see p.5 of Le Gall &amp; Rosenbaum. In 2014, at a conference on Groups, Computation, and Geometry organized by Wilson, Brooksbank, Hulpke, Kantor, and Penttila, it was concluded that modern practical methods, such as those used in GAP and MAGMA, still take \(n^{O(\log n)}\) steps in the worst case.<p></p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;"><i>Guest post by Josh Grochow and </i></span><span style="font-family: Arial;"><span style="font-size: 14.6667px; white-space: pre-wrap;"><i>Youming Qiao</i></span></span></p><p><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">There has, quietly, been somewhat of a breakthrough in isomorphism testing. No, not as big as Babai's 2016 </span><a href="https://arxiv.org/abs/1512.03547" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">Graph Isomorphism in Quasipolynomial Time</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">. But a first foothold in climbing a wall for which no one had gotten much off the ground before. The result, due to </span><a href="https://arxiv.org/abs/2303.15412" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">Xiaorui Sun in this year's STOC</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">, is an algorithm for testing isomorphism of a certain class of groups - p-groups of class 2 and exponent p if you must know, but we'll get to that - in time \(n^{O(\log^{5/6} n)}\) where n is the order of the group. To understand why we're excited about this we have to tell a bit of a story.&nbsp;</span></p><span id="docs-internal-guid-259ecb6b-7fff-b1a3-e5ab-283b928791b9"><p dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">In the 1970s, when Graph Isomorphism was still a mystery, people also thought more widely about isomorphism testing of other combinatorial and algebraic structures. For finite groups of order n, Robert Tarjan realized that there is an \(n^{\log n+O(1)}\)-time algorithm, simply because a group of order n has a generating set of size \(\log n\). This observation was recorded by Gary Miller in a </span><a href="https://doi.org/10.1145/800133.804331" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">paper in STOC'78</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">, and independently realized by </span><a href="https://www.sciencedirect.com/science/article/abs/pii/B9780080129754500114" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">Felsch and Neubüser</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">. A natural question is then whether Group Isomorphism can be solved in time poly(n) where n is the group order.</span></p><br /><p dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">Not only is this question natural from the perspective of studying groups computationally, it is also natural from the perspective of </span><span style="font-family: Arial; font-size: 11pt; font-style: italic; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">Graph</span><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;"> Isomorphism. For Group Isomorphism reduces to Graph Isomorphism in polynomial-time (as does the isomorphism problem for any finite algebraic or relational structure, see </span><a href="https://doi.org/10.1007/BF02104746" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">Zemlyachenko, Korneenko, &amp; Tyshkevich</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">). While this has been known for a long time, Babai’s result on Graph Isomorphism brings the running times quite close: \(n^{O(\log^2 n)}\) for graphs, and \(n^{O(\log n)}\) for groups. So not only does Group Isomorphism stand in the way of getting Graph Isomorphism into P, but in our current state of knowledge, it even stands in the way of shaving off more than a single log in the exponent of the runtime.</span></p><br /><p dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">Since the general Group Isomorphism problem seems difficult, attention turned to special classes of groups. It was not hard to see that isomorphism of Abelian groups could be computed in polynomial time. However, a group class that is just “one step away” from Abelian - groups G where, when you mod out by the center Z(G), what’s left is Abelian -&nbsp; turned out to be difficult. Such groups are called class-2 nilpotent, and in one sense, their&nbsp; group-theoretic structure is relatively straightforward: both G/Z(G) and Z(G) are Abelian. Yet, to devise an efficient isomorphism testing procedure turned out to be extremely difficult (see e.g. </span><a href="https://doi.org/10.1016/0022-0000(91)90012-T" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">Garzon-Zalcstein</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">, </span><a href="https://doi.org/10.1016/j.tcs.2015.05.036" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">Rosenbaum-Wagner</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">, </span><a href="https://www.math.auckland.ac.nz/~obrien/research/isom.pdf" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">O’Brien</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">, </span><a href="https://www.sciencedirect.com/science/article/pii/S0021869309004463" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">Wilson</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">), to the point that this is usually considered as a bottleneck for putting Group Isomorphism in P.&nbsp;</span></p><br /><p dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">Among class-2 nilpotent groups, the “key case” to resolve is widely believed, </span><a href="https://cstheory.stackexchange.com/a/42551/129" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">for several reasons</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">, to be p-groups of class 2 and exponent p. In such groups, both the center Z(G) and quotient G/Z(G) are elementary abelian, i.e., of the form \((Z_p)^d\). Despite having an even simpler group-theoretic structure, this group class still turns out to be difficult! For a long time, the asymptotic growth of the exponent of the runtime for solving this restricted problem has not improved over the \(n^{\log n+O(1)}\)-time algorithm, which works for all groups.<sup>1</sup></span></p><br /><p dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">Xiaorui Sun’s result represents the first substantial improvement, cracking open this decades-old quest. His algorithm runs in time \(n^{O(\log^{5/6} n)}\), and its techniques are indeed novel. The starting point of this algorithm is to consider the following equivalent problem in (multi)linear algebra: let \(f, g:Z_p^d \times Z_p^d \rightarrow Z_p^e\) be two skew-symmetric bilinear maps. Do there exist change of bases A in \(GL(d, p)\) and B in \(GL(e, p)\), such that for all \(u, v\) in \(Z_p^d\), \(f(A(u), A(v))=B(g(u, v))\)?</span></p><br /><p dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><a href="https://www.jstor.org/stable/1989886" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">Baer’s Correspondence</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;"> sets up an equivalence of categories between p-groups of class 2 and exponent p, and skew-symmetric bilinear maps over \(Z_p\). This viewpoint allows Xiaorui to use multilinear algebra to study the structure of these bilinear maps. He also crucially depends on a result of </span><a href="https://doi.org/10.1137/18M1165682" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">Ivanyos and Qiao</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">, which built on </span><a href="https://doi.org/10.1016/j.jalgebra.2009.07.029" style="text-decoration-line: none;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">Wilson’s use</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;"> of involutive algebras in this context. He also uses the individualization-and-refinement technique (but for matrix spaces, not graphs!), a characterization of spaces of matrices of low rank, and reducing a tensor to a “semi-canonical” form part of which is somewhat reminiscent of the Tucker decomposition.</span></p><br /><p dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">All this results in an algorithm which solves the above problem on bilinear maps in time \(p^{(d+e)^{1.8} \log p}\). For groups of order \(p^n\) with \(\log_p(n)\) larger than \(\log^5 p\), Baer’s Correspondence then says that this algorithm does it; when \(\log_p n\) is smaller than \(log^5 p,\) he can fall back on the generator-enumerator algorithm, since the number of generators is at most \(log_p n\).</span></p><br /><p dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;">For us, who have been working on Group Isomorphism for more than a decade, Xiaorui’s result represents an exciting development on this classic algorithmic problem, and we look forward to seeing more progress in this direction in the near future.&nbsp;</span></p><p dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;"><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline;"></span></span></p><hr /><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;"><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline;"><sup>1</sup></span><a href="https://doi.org/10.1016/j.tcs.2015.05.036" style="font-family: &quot;Times New Roman&quot;; font-size: medium; text-decoration-line: none; white-space: normal;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">Rosenbaum &amp; Wagner</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline;"> improved the exponent to \(\frac{1}{2}\log {p(n)} + O(1)\), and later improved to \(\frac{1}{4}\log {p(n)} + O(1)\) for all groups, see p.5 of </span><a href="https://arxiv.org/abs/1609.08253" style="font-family: &quot;Times New Roman&quot;; font-size: medium; text-decoration-line: none; white-space: normal;"><span style="color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;">Le Gall &amp; Rosenbaum</span></a><span style="font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline;">. In 2014, at a conference on Groups, Computation, and Geometry organized by Wilson, Brooksbank, Hulpke, Kantor, and Penttila, it was concluded that modern practical methods, such as those used in GAP and MAGMA, still take \(n^{O(\log n)}\) steps in the worst case.</span></span><p></p></span><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T11:12:00Z">Thursday, May 04 2023, 11:12</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/05/04/phd-student-at-department-of-computer-and-information-science-linkoping-university-apply-by-may-28-2023/'>PhD Student at Department of Computer and Information Science, Linköping University (apply by May 28, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Linköping University advertises one (1) position as PhD student in Computer Science. The PhD student will be supervised by prof. Peter Jonsson. The research for the advertised position is in the area of parameterized complexity of constraint satisfaction problems (CSP). Website: liu.se/en/work-at-liu/vacancies/21872 Email: peter.jonsson@liu.se
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Linköping University advertises one (1) position as PhD student in Computer Science. The PhD student will be supervised by prof. Peter Jonsson. The research for the advertised position is in the area of parameterized complexity of constraint satisfaction problems (CSP).</p>
<p>Website: <a href="https://liu.se/en/work-at-liu/vacancies/21872">https://liu.se/en/work-at-liu/vacancies/21872</a><br />
Email: peter.jonsson@liu.se</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T09:18:29Z">Thursday, May 04 2023, 09:18</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01721'>Construction of Decision Trees and Acyclic Decision Graphs from Decision Rule Systems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kerven Durdymyradov, Mikhail Moshkov</p><p>Decision trees and systems of decision rules are widely used as classifiers,
as a means for knowledge representation, and as algorithms. They are among the
most interpretable models for data analysis. The study of the relationships
between these two models can be seen as an important task of computer science.
Methods for transforming decision trees into systems of decision rules are
simple and well-known. In this paper, we consider the inverse transformation
problem, which is not trivial. We study the complexity of constructing decision
trees and acyclic decision graphs representing decision trees from decision
rule systems, and we discuss the possibility of not building the entire
decision tree, but describing the computation path in this tree for the given
input.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Durdymyradov_K/0/1/0/all/0/1">Kerven Durdymyradov</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshkov_M/0/1/0/all/0/1">Mikhail Moshkov</a></p><p>Decision trees and systems of decision rules are widely used as classifiers,
as a means for knowledge representation, and as algorithms. They are among the
most interpretable models for data analysis. The study of the relationships
between these two models can be seen as an important task of computer science.
Methods for transforming decision trees into systems of decision rules are
simple and well-known. In this paper, we consider the inverse transformation
problem, which is not trivial. We study the complexity of constructing decision
trees and acyclic decision graphs representing decision trees from decision
rule systems, and we discuss the possibility of not building the entire
decision tree, but describing the computation path in this tree for the given
input.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01851'>Complexity and Enumeration in Models of Genome Rearrangement</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lora Bailey, Heather Smith Blake, Garner Cochran, Nathan Fox, Michael Levet, Reem Mahmoud, Elizabeth Matson, Inne Singgih, Grace Stadnyk, Xinyi Wang, Alexander Widemann</p><p>In this paper, we examine the computational complexity of enumeration in
certain genome rearrangement models. We first show that the Pairwise
Rearrangement problem in the Single Cut-and-Join model (Bergeron, Medvedev, &amp;
Stoye, J. Comput. Biol. 2010) is $\#\textsf{P}$-complete under polynomial-time
Turing reductions. Next, we show that in the Single Cut or Join model (Feijao &amp;
Meidanis, IEEE ACM Trans. Comp. Biol. Bioinf. 2011), the problem of enumerating
all medians ($\#$Median) is logspace-computable ($\textsf{FL}$), improving upon
the previous polynomial-time ($\textsf{FP}$) bound of Mikl\'os &amp; Smith (RECOMB
2015).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/q-bio/1/au:+Bailey_L/0/1/0/all/0/1">Lora Bailey</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Blake_H/0/1/0/all/0/1">Heather Smith Blake</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cochran_G/0/1/0/all/0/1">Garner Cochran</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Fox_N/0/1/0/all/0/1">Nathan Fox</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Levet_M/0/1/0/all/0/1">Michael Levet</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Mahmoud_R/0/1/0/all/0/1">Reem Mahmoud</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Matson_E/0/1/0/all/0/1">Elizabeth Matson</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Singgih_I/0/1/0/all/0/1">Inne Singgih</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Stadnyk_G/0/1/0/all/0/1">Grace Stadnyk</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_X/0/1/0/all/0/1">Xinyi Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Widemann_A/0/1/0/all/0/1">Alexander Widemann</a></p><p>In this paper, we examine the computational complexity of enumeration in
certain genome rearrangement models. We first show that the Pairwise
Rearrangement problem in the Single Cut-and-Join model (Bergeron, Medvedev, &amp;
Stoye, J. Comput. Biol. 2010) is $\#\textsf{P}$-complete under polynomial-time
Turing reductions. Next, we show that in the Single Cut or Join model (Feijao &amp;
Meidanis, IEEE ACM Trans. Comp. Biol. Bioinf. 2011), the problem of enumerating
all medians ($\#$Median) is logspace-computable ($\textsf{FL}$), improving upon
the previous polynomial-time ($\textsf{FP}$) bound of Mikl\'os &amp; Smith (RECOMB
2015).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.02226'>$P\not=NP$ relative to a $P$-complete oracle</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Reiner Czerwinski</p><p>The $P$ versus $NP$ problem is still unsolved. But there are several oracles
with $P$ unequal $NP$ relative to them. Here we will prove, that $P\not=NP$
relative to a $P$-complete oracle. In this paper, we use padding arguments as
the proof method. The padding arguments are not bounded by a computable
function. Such as we can use methods from computability theory to separate
complexity classes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Czerwinski_R/0/1/0/all/0/1">Reiner Czerwinski</a></p><p>The $P$ versus $NP$ problem is still unsolved. But there are several oracles
with $P$ unequal $NP$ relative to them. Here we will prove, that $P\not=NP$
relative to a $P$-complete oracle. In this paper, we use padding arguments as
the proof method. The padding arguments are not bounded by a computable
function. Such as we can use methods from computability theory to separate
complexity classes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01877'>The Impacts of Dimensionality, Diffusion, and Directedness on Intrinsic Cross-Model Simulation in Tile-Based Self-Assembly</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Hader, Matthew J. Patitz</p><p>Algorithmic self-assembly occurs when disorganized components autonomously
combine to form structures and, by their design and the dynamics of the system,
are forced to follow the execution of algorithms. Motivated by applications in
DNA-nanotechnology, investigations in algorithmic tile-based self-assembly have
blossomed into a mature theory with research leveraging tools from
computability theory, complexity theory, information theory, and graph theory
to develop a wide range of models and show that many are computationally
universal, while also exposing powers and limitations of each. Beyond
computational universality, the abstract Tile Assembly Model (aTAM) was shown
to be intrinsically universal (IU), a strong notion of completeness where a
single tile set is capable of simulating all systems within the model; however,
this result required non-deterministic tile attachments. This was later
confirmed necessary when it was shown that the class of directed aTAM systems
is not IU. Building on these results to further investigate the impacts of
other dynamics, Hader et al. examined several tile-assembly models which varied
across (1) the numbers of dimensions used, (2) restrictions based on diffusion
of tiles through space, and (3) whether each system is directed, and showed
which models are IU. Such results have shed much light on the roles of various
aspects of the dynamics of tile-assembly and their effects on the intrinsic
universality of each model. Here we provide direct comparisons of the various
models by considering intrinsic simulations between models. We show that in
some cases one model is more powerful than another, and in others, pairs of
models have mutually exclusive capabilities. This comparison helps to expose
the impacts of these three important aspects and further helps define a
hierarchy of tile-assembly models.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hader_D/0/1/0/all/0/1">Daniel Hader</a>, <a href="http://arxiv.org/find/cs/1/au:+Patitz_M/0/1/0/all/0/1">Matthew J. Patitz</a></p><p>Algorithmic self-assembly occurs when disorganized components autonomously
combine to form structures and, by their design and the dynamics of the system,
are forced to follow the execution of algorithms. Motivated by applications in
DNA-nanotechnology, investigations in algorithmic tile-based self-assembly have
blossomed into a mature theory with research leveraging tools from
computability theory, complexity theory, information theory, and graph theory
to develop a wide range of models and show that many are computationally
universal, while also exposing powers and limitations of each. Beyond
computational universality, the abstract Tile Assembly Model (aTAM) was shown
to be intrinsically universal (IU), a strong notion of completeness where a
single tile set is capable of simulating all systems within the model; however,
this result required non-deterministic tile attachments. This was later
confirmed necessary when it was shown that the class of directed aTAM systems
is not IU. Building on these results to further investigate the impacts of
other dynamics, Hader et al. examined several tile-assembly models which varied
across (1) the numbers of dimensions used, (2) restrictions based on diffusion
of tiles through space, and (3) whether each system is directed, and showed
which models are IU. Such results have shed much light on the roles of various
aspects of the dynamics of tile-assembly and their effects on the intrinsic
universality of each model. Here we provide direct comparisons of the various
models by considering intrinsic simulations between models. We show that in
some cases one model is more powerful than another, and in others, pairs of
models have mutually exclusive capabilities. This comparison helps to expose
the impacts of these three important aspects and further helps define a
hierarchy of tile-assembly models.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01883'>A Lightweight CNN-Transformer Model for Learning Traveling Salesman Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Minseop Jung, Jaeseung Lee, Jibum Kim</p><p>Transformer-based models show state-of-the-art performance even for
large-scale Traveling Salesman Problems (TSPs). However, they are based on
fully-connected attention models and suffer from large computational complexity
and GPU memory usage. We propose a lightweight CNN-Transformer model based on a
CNN embedding layer and partial self-attention. Our CNN-Transformer model is
able to better learn spatial features from input data using a CNN embedding
layer compared with the standard Transformer models. It also removes
considerable redundancy in fully connected attention models using the proposed
partial self-attention. Experiments show that the proposed model outperforms
other state-of-the-art Transformer-based models in terms of TSP solution
quality, GPU memory usage, and inference time. Our model consumes approximately
20% less GPU memory usage and has 45% faster inference time compared with other
state-of-the-art Transformer-based models. Our code is publicly available at
github.com/cm8908/CNN_Transformer3
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jung_M/0/1/0/all/0/1">Minseop Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jaeseung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jibum Kim</a></p><p>Transformer-based models show state-of-the-art performance even for
large-scale Traveling Salesman Problems (TSPs). However, they are based on
fully-connected attention models and suffer from large computational complexity
and GPU memory usage. We propose a lightweight CNN-Transformer model based on a
CNN embedding layer and partial self-attention. Our CNN-Transformer model is
able to better learn spatial features from input data using a CNN embedding
layer compared with the standard Transformer models. It also removes
considerable redundancy in fully connected attention models using the proposed
partial self-attention. Experiments show that the proposed model outperforms
other state-of-the-art Transformer-based models in terms of TSP solution
quality, GPU memory usage, and inference time. Our model consumes approximately
20% less GPU memory usage and has 45% faster inference time compared with other
state-of-the-art Transformer-based models. Our code is publicly available at
https://github.com/cm8908/CNN_Transformer3
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.02056'>Approximate Evaluation of Quantitative Second Order Queries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jan Dreier, Robert Ganian, Thekla Hamm</p><p>Courcelle's theorem and its adaptations to cliquewidth have shaped the field
of exact parameterized algorithms and are widely considered the archetype of
algorithmic meta-theorems. In the past decade, there has been growing interest
in developing parameterized approximation algorithms for problems which are not
captured by Courcelle's theorem and, in particular, are considered not
fixed-parameter tractable under the associated widths.
</p>
<p>We develop a generalization of Courcelle's theorem that yields efficient
approximation schemes for any problem that can be captured by an expanded logic
we call Blocked CMSO, capable of making logical statements about the sizes of
set variables via so-called weight comparisons. The logic controls weight
comparisons via the quantifier-alternation depth of the involved variables,
allowing full comparisons for zero-alternation variables and limited
comparisons for one-alternation variables. We show that the developed framework
threads the very needle of tractability: on one hand it can describe a broad
range of approximable problems, while on the other hand we show that the
restrictions of our logic cannot be relaxed under well-established complexity
assumptions.
</p>
<p>The running time of our approximation scheme is polynomial in
$1/\varepsilon$, allowing us to fully interpolate between faster approximate
algorithms and slower exact algorithms. This provides a unified framework to
explain the tractability landscape of graph problems parameterized by treewidth
and cliquewidth, as well as classical non-graph problems such as Subset Sum and
Knapsack.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dreier_J/0/1/0/all/0/1">Jan Dreier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganian_R/0/1/0/all/0/1">Robert Ganian</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamm_T/0/1/0/all/0/1">Thekla Hamm</a></p><p>Courcelle's theorem and its adaptations to cliquewidth have shaped the field
of exact parameterized algorithms and are widely considered the archetype of
algorithmic meta-theorems. In the past decade, there has been growing interest
in developing parameterized approximation algorithms for problems which are not
captured by Courcelle's theorem and, in particular, are considered not
fixed-parameter tractable under the associated widths.
</p>
<p>We develop a generalization of Courcelle's theorem that yields efficient
approximation schemes for any problem that can be captured by an expanded logic
we call Blocked CMSO, capable of making logical statements about the sizes of
set variables via so-called weight comparisons. The logic controls weight
comparisons via the quantifier-alternation depth of the involved variables,
allowing full comparisons for zero-alternation variables and limited
comparisons for one-alternation variables. We show that the developed framework
threads the very needle of tractability: on one hand it can describe a broad
range of approximable problems, while on the other hand we show that the
restrictions of our logic cannot be relaxed under well-established complexity
assumptions.
</p>
<p>The running time of our approximation scheme is polynomial in
$1/\varepsilon$, allowing us to fully interpolate between faster approximate
algorithms and slower exact algorithms. This provides a unified framework to
explain the tractability landscape of graph problems parameterized by treewidth
and cliquewidth, as well as classical non-graph problems such as Subset Sum and
Knapsack.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.02271'>$L$ is unequal $NL$ under the Strong Exponential Time Hypothesis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Reiner Czerwinski</p><p>Due to Savitch's theorem we know $NL\subseteq DSPACE(\log^2(n))$. To show
this upper bound, Savitch constructed an algorithm with $O(\log^2(n))$ space on
the working tape. We will show that Savitch's algorithm also described a lower
bound under the Strong Exponential Time Hypothesis. Every algorithm for the
Connectivity Problem needs $O(\log^2(n))$ space in this case.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Czerwinski_R/0/1/0/all/0/1">Reiner Czerwinski</a></p><p>Due to Savitch's theorem we know $NL\subseteq DSPACE(\log^2(n))$. To show
this upper bound, Savitch constructed an algorithm with $O(\log^2(n))$ space on
the working tape. We will show that Savitch's algorithm also described a lower
bound under the Strong Exponential Time Hypothesis. Every algorithm for the
Connectivity Problem needs $O(\log^2(n))$ space in this case.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01892'>On the Fine-Grained Complexity of Small-Size Geometric Set Cover and Discrete $k$-Center for Small $k$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Timothy M. Chan, Qizheng He, Yuancheng Yu</p><p>We study the time complexity of the discrete $k$-center problem and related
(exact) geometric set cover problems when $k$ or the size of the cover is
small. We obtain a plethora of new results:
</p>
<p>- We give the first subquadratic algorithm for rectilinear discrete 3-center
in 2D, running in $\widetilde{O}(n^{3/2})$ time.
</p>
<p>- We prove a lower bound of $\Omega(n^{4/3-\delta})$ for rectilinear discrete
3-center in 4D, for any constant $\delta&gt;0$, under a standard hypothesis about
triangle detection in sparse graphs.
</p>
<p>- Given $n$ points and $n$ weighted axis-aligned unit squares in 2D, we give
the first subquadratic algorithm for finding a minimum-weight cover of the
points by 3 unit squares, running in $\widetilde{O}(n^{8/5})$ time. We also
prove a lower bound of $\Omega(n^{3/2-\delta})$ for the same problem in 2D,
under the well-known APSP Hypothesis. For arbitrary axis-aligned rectangles in
2D, our upper bound is $\widetilde{O}(n^{7/4})$.
</p>
<p>- We prove a lower bound of $\Omega(n^{2-\delta})$ for Euclidean discrete
2-center in 13D, under the Hyperclique Hypothesis. This lower bound nearly
matches the straightforward upper bound of $\widetilde{O}(n^\omega)$, if the
matrix multiplication exponent $\omega$ is equal to 2.
</p>
<p>- We similarly prove an $\Omega(n^{k-\delta})$ lower bound for Euclidean
discrete $k$-center in $O(k)$ dimensions for any constant $k\ge 3$, under the
Hyperclique Hypothesis. This lower bound again nearly matches known upper
bounds if $\omega=2$.
</p>
<p>- We also prove an $\Omega(n^{2-\delta})$ lower bound for the problem of
finding 2 boxes to cover the largest number of points, given $n$ points and $n$
boxes in 12D. This matches the straightforward near-quadratic upper bound.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chan_T/0/1/0/all/0/1">Timothy M. Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1">Qizheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yuancheng Yu</a></p><p>We study the time complexity of the discrete $k$-center problem and related
(exact) geometric set cover problems when $k$ or the size of the cover is
small. We obtain a plethora of new results:
</p>
<p>- We give the first subquadratic algorithm for rectilinear discrete 3-center
in 2D, running in $\widetilde{O}(n^{3/2})$ time.
</p>
<p>- We prove a lower bound of $\Omega(n^{4/3-\delta})$ for rectilinear discrete
3-center in 4D, for any constant $\delta&gt;0$, under a standard hypothesis about
triangle detection in sparse graphs.
</p>
<p>- Given $n$ points and $n$ weighted axis-aligned unit squares in 2D, we give
the first subquadratic algorithm for finding a minimum-weight cover of the
points by 3 unit squares, running in $\widetilde{O}(n^{8/5})$ time. We also
prove a lower bound of $\Omega(n^{3/2-\delta})$ for the same problem in 2D,
under the well-known APSP Hypothesis. For arbitrary axis-aligned rectangles in
2D, our upper bound is $\widetilde{O}(n^{7/4})$.
</p>
<p>- We prove a lower bound of $\Omega(n^{2-\delta})$ for Euclidean discrete
2-center in 13D, under the Hyperclique Hypothesis. This lower bound nearly
matches the straightforward upper bound of $\widetilde{O}(n^\omega)$, if the
matrix multiplication exponent $\omega$ is equal to 2.
</p>
<p>- We similarly prove an $\Omega(n^{k-\delta})$ lower bound for Euclidean
discrete $k$-center in $O(k)$ dimensions for any constant $k\ge 3$, under the
Hyperclique Hypothesis. This lower bound again nearly matches known upper
bounds if $\omega=2$.
</p>
<p>- We also prove an $\Omega(n^{2-\delta})$ lower bound for the problem of
finding 2 boxes to cover the largest number of points, given $n$ points and $n$
boxes in 12D. This matches the straightforward near-quadratic upper bound.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01714'>Streaming Edge Coloring with Asymptotically Optimal Colors</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Soheil Behnezhad, Mohammad Saneian</p><p>Given a graph $G$, an edge-coloring is an assignment of colors to edges of
$G$ such that any two edges sharing an endpoint receive different colors. By
Vizing's celebrated theorem, any graph of maximum degree $\Delta$ needs at
least $\Delta$ and at most $(\Delta + 1)$ colors to be properly edge colored.
In this paper, we study edge colorings in the streaming setting. The edges
arrive one by one in an arbitrary order. The algorithm takes a single pass over
the input and must output a solution using a much smaller space than the input
size. Since the output of edge coloring is as large as its input, the assigned
colors should also be reported in a streaming fashion.
</p>
<p>The streaming edge coloring problem has been studied in a series of works
over the past few years. The main challenge is that the algorithm cannot
"remember" all the color assignments that it returns. To ensure the validity of
the solution, existing algorithms use many more colors than Vizing's bound.
Namely, in $n$-vertex graphs, the state-of-the-art algorithm with
$\widetilde{O}(n s)$ space requires $O(\Delta^2/s + \Delta)$ colors. Note, in
particular, that for an asymptotically optimal $O(\Delta)$ coloring, this
algorithm requires $\Omega(n\Delta)$ space which is as large as the input.
Whether such a coloring can be achieved with sublinear space has been left
open.
</p>
<p>In this paper, we answer this question in the affirmative. We present a
randomized algorithm that returns an asymptotically optimal $O(\Delta)$ edge
coloring using $\widetilde{O}(n \sqrt{\Delta})$ space. More generally, our
algorithm returns a proper $O(\Delta^{1.5}/s + \Delta)$ edge coloring with
$\widetilde{O}(n s)$ space, improving prior algorithms for the whole range of
$s$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Behnezhad_S/0/1/0/all/0/1">Soheil Behnezhad</a>, <a href="http://arxiv.org/find/cs/1/au:+Saneian_M/0/1/0/all/0/1">Mohammad Saneian</a></p><p>Given a graph $G$, an edge-coloring is an assignment of colors to edges of
$G$ such that any two edges sharing an endpoint receive different colors. By
Vizing's celebrated theorem, any graph of maximum degree $\Delta$ needs at
least $\Delta$ and at most $(\Delta + 1)$ colors to be properly edge colored.
In this paper, we study edge colorings in the streaming setting. The edges
arrive one by one in an arbitrary order. The algorithm takes a single pass over
the input and must output a solution using a much smaller space than the input
size. Since the output of edge coloring is as large as its input, the assigned
colors should also be reported in a streaming fashion.
</p>
<p>The streaming edge coloring problem has been studied in a series of works
over the past few years. The main challenge is that the algorithm cannot
"remember" all the color assignments that it returns. To ensure the validity of
the solution, existing algorithms use many more colors than Vizing's bound.
Namely, in $n$-vertex graphs, the state-of-the-art algorithm with
$\widetilde{O}(n s)$ space requires $O(\Delta^2/s + \Delta)$ colors. Note, in
particular, that for an asymptotically optimal $O(\Delta)$ coloring, this
algorithm requires $\Omega(n\Delta)$ space which is as large as the input.
Whether such a coloring can be achieved with sublinear space has been left
open.
</p>
<p>In this paper, we answer this question in the affirmative. We present a
randomized algorithm that returns an asymptotically optimal $O(\Delta)$ edge
coloring using $\widetilde{O}(n \sqrt{\Delta})$ space. More generally, our
algorithm returns a proper $O(\Delta^{1.5}/s + \Delta)$ edge coloring with
$\widetilde{O}(n s)$ space, improving prior algorithms for the whole range of
$s$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01756'>Connectivity Queries under Vertex Failures: Not Optimal, but Practical</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Evangelos Kosinas</p><p>We revisit once more the problem of designing an oracle for answering
connectivity queries in undirected graphs in the presence of vertex failures.
Specifically, given an undirected graph $G$ with $n$ vertices and $m$ edges and
an integer $d_{\star}\ll n$, the goal is to preprocess the graph in order to
construct a data structure $\mathcal{D}$ such that, given a set of vertices $F$
with $|F|=d\leq d_{\star}$, we can derive an oracle from $\mathcal{D}$ that can
efficiently answer queries of the form "is $x$ connected with $y$ in
$G\setminus F$?". Very recently, Long and Saranurak (FOCS 2022) provided a
solution to this problem that is almost optimal with respect to the
preprocessing time, the space usage, the update time, and the query time.
However, their solution is highly complicated, and it seems very difficult to
be implemented efficiently. Furthermore, it does not settle the complexity of
the problem in the regime where $d_{\star}$ is a constant. Here, we provide a
much simpler solution to this problem, that uses only textbook data structures.
Our algorithm is deterministic, it has preprocessing time and space complexity
$O(d_{\star}m\log n)$, update time $O(d^4 \log n)$, and query time $O(d)$.
These bounds compare very well with the previous best, especially considering
the simplicity of our approach. In fact, if we assume that $d_{\star}$ is a
constant ($d_{\star}\geq 4$), then our algorithm improves on the
state-of-the-art in every respect, except space. Nevertheless, even our space
usage in this case is almost linear. Finally, the data structure that we
provide is flexible with respect to $d_{\star}$: it can be adapted to increases
and decreases, in time and space that are almost proportional to the change in
$d_{\star}$ and the size of the graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kosinas_E/0/1/0/all/0/1">Evangelos Kosinas</a></p><p>We revisit once more the problem of designing an oracle for answering
connectivity queries in undirected graphs in the presence of vertex failures.
Specifically, given an undirected graph $G$ with $n$ vertices and $m$ edges and
an integer $d_{\star}\ll n$, the goal is to preprocess the graph in order to
construct a data structure $\mathcal{D}$ such that, given a set of vertices $F$
with $|F|=d\leq d_{\star}$, we can derive an oracle from $\mathcal{D}$ that can
efficiently answer queries of the form "is $x$ connected with $y$ in
$G\setminus F$?". Very recently, Long and Saranurak (FOCS 2022) provided a
solution to this problem that is almost optimal with respect to the
preprocessing time, the space usage, the update time, and the query time.
However, their solution is highly complicated, and it seems very difficult to
be implemented efficiently. Furthermore, it does not settle the complexity of
the problem in the regime where $d_{\star}$ is a constant. Here, we provide a
much simpler solution to this problem, that uses only textbook data structures.
Our algorithm is deterministic, it has preprocessing time and space complexity
$O(d_{\star}m\log n)$, update time $O(d^4 \log n)$, and query time $O(d)$.
These bounds compare very well with the previous best, especially considering
the simplicity of our approach. In fact, if we assume that $d_{\star}$ is a
constant ($d_{\star}\geq 4$), then our algorithm improves on the
state-of-the-art in every respect, except space. Nevertheless, even our space
usage in this case is almost linear. Finally, the data structure that we
provide is flexible with respect to $d_{\star}$: it can be adapted to increases
and decreases, in time and space that are almost proportional to the change in
$d_{\star}$ and the size of the graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01942'>Experimental Design for Any $p$-Norm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lap Chi Lau, Robert Wang, Hong Zhou</p><p>We consider a general $p$-norm objective for experimental design problems
that captures some well-studied objectives (D/A/E-design) as special cases. We
prove that a randomized local search approach provides a unified algorithm to
solve this problem for all $p$. This provides the first approximation algorithm
for the general $p$-norm objective, and a nice interpolation of the best known
bounds of the special cases.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lau_L/0/1/0/all/0/1">Lap Chi Lau</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Robert Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hong Zhou</a></p><p>We consider a general $p$-norm objective for experimental design problems
that captures some well-studied objectives (D/A/E-design) as special cases. We
prove that a randomized local search approach provides a unified algorithm to
solve this problem for all $p$. This provides the first approximation algorithm
for the general $p$-norm objective, and a nice interpolation of the best known
bounds of the special cases.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01993'>Computing paths of large rank in planar frameworks deterministically</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fedor V. Fomin, Petr A. Golovach, Tuukka Korhonen, Giannos Stamoulis</p><p>A framework consists of an undirected graph $G$ and a matroid $M$ whose
elements correspond to the vertices of $G$. Recently, Fomin et al. [SODA 2023]
and Eiben et al. [ArXiV 2023] developed parameterized algorithms for computing
paths of rank $k$ in frameworks. More precisely, for vertices $s$ and $t$ of
$G$, and an integer $k$, they gave FPT algorithms parameterized by $k$ deciding
whether there is an $(s,t)$-path in $G$ whose vertex set contains a subset of
elements of $M$ of rank $k$. These algorithms are based on Schwartz-Zippel
lemma for polynomial identity testing and thus are randomized, and therefore
the existence of a deterministic FPT algorithm for this problem remains open.
We present the first deterministic FPT algorithm that solves the problem in
frameworks whose underlying graph $G$ is planar. While the running time of our
algorithm is worse than the running times of the recent randomized algorithms,
our algorithm works on more general classes of matroids. In particular, this is
the first FPT algorithm for the case when matroid $M$ is represented over
rationals. Our main technical contribution is the nontrivial adaptation of the
classic irrelevant vertex technique to frameworks to reduce the given instance
to one of bounded treewidth. This allows us to employ the toolbox of
representative sets to design a dynamic programming procedure solving the
problem efficiently on instances of bounded treewidth.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fomin_F/0/1/0/all/0/1">Fedor V. Fomin</a>, <a href="http://arxiv.org/find/cs/1/au:+Golovach_P/0/1/0/all/0/1">Petr A. Golovach</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_T/0/1/0/all/0/1">Tuukka Korhonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Stamoulis_G/0/1/0/all/0/1">Giannos Stamoulis</a></p><p>A framework consists of an undirected graph $G$ and a matroid $M$ whose
elements correspond to the vertices of $G$. Recently, Fomin et al. [SODA 2023]
and Eiben et al. [ArXiV 2023] developed parameterized algorithms for computing
paths of rank $k$ in frameworks. More precisely, for vertices $s$ and $t$ of
$G$, and an integer $k$, they gave FPT algorithms parameterized by $k$ deciding
whether there is an $(s,t)$-path in $G$ whose vertex set contains a subset of
elements of $M$ of rank $k$. These algorithms are based on Schwartz-Zippel
lemma for polynomial identity testing and thus are randomized, and therefore
the existence of a deterministic FPT algorithm for this problem remains open.
We present the first deterministic FPT algorithm that solves the problem in
frameworks whose underlying graph $G$ is planar. While the running time of our
algorithm is worse than the running times of the recent randomized algorithms,
our algorithm works on more general classes of matroids. In particular, this is
the first FPT algorithm for the case when matroid $M$ is represented over
rationals. Our main technical contribution is the nontrivial adaptation of the
classic irrelevant vertex technique to frameworks to reduce the given instance
to one of bounded treewidth. This allows us to employ the toolbox of
representative sets to design a dynamic programming procedure solving the
problem efficiently on instances of bounded treewidth.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.02011'>Approximating Long Cycle Above Dirac's Guarantee</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fedor F. Fomin, Petr A. Golovach, Danil Sagunov, Kirill Simonov</p><p>Parameterization above (or below) a guarantee is a successful concept in
parameterized algorithms. The idea is that many computational problems admit
``natural'' guarantees bringing to algorithmic questions whether a better
solution (above the guarantee) could be obtained efficiently. The above
guarantee paradigm has led to several exciting discoveries in the areas of
parameterized algorithms and kernelization. We argue that this paradigm could
bring forth fresh perspectives on well-studied problems in approximation
algorithms. Our example is the longest cycle problem. One of the oldest results
in extremal combinatorics is the celebrated Dirac's theorem from 1952. Dirac's
theorem provides the following guarantee on the length of the longest cycle:
for every 2-connected n-vertex graph G with minimum degree \delta(G)\leq n/2,
the length of a longest cycle L is at least 2\delta(G). Thus, the ``essential''
part in finding the longest cycle is in approximating the ``offset'' k = L - 2
\delta(G). The main result of this paper is the above-guarantee approximation
theorem for k. Informally, the theorem says that approximating the offset k is
not harder than approximating the total length L of a cycle. In other words,
for any (reasonably well-behaved) function f, a polynomial time algorithm
constructing a cycle of length f(L) in an undirected graph with a cycle of
length L, yields a polynomial time algorithm constructing a cycle of length
2\delta(G)+\Omega(f(k)).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fomin_F/0/1/0/all/0/1">Fedor F. Fomin</a>, <a href="http://arxiv.org/find/cs/1/au:+Golovach_P/0/1/0/all/0/1">Petr A. Golovach</a>, <a href="http://arxiv.org/find/cs/1/au:+Sagunov_D/0/1/0/all/0/1">Danil Sagunov</a>, <a href="http://arxiv.org/find/cs/1/au:+Simonov_K/0/1/0/all/0/1">Kirill Simonov</a></p><p>Parameterization above (or below) a guarantee is a successful concept in
parameterized algorithms. The idea is that many computational problems admit
``natural'' guarantees bringing to algorithmic questions whether a better
solution (above the guarantee) could be obtained efficiently. The above
guarantee paradigm has led to several exciting discoveries in the areas of
parameterized algorithms and kernelization. We argue that this paradigm could
bring forth fresh perspectives on well-studied problems in approximation
algorithms. Our example is the longest cycle problem. One of the oldest results
in extremal combinatorics is the celebrated Dirac's theorem from 1952. Dirac's
theorem provides the following guarantee on the length of the longest cycle:
for every 2-connected n-vertex graph G with minimum degree \delta(G)\leq n/2,
the length of a longest cycle L is at least 2\delta(G). Thus, the ``essential''
part in finding the longest cycle is in approximating the ``offset'' k = L - 2
\delta(G). The main result of this paper is the above-guarantee approximation
theorem for k. Informally, the theorem says that approximating the offset k is
not harder than approximating the total length L of a cycle. In other words,
for any (reasonably well-behaved) function f, a polynomial time algorithm
constructing a cycle of length f(L) in an undirected graph with a cycle of
length L, yields a polynomial time algorithm constructing a cycle of length
2\delta(G)+\Omega(f(k)).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.02059'>Algorithmic Theory of Qubit Routing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Takehiro Ito, Naonori Kakimura, Naoyuki Kamiyama, Yusuke Kobayashi, Yoshio Okamoto</p><p>The qubit routing problem, also known as the swap minimization problem, is a
(classical) combinatorial optimization problem that arises in the design of
compilers of quantum programs. We study the qubit routing problem from the
viewpoint of theoretical computer science, while most of the existing studies
investigated the practical aspects. We concentrate on the linear nearest
neighbor (LNN) architectures of quantum computers, in which the graph topology
is a path. Our results are three-fold. (1) We prove that the qubit routing
problem is NP-hard. (2) We give a fixed-parameter algorithm when the number of
two-qubit gates is a parameter. (3) We give a polynomial-time algorithm when
each qubit is involved in at most one two-qubit gate.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ito_T/0/1/0/all/0/1">Takehiro Ito</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakimura_N/0/1/0/all/0/1">Naonori Kakimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamiyama_N/0/1/0/all/0/1">Naoyuki Kamiyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1">Yusuke Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Okamoto_Y/0/1/0/all/0/1">Yoshio Okamoto</a></p><p>The qubit routing problem, also known as the swap minimization problem, is a
(classical) combinatorial optimization problem that arises in the design of
compilers of quantum programs. We study the qubit routing problem from the
viewpoint of theoretical computer science, while most of the existing studies
investigated the practical aspects. We concentrate on the linear nearest
neighbor (LNN) architectures of quantum computers, in which the graph topology
is a path. Our results are three-fold. (1) We prove that the qubit routing
problem is NP-hard. (2) We give a fixed-parameter algorithm when the number of
two-qubit gates is a parameter. (3) We give a polynomial-time algorithm when
each qubit is involved in at most one two-qubit gate.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.02132'>An Efficient Algorithm for All-Pairs Bounded Edge Connectivity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shyan Akmal, Ce Jin</p><p>Our work concerns algorithms for an unweighted variant of Maximum Flow. In
the All-Pairs Connectivity (APC) problem, we are given a graph $G$ on $n$
vertices and $m$ edges, and are tasked with computing the maximum number of
edge-disjoint paths from $s$ to $t$ (equivalently, the size of a minimum
$(s,t)$-cut) in $G$, for all pairs of vertices $(s,t)$. Although over
undirected graphs APC can be solved in essentially optimal $n^{2+o(1)}$ time,
the true time complexity of APC over directed graphs remains open: this problem
can be solved in $\tilde{O}(m^\omega)$ time, where $\omega \in [2, 2.373)$ is
the exponent of matrix multiplication, but no matching conditional lower bound
is known.
</p>
<p>We study a variant of APC called the $k$-Bounded All Pairs Connectivity
($k$-APC) problem. In this problem, we are given an integer $k$ and graph $G$,
and are tasked with reporting the size of a minimum $(s,t)$-cut only for pairs
$(s,t)$ of vertices with a minimum cut size less than $k$ (if the minimum
$(s,t)$-cut has size at least $k$, we just report it is "large" instead of
computing the exact value).
</p>
<p>We present an algorithm solving $k$-APC in directed graphs in
$\tilde{O}((kn)^\omega)$ time. This runtime is $\tilde O(n^\omega)$ for all $k$
polylogarithmic in $n$, which is essentially optimal under popular conjectures
from fine-grained complexity. Previously, this runtime was only known for $k\le
2$ [Georgiadis et al., ICALP 2017].
</p>
<p>We also study a variant of $k$-APC, the $k$-Bounded All-Pairs Vertex
Connectivity ($k$-APVC) problem, which considers internally vertex-disjoint
paths instead of edge-disjoint paths. We present an algorithm solving $k$-APVC
in directed graphs in $\tilde{O}(k^2n^\omega)$ time. Previous work solved an
easier version of the $k$-APVC problem in $\tilde O((kn)^\omega)$ time [Abboud
et al, ICALP 2019].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Akmal_S/0/1/0/all/0/1">Shyan Akmal</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1">Ce Jin</a></p><p>Our work concerns algorithms for an unweighted variant of Maximum Flow. In
the All-Pairs Connectivity (APC) problem, we are given a graph $G$ on $n$
vertices and $m$ edges, and are tasked with computing the maximum number of
edge-disjoint paths from $s$ to $t$ (equivalently, the size of a minimum
$(s,t)$-cut) in $G$, for all pairs of vertices $(s,t)$. Although over
undirected graphs APC can be solved in essentially optimal $n^{2+o(1)}$ time,
the true time complexity of APC over directed graphs remains open: this problem
can be solved in $\tilde{O}(m^\omega)$ time, where $\omega \in [2, 2.373)$ is
the exponent of matrix multiplication, but no matching conditional lower bound
is known.
</p>
<p>We study a variant of APC called the $k$-Bounded All Pairs Connectivity
($k$-APC) problem. In this problem, we are given an integer $k$ and graph $G$,
and are tasked with reporting the size of a minimum $(s,t)$-cut only for pairs
$(s,t)$ of vertices with a minimum cut size less than $k$ (if the minimum
$(s,t)$-cut has size at least $k$, we just report it is "large" instead of
computing the exact value).
</p>
<p>We present an algorithm solving $k$-APC in directed graphs in
$\tilde{O}((kn)^\omega)$ time. This runtime is $\tilde O(n^\omega)$ for all $k$
polylogarithmic in $n$, which is essentially optimal under popular conjectures
from fine-grained complexity. Previously, this runtime was only known for $k\le
2$ [Georgiadis et al., ICALP 2017].
</p>
<p>We also study a variant of $k$-APC, the $k$-Bounded All-Pairs Vertex
Connectivity ($k$-APVC) problem, which considers internally vertex-disjoint
paths instead of edge-disjoint paths. We present an algorithm solving $k$-APVC
in directed graphs in $\tilde{O}(k^2n^\omega)$ time. Previous work solved an
easier version of the $k$-APVC problem in $\tilde O((kn)^\omega)$ time [Abboud
et al, ICALP 2019].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.02154'>Random Shreier graphs of the general linear group over finite fields and expanders</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Geoffroy Caillat-Grenier</p><p>In this paper we discuss potentially practical ways to produce expander
graphs with good spectral properties and a compact description. We focus on
several classes of uniform and bipartite expander graphs defined as random
Schreier graphs of the general linear group over the finite field of size two.
We perform numerical experiments and show that such constructions produce
spectral expanders that can be useful for practical applications. To find a
theoretical explanation of the observed experimental results, we used the
method of moments to prove upper bounds for the expected second largest
eigenvalue of the random Schreier graphs used in our constructions. We focus on
bounds for which it is difficult to study the asymptotic behaviour but it is
possible to compute non-trivial conclusions for relatively small graphs with
parameters from our numerical experiments (e.g., with less than 2^200 vertices
and degree at least logarithmic in the number of vertices).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Caillat_Grenier_G/0/1/0/all/0/1">Geoffroy Caillat-Grenier</a></p><p>In this paper we discuss potentially practical ways to produce expander
graphs with good spectral properties and a compact description. We focus on
several classes of uniform and bipartite expander graphs defined as random
Schreier graphs of the general linear group over the finite field of size two.
We perform numerical experiments and show that such constructions produce
spectral expanders that can be useful for practical applications. To find a
theoretical explanation of the observed experimental results, we used the
method of moments to prove upper bounds for the expected second largest
eigenvalue of the random Schreier graphs used in our constructions. We focus on
bounds for which it is difficult to study the asymptotic behaviour but it is
possible to compute non-trivial conclusions for relatively small graphs with
parameters from our numerical experiments (e.g., with less than 2^200 vertices
and degree at least logarithmic in the number of vertices).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.02166'>Minimum Chain Cover in Almost Linear Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Manuel Caceres</p><p>A minimum chain cover (MCC) of a $k$-width directed acyclic graph (DAG) $G =
(V, E)$ is a set of $k$ chains (paths in the transitive closure) of $G$ such
that every vertex appears in at least one chain in the cover. The
state-of-the-art solutions for MCC run in time $\tilde{O}(k(|V|+|E|))$
[M\"akinen et at., TALG], $O(T_{MF}(|E|) + k|V|)$, $O(k^2|V| + |E|)$ [C\'aceres
et al., SODA 2022], $\tilde{O}(|V|^{3/2} + |E|)$ [Kogan and Parter, ICALP 2022]
and $\tilde{O}(T_{MCF}(|E|) + \sqrt{k}|V|)$ [Kogan and Parter, SODA 2023],
where $T_{MF}(|E|)$ and $T_{MCF}(|E|)$ are the running times for solving
maximum flow (MF) and minimum-cost flow (MCF), respectively.
</p>
<p>In this work we present an algorithm running in time $O(T_{MF}(|E|) +
(|V|+|E|)\log{k})$. By considering the recent result for solving MF [Chen et
al., FOCS 2022] our algorithm is the first running in almost linear time.
Moreover, our techniques are deterministic and derive a deterministic
near-linear time algorithm for MCC if the same is provided for MF. At the core
of our solution we use a modified version of the mergeable dictionaries [Farach
and Thorup, Algorithmica], [Iacono and \"Ozkan, ICALP 2010] data structure
boosted with the SIZE-SPLIT operation and answering queries in amortized
logarithmic time, which can be of independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Caceres_M/0/1/0/all/0/1">Manuel Caceres</a></p><p>A minimum chain cover (MCC) of a $k$-width directed acyclic graph (DAG) $G =
(V, E)$ is a set of $k$ chains (paths in the transitive closure) of $G$ such
that every vertex appears in at least one chain in the cover. The
state-of-the-art solutions for MCC run in time $\tilde{O}(k(|V|+|E|))$
[M\"akinen et at., TALG], $O(T_{MF}(|E|) + k|V|)$, $O(k^2|V| + |E|)$ [C\'aceres
et al., SODA 2022], $\tilde{O}(|V|^{3/2} + |E|)$ [Kogan and Parter, ICALP 2022]
and $\tilde{O}(T_{MCF}(|E|) + \sqrt{k}|V|)$ [Kogan and Parter, SODA 2023],
where $T_{MF}(|E|)$ and $T_{MCF}(|E|)$ are the running times for solving
maximum flow (MF) and minimum-cost flow (MCF), respectively.
</p>
<p>In this work we present an algorithm running in time $O(T_{MF}(|E|) +
(|V|+|E|)\log{k})$. By considering the recent result for solving MF [Chen et
al., FOCS 2022] our algorithm is the first running in almost linear time.
Moreover, our techniques are deterministic and derive a deterministic
near-linear time algorithm for MCC if the same is provided for MF. At the core
of our solution we use a modified version of the mergeable dictionaries [Farach
and Thorup, Algorithmica], [Iacono and \"Ozkan, ICALP 2010] data structure
boosted with the SIZE-SPLIT operation and answering queries in amortized
logarithmic time, which can be of independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.02169'>Learning-Augmented Online TSP on Rings, Trees, Flowers and (almost) Everywhere Else</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Evripidis Bampis, Bruno Escoffier, Themis Gouleakis, Niklas Hahn, Kostas Lakis, Golnoosh Shahkarami, Michalis Xefteris</p><p>We study the Online Traveling Salesperson Problem (OLTSP) with predictions.
In OLTSP, a sequence of initially unknown requests arrive over time at points
(locations) of a metric space. The goal is, starting from a particular point of
the metric space (the origin), to serve all these requests while minimizing the
total time spent. The server moves with unit speed or is "waiting" (zero speed)
at some location. We consider two variants: in the open variant, the goal is
achieved when the last request is served. In the closed one, the server
additionally has to return to the origin. We adopt a prediction model,
introduced for OLTSP on the line, in which the predictions correspond to the
locations of the requests and extend it to more general metric spaces.
</p>
<p>We first propose an oracle-based algorithmic framework, inspired by previous
work. This framework allows us to design online algorithms for general metric
spaces that provide competitive ratio guarantees which, given perfect
predictions, beat the best possible classical guarantee (consistency).
Moreover, they degrade gracefully along with the increase in error
(smoothness), but always within a constant factor of the best known competitive
ratio in the classical case (robustness).
</p>
<p>Having reduced the problem to designing suitable efficient oracles, we
describe how to achieve this for general metric spaces as well as specific
metric spaces (rings, trees and flowers), the resulting algorithms being
tractable in the latter case. The consistency guarantees of our algorithms are
tight in almost all cases, and their smoothness guarantees only suffer a linear
dependency on the error, which we show is necessary. Finally, we provide
robustness guarantees improving previous results.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bampis_E/0/1/0/all/0/1">Evripidis Bampis</a>, <a href="http://arxiv.org/find/cs/1/au:+Escoffier_B/0/1/0/all/0/1">Bruno Escoffier</a>, <a href="http://arxiv.org/find/cs/1/au:+Gouleakis_T/0/1/0/all/0/1">Themis Gouleakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hahn_N/0/1/0/all/0/1">Niklas Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakis_K/0/1/0/all/0/1">Kostas Lakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahkarami_G/0/1/0/all/0/1">Golnoosh Shahkarami</a>, <a href="http://arxiv.org/find/cs/1/au:+Xefteris_M/0/1/0/all/0/1">Michalis Xefteris</a></p><p>We study the Online Traveling Salesperson Problem (OLTSP) with predictions.
In OLTSP, a sequence of initially unknown requests arrive over time at points
(locations) of a metric space. The goal is, starting from a particular point of
the metric space (the origin), to serve all these requests while minimizing the
total time spent. The server moves with unit speed or is "waiting" (zero speed)
at some location. We consider two variants: in the open variant, the goal is
achieved when the last request is served. In the closed one, the server
additionally has to return to the origin. We adopt a prediction model,
introduced for OLTSP on the line, in which the predictions correspond to the
locations of the requests and extend it to more general metric spaces.
</p>
<p>We first propose an oracle-based algorithmic framework, inspired by previous
work. This framework allows us to design online algorithms for general metric
spaces that provide competitive ratio guarantees which, given perfect
predictions, beat the best possible classical guarantee (consistency).
Moreover, they degrade gracefully along with the increase in error
(smoothness), but always within a constant factor of the best known competitive
ratio in the classical case (robustness).
</p>
<p>Having reduced the problem to designing suitable efficient oracles, we
describe how to achieve this for general metric spaces as well as specific
metric spaces (rings, trees and flowers), the resulting algorithms being
tractable in the latter case. The consistency guarantees of our algorithms are
tight in almost all cases, and their smoothness guarantees only suffer a linear
dependency on the error, which we show is necessary. Finally, we provide
robustness guarantees improving previous results.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.02240'>A $4/3$ Approximation for $2$-Vertex-Connectivity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Miguel Bosch-Calvo, Fabrizio Grandoni, Afrouz Jabal Ameli</p><p>The 2-Vertex-Connected Spanning Subgraph problem (2VCSS) is among the most
basic NP-hard (Survivable) Network Design problems: we are given an
(unweighted) undirected graph $G$. Our goal is to find a subgraph $S$ of $G$
with the minimum number of edges which is $2$-vertex-connected, namely $S$
remains connected after the deletion of an arbitrary node. 2VCSS is
well-studied in terms of approximation algorithms, and the current best
(polynomial-time) approximation factor is $10/7$ by Heeger and Vygen [SIDMA'17]
(improving on earlier results by Khuller and Vishkin [STOC'92] and Garg,
Vempala and Singla [SODA'93]).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bosch_Calvo_M/0/1/0/all/0/1">Miguel Bosch-Calvo</a>, <a href="http://arxiv.org/find/cs/1/au:+Grandoni_F/0/1/0/all/0/1">Fabrizio Grandoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Ameli_A/0/1/0/all/0/1">Afrouz Jabal Ameli</a></p><p>The 2-Vertex-Connected Spanning Subgraph problem (2VCSS) is among the most
basic NP-hard (Survivable) Network Design problems: we are given an
(unweighted) undirected graph $G$. Our goal is to find a subgraph $S$ of $G$
with the minimum number of edges which is $2$-vertex-connected, namely $S$
remains connected after the deletion of an arbitrary node. 2VCSS is
well-studied in terms of approximation algorithms, and the current best
(polynomial-time) approximation factor is $10/7$ by Heeger and Vygen [SIDMA'17]
(improving on earlier results by Khuller and Vishkin [STOC'92] and Garg,
Vempala and Singla [SODA'93]).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.02263'>Triangle Counting with Local Edge Differential Privacy</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Talya Eden, Quanquan C. Liu, Sofya Raskhodnikova, Adam Smith</p><p>Many deployments of differential privacy in industry are in the local model,
where each party releases its private information via a differentially private
randomizer. We study triangle counting in the noninteractive and interactive
local model with edge differential privacy (that, intuitively, requires that
the outputs of the algorithm on graphs that differ in one edge be
indistinguishable). In this model, each party's local view consists of the
adjacency list of one vertex.
</p>
<p>In the noninteractive model, we prove that additive $\Omega(n^2)$ error is
necessary, where $n$ is the number of nodes. This lower bound is our main
technical contribution. It uses a reconstruction attack with a new class of
linear queries and a novel mix-and-match strategy of running the local
randomizers with different completions of their adjacency lists. It matches the
additive error of the algorithm based on Randomized Response, proposed by
Imola, Murakami and Chaudhuri (USENIX2021) and analyzed by Imola, Murakami and
Chaudhuri (CCS2022) for constant $\varepsilon$. We use a different
postprocessing of Randomized Response and provide tight bounds on the variance
of the resulting algorithm.
</p>
<p>In the interactive setting, we prove a lower bound of $\Omega(n^{3/2})$ on
the additive error. Previously, no hardness results were known for interactive,
edge-private algorithms in the local model, except for those that follow
trivially from the results for the central model. Our work significantly
improves on the state of the art in differentially private graph analysis in
the local model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Eden_T/0/1/0/all/0/1">Talya Eden</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Quanquan C. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Raskhodnikova_S/0/1/0/all/0/1">Sofya Raskhodnikova</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_A/0/1/0/all/0/1">Adam Smith</a></p><p>Many deployments of differential privacy in industry are in the local model,
where each party releases its private information via a differentially private
randomizer. We study triangle counting in the noninteractive and interactive
local model with edge differential privacy (that, intuitively, requires that
the outputs of the algorithm on graphs that differ in one edge be
indistinguishable). In this model, each party's local view consists of the
adjacency list of one vertex.
</p>
<p>In the noninteractive model, we prove that additive $\Omega(n^2)$ error is
necessary, where $n$ is the number of nodes. This lower bound is our main
technical contribution. It uses a reconstruction attack with a new class of
linear queries and a novel mix-and-match strategy of running the local
randomizers with different completions of their adjacency lists. It matches the
additive error of the algorithm based on Randomized Response, proposed by
Imola, Murakami and Chaudhuri (USENIX2021) and analyzed by Imola, Murakami and
Chaudhuri (CCS2022) for constant $\varepsilon$. We use a different
postprocessing of Randomized Response and provide tight bounds on the variance
of the resulting algorithm.
</p>
<p>In the interactive setting, we prove a lower bound of $\Omega(n^{3/2})$ on
the additive error. Previously, no hardness results were known for interactive,
edge-private algorithms in the local model, except for those that follow
trivially from the results for the central model. Our work significantly
improves on the state of the art in differentially private graph analysis in
the local model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:30:00Z">Thursday, May 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.simons.berkeley.edu/2023/05/mechanisms-inside-or-in-between/'>Mechanisms: Inside or In-Between?</a></h3>
        <p class='tr-article-feed'>from <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          by Issa Kohler-Hausmann (Senior Law and Society Fellow, Spring 2022, Simons Institute)1 This work was made possible by the Simons Institute’s Causality program in the spring of 2022, where I was the Law and Society fellow and had the opportunity &#8230; Continue reading &#8594;<p>By Simons Institute Editor</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          by Issa Kohler-Hausmann (Senior Law and Society Fellow, Spring 2022, Simons Institute)1 This work was made possible by the Simons Institute’s Causality program in the spring of 2022, where I was the Law and Society fellow and had the opportunity &#8230; <a href="https://blog.simons.berkeley.edu/2023/05/mechanisms-inside-or-in-between/">Continue reading <span class="meta-nav">&#8594;</span></a><p class="authors">By Simons Institute Editor</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-04T00:00:00Z">Thursday, May 04 2023, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, May 03
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/05/03/postdocs-at-aalto-university-apply-by-june-1-2023/'>Postdocs at Aalto University (apply by June 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The research group of Jukka Suomela at Aalto University is looking for postdoctoral researchers to work on the foundations of distributed and parallel computing. Website: research.cs.aalto.fi/da/jobs/ Email: jukka.suomela@aalto.fi
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The research group of Jukka Suomela at Aalto University is looking for postdoctoral researchers to work on the foundations of distributed and parallel computing.</p>
<p>Website: <a href="https://research.cs.aalto.fi/da/jobs/">https://research.cs.aalto.fi/da/jobs/</a><br />
Email: jukka.suomela@aalto.fi</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T20:30:59Z">Wednesday, May 03 2023, 20:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/064'>TR23-064 |   On the Lower Bound on the Length of Relaxed Locally Decodable Codes | 

	Oded Goldreich</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We revisit the known proof of the lower bound on the length of relaxed locally decodable codes, providing an arguably simpler exposition that yields a slightly better lower bound for the non-adaptive case and a weaker bound in the general case.

Recall that a locally decodable code is an error correcting code that allows for the recovery of any desired bit in the message based on a constant number of randomly selected bits in the possibly corrupted codeword.
The relaxed version requires correct recovery only in case of actual codewords, while requiring that for strings that are (only) close to the code, with high probability, the local decoder outputs either the correct value or a special failure symbol (but not a wrong value). 

The lower bounds we prove are $n\geq k^{1+\Omega(1/q^2)}$ for the non-adaptive case and $n\geq k^{1+\Omega(1/q^3)}$ for the general case, where $k$ denotes the message length, $n$ denotes the length of the codewords, and $q$ denotes the (constant) number of queries.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We revisit the known proof of the lower bound on the length of relaxed locally decodable codes, providing an arguably simpler exposition that yields a slightly better lower bound for the non-adaptive case and a weaker bound in the general case.

Recall that a locally decodable code is an error correcting code that allows for the recovery of any desired bit in the message based on a constant number of randomly selected bits in the possibly corrupted codeword.
The relaxed version requires correct recovery only in case of actual codewords, while requiring that for strings that are (only) close to the code, with high probability, the local decoder outputs either the correct value or a special failure symbol (but not a wrong value). 

The lower bounds we prove are $n\geq k^{1+\Omega(1/q^2)}$ for the non-adaptive case and $n\geq k^{1+\Omega(1/q^3)}$ for the general case, where $k$ denotes the message length, $n$ denotes the length of the codewords, and $q$ denotes the (constant) number of queries.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T14:52:01Z">Wednesday, May 03 2023, 14:52</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01064'>Questions and Concerns About Google's Quantum Supremacy Claim</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gil Kalai, Yosef Rinott, Tomer Shoham</p><p>In October 2019, Nature published a paper [6] describing an experimental work
that was performed at Google. The paper claims to demonstrate quantum
(computational) supremacy on a 53-qubit quantum computer. Since then we have
been involved in a long-term project to study various statistical aspects of
the Google experiment. In [30] we studied Google's statistical framework that
we found to be very sound and offered some technical improvements. This
document describes three main concerns (based on statistical analysis) about
the Google 2019 experiment. The first concern is that the data do not agree
with Google's noise model (or any other specific model). The second concern is
that a crucial simple formula for a priori estimation of the fidelity seems to
involve an unexpected independence assumption, and yet it gives very accurate
predictions. The third concern is about statistical properties of the
calibration process.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Kalai_G/0/1/0/all/0/1">Gil Kalai</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Rinott_Y/0/1/0/all/0/1">Yosef Rinott</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Shoham_T/0/1/0/all/0/1">Tomer Shoham</a></p><p>In October 2019, Nature published a paper [6] describing an experimental work
that was performed at Google. The paper claims to demonstrate quantum
(computational) supremacy on a 53-qubit quantum computer. Since then we have
been involved in a long-term project to study various statistical aspects of
the Google experiment. In [30] we studied Google's statistical framework that
we found to be very sound and offered some technical improvements. This
document describes three main concerns (based on statistical analysis) about
the Google 2019 experiment. The first concern is that the data do not agree
with Google's noise model (or any other specific model). The second concern is
that a crucial simple formula for a priori estimation of the fidelity seems to
involve an unexpected independence assumption, and yet it gives very accurate
predictions. The third concern is about statistical properties of the
calibration process.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01581'>Coverability in VASS Revisited: Improving Rackoff's Bound to Obtain Conditional Optimality</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marvin K&#xfc;nnemann, Filip Mazowiecki, Lia Sch&#xfc;tze, Henry Sinclair-Banks, Karol W&#x119;grzycki</p><p>Seminal results establish that the coverability problem for Vector Addition
Systems with States (VASS) is in EXPSPACE (Rackoff, '78) and is EXPSPACE-hard
already under unary encodings (Lipton, '76). More precisely, Rosier and Yen
later utilise Rackoff's bounding technique to show that if coverability holds
then there is a run of length at most $n^{2^{\mathcal{O}(d \log d)}}$, where
$d$ is the dimension and $n$ is the size of the given unary VASS. Earlier,
Lipton showed that there exist instances of coverability in $d$-dimensional
unary VASS that are only witnessed by runs of length at least
$n^{2^{\Omega(d)}}$. Our first result closes this gap. We improve the upper
bound by removing the twice-exponentiated $\log(d)$ factor, thus matching
Lipton's lower bound. This closes the corresponding gap for the exact space
required to decide coverability. This also yields a deterministic
$n^{2^{\mathcal{O}(d)}}$-time algorithm for coverability. Our second result is
a matching lower bound, that there does not exist a deterministic
$n^{2^{o(d)}}$-time algorithm, conditioned upon the Exponential Time
Hypothesis.
</p>
<p>When analysing coverability, a standard proof technique is to consider VASS
with bounded counters. Bounded VASS make for an interesting and popular model
due to strong connections with timed automata. Withal, we study a natural
setting where the counter bound is linear in the size of the VASS. Here the
trivial exhaustive search algorithm runs in $\mathcal{O}(n^{d+1})$-time. We
give evidence to this being near-optimal. We prove that in dimension one this
trivial algorithm is conditionally optimal, by showing that $n^{2-o(1)}$-time
is required under the $k$-cycle hypothesis. In general fixed dimension $d$, we
show that $n^{d-2-o(1)}$-time is required under the 3-uniform hyperclique
hypothesis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kunnemann_M/0/1/0/all/0/1">Marvin K&#xfc;nnemann</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazowiecki_F/0/1/0/all/0/1">Filip Mazowiecki</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_L/0/1/0/all/0/1">Lia Sch&#xfc;tze</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinclair_Banks_H/0/1/0/all/0/1">Henry Sinclair-Banks</a>, <a href="http://arxiv.org/find/cs/1/au:+Wegrzycki_K/0/1/0/all/0/1">Karol W&#x119;grzycki</a></p><p>Seminal results establish that the coverability problem for Vector Addition
Systems with States (VASS) is in EXPSPACE (Rackoff, '78) and is EXPSPACE-hard
already under unary encodings (Lipton, '76). More precisely, Rosier and Yen
later utilise Rackoff's bounding technique to show that if coverability holds
then there is a run of length at most $n^{2^{\mathcal{O}(d \log d)}}$, where
$d$ is the dimension and $n$ is the size of the given unary VASS. Earlier,
Lipton showed that there exist instances of coverability in $d$-dimensional
unary VASS that are only witnessed by runs of length at least
$n^{2^{\Omega(d)}}$. Our first result closes this gap. We improve the upper
bound by removing the twice-exponentiated $\log(d)$ factor, thus matching
Lipton's lower bound. This closes the corresponding gap for the exact space
required to decide coverability. This also yields a deterministic
$n^{2^{\mathcal{O}(d)}}$-time algorithm for coverability. Our second result is
a matching lower bound, that there does not exist a deterministic
$n^{2^{o(d)}}$-time algorithm, conditioned upon the Exponential Time
Hypothesis.
</p>
<p>When analysing coverability, a standard proof technique is to consider VASS
with bounded counters. Bounded VASS make for an interesting and popular model
due to strong connections with timed automata. Withal, we study a natural
setting where the counter bound is linear in the size of the VASS. Here the
trivial exhaustive search algorithm runs in $\mathcal{O}(n^{d+1})$-time. We
give evidence to this being near-optimal. We prove that in dimension one this
trivial algorithm is conditionally optimal, by showing that $n^{2-o(1)}$-time
is required under the $k$-cycle hypothesis. In general fixed dimension $d$, we
show that $n^{d-2-o(1)}$-time is required under the 3-uniform hyperclique
hypothesis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01356'>A Quadtree for Hyperbolic Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: S&#xe1;ndor Kisfaludi-Bak, Geert van Wordragen</p><p>We propose a data structure in d-dimensional hyperbolic space that can be
considered a natural counterpart to quadtrees in Euclidean spaces. Based on
this data structure we propose a so-called L-order for hyperbolic point sets,
which is an extension of the Z-order defined in Euclidean spaces. We
demonstrate the usefulness of our hyperbolic quadtree data structure by giving
an algorithm for constant-approximate closest pair and dynamic
constant-approximate nearest neighbours in hyperbolic space of constant
dimension d.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kisfaludi_Bak_S/0/1/0/all/0/1">S&#xe1;ndor Kisfaludi-Bak</a>, <a href="http://arxiv.org/find/cs/1/au:+Wordragen_G/0/1/0/all/0/1">Geert van Wordragen</a></p><p>We propose a data structure in d-dimensional hyperbolic space that can be
considered a natural counterpart to quadtrees in Euclidean spaces. Based on
this data structure we propose a so-called L-order for hyperbolic point sets,
which is an extension of the Z-order defined in Euclidean spaces. We
demonstrate the usefulness of our hyperbolic quadtree data structure by giving
an algorithm for constant-approximate closest pair and dynamic
constant-approximate nearest neighbours in hyperbolic space of constant
dimension d.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01467'>Folding Every Point on a Polygon Boundary to a Point</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nattawut Phetmak, Jittat Fakcharoenphol</p><p>We consider a problem in computational origami. Given a piece of paper as a
convex polygon $P$ and a point $f$ located within, fold every point on a
boundary of $P$ to $f$ and compute a region that is safe from folding, i.e.,
the region with no creases. This problem is an extended version of a problem by
Akitaya, Ballinger, Demaine, Hull, and Schmidt~[CCCG'21] that only folds
corners of the polygon. To find the region, we prove structural properties of
intersections of parabola-bounded regions and use them to devise a linear-time
algorithm. We also prove a structural result regarding the complexity of the
safe region as a variable of the location of point $f$, i.e., the number of
arcs of the safe region can be determined using the straight skeleton of the
polygon $P$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Phetmak_N/0/1/0/all/0/1">Nattawut Phetmak</a>, <a href="http://arxiv.org/find/cs/1/au:+Fakcharoenphol_J/0/1/0/all/0/1">Jittat Fakcharoenphol</a></p><p>We consider a problem in computational origami. Given a piece of paper as a
convex polygon $P$ and a point $f$ located within, fold every point on a
boundary of $P$ to $f$ and compute a region that is safe from folding, i.e.,
the region with no creases. This problem is an extended version of a problem by
Akitaya, Ballinger, Demaine, Hull, and Schmidt~[CCCG'21] that only folds
corners of the polygon. To find the region, we prove structural properties of
intersections of parabola-bounded regions and use them to devise a linear-time
algorithm. We also prove a structural result regarding the complexity of the
safe region as a variable of the location of point $f$, i.e., the number of
arcs of the safe region can be determined using the straight skeleton of the
polygon $P$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01613'>Complexity Framework for Forbidden Subgraphs IV: The Steiner Forest Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hans L. Bodlaender, Matthew Johnson, Barnaby Martin, Jelle J. Oostveen, Sukanya Pandey, Daniel Paulusma, Siani Smith, Erik Jan van Leeuwen</p><p>We study Steiner Forest on $H$-subgraph-free graphs, that is, graphs that do
not contain some fixed graph $H$ as a (not necessarily induced) subgraph. We
are motivated by a recent framework that completely characterizes the
complexity of many problems on $H$-subgraph-free graphs. However, in contrast
to e.g. the related Steiner Tree problem, Steiner Forest falls outside this
framework. Hence, the complexity of Steiner Forest on $H$-subgraph-free graphs
remained tantalizingly open. In this paper, we make significant progress
towards determining the complexity of Steiner Forest on $H$-subgraph-free
graphs. Our main results are four novel polynomial-time algorithms for
different excluded graphs $H$ that are central to further understand its
complexity. Along the way, we study the complexity of Steiner Forest for graphs
with a small $c$-deletion set, that is, a small set $S$ of vertices such that
each component of $G-S$ has size at most $c$. Using this parameter, we give two
noteworthy algorithms that we later employ as subroutines. First, we prove
Steiner Forest is FPT parameterized by $|S|$ when $c=1$ (i.e. the vertex cover
number). Second, we prove Steiner Forest is polynomial-time solvable for graphs
with a 2-deletion set of size at most 2. The latter result is tight, as the
problem is NP-complete for graphs with a 3-deletion set of size 2.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Bodlaender_H/0/1/0/all/0/1">Hans L. Bodlaender</a>, <a href="http://arxiv.org/find/math/1/au:+Johnson_M/0/1/0/all/0/1">Matthew Johnson</a>, <a href="http://arxiv.org/find/math/1/au:+Martin_B/0/1/0/all/0/1">Barnaby Martin</a>, <a href="http://arxiv.org/find/math/1/au:+Oostveen_J/0/1/0/all/0/1">Jelle J. Oostveen</a>, <a href="http://arxiv.org/find/math/1/au:+Pandey_S/0/1/0/all/0/1">Sukanya Pandey</a>, <a href="http://arxiv.org/find/math/1/au:+Paulusma_D/0/1/0/all/0/1">Daniel Paulusma</a>, <a href="http://arxiv.org/find/math/1/au:+Smith_S/0/1/0/all/0/1">Siani Smith</a>, <a href="http://arxiv.org/find/math/1/au:+Leeuwen_E/0/1/0/all/0/1">Erik Jan van Leeuwen</a></p><p>We study Steiner Forest on $H$-subgraph-free graphs, that is, graphs that do
not contain some fixed graph $H$ as a (not necessarily induced) subgraph. We
are motivated by a recent framework that completely characterizes the
complexity of many problems on $H$-subgraph-free graphs. However, in contrast
to e.g. the related Steiner Tree problem, Steiner Forest falls outside this
framework. Hence, the complexity of Steiner Forest on $H$-subgraph-free graphs
remained tantalizingly open. In this paper, we make significant progress
towards determining the complexity of Steiner Forest on $H$-subgraph-free
graphs. Our main results are four novel polynomial-time algorithms for
different excluded graphs $H$ that are central to further understand its
complexity. Along the way, we study the complexity of Steiner Forest for graphs
with a small $c$-deletion set, that is, a small set $S$ of vertices such that
each component of $G-S$ has size at most $c$. Using this parameter, we give two
noteworthy algorithms that we later employ as subroutines. First, we prove
Steiner Forest is FPT parameterized by $|S|$ when $c=1$ (i.e. the vertex cover
number). Second, we prove Steiner Forest is polynomial-time solvable for graphs
with a 2-deletion set of size at most 2. The latter result is tight, as the
problem is NP-complete for graphs with a 3-deletion set of size 2.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01015'>Collision Detection for Modular Robots -- it is easy to cause collisions and hard to avoid them</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Siddharth Gupta, Marc van Kreveld, Othon Michail, Andreas Padalkin</p><p>We consider geometric collision-detection problems for modular reconfigurable
robots. Assuming the nodes (modules) are connected squares on a grid, we
investigate the complexity of deciding whether collisions may occur, or can be
avoided, if a set of expansion and contraction operations is executed. We study
both discrete- and continuous-time models, and allow operations to be coupled
into a single parallel group. Our algorithms to decide if a collision may occur
run in $O(n^2\log^2 n)$ time, $O(n^2)$ time, or $O(n\log^2 n)$ time, depending
on the presence and type of coupled operations, in a continuous-time model for
a modular robot with $n$ nodes. To decide if collisions can be avoided, we show
that a very restricted version is already NP-complete in the discrete-time
model, while the same problem is polynomial in the continuous-time model. A
less restricted version is NP-hard in the continuous-time model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Siddharth Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreveld_M/0/1/0/all/0/1">Marc van Kreveld</a>, <a href="http://arxiv.org/find/cs/1/au:+Michail_O/0/1/0/all/0/1">Othon Michail</a>, <a href="http://arxiv.org/find/cs/1/au:+Padalkin_A/0/1/0/all/0/1">Andreas Padalkin</a></p><p>We consider geometric collision-detection problems for modular reconfigurable
robots. Assuming the nodes (modules) are connected squares on a grid, we
investigate the complexity of deciding whether collisions may occur, or can be
avoided, if a set of expansion and contraction operations is executed. We study
both discrete- and continuous-time models, and allow operations to be coupled
into a single parallel group. Our algorithms to decide if a collision may occur
run in $O(n^2\log^2 n)$ time, $O(n^2)$ time, or $O(n\log^2 n)$ time, depending
on the presence and type of coupled operations, in a continuous-time model for
a modular robot with $n$ nodes. To decide if collisions can be avoided, we show
that a very restricted version is already NP-complete in the discrete-time
model, while the same problem is polynomial in the continuous-time model. A
less restricted version is NP-hard in the continuous-time model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01367'>Multi Layer Peeling for Linear Arrangement and Hierarchical Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yossi Azar, Danny Vainstein</p><p>We present a new multi-layer peeling technique to cluster points in a metric
space. A well-known non-parametric objective is to embed the metric space into
a simpler structured metric space such as a line (i.e., Linear Arrangement) or
a binary tree (i.e., Hierarchical Clustering). Points which are close in the
metric space should be mapped to close points/leaves in the line/tree;
similarly, points which are far in the metric space should be far in the line
or on the tree. In particular we consider the Maximum Linear Arrangement
problem \cite{Approximation_algorithms_for_maximum_linear_arrangement} and the
Maximum Hierarchical Clustering problem
\cite{Hierarchical_Clustering:_Objective_Functions_and_Algorithms} applied to
metrics.
</p>
<p>We design approximation schemes ($1 - \epsilon$ approximation for any
constant $\epsilon &gt; 0$) for these objectives. In particular this shows that by
considering metrics one may significantly improve former approximations ($0.5$
for Max Linear Arrangement and $0.74$ for Max Hierarchical Clustering). Our
main technique, which is called multi-layer peeling, consists of recursively
peeling off points which are far from the "core" of the metric space. The
recursion ends once the core becomes a sufficiently densely weighted metric
space (i.e. the average distance is at least a constant times the diameter) or
once it becomes negligible with respect to its inner contribution to the
objective. Interestingly, the algorithm in the Linear Arrangement case is much
more involved than that in the Hierarchical Clustering case, and uses a
significantly more delicate peeling.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Azar_Y/0/1/0/all/0/1">Yossi Azar</a>, <a href="http://arxiv.org/find/cs/1/au:+Vainstein_D/0/1/0/all/0/1">Danny Vainstein</a></p><p>We present a new multi-layer peeling technique to cluster points in a metric
space. A well-known non-parametric objective is to embed the metric space into
a simpler structured metric space such as a line (i.e., Linear Arrangement) or
a binary tree (i.e., Hierarchical Clustering). Points which are close in the
metric space should be mapped to close points/leaves in the line/tree;
similarly, points which are far in the metric space should be far in the line
or on the tree. In particular we consider the Maximum Linear Arrangement
problem \cite{Approximation_algorithms_for_maximum_linear_arrangement} and the
Maximum Hierarchical Clustering problem
\cite{Hierarchical_Clustering:_Objective_Functions_and_Algorithms} applied to
metrics.
</p>
<p>We design approximation schemes ($1 - \epsilon$ approximation for any
constant $\epsilon &gt; 0$) for these objectives. In particular this shows that by
considering metrics one may significantly improve former approximations ($0.5$
for Max Linear Arrangement and $0.74$ for Max Hierarchical Clustering). Our
main technique, which is called multi-layer peeling, consists of recursively
peeling off points which are far from the "core" of the metric space. The
recursion ends once the core becomes a sufficiently densely weighted metric
space (i.e. the average distance is at least a constant times the diameter) or
once it becomes negligible with respect to its inner contribution to the
objective. Interestingly, the algorithm in the Linear Arrangement case is much
more involved than that in the Hierarchical Clustering case, and uses a
significantly more delicate peeling.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00979'>Spectral clustering in the Gaussian mixture block model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shuangping Li, Tselil Schramm</p><p>Gaussian mixture block models are distributions over graphs that strive to
model modern networks: to generate a graph from such a model, we associate each
vertex $i$ with a latent feature vector $u_i \in \mathbb{R}^d$ sampled from a
mixture of Gaussians, and we add edge $(i,j)$ if and only if the feature
vectors are sufficiently similar, in that $\langle u_i,u_j \rangle \ge \tau$
for a pre-specified threshold $\tau$. The different components of the Gaussian
mixture represent the fact that there may be different types of nodes with
different distributions over features -- for example, in a social network each
component represents the different attributes of a distinct community. Natural
algorithmic tasks associated with these networks are embedding (recovering the
latent feature vectors) and clustering (grouping nodes by their mixture
component).
</p>
<p>In this paper we initiate the study of clustering and embedding graphs
sampled from high-dimensional Gaussian mixture block models, where the
dimension of the latent feature vectors $d\to \infty$ as the size of the
network $n \to \infty$. This high-dimensional setting is most appropriate in
the context of modern networks, in which we think of the latent feature space
as being high-dimensional. We analyze the performance of canonical spectral
clustering and embedding algorithms for such graphs in the case of 2-component
spherical Gaussian mixtures, and begin to sketch out the
information-computation landscape for clustering and embedding in these models.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Li_S/0/1/0/all/0/1">Shuangping Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Schramm_T/0/1/0/all/0/1">Tselil Schramm</a></p><p>Gaussian mixture block models are distributions over graphs that strive to
model modern networks: to generate a graph from such a model, we associate each
vertex $i$ with a latent feature vector $u_i \in \mathbb{R}^d$ sampled from a
mixture of Gaussians, and we add edge $(i,j)$ if and only if the feature
vectors are sufficiently similar, in that $\langle u_i,u_j \rangle \ge \tau$
for a pre-specified threshold $\tau$. The different components of the Gaussian
mixture represent the fact that there may be different types of nodes with
different distributions over features -- for example, in a social network each
component represents the different attributes of a distinct community. Natural
algorithmic tasks associated with these networks are embedding (recovering the
latent feature vectors) and clustering (grouping nodes by their mixture
component).
</p>
<p>In this paper we initiate the study of clustering and embedding graphs
sampled from high-dimensional Gaussian mixture block models, where the
dimension of the latent feature vectors $d\to \infty$ as the size of the
network $n \to \infty$. This high-dimensional setting is most appropriate in
the context of modern networks, in which we think of the latent feature space
as being high-dimensional. We analyze the performance of canonical spectral
clustering and embedding algorithms for such graphs in the case of 2-component
spherical Gaussian mixtures, and begin to sketch out the
information-computation landscape for clustering and embedding in these models.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01069'>Approximating submodular $k$-partition via principle partition sequence</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Karthekeyan Chandrasekaran, Weihang Wang</p><p>In submodular $k$-partition, the input is a non-negative submodular function
$f$ defined over a finite ground set $V$ (given by an evaluation oracle) along
with a positive integer $k$ and the goal is to find a partition of the ground
set $V$ into $k$ non-empty parts $V_1, V_2, ..., V_k$ in order to minimize
$\sum_{i=1}^k f(V_i)$. Narayanan, Roy, and Patkar (Journal of Algorithms, 1996)
designed an algorithm for submodular $k$-partition based on the principal
partition sequence and showed that the approximation factor of their algorithm
is $2$ for the special case of graph cut functions (subsequently rediscovered
by Ravi and Sinha (Journal of Operational Research, 2008)). In this work, we
study the approximation factor of their algorithm for three subfamilies of
submodular functions -- monotone, symmetric, and posimodular. We note that
graph and hypergraph cut functions are symmetric submodular and moreover, both
monotone submodular functions and symmetric submodular functions are
posimodular submodular. We analyze the approximation factor of Narayanan, Roy,
and Patkar's algorithm to show the following results:
</p>
<p>1. The approximation factor of their algorithm for monotone submodular
$k$-partition is $4/3$. This result improves on the $2$-factor achievable via
other algorithms. Moreover, our upper bound of $4/3$ matches the recently shown
lower bound under polynomial number of function evaluation queries (Santiago,
IWOCA 2021).
</p>
<p>2. The approximation factor of their algorithm for symmetric submodular
$k$-partition is $2$. This result generalizes their approximation factor
analysis beyond graph cut functions.
</p>
<p>3. The approximation factor of their algorithm for posimodular submodular
$k$-partition is $2$.
</p>
<p>We also construct an example to show that the approximation factor of their
algorithm for arbitrary submodular functions is $\Omega(n/k)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chandrasekaran_K/0/1/0/all/0/1">Karthekeyan Chandrasekaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weihang Wang</a></p><p>In submodular $k$-partition, the input is a non-negative submodular function
$f$ defined over a finite ground set $V$ (given by an evaluation oracle) along
with a positive integer $k$ and the goal is to find a partition of the ground
set $V$ into $k$ non-empty parts $V_1, V_2, ..., V_k$ in order to minimize
$\sum_{i=1}^k f(V_i)$. Narayanan, Roy, and Patkar (Journal of Algorithms, 1996)
designed an algorithm for submodular $k$-partition based on the principal
partition sequence and showed that the approximation factor of their algorithm
is $2$ for the special case of graph cut functions (subsequently rediscovered
by Ravi and Sinha (Journal of Operational Research, 2008)). In this work, we
study the approximation factor of their algorithm for three subfamilies of
submodular functions -- monotone, symmetric, and posimodular. We note that
graph and hypergraph cut functions are symmetric submodular and moreover, both
monotone submodular functions and symmetric submodular functions are
posimodular submodular. We analyze the approximation factor of Narayanan, Roy,
and Patkar's algorithm to show the following results:
</p>
<p>1. The approximation factor of their algorithm for monotone submodular
$k$-partition is $4/3$. This result improves on the $2$-factor achievable via
other algorithms. Moreover, our upper bound of $4/3$ matches the recently shown
lower bound under polynomial number of function evaluation queries (Santiago,
IWOCA 2021).
</p>
<p>2. The approximation factor of their algorithm for symmetric submodular
$k$-partition is $2$. This result generalizes their approximation factor
analysis beyond graph cut functions.
</p>
<p>3. The approximation factor of their algorithm for posimodular submodular
$k$-partition is $2$.
</p>
<p>We also construct an example to show that the approximation factor of their
algorithm for arbitrary submodular functions is $\Omega(n/k)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01070'>Robust Communication Complexity of Matching: EDCS Achieves 5/6 Approximation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Amir Azarmehr, Soheil Behnezhad</p><p>We study the robust communication complexity of maximum matching. Edges of an
arbitrary $n$-vertex graph $G$ are randomly partitioned between Alice and Bob
independently and uniformly. Alice has to send a single message to Bob such
that Bob can find an (approximate) maximum matching of the whole graph $G$. We
specifically study the best approximation ratio achievable via protocols where
Alice communicates only $\widetilde{O}(n)$ bits to Bob.
</p>
<p>There has been a growing interest on the robust communication model due to
its connections to the random-order streaming model. An algorithm of Assadi and
Behnezhad [ICALP'21] implies a $(2/3+\epsilon_0 \sim .667)$-approximation for a
small constant $0 &lt; \epsilon_0 &lt; 10^{-18}$, which remains the best-known
approximation for general graphs. For bipartite graphs, Assadi and Behnezhad
[Random'21] improved the approximation to .716 albeit with a computationally
inefficient (i.e., exponential time) protocol.
</p>
<p>In this paper, we study a natural and efficient protocol implied by a
random-order streaming algorithm of Bernstein [ICALP'20] which is based on
edge-degree constrained subgraphs (EDCS) [Bernstein and Stein; ICALP'15]. The
result of Bernstein immediately implies that this protocol achieves an (almost)
$(2/3 \sim .666)$-approximation in the robust communication model. We present a
new analysis, proving that it achieves a much better (almost) $(5/6 \sim
.833)$-approximation. This significantly improves previous approximations both
for general and bipartite graphs. We also prove that our analysis of
Bernstein's protocol is tight.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Azarmehr_A/0/1/0/all/0/1">Amir Azarmehr</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnezhad_S/0/1/0/all/0/1">Soheil Behnezhad</a></p><p>We study the robust communication complexity of maximum matching. Edges of an
arbitrary $n$-vertex graph $G$ are randomly partitioned between Alice and Bob
independently and uniformly. Alice has to send a single message to Bob such
that Bob can find an (approximate) maximum matching of the whole graph $G$. We
specifically study the best approximation ratio achievable via protocols where
Alice communicates only $\widetilde{O}(n)$ bits to Bob.
</p>
<p>There has been a growing interest on the robust communication model due to
its connections to the random-order streaming model. An algorithm of Assadi and
Behnezhad [ICALP'21] implies a $(2/3+\epsilon_0 \sim .667)$-approximation for a
small constant $0 &lt; \epsilon_0 &lt; 10^{-18}$, which remains the best-known
approximation for general graphs. For bipartite graphs, Assadi and Behnezhad
[Random'21] improved the approximation to .716 albeit with a computationally
inefficient (i.e., exponential time) protocol.
</p>
<p>In this paper, we study a natural and efficient protocol implied by a
random-order streaming algorithm of Bernstein [ICALP'20] which is based on
edge-degree constrained subgraphs (EDCS) [Bernstein and Stein; ICALP'15]. The
result of Bernstein immediately implies that this protocol achieves an (almost)
$(2/3 \sim .666)$-approximation in the robust communication model. We present a
new analysis, proving that it achieves a much better (almost) $(5/6 \sim
.833)$-approximation. This significantly improves previous approximations both
for general and bipartite graphs. We also prove that our analysis of
Bernstein's protocol is tight.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01080'>Temporal Betweenness Centrality on Shortest Paths Variants</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mehdi Naima, Matthieu Latapy, Cl&#xe9;mence Magnien</p><p>Betweenness centrality has been extensively studied since its introduction in
1977 as a measure of node importance in graphs. This measure has found use in
various applications and has been extended to temporal graphs with time-labeled
edges. Recent research by Bu{\ss} et al. \cite{buss2020algorithmic} and Rymar
et al. \cite{rymar2021towards} has shown that it is possible to compute the
shortest path betweenness centrality of all nodes in a temporal graph in
$O(n^3\,T^2)$ and $O(n^2\,m\,T^2)$ time, respectively, where $T$ is the maximum
time, $m$ is the number of temporal edges, and $n$ is the number of nodes.
These approaches considered paths that do not take into account contributions
from intermediate temporal nodes.
</p>
<p>In this paper, we study the classical temporal betweenness centrality paths
that we call \textit{passive} shortest paths, as well as an alternative variant
that we call \textit{active} shortest paths, which takes into account
contributions from all temporal nodes. We present an improved analysis of the
running time of the classical algorithm for computing betweenness centrality of
all nodes, reducing the time complexity to $O(n\,m\,T+ n^2\,T)$. Furthermore,
for active paths, we show that the betweenness centrality can be computed in
$O(n\,m\,T+ n^2\,T^2)$. We also show that our results hold for different
shortest paths variants.
</p>
<p>Finally, we provide an open-source implementation of our algorithms and
conduct experiments on several real-world datasets. We compare the results of
the two variants on both the node and time dimensions of the temporal graph,
and we also compare the temporal betweenness centrality to its static
counterpart. Our experiments suggest that for the shortest foremost variant
looking only at the first $10\%$ of the temporal interaction is a very good
approximation for the overall top ranked nodes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Naima_M/0/1/0/all/0/1">Mehdi Naima</a>, <a href="http://arxiv.org/find/cs/1/au:+Latapy_M/0/1/0/all/0/1">Matthieu Latapy</a>, <a href="http://arxiv.org/find/cs/1/au:+Magnien_C/0/1/0/all/0/1">Cl&#xe9;mence Magnien</a></p><p>Betweenness centrality has been extensively studied since its introduction in
1977 as a measure of node importance in graphs. This measure has found use in
various applications and has been extended to temporal graphs with time-labeled
edges. Recent research by Bu{\ss} et al. \cite{buss2020algorithmic} and Rymar
et al. \cite{rymar2021towards} has shown that it is possible to compute the
shortest path betweenness centrality of all nodes in a temporal graph in
$O(n^3\,T^2)$ and $O(n^2\,m\,T^2)$ time, respectively, where $T$ is the maximum
time, $m$ is the number of temporal edges, and $n$ is the number of nodes.
These approaches considered paths that do not take into account contributions
from intermediate temporal nodes.
</p>
<p>In this paper, we study the classical temporal betweenness centrality paths
that we call \textit{passive} shortest paths, as well as an alternative variant
that we call \textit{active} shortest paths, which takes into account
contributions from all temporal nodes. We present an improved analysis of the
running time of the classical algorithm for computing betweenness centrality of
all nodes, reducing the time complexity to $O(n\,m\,T+ n^2\,T)$. Furthermore,
for active paths, we show that the betweenness centrality can be computed in
$O(n\,m\,T+ n^2\,T^2)$. We also show that our results hold for different
shortest paths variants.
</p>
<p>Finally, we provide an open-source implementation of our algorithms and
conduct experiments on several real-world datasets. We compare the results of
the two variants on both the node and time dimensions of the temporal graph,
and we also compare the temporal betweenness centrality to its static
counterpart. Our experiments suggest that for the shortest foremost variant
looking only at the first $10\%$ of the temporal interaction is a very good
approximation for the overall top ranked nodes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01087'>An Update-intensive LSM-based R-tree Index</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jaewoo Shin, Jianguo Wang, Walid G. Aref</p><p>Many applications require update-intensive workloads on spatial objects,
e.g., social-network services and shared-riding services that track moving
objects. By buffering insert and delete operations in memory, the Log
Structured Merge Tree (LSM) has been used widely in various systems because of
its ability to handle write-heavy workloads. While the focus on LSM has been on
key-value stores and their optimizations, there is a need to study how to
efficiently support LSM-based {\em secondary} indexes (e.g., location-based
indexes) as modern, heterogeneous data necessitates the use of secondary
indexes. In this paper, we investigate the augmentation of a main-memory-based
memo structure into an LSM secondary index structure to handle update-intensive
workloads efficiently. We conduct this study in the context of an R-tree-based
secondary index. In particular, we introduce the LSM RUM-tree that demonstrates
the use of an Update Memo in an LSM-based R-tree to enhance the performance of
the R-tree's insert, delete, update, and search operations. The LSM RUM-tree
introduces new strategies to control the size of the Update Memo to make sure
it always fits in memory for high performance. The Update Memo is a
light-weight in-memory structure that is suitable for handling update-intensive
workloads without introducing significant overhead. Experimental results using
real spatial data demonstrate that the LSM RUM-tree achieves up to 9.6x speedup
on update operations and up to 2400x speedup on query processing over existing
LSM R-tree implementations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jaewoo Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianguo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Aref_W/0/1/0/all/0/1">Walid G. Aref</a></p><p>Many applications require update-intensive workloads on spatial objects,
e.g., social-network services and shared-riding services that track moving
objects. By buffering insert and delete operations in memory, the Log
Structured Merge Tree (LSM) has been used widely in various systems because of
its ability to handle write-heavy workloads. While the focus on LSM has been on
key-value stores and their optimizations, there is a need to study how to
efficiently support LSM-based {\em secondary} indexes (e.g., location-based
indexes) as modern, heterogeneous data necessitates the use of secondary
indexes. In this paper, we investigate the augmentation of a main-memory-based
memo structure into an LSM secondary index structure to handle update-intensive
workloads efficiently. We conduct this study in the context of an R-tree-based
secondary index. In particular, we introduce the LSM RUM-tree that demonstrates
the use of an Update Memo in an LSM-based R-tree to enhance the performance of
the R-tree's insert, delete, update, and search operations. The LSM RUM-tree
introduces new strategies to control the size of the Update Memo to make sure
it always fits in memory for high performance. The Update Memo is a
light-weight in-memory structure that is suitable for handling update-intensive
workloads without introducing significant overhead. Experimental results using
real spatial data demonstrate that the LSM RUM-tree achieves up to 9.6x speedup
on update operations and up to 2400x speedup on query processing over existing
LSM R-tree implementations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01104'>Complexity Framework for Forbidden Subgraphs III: When Problems are Tractable on Subcubic Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Matthew Johnson, Barnaby Martin, Sukanya Pandey, Dani&#xeb;l Paulusma, Siani Smith, Erik Jan van Leeuwen</p><p>For any finite set $\mathcal{H} = \{H_1,\ldots,H_p\}$ of graphs, a graph is
$\mathcal{H}$-subgraph-free if it does not contain any of $H_1,\ldots,H_p$ as a
subgraph. In recent work, meta-classifications have been studied: these show
that if graph problems satisfy certain prescribed conditions, their complexity
is determined on classes of $\mathcal{H}$-subgraph-free graphs. We continue
this work and focus on problems that have polynomial-time solutions on classes
that have bounded treewidth or maximum degree at most~$3$ and examine their
complexity on $H$-subgraph-free graph classes where $H$ is a connected graph.
With this approach, we obtain comprehensive classifications for (Independent)
Feedback Vertex Set, Connected Vertex Cover, Colouring and Matching Cut. This
resolves a number of open problems.
</p>
<p>We highlight that, to establish that Independent Feedback Vertex Set belongs
to this collection of problems, we first show that it can be solved in
polynomial time on graphs of maximum degree $3$. We demonstrate that, with the
exception of the complete graph on four vertices, each graph in this class has
a minimum size feedback vertex set that is also an independent set.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1">Matthew Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_B/0/1/0/all/0/1">Barnaby Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_S/0/1/0/all/0/1">Sukanya Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Paulusma_D/0/1/0/all/0/1">Dani&#xeb;l Paulusma</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_S/0/1/0/all/0/1">Siani Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Leeuwen_E/0/1/0/all/0/1">Erik Jan van Leeuwen</a></p><p>For any finite set $\mathcal{H} = \{H_1,\ldots,H_p\}$ of graphs, a graph is
$\mathcal{H}$-subgraph-free if it does not contain any of $H_1,\ldots,H_p$ as a
subgraph. In recent work, meta-classifications have been studied: these show
that if graph problems satisfy certain prescribed conditions, their complexity
is determined on classes of $\mathcal{H}$-subgraph-free graphs. We continue
this work and focus on problems that have polynomial-time solutions on classes
that have bounded treewidth or maximum degree at most~$3$ and examine their
complexity on $H$-subgraph-free graph classes where $H$ is a connected graph.
With this approach, we obtain comprehensive classifications for (Independent)
Feedback Vertex Set, Connected Vertex Cover, Colouring and Matching Cut. This
resolves a number of open problems.
</p>
<p>We highlight that, to establish that Independent Feedback Vertex Set belongs
to this collection of problems, we first show that it can be solved in
polynomial time on graphs of maximum degree $3$. We demonstrate that, with the
exception of the complete graph on four vertices, each graph in this class has
a minimum size feedback vertex set that is also an independent set.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01177'>Unbounded Differentially Private Quantile and Maximum Estimation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David Durfee</p><p>In this work we consider the problem of differentially private computation of
quantiles for the data, especially the highest quantiles such as maximum, but
with an unbounded range for the dataset. We show that this can be done
efficiently through a simple invocation of $\texttt{AboveThreshold}$, a
subroutine that is iteratively called in the fundamental Sparse Vector
Technique, even when there is no upper bound on the data. In particular, we
show that this procedure can give more accurate and robust estimates on the
highest quantiles with applications towards clipping that is essential for
differentially private sum and mean estimation. In addition, we show how two
invocations can handle the fully unbounded data setting. Within our study, we
show that an improved analysis of $\texttt{AboveThreshold}$ can improve the
privacy guarantees for the widely used Sparse Vector Technique that is of
independent interest. We give a more general characterization of privacy loss
for $\texttt{AboveThreshold}$ which we immediately apply to our method for
improved privacy guarantees. Our algorithm only requires one $O(n)$ pass
through the data, which can be unsorted, and each subsequent query takes $O(1)$
time. We empirically compare our unbounded algorithm with the state-of-the-art
algorithms in the bounded setting. For inner quantiles, we find that our method
often performs better on non-synthetic datasets. For the maximal quantiles,
which we apply to differentially private sum computation, we find that our
method performs significantly better.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Durfee_D/0/1/0/all/0/1">David Durfee</a></p><p>In this work we consider the problem of differentially private computation of
quantiles for the data, especially the highest quantiles such as maximum, but
with an unbounded range for the dataset. We show that this can be done
efficiently through a simple invocation of $\texttt{AboveThreshold}$, a
subroutine that is iteratively called in the fundamental Sparse Vector
Technique, even when there is no upper bound on the data. In particular, we
show that this procedure can give more accurate and robust estimates on the
highest quantiles with applications towards clipping that is essential for
differentially private sum and mean estimation. In addition, we show how two
invocations can handle the fully unbounded data setting. Within our study, we
show that an improved analysis of $\texttt{AboveThreshold}$ can improve the
privacy guarantees for the widely used Sparse Vector Technique that is of
independent interest. We give a more general characterization of privacy loss
for $\texttt{AboveThreshold}$ which we immediately apply to our method for
improved privacy guarantees. Our algorithm only requires one $O(n)$ pass
through the data, which can be unsorted, and each subsequent query takes $O(1)$
time. We empirically compare our unbounded algorithm with the state-of-the-art
algorithms in the bounded setting. For inner quantiles, we find that our method
often performs better on non-synthetic datasets. For the maximal quantiles,
which we apply to differentially private sum computation, we find that our
method performs significantly better.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01310'>Incremental Maximization via Continuization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yann Disser, Max Klimm, Kevin Schewior, David Weckbecker</p><p>We consider the problem of finding an incremental solution to a
cardinality-constrained maximization problem that not only captures the
solution for a fixed cardinality, but also describes how to gradually grow the
solution as the cardinality bound increases. The goal is to find an incremental
solution that guarantees a good competitive ratio against the optimum solution
for all cardinalities simultaneously. The central challenge is to characterize
maximization problems where this is possible, and to determine the
best-possible competitive ratio that can be attained. A lower bound of $2.18$
and an upper bound of $\varphi + 1 \approx 2.618$ are known on the competitive
ratio for monotone and accountable objectives [Bernstein et al., Math. Prog.,
2022], which capture a wide range of maximization problems. We introduce a
continuization technique and identify an optimal incremental algorithm that
provides strong evidence that $\varphi + 1$ is the best-possible competitive
ratio. Using this continuization, we obtain an improved lower bound of $2.246$
by studying a particular recurrence relation whose characteristic polynomial
has complex roots exactly beyond the lower bound. Based on the optimal
continuous algorithm combined with a scaling approach, we also provide a
$1.772$-competitive randomized algorithm. We complement this by a randomized
lower bound of $1.447$ via Yao's principle.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Disser_Y/0/1/0/all/0/1">Yann Disser</a>, <a href="http://arxiv.org/find/cs/1/au:+Klimm_M/0/1/0/all/0/1">Max Klimm</a>, <a href="http://arxiv.org/find/cs/1/au:+Schewior_K/0/1/0/all/0/1">Kevin Schewior</a>, <a href="http://arxiv.org/find/cs/1/au:+Weckbecker_D/0/1/0/all/0/1">David Weckbecker</a></p><p>We consider the problem of finding an incremental solution to a
cardinality-constrained maximization problem that not only captures the
solution for a fixed cardinality, but also describes how to gradually grow the
solution as the cardinality bound increases. The goal is to find an incremental
solution that guarantees a good competitive ratio against the optimum solution
for all cardinalities simultaneously. The central challenge is to characterize
maximization problems where this is possible, and to determine the
best-possible competitive ratio that can be attained. A lower bound of $2.18$
and an upper bound of $\varphi + 1 \approx 2.618$ are known on the competitive
ratio for monotone and accountable objectives [Bernstein et al., Math. Prog.,
2022], which capture a wide range of maximization problems. We introduce a
continuization technique and identify an optimal incremental algorithm that
provides strong evidence that $\varphi + 1$ is the best-possible competitive
ratio. Using this continuization, we obtain an improved lower bound of $2.246$
by studying a particular recurrence relation whose characteristic polynomial
has complex roots exactly beyond the lower bound. Based on the optimal
continuous algorithm combined with a scaling approach, we also provide a
$1.772$-competitive randomized algorithm. We complement this by a randomized
lower bound of $1.447$ via Yao's principle.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01314'>Two-sets cut-uncut on planar graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Matthias Bentert, P&#xe5;l Gr&#xf8;n&#xe5;s Drange, Fedor V. Fomin, Petr A. Golovach, Tuukka Korhonen</p><p>We study the following Two-Sets Cut-Uncut problem on planar graphs. Therein,
one is given an undirected planar graph $G$ and two sets of vertices $S$ and
$T$. The question is, what is the minimum number of edges to remove from $G$,
such that we separate all of $S$ from all of $T$, while maintaining that every
vertex in $S$, and respectively in $T$, stays in the same connected component.
We show that this problem can be solved in time $2^{|S|+|T|} n^{O(1)}$ with a
one-sided error randomized algorithm. Our algorithm implies a polynomial-time
algorithm for the network diversion problem on planar graphs, which resolves an
open question from the literature. More generally, we show that Two-Sets
Cut-Uncut remains fixed-parameter tractable even when parameterized by the
number $r$ of faces in the plane graph covering the terminals $S \cup T$, by
providing an algorithm of running time $4^{r + O(\sqrt r)} n^{O(1)}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bentert_M/0/1/0/all/0/1">Matthias Bentert</a>, <a href="http://arxiv.org/find/cs/1/au:+Drange_P/0/1/0/all/0/1">P&#xe5;l Gr&#xf8;n&#xe5;s Drange</a>, <a href="http://arxiv.org/find/cs/1/au:+Fomin_F/0/1/0/all/0/1">Fedor V. Fomin</a>, <a href="http://arxiv.org/find/cs/1/au:+Golovach_P/0/1/0/all/0/1">Petr A. Golovach</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_T/0/1/0/all/0/1">Tuukka Korhonen</a></p><p>We study the following Two-Sets Cut-Uncut problem on planar graphs. Therein,
one is given an undirected planar graph $G$ and two sets of vertices $S$ and
$T$. The question is, what is the minimum number of edges to remove from $G$,
such that we separate all of $S$ from all of $T$, while maintaining that every
vertex in $S$, and respectively in $T$, stays in the same connected component.
We show that this problem can be solved in time $2^{|S|+|T|} n^{O(1)}$ with a
one-sided error randomized algorithm. Our algorithm implies a polynomial-time
algorithm for the network diversion problem on planar graphs, which resolves an
open question from the literature. More generally, we show that Two-Sets
Cut-Uncut remains fixed-parameter tractable even when parameterized by the
number $r$ of faces in the plane graph covering the terminals $S \cup T$, by
providing an algorithm of running time $4^{r + O(\sqrt r)} n^{O(1)}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01324'>The Complexity of Distributed Approximation of Packing and Covering Integer Linear Programs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yi-Jun Chang, Zeyong Li</p><p>In this paper, we present a low-diameter decomposition algorithm in the LOCAL
model of distributed computing that succeeds with probability $1 - 1/poly(n)$.
Specifically, we show how to compute an $\left(\epsilon, O\left(\frac{\log
n}{\epsilon}\right)\right)$ low-diameter decomposition in
$O\left(\frac{\log^3(1/\epsilon)\log n}{\epsilon}\right)$ round
</p>
<p>Further developing our techniques, we show new distributed algorithms for
approximating general packing and covering integer linear programs in the LOCAL
model. For packing problems, our algorithm finds an $(1-\epsilon)$-approximate
solution in $O\left(\frac{\log^3 (1/\epsilon) \log n}{\epsilon}\right)$ rounds
with probability $1 - 1/poly(n)$. For covering problems, our algorithm finds an
$(1+\epsilon)$-approximate solution in $O\left(\frac{\left(\log \log n + \log
(1/\epsilon)\right)^3 \log n}{\epsilon}\right)$ rounds with probability $1 -
1/poly(n)$. These results improve upon the previous $O\left(\frac{\log^3
n}{\epsilon}\right)$-round algorithm by Ghaffari, Kuhn, and Maus [STOC 2017]
which is based on network decompositions.
</p>
<p>Our algorithms are near-optimal for many fundamental combinatorial graph
optimization problems in the LOCAL model, such as minimum vertex cover and
minimum dominating set, as their $(1\pm \epsilon)$-approximate solutions
require $\Omega\left(\frac{\log n}{\epsilon}\right)$ rounds to compute.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yi-Jun Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zeyong Li</a></p><p>In this paper, we present a low-diameter decomposition algorithm in the LOCAL
model of distributed computing that succeeds with probability $1 - 1/poly(n)$.
Specifically, we show how to compute an $\left(\epsilon, O\left(\frac{\log
n}{\epsilon}\right)\right)$ low-diameter decomposition in
$O\left(\frac{\log^3(1/\epsilon)\log n}{\epsilon}\right)$ round
</p>
<p>Further developing our techniques, we show new distributed algorithms for
approximating general packing and covering integer linear programs in the LOCAL
model. For packing problems, our algorithm finds an $(1-\epsilon)$-approximate
solution in $O\left(\frac{\log^3 (1/\epsilon) \log n}{\epsilon}\right)$ rounds
with probability $1 - 1/poly(n)$. For covering problems, our algorithm finds an
$(1+\epsilon)$-approximate solution in $O\left(\frac{\left(\log \log n + \log
(1/\epsilon)\right)^3 \log n}{\epsilon}\right)$ rounds with probability $1 -
1/poly(n)$. These results improve upon the previous $O\left(\frac{\log^3
n}{\epsilon}\right)$-round algorithm by Ghaffari, Kuhn, and Maus [STOC 2017]
which is based on network decompositions.
</p>
<p>Our algorithms are near-optimal for many fundamental combinatorial graph
optimization problems in the LOCAL model, such as minimum vertex cover and
minimum dominating set, as their $(1\pm \epsilon)$-approximate solutions
require $\Omega\left(\frac{\log n}{\epsilon}\right)$ rounds to compute.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01358'>Sample-based distance-approximation for subsequence-freeness</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Omer Cohen Sidon, Dana Ron</p><p>In this work, we study the problem of approximating the distance to
subsequence-freeness in the sample-based distribution-free model. For a given
subsequence (word) $w = w_1 \dots w_k$, a sequence (text) $T = t_1 \dots t_n$
is said to contain $w$ if there exist indices $1 \leq i_1 &lt; \dots &lt; i_k \leq n$
such that $t_{i_{j}} = w_j$ for every $1 \leq j \leq k$. Otherwise, $T$ is
$w$-free. Ron and Rosin (ACM TOCT 2022) showed that the number of samples both
necessary and sufficient for one-sided error testing of subsequence-freeness in
the sample-based distribution-free model is $\Theta(k/\epsilon)$. Denoting by
$\Delta(T,w,p)$ the distance of $T$ to $w$-freeness under a distribution $p
:[n]\to [0,1]$, we are interested in obtaining an estimate $\widehat{\Delta}$,
such that $|\widehat{\Delta} - \Delta(T,w,p)| \leq \delta$ with probability at
least $2/3$, for a given distance parameter $\delta$. Our main result is an
algorithm whose sample complexity is $\tilde{O}(k^2/\delta^2)$. We first
present an algorithm that works when the underlying distribution $p$ is
uniform, and then show how it can be modified to work for any (unknown)
distribution $p$. We also show that a quadratic dependence on $1/\delta$ is
necessary.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sidon_O/0/1/0/all/0/1">Omer Cohen Sidon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ron_D/0/1/0/all/0/1">Dana Ron</a></p><p>In this work, we study the problem of approximating the distance to
subsequence-freeness in the sample-based distribution-free model. For a given
subsequence (word) $w = w_1 \dots w_k$, a sequence (text) $T = t_1 \dots t_n$
is said to contain $w$ if there exist indices $1 \leq i_1 &lt; \dots &lt; i_k \leq n$
such that $t_{i_{j}} = w_j$ for every $1 \leq j \leq k$. Otherwise, $T$ is
$w$-free. Ron and Rosin (ACM TOCT 2022) showed that the number of samples both
necessary and sufficient for one-sided error testing of subsequence-freeness in
the sample-based distribution-free model is $\Theta(k/\epsilon)$. Denoting by
$\Delta(T,w,p)$ the distance of $T$ to $w$-freeness under a distribution $p
:[n]\to [0,1]$, we are interested in obtaining an estimate $\widehat{\Delta}$,
such that $|\widehat{\Delta} - \Delta(T,w,p)| \leq \delta$ with probability at
least $2/3$, for a given distance parameter $\delta$. Our main result is an
algorithm whose sample complexity is $\tilde{O}(k^2/\delta^2)$. We first
present an algorithm that works when the underlying distribution $p$ is
uniform, and then show how it can be modified to work for any (unknown)
distribution $p$. We also show that a quadratic dependence on $1/\delta$ is
necessary.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01420'>A Subquadratic Bound for Online Bisection</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marcin Bienkowski, Stefan Schmid</p><p>In the online bisection problem one has to maintain a partition of $n$
elements into two clusters of cardinality $n/2$. During runtime, an online
algorithm is given a sequence of requests, each being a pair of elements: an
inter-cluster request costs one unit while an intra-cluster one is free. The
algorithm may change the partition, paying a unit cost for each element that
changes its cluster.
</p>
<p>This natural problem admits a simple deterministic $O(n^2)$-competitive
algorithm [Avin et al., DISC 2016]. While several significant improvements over
this result have been obtained since the original work, all of them either
limit the generality of the input or assume some form of resource augmentation
(e.g., larger clusters). Moreover, the algorithm of Avin et al. achieves the
best known competitive ratio even if randomization is allowed.
</p>
<p>In this paper, we present a first randomized online algorithm that breaks
this natural barrier and achieves a competitive ratio of $\tilde{O}(n^{27/14})$
without resource augmentation and for an arbitrary sequence of requests.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bienkowski_M/0/1/0/all/0/1">Marcin Bienkowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a></p><p>In the online bisection problem one has to maintain a partition of $n$
elements into two clusters of cardinality $n/2$. During runtime, an online
algorithm is given a sequence of requests, each being a pair of elements: an
inter-cluster request costs one unit while an intra-cluster one is free. The
algorithm may change the partition, paying a unit cost for each element that
changes its cluster.
</p>
<p>This natural problem admits a simple deterministic $O(n^2)$-competitive
algorithm [Avin et al., DISC 2016]. While several significant improvements over
this result have been obtained since the original work, all of them either
limit the generality of the input or assume some form of resource augmentation
(e.g., larger clusters). Moreover, the algorithm of Avin et al. achieves the
best known competitive ratio even if randomization is allowed.
</p>
<p>In this paper, we present a first randomized online algorithm that breaks
this natural barrier and achieves a competitive ratio of $\tilde{O}(n^{27/14})$
without resource augmentation and for an arbitrary sequence of requests.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01471'>FPT Approximations for Capacitated/Fair Clustering with Outliers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rajni Dabas, Neelima Gupta, Tanmay Inamdar</p><p>Clustering problems such as $k$-Median, and $k$-Means, are motivated from
applications such as location planning, unsupervised learning among others. In
such applications, it is important to find the clustering of points that is not
``skewed'' in terms of the number of points, i.e., no cluster should contain
too many points. This is modeled by capacity constraints on the sizes of
clusters. In an orthogonal direction, another important consideration in
clustering is how to handle the presence of outliers in the data. Indeed, these
clustering problems have been generalized in the literature to separately
handle capacity constraints and outliers. To the best of our knowledge, there
has been very little work on studying the approximability of clustering
problems that can simultaneously handle both capacities and outliers.
</p>
<p>We initiate the study of the Capacitated $k$-Median with Outliers (C$k$MO)
problem. Here, we want to cluster all except $m$ outlier points into at most
$k$ clusters, such that (i) the clusters respect the capacity constraints, and
(ii) the cost of clustering, defined as the sum of distances of each
non-outlier point to its assigned cluster-center, is minimized.
</p>
<p>We design the first constant-factor approximation algorithms for C$k$MO. In
particular, our algorithm returns a (3+\epsilon)-approximation for C$k$MO in
general metric spaces, and a (1+\epsilon)-approximation in Euclidean spaces of
constant dimension, that runs in time in time $f(k, m, \epsilon) \cdot
|I_m|^{O(1)}$, where $|I_m|$ denotes the input size. We can also extend these
results to a broader class of problems, including Capacitated
k-Means/k-Facility Location with Outliers, and Size-Balanced Fair Clustering
problems with Outliers. For each of these problems, we obtain an approximation
ratio that matches the best known guarantee of the corresponding outlier-free
problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dabas_R/0/1/0/all/0/1">Rajni Dabas</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1">Neelima Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Inamdar_T/0/1/0/all/0/1">Tanmay Inamdar</a></p><p>Clustering problems such as $k$-Median, and $k$-Means, are motivated from
applications such as location planning, unsupervised learning among others. In
such applications, it is important to find the clustering of points that is not
``skewed'' in terms of the number of points, i.e., no cluster should contain
too many points. This is modeled by capacity constraints on the sizes of
clusters. In an orthogonal direction, another important consideration in
clustering is how to handle the presence of outliers in the data. Indeed, these
clustering problems have been generalized in the literature to separately
handle capacity constraints and outliers. To the best of our knowledge, there
has been very little work on studying the approximability of clustering
problems that can simultaneously handle both capacities and outliers.
</p>
<p>We initiate the study of the Capacitated $k$-Median with Outliers (C$k$MO)
problem. Here, we want to cluster all except $m$ outlier points into at most
$k$ clusters, such that (i) the clusters respect the capacity constraints, and
(ii) the cost of clustering, defined as the sum of distances of each
non-outlier point to its assigned cluster-center, is minimized.
</p>
<p>We design the first constant-factor approximation algorithms for C$k$MO. In
particular, our algorithm returns a (3+\epsilon)-approximation for C$k$MO in
general metric spaces, and a (1+\epsilon)-approximation in Euclidean spaces of
constant dimension, that runs in time in time $f(k, m, \epsilon) \cdot
|I_m|^{O(1)}$, where $|I_m|$ denotes the input size. We can also extend these
results to a broader class of problems, including Capacitated
k-Means/k-Facility Location with Outliers, and Size-Balanced Fair Clustering
problems with Outliers. For each of these problems, we obtain an approximation
ratio that matches the best known guarantee of the corresponding outlier-free
problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01593'>Faster 0-1-Knapsack via Near-Convex Min-Plus-Convolution</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Karl Bringmann, Alejandro Cassis</p><p>We revisit the classic 0-1-Knapsack problem, in which we are given $n$ items
with their weights and profits as well as a weight budget $W$, and the goal is
to find a subset of items of total weight at most $W$ that maximizes the total
profit. We study pseudopolynomial-time algorithms parameterized by the largest
profit of any item $p_{\max}$, and the largest weight of any item $w_{\max}$.
Our main result are algorithms for 0-1-Knapsack running in time
$\tilde{O}(n\,w_\max\,p_\max^{2/3})$ and $\tilde{O}(n\,p_\max\,w_\max^{2/3})$,
improving upon an algorithm in time $O(n\,p_\max\,w_\max)$ by Pisinger [J.
Algorithms '99]. In the regime $p_\max \approx w_\max \approx n$ (and $W
\approx \mathrm{OPT} \approx n^2$) our algorithms are the first to break the
cubic barrier $n^3$.
</p>
<p>To obtain our result, we give an efficient algorithm to compute the min-plus
convolution of near-convex functions. More precisely, we say that a function $f
\colon [n] \mapsto \mathbf{Z}$ is $\Delta$-near convex with $\Delta \geq 1$, if
there is a convex function $\breve{f}$ such that $\breve{f}(i) \leq f(i) \leq
\breve{f}(i) + \Delta$ for every $i$. We design an algorithm computing the
min-plus convolution of two $\Delta$-near convex functions in time
$\tilde{O}(n\Delta)$. This tool can replace the usage of the prediction
technique of Bateni, Hajiaghayi, Seddighin and Stein [STOC '18] in all
applications we are aware of, and we believe it has wider applicability.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bringmann_K/0/1/0/all/0/1">Karl Bringmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Cassis_A/0/1/0/all/0/1">Alejandro Cassis</a></p><p>We revisit the classic 0-1-Knapsack problem, in which we are given $n$ items
with their weights and profits as well as a weight budget $W$, and the goal is
to find a subset of items of total weight at most $W$ that maximizes the total
profit. We study pseudopolynomial-time algorithms parameterized by the largest
profit of any item $p_{\max}$, and the largest weight of any item $w_{\max}$.
Our main result are algorithms for 0-1-Knapsack running in time
$\tilde{O}(n\,w_\max\,p_\max^{2/3})$ and $\tilde{O}(n\,p_\max\,w_\max^{2/3})$,
improving upon an algorithm in time $O(n\,p_\max\,w_\max)$ by Pisinger [J.
Algorithms '99]. In the regime $p_\max \approx w_\max \approx n$ (and $W
\approx \mathrm{OPT} \approx n^2$) our algorithms are the first to break the
cubic barrier $n^3$.
</p>
<p>To obtain our result, we give an efficient algorithm to compute the min-plus
convolution of near-convex functions. More precisely, we say that a function $f
\colon [n] \mapsto \mathbf{Z}$ is $\Delta$-near convex with $\Delta \geq 1$, if
there is a convex function $\breve{f}$ such that $\breve{f}(i) \leq f(i) \leq
\breve{f}(i) + \Delta$ for every $i$. We design an algorithm computing the
min-plus convolution of two $\Delta$-near convex functions in time
$\tilde{O}(n\Delta)$. This tool can replace the usage of the prediction
technique of Bateni, Hajiaghayi, Seddighin and Stein [STOC '18] in all
applications we are aware of, and we believe it has wider applicability.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.01605'>Randomized algorithms for fully online multiprocessor scheduling with testing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mingyang Gong, Zhi-Zhong Chen, Guohui Lin</p><p>We contribute the first randomized algorithm that is an integration of
arbitrarily many deterministic algorithms for the fully online multiprocessor
scheduling with testing problem. When there are only two machines, we show that
with two component algorithms its expected competitive ratio is already
strictly smaller than the best proven deterministic competitive ratio lower
bound. Such algorithmic results are rarely seen in the literature.
</p>
<p>Multiprocessor scheduling is one of the first combinatorial optimization
problems that have received numerous studies. Recently, several research groups
examined its testing variant, in which each job $J_j$ arrives with an upper
bound $u_j$ on the processing time and a testing operation of length $t_j$; one
can choose to execute $J_j$ for $u_j$ time, or to test $J_j$ for $t_j$ time to
obtain the exact processing time $p_j$ followed by immediately executing the
job for $p_j$ time. Our target problem is the fully online multiprocessor
scheduling with testing, in which the jobs arrive in sequence so that the
testing decision needs to be made at the job arrival as well as the designated
machine. We first use Yao's principle to prove lower bounds of 1.6682 and
1.6522 on the expected competitive ratio for any randomized algorithm at the
presence of at least three machines and only two machines, respectively, and
then propose an expected $(\sqrt{\varphi + 3} + 1) (\approx
3.1490)$-competitive randomized algorithm as a non-uniform probability
distribution over arbitrarily many deterministic algorithms, where $\varphi =
\frac{\sqrt{5} + 1}2$ is the Golden ratio. When there are only two machines, we
show that our randomized algorithm based on two deterministic algorithms is
already expected $\frac{3 \varphi + 3 \sqrt{13 - 7\varphi}}4 (\approx
2.1839)$-competitive, while proving a lower bound of 2.2117 on the competitive
ratio for any deterministic algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1">Mingyang Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhi-Zhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guohui Lin</a></p><p>We contribute the first randomized algorithm that is an integration of
arbitrarily many deterministic algorithms for the fully online multiprocessor
scheduling with testing problem. When there are only two machines, we show that
with two component algorithms its expected competitive ratio is already
strictly smaller than the best proven deterministic competitive ratio lower
bound. Such algorithmic results are rarely seen in the literature.
</p>
<p>Multiprocessor scheduling is one of the first combinatorial optimization
problems that have received numerous studies. Recently, several research groups
examined its testing variant, in which each job $J_j$ arrives with an upper
bound $u_j$ on the processing time and a testing operation of length $t_j$; one
can choose to execute $J_j$ for $u_j$ time, or to test $J_j$ for $t_j$ time to
obtain the exact processing time $p_j$ followed by immediately executing the
job for $p_j$ time. Our target problem is the fully online multiprocessor
scheduling with testing, in which the jobs arrive in sequence so that the
testing decision needs to be made at the job arrival as well as the designated
machine. We first use Yao's principle to prove lower bounds of 1.6682 and
1.6522 on the expected competitive ratio for any randomized algorithm at the
presence of at least three machines and only two machines, respectively, and
then propose an expected $(\sqrt{\varphi + 3} + 1) (\approx
3.1490)$-competitive randomized algorithm as a non-uniform probability
distribution over arbitrarily many deterministic algorithms, where $\varphi =
\frac{\sqrt{5} + 1}2$ is the Golden ratio. When there are only two machines, we
show that our randomized algorithm based on two deterministic algorithms is
already expected $\frac{3 \varphi + 3 \sqrt{13 - 7\varphi}}4 (\approx
2.1839)$-competitive, while proving a lower bound of 2.2117 on the competitive
ratio for any deterministic algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-03T00:30:00Z">Wednesday, May 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, May 02
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/05/02/isbell-accepts/'>Isbell Accepts</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Charles Isbell was my colleague at Georgia Tech for a long time. He has some news, which I am glad to convey in the words of the UW Madison Chancellor, Jennifer Mnookin: I am delighted to share the terrific news that Dr. Charles Lee Isbell Jr., the John P. Imlay Jr. Dean of the College [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Charles Isbell was my colleague at Georgia Tech for a long time.  He has some news, which I am glad to convey in the words of the UW Madison Chancellor, Jennifer Mnookin:</p>
<blockquote><p>
I am delighted to share the terrific news that Dr. Charles Lee Isbell Jr., the John P. Imlay Jr. Dean of the College of Computing at Georgia Institute of Technology, has accepted my offer to become our next provost at the University of Wisconsin&#8212;Madison. He will begin his work with us on August 1.
</p></blockquote>
<p><a href="https://rjlipton.wpcomstaging.com/2023/05/02/isbell-accepts/isbellmnookin/" rel="attachment wp-att-21584"><img data-attachment-id="21584" data-permalink="https://rjlipton.wpcomstaging.com/2023/05/02/isbell-accepts/isbellmnookin/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/IsbellMnookin.png?fit=451%2C298&amp;ssl=1" data-orig-size="451,298" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IsbellMnookin" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/IsbellMnookin.png?fit=300%2C198&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/IsbellMnookin.png?fit=451%2C298&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/IsbellMnookin.png?resize=451%2C298&#038;ssl=1" alt="" width="451" height="298" class="aligncenter size-full wp-image-21584" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/IsbellMnookin.png?w=451&amp;ssl=1 451w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/IsbellMnookin.png?resize=300%2C198&amp;ssl=1 300w" sizes="(max-width: 451px) 100vw, 451px" data-recalc-dims="1" /></a></p>
<p>Isbell will be the next provost:</p>
<blockquote><p>
A <a href="https://en.wikipedia.org/wiki/Provost_(education)">provost</a> is a senior academic administrator. At many institutions of higher education, they are the chief academic officer, a role that may be combined with being deputy to the chief executive officer. They may also be the chief executive officer of a university, of a branch campus of a university, or of a college within a university.
</p></blockquote>
<p>See <a href="https://news.wisc.edu/charles-lee-isbell-jr-named-uw-madison-provost">this</a> for more details about the hiring of Isbell.</p>
<header>
<h2>Chart</h2>
</header>
<p>Here is the level under Chancellor of the <a href="https://www.wisc.edu/pdfs/UW-Madison-Leadership-Org-Chart.pdf">org chart for UW Madison</a>, with Charles&#8217;s place in italics:</p>
<p><em>Provost and Vice Chancellor for Academic Affairs </em><br />
Vice Chancellor for Finance and Administration<br />
Vice Chancellor for Legal Affairs<br />
Vice Chancellor for Research and Graduate Education<br />
Vice Chancellor for Student Affairs<br />
Vice Chancellor for University Relations<br />
Chief Diversity Officer and Deputy Vice Chancellor for Diversity and Inclusion<br />
Vice Chancellor for Medical Affairs and Dean, School of Medicine and Public Health</p>
<header>
<h2>Open Problems</h2>
</header>
<p>Congrads Charles&#8212;wonderful you are going to Madison. That is a wonderful place&#8212;I spent many happy days being a visitor there over the years. He is following UW-Madison Provost John Scholz who was named as the new <a href="https://ls.wisc.edu/about/scholz">president</a> of the University of Oregon in Eugene, Oregon.</p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T22:10:14Z">Tuesday, May 02 2023, 22:10</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/05/02/mathematics-of-the-impossible-chapter-10-constant-depth-circuits/'>Mathematics of the impossible, Chapter 10, Constant-depth circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this chapter we further investigate circuits of constant depth, focusing on two pervasive classes, which indeed we have already encountered under different names. Note on notation: I here use “AC” for AltCkt a.k.a.&#160;alternating circuits. I also use AC for the class of functions computable by an AC of depth and size . 10.1 Threshold [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In this chapter we further investigate circuits of constant depth, focusing on two pervasive classes, which indeed we have already encountered under different names.</p>
<p style="text-align:justify">   Note on notation: I here use “AC” for AltCkt a.k.a.&nbsp;alternating circuits. I also use AC for the class of functions <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> computable by an AC of depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{d}" class="latex" />.</p>
<h3 class="sectionHead"><span class="titlemark">10.1   </span> <a id="x1-10700010.1"></a>Threshold circuits</h3>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-107001r1"></a> <b>Definition</b> 10.1.  </span>A <em>threshold circuit, </em>abbreviated TC, is a circuit made of Majority gates (of unbounded fan-in). We also denote by TC the class of functions <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> computable by a TC of depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{d}" class="latex" /> for some constant <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">TCs are one of the frontiers of our knowledge. It isn’t known how to prove impossibility results even for TCs of depth <img src="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3" class="latex" /> and size, say, <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-107002r1"></a> <b>Exercise</b> 10.1.  </span>Prove that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BAC%7D%5Csubseteq+%5Ctext+%7BTC%7D%5Csubseteq+%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BAC%7D%5Csubseteq+%5Ctext+%7BTC%7D%5Csubseteq+%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BAC%7D%5Csubseteq+%5Ctext+%7BTC%7D%5Csubseteq+%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {AC}&#92;subseteq &#92;text {TC}&#92;subseteq &#92;text {NC}^{1}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-107003r2"></a> <b>Exercise</b> 10.2.  </span>A function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7B%2A%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7B%2A%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7B%2A%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;} ^{*}&#92;to &#92;{0,1&#92;} " class="latex" /> is <em>symmetric</em> if it only depends on the weight of the input. Prove that any symmetric function is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TC}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The result <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BPH%7D%5Ctext+%7B%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BMaj%7D%5Ccdot+%5Ctext+%7BMaj%7D%5Ccdot+%5Ctext+%7BP%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BPH%7D%5Ctext+%7B%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BMaj%7D%5Ccdot+%5Ctext+%7BMaj%7D%5Ccdot+%5Ctext+%7BP%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BPH%7D%5Ctext+%7B%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BMaj%7D%5Ccdot+%5Ctext+%7BMaj%7D%5Ccdot+%5Ctext+%7BP%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {PH}&#92;text {&#92;ensuremath {&#92;subseteq &#92;text {Maj}&#92;cdot &#92;text {Maj}&#92;cdot &#92;text {P}}}" class="latex" /> obtained in <a href="#x1-79001r13">6.13<!--tex4ht:ref: xca:power-of-majority --></a> in particular yields the following.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-107004r1"></a>                                                                                                                                                                                     <b>Theorem</b> 10.1.  </span><span class="cite">[<a href="#XAll89">5</a>]</span>Any function <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> in AC has TCs of depth <img src="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=2%5E%7B%5Clog+%5E%7Bc_%7Bf%7D%7Dn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7B%5Clog+%5E%7Bc_%7Bf%7D%7Dn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7B%5Clog+%5E%7Bc_%7Bf%7D%7Dn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{&#92;log ^{c_{f}}n}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-107005r2"></a> <b>Theorem</b> 10.2.  </span> The following problems are in TC:</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-107007x1">Addition of two input integers.</li>
<li class="enumerate" id="x1-107009x2">Iterated addition: Addition of any number of input integers.</li>
<li class="enumerate" id="x1-107011x3">Multiplication of two input integers.</li>
<li class="enumerate" id="x1-107013x4">Iterated multiplication: Multiplication of any number of input integers.</li>
<li class="enumerate" id="x1-107015x5">Division of two integers.</li>
</ol>
<p style="text-align:justify">The proof follows closely that for NC<img src="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^{1}" class="latex" /> in section&nbsp;�<a href="#x1-1020009.1">9.1<!--tex4ht:ref: sec:The-power-of-NC1-arithmetic --></a> (which in turn was based on that for L). Only iterated addition requires a new idea.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-107016r3"></a> <b>Exercise</b> 10.3.  </span>Prove the claim about iterated addition. (Hint: Write input as <img src="https://s0.wp.com/latex.php?latex=n%5Ctimes+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5Ctimes+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Ctimes+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#92;times n" class="latex" /> matrix, one number per row. Divide columns into blocks of <img src="https://s0.wp.com/latex.php?latex=t%3Dc%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%3Dc%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%3Dc%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t=c&#92;log n" class="latex" />.)</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">10.2   </span> <a id="x1-10800010.2"></a>TC vs.&nbsp;NC<img src="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^{1}" class="latex" /></h3>
<p style="text-align:justify">Another great question is whether <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D%3D%5Ctext+%7BNC%7D%5E%7B1%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D%3D%5Ctext+%7BNC%7D%5E%7B1%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D%3D%5Ctext+%7BNC%7D%5E%7B1%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TC}=&#92;text {NC}^{1}." class="latex" /> For any <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />, we can show that functions in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NC}^{1}" class="latex" />, such as Parity, require depth-<img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> TCs of size <img src="https://s0.wp.com/latex.php?latex=%5Cge+n%5E%7B1%2Bc%5Clog+d%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+n%5E%7B1%2Bc%5Clog+d%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+n%5E%7B1%2Bc%5Clog+d%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge n^{1+c&#92;log d}" class="latex" />, and this is tight up to constants.<span class="cite">[<a href="#XImpagliazzoPS97">34</a>]</span> A natural question is whether we can prove stronger bounds for harder functions in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NC}^{1}" class="latex" />. A natural candidate is iterated multiplication of 3&#215;3 matrices. The following result shows that, in fact, stronger bounds would already prove “the whole thing,” that is, <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D%5Cne+%5Ctext+%7BNC%7D%5E%7B1%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D%5Cne+%5Ctext+%7BNC%7D%5E%7B1%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D%5Cne+%5Ctext+%7BNC%7D%5E%7B1%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TC}&#92;ne &#92;text {NC}^{1}." class="latex" /></p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-108001r3"></a> <b>Theorem</b> 10.3.  </span><span class="cite">[<a href="#XAllenderK10">7</a>,&nbsp;<a href="conf/stoc/ChenT19">17</a>]</span> Let <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> be the set of 3&#215;3 matrices of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{2}" class="latex" />. Suppose that the product of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> elements in <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> can be computed by TCs of size <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{k}" class="latex" /> and depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />. Then for any <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon " class="latex" /> the product can also be computed by TCs of size <img src="https://s0.wp.com/latex.php?latex=d%27n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%27n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%27n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#039;n^{1+&#92;epsilon }" class="latex" /> and depth <img src="https://s0.wp.com/latex.php?latex=d%27%3A%3Dcdk%5Clog+1%2F%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%27%3A%3Dcdk%5Clog+1%2F%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%27%3A%3Dcdk%5Clog+1%2F%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#039;:=cdk&#92;log 1/&#92;epsilon " class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The same result applies to any constant-size group <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> – we state it for matrices for concreteness.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Exploiting the associativity of the problem, we compute the product recursively according to a regular tree. The root is defined to have level <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" />. At Level <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> we compute <img src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n_{i}" class="latex" /> products of <img src="https://s0.wp.com/latex.php?latex=%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(n^{1+&#92;epsilon }/n_{i})^{1/k}" class="latex" /> matrices. At the root <img src="https://s0.wp.com/latex.php?latex=%28i%3D0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28i%3D0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28i%3D0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(i=0)" class="latex" /> we have <img src="https://s0.wp.com/latex.php?latex=n_%7B0%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n_%7B0%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n_%7B0%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n_{0}=1" class="latex" />.</p>
<p style="text-align:justify">   By the assumption, each product at Level <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> has TCs of size <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{1+&#92;epsilon }/n_{i}" class="latex" /> and depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />. Hence Level <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> can be computed by TCs of size <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{1+&#92;epsilon }" class="latex" /> and depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />.</p>
<p style="text-align:justify">   We have the recursion</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+n_%7Bi%2B1%7D%3Dn_%7Bi%7D%5Ccdot+%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+n_%7Bi%2B1%7D%3Dn_%7Bi%7D%5Ccdot+%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+n_%7Bi%2B1%7D%3Dn_%7Bi%7D%5Ccdot+%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} n_{i+1}=n_{i}&#92;cdot (n^{1+&#92;epsilon }/n_{i})^{1/k}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   The solution to this recursion is <img src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%281-1%2Fk%29%5E%7Bi%7D%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%281-1%2Fk%29%5E%7Bi%7D%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%281-1%2Fk%29%5E%7Bi%7D%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n_{i}=n^{(1+&#92;epsilon )(1-(1-1/k)^{i})}" class="latex" />, see below.</p>
<p style="text-align:justify">   For <img src="https://s0.wp.com/latex.php?latex=i%3Dck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%3Dck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%3Dck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i=ck&#92;log (1/&#92;epsilon )" class="latex" /> we have <img src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%5Cepsilon+%5E%7B2%7D%29%7D%3En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%5Cepsilon+%5E%7B2%7D%29%7D%3En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%5Cepsilon+%5E%7B2%7D%29%7D%3En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n_{i}=n^{(1+&#92;epsilon )(1-&#92;epsilon ^{2})}&gt;n" class="latex" />; this means that we can compute a product of <img src="https://s0.wp.com/latex.php?latex=%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge n" class="latex" /> matrices, as required.</p>
<p style="text-align:justify">   Hence the total depth of the circuit is <img src="https://s0.wp.com/latex.php?latex=d%5Ccdot+ck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%5Ccdot+ck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%5Ccdot+ck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#92;cdot ck&#92;log (1/&#92;epsilon )" class="latex" />, and the total size is the depth times <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{1+&#92;epsilon }" class="latex" />.</p>
<p style="text-align:justify">   It remains to solve the recurrence. Letting <img src="https://s0.wp.com/latex.php?latex=a_%7Bi%7D%3A%3D%5Clog+_%7Bn%7Dn_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a_%7Bi%7D%3A%3D%5Clog+_%7Bn%7Dn_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a_%7Bi%7D%3A%3D%5Clog+_%7Bn%7Dn_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a_{i}:=&#92;log _{n}n_{i}" class="latex" /> we have the following recurrence for the exponents of <img src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n_{i}" class="latex" />.</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7B0%7D+%26+%3D0%5C%5C+a_%7Bi%2B1%7D+%26+%3Da_%7Bi%7D%281-1%2Fk%29%2B%281%2B%5Cepsilon+%29%2Fk%3Da_%7Bi%7D%5Calpha+%2B%5Cgamma+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7B0%7D+%26+%3D0%5C%5C+a_%7Bi%2B1%7D+%26+%3Da_%7Bi%7D%281-1%2Fk%29%2B%281%2B%5Cepsilon+%29%2Fk%3Da_%7Bi%7D%5Calpha+%2B%5Cgamma+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7B0%7D+%26+%3D0%5C%5C+a_%7Bi%2B1%7D+%26+%3Da_%7Bi%7D%281-1%2Fk%29%2B%281%2B%5Cepsilon+%29%2Fk%3Da_%7Bi%7D%5Calpha+%2B%5Cgamma+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} a_{0} &amp; =0&#92;&#92; a_{i+1} &amp; =a_{i}(1-1/k)+(1+&#92;epsilon )/k=a_{i}&#92;alpha +&#92;gamma &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   where <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3A%3D%281-1%2Fk%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+%3A%3D%281-1%2Fk%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+%3A%3D%281-1%2Fk%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha :=(1-1/k)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3A%3D%281%2B%5Cepsilon+%29%2Fk&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+%3A%3D%281%2B%5Cepsilon+%29%2Fk&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+%3A%3D%281%2B%5Cepsilon+%29%2Fk&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma :=(1+&#92;epsilon )/k" class="latex" />.</p>
<p style="text-align:justify">   This gives</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7Bi%7D%3D%5Cgamma+%5Csum+_%7Bj%5Cle+i%7D%5Calpha+%7B%7D%5E%7Bj%7D%3D%5Cgamma+%5Cfrac+%7B1-%5Calpha+%5E%7Bi%2B1%7D%7D%7B1-%5Calpha+%7D%3D%281%2B%5Cepsilon+%29%281-%5Calpha+%5E%7Bi%2B1%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7Bi%7D%3D%5Cgamma+%5Csum+_%7Bj%5Cle+i%7D%5Calpha+%7B%7D%5E%7Bj%7D%3D%5Cgamma+%5Cfrac+%7B1-%5Calpha+%5E%7Bi%2B1%7D%7D%7B1-%5Calpha+%7D%3D%281%2B%5Cepsilon+%29%281-%5Calpha+%5E%7Bi%2B1%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7Bi%7D%3D%5Cgamma+%5Csum+_%7Bj%5Cle+i%7D%5Calpha+%7B%7D%5E%7Bj%7D%3D%5Cgamma+%5Cfrac+%7B1-%5Calpha+%5E%7Bi%2B1%7D%7D%7B1-%5Calpha+%7D%3D%281%2B%5Cepsilon+%29%281-%5Calpha+%5E%7Bi%2B1%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} a_{i}=&#92;gamma &#92;sum _{j&#92;le i}&#92;alpha {}^{j}=&#92;gamma &#92;frac {1-&#92;alpha ^{i+1}}{1-&#92;alpha }=(1+&#92;epsilon )(1-&#92;alpha ^{i+1}). &#92;end{aligned}" class="latex" /></div>
<p><b>QED</b></p>
</div>
<p style="text-align:justify">   Were the recursion of the form <img src="https://s0.wp.com/latex.php?latex=a%27_%7Bi%2B1%7D%3Da%27_%7Bi%7D%2B%281%2B%5Cepsilon+%29%2Fk&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%27_%7Bi%2B1%7D%3Da%27_%7Bi%7D%2B%281%2B%5Cepsilon+%29%2Fk&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%27_%7Bi%2B1%7D%3Da%27_%7Bi%7D%2B%281%2B%5Cepsilon+%29%2Fk&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a&#039;_{i+1}=a&#039;_{i}+(1+&#92;epsilon )/k" class="latex" /> then obviously <img src="https://s0.wp.com/latex.php?latex=a%27_%7Bck%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%27_%7Bck%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%27_%7Bck%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a&#039;_{ck}" class="latex" /> would already be <img src="https://s0.wp.com/latex.php?latex=%5Cge+1%2B%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+1%2B%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+1%2B%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge 1+&#92;epsilon " class="latex" />. Instead for <img src="https://s0.wp.com/latex.php?latex=a_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a_{i}" class="latex" /> we need to get to <img src="https://s0.wp.com/latex.php?latex=ck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=ck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=ck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="ck&#92;log (1/&#92;epsilon )" class="latex" />.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">10.3   </span> <a id="x1-10900010.3"></a>Impossibility results for AC</h3>
<p style="text-align:justify">In this section we prove impossibility results for ACs, matching several settings of parameters mentioned earlier (cf.&nbsp;section&nbsp;�<a href="#x1-910007.3">7.3<!--tex4ht:ref: sec:Checkpoints --></a>).</p>
<p style="text-align:justify">   To set the stage, let’s prove strong results for depth 2, that is, DNFs.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-109001r4"></a> <b>Exercise</b> 10.4.  </span>Prove that Majority requires DNFs of size <img src="https://s0.wp.com/latex.php?latex=%5Cge+2%5E%7Bcn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+2%5E%7Bcn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+2%5E%7Bcn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge 2^{cn}" class="latex" />. Hint: What if you have a term with less than <img src="https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n " class="latex" /> variables?</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   As discussed, <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bcn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bcn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bcn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{cn}" class="latex" /> bounds even for depth 3 ACs are unknown, and would imply major separations. The following is close to the state-of-the-art for depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-109002r4"></a> <b>Theorem</b> 10.4.  </span><span class="cite">[<a href="#XRaz87">52</a>,&nbsp;<a href="#XSmo87">63</a>]</span>  Let C be an AC of depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> computing Majority on <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> bits. Then <img src="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bd%7Ds%5Cge+c%5Csqrt+%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bd%7Ds%5Cge+c%5Csqrt+%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bd%7Ds%5Cge+c%5Csqrt+%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log ^{d}s&#92;ge c&#92;sqrt {n}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Recall from section&nbsp;�<a href="#x1-910007.3">7.3<!--tex4ht:ref: sec:Checkpoints --></a> that a stronger bound for an explicit function would have major consequences; in particular the function cannot be in L.</p>
<p style="text-align:justify">   The proof uses the simulation of circuits by low-degree polynomials which we saw in Theorem <a href="#x1-77004r5">6.5<!--tex4ht:ref: thm:AC0-Razborov-approx --></a>. Specifically, we use the following corollary:</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-109003r1"></a> <b>Corollary</b> 10.1.  </span>Let <img src="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} " class="latex" /> be an alternating circuit of depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />. Then there is a polynomial <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> over <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{2}" class="latex" /> of degree <img src="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bd%7Ds%2F%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bd%7Ds%2F%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bd%7Ds%2F%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log ^{d}s/&#92;epsilon " class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BP%7D_%7Bx%7D%5BC%28x%29%5Cne+p%28x%29%5D%5Cle+%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BP%7D_%7Bx%7D%5BC%28x%29%5Cne+p%28x%29%5D%5Cle+%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BP%7D_%7Bx%7D%5BC%28x%29%5Cne+p%28x%29%5D%5Cle+%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {P}_{x}[C(x)&#92;ne p(x)]&#92;le &#92;epsilon " class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Theorem <a href="#x1-77004r5">6.5<!--tex4ht:ref: thm:AC0-Razborov-approx --></a> gave a distribution <img src="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="P" class="latex" /> on polynomials s.t.&nbsp;for every <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> we have</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BP%7D%5BC%28x%29%5Cne+P%28x%29%5D%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BP%7D%5BC%28x%29%5Cne+P%28x%29%5D%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BP%7D%5BC%28x%29%5Cne+P%28x%29%5D%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;mathbb {P}_{P}[C(x)&#92;ne P(x)]&#92;le &#92;epsilon . &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   Averaging over <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> we also have</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7Bx%2CP%7D%5BC%28x%29%5Cne+P%28x%29%5D%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7Bx%2CP%7D%5BC%28x%29%5Cne+P%28x%29%5D%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7Bx%2CP%7D%5BC%28x%29%5Cne+P%28x%29%5D%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;mathbb {P}_{x,P}[C(x)&#92;ne P(x)]&#92;le &#92;epsilon . &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   Hence we can fix a particular polynomial <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> s.t.&nbsp;the probability over <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cle+%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le &#92;epsilon " class="latex" />, yielding the result. <b>QED</b></p>
</div>
<p style="text-align:justify">   We then show that Majority cannot be approximated by such low-degree polynomials.</p>
<p style="text-align:justify">   The key result is the following:</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-109004r1"></a> <b>Lemma</b> 10.1.  </span>Every function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^n &#92;to &#92;{0,1&#92;}" class="latex" /> can be written as <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3Dp_%7B0%7D%28x%29%2Bp_%7B1%7D%28x%29%5Ccdot+%5Ctext+%7BMaj%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3Dp_%7B0%7D%28x%29%2Bp_%7B1%7D%28x%29%5Ccdot+%5Ctext+%7BMaj%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3Dp_%7B0%7D%28x%29%2Bp_%7B1%7D%28x%29%5Ccdot+%5Ctext+%7BMaj%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)=p_{0}(x)+p_{1}(x)&#92;cdot &#92;text {Maj}(x)" class="latex" />, for some polynomials <img src="https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_{0}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=p_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_{1}" class="latex" /> of degree <img src="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n/2" class="latex" />. This holds for every odd <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Let <img src="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{0}" class="latex" /> be the set of strings with weight <img src="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n/2" class="latex" />. We claim that for every function <img src="https://s0.wp.com/latex.php?latex=f%3AM_%7B0%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AM_%7B0%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AM_%7B0%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:M_{0}&#92;to &#92;{0,1&#92;} " class="latex" /> there is a polynomial <img src="https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_{0}" class="latex" /> of degree <img src="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n/2" class="latex" /> s.t.&nbsp;<img src="https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_{0}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> agree on <img src="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{0}" class="latex" />.</p>
<p style="text-align:justify">   To verify this, consider the monomials of degree <img src="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n/2" class="latex" />. We claim that (the vectors corresponding to) their truth tables over <img src="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{0}" class="latex" /> are linearly independent. This means that any polynomial gives a different function over <img src="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{0}" class="latex" />, and because the number of polynomials is the same as the number of functions, the result follows. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-109005r5"></a> <b>Exercise</b> 10.5.  </span>Prove the claim in the proof.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Theorem <a href="#x1-109002r4">10.4<!--tex4ht:ref: thm:-Majority-not-in-acz --></a></b>.&nbsp;</span> Apply Corollary <a href="#x1-109003r1">10.1<!--tex4ht:ref: cor:Raz-approx-fixed-p --></a> with <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2F10&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2F10&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2F10&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon =1/10" class="latex" /> to obtain <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />. Let <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> be the set of inputs on which <img src="https://s0.wp.com/latex.php?latex=p%28x%29%3DC%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28x%29%3DC%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28x%29%3DC%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(x)=C(x)" class="latex" />. By Lemma <a href="#x1-109004r1">10.1<!--tex4ht:ref: lem:Maj-versatile --></a>, any function <img src="https://s0.wp.com/latex.php?latex=f%3AS%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AS%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AS%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:S&#92;to &#92;{0,1&#92;} " class="latex" /> ca be written as</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29%3Dp_%7B0%7D%28x%29%2Bp_%7B1%7D%28x%29%5Ccdot+p%28x%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29%3Dp_%7B0%7D%28x%29%2Bp_%7B1%7D%28x%29%5Ccdot+p%28x%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29%3Dp_%7B0%7D%28x%29%2Bp_%7B1%7D%28x%29%5Ccdot+p%28x%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} f(x)=p_{0}(x)+p_{1}(x)&#92;cdot p(x). &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   The right-hand size is a polynomial of degree <img src="https://s0.wp.com/latex.php?latex=%5Cle+d%27%3A%3Dn%2F2%2B%5Clog+%5E%7Bd%7D%28cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+d%27%3A%3Dn%2F2%2B%5Clog+%5E%7Bd%7D%28cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+d%27%3A%3Dn%2F2%2B%5Clog+%5E%7Bd%7D%28cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le d&#039;:=n/2+&#92;log ^{d}(cs)" class="latex" />. The number of such polynomials is the number of possible choices for each monomial of degree <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />, for any <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> up to the degree. This number is</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cprod+_%7Bi%3D0%7D%5E%7Bd%27%7D2%5E%7B%7Bn+%5Cchoose+i%7D%7D%3D2%5E%7B%5Csum+_%7Bi%7D%5E%7Bd%27%7D%7Bn+%5Cchoose+i%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cprod+_%7Bi%3D0%7D%5E%7Bd%27%7D2%5E%7B%7Bn+%5Cchoose+i%7D%7D%3D2%5E%7B%5Csum+_%7Bi%7D%5E%7Bd%27%7D%7Bn+%5Cchoose+i%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cprod+_%7Bi%3D0%7D%5E%7Bd%27%7D2%5E%7B%7Bn+%5Cchoose+i%7D%7D%3D2%5E%7B%5Csum+_%7Bi%7D%5E%7Bd%27%7D%7Bn+%5Cchoose+i%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;prod _{i=0}^{d&#039;}2^{{n &#92;choose i}}=2^{&#92;sum _{i}^{d&#039;}{n &#92;choose i}}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   On the other hand, the number of possible functions <img src="https://s0.wp.com/latex.php?latex=f%3AS%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AS%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AS%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:S&#92;to &#92;{0,1&#92;} " class="latex" /> is</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+2%5E%7B%7CS%7C%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+2%5E%7B%7CS%7C%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+2%5E%7B%7CS%7C%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} 2^{|S|}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   Since a polynomial computes at most one function, taking logs we have</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7CS%7C%5Cle+%5Csum+_%7Bi%7D%5E%7Bd%27%7D%7Bn+%5Cchoose+i%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7CS%7C%5Cle+%5Csum+_%7Bi%7D%5E%7Bd%27%7D%7Bn+%5Cchoose+i%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7CS%7C%5Cle+%5Csum+_%7Bi%7D%5E%7Bd%27%7D%7Bn+%5Cchoose+i%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} |S|&#92;le &#92;sum _{i}^{d&#039;}{n &#92;choose i}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   The right-hand side is at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%281%2F2%2Bc%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%281%2F2%2Bc%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%281%2F2%2Bc%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{n}(1/2+c&#92;log ^{d}(s)/&#92;sqrt {n})" class="latex" />, since each binomial coefficient is <img src="https://s0.wp.com/latex.php?latex=%5Cle+c2%5E%7Bn%7D%2F%5Csqrt+%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c2%5E%7Bn%7D%2F%5Csqrt+%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c2%5E%7Bn%7D%2F%5Csqrt+%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c2^{n}/&#92;sqrt {n}" class="latex" />.</p>
<p style="text-align:justify">   On the other hand, <img src="https://s0.wp.com/latex.php?latex=%7CS%7C%5Cge+0.9%5Ccdot+2%5E%7Bn%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CS%7C%5Cge+0.9%5Ccdot+2%5E%7Bn%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CS%7C%5Cge+0.9%5Ccdot+2%5E%7Bn%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|S|&#92;ge 0.9&#92;cdot 2^{n}." class="latex" /></p>
<p style="text-align:justify">   Combining this we get</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+0.9%5Ccdot+2%5E%7Bn%7D%5Cle+2%5E%7Bn%7D%281%2F2%2Bc%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+0.9%5Ccdot+2%5E%7Bn%7D%5Cle+2%5E%7Bn%7D%281%2F2%2Bc%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+0.9%5Ccdot+2%5E%7Bn%7D%5Cle+2%5E%7Bn%7D%281%2F2%2Bc%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} 0.9&#92;cdot 2^{n}&#92;le 2^{n}(1/2+c&#92;log ^{d}(s)/&#92;sqrt {n}). &#92;end{aligned}" class="latex" /></div>
<p>This implies</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+0.4%5Cle+c%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+0.4%5Cle+c%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+0.4%5Cle+c%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} 0.4&#92;le c&#92;log ^{d}(s)/&#92;sqrt {n}, &#92;end{aligned}" class="latex" /></div>
<p>proving the theorem. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-109006r6"></a> <b>Exercise</b> 10.6.  </span>Explain why Theorem <a href="#x1-109002r4">10.4<!--tex4ht:ref: thm:-Majority-not-in-acz --></a> holds even if the circuits have Parity gates (in addition to Or and And gates).</p>
<p style="text-align:justify">
</div>
<div class="thebibliography">
<p class="bibitem"><span class="biblabel">   [1]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/focs/AbboudBW15"></a>Amir Abboud, Arturs Backurs, and Virginia&nbsp;Vassilevska Williams. Tight hardness      results for LCS and other sequence similarity measures.  In Venkatesan Guruswami,      editor, IEEE 56th Annual Symposium on Foundations of Computer Science, FOCS      2015, Berkeley, CA, USA, 17-20 October, 2015, pages 59–78. IEEE Computer Society,      2015.</p>
<p class="bibitem"><span class="biblabel">   [2]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAdleman78"></a>Leonard  Adleman.   Two  theorems  on  random  polynomial  time.   In  19th IEEE      Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 75–83. 1978.</p>
<p class="bibitem"><span class="biblabel">   [3]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAjt83"></a>Mikl�s Ajtai.  <img src="https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Sigma &#92;sp {1}&#92;sb {1}" class="latex" />-formulae on finite structures.  Annals of Pure and Applied Logic,      24(1):1–48, 1983.</p>
<p class="bibitem"><span class="biblabel">   [4]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAjtai05"></a>Mikl�s Ajtai. A non-linear time lower bound for boolean branching programs. Theory      of Computing, 1(1):149–176, 2005.</p>
<p class="bibitem"><span class="biblabel">   [5]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAll89"></a>Eric  Allender.   A  note  on  the  power  of  threshold  circuits.   In  30th Symposium      on Foundations of Computer Science, pages 580–584, Research Triangle Park, North      Carolina, 30 October–1 November 1989. IEEE.</p>
<p class="bibitem"><span class="biblabel">   [6]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAllender01"></a>Eric Allender. The division breakthroughs. Bulletin of the EATCS, 74:61–77, 2001.</p>
<p class="bibitem"><span class="biblabel">   [7]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAllenderK10"></a>Eric  Allender  and  Michal  Koucký.     Amplifying  lower  bounds  by  means  of      self-reducibility. J.&nbsp;of the ACM, 57(3), 2010.</p>
<p class="bibitem"><span class="biblabel">   [8]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAGHP92"></a>Noga Alon, Oded Goldreich, Johan H�stad, and Ren� Peralta. Simple constructions      of  almost  <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-wise  independent  random  variables.   Random  Structures  &amp;  Algorithms,      3(3):289–304, 1992.</p>
<p class="bibitem"><span class="biblabel">   [9]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/AngluinV79"></a>Dana Angluin and Leslie&nbsp;G. Valiant. Fast probabilistic algorithms for hamiltonian      circuits and matchings. J. Comput. Syst. Sci., 18(2):155–193, 1979.</p>
<p class="bibitem"><span class="biblabel">  [10]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAroraLuMoSuSz98"></a>Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy.      Proof  verification  and  the  hardness  of  approximation  problems.    J.&nbsp;of  the  ACM,      45(3):501–555, May 1998.</p>
<p class="bibitem"><span class="biblabel">  [11]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/BackursI18"></a>Arturs Backurs and Piotr Indyk.  Edit distance cannot be computed in strongly      subquadratic time (unless SETH is false). SIAM J. Comput., 47(3):1087–1097, 2018.</p>
<p class="bibitem"><span class="biblabel">  [12]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBatcher68"></a>Kenneth&nbsp;E. Batcher.  Sorting networks and their applications.  In AFIPS Spring      Joint Computing Conference, volume&nbsp;32, pages 307–314, 1968.</p>
<p class="bibitem"><span class="biblabel">  [13]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBeameCH86"></a>Paul  Beame,  Stephen&nbsp;A.  Cook,  and  H.&nbsp;James  Hoover.   Log  depth  circuits  for      division and related problems. SIAM J. Comput., 15(4):994–1003, 1986.</p>
<p class="bibitem"><span class="biblabel">  [14]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBSSV03"></a>Paul Beame, Michael Saks, Xiaodong Sun, and Erik Vee.   Time-space trade-off      lower  bounds  for  randomized  computation  of  decision  problems.   J.&nbsp;of  the  ACM,      50(2):154–195, 2003.</p>
<p class="bibitem"><span class="biblabel">  [15]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBen-OrC92"></a>Michael Ben-Or and Richard Cleve. Computing algebraic formulas using a constant      number of registers. SIAM J.&nbsp;on Computing, 21(1):54–58, 1992.</p>
<p class="bibitem"><span class="biblabel">  [16]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/cc/BussW15"></a>Samuel&nbsp;R.  Buss  and  Ryan  Williams.   Limits  on  alternation  trading  proofs  for      time-space lower bounds. Comput. Complex., 24(3):533–600, 2015.</p>
<p class="bibitem"><span class="biblabel">  [17]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/stoc/ChenT19"></a>Lijie Chen and Roei Tell. Bootstrapping results for threshold circuits &#8220;just beyond&#8221;      known lower bounds.  In Moses Charikar and Edith Cohen, editors, Proceedings of the      51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, Phoenix,      AZ, USA, June 23-26, 2019, pages 34–41. ACM, 2019.</p>
<p class="bibitem"><span class="biblabel">  [18]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCleve91"></a>Richard  Cleve.    Towards  optimal  simulations  of  formulas  by  bounded-width                                                                                                                                                                                          programs. Computational Complexity, 1:91–105, 1991.</p>
<p class="bibitem"><span class="biblabel">  [19]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCook73"></a>Stephen&nbsp;A. Cook. A hierarchy for nondeterministic time complexity. J.&nbsp;of Computer      and System Sciences, 7(4):343–353, 1973.</p>
<p class="bibitem"><span class="biblabel">  [20]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Csanky76"></a>L.&nbsp;Csanky.     Fast  parallel  matrix  inversion  algorithms.     SIAM  J.  Comput.,      5(4):618–623, 1976.</p>
<p class="bibitem"><span class="biblabel">  [21]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/Fortnow00"></a>Lance  Fortnow.   Time-space  tradeoffs  for  satisfiability.   J.  Comput.  Syst.  Sci.,      60(2):337–353, 2000.</p>
<p class="bibitem"><span class="biblabel">  [22]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jct/FraenkelL81"></a>Aviezri&nbsp;S. Fraenkel and David Lichtenstein. Computing a perfect strategy for n x n      chess requires time exponential in n. J. Comb. Theory, Ser. A, 31(2):199–214, 1981.</p>
<p class="bibitem"><span class="biblabel">  [23]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XFredmanS89"></a>Michael&nbsp;L. Fredman and Michael&nbsp;E. Saks.  The cell probe complexity of dynamic      data structures. In ACM Symp.&nbsp;on the Theory of Computing (STOC), pages 345–354,      1989.</p>
<p class="bibitem"><span class="biblabel">  [24]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGajentaanO95"></a>Anka Gajentaan and Mark&nbsp;H. Overmars. On a class of <img src="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="{O}(n^2)" class="latex" /> problems in computational      geometry. Comput. Geom., 5:165–185, 1995.</p>
<p class="bibitem"><span class="biblabel">  [25]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGareyJ79"></a>M.&nbsp;R. Garey and David&nbsp;S. Johnson. Computers and Intractability: A Guide to the      Theory of NP-Completeness. W. H. Freeman, 1979.</p>
<p class="bibitem"><span class="biblabel">  [26]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR1549939"></a>K.&nbsp;G�del.   �ber  formal  unentscheidbare  s�tze  der  Principia  Mathematica  und      verwandter systeme I. Monatsh. Math. Phys., 38, 1931.</p>
<p class="bibitem"><span class="biblabel">  [27]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGoldreich08Complexity"></a>Oded Goldreich. Computational Complexity: A Conceptual Perspective. Cambridge      University Press, 2008.</p>
<p class="bibitem"><span class="biblabel">  [28]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGreenlawHR-Limits"></a>Raymond  Greenlaw,  H.&nbsp;James  Hoover,  and  Walter  Ruzzo.   Limits  to  Parallel      Computation: P-Completeness Theory. 02 2001.</p>
<p class="bibitem"><span class="biblabel">  [29]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="X10.4007/annals.2021.193.2.4"></a>David Harvey and Joris van&nbsp;der Hoeven. Integer multiplication in time <img src="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(n&#92;mathrm {log}&#92;, n)" class="latex" />. Annals of      Mathematics, 193(2):563 – 617, 2021.</p>
<p class="bibitem"><span class="biblabel">  [30]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F.&nbsp;C. Hennie.  One-tape, off-line turing machine computations.  Information and      Control, 8(6):553–578, 1965.</p>
<p class="bibitem"><span class="biblabel">  [31]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XHennieS66"></a>Fred  Hennie  and  Richard  Stearns.    Two-tape  simulation  of  multitape  turing      machines. J.&nbsp;of the ACM, 13:533–546, October 1966.</p>
<p class="bibitem"><span class="biblabel">  [32]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jacm/HopcroftPV77"></a>John&nbsp;E. Hopcroft, Wolfgang&nbsp;J. Paul, and Leslie&nbsp;G. Valiant. On time versus space.      J. ACM, 24(2):332–337, 1977.</p>
<p class="bibitem"><span class="biblabel">  [33]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIP99"></a>Russell Impagliazzo and Ramamohan Paturi.   The complexity of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-sat.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 237–, 1999.</p>
<p class="bibitem"><span class="biblabel">  [34]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImpagliazzoPS97"></a>Russell Impagliazzo, Ramamohan Paturi, and Michael&nbsp;E. Saks. Size-depth tradeoffs      for threshold circuits. SIAM J. Comput., 26(3):693–707, 1997.</p>
<p class="bibitem"><span class="biblabel">  [35]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIPZ01"></a>Russell Impagliazzo, Ramamohan Paturi, and Francis Zane.  Which problems have      strongly exponential complexity? J. Computer &amp; Systems Sciences, 63(4):512–530, Dec      2001.</p>
<p class="bibitem"><span class="biblabel">  [36]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImW97"></a>Russell  Impagliazzo  and  Avi  Wigderson.    <img src="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathit {P} = &#92;mathit {BPP}" class="latex" />  if  <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E" class="latex" />  requires  exponential  circuits:      Derandomizing the XOR lemma.  In 29th ACM Symp.&nbsp;on the Theory of Computing      (STOC), pages 220–229. ACM, 1997.</p>
<p class="bibitem"><span class="biblabel">  [37]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKarpLi82"></a>Richard&nbsp;M.  Karp  and  Richard&nbsp;J.  Lipton.    Turing  machines  that  take  advice.      L’Enseignement Math�matique. Revue Internationale. IIe S�rie, 28(3-4):191–209, 1982.</p>
<p class="bibitem"><span class="biblabel">  [38]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi.  On the structure of one-tape nondeterministic turing machine      time hierarchy. Theor. Comput. Sci., 40:175–193, 1985.</p>
<p class="bibitem"><span class="biblabel">  [39]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/LarsenWY20"></a>Kasper&nbsp;Green Larsen, Omri Weinstein, and Huacheng Yu. Crossing the logarithmic      barrier for dynamic boolean data structure lower bounds.  SIAM J. Comput., 49(5),      2020.</p>
<p class="bibitem"><span class="biblabel">  [40]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLevin73"></a>Leonid&nbsp;A.  Levin.    Universal  sequential  search  problems.    Problemy  Peredachi      Informatsii, 9(3):115–116, 1973.</p>
<p class="bibitem"><span class="biblabel">  [41]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLundFoKaNi92"></a>Carsten Lund, Lance Fortnow, Howard Karloff, and Noam Nisan. Algebraic methods      for interactive proof systems. J.&nbsp;of the ACM, 39(4):859–868, October 1992.</p>
<p class="bibitem"><span class="biblabel">  [42]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLupanov58"></a>O.&nbsp;B. Lupanov. A method of circuit synthesis. Izv. VUZ Radiofiz., 1:120–140, 1958.</p>
<p class="bibitem"><span class="biblabel">  [43]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMaS87"></a>Wolfgang Maass and Amir Schorr. Speed-up of Turing machines with one work tape      and a two-way input tape. SIAM J.&nbsp;on Computing, 16(1):195–202, 1987.</p>
<p class="bibitem"><span class="biblabel">  [44]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBarrington89"></a>David&nbsp;A.  Mix  Barrington.   Bounded-width  polynomial-size  branching  programs      recognize  exactly  those  languages  in  NC<img src="https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^1" class="latex" />.    J.&nbsp;of  Computer  and  System  Sciences,      38(1):150–164, 1989.</p>
<p class="bibitem"><span class="biblabel">  [45]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNaN93"></a>Joseph Naor and Moni Naor.  Small-bias probability spaces: efficient constructions      and applications. SIAM J.&nbsp;on Computing, 22(4):838–856, 1993.</p>
<p class="bibitem"><span class="biblabel">  [46]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNechiporuk66"></a>E.&nbsp;I. Nechiporuk. A boolean function. Soviet Mathematics-Doklady, 169(4):765–766,      1966.</p>
<p class="bibitem"><span class="biblabel">  [47]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNep70"></a>Valery&nbsp;A. Nepomnjaščiĭ. Rudimentary predicates and Turing calculations. Soviet      Mathematics-Doklady, 11(6):1462–1465, 1970.</p>
<p class="bibitem"><span class="biblabel">  [48]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaNEU-ram2sat-neu-author"></a>NEU. From RAM to SAT. Available at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2012.</p>
<p class="bibitem"><span class="biblabel">                                                                                                                                                                                      [49]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/PapadimitriouY91"></a>Christos&nbsp;H. Papadimitriou and Mihalis Yannakakis. Optimization, approximation,      and complexity classes. J. Comput. Syst. Sci., 43(3):425–440, 1991.</p>
<p class="bibitem"><span class="biblabel">  [50]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPPST83"></a>Wolfgang&nbsp;J. Paul, Nicholas Pippenger, Endre Szemer�di, and William&nbsp;T. Trotter.      On determinism versus non-determinism and related problems (preliminary version). In      IEEE Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 429–438, 1983.</p>
<p class="bibitem"><span class="biblabel">  [51]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPippengerF79"></a>Nicholas Pippenger and Michael&nbsp;J. Fischer. Relations among complexity measures.      J.&nbsp;of the ACM, 26(2):361–381, 1979.</p>
<p class="bibitem"><span class="biblabel">  [52]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XRaz87"></a>Alexander Razborov. Lower bounds on the dimension of schemes of bounded depth      in a complete basis containing the logical addition function.  Akademiya Nauk SSSR.      Matematicheskie Zametki, 41(4):598–607, 1987.  English translation in Mathematical      Notes of the Academy of Sci. of the USSR, 41(4):333-338, 1987.</p>
<p class="bibitem"><span class="biblabel">  [53]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XReingold08"></a>Omer Reingold. Undirected connectivity in log-space. J.&nbsp;of the ACM, 55(4), 2008.</p>
<p class="bibitem"><span class="biblabel">  [54]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Robson84"></a>J.&nbsp;M.  Robson.    N  by  N  checkers  is  exptime  complete.    SIAM  J.  Comput.,      13(2):252–267, 1984.</p>
<p class="bibitem"><span class="biblabel">  [55]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/coco/Santhanam01"></a>Rahul Santhanam.   On separators, segregators and time versus space.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 286–294, 2001.</p>
<p class="bibitem"><span class="biblabel">  [56]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSAVITCH1970177"></a>Walter&nbsp;J. Savitch.  Relationships between nondeterministic and deterministic tape      complexities. Journal of Computer and System Sciences, 4(2):177–192, 1970.</p>
<p class="bibitem"><span class="biblabel">  [57]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Schonhage80"></a>Arnold Sch�nhage. Storage modification machines. SIAM J. Comput., 9(3):490–508,      1980.</p>
<p class="bibitem"><span class="biblabel">  [58]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XShamir92"></a>Adi Shamir. IP = PSPACE. J.&nbsp;of the ACM, 39(4):869–877, October 1992.</p>
<p class="bibitem"><span class="biblabel">  [59]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR29860"></a>Claude&nbsp;E. Shannon. The synthesis of two-terminal switching circuits. Bell System                                                                                                                                                                                          Tech. J., 28:59–98, 1949.</p>
<p class="bibitem"><span class="biblabel">  [60]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSho90"></a>Victor Shoup. New algorithms for finding irreducible polynomials over finite fields.      Mathematics of Computation, 54(189):435–447, 1990.</p>
<p class="bibitem"><span class="biblabel">  [61]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSiegel04"></a>Alan Siegel. On universal classes of extremely random constant-time hash functions.      SIAM J.&nbsp;on Computing, 33(3):505–543, 2004.</p>
<p class="bibitem"><span class="biblabel">  [62]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSip83b"></a>Michael Sipser. A complexity theoretic approach to randomness. In ACM Symp.&nbsp;on      the Theory of Computing (STOC), pages 330–335, 1983.</p>
<p class="bibitem"><span class="biblabel">  [63]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSmo87"></a>Roman Smolensky.  Algebraic methods in the theory of lower bounds for Boolean      circuit complexity.  In 19th ACM Symp.&nbsp;on the Theory of Computing (STOC), pages      77–82. ACM, 1987.</p>
<p class="bibitem"><span class="biblabel">  [64]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert&nbsp;R. Meyer.  Cosmological lower bound on the circuit      complexity of a small problem in logic. J. ACM, 49(6):753–784, 2002.</p>
<p class="bibitem"><span class="biblabel">  [65]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XToda91"></a>Seinosuke Toda.   PP is as hard as the polynomial-time hierarchy.   SIAM J.&nbsp;on      Computing, 20(5):865–877, 1991.</p>
<p class="bibitem"><span class="biblabel">  [66]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/x/Turing37"></a>Alan&nbsp;M.   Turing.      On   computable   numbers,   with   an   application   to   the      entscheidungsproblem. Proc. London Math. Soc., s2-42(1):230–265, 1937.</p>
<p class="bibitem"><span class="biblabel">  [67]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XVal77"></a>Leslie&nbsp;G.  Valiant.   Graph-theoretic  arguments  in  low-level  complexity.   In  6th      Symposium on Mathematical Foundations of Computer Science, volume&nbsp;53 of Lecture      Notes in Computer Science, pages 162–176. Springer, 1977.</p>
<p class="bibitem"><span class="biblabel">  [68]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/ValiantV86"></a>Leslie&nbsp;G. Valiant and Vijay&nbsp;V. Vazirani. NP is as easy as detecting unique solutions.      Theor. Comput. Sci., 47(3):85–93, 1986.</p>
<p class="bibitem"><span class="biblabel">  [69]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMelkebeek06"></a>Dieter  van  Melkebeek.   A  survey  of  lower  bounds  for  satisfiability  and  related                                                                                                                                                                                          problems. Foundations and Trends in Theoretical Computer Science, 2(3):197–303, 2006.</p>
<p class="bibitem"><span class="biblabel">  [70]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/MelkebeekR05"></a>Dieter van Melkebeek and Ran Raz.  A time lower bound for satisfiability.  Theor.      Comput. Sci., 348(2-3):311–320, 2005.</p>
<p class="bibitem"><span class="biblabel">  [71]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/Vinodchandran05"></a>N.&nbsp;V. Vinodchandran.  A note on the circuit complexity of PP.  Theor. Comput.      Sci., 347(1-2):415–418, 2005.</p>
<p class="bibitem"><span class="biblabel">  [72]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaBPvsE"></a>Emanuele Viola.  On approximate majority and probabilistic time.  Computational      Complexity, 18(3):337–375, 2009.</p>
<p class="bibitem"><span class="biblabel">  [73]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-FTTCS09"></a>Emanuele Viola. On the power of small-depth computation. Foundations and Trends      in Theoretical Computer Science, 5(1):1–72, 2009.</p>
<p class="bibitem"><span class="biblabel">  [74]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViola-xxx"></a>Emanuele Viola.  Reducing 3XOR to listing triangles, an exposition.  Available at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2011.</p>
<p class="bibitem"><span class="biblabel">  [75]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-datastructurelb-implies-cclb"></a>Emanuele Viola.  Lower bounds for data structures with space close to maximum      imply  circuit  lower  bounds.    Theory  of  Computing,  15:1–9,  2019.    Available  at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>.</p>
<p class="bibitem"><span class="biblabel">  [76]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-tm"></a>Emanuele  Viola.   Pseudorandom  bits  and  lower  bounds  for  randomized  turing      machines. Theory of Computing, 18(10):1–12, 2022.</p>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T21:37:15Z">Tuesday, May 02 2023, 21:37</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
