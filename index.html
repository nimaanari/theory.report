<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2022-10-27T13:12:41Z">Thursday, October 27 2022, 13:12</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, October 27
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/10/the-media-coverage-of-matrix-result-is.html'>The Media Coverage of the Matrix result is Terrible (though not worse than usual)</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;BILL: A computer program (or an AI or an ML or whatever) found a BETTER way to do matrix mult! Its in the same spirit as Strassen. I've always wondered if Strassen was practical&nbsp; since it is simple, and computers have come a long way since 1969, though I suspect not (I WAS WRONG ABOUT THAT). I'll blog about and ask if Strassen will ever be used/practical&nbsp; &nbsp;(I did that post&nbsp;here).</p><p>READERS: Uh, Bill,&nbsp; (1) Strassen IS used and practical and (2) the new algorithm only works in&nbsp; GF(2). (Lance did a post about the new algorithm where he makes this explicit&nbsp;here.) Some readers claimed it was GF(2^k) and some that it was fields if char 2. In any case NO it is not a general algorithm.</p><p>BILL: There is good news and what others might consider bad news but I do not.</p><p>GOOD NEWS: I learned that Strassen IS practical and used, which I did not know.&nbsp;</p><p>GOOD NEWS: I learned that I was WRONG about the new algorithm since I just assumed it worked in general, and updated the post so others would not be deceived.&nbsp;</p><p>BAD NEWS: Darling asked if I was embarrassed to be wrong. If I am embarrassed that easily I would have quit blogging in 2009.&nbsp;</p><p>DARLING: So Bill, how did you get it so wrong?</p><p>BILL: Well obviously my bad for not doing my due diligence. But that's not what's interesting. What's interesting is that if you read the articles about it for the popular press you would have NO IDEA that it only works for mod 2. Its like reading that quantum computing will solve world hunger.</p><p>DARLING: It won't?</p><p>BILL: No it won't.&nbsp;</p><p>DARLING: I was being sarcastic.&nbsp;</p><p>BILL: Anyway, the coverage pushed two points</p><p>a) IMPRESSIVE that a computer could FIND these things that humans could not. This is TRUE (gee, how do I know that? There is some statement about this. BLANK's Law or something, that people are disgusted when they read a newspaper article on something they know about and find the mistakes, but then assume that the other articles are fine.)&nbsp;</p><p>b) The algorithm is practical! They did not quite say that but it was implied. And certainly there was NO mention of it only working in GF(2). And I was fooled into thinking that it might be competitive with Strassen.&nbsp;</p><p>READERS (of this blog entry, I predict) Uh, Bill, the popular press getting science news wrong and saying its more practical than it is probably predates the Bible. I can imagine&nbsp; the Cairo Times in 2000BC writing&nbsp;`Scientists discover that in any right triangle with sides a,b,c&nbsp; a^2+b^2=c^2 and this will enable us to build food silos and cure Hunger. In reality they knew that the 3,4,5 triangle was a right triangle, were no where near a proof of a general theorem, and I doubt it would have helped cure hunger.&nbsp;</p><p>BILL: This time the news was REALLY CLOSE to what I do (if&nbsp; R(5) is found by a computer and the media claims its practical I'll either have a very angry blog or repost my April Fools' day article on Ramsey Theory's application to&nbsp; History) AND I posted incorrectly about it. So, to quote many a bad movie</p><p>THIS TIME ITS PERSONAL!</p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;BILL: A computer program (or an AI or an ML or whatever) found a BETTER way to do matrix mult! Its in the same spirit as Strassen. I've always wondered if Strassen was practical&nbsp; since it is simple, and computers have come a long way since 1969, though I suspect not (I WAS WRONG ABOUT THAT). I'll blog about and ask if Strassen will ever be used/practical&nbsp; &nbsp;(I did that post&nbsp;<a href="https://blog.computationalcomplexity.org/2022/10/will-strassens-matrix-mult-alg-ever-be.html">here</a>).</p><p>READERS: Uh, Bill,&nbsp; (1) Strassen IS used and practical and (2) the new algorithm only works in&nbsp; GF(2). (Lance did a post about the new algorithm where he makes this explicit&nbsp;<a href="https://blog.computationalcomplexity.org/2022/10/alpha-tensor.html">here</a>.) Some readers claimed it was GF(2^k) and some that it was fields if char 2. In any case NO it is not a general algorithm.</p><p>BILL: There is good news and what others might consider bad news but I do not.</p><p>GOOD NEWS: I learned that Strassen IS practical and used, which I did not know.&nbsp;</p><p>GOOD NEWS: I learned that I was WRONG about the new algorithm since I just assumed it worked in general, and updated the post so others would not be deceived.&nbsp;</p><p>BAD NEWS: Darling asked if I was embarrassed to be wrong. If I am embarrassed that easily I would have quit blogging in 2009.&nbsp;</p><p>DARLING: So Bill, how did you get it so wrong?</p><p>BILL: Well obviously my bad for not doing my due diligence. But that's not what's interesting. What's interesting is that if you read the articles about it for the popular press you would have NO IDEA that it only works for mod 2. Its like reading that quantum computing will solve world hunger.</p><p>DARLING: It won't?</p><p>BILL: No it won't.&nbsp;</p><p>DARLING: I was being sarcastic.&nbsp;</p><p>BILL: Anyway, the coverage pushed two points</p><p>a) IMPRESSIVE that a computer could FIND these things that humans could not. This is TRUE (gee, how do I know that? There is some statement about this. BLANK's Law or something, that people are disgusted when they read a newspaper article on something they know about and find the mistakes, but then assume that the other articles are fine.)&nbsp;</p><p>b) The algorithm is practical! They did not quite say that but it was implied. And certainly there was NO mention of it only working in GF(2). And I was fooled into thinking that it might be competitive with Strassen.&nbsp;</p><p>READERS (of this blog entry, I predict) Uh, Bill, the popular press getting science news wrong and saying its more practical than it is probably predates the Bible. I can imagine&nbsp; the Cairo Times in 2000BC writing&nbsp;<i>`Scientists discover that in any right triangle with sides a,b,c&nbsp; a^2+b^2=c^2 and this will</i> <i>enable us to build food silos and cure Hunger</i>. In reality they knew that the 3,4,5 triangle was a right triangle, were no where near a proof of a general theorem, and I doubt it would have helped cure hunger.&nbsp;</p><p>BILL: This time the news was REALLY CLOSE to what I do (if&nbsp; R(5) is found by a computer and the media claims its practical I'll either have a very angry blog or repost my April Fools' day article on Ramsey Theory's application to&nbsp; History) AND I posted incorrectly about it. So, to quote many a bad movie</p><p><b>THIS TIME ITS PERSONAL!</b></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T11:46:00Z">Thursday, October 27 2022, 11:46</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14259'>Net Separation-Oriented Printed Circuit Board Placement via Margin Maximization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chung-Kuan Cheng, Chia-Tung Ho, Chester Holtz</p><p>Packaging has become a crucial process due to the paradigm shift of More than
Moore. Addressing manufacturing and yield issues is a significant challenge for
modern layout algorithms.
</p>
<p>We propose to use printed circuit board (PCB) placement as a benchmark for
the packaging problem. A maximum-margin formulation is devised to improve the
separation between nets. Our framework includes seed layout proposals, a
coordinate descent-based procedure to optimize routability, and a mixed-integer
linear programming method to legalize the layout. We perform an extensive study
with 14 PCB designs and an open-source router. We show that the placements
produced by NS-place improve routed wirelength by up to 25\%, reduce the number
of vias by up to 50\%, and reduce the number of DRVs by 79\% compared to manual
and wirelength-minimal placements.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Chung-Kuan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_C/0/1/0/all/0/1">Chia-Tung Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Holtz_C/0/1/0/all/0/1">Chester Holtz</a></p><p>Packaging has become a crucial process due to the paradigm shift of More than
Moore. Addressing manufacturing and yield issues is a significant challenge for
modern layout algorithms.
</p>
<p>We propose to use printed circuit board (PCB) placement as a benchmark for
the packaging problem. A maximum-margin formulation is devised to improve the
separation between nets. Our framework includes seed layout proposals, a
coordinate descent-based procedure to optimize routability, and a mixed-integer
linear programming method to legalize the layout. We perform an extensive study
with 14 PCB designs and an open-source router. We show that the placements
produced by NS-place improve routed wirelength by up to 25\%, reduce the number
of vias by up to 50\%, and reduce the number of DRVs by 79\% compared to manual
and wirelength-minimal placements.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14736'>An Optimal Lower Bound for Simplex Range Reporting</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Peyman Afshani, Pingan Cheng</p><p>We give a simplified and improved lower bound for the simplex range reporting
problem. We show that given a set $P$ of $n$ points in $\mathbb{R}^d$, any data
structure that uses $S(n)$ space to answer such queries must have
$Q(n)=\Omega((n^2/S(n))^{(d-1)/d}+k)$ query time, where $k$ is the output size.
For near-linear space data structures, i.e., $S(n)=O(n\log^{O(1)}n)$, this
improves the previous lower bounds by Chazelle and Rosenberg [CR96] and Afshani
[A12] but perhaps more importantly, it is the first ever tight lower bound for
any variant of simplex range searching for $d\ge 3$ dimensions.
</p>
<p>We obtain our lower bound by making a simple connection to well-studied
problems in incident geometry which allows us to use known constructions in the
area. We observe that a small modification of a simple already existing
construction can lead to our lower bound. We believe that our proof is
accessible to a much wider audience, at least compared to the previous
intricate probabilistic proofs based on measure arguments by Chazelle and
Rosenberg [CR96] and Afshani [A12].
</p>
<p>The lack of tight or almost-tight (up to polylogarithmic factor) lower bounds
for near-linear space data structures is a major bottleneck in making progress
on problems such as proving lower bounds for multilevel data structures. It is
our hope that this new line of attack based on incidence geometry can lead to
further progress in this area.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Afshani_P/0/1/0/all/0/1">Peyman Afshani</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1">Pingan Cheng</a></p><p>We give a simplified and improved lower bound for the simplex range reporting
problem. We show that given a set $P$ of $n$ points in $\mathbb{R}^d$, any data
structure that uses $S(n)$ space to answer such queries must have
$Q(n)=\Omega((n^2/S(n))^{(d-1)/d}+k)$ query time, where $k$ is the output size.
For near-linear space data structures, i.e., $S(n)=O(n\log^{O(1)}n)$, this
improves the previous lower bounds by Chazelle and Rosenberg [CR96] and Afshani
[A12] but perhaps more importantly, it is the first ever tight lower bound for
any variant of simplex range searching for $d\ge 3$ dimensions.
</p>
<p>We obtain our lower bound by making a simple connection to well-studied
problems in incident geometry which allows us to use known constructions in the
area. We observe that a small modification of a simple already existing
construction can lead to our lower bound. We believe that our proof is
accessible to a much wider audience, at least compared to the previous
intricate probabilistic proofs based on measure arguments by Chazelle and
Rosenberg [CR96] and Afshani [A12].
</p>
<p>The lack of tight or almost-tight (up to polylogarithmic factor) lower bounds
for near-linear space data structures is a major bottleneck in making progress
on problems such as proving lower bounds for multilevel data structures. It is
our hope that this new line of attack based on incidence geometry can lead to
further progress in this area.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14664'>Coresets for Vertical Federated Learning: Regularized Linear Regression and $K$-Means Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lingxiao Huang, Zhize Li, Jialin Sun, Haoyu Zhao</p><p>Vertical federated learning (VFL), where data features are stored in multiple
parties distributively, is an important area in machine learning. However, the
communication complexity for VFL is typically very high. In this paper, we
propose a unified framework by constructing coresets in a distributed fashion
for communication-efficient VFL. We study two important learning tasks in the
VFL setting: regularized linear regression and $k$-means clustering, and apply
our coreset framework to both problems. We theoretically show that using
coresets can drastically alleviate the communication complexity, while nearly
maintain the solution quality. Numerical experiments are conducted to
corroborate our theoretical findings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhize Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jialin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haoyu Zhao</a></p><p>Vertical federated learning (VFL), where data features are stored in multiple
parties distributively, is an important area in machine learning. However, the
communication complexity for VFL is typically very high. In this paper, we
propose a unified framework by constructing coresets in a distributed fashion
for communication-efficient VFL. We study two important learning tasks in the
VFL setting: regularized linear regression and $k$-means clustering, and apply
our coreset framework to both problems. We theoretically show that using
coresets can drastically alleviate the communication complexity, while nearly
maintain the solution quality. Numerical experiments are conducted to
corroborate our theoretical findings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14315'>Streaming Submodular Maximization with Differential Privacy</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anamay Chaturvedi, Huy L&#xea; Nguyen, Thy Nguyen</p><p>In this work, we study the problem of privately maximizing a submodular
function in the streaming setting. Extensive work has been done on privately
maximizing submodular functions in the general case when the function depends
upon the private data of individuals. However, when the size of the data stream
drawn from the domain of the objective function is large or arrives very fast,
one must privately optimize the objective within the constraints of the
streaming setting. We establish fundamental differentially private baselines
for this problem and then derive better trade-offs between privacy and utility
for the special case of decomposable submodular functions. A submodular
function is decomposable when it can be written as a sum of submodular
functions; this structure arises naturally when each summand function models
the utility of an individual and the goal is to study the total utility of the
whole population as in the well-known Combinatorial Public Projects Problem.
Finally, we complement our theoretical analysis with experimental
corroboration.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chaturvedi_A/0/1/0/all/0/1">Anamay Chaturvedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Huy L&#xea; Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thy Nguyen</a></p><p>In this work, we study the problem of privately maximizing a submodular
function in the streaming setting. Extensive work has been done on privately
maximizing submodular functions in the general case when the function depends
upon the private data of individuals. However, when the size of the data stream
drawn from the domain of the objective function is large or arrives very fast,
one must privately optimize the objective within the constraints of the
streaming setting. We establish fundamental differentially private baselines
for this problem and then derive better trade-offs between privacy and utility
for the special case of decomposable submodular functions. A submodular
function is decomposable when it can be written as a sum of submodular
functions; this structure arises naturally when each summand function models
the utility of an individual and the goal is to study the total utility of the
whole population as in the well-known Combinatorial Public Projects Problem.
Finally, we complement our theoretical analysis with experimental
corroboration.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14582'>WebCrack: Dynamic Dictionary Adjustment for Web Weak Password Detection based on Blasting Response Event Discrimination</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiang Long, Yan Huang, Zhendong Liu, Lansheng Han, Haili Sun, Jingyuan He</p><p>The feature diversity of different web systems in page elements, submission
contents and return information makes it difficult to detect weak password
automatically. To solve this problem, multi-factor correlation detection method
as integrated in the DBKER algorithm is proposed to achieve automatic detection
of web weak passwords and universal passwords. It generates password
dictionaries based on PCFG algorithm, proposes to judge blasting result via 4
steps with traditional static keyword features and dynamic page feature
information. Then the blasting failure events are discriminated and the
usernames are blasted based on response time. Thereafter the weak password
dictionary is dynamically adjusted according to the hints provided by the
response failure page. Based on the algorithm, this paper implements a
detection system named WebCrack. Experimental results of two blasting tests on
DedeCMS and Discuz! systems as well as a random backend test show that the
proposed method can detect weak passwords and universal passwords of various
web systems with an average accuracy rate of about 93.75%, providing security
advisories for users' password settings with strong practicability.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Long_X/0/1/0/all/0/1">Xiang Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhendong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Lansheng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haili Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jingyuan He</a></p><p>The feature diversity of different web systems in page elements, submission
contents and return information makes it difficult to detect weak password
automatically. To solve this problem, multi-factor correlation detection method
as integrated in the DBKER algorithm is proposed to achieve automatic detection
of web weak passwords and universal passwords. It generates password
dictionaries based on PCFG algorithm, proposes to judge blasting result via 4
steps with traditional static keyword features and dynamic page feature
information. Then the blasting failure events are discriminated and the
usernames are blasted based on response time. Thereafter the weak password
dictionary is dynamically adjusted according to the hints provided by the
response failure page. Based on the algorithm, this paper implements a
detection system named WebCrack. Experimental results of two blasting tests on
DedeCMS and Discuz! systems as well as a random backend test show that the
proposed method can detect weak passwords and universal passwords of various
web systems with an average accuracy rate of about 93.75%, providing security
advisories for users' password settings with strong practicability.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14608'>Inapproximability of shortest paths on perfect matching polytopes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jean Cardinal, Raphael Steiner</p><p>We consider the computational problem of finding short paths in the skeleton
of the perfect matching polytope of a bipartite graph. We prove that unless
$P=NP$, there is no polynomial-time algorithm that computes a path of constant
length between two vertices at distance two of the perfect matching polytope of
a bipartite graph. Conditioned on $P\neq NP$, this disproves a conjecture by
Ito, Kakimura, Kamiyama, Kobayashi and Okamoto [SIAM Journal on Discrete
Mathematics, 36(2), pp. 1102-1123 (2022)]. Assuming the Exponential Time
Hypothesis we prove the stronger result that there exists no polynomial-time
algorithm computing a path of length at most
$\left(\frac{1}{4}-o(1)\right)\frac{\log N}{\log \log N}$ between two vertices
at distance two of the perfect matching polytope of an $N$-vertex bipartite
graph. These results remain true if the bipartite graph is restricted to be of
maximum degree three. The above has the following interesting implication for
the performance of pivot rules for the simplex algorithm on simply-structured
combinatorial polytopes: If $P\neq NP$, then for every simplex pivot rule
executable in polynomial time and every constant $k \in \mathbb{N}$ there
exists a linear program on a perfect matching polytope and a starting vertex of
the polytope such that the optimal solution can be reached in two monotone
steps from the starting vertex, yet the pivot rule will require at least $k$
steps to reach the optimal solution. This result remains true in the more
general setting of pivot rules for so-called circuit-augmentation algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Cardinal_J/0/1/0/all/0/1">Jean Cardinal</a>, <a href="http://arxiv.org/find/math/1/au:+Steiner_R/0/1/0/all/0/1">Raphael Steiner</a></p><p>We consider the computational problem of finding short paths in the skeleton
of the perfect matching polytope of a bipartite graph. We prove that unless
$P=NP$, there is no polynomial-time algorithm that computes a path of constant
length between two vertices at distance two of the perfect matching polytope of
a bipartite graph. Conditioned on $P\neq NP$, this disproves a conjecture by
Ito, Kakimura, Kamiyama, Kobayashi and Okamoto [SIAM Journal on Discrete
Mathematics, 36(2), pp. 1102-1123 (2022)]. Assuming the Exponential Time
Hypothesis we prove the stronger result that there exists no polynomial-time
algorithm computing a path of length at most
$\left(\frac{1}{4}-o(1)\right)\frac{\log N}{\log \log N}$ between two vertices
at distance two of the perfect matching polytope of an $N$-vertex bipartite
graph. These results remain true if the bipartite graph is restricted to be of
maximum degree three. The above has the following interesting implication for
the performance of pivot rules for the simplex algorithm on simply-structured
combinatorial polytopes: If $P\neq NP$, then for every simplex pivot rule
executable in polynomial time and every constant $k \in \mathbb{N}$ there
exists a linear program on a perfect matching polytope and a starting vertex of
the polytope such that the optimal solution can be reached in two monotone
steps from the starting vertex, yet the pivot rule will require at least $k$
steps to reach the optimal solution. This result remains true in the more
general setting of pivot rules for so-called circuit-augmentation algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14629'>Highly unbreakable graph with a fixed excluded minor are almost rigid</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Lokshtanov, Marcin Pilipczuk, Micha&#x142; Pilipczuk, Saket Saurabh</p><p>A set $X \subseteq V(G)$ in a graph $G$ is $(q,k)$-unbreakable if every
separation $(A,B)$ of order at most $k$ in $G$ satisfies $|A \cap X| \leq q$ or
$|B \cap X| \leq q$. In this paper, we prove the following result: If a graph
$G$ excludes a fixed complete graph $K_h$ as a minor and satisfies certain
unbreakability guarantees, then $G$ is almost rigid in the following sense: the
vertices of $G$ can be partitioned in an isomorphism-invariant way into a part
inducing a graph of bounded treewidth and a part that admits a small
isomorphism-invariant family of labelings. This result is the key ingredient in
the fixed-parameter algorithm for Graph Isomorphism parameterized by the
Hadwiger number of the graph, which is presented in a companion paper.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Lokshtanov_D/0/1/0/all/0/1">Daniel Lokshtanov</a>, <a href="http://arxiv.org/find/math/1/au:+Pilipczuk_M/0/1/0/all/0/1">Marcin Pilipczuk</a>, <a href="http://arxiv.org/find/math/1/au:+Pilipczuk_M/0/1/0/all/0/1">Micha&#x142; Pilipczuk</a>, <a href="http://arxiv.org/find/math/1/au:+Saurabh_S/0/1/0/all/0/1">Saket Saurabh</a></p><p>A set $X \subseteq V(G)$ in a graph $G$ is $(q,k)$-unbreakable if every
separation $(A,B)$ of order at most $k$ in $G$ satisfies $|A \cap X| \leq q$ or
$|B \cap X| \leq q$. In this paper, we prove the following result: If a graph
$G$ excludes a fixed complete graph $K_h$ as a minor and satisfies certain
unbreakability guarantees, then $G$ is almost rigid in the following sense: the
vertices of $G$ can be partitioned in an isomorphism-invariant way into a part
inducing a graph of bounded treewidth and a part that admits a small
isomorphism-invariant family of labelings. This result is the key ingredient in
the fixed-parameter algorithm for Graph Isomorphism parameterized by the
Hadwiger number of the graph, which is presented in a companion paper.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14638'>Fixed-parameter tractability of Graph Isomorphism in graphs with an excluded minor</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Lokshtanov, Marcin Pilipczuk, Micha&#x142; Pilipczuk, Saket Saurabh</p><p>We prove that Graph Isomorphism and Canonization in graphs excluding a fixed
graph $H$ as a minor can be solved by an algorithm working in time $f(H)\cdot
n^{O(1)}$, where $f$ is some function. In other words, we show that these
problems are fixed-parameter tractable when parameterized by the size of the
excluded minor, with the caveat that the bound on the running time is not
necessarily computable. The underlying approach is based on decomposing the
graph in a canonical way into unbreakable (intuitively, well-connected) parts,
which essentially provides a reduction to the case where the given
$H$-minor-free graph is unbreakable itself. This is complemented by an analysis
of unbreakable $H$-minor-free graphs, performed in a second subordinate
manuscript, which reveals that every such graph can be canonically decomposed
into a part that admits few automorphisms and a part that has bounded
treewidth.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lokshtanov_D/0/1/0/all/0/1">Daniel Lokshtanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Marcin Pilipczuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Micha&#x142; Pilipczuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1">Saket Saurabh</a></p><p>We prove that Graph Isomorphism and Canonization in graphs excluding a fixed
graph $H$ as a minor can be solved by an algorithm working in time $f(H)\cdot
n^{O(1)}$, where $f$ is some function. In other words, we show that these
problems are fixed-parameter tractable when parameterized by the size of the
excluded minor, with the caveat that the bound on the running time is not
necessarily computable. The underlying approach is based on decomposing the
graph in a canonical way into unbreakable (intuitively, well-connected) parts,
which essentially provides a reduction to the case where the given
$H$-minor-free graph is unbreakable itself. This is complemented by an analysis
of unbreakable $H$-minor-free graphs, performed in a second subordinate
manuscript, which reveals that every such graph can be canonically decomposed
into a part that admits few automorphisms and a part that has bounded
treewidth.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14722'>Online TSP with Known Locations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Evripidis Bampis, Bruno Escoffier, Niklas Hahn, Michalis Xefteris</p><p>In this paper, we consider the Online Traveling Salesperson Problem (OLTSP)
where the locations of the requests are known in advance, but not their arrival
times. We study both the open variant, in which the algorithm is not required
to return to the origin when all the requests are served, as well as the closed
variant, in which the algorithm has to return to the origin after serving all
the requests. Our aim is to measure the impact of the extra knowledge of the
locations on the competitiveness of the problem. We present an online
3/2-competitive algorithm for the general case and a matching lower bound for
both the open and the closed variant. Then, we focus on some interesting metric
spaces (ring, star, semi-line), providing both lower bounds and polynomial time
online algorithms for the problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bampis_E/0/1/0/all/0/1">Evripidis Bampis</a>, <a href="http://arxiv.org/find/cs/1/au:+Escoffier_B/0/1/0/all/0/1">Bruno Escoffier</a>, <a href="http://arxiv.org/find/cs/1/au:+Hahn_N/0/1/0/all/0/1">Niklas Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Xefteris_M/0/1/0/all/0/1">Michalis Xefteris</a></p><p>In this paper, we consider the Online Traveling Salesperson Problem (OLTSP)
where the locations of the requests are known in advance, but not their arrival
times. We study both the open variant, in which the algorithm is not required
to return to the origin when all the requests are served, as well as the closed
variant, in which the algorithm has to return to the origin after serving all
the requests. Our aim is to measure the impact of the extra knowledge of the
locations on the competitiveness of the problem. We present an online
3/2-competitive algorithm for the general case and a matching lower bound for
both the open and the closed variant. Then, we focus on some interesting metric
spaces (ring, star, semi-line), providing both lower bounds and polynomial time
online algorithms for the problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14869'>An Efficient Dynamic Multi-Sources To Single-Destination (DMS-SD) Algorithm In Smart City Navigation Using Adjacent Matrix</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ziren Xiao, Ruxin Xiao, Chang Liu, Honghao Gao, Xiaolong Xu, Shan Luo, Xinheng Wang</p><p>Dijkstra's algorithm is one of the most popular classic path planning
algorithms, achieving optimal solutions across a wide range of challenging
tasks. However, it only calculates the shortest distance from one vertex to
another, which is hard to directly apply to the Dynamic Multi-Sources to
Single-Destination (DMS-SD) problem. This paper proposes a modified Dijkstra
algorithm to address the DMS-SD problem, where the destination can be
dynamically changed. Our method deploys the concept of Adjacent Matrix from
Floyd's algorithm and achieves the goal with mathematical calculations. We
formally show that all-pairs shortest distance information in Floyd's algorithm
is not required in our algorithm. Extensive experiments verify the scalability
and optimality of the proposed method.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1">Ziren Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_R/0/1/0/all/0/1">Ruxin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1">Honghao Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaolong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinheng Wang</a></p><p>Dijkstra's algorithm is one of the most popular classic path planning
algorithms, achieving optimal solutions across a wide range of challenging
tasks. However, it only calculates the shortest distance from one vertex to
another, which is hard to directly apply to the Dynamic Multi-Sources to
Single-Destination (DMS-SD) problem. This paper proposes a modified Dijkstra
algorithm to address the DMS-SD problem, where the destination can be
dynamically changed. Our method deploys the concept of Adjacent Matrix from
Floyd's algorithm and achieves the goal with mathematical calculations. We
formally show that all-pairs shortest distance information in Floyd's algorithm
is not required in our algorithm. Extensive experiments verify the scalability
and optimality of the proposed method.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14894'>Learning to predict arbitrary quantum processes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hsin-Yuan Huang, Sitan Chen, John Preskill</p><p>We present an efficient machine learning (ML) algorithm for predicting any
unknown quantum process $\mathcal{E}$ over $n$ qubits. For a wide range of
distributions $\mathcal{D}$ on arbitrary $n$-qubit states, we show that this ML
algorithm can learn to predict any local property of the output from the
unknown process $\mathcal{E}$, with a small average error over input states
drawn from $\mathcal{D}$. The ML algorithm is computationally efficient even
when the unknown process is a quantum circuit with exponentially many gates.
Our algorithm combines efficient procedures for learning properties of an
unknown state and for learning a low-degree approximation to an unknown
observable. The analysis hinges on proving new norm inequalities, including a
quantum analogue of the classical Bohnenblust-Hille inequality, which we derive
by giving an improved algorithm for optimizing local Hamiltonians. Overall, our
results highlight the potential for ML models to predict the output of complex
quantum dynamics much faster than the time needed to run the process itself.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Huang_H/0/1/0/all/0/1">Hsin-Yuan Huang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chen_S/0/1/0/all/0/1">Sitan Chen</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Preskill_J/0/1/0/all/0/1">John Preskill</a></p><p>We present an efficient machine learning (ML) algorithm for predicting any
unknown quantum process $\mathcal{E}$ over $n$ qubits. For a wide range of
distributions $\mathcal{D}$ on arbitrary $n$-qubit states, we show that this ML
algorithm can learn to predict any local property of the output from the
unknown process $\mathcal{E}$, with a small average error over input states
drawn from $\mathcal{D}$. The ML algorithm is computationally efficient even
when the unknown process is a quantum circuit with exponentially many gates.
Our algorithm combines efficient procedures for learning properties of an
unknown state and for learning a low-degree approximation to an unknown
observable. The analysis hinges on proving new norm inequalities, including a
quantum analogue of the classical Bohnenblust-Hille inequality, which we derive
by giving an improved algorithm for optimizing local Hamiltonians. Overall, our
results highlight the potential for ML models to predict the output of complex
quantum dynamics much faster than the time needed to run the process itself.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, October 26
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/26/faculty-at-johns-hopkins-university-apply-by-january-6-2023/'>Faculty at Johns Hopkins University (apply by January 6, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Johns Hopkins University’s Department of Computer Science invites applications for tenure-track faculty positions at all levels and across all areas of computer science. We are particularly interested in applicants in computer vision, networked systems, theoretical computer science, and machine learning. Website: cra.org/job/johns-hopkins-university-tenure-track-faculty-department-of-computer-science-4/ Email: fsearch2022@cs.jhu.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Johns Hopkins University’s Department of Computer Science invites applications for tenure-track faculty positions at all levels and across all areas of computer science. We are particularly interested in applicants in computer vision, networked systems, theoretical computer science, and machine learning.</p>
<p>Website: <a href="https://cra.org/job/johns-hopkins-university-tenure-track-faculty-department-of-computer-science-4/">https://cra.org/job/johns-hopkins-university-tenure-track-faculty-department-of-computer-science-4/</a><br />
Email: fsearch2022@cs.jhu.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T22:56:02Z">Wednesday, October 26 2022, 22:56</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/26/tenured-tenure-track-positions-in-computer-science-at-nyu-shanghai-apply-by-february-1-2023/'>Tenured/Tenure-track Positions in Computer Science  at NYU Shanghai (apply by February 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          NYU Shanghai is currently inviting applications for Tenured or Tenure-Track positions in Computer Science. The search is not restricted to any rank and outstanding candidates at all levels are encouraged to apply. We seek candidates who have completed a Ph.D. in Computer Science, or a closely related discipline. We seek candidates in all sub-fields of [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>NYU Shanghai is currently inviting applications for Tenured or Tenure-Track positions in Computer Science. The search is not restricted to any rank and outstanding candidates at all levels are encouraged to apply. We seek candidates who have completed a Ph.D. in Computer Science, or a closely related discipline. We seek candidates in all sub-fields of Computer Science.</p>
<p>Website: <a href="https://apply.interfolio.com/116511">https://apply.interfolio.com/116511</a><br />
Email: shanghai.faculty.recruitment@nyu.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T16:37:08Z">Wednesday, October 26 2022, 16:37</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13741'>Deep Neural Networks as the Semi-classical Limit of Topological Quantum Neural Networks: The problem of generalisation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Antonino Marciano, Deen Chen, Filippo Fabrocini, Chris Fields, Matteo Lulli, Emanuele Zappala</p><p>Deep Neural Networks miss a principled model of their operation. A novel
framework for supervised learning based on Topological Quantum Field Theory
that looks particularly well suited for implementation on quantum processors
has been recently explored. We propose the use of this framework for
understanding the problem of generalization in Deep Neural Networks. More
specifically, in this approach Deep Neural Networks are viewed as the
semi-classical limit of Topological Quantum Neural Networks. A framework of
this kind explains easily the overfitting behavior of Deep Neural Networks
during the training step and the corresponding generalization capabilities.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Marciano_A/0/1/0/all/0/1">Antonino Marciano</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chen_D/0/1/0/all/0/1">Deen Chen</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Fabrocini_F/0/1/0/all/0/1">Filippo Fabrocini</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Fields_C/0/1/0/all/0/1">Chris Fields</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Lulli_M/0/1/0/all/0/1">Matteo Lulli</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zappala_E/0/1/0/all/0/1">Emanuele Zappala</a></p><p>Deep Neural Networks miss a principled model of their operation. A novel
framework for supervised learning based on Topological Quantum Field Theory
that looks particularly well suited for implementation on quantum processors
has been recently explored. We propose the use of this framework for
understanding the problem of generalization in Deep Neural Networks. More
specifically, in this approach Deep Neural Networks are viewed as the
semi-classical limit of Topological Quantum Neural Networks. A framework of
this kind explains easily the overfitting behavior of Deep Neural Networks
during the training step and the corresponding generalization capabilities.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13694'>Worst-Case Adaptive Submodular Cover</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jing Yuan, Shaojie Tang</p><p>In this paper, we study the adaptive submodular cover problem under the
worst-case setting. This problem generalizes many previously studied problems,
namely, the pool-based active learning and the stochastic submodular set cover.
The input of our problem is a set of items (e.g., medical tests) and each item
has a random state (e.g., the outcome of a medical test), whose realization is
initially unknown. One must select an item at a fixed cost in order to observe
its realization. There is an utility function which is defined over items and
their states. Our goal is to sequentially select a group of items to achieve a
``goal value'' while minimizing the maximum cost across realizations (a.k.a.
worst-case cost). To facilitate our study, we introduce a broad class of
stochastic functions, called \emph{worst-case submodular function}. Assume the
utility function is worst-case submodular, we develop a tight $(\log
(Q/\eta)+1)$-approximation policy, where $Q$ is the ``goal value'' and $\eta$
is the minimum gap between $Q$ and any attainable utility value $\hat{Q}&lt;Q$. We
also study a worst-case maximum-coverage problem, whose goal is to select a
group of items to maximize its worst-case utility subject to a budget
constraint. This is a flipped problem of the minimum-cost-cover problem, and to
solve this problem, we develop a tight $(1-1/e)$-approximation solution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Jing Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Shaojie Tang</a></p><p>In this paper, we study the adaptive submodular cover problem under the
worst-case setting. This problem generalizes many previously studied problems,
namely, the pool-based active learning and the stochastic submodular set cover.
The input of our problem is a set of items (e.g., medical tests) and each item
has a random state (e.g., the outcome of a medical test), whose realization is
initially unknown. One must select an item at a fixed cost in order to observe
its realization. There is an utility function which is defined over items and
their states. Our goal is to sequentially select a group of items to achieve a
``goal value'' while minimizing the maximum cost across realizations (a.k.a.
worst-case cost). To facilitate our study, we introduce a broad class of
stochastic functions, called \emph{worst-case submodular function}. Assume the
utility function is worst-case submodular, we develop a tight $(\log
(Q/\eta)+1)$-approximation policy, where $Q$ is the ``goal value'' and $\eta$
is the minimum gap between $Q$ and any attainable utility value $\hat{Q}&lt;Q$. We
also study a worst-case maximum-coverage problem, whose goal is to select a
group of items to maximize its worst-case utility subject to a budget
constraint. This is a flipped problem of the minimum-cost-cover problem, and to
solve this problem, we develop a tight $(1-1/e)$-approximation solution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13706'>Gaussian Mean Testing Made Simple</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ilias Diakonikolas, Daniel M. Kane, Ankit Pensia</p><p>We study the following fundamental hypothesis testing problem, which we term
Gaussian mean testing. Given i.i.d. samples from a distribution $p$ on
$\mathbb{R}^d$, the task is to distinguish, with high probability, between the
following cases: (i) $p$ is the standard Gaussian distribution,
$\mathcal{N}(0,I_d)$, and (ii) $p$ is a Gaussian $\mathcal{N}(\mu,\Sigma)$ for
some unknown covariance $\Sigma$ and mean $\mu \in \mathbb{R}^d$ satisfying
$\|\mu\|_2 \geq \epsilon$. Recent work gave an algorithm for this testing
problem with the optimal sample complexity of $\Theta(\sqrt{d}/\epsilon^2)$.
Both the previous algorithm and its analysis are quite complicated. Here we
give an extremely simple algorithm for Gaussian mean testing with a one-page
analysis. Our algorithm is sample optimal and runs in sample linear time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Diakonikolas_I/0/1/0/all/0/1">Ilias Diakonikolas</a>, <a href="http://arxiv.org/find/math/1/au:+Kane_D/0/1/0/all/0/1">Daniel M. Kane</a>, <a href="http://arxiv.org/find/math/1/au:+Pensia_A/0/1/0/all/0/1">Ankit Pensia</a></p><p>We study the following fundamental hypothesis testing problem, which we term
Gaussian mean testing. Given i.i.d. samples from a distribution $p$ on
$\mathbb{R}^d$, the task is to distinguish, with high probability, between the
following cases: (i) $p$ is the standard Gaussian distribution,
$\mathcal{N}(0,I_d)$, and (ii) $p$ is a Gaussian $\mathcal{N}(\mu,\Sigma)$ for
some unknown covariance $\Sigma$ and mean $\mu \in \mathbb{R}^d$ satisfying
$\|\mu\|_2 \geq \epsilon$. Recent work gave an algorithm for this testing
problem with the optimal sample complexity of $\Theta(\sqrt{d}/\epsilon^2)$.
Both the previous algorithm and its analysis are quite complicated. Here we
give an extremely simple algorithm for Gaussian mean testing with a one-page
analysis. Our algorithm is sample optimal and runs in sample linear time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13739'>Deterministic Small Vertex Connectivity in Almost Linear Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Thatchaphol Saranurak, Sorrachai Yingchareonthawornchai</p><p>In the vertex connectivity problem, given an undirected $n$-vertex $m$-edge
graph $G$, we need to compute the minimum number of vertices that can
disconnect $G$ after removing them. This problem is one of the most
well-studied graph problems. From 2019, a new line of work [Nanongkai et
al.~STOC'19;SODA'20;STOC'21] has used randomized techniques to break the
quadratic-time barrier and, very recently, culminated in an almost-linear time
algorithm via the recently announced maxflow algorithm by Chen et al. In
contrast, all known deterministic algorithms are much slower. The fastest
algorithm [Gabow FOCS'00] takes $O(m(n+\min\{c^{5/2},cn^{3/4}\}))$ time where
$c$ is the vertex connectivity. It remains open whether there exists a
subquadratic-time deterministic algorithm for any constant $c&gt;3$.
</p>
<p>In this paper, we give the first deterministic almost-linear time vertex
connectivity algorithm for all constants $c$. Our running time is
$m^{1+o(1)}2^{O(c^{2})}$ time, which is almost-linear for all $c=o(\sqrt{\log
n})$. This is the first deterministic algorithm that breaks the $O(n^{2})$-time
bound on sparse graphs where $m=O(n)$, which is known for more than 50 years
ago [Kleitman'69]. Towards our result, we give a new reduction framework to
vertex expanders which in turn exploits our new almost-linear time construction
of mimicking network for vertex connectivity. The previous construction by
Kratsch and Wahlstr\"{o}m [FOCS'12] requires large polynomial time and is
randomized.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Saranurak_T/0/1/0/all/0/1">Thatchaphol Saranurak</a>, <a href="http://arxiv.org/find/cs/1/au:+Yingchareonthawornchai_S/0/1/0/all/0/1">Sorrachai Yingchareonthawornchai</a></p><p>In the vertex connectivity problem, given an undirected $n$-vertex $m$-edge
graph $G$, we need to compute the minimum number of vertices that can
disconnect $G$ after removing them. This problem is one of the most
well-studied graph problems. From 2019, a new line of work [Nanongkai et
al.~STOC'19;SODA'20;STOC'21] has used randomized techniques to break the
quadratic-time barrier and, very recently, culminated in an almost-linear time
algorithm via the recently announced maxflow algorithm by Chen et al. In
contrast, all known deterministic algorithms are much slower. The fastest
algorithm [Gabow FOCS'00] takes $O(m(n+\min\{c^{5/2},cn^{3/4}\}))$ time where
$c$ is the vertex connectivity. It remains open whether there exists a
subquadratic-time deterministic algorithm for any constant $c&gt;3$.
</p>
<p>In this paper, we give the first deterministic almost-linear time vertex
connectivity algorithm for all constants $c$. Our running time is
$m^{1+o(1)}2^{O(c^{2})}$ time, which is almost-linear for all $c=o(\sqrt{\log
n})$. This is the first deterministic algorithm that breaks the $O(n^{2})$-time
bound on sparse graphs where $m=O(n)$, which is known for more than 50 years
ago [Kleitman'69]. Towards our result, we give a new reduction framework to
vertex expanders which in turn exploits our new almost-linear time construction
of mimicking network for vertex connectivity. The previous construction by
Kratsch and Wahlstr\"{o}m [FOCS'12] requires large polynomial time and is
randomized.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13755'>Online and Bandit Algorithms Beyond $\ell_p$ Norms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Thomas Kesselheim, Marco Molinaro, Sahil Singla</p><p>Vector norms play a fundamental role in computer science and optimization, so
there is an ongoing effort to generalize existing algorithms to settings beyond
$\ell_\infty$ and $\ell_p$ norms. We show that many online and bandit
applications for general norms admit good algorithms as long as the norm can be
approximated by a function that is ``gradient-stable'', a notion that we
introduce. Roughly it says that the gradient of the function should not
drastically decrease (multiplicatively) in any component as we increase the
input vector. We prove that several families of norms, including all monotone
symmetric norms, admit a gradient-stable approximation, giving us the first
online and bandit algorithms for these norm families.
</p>
<p>In particular, our notion of gradient-stability gives $O\big(\log^2
(\text{dimension})\big)$-competitive algorithms for the symmetric norm
generalizations of Online Generalized Load Balancing and Bandits with
Knapsacks. Our techniques extend to applications beyond symmetric norms as
well, e.g., to Online Vector Scheduling and to Online Generalized Assignment
with Convex Costs. Some key properties underlying our applications that are
implied by gradient-stable approximations are a ``smooth game inequality'' and
an approximate converse to Jensen's inequality.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kesselheim_T/0/1/0/all/0/1">Thomas Kesselheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Molinaro_M/0/1/0/all/0/1">Marco Molinaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1">Sahil Singla</a></p><p>Vector norms play a fundamental role in computer science and optimization, so
there is an ongoing effort to generalize existing algorithms to settings beyond
$\ell_\infty$ and $\ell_p$ norms. We show that many online and bandit
applications for general norms admit good algorithms as long as the norm can be
approximated by a function that is ``gradient-stable'', a notion that we
introduce. Roughly it says that the gradient of the function should not
drastically decrease (multiplicatively) in any component as we increase the
input vector. We prove that several families of norms, including all monotone
symmetric norms, admit a gradient-stable approximation, giving us the first
online and bandit algorithms for these norm families.
</p>
<p>In particular, our notion of gradient-stability gives $O\big(\log^2
(\text{dimension})\big)$-competitive algorithms for the symmetric norm
generalizations of Online Generalized Load Balancing and Bandits with
Knapsacks. Our techniques extend to applications beyond symmetric norms as
well, e.g., to Online Vector Scheduling and to Online Generalized Assignment
with Convex Costs. Some key properties underlying our applications that are
implied by gradient-stable approximations are a ``smooth game inequality'' and
an approximate converse to Jensen's inequality.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13850'>Tight analysis of lazy: an improved algorithm for open online dial-a-ride</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Julia Baligacs, Yann Disser, David Weckbecker</p><p>In the open online dial-a-ride problem, a single server has to carry
transportation requests appearing over time in some metric space, subject to
minimizing the completion time. We improve on the best known upper bounds on
the competitive ratio on general metric spaces and on the half-line, in both,
the preemptive and non-preemptive version of the problem. We achieve this by
revisiting the algorithm Lazy recently suggested in [WAOA, 2022] and giving an
improved and tight analysis. More precisely, we show that it is
$(\frac{3}{2}+\sqrt{11/12}\thickapprox 2.457)$-competitive on general metric
spaces and $(1+\frac{1}{2}(1+\sqrt{3})\approx 2.366)$-competitive on the
half-line.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Baligacs_J/0/1/0/all/0/1">Julia Baligacs</a>, <a href="http://arxiv.org/find/cs/1/au:+Disser_Y/0/1/0/all/0/1">Yann Disser</a>, <a href="http://arxiv.org/find/cs/1/au:+Weckbecker_D/0/1/0/all/0/1">David Weckbecker</a></p><p>In the open online dial-a-ride problem, a single server has to carry
transportation requests appearing over time in some metric space, subject to
minimizing the completion time. We improve on the best known upper bounds on
the competitive ratio on general metric spaces and on the half-line, in both,
the preemptive and non-preemptive version of the problem. We achieve this by
revisiting the algorithm Lazy recently suggested in [WAOA, 2022] and giving an
improved and tight analysis. More precisely, we show that it is
$(\frac{3}{2}+\sqrt{11/12}\thickapprox 2.457)$-competitive on general metric
spaces and $(1+\frac{1}{2}(1+\sqrt{3})\approx 2.366)$-competitive on the
half-line.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13854'>An Improved Algorithm for Open Online Dial-a-Ride</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Julia Baligacs, Yann Disser, Nils Mosis, David Weckbecker</p><p>We consider the open online dial-a-ride problem, where transportation
requests appear online in a metric space and need to be served by a single
server. The objective is to minimize the completion time until all requests
have been served. We present a new, parameterized algorithm for this problem
and prove that it attains a competitive ratio of $1 + \varphi \approx 2.618$
for some choice of its parameter, where $\varphi$ is the golden ratio. This
improves the best known bounds for open online dial-a-ride both for general
metric spaces as well as for the real line. We also give a lower bound
of~$2.457$ for the competitive ratio of our algorithm for any parameter choice.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Baligacs_J/0/1/0/all/0/1">Julia Baligacs</a>, <a href="http://arxiv.org/find/cs/1/au:+Disser_Y/0/1/0/all/0/1">Yann Disser</a>, <a href="http://arxiv.org/find/cs/1/au:+Mosis_N/0/1/0/all/0/1">Nils Mosis</a>, <a href="http://arxiv.org/find/cs/1/au:+Weckbecker_D/0/1/0/all/0/1">David Weckbecker</a></p><p>We consider the open online dial-a-ride problem, where transportation
requests appear online in a metric space and need to be served by a single
server. The objective is to minimize the completion time until all requests
have been served. We present a new, parameterized algorithm for this problem
and prove that it attains a competitive ratio of $1 + \varphi \approx 2.618$
for some choice of its parameter, where $\varphi$ is the golden ratio. This
improves the best known bounds for open online dial-a-ride both for general
metric spaces as well as for the real line. We also give a lower bound
of~$2.457$ for the competitive ratio of our algorithm for any parameter choice.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13880'>Efficient and Stable Fully Dynamic Facility Location</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sayan Bhattacharya, Silvio Lattanzi, Nikos Parotsidis</p><p>We consider the classic facility location problem in fully dynamic data
streams, where elements can be both inserted and deleted. In this problem, one
is interested in maintaining a stable and high quality solution throughout the
data stream while using only little time per update (insertion or deletion). We
study the problem and provide the first algorithm that at the same time
maintains a constant approximation and incurs polylogarithmic amortized
recourse per update. We complement our theoretical results with an experimental
analysis showing the practical efficiency of our method.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1">Sayan Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Lattanzi_S/0/1/0/all/0/1">Silvio Lattanzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Parotsidis_N/0/1/0/all/0/1">Nikos Parotsidis</a></p><p>We consider the classic facility location problem in fully dynamic data
streams, where elements can be both inserted and deleted. In this problem, one
is interested in maintaining a stable and high quality solution throughout the
data stream while using only little time per update (insertion or deletion). We
study the problem and provide the first algorithm that at the same time
maintains a constant approximation and incurs polylogarithmic amortized
recourse per update. We complement our theoretical results with an experimental
analysis showing the practical efficiency of our method.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://benjamin-recht.github.io/2022/10/26/ai-image-search/'>Does AI Suck at Art?</a></h3>
        <p class='tr-article-feed'>from <a href='http://benjamin-recht.github.io/'>Ben Recht</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>I’ve been researching machine learning for a little over 20 years. For the past five years or so, with the latest wave of AI overpromising, I think I’ve been mostly known as an AI skeptic. But I’ve been engaging with these new AI image generation tools, and they are delightful. They have a lot of promise, and I want to explain why and suggest a few ways to make them even better.</p>

<p>Though I don’t talk about it much, for the past 20 years I’ve also been playing in an ambient shoegazer band called “the fun years.” My bandmate, Isaac Sparks, has been in charge of our visual design from the get-go. Over the years, he’s progressively refined his style, and he has been dipping his toes into the weird world of prompt-to-art.</p>

<p>Last week, we re-released an old single from 2006, and Isaac used midjourney for the cover art. Isaac is a turntablist, and approaches his art similarly to how he approaches searching for records. He seeks out happy accidents that can take on some new life when repurposed in new contexts. The cover of our first CDR, now that’s what i call droning, volume 4, was a photograph Isaac had taken out of my apartment window on a foggy evening. Over time, his covers grew more abstract. The cover of baby it’s cold inside is a collage of close up images of an old paint can Isaac found in the basement of his apartment complex. Most recently, the cover of our latest album typos in your obituary is a photograph of a stark, black, sculpture Isaac made out of wood scraps (He made a similar, Big Lebowski inspired sculpture for the cover art of my book with Steve Wright Optimization for Data Analysis).</p>

<p>For our new single, Isaac tried to come up with a midjourney prompt that captured the appropriate aesthetic of a fun years cover. It only took a couple of iterations to get what he wanted:</p>

<blockquote>
  <p>A mess of scrap paper, dull color plastic caps, dust, paint smear, chip, cruft, drinking straw, rusty nails, wooden lath, mold fractal, layers, black and white, realistic</p>
</blockquote>

<p>♦</p>

<p>And we went with the image in the bottom left.</p>

<p>♦</p>

<p>The image didn’t have any obvious visual artifacts and looked like something Isaac might have found out in the world. Having read recent reporting on some rather suspect copyright infringement, Isaac and I wondered if midjourney had obviously just ripped off the image.</p>

<p>For a lot of the early DALL-E memes that I saw on social media, I could often find strikingly similar pictures by pasting the prompt into google image search. But for Isaac’s mess prompt, we came up pretty empty, with some rather hilariously bad results.</p>

<p>♦</p>

<p>♦</p>

<p>Vaishaal Shankar then reminded me that there was a much better image search engine. The original DALL-E model which started the prompt-to-image craze was based on a neural network model called CLIP that learned a model to compare images and text. The model was trained on a huge data set of images paired with captions. It produced two functions: one that mapped images to a code book and one that mapped text to a code book. When you compared codes for two snippets of text, this would tell you how similar the snippets were. When you compared codes of two images, this would tell you how similar the images were. But one of the more amazing things about CLIP is that you could compare the codes of text and images and find images which were similar to the text.</p>

<p>Romain Beaumont built an image search system, clip-retrieval that used CLIP and a new data set LAION-5B consisting of 5 billion images scraped by common crawl. 5 billion! (Insert Dr. Evil meme). Romain hosts a free version of this system, where you type some text, it computes the codebook, and it returns all of the images in LAION-5B which have similar codes to your text. We tried Isaac’s prompt here, and now found some strikingly similar images.</p>

<p>♦</p>

<p>There were hundreds of art pieces and stock photos that captured elements of the spirit of the prompt. Again, with 5 billion images, it’s hard to imagine what’s not in there. But after scrolling through pages of similar images, we couldn’t find any of the four renderings produced by midjourney.</p>

<p>We tried the reverse image search in both clip-retrieval and google, and though we got back some similar textures, we couldn’t find the image itself.</p>

<p>♦</p>

<p>Now, just because we didn’t find our image doesn’t mean it’s not in the corpus somewhere. We looked at around 100 images, but what if we had looked at 1000? Or 10000? Perhaps it’s buried in the corner of some thumbnail in the LAION set. The biggest flaw of these tools is making artist attribution impossible. There should be some simple way of tracing back to the training set. Without traceback and attribution, this is just going to lead to annoying copyright lawsuits like we saw in the early days of sampling in music. We’d be better off if we could avoid those legal battles before they happen.</p>

<p>All that said, it really seems like the midjourney neural nets are doing something more than re-displaying images from the training set. There are certainly billions of amazing textures out in the world, and CLIP-style models make them easier to bring to the surface. But midjourney adds something extra to fuse these textures into something new. It’s much more than a “copyright infringing blur filter” and that’s pretty cool!</p>

<p>I still maintain that AI was and is overhyped. We were promised self-driving cars and cures for cancer, and we ended up with splashy tools for image generation. I’m not sure we can justify the billions of dollars of investment. But the image processing tools are still super fun and I want more to play with, so I’ll be selfish and hope OpenAI raises more money. I hope future variants allow for clearer navigation and enable more intentional sampling and pastiche of the source materials. And I can’t wait until they figure out how to make a plugin for Ableton Live that scours huge audio libraries to produce melted sonic textures. At that point, you won’t hear from me as an AI skeptic anymore as I’ll be blissfully hiding in my music studio.</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I’ve been researching machine learning for a little over 20 years. For the past five years or so, with the latest wave of AI overpromising, I think I’ve been mostly known as an AI skeptic. But I’ve been engaging with these new AI image generation tools, and they are delightful. They have a lot of promise, and I want to explain why and suggest a few ways to make them even better.</p>

<p>Though I don’t talk about it much, for the past 20 years I’ve also been playing in an ambient shoegazer band called <a href="https://thefunyears.bandcamp.com/">“the fun years.”</a> My bandmate, <a href="http://www.isaacsparks.com/">Isaac Sparks</a>, has been in charge of our visual design from the get-go. Over the years, he’s progressively refined his style, and he has been dipping his toes into the weird world of prompt-to-art.</p>

<p>Last week, <a href="https://thefunyears.bandcamp.com/track/electricity-is-a-scarce-commodity">we re-released an old single from 2006</a>, and Isaac used <a href="https://www.midjourney.com/home/">midjourney</a> for the cover art. Isaac is a turntablist, and approaches his art similarly to how he approaches searching for records. He seeks out happy accidents that can take on some new life when repurposed in new contexts. The cover of our first CDR, <a href="https://thefunyears.bandcamp.com/album/now-thats-what-i-call-droning-volume-4"><em>now that’s what i call droning, volume 4</em></a>, was a photograph Isaac had taken out of my apartment window on a foggy evening. Over time, his covers grew more abstract. The cover of <a href="https://thefunyears.bandcamp.com/album/baby-its-cold-inside"><em>baby it’s cold inside</em></a> is a collage of close up images of an old paint can Isaac found in the basement of his apartment complex. Most recently, the cover of our latest album <a href="https://thefunyears.bandcamp.com/album/typos-in-your-obituary"><em>typos in your obituary</em></a> is a photograph of a stark, black, sculpture Isaac made out of wood scraps (He made a similar, Big Lebowski inspired sculpture for the cover art of my book with Steve Wright <a href="https://www.cambridge.org/core/books/optimization-for-data-analysis/C02C3708905D236AA354D1CE1739A6A2"><em>Optimization for Data Analysis</em></a>).</p>

<p>For our new single, Isaac tried to come up with a midjourney prompt that captured the appropriate aesthetic of a fun years cover. It only took a couple of iterations to get what he wanted:</p>

<blockquote>
  <p>A mess of scrap paper, dull color plastic caps, dust, paint smear, chip, cruft, drinking straw, rusty nails, wooden lath, mold fractal, layers, black and white, realistic</p>
</blockquote>

<p class="center"><img src="/assets/ai-art/mid_query_return.jpg" alt="midjourney returns some pretty cool cover art." width="100%" /></p>

<p>And we went with the image in the bottom left.</p>

<p class="center"><img src="/assets/ai-art/EIASC.jpg" alt="cover art of electricity is a scarce commodity." width="100%" /></p>

<p>The image didn’t have any obvious visual artifacts and looked like something Isaac might have found out in the world. Having read <a href="https://www.technologyreview.com/2022/09/16/1059598/this-artist-is-dominating-ai-generated-art-and-hes-not-happy-about-it/">recent reporting</a> on some rather suspect copyright infringement, Isaac and I wondered if midjourney had obviously just ripped off the image.</p>

<p>For a lot of the early <a href="https://openai.com/blog/dall-e/">DALL-E</a> memes that I saw on social media, I could often find strikingly similar pictures by pasting the prompt into google image search. But for Isaac’s mess prompt, we came up pretty empty, with some rather hilariously bad results.</p>

<p class="center"><img src="/assets/ai-art/google_image_stinks.png" alt="google image search results for Isaac's query." width="100%" /></p>

<p class="center"><img src="/assets/ai-art/google_image_stinks2.png" alt="more google image search results." width="100%" /></p>

<p><a href="http://vaishaal.com/">Vaishaal Shankar</a> then reminded me that there was a much better image search engine. The original <a href="https://openai.com/blog/dall-e/">DALL-E</a> model which started the prompt-to-image craze was based on a neural network model called <a href="https://openai.com/blog/clip/">CLIP</a> that learned a model to compare images and text. The model was trained on a huge data set of images paired with captions. It produced two functions: one that mapped images to a code book and one that mapped text to a code book. When you compared codes for two snippets of text, this would tell you how similar the snippets were. When you compared codes of two images, this would tell you how similar the images were. But one of the more amazing things about CLIP is that you could compare the codes of text and images and find images which were similar to the text.</p>

<p><a href="https://github.com/rom1504">Romain Beaumont</a> built an image search system, <a href="https://rom1504.github.io/clip-retrieval">clip-retrieval</a> that used CLIP and a new data set <a href="https://laion.ai/blog/laion-5b/">LAION-5B</a> consisting of 5 billion images scraped by <a href="https://commoncrawl.org/">common crawl</a>. 5 billion! (Insert Dr. Evil meme). Romain hosts a <a href="https://rom1504.github.io/clip-retrieval">free version of this system</a>, where you type some text, it computes the codebook, and it returns all of the images in LAION-5B which have similar codes to your text. We tried Isaac’s prompt here, and now found some strikingly similar images.</p>

<p class="center"><img src="/assets/ai-art/clip-retrieval-works.png" alt="clip-retrieval image search results for Isaac's query." width="100%" /></p>

<p>There were hundreds of art pieces and stock photos that captured elements of the spirit of the prompt. Again, with 5 billion images, it’s hard to imagine what’s not in there. But after scrolling through pages of similar images, we couldn’t find any of the four renderings produced by midjourney.</p>

<p>We tried the reverse image search in both clip-retrieval and google, and though we got back some similar textures, we couldn’t find the image itself.</p>

<p class="center"><img src="/assets/ai-art/clip-retrieval-image-search.png" alt="clip-retrieval reverse image search results for the cover art image." width="100%" /></p>

<p>Now, just because we didn’t find our image doesn’t mean it’s not in the corpus somewhere. We looked at around 100 images, but what if we had looked at 1000? Or 10000? Perhaps it’s buried in the corner of some thumbnail in the LAION set. The biggest flaw of these tools is making artist attribution impossible. There should be some simple way of tracing back to the training set. Without traceback and attribution, this is just going to lead to annoying copyright lawsuits like we saw in the early days of sampling in music. We’d be better off if we could avoid those legal battles before they happen.</p>

<p>All that said, it really seems like the midjourney neural nets are doing something more than re-displaying images from the training set. There are certainly billions of amazing textures out in the world, and CLIP-style models make them easier to bring to the surface. But midjourney adds something extra to fuse these textures into something new. It’s much more than a “copyright infringing blur filter” and that’s pretty cool!</p>

<p>I still maintain that AI was and is overhyped. We were promised self-driving cars and cures for cancer, and we ended up with splashy tools for image generation. I’m not sure we can justify the billions of dollars of investment. But the image processing tools are still super fun and I want more to play with, so I’ll be selfish and hope OpenAI raises more money. I hope future variants allow for clearer navigation and enable more intentional sampling and pastiche of the source materials. And I can’t wait until they figure out how to make a plugin for Ableton Live that scours huge audio libraries to produce melted sonic textures. At that point, you won’t hear from me as an AI skeptic anymore as I’ll be blissfully hiding in my music studio.</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:00:00Z">Wednesday, October 26 2022, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, October 25
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/25/tenure-track-faculty-at-university-of-rochester-apply-by-december-1-2022/'>Tenure-track Faculty at University of Rochester (apply by December 1, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The department of Computer Science at the University of Rochester is looking to hire three tenure-track faculty. One position is targeting cryptography/security but exceptional theory candidates in all other areas are welcome. Other positions are targeting computer systems and machine learning (broadly construed). Website: www.cs.rochester.edu/about/recruit.html#Faculty Email: kristi@cs.rochester.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The department of Computer Science at the University of Rochester is looking to hire three tenure-track faculty. One position is targeting cryptography/security but exceptional theory candidates in all other areas are welcome. Other positions are targeting computer systems and machine learning (broadly construed).</p>
<p>Website: <a href="https://www.cs.rochester.edu/about/recruit.html#Faculty">https://www.cs.rochester.edu/about/recruit.html#Faculty</a><br />
Email: kristi@cs.rochester.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T17:06:44Z">Tuesday, October 25 2022, 17:06</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2022/10/25/remarkable-limitations-of-linear-cross-entropy-as-a-measure-for-quantum-advantage-by-xun-gao-marcin-kalinowski-chi-ning-chou-mikhail-d-lukin-boaz-barak-and-soonwon-choi/'>Remarkable: “Limitations of Linear Cross-Entropy as a Measure for Quantum Advantage,” by Xun Gao, Marcin Kalinowski, Chi-Ning Chou, Mikhail D. Lukin, Boaz Barak, and Soonwon Choi</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this post I would like to report about an important paper (posted Dec. 2021) by Xun Gao, Marcin Kalinowski, Chi-Ning Chou, Mikhail D. Lukin, Boaz Barak, and Soonwon Choi. (I am thankful to Xun Gao and&#160; Boaz Barak for &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In this post I would like to report about an important paper (posted Dec. 2021) by Xun Gao, Marcin Kalinowski, Chi-Ning Chou, Mikhail D. Lukin, Boaz Barak, and Soonwon Choi. (I am thankful to Xun Gao and&nbsp; Boaz Barak for helpful discussions).</p>
<h3><a href="https://arxiv.org/abs/2112.01657">Limitations of Linear Cross-Entropy as a Measure for Quantum Advantage</a></h3>
<p>Here is the abstract:</p>
<blockquote><p><em> <span id="2112.01657v1-abstract-full" class="abstract-full has-text-grey-dark mathjax"> Demonstrating quantum advantage requires experimental implementation of a computational task that is hard to achieve using state-of-the-art classical systems. One approach is to perform sampling from a probability distribution associated with a class of highly entangled many-body wavefunctions. It has been suggested that this approach can be certified with the Linear Cross-Entropy Benchmark (XEB). We critically examine this notion. First, in a &#8220;benign&#8221; setting where an honest implementation of noisy quantum circuits is assumed, we characterize the conditions under which the XEB approximates the fidelity. Second, in an &#8220;adversarial&#8221; setting where all possible classical algorithms are considered for comparison, we show that achieving relatively high XEB values does not imply faithful simulation of quantum dynamics. We present an efficient classical algorithm that, with 1 GPU within 2s, yields high XEB values, namely 2-12% of those obtained in experiments. By identifying and exploiting several vulnerabilities of the XEB, we achieve high XEB values without full simulation of quantum circuits. Remarkably, our algorithm features better scaling with the system size than noisy quantum devices for commonly studied random circuit ensembles. To quantitatively explain the success of our algorithm and the limitations of the XEB, we use a theoretical framework in which the average XEB and fidelity are mapped to statistical models. We illustrate the relation between the XEB and the fidelity for quantum circuits in various architectures, with different gate choices, and in the presence of noise. Our results show that XEB&#8217;s utility as a proxy for fidelity hinges on several conditions, which must be checked in the benign setting but cannot be assumed in the adversarial setting. Thus, the XEB alone has limited utility as a benchmark for quantum advantage. We discuss ways to overcome these limitations.</span></em></p></blockquote>
<h2>I. Three parameters for noisy quantum circuits:</h2>
<ol>
<li><strong>F</strong> &#8211; The fidelity. If <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi" class="latex" /> is the ideal state and <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;psi" class="latex" /> is the noisy state, then the fidelity <strong>F</strong> is defined by <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%5Cleft+%7C+%5Cphi+%5Cright+%7C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%5Cleft+%7C+%5Cphi+%5Cright+%7C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%5Cleft+%7C+%5Cphi+%5Cright+%7C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle &#92;psi &#92;left | &#92;phi &#92;right | &#92;psi &#92;rangle" class="latex" />,</li>
<li><strong>XEB</strong> &#8211; the linear cross entropy estimator for the fidelity</li>
<li><strong>P(No err)</strong> &#8211; The probability of no errors (denoted in the paper by <img src="https://s0.wp.com/latex.php?latex=p_%7Bno%7Eerr%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_%7Bno%7Eerr%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_%7Bno%7Eerr%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_{no~err}" class="latex" />).</li>
</ol>
<h2>II. Some issues:</h2>
<p>a) The fidelity <strong>F</strong> cannot be read from the distribution of the samples produced by the quantum computer. Suppose we are given an unlimited number of samples (or a large number of samples for which the empirical distribution is a good approximation to the noisy distribution), what is the best way to estimate the fidelity?</p>
<p>b) If we have a polynomial number of samples in (1/F). What are the best ways to estimate the fidelity?</p>
<p>c) What in general are the relations between <strong>F</strong>, <strong>XEB</strong>, and <strong>P(No err)?</strong></p>
<h2>III. A basic observation:</h2>
<p>A basic observation of the paper is that when you apply depolarizing noise to the gates, the resulting distribution has a positive correlation to the ideal distribution. (Hence this leads to positive XEB value.)&nbsp; The basic idea (as I see it) is simple: let&#8217;s consider 1-gate which is a certain unitary operator U.<br />
The space of such operators is spanned by I, X, Y, and Z. Let us assume that applying to U unitary noise, say, Y, will lead to a new quantum circuit which gives uncorrelated samples and fidelity estimator 0. However, applying (I+X+Y+Z), which replace the qubit with a maximal entropy state is a very basic form of noise (depolarizing noise on the qubit on which the gate acts) and this form of noise is expected to slash the fidelity estimator by four and not send it to zero. (For 2-gates the story is similar but this time there are 16 basic possibilities for unitary noise so we can expect that a depolarizing noise will slash the linear cross entropy estimator by 1/16 (and not to zero).)</p>
<h2>IV. Additional observations</h2>
<p>The paper by Gao et al. describes various additional reasons for which the effect of gate errors will lead to positive correlations with the ideal distribution, and in general will lead to strict inequalities</p>
<p style="text-align:center;"><strong>(1) &nbsp; XEB &nbsp; &gt;&nbsp; P(No err) </strong></p>
<p>and</p>
<p style="text-align:center;"><strong>(2) &nbsp;</strong> <strong>XEB &gt; F &gt; P(No err) </strong></p>
<p>First, it turns out that even a single unitary gate error can contribute to the increase of <strong>XEB&nbsp; </strong>(and also to increase<strong> F)</strong>, and, moreover, the effect of two (or more) gate errors can also lead to an increased <strong>XEB (</strong>and also an increased <strong>F</strong>.)</p>
<p>In expectation we can actually expect.</p>
<p style="text-align:center;"><strong>(3) &nbsp;&nbsp; XEB &gt; F &gt; P(No err) </strong></p>
<p>This is demonstrated by Figure 1 of the paper.</p>
<h2><img loading="lazy" data-attachment-id="23473" data-permalink="https://gilkalai.wordpress.com/2022/10/25/remarkable-limitations-of-linear-cross-entropy-as-a-measure-for-quantum-advantage-by-xun-gao-marcin-kalinowski-chi-ning-chou-mikhail-d-lukin-boaz-barak-and-soonwon-choi/xungao/" data-orig-file="https://gilkalai.files.wordpress.com/2022/10/xungao.png" data-orig-size="337,578" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="XunGao" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/10/xungao.png?w=175" data-large-file="https://gilkalai.files.wordpress.com/2022/10/xungao.png?w=337" class="alignnone  wp-image-23473" src="https://gilkalai.files.wordpress.com/2022/10/xungao.png?w=310&#038;h=532" alt="XunGao" width="310" height="532" srcset="https://gilkalai.files.wordpress.com/2022/10/xungao.png?w=310&amp;h=532 310w, https://gilkalai.files.wordpress.com/2022/10/xungao.png?w=87&amp;h=150 87w, https://gilkalai.files.wordpress.com/2022/10/xungao.png?w=175&amp;h=300 175w, https://gilkalai.files.wordpress.com/2022/10/xungao.png 337w" sizes="(max-width: 310px) 100vw, 310px"></h2>
<h2>V. The idea behind the spoofing algorithm</h2>
<p>The way Gao, Kalinowski, Chou, Lukin, Barak, and Choi used this observation is by applying such depolarization noise on a set of 2-gates that would split the circuit into two parts. This will lead to a sort of &#8220;patched&#8221; circuit for which one can make the computation separately on every patch, which gives much quicker classical algorithms.</p>
<h2>VI The asymptotic behavior</h2>
<p>One interesting aspect of the paper is that (as far as I could understand) when the number of qubits grows the &#8220;quantum advantage&#8221; , namely the advantage of the quantum algorithms over the classical algorithms, diminishes. As Gao et al. write</p>
<blockquote><p><span style="color:#0000ff;"><em>&#8220;Remarkably, the <strong>XEB </strong></em><em>value of our algorithm generally improves for larger </em><em>quantum circuits, whereas that of noisy quantum </em><em>devices quickly deteriorates. Such scaling continues to hold when the number of qubits is increased </em><em>while the depth of the circuit and the error-per-gate </em><em>are fixed&#8230;&#8221;</em></span></p></blockquote>
<p>Remark: This conclusion assumes that you need enough samples to verify the fidelity. Philosophically one can claim that the quantum advantage may apply for producing *one* sample; After all, your argument is based anyway on extrapolation, and for supremacy experiments you cannot verify even the individual amplitudes. (I made this claim in a discussion with Daniel Lidar regarding the very nice paper by <span dir="ltr" role="presentation">Zlokapa, Boixo, and Lidar, <a href="https://arxiv.org/abs/2005.02464">Boundaries of quantum supremacy </a></span><span dir="ltr" role="presentation">via random circuit sampling,</span> but I couldn&#8217;t persuade Daniel.)</p>
<h2>VII Relevance to the statistical analysis and the concerns regarding the Google 2019 experiment</h2>
<p>The paper is relevant to two important aspects of my <a href="https://gilkalai.files.wordpress.com/2022/08/sts836.pdf">statistical science paper</a> with Yosi Rinott and Tomer Shoham and to our work which puts the Google 2019 experiment under scrutiny.</p>
<ol>
<li>The fact that <strong>XEB</strong> is systematically larger than <strong>P(No err)</strong> may support the concern that the precise agreement of the <strong>XEB</strong> estimator with the <strong>P(No err)</strong> computation (Formula (77)) is &#8220;too good to be true,&#8221; namely, it fits too well with the researcher&#8217;s expectations rather than with physical reality.</li>
<li>The basic observation (III) implies that the exponential decay for the Fourier coefficients with the degrees, that we attributed only to readout errors is also caused by gate errors. Subsequently, the Fourier description of the data that we regarded as providing confirmation to the Google claim (see, Figure 2 in <a href="https://arxiv.org/abs/2210.12753">our recent paper</a>) actually appears to show that the empirical data does not fit the theory.</li>
</ol>
<p>Apropos Fourier methods and Xun Gao: The first I heard of Xun Gao&#8217;s work was in connection with his excellent early work with Duan <a href="https://arxiv.org/abs/1810.03176">Efficient classical simulation of noisy quantum computation</a> that used Fourier methods to study quantum circuits.</p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T04:59:48Z">Tuesday, October 25 2022, 04:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://theorydish.blog/2022/10/24/9th-toca-sv-11-18/'>9th TOCA-SV – 11/18</a></h3>
        <p class='tr-article-feed'>from <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The 9th TOCA-SV day is Coming on Friday 11/18/22, in the Google campus in Mountain View. It is free but you need to register here, where you can also see an up-to-date list of talks and abstracts. Schedule (tentative): 0930-1000: Breakfast 1000-1015: Welcome 1015-1100: Gagan Aggarwal (Google) 1100-1145: Li-Yang Tan (Stanford) 1145-1245: Short talks I 1245-1400: Lunch (provided) and campus tour 1400-1445: Sandy Irani (Simons/UC Berkeley) 1445-1530: Kunal Talwar (Apple) 1530-1600: Coffee Break 1600-1730: Short talks II
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The 9th TOCA-SV day is Coming on Friday 11/18/22, in the Google campus in Mountain View. It is free but you need to register <a href="https://sites.google.com/view/9th-toca-sv-nov-18-2022/">here</a>, where you can also see an up-to-date list of talks and abstracts.</p>
<div class="CjVfdc">Schedule (tentative):</div>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>0930-1000: Breakfast</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1000-1015: Welcome</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1015-1100: Gagan Aggarwal (Google)</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1100-1145: Li-Yang Tan (Stanford)</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1145-1245: Short talks I</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1245-1400: Lunch</strong><strong> (provided) </strong><strong>and campus tour</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1400-1445: Sandy Irani (Simons/UC Berkeley)</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1445-1530: Kunal Talwar (Apple)</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1530-1600: Coffee Break</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1600-1730: Short talks II</strong></p>
<p class="authors">By Omer Reingold</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T04:34:04Z">Tuesday, October 25 2022, 04:34</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12289'>Complexity and Ramsey Largeness of Sets of Oracles Separating Complexity Classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alex Creiner, Stephen Jackson</p><p>We prove two sets of results concerning computational complexity classes. The
first concerns a variation of the random oracle hypothesis posed by Bennett and
Gill after they showed that relative to a randomly chosen oracle, P not equal
NP with probability 1. This hypothesis was quickly disproven in several ways,
most famously in 1992 with the result that IP equals PSPACE, in spite of the
classes being shown unequal with probability 1. Here we propose a variation of
what it means to be ``large'' using the Ellentuck topology. In this new
context, we demonstrate that the set of oracles separating NP and co-NP is not
small, and obtain similar results for the separation of PSPACE from PH along
with the separation of NP from BQP. We demonstrate that this version of the
hypothesis turns it into a sufficient condition for unrelativized
relationships, at least in the three cases considered here. Second, we example
the descriptive complexity of the classes of oracles providing the separations
for these various classes, and determine their exact placement in the Borel
hierarchy.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Creiner_A/0/1/0/all/0/1">Alex Creiner</a>, <a href="http://arxiv.org/find/math/1/au:+Jackson_S/0/1/0/all/0/1">Stephen Jackson</a></p><p>We prove two sets of results concerning computational complexity classes. The
first concerns a variation of the random oracle hypothesis posed by Bennett and
Gill after they showed that relative to a randomly chosen oracle, P not equal
NP with probability 1. This hypothesis was quickly disproven in several ways,
most famously in 1992 with the result that IP equals PSPACE, in spite of the
classes being shown unequal with probability 1. Here we propose a variation of
what it means to be ``large'' using the Ellentuck topology. In this new
context, we demonstrate that the set of oracles separating NP and co-NP is not
small, and obtain similar results for the separation of PSPACE from PH along
with the separation of NP from BQP. We demonstrate that this version of the
hypothesis turns it into a sufficient condition for unrelativized
relationships, at least in the three cases considered here. Second, we example
the descriptive complexity of the classes of oracles providing the separations
for these various classes, and determine their exact placement in the Borel
hierarchy.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T00:30:00Z">Tuesday, October 25 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12438'>Algorithms with Prediction Portfolios</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, Sergei Vassilvitskii</p><p>The research area of algorithms with predictions has seen recent success
showing how to incorporate machine learning into algorithm design to improve
performance when the predictions are correct, while retaining worst-case
guarantees when they are not. Most previous work has assumed that the algorithm
has access to a single predictor. However, in practice, there are many machine
learning methods available, often with incomparable generalization guarantees,
making it hard to pick a best method a priori. In this work we consider
scenarios where multiple predictors are available to the algorithm and the
question is how to best utilize them.
</p>
<p>Ideally, we would like the algorithm's performance to depend on the quality
of the best predictor. However, utilizing more predictions comes with a cost,
since we now have to identify which prediction is the best. We study the use of
multiple predictors for a number of fundamental problems, including matching,
load balancing, and non-clairvoyant scheduling, which have been well-studied in
the single predictor setting. For each of these problems we introduce new
algorithms that take advantage of multiple predictors, and prove bounds on the
resulting performance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dinitz_M/0/1/0/all/0/1">Michael Dinitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Im_S/0/1/0/all/0/1">Sungjin Im</a>, <a href="http://arxiv.org/find/cs/1/au:+Lavastida_T/0/1/0/all/0/1">Thomas Lavastida</a>, <a href="http://arxiv.org/find/cs/1/au:+Moseley_B/0/1/0/all/0/1">Benjamin Moseley</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilvitskii_S/0/1/0/all/0/1">Sergei Vassilvitskii</a></p><p>The research area of algorithms with predictions has seen recent success
showing how to incorporate machine learning into algorithm design to improve
performance when the predictions are correct, while retaining worst-case
guarantees when they are not. Most previous work has assumed that the algorithm
has access to a single predictor. However, in practice, there are many machine
learning methods available, often with incomparable generalization guarantees,
making it hard to pick a best method a priori. In this work we consider
scenarios where multiple predictors are available to the algorithm and the
question is how to best utilize them.
</p>
<p>Ideally, we would like the algorithm's performance to depend on the quality
of the best predictor. However, utilizing more predictions comes with a cost,
since we now have to identify which prediction is the best. We study the use of
multiple predictors for a number of fundamental problems, including matching,
load balancing, and non-clairvoyant scheduling, which have been well-studied in
the single predictor setting. For each of these problems we introduce new
algorithms that take advantage of multiple predictors, and prove bounds on the
resulting performance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T00:30:00Z">Tuesday, October 25 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12468'>Discrepancy Minimization in Input-Sparsity Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yichuan Deng, Zhao Song, Omri Weinstein</p><p>A recent work of Larsen [Lar23] gave a faster combinatorial alternative to
Bansal's SDP algorithm for finding a coloring $x\in\{-1,1\}^n$ that
approximately minimizes the discrepancy $\mathrm{disc}(A,x) : = \| A x
\|_{\infty}$ of a general real-valued $m\times n$ matrix $A$. Larsen's
algorithm runs in $\widetilde{O}(mn^2)$ time compared to Bansal's
$\widetilde{O}(mn^{4.5})$-time algorithm, at the price of a slightly weaker
logarithmic approximation ratio in terms of the hereditary discrepancy of $A$
[Ban10].
</p>
<p>In this work we present a combinatorial $\widetilde{O}(\mathrm{nnz}(A) +
n^3)$ time algorithm with the same approximation guarantee as Larsen, which is
optimal for tall matrices $m=\mathrm{poly}(n)$. Using a more intricate analysis
and fast matrix-multiplication, we achieve $\widetilde{O}(\mathrm{nnz}(A) +
n^{2.53})$ time, which breaks cubic runtime for square matrices, and bypasses
the barrier of linear-programming approaches [ES14] for which input-sparsity
time is currently out of reach.
</p>
<p>Our algorithm relies on two main ideas: (i) A new sketching technique for
finding a projection matrix with short $\ell_2$-basis using implicit
leverage-score sampling; (ii) A data structure for faster implementation of the
iterative Edge-Walk partial-coloring algorithm of Lovett-Meka, using an
alternative analysis that enables ``lazy" batch-updates with low-rank
corrections. Our result nearly closes the computational gap between real-valued
and binary matrices (set-systems), for which input-sparsity time coloring was
very recently obtained [JSS23].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yichuan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinstein_O/0/1/0/all/0/1">Omri Weinstein</a></p><p>A recent work of Larsen [Lar23] gave a faster combinatorial alternative to
Bansal's SDP algorithm for finding a coloring $x\in\{-1,1\}^n$ that
approximately minimizes the discrepancy $\mathrm{disc}(A,x) : = \| A x
\|_{\infty}$ of a general real-valued $m\times n$ matrix $A$. Larsen's
algorithm runs in $\widetilde{O}(mn^2)$ time compared to Bansal's
$\widetilde{O}(mn^{4.5})$-time algorithm, at the price of a slightly weaker
logarithmic approximation ratio in terms of the hereditary discrepancy of $A$
[Ban10].
</p>
<p>In this work we present a combinatorial $\widetilde{O}(\mathrm{nnz}(A) +
n^3)$ time algorithm with the same approximation guarantee as Larsen, which is
optimal for tall matrices $m=\mathrm{poly}(n)$. Using a more intricate analysis
and fast matrix-multiplication, we achieve $\widetilde{O}(\mathrm{nnz}(A) +
n^{2.53})$ time, which breaks cubic runtime for square matrices, and bypasses
the barrier of linear-programming approaches [ES14] for which input-sparsity
time is currently out of reach.
</p>
<p>Our algorithm relies on two main ideas: (i) A new sketching technique for
finding a projection matrix with short $\ell_2$-basis using implicit
leverage-score sampling; (ii) A data structure for faster implementation of the
iterative Edge-Walk partial-coloring algorithm of Lovett-Meka, using an
alternative analysis that enables ``lazy" batch-updates with low-rank
corrections. Our result nearly closes the computational gap between real-valued
and binary matrices (set-systems), for which input-sparsity time coloring was
very recently obtained [JSS23].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T00:30:00Z">Tuesday, October 25 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12495'>Quartic Samples Suffice for Fourier Interpolation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhao Song, Baocheng Sun, Omri Weinstein, Ruizhe Zhang</p><p>We study the classic problem of interpolating a Fourier-sparse signal in the
time duration $[0, T]$ from noisy samples in the same range, where the ground
truth signal can be any $k$-Fourier-sparse signal with band-limit $[-F, F]$.
Our main result is an efficient Fourier Interpolation algorithm that improves
the previous best algorithm by [Chen, Kane, Price and Song, FOCS 2016] in the
following three aspects:
</p>
<p>$\bullet$ The sample complexity is improved from $\widetilde{O}(k^{51})$ to
$\widetilde{O}(k^{4})$.
</p>
<p>$\bullet$ The time complexity is improved from $
\widetilde{O}(k^{10\omega+40})$ to $\widetilde{O}(k^{4 \omega})$.
</p>
<p>$\bullet$ The output sparsity is improved from $\widetilde{O}(k^{10})$ to
$\widetilde{O}(k^{4})$.
</p>
<p>Here, $\omega$ denotes the exponent of fast matrix multiplication. The
state-of-the-art sample complexity of this problem is $\widetilde{O}(k)$, but
can only be achieved by an *exponential-time* algorithm. Our algorithm uses
slightly more samples ($\sim k^4$) in exchange for small polynomial runtime,
laying the groundwork for a practical Fourier Interpolation algorithm.
</p>
<p>The centerpiece of our algorithm is a new sufficient condition for the
frequency estimation task -- a high signal-to-noise (SNR) band condition --
which allows for efficient and accurate signal reconstruction. Based on this
condition together with a new structural decomposition of Fourier signals
(Signal Equivalent Method), we design a cheap algorithm for estimating each
"significant" frequency within a narrow range, which is then combined with a
new high-accuracy signal estimation algorithm to reconstruct the ground-truth
signal.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1">Baocheng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinstein_O/0/1/0/all/0/1">Omri Weinstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruizhe Zhang</a></p><p>We study the classic problem of interpolating a Fourier-sparse signal in the
time duration $[0, T]$ from noisy samples in the same range, where the ground
truth signal can be any $k$-Fourier-sparse signal with band-limit $[-F, F]$.
Our main result is an efficient Fourier Interpolation algorithm that improves
the previous best algorithm by [Chen, Kane, Price and Song, FOCS 2016] in the
following three aspects:
</p>
<p>$\bullet$ The sample complexity is improved from $\widetilde{O}(k^{51})$ to
$\widetilde{O}(k^{4})$.
</p>
<p>$\bullet$ The time complexity is improved from $
\widetilde{O}(k^{10\omega+40})$ to $\widetilde{O}(k^{4 \omega})$.
</p>
<p>$\bullet$ The output sparsity is improved from $\widetilde{O}(k^{10})$ to
$\widetilde{O}(k^{4})$.
</p>
<p>Here, $\omega$ denotes the exponent of fast matrix multiplication. The
state-of-the-art sample complexity of this problem is $\widetilde{O}(k)$, but
can only be achieved by an *exponential-time* algorithm. Our algorithm uses
slightly more samples ($\sim k^4$) in exchange for small polynomial runtime,
laying the groundwork for a practical Fourier Interpolation algorithm.
</p>
<p>The centerpiece of our algorithm is a new sufficient condition for the
frequency estimation task -- a high signal-to-noise (SNR) band condition --
which allows for efficient and accurate signal reconstruction. Based on this
condition together with a new structural decomposition of Fourier signals
(Signal Equivalent Method), we design a cheap algorithm for estimating each
"significant" frequency within a narrow range, which is then combined with a
new high-accuracy signal estimation algorithm to reconstruct the ground-truth
signal.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T00:30:00Z">Tuesday, October 25 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12543'>Edge-weighted Online Stochastic Matching: Beating $1-\frac1e$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shuyi Yan</p><p>We study the edge-weighted online stochastic matching problem. Since Feldman,
Mehta, Mirrokni, and Muthukrishnan proposed the $(1-\frac1e)$-competitive
Suggested Matching algorithm, there has been no improvement for the general
edge-weighted online stochastic matching problem. In this paper, we introduce
the first algorithm beating the $1-\frac1e$ bound in this setting, achieving a
competitive ratio of $0.645$. Under the LP proposed by Jaillet and Lu, we
design an algorithmic preprocessing, dividing all edges into two classes. Then
based on the Suggested Matching algorithm, we adjust the matching strategy to
improve the performance on one class in the early stage and on another class in
the late stage, while keeping the matching events of different edges highly
independent. By balancing them, we guarantee the matching probability of every
single edge.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Shuyi Yan</a></p><p>We study the edge-weighted online stochastic matching problem. Since Feldman,
Mehta, Mirrokni, and Muthukrishnan proposed the $(1-\frac1e)$-competitive
Suggested Matching algorithm, there has been no improvement for the general
edge-weighted online stochastic matching problem. In this paper, we introduce
the first algorithm beating the $1-\frac1e$ bound in this setting, achieving a
competitive ratio of $0.645$. Under the LP proposed by Jaillet and Lu, we
design an algorithmic preprocessing, dividing all edges into two classes. Then
based on the Suggested Matching algorithm, we adjust the matching strategy to
improve the performance on one class in the early stage and on another class in
the late stage, while keeping the matching events of different edges highly
independent. By balancing them, we guarantee the matching probability of every
single edge.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T00:30:00Z">Tuesday, October 25 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, October 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/24/research-fellowship-at-simons-institute-for-the-theory-of-computing-apply-by-december-15-2022/'>Research Fellowship at Simons Institute for the Theory of Computing (apply by December 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Simons Institute invites applications for Simons-Berkeley Research Fellowships for the Summer 2023, Fall 2023, and Spring 2024 semesters. Simons-Berkeley Research Fellowships are intended for exceptional scientists to participate in at least one of the semester-long programs at the institute. Website: simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications Email: simonsvisitorservices@berkeley.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Simons Institute invites applications for Simons-Berkeley Research Fellowships for the Summer 2023, Fall 2023, and Spring 2024 semesters. Simons-Berkeley Research Fellowships are intended for exceptional scientists to participate in at least one of the semester-long programs at the institute.</p>
<p>Website: <a href="https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications">https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications</a><br />
Email: simonsvisitorservices@berkeley.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T22:40:28Z">Monday, October 24 2022, 22:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/10/cheating-in-chess-and-in-class.html'>Cheating in Chess and in Class</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>In the 24th move of the second game of the 1978 Chess Championship, a cup of blueberry yogurt was delivered to the defending champion&nbsp;Anatoly Karpov who offered a draw shortly thereafter. The challenger&nbsp;Victor Korchnoi claimed the flavor of yogurt was a coded message to Karpov and later in the tournament all food deliveries had to be decided on in advance. The good old days.</p><p>With computer chess programs now far more powerful than humans, chess cheating has become far more common and came to a head last month with the controversy between Magnus Carlsen and Hans Niemann. Did Niemann cheat to win in his win over Carlsen in St. Louis or was it just a rare upset? How can we tell?</p><p>This brings up cheating by students in class. Reports and statistics show that cheating has increased over the last few years. The pandemic played a role, but a good rule is that pandemic didn't change behaviors, rather accelerated changes already in progress. Technology has made it easier to cheat. It's difficult to near impossible to create a homework problem where someone couldn't just look up an answer. Sites like Chegg&nbsp;provide solutions to all sorts of problems while there are many sites where you can hire someone to write a paper or do a project for you. Advances in generative AI, like GPT-3 and GitHub co-pilot will soon make cheating as easy as clicking a button.</p><p>But it's more than technology. As students view university education less about learning and more about getting the credentials for a job, the inhibitions to cheat disappear. And while the vast majority of students don't significantly cheat, it's hard for anyone to avoid using Google when they get stuck on a problem.&nbsp;</p><p>We can continue to use technology to fight the technology in a every growing arms race to catch cheaters but it can feel like a losing war. We should take solace that the students who work hard solving problems and projects will be the ones who will succeed in life.&nbsp;</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In the 24th move of the second game of the 1978 Chess Championship, a cup of blueberry yogurt was delivered to the defending champion&nbsp;Anatoly Karpov who offered a draw shortly thereafter. The challenger&nbsp;Victor Korchnoi claimed the flavor of yogurt was a coded message to Karpov and later in the tournament all food deliveries had to be decided on in advance. The good old days.</p><p>With computer chess programs now far more powerful than humans, chess cheating has become far more common and came to a head last month with the controversy between <a href="https://en.wikipedia.org/wiki/Carlsen%E2%80%93Niemann_controversy">Magnus Carlsen and Hans Niemann</a>. Did Niemann cheat to win in his win over Carlsen in St. Louis or was it just a rare upset? How can we tell?</p><p>This brings up cheating by students in class. <a href="https://www.npr.org/2021/08/27/1031255390/reports-of-cheating-at-colleges-soar-during-the-pandemic">Reports</a> and <a href="https://academicintegrity.org/resources/facts-and-statistics">statistics</a> show that cheating has increased over the last few years. The pandemic played a role, but a good rule is that pandemic didn't change behaviors, rather accelerated changes already in progress. Technology has made it easier to cheat. It's difficult to near impossible to create a homework problem where someone couldn't just look up an answer. Sites like Chegg&nbsp;provide solutions to all sorts of problems while there are many sites where you can hire someone to write a paper or do a project for you. Advances in generative AI, like GPT-3 and GitHub co-pilot will soon make cheating as easy as clicking a button.</p><p>But it's more than technology. As students view university education less about learning and more about getting the credentials for a job, the inhibitions to cheat disappear. And while the vast majority of students don't significantly cheat, it's hard for anyone to avoid using Google when they get stuck on a problem.&nbsp;</p><p>We can continue to use technology to fight the technology in a every growing arms race to catch cheaters but it can feel like a losing war. We should take solace that the students who work hard solving problems and projects will be the ones who will succeed in life.&nbsp;</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T14:04:00Z">Monday, October 24 2022, 14:04</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11568'>Polynomial computational complexity of matrix elements of finite-rank-generated single-particle operators in products of finite bosonic states</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dmitri A. Ivanov</p><p>It is known that computing the permanent $\mathop{\rm Per}(1+A)$, where $A$
is a finite-rank matrix requires a number of operations polynomial in the
matrix size. I generalize this result to the expectation values
$\left\langle\Psi| P(1+A) |\Psi\right\rangle$, where $P()$ is the
multiplicative extension of a single-particle operator and
$\left|\Psi\right\rangle$ is a product of a large number of identical finite
bosonic states (i.e. bosonic states with a bounded number of bosons). I also
improve an earlier polynomial estimate for the fermionic version of the same
problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Ivanov_D/0/1/0/all/0/1">Dmitri A. Ivanov</a></p><p>It is known that computing the permanent $\mathop{\rm Per}(1+A)$, where $A$
is a finite-rank matrix requires a number of operations polynomial in the
matrix size. I generalize this result to the expectation values
$\left\langle\Psi| P(1+A) |\Psi\right\rangle$, where $P()$ is the
multiplicative extension of a single-particle operator and
$\left|\Psi\right\rangle$ is a product of a large number of identical finite
bosonic states (i.e. bosonic states with a bounded number of bosons). I also
improve an earlier polynomial estimate for the fermionic version of the same
problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12036'>On the Longest Flip Sequence to Untangle Segments in the Plane</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guilherme D. da Fonseca, Yan Gerard, Bastien Rivier</p><p>A set of segments in the plane may form a Euclidean TSP tour or a matching.
Optimal TSP tours as well as minimum weight perfect matchings have no crossing
segments, but several heuristics and approximation algorithms may produce
solutions with crossings. To improve such solutions, we can successively apply
a flip operation that replaces a pair of crossing segments by non-crossing
ones. This paper considers the maximum number D(n) of flips performed on n
segments. First, we present reductions relating D(n) for different versions of
matchings and the TSP tour. Second, we show that if all except t points are in
convex position, then D(n) = O(tn^2), providing a smooth transition between the
convex O(n^2) bound and the general O(n^3) bound. Last, we show that if instead
of counting the total number of flips, we only count the number of distinct
flips, then the cubic upper bound improves to O(n^{8/3}).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fonseca_G/0/1/0/all/0/1">Guilherme D. da Fonseca</a>, <a href="http://arxiv.org/find/cs/1/au:+Gerard_Y/0/1/0/all/0/1">Yan Gerard</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivier_B/0/1/0/all/0/1">Bastien Rivier</a></p><p>A set of segments in the plane may form a Euclidean TSP tour or a matching.
Optimal TSP tours as well as minimum weight perfect matchings have no crossing
segments, but several heuristics and approximation algorithms may produce
solutions with crossings. To improve such solutions, we can successively apply
a flip operation that replaces a pair of crossing segments by non-crossing
ones. This paper considers the maximum number D(n) of flips performed on n
segments. First, we present reductions relating D(n) for different versions of
matchings and the TSP tour. Second, we show that if all except t points are in
convex position, then D(n) = O(tn^2), providing a smooth transition between the
convex O(n^2) bound and the general O(n^3) bound. Last, we show that if instead
of counting the total number of flips, we only count the number of distinct
flips, then the cubic upper bound improves to O(n^{8/3}).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12015'>Blocking Delaunay Triangulations from the Exterior</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Oswin Aichholzer, Thomas Hackl, Maarten L&#xf6;ffler, Alexander Pilz, Irene Parada, Manfred Scheucher, Birgit Vogtenhuber</p><p>Given two distinct point sets $P$ and $Q$ in the plane, we say that $Q$
\emph{blocks} $P$ if no two points of $P$ are adjacent in any Delaunay
triangulation of $P\cup Q$. Aichholzer et al. (2013) showed that any set $P$ of
$n$ points in general position can be blocked by $\frac{3}{2}n$ points and that
every set $P$ of $n$ points in convex position can be blocked by $\frac{5}{4}n$
points. Moreover, they conjectured that, if $P$ is in convex position, $n$
blocking points are sufficient and necessary. The necessity was recently shown
by Biniaz (2021) who proved that every point set in general position requires
$n$ blocking points.
</p>
<p>Here we investigate the variant, where blocking points can only lie outside
of the convex hull of the given point set. We show that $\frac{5}{4}n-O(1)$
such \emph{exterior-blocking} points are sometimes necessary, even if the given
point set is in convex position. As a consequence we obtain that, if the
conjecture of Aichholzer et al. for the original setting was true, then minimal
blocking sets of some point configurations $P$ would have to contain points
inside of the convex hull of $P$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aichholzer_O/0/1/0/all/0/1">Oswin Aichholzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Hackl_T/0/1/0/all/0/1">Thomas Hackl</a>, <a href="http://arxiv.org/find/cs/1/au:+Loffler_M/0/1/0/all/0/1">Maarten L&#xf6;ffler</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilz_A/0/1/0/all/0/1">Alexander Pilz</a>, <a href="http://arxiv.org/find/cs/1/au:+Parada_I/0/1/0/all/0/1">Irene Parada</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheucher_M/0/1/0/all/0/1">Manfred Scheucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogtenhuber_B/0/1/0/all/0/1">Birgit Vogtenhuber</a></p><p>Given two distinct point sets $P$ and $Q$ in the plane, we say that $Q$
\emph{blocks} $P$ if no two points of $P$ are adjacent in any Delaunay
triangulation of $P\cup Q$. Aichholzer et al. (2013) showed that any set $P$ of
$n$ points in general position can be blocked by $\frac{3}{2}n$ points and that
every set $P$ of $n$ points in convex position can be blocked by $\frac{5}{4}n$
points. Moreover, they conjectured that, if $P$ is in convex position, $n$
blocking points are sufficient and necessary. The necessity was recently shown
by Biniaz (2021) who proved that every point set in general position requires
$n$ blocking points.
</p>
<p>Here we investigate the variant, where blocking points can only lie outside
of the convex hull of the given point set. We show that $\frac{5}{4}n-O(1)$
such \emph{exterior-blocking} points are sometimes necessary, even if the given
point set is in convex position. As a consequence we obtain that, if the
conjecture of Aichholzer et al. for the original setting was true, then minimal
blocking sets of some point configurations $P$ would have to contain points
inside of the convex hull of $P$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11778'>Rerouting Planar Curves and Disjoint Paths</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Takehiro Ito, Yuni Iwamasa, Naonori Kakimura, Yusuke Kobayashi, Shun-ichi Maezawa, Yuta Nozaki, Yoshio Okamoto, Kenta Ozeki</p><p>In this paper, we consider a transformation of $k$ disjoint paths in a graph.
For a graph and a pair of $k$ disjoint paths $\mathcal{P}$ and $\mathcal{Q}$
connecting the same set of terminal pairs, we aim to determine whether
$\mathcal{P}$ can be transformed to $\mathcal{Q}$ by repeatedly replacing one
path with another path so that the intermediates are also $k$ disjoint paths.
The problem is called Disjoint Paths Reconfiguration. We first show that
Disjoint Paths Reconfiguration is PSPACE-complete even when $k=2$. On the other
hand, we prove that, when the graph is embedded on a plane and all paths in
$\mathcal{P}$ and $\mathcal{Q}$ connect the boundaries of two faces, Disjoint
Paths Reconfiguration can be solved in polynomial time. The algorithm is based
on a topological characterization for rerouting curves on a plane using the
algebraic intersection number. We also consider a transformation of disjoint
$s$-$t$ paths as a variant. We show that the disjoint $s$-$t$ paths
reconfiguration problem in planar graphs can be determined in polynomial time,
while the problem is PSPACE-complete in general.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ito_T/0/1/0/all/0/1">Takehiro Ito</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwamasa_Y/0/1/0/all/0/1">Yuni Iwamasa</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakimura_N/0/1/0/all/0/1">Naonori Kakimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1">Yusuke Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Maezawa_S/0/1/0/all/0/1">Shun-ichi Maezawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Nozaki_Y/0/1/0/all/0/1">Yuta Nozaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Okamoto_Y/0/1/0/all/0/1">Yoshio Okamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozeki_K/0/1/0/all/0/1">Kenta Ozeki</a></p><p>In this paper, we consider a transformation of $k$ disjoint paths in a graph.
For a graph and a pair of $k$ disjoint paths $\mathcal{P}$ and $\mathcal{Q}$
connecting the same set of terminal pairs, we aim to determine whether
$\mathcal{P}$ can be transformed to $\mathcal{Q}$ by repeatedly replacing one
path with another path so that the intermediates are also $k$ disjoint paths.
The problem is called Disjoint Paths Reconfiguration. We first show that
Disjoint Paths Reconfiguration is PSPACE-complete even when $k=2$. On the other
hand, we prove that, when the graph is embedded on a plane and all paths in
$\mathcal{P}$ and $\mathcal{Q}$ connect the boundaries of two faces, Disjoint
Paths Reconfiguration can be solved in polynomial time. The algorithm is based
on a topological characterization for rerouting curves on a plane using the
algebraic intersection number. We also consider a transformation of disjoint
$s$-$t$ paths as a variant. We show that the disjoint $s$-$t$ paths
reconfiguration problem in planar graphs can be determined in polynomial time,
while the problem is PSPACE-complete in general.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11542'>Sketching Meets Differential Privacy: Fast Algorithm for Dynamic Kronecker Projection Maintenance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhao Song, Xin Yang, Yuanyuan Yang, Lichen Zhang</p><p>Projection maintenance is one of the core data structure tasks. Efficient
data structures for projection maintenance have led to recent breakthroughs in
many convex programming algorithms. In this work, we further extend this
framework to the Kronecker product structure. Given a constraint matrix ${\sf
A}$ and a positive semi-definite matrix $W\in \mathbb{R}^{n\times n}$ with a
sparse eigenbasis, we consider the task of maintaining the projection in the
form of ${\sf B}^\top({\sf B}{\sf B}^\top)^{-1}{\sf B}$, where ${\sf B}={\sf
A}(W\otimes I)$ or ${\sf B}={\sf A}(W^{1/2}\otimes W^{1/2})$. At each
iteration, the weight matrix $W$ receives a low rank change and we receive a
new vector $h$. The goal is to maintain the projection matrix and answer the
query ${\sf B}^\top({\sf B}{\sf B}^\top)^{-1}{\sf B}h$ with good approximation
guarantees. We design a fast dynamic data structure for this task and it is
robust against an adaptive adversary. Following the work of [Beimel, Kaplan,
Mansour, Nissim, Saranurak and Stemmer, STOC'22], we use tools from
differential privacy to reduce the randomness required by the data structure
and further improve the running time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuanyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lichen Zhang</a></p><p>Projection maintenance is one of the core data structure tasks. Efficient
data structures for projection maintenance have led to recent breakthroughs in
many convex programming algorithms. In this work, we further extend this
framework to the Kronecker product structure. Given a constraint matrix ${\sf
A}$ and a positive semi-definite matrix $W\in \mathbb{R}^{n\times n}$ with a
sparse eigenbasis, we consider the task of maintaining the projection in the
form of ${\sf B}^\top({\sf B}{\sf B}^\top)^{-1}{\sf B}$, where ${\sf B}={\sf
A}(W\otimes I)$ or ${\sf B}={\sf A}(W^{1/2}\otimes W^{1/2})$. At each
iteration, the weight matrix $W$ receives a low rank change and we receive a
new vector $h$. The goal is to maintain the projection matrix and answer the
query ${\sf B}^\top({\sf B}{\sf B}^\top)^{-1}{\sf B}h$ with good approximation
guarantees. We design a fast dynamic data structure for this task and it is
robust against an adaptive adversary. Following the work of [Beimel, Kaplan,
Mansour, Nissim, Saranurak and Stemmer, STOC'22], we use tools from
differential privacy to reduce the randomness required by the data structure
and further improve the running time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11570'>Online Resource Allocation with Buyback: Optimal Algorithms via Primal-Dual</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Farbod Ekbatani, Yiding Feng, Rad Niazadeh</p><p>Motivated by applications in cloud computing spot markets and selling banner
ads on popular websites, we study the online resource allocation problem with
"costly buyback". To model this problem, we consider the classic edge-weighted
fractional online matching problem with a tweak, where the decision maker can
recall (i.e., buyback) any fraction of an offline resource that is
pre-allocated to an earlier online vertex; however, by doing so not only the
decision maker loses the previously allocated reward (which equates the
edge-weight), it also has to pay a non-negative constant factor $f$ of this
edge-weight as an extra penalty. Parameterizing the problem by the buyback
factor $f$, our main result is obtaining optimal competitive algorithms for all
possible values of $f$ through a novel primal-dual family of algorithms. We
establish the optimality of our results by obtaining separate lower-bounds for
each of small and large buyback factor regimes, and showing how our primal-dual
algorithm exactly matches this lower-bound by appropriately tuning a parameter
as a function of $f$. We further study lower and upper bounds on the
competitive ratio in variants of this model, e.g., single-resource with
different demand sizes, or matching with deterministic integral allocations. We
show how algorithms in the our family of primal-dual algorithms can obtain the
exact optimal competitive ratio in all of these variants -- which in turn
demonstrates the power of our algorithmic framework for online resource
allocations with costly buyback.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ekbatani_F/0/1/0/all/0/1">Farbod Ekbatani</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yiding Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Niazadeh_R/0/1/0/all/0/1">Rad Niazadeh</a></p><p>Motivated by applications in cloud computing spot markets and selling banner
ads on popular websites, we study the online resource allocation problem with
"costly buyback". To model this problem, we consider the classic edge-weighted
fractional online matching problem with a tweak, where the decision maker can
recall (i.e., buyback) any fraction of an offline resource that is
pre-allocated to an earlier online vertex; however, by doing so not only the
decision maker loses the previously allocated reward (which equates the
edge-weight), it also has to pay a non-negative constant factor $f$ of this
edge-weight as an extra penalty. Parameterizing the problem by the buyback
factor $f$, our main result is obtaining optimal competitive algorithms for all
possible values of $f$ through a novel primal-dual family of algorithms. We
establish the optimality of our results by obtaining separate lower-bounds for
each of small and large buyback factor regimes, and showing how our primal-dual
algorithm exactly matches this lower-bound by appropriately tuning a parameter
as a function of $f$. We further study lower and upper bounds on the
competitive ratio in variants of this model, e.g., single-resource with
different demand sizes, or matching with deterministic integral allocations. We
show how algorithms in the our family of primal-dual algorithms can obtain the
exact optimal competitive ratio in all of these variants -- which in turn
demonstrates the power of our algorithmic framework for online resource
allocations with costly buyback.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11634'>A polynomial-time algorithm to solve the large scale of airplane refueling problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jinchuan Cui, Xiaoya Li</p><p>Airplane refueling problem (ARP) is a scheduling problem with an objective
function of fractional form. Given a fleet of $n$ airplanes with mid-air
refueling technique, each airplane has a specific fuel capacity and fuel
consumption rate. The fleet starts to fly together to a same target and during
the trip each airplane could instantaneously refuel to other airplanes and then
be dropped out. The question is how to find the best refueling policy to make
the last remaining airplane travels the farthest. We give a definition of the
sequential feasible solution and construct a sequential search algorithm, whose
computational complexity depends on the number of sequential feasible solutions
referred to $Q_n$. By utilizing combination and recurrence ideas, we prove that
the the upper bound of $Q_n$ is $2^{n-2}$. Then we focus on the worst-case and
investigate the complexity of the sequential search algorithm from a dynamic
perspective. Given a worst-case instance under some assumptions, we prove that
there must exist an index $m$ such that when $n$ is greater than $2m$, $Q_n$
turns out to be upper bounded by $\frac{m^2}{n}C_n^m$. Here the index $m$ is a
constant and could be regarded as an "inflection point": with the increasing
scale of input $n$, $Q_n$ turns out to be a polynomial function of $n$. Hence,
the sequential search algorithm turns out to run in polynomial time of $n$.
Moreover, we build an efficient computability scheme by which we shall predict
the complexity of $Q_n$ to choose a proper algorithm considering the available
running time for decision makers or users.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1">Jinchuan Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoya Li</a></p><p>Airplane refueling problem (ARP) is a scheduling problem with an objective
function of fractional form. Given a fleet of $n$ airplanes with mid-air
refueling technique, each airplane has a specific fuel capacity and fuel
consumption rate. The fleet starts to fly together to a same target and during
the trip each airplane could instantaneously refuel to other airplanes and then
be dropped out. The question is how to find the best refueling policy to make
the last remaining airplane travels the farthest. We give a definition of the
sequential feasible solution and construct a sequential search algorithm, whose
computational complexity depends on the number of sequential feasible solutions
referred to $Q_n$. By utilizing combination and recurrence ideas, we prove that
the the upper bound of $Q_n$ is $2^{n-2}$. Then we focus on the worst-case and
investigate the complexity of the sequential search algorithm from a dynamic
perspective. Given a worst-case instance under some assumptions, we prove that
there must exist an index $m$ such that when $n$ is greater than $2m$, $Q_n$
turns out to be upper bounded by $\frac{m^2}{n}C_n^m$. Here the index $m$ is a
constant and could be regarded as an "inflection point": with the increasing
scale of input $n$, $Q_n$ turns out to be a polynomial function of $n$. Hence,
the sequential search algorithm turns out to run in polynomial time of $n$.
Moreover, we build an efficient computability scheme by which we shall predict
the complexity of $Q_n$ to choose a proper algorithm considering the available
running time for decision makers or users.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11648'>Two-stage Stochastic Matching and Pricing with Applications to Ride Hailing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yiding Feng, Rad Niazadeh, Amin Saberi</p><p>Matching and pricing are two critical levers in two-sided marketplaces to
connect demand and supply. The platform can produce more efficient matching and
pricing decisions by batching the demand requests. We initiate the study of the
two-stage stochastic matching problem, with or without pricing, to enable the
platform to make improved decisions in a batch with an eye toward the imminent
future demand requests. This problem is motivated in part by applications in
online marketplaces such as ride hailing platforms.
</p>
<p>We design online competitive algorithms for vertex-weighted (or unweighted)
two-stage stochastic matching for maximizing supply efficiency, and two-stage
joint matching and pricing for maximizing market efficiency. In the former
problem, using a randomized primal-dual algorithm applied to a family of
``balancing'' convex programs, we obtain the optimal $3/4$ competitive ratio
against the optimum offline benchmark. Using a factor revealing program and
connections to submodular optimization, we improve this ratio against the
optimum online benchmark to $(1-1/e+1/e^2)\approx 0.767$ for the unweighted and
$0.761$ for the weighted case. In the latter problem, we design optimal
$1/2$-competitive joint pricing and matching algorithm by borrowing ideas from
the ex-ante prophet inequality literature. We also show an improved
$(1-1/e)$-competitive algorithm for the special case of demand efficiency
objective using the correlation gap of submodular functions. Finally, we
complement our theoretical study by using DiDi's ride-sharing dataset for
Chengdu city and numerically evaluating the performance of our proposed
algorithms in practical instances of this problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yiding Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Niazadeh_R/0/1/0/all/0/1">Rad Niazadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Saberi_A/0/1/0/all/0/1">Amin Saberi</a></p><p>Matching and pricing are two critical levers in two-sided marketplaces to
connect demand and supply. The platform can produce more efficient matching and
pricing decisions by batching the demand requests. We initiate the study of the
two-stage stochastic matching problem, with or without pricing, to enable the
platform to make improved decisions in a batch with an eye toward the imminent
future demand requests. This problem is motivated in part by applications in
online marketplaces such as ride hailing platforms.
</p>
<p>We design online competitive algorithms for vertex-weighted (or unweighted)
two-stage stochastic matching for maximizing supply efficiency, and two-stage
joint matching and pricing for maximizing market efficiency. In the former
problem, using a randomized primal-dual algorithm applied to a family of
``balancing'' convex programs, we obtain the optimal $3/4$ competitive ratio
against the optimum offline benchmark. Using a factor revealing program and
connections to submodular optimization, we improve this ratio against the
optimum online benchmark to $(1-1/e+1/e^2)\approx 0.767$ for the unweighted and
$0.761$ for the weighted case. In the latter problem, we design optimal
$1/2$-competitive joint pricing and matching algorithm by borrowing ideas from
the ex-ante prophet inequality literature. We also show an improved
$(1-1/e)$-competitive algorithm for the special case of demand efficiency
objective using the correlation gap of submodular functions. Finally, we
complement our theoretical study by using DiDi's ride-sharing dataset for
Chengdu city and numerically evaluating the performance of our proposed
algorithms in practical instances of this problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11784'>A Simple Deterministic Distributed Low-Diameter Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: V&#xe1;clav Rozho&#x148;, Bernhard Haeupler, Christoph Grunau</p><p>We give a simple, local process for nodes in an undirected graph to form
non-adjacent clusters that (1) have at most a polylogarithmic diameter and (2)
contain at least half of all vertices. Efficient deterministic distributed
clustering algorithms for computing strong-diameter network decompositions and
other key tools follow immediately. Overall, our process is a direct and
drastically simplified way for computing these fundamental objects.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rozhon_V/0/1/0/all/0/1">V&#xe1;clav Rozho&#x148;</a>, <a href="http://arxiv.org/find/cs/1/au:+Haeupler_B/0/1/0/all/0/1">Bernhard Haeupler</a>, <a href="http://arxiv.org/find/cs/1/au:+Grunau_C/0/1/0/all/0/1">Christoph Grunau</a></p><p>We give a simple, local process for nodes in an undirected graph to form
non-adjacent clusters that (1) have at most a polylogarithmic diameter and (2)
contain at least half of all vertices. Efficient deterministic distributed
clustering algorithms for computing strong-diameter network decompositions and
other key tools follow immediately. Overall, our process is a direct and
drastically simplified way for computing these fundamental objects.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11881'>Solving the Probabilistic Profitable Tour Problem on a Tree</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Enrico Angelelli, Renata Mansini, Romeo Rizzi</p><p>The profitable tour problem (PTP) is a well-known NP-hard routing problem
searching for a tour visiting a subset of customers while maximizing profit as
the difference between total revenue collected and traveling costs. PTP is
known to be solvable in polynomial time when special structures of the
underlying graph are considered. However, the computational complexity of the
corresponding probabilistic generalizations is still an open issue in many
cases. In this paper, we analyze the probabilistic PTP where customers are
located on a tree and need, with a known probability, for a service provision
at a predefined prize. The problem objective is to select a priori a subset of
customers with whom to commit the service so to maximize the expected profit.
We provide a polynomial time algorithm computing the optimal solution in
$O(n^2)$, where $n$ is the number of nodes in the tree.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Angelelli_E/0/1/0/all/0/1">Enrico Angelelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansini_R/0/1/0/all/0/1">Renata Mansini</a>, <a href="http://arxiv.org/find/cs/1/au:+Rizzi_R/0/1/0/all/0/1">Romeo Rizzi</a></p><p>The profitable tour problem (PTP) is a well-known NP-hard routing problem
searching for a tour visiting a subset of customers while maximizing profit as
the difference between total revenue collected and traveling costs. PTP is
known to be solvable in polynomial time when special structures of the
underlying graph are considered. However, the computational complexity of the
corresponding probabilistic generalizations is still an open issue in many
cases. In this paper, we analyze the probabilistic PTP where customers are
located on a tree and need, with a known probability, for a service provision
at a predefined prize. The problem objective is to select a priori a subset of
customers with whom to commit the service so to maximize the expected profit.
We provide a polynomial time algorithm computing the optimal solution in
$O(n^2)$, where $n$ is the number of nodes in the tree.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11918'>Splay Top Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jacob Holm (1), Eva Rotenberg (2), Alice Ryhl (2) ((1) University of Copenhagen, (2) Technical University of Denmark)</p><p>The top tree data structure is an important and fundamental tool in dynamic
graph algorithms. Top trees have existed for decades, and today serve as an
ingredient in many state-of-the-art algorithms for dynamic graphs. In this
work, we give a new direct proof of the existence of top trees, facilitating
simpler and more direct implementations of top trees, based on ideas from splay
trees. This result hinges on new insights into the structure of top trees, and
in particular the structure of each root path in a top tree.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Holm_J/0/1/0/all/0/1">Jacob Holm</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1">Eva Rotenberg</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Ryhl_A/0/1/0/all/0/1">Alice Ryhl</a> (2) ((1) University of Copenhagen, (2) Technical University of Denmark)</p><p>The top tree data structure is an important and fundamental tool in dynamic
graph algorithms. Top trees have existed for decades, and today serve as an
ingredient in many state-of-the-art algorithms for dynamic graphs. In this
work, we give a new direct proof of the existence of top trees, facilitating
simpler and more direct implementations of top trees, based on ideas from splay
trees. This result hinges on new insights into the structure of top trees, and
in particular the structure of each root path in a top tree.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11992'>Efficient Submodular Optimization under Noise: Local Search is Robust</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lingxiao Huang, Yuyi Wang, Chunxue Yang, Huanjian Zhou</p><p>The problem of monotone submodular maximization has been studied extensively
due to its wide range of applications. However, there are cases where one can
only access the objective function in a distorted or noisy form because of the
uncertain nature or the errors involved in the evaluation. This paper considers
the problem of constrained monotone submodular maximization with noisy oracles
introduced by [Hassidim et al., 2017]. For a cardinality constraint, we propose
an algorithm achieving a near-optimal
$\left(1-\frac{1}{e}-O(\varepsilon)\right)$-approximation guarantee (for
arbitrary $\varepsilon &gt; 0$) with only a polynomial number of queries to the
noisy value oracle, which improves the exponential query complexity of [Singer
et al., 2018]. For general matroid constraints, we show the first constant
approximation algorithm in the presence of noise. Our main approaches are to
design a novel local search framework that can handle the effect of noise and
to construct certain smoothing surrogate functions for noise reduction.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chunxue Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huanjian Zhou</a></p><p>The problem of monotone submodular maximization has been studied extensively
due to its wide range of applications. However, there are cases where one can
only access the objective function in a distorted or noisy form because of the
uncertain nature or the errors involved in the evaluation. This paper considers
the problem of constrained monotone submodular maximization with noisy oracles
introduced by [Hassidim et al., 2017]. For a cardinality constraint, we propose
an algorithm achieving a near-optimal
$\left(1-\frac{1}{e}-O(\varepsilon)\right)$-approximation guarantee (for
arbitrary $\varepsilon &gt; 0$) with only a polynomial number of queries to the
noisy value oracle, which improves the exponential query complexity of [Singer
et al., 2018]. For general matroid constraints, we show the first constant
approximation algorithm in the presence of noise. Our main approaches are to
design a novel local search framework that can handle the effect of noise and
to construct certain smoothing surrogate functions for noise reduction.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11996'>Unbalanced Triangle Detection and Enumeration Hardness for Unions of Conjunctive Queries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Karl Bringmann, Nofar Carmeli</p><p>We study the enumeration of answers to Unions of Conjunctive Queries (UCQs)
with optimal time guarantees. More precisely, we wish to identify the queries
that can be solved with linear preprocessing time and constant delay. Despite
the basic nature of this problem, it was shown only recently that UCQs can be
solved within these time bounds if they admit free-connex union extensions,
even if all individual CQs in the union are intractable with respect to the
same complexity measure. Our goal is to understand whether there exist
additional tractable UCQs, not covered by the currently known algorithms.
</p>
<p>As a first step, we show that some previously unclassified UCQs are hard
using the classic 3SUM hypothesis, via a known reduction from 3SUM to triangle
listing in graphs. As a second step, we identify a question about a variant of
this graph task which is unavoidable if we want to classify all self-join free
UCQs: is it possible to decide the existence of a triangle in a
vertex-unbalanced tripartite graph in linear time? We prove that this task is
equivalent in hardness to some family of UCQs. Finally, we show a dichotomy for
unions of two self-join-free CQs if we assume the answer to this question is
negative.
</p>
<p>As a result, to reason about a class of enumeration problems defined by UCQs,
it is enough to study the single decision problem of detecting triangles in
unbalanced graphs. As of today, we know of no algorithm that comes close to
solving this decision problem within the required time bounds. Our conclusion
is that, without a breakthrough for triangle detection, we have no hope to find
an efficient algorithm for additional unions of two self-join free CQs. On the
other hand, if we will one day have such a triangle detection algorithm, we
will immediately obtain an efficient algorithm for a family of UCQs that are
currently not known to be tractable.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bringmann_K/0/1/0/all/0/1">Karl Bringmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Carmeli_N/0/1/0/all/0/1">Nofar Carmeli</a></p><p>We study the enumeration of answers to Unions of Conjunctive Queries (UCQs)
with optimal time guarantees. More precisely, we wish to identify the queries
that can be solved with linear preprocessing time and constant delay. Despite
the basic nature of this problem, it was shown only recently that UCQs can be
solved within these time bounds if they admit free-connex union extensions,
even if all individual CQs in the union are intractable with respect to the
same complexity measure. Our goal is to understand whether there exist
additional tractable UCQs, not covered by the currently known algorithms.
</p>
<p>As a first step, we show that some previously unclassified UCQs are hard
using the classic 3SUM hypothesis, via a known reduction from 3SUM to triangle
listing in graphs. As a second step, we identify a question about a variant of
this graph task which is unavoidable if we want to classify all self-join free
UCQs: is it possible to decide the existence of a triangle in a
vertex-unbalanced tripartite graph in linear time? We prove that this task is
equivalent in hardness to some family of UCQs. Finally, we show a dichotomy for
unions of two self-join-free CQs if we assume the answer to this question is
negative.
</p>
<p>As a result, to reason about a class of enumeration problems defined by UCQs,
it is enough to study the single decision problem of detecting triangles in
unbalanced graphs. As of today, we know of no algorithm that comes close to
solving this decision problem within the required time bounds. Our conclusion
is that, without a breakthrough for triangle detection, we have no hope to find
an efficient algorithm for additional unions of two self-join free CQs. On the
other hand, if we will one day have such a triangle detection algorithm, we
will immediately obtain an efficient algorithm for a family of UCQs that are
currently not known to be tractable.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, October 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2022/141'>TR22-141 |  TFNP Characterizations of Proof Systems and Monotone Circuits | 

	Noah Fleming, 

	Sam Buss, 

	Russell Impagliazzo</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Connections between proof complexity and circuit complexity have become major tools for obtaining lower bounds in both areas. These connections -- which take the form of interpolation theorems and query-to-communication lifting theorems --  translate efficient proofs into small circuits, and vice versa, allowing tools from one area to be applied to the other. Recently, the theory of TFNP has emerged as a unifying framework underlying these connections. For many of the proof systems which admit such a connection there is a TFNP problem which characterizes it: the class of problems which are reducible to this TFNP problem via query-efficient reductions is equivalent to the tautologies that can be efficiently proven in the system. Through this, proof complexity has become a major tool for proving separations in black-box TFNP. Similarly, for certain monotone circuit models, the class of functions that it can compute efficiently is equivalent to what can be reduced to a certain TFNP problem in low communication. When a TFNP problem has both a proof and circuit characterization, one can prove an interpolation theorem. Conversely, many lifting theorems can be viewed as relating the communication and query reductions to TFNP problems. This is exciting, as it suggests that TFNP provides a roadmap for the development of further interpolation theorems and lifting theorems. 

In this paper we begin to develop a more systematic understanding of when these connections to TFNP occur. We give exact conditions under which a proof system or circuit model admits a characterization by a TFNP problem. We show:

- Every well-behaved proof system which can prove its own soundness (a reflection principle) is characterized by a TFNP problem. Conversely, every TFNP problem gives rise to a well-behaved proof system which proves its own soundness.

- Every well-behaved monotone circuit model which admits a universal family  of functions is characterized by a TFNP problem. Conversely, every TFNP problem gives rise to a well-behaved monotone circuit model with a universal problem.

As an example, we provide a TFNP characterization of the Polynomial Calculus, answering a question of Goos et al., and show that it can prove its own soundness.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Connections between proof complexity and circuit complexity have become major tools for obtaining lower bounds in both areas. These connections -- which take the form of interpolation theorems and query-to-communication lifting theorems --  translate efficient proofs into small circuits, and vice versa, allowing tools from one area to be applied to the other. Recently, the theory of TFNP has emerged as a unifying framework underlying these connections. For many of the proof systems which admit such a connection there is a TFNP problem which characterizes it: the class of problems which are reducible to this TFNP problem via query-efficient reductions is equivalent to the tautologies that can be efficiently proven in the system. Through this, proof complexity has become a major tool for proving separations in black-box TFNP. Similarly, for certain monotone circuit models, the class of functions that it can compute efficiently is equivalent to what can be reduced to a certain TFNP problem in low communication. When a TFNP problem has both a proof and circuit characterization, one can prove an interpolation theorem. Conversely, many lifting theorems can be viewed as relating the communication and query reductions to TFNP problems. This is exciting, as it suggests that TFNP provides a roadmap for the development of further interpolation theorems and lifting theorems. 

In this paper we begin to develop a more systematic understanding of when these connections to TFNP occur. We give exact conditions under which a proof system or circuit model admits a characterization by a TFNP problem. We show:

- Every well-behaved proof system which can prove its own soundness (a reflection principle) is characterized by a TFNP problem. Conversely, every TFNP problem gives rise to a well-behaved proof system which proves its own soundness.

- Every well-behaved monotone circuit model which admits a universal family  of functions is characterized by a TFNP problem. Conversely, every TFNP problem gives rise to a well-behaved monotone circuit model with a universal problem.

As an example, we provide a TFNP characterization of the Polynomial Calculus, answering a question of Goos et al., and show that it can prove its own soundness.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-23T01:10:16Z">Sunday, October 23 2022, 01:10</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, October 22
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2022/10/22/repeated-vertices-tsp.html'>Repeated vertices in TSP tours</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This week my graph algorithms course covered the traveling salesperson problem, which I usually describe in two equivalent forms:
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>This week my graph algorithms course covered the traveling salesperson problem, which I usually describe in two equivalent forms:</p>

<ul>
  <li>
    <p>Given a distance matrix representing a metric space, find a cycle that passes through each point of the space exactly once, of minimum total length</p>
  </li>
  <li>
    <p>Given a connected positively-weighted undirected graph, find a closed walk that passes through each vertex at least once, of minimum total length</p>
  </li>
</ul>

<p>To go from a distance matrix to a graph, we just use the complete graph, and skip any repeated vertices in its closed walk. To go from a graph to a distance matrix, compute all pairs shortest distances, and then form a closed walk by concatenating the shortest paths between consecutive vertices of the non-repeating cycle. But this concatenation may create many unavoidable repeated vertices. For instance, if your graph is an <span style="white-space:nowrap">\(n\)-vertex</span> star, then any closed walk through all the vertices must return to the central vertex \(n-1\) times, like the blue curve past all of the vertices in the nine-vertex star below.</p>

<p style="text-align:center"><img src="/blog/assets/2022/star-tour.svg" alt="A closed walk through all vertices of the star $$K_{1,8}$$ visits the central vertex eight times." /></p>

<p>It occurred to me to wonder: how many repetitions might be necessary, in total? The multigraph of edges used by the closed walk (with one copy for each time the walk uses each edge) is Eulerian, meaning that it connects all the vertices and has even degree at all of them. Any Eulerian multigraph has a closed walk visiting all the vertices, its Euler tour. Among these graphs, the TSP multigraph must be minimal: if it had an Eulerian subgraph we could walk on that instead. And any minimal Eulerian multigraph can be turned into a simple graph and weighted in such a way that all edges are used with their given multiplicities in the optimal TSP walk. So another, more combinatorial, way of asking the same question is: how many edges can a minimal Eulerian multigraph have?</p>

<p>The answer: <span style="white-space:nowrap">\(2n-2\).</span> More precisely, a graph is said to be <a href="https://en.wikipedia.org/wiki/Dense_graph">\((a,b)\)-sparse</a> if every <span style="white-space:nowrap">\(k\)-vertex</span> subgraph has at most \(ak-b\) edges. In this sense, the minimal Eulerian graphs are <span style="white-space:nowrap">\((2,2)\)-sparse.</span></p>

<p>If you were given an Eulerian graph that is not <span style="white-space:nowrap">\((2,2)\)-sparse,</span> it could not be minimal Eulerian. To see this, choose a minimal subset of \(k\) vertices that has more than \(2k-2\) edges. By deleting edges, you can find a subgraph that is <span style="white-space:nowrap">\((2,2)\)-tight:</span> it has exactly \(2k-2\) edges, and every subgraph is <span style="white-space:nowrap">\((2,2)\)-sparse.</span> A result of Nash-Williams from the 1960s states that a subgraph like this can always be decomposed into two spanning trees. But if you combine one of the deleted edges with a path between its endpoints in one of the trees, you get a cycle that you can remove without changing the parity of the vertex degrees. Removing this cycle still leaves a subgraph that is connected through the other spanning tree. Because there is a cycle you can remove leaving an Eulerian subgraph, your starting graph is not minimal.</p>

<p>The bound of \(2(n-1)\) on the number of edges in a minimal Eulerian multigraph cannot be made any smaller. One way to construct a minimal Eulerian multigraph with exactly this many edges (maybe the only way) is just to double all of the edges in a tree.</p>

<p>Instead of counting edges, another way to define sparse graphs involves forbidden <a href="https://en.wikipedia.org/wiki/Shallow_minor">shallow minors</a>. However, this does not work for minimal Eulerian graphs: they have no forbidden shallow minors. For instance, if you subdivide the edges of any Eulerian graph, such as a complete graph on an odd number of vertices, you will get a minimal Eulerian graph that has the complete graph as a depth-1 minor.</p>

<p style="text-align:center"><img src="/blog/assets/2022/subdivided-K7.svg" alt="Subdividing the edges of the complete graph $$K_7$$ produces a minimal Eulerian graph with $$K_7$$ as a 1-shallow minor." /></p>

<p>(<a href="https://mathstodon.xyz/@11011110/109214811068499556">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-22T17:22:00Z">Saturday, October 22 2022, 17:22</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, October 21
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/21/faculty-at-northeastern-university-apply-by-december-1-2022/'>Faculty at Northeastern University (apply by December 1, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Northeastern&#8217;s Khoury College of Computer Sciences is looking to hire 8 open-rank tenure-track faculty this year! We are specifically targeting cryptography, differential privacy, and quantum computing, but are interested in exceptional candidates in all areas. Website: www.khoury.northeastern.edu/information-for-overview/prospective-faculty/open-positions/tenure-track/ Email: jullman@ccs.neu.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Northeastern&#8217;s Khoury College of Computer Sciences is looking to hire 8 open-rank tenure-track faculty this year! We are specifically targeting cryptography, differential privacy, and quantum computing, but are interested in exceptional candidates in all areas.</p>
<p>Website: <a href="https://www.khoury.northeastern.edu/information-for-overview/prospective-faculty/open-positions/tenure-track/">https://www.khoury.northeastern.edu/information-for-overview/prospective-faculty/open-positions/tenure-track/</a><br />
Email: jullman@ccs.neu.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T17:52:43Z">Friday, October 21 2022, 17:52</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/21/postdoc-at-nanyang-technological-university-apply-by-december-31-2023/'>Postdoc at Nanyang Technological University (apply by December 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I&#8217;m looking for two postdocs to work with me on data stream algorithms, low distortion metric embeddings, randomized numerical linear algebra or other related topics. The starting date is flexible and will be from February 2023 onwards. The initial contract is for one year and an extension is possible based on performance and the funding [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I&#8217;m looking for two postdocs to work with me on data stream algorithms, low distortion metric embeddings, randomized numerical linear algebra or other related topics.</p>
<p>The starting date is flexible and will be from February 2023 onwards. The initial contract is for one year and an extension is possible based on performance and the funding situation.</p>
<p>Website: <a href="https://personal.ntu.edu.sg/yili/">https://personal.ntu.edu.sg/yili/</a><br />
Email: yili@ntu.edu.sg</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T04:49:58Z">Friday, October 21 2022, 04:49</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
