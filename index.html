<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-03-15T02:30:29Z">Wednesday, March 15 2023, 02:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, March 15
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07401'>Drawings of Complete Multipartite Graphs Up to Triangle Flips</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Oswin Aichholzer, Man-Kwun Chiu, Hung P. Hoang, Michael Hoffmann, Jan Kyn&#x10d;l, Yannic Maus, Birgit Vogtenhuber, Alexandra Weinberger</p><p>For a drawing of a labeled graph, the rotation of a vertex or crossing is the
cyclic order of its incident edges, represented by the labels of their other
endpoints. The extended rotation system (ERS) of the drawing is the collection
of the rotations of all vertices and crossings. A drawing is simple if each
pair of edges has at most one common point. Gioan's Theorem states that for any
two simple drawings of the complete graph $K_n$ with the same crossing edge
pairs, one drawing can be transformed into the other by a sequence of triangle
flips (a.k.a. Reidemeister moves of Type 3). This operation refers to the act
of moving one edge of a triangular cell formed by three pairwise crossing edges
over the opposite crossing of the cell, via a local transformation.
</p>
<p>We investigate to what extent Gioan-type theorems can be obtained for wider
classes of graphs. A necessary (but in general not sufficient) condition for
two drawings of a graph to be transformable into each other by a sequence of
triangle flips is that they have the same ERS. As our main result, we show that
for the large class of complete multipartite graphs, this necessary condition
is in fact also sufficient. We present two different proofs of this result, one
of which is shorter, while the other one yields a polynomial time algorithm for
which the number of needed triangle flips for graphs on $n$ vertices is bounded
by $O(n^{16})$. The latter proof uses a Carath\'eodory-type theorem for simple
drawings of complete multipartite graphs, which we believe to be of independent
interest.
</p>
<p>Moreover, we show that our Gioan-type theorem for complete multipartite
graphs is essentially tight in the sense that having the same ERS does not
remain sufficient when removing or adding very few edges.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aichholzer_O/0/1/0/all/0/1">Oswin Aichholzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_M/0/1/0/all/0/1">Man-Kwun Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoang_H/0/1/0/all/0/1">Hung P. Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffmann_M/0/1/0/all/0/1">Michael Hoffmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyncl_J/0/1/0/all/0/1">Jan Kyn&#x10d;l</a>, <a href="http://arxiv.org/find/cs/1/au:+Maus_Y/0/1/0/all/0/1">Yannic Maus</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogtenhuber_B/0/1/0/all/0/1">Birgit Vogtenhuber</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinberger_A/0/1/0/all/0/1">Alexandra Weinberger</a></p><p>For a drawing of a labeled graph, the rotation of a vertex or crossing is the
cyclic order of its incident edges, represented by the labels of their other
endpoints. The extended rotation system (ERS) of the drawing is the collection
of the rotations of all vertices and crossings. A drawing is simple if each
pair of edges has at most one common point. Gioan's Theorem states that for any
two simple drawings of the complete graph $K_n$ with the same crossing edge
pairs, one drawing can be transformed into the other by a sequence of triangle
flips (a.k.a. Reidemeister moves of Type 3). This operation refers to the act
of moving one edge of a triangular cell formed by three pairwise crossing edges
over the opposite crossing of the cell, via a local transformation.
</p>
<p>We investigate to what extent Gioan-type theorems can be obtained for wider
classes of graphs. A necessary (but in general not sufficient) condition for
two drawings of a graph to be transformable into each other by a sequence of
triangle flips is that they have the same ERS. As our main result, we show that
for the large class of complete multipartite graphs, this necessary condition
is in fact also sufficient. We present two different proofs of this result, one
of which is shorter, while the other one yields a polynomial time algorithm for
which the number of needed triangle flips for graphs on $n$ vertices is bounded
by $O(n^{16})$. The latter proof uses a Carath\'eodory-type theorem for simple
drawings of complete multipartite graphs, which we believe to be of independent
interest.
</p>
<p>Moreover, we show that our Gioan-type theorem for complete multipartite
graphs is essentially tight in the sense that having the same ERS does not
remain sufficient when removing or adding very few edges.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07645'>Finding a Maximum Clique in a Disk Graph</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jared Espenant, J. Mark Keil, Debajyoti Mondal</p><p>A disk graph is an intersection graph of disks in the Euclidean plane, where
the disks correspond to the vertices of the graph and a pair of vertices are
adjacent if and only if their corresponding disks intersect. The problem of
determining the time complexity of computing a maximum clique in a disk graph
is a long-standing open question. The problem is known to be open even when the
radii of all the disks are in the interval $[1,(1+\varepsilon)]$, where
$\varepsilon&gt;0$. However, the maximum clique problem is known to be APX-hard
for the intersection graphs of many other convex objects such as intersection
graphs of ellipses, triangles, and a combination of unit disks and
axis-parallel rectangles. Furthermore, there exists an $O(n^3\log n)$-time
algorithm to compute a maximum clique for unit disks. Here we obtain the
following results.
</p>
<p>- We give an algorithm to compute a maximum clique in a unit disk graph in
$O(n^{2.5}\log n)$-time, which improves the previously best known running time
of $O(n^3\log n)$ [Eppstein '09].
</p>
<p>- We extend a widely used `co-2-subdivision approach' to prove that computing
a maximum clique in a combination of unit disks and axis-parallel rectangles is
NP-hard to approximate within $4448/4449 \approx 0.9997 $. The use of a
`co-2-subdivision approach' was previously thought to be unlikely in this
setting [Bonnet et al. '20]. Our result improves the previously known
inapproximability factor of $7633010347/7633010348\approx 0.9999$.
</p>
<p>- We show that the parameter minimum lens width of the disk arrangement may
be used to make progress in the case when disk radii are in
$[1,(1+\varepsilon)]$. For example, if the minimum lens width is at least
$0.265$ and $ \varepsilon\le 0.0001$, which still allows for non-Helly triples
in the arrangement, then one can find a maximum clique in polynomial time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Espenant_J/0/1/0/all/0/1">Jared Espenant</a>, <a href="http://arxiv.org/find/cs/1/au:+Keil_J/0/1/0/all/0/1">J. Mark Keil</a>, <a href="http://arxiv.org/find/cs/1/au:+Mondal_D/0/1/0/all/0/1">Debajyoti Mondal</a></p><p>A disk graph is an intersection graph of disks in the Euclidean plane, where
the disks correspond to the vertices of the graph and a pair of vertices are
adjacent if and only if their corresponding disks intersect. The problem of
determining the time complexity of computing a maximum clique in a disk graph
is a long-standing open question. The problem is known to be open even when the
radii of all the disks are in the interval $[1,(1+\varepsilon)]$, where
$\varepsilon&gt;0$. However, the maximum clique problem is known to be APX-hard
for the intersection graphs of many other convex objects such as intersection
graphs of ellipses, triangles, and a combination of unit disks and
axis-parallel rectangles. Furthermore, there exists an $O(n^3\log n)$-time
algorithm to compute a maximum clique for unit disks. Here we obtain the
following results.
</p>
<p>- We give an algorithm to compute a maximum clique in a unit disk graph in
$O(n^{2.5}\log n)$-time, which improves the previously best known running time
of $O(n^3\log n)$ [Eppstein '09].
</p>
<p>- We extend a widely used `co-2-subdivision approach' to prove that computing
a maximum clique in a combination of unit disks and axis-parallel rectangles is
NP-hard to approximate within $4448/4449 \approx 0.9997 $. The use of a
`co-2-subdivision approach' was previously thought to be unlikely in this
setting [Bonnet et al. '20]. Our result improves the previously known
inapproximability factor of $7633010347/7633010348\approx 0.9999$.
</p>
<p>- We show that the parameter minimum lens width of the disk arrangement may
be used to make progress in the case when disk radii are in
$[1,(1+\varepsilon)]$. For example, if the minimum lens width is at least
$0.265$ and $ \varepsilon\le 0.0001$, which still allows for non-Helly triples
in the arrangement, then one can find a maximum clique in polynomial time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07696'>Shadoks Approach to Convex Covering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guilherme D. da Fonseca</p><p>We describe the heuristics used by the Shadoks team in the CG:SHOP 2023
Challenge. The Challenge consists of 206 instances, each being a polygon with
holes. The goal is to cover each instance polygon with a small number of convex
polygons. Our general strategy is the following. We find a big collection of
large (often maximal) convex polygons inside the instance polygon and then
solve several set cover problems to find a small subset of the collection that
covers the whole polygon.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fonseca_G/0/1/0/all/0/1">Guilherme D. da Fonseca</a></p><p>We describe the heuristics used by the Shadoks team in the CG:SHOP 2023
Challenge. The Challenge consists of 206 instances, each being a polygon with
holes. The goal is to cover each instance polygon with a small number of convex
polygons. Our general strategy is the following. We find a big collection of
large (often maximal) convex polygons inside the instance polygon and then
solve several set cover problems to find a small subset of the collection that
covers the whole polygon.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07710'>A note on the flip distance between non-crossing spanning trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicolas Bousquet, Valentin Gledel, Jonathan Narboni, Th&#xe9;o Pierron</p><p>We consider spanning trees of $n$ points in convex position whose edges are
pairwise non-crossing. Applying a flip to such a tree consists in adding an
edge and removing another so that the result is still a non-crossing spanning
tree. Given two trees, we investigate the minimum number of flips required to
transform one into the other. The naive $2n-\Omega(1)$ upper bound stood for 25
years until a recent breakthrough from Aichholzer et al. yielding a
$2n-\Omega(\log n)$ bound. We improve their result with a $2n-\Omega(\sqrt{n})$
upper bound, and we strengthen and shorten the proofs of several of their
results.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bousquet_N/0/1/0/all/0/1">Nicolas Bousquet</a>, <a href="http://arxiv.org/find/cs/1/au:+Gledel_V/0/1/0/all/0/1">Valentin Gledel</a>, <a href="http://arxiv.org/find/cs/1/au:+Narboni_J/0/1/0/all/0/1">Jonathan Narboni</a>, <a href="http://arxiv.org/find/cs/1/au:+Pierron_T/0/1/0/all/0/1">Th&#xe9;o Pierron</a></p><p>We consider spanning trees of $n$ points in convex position whose edges are
pairwise non-crossing. Applying a flip to such a tree consists in adding an
edge and removing another so that the result is still a non-crossing spanning
tree. Given two trees, we investigate the minimum number of flips required to
transform one into the other. The naive $2n-\Omega(1)$ upper bound stood for 25
years until a recent breakthrough from Aichholzer et al. yielding a
$2n-\Omega(\log n)$ bound. We improve their result with a $2n-\Omega(\sqrt{n})$
upper bound, and we strengthen and shorten the proofs of several of their
results.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07947'>Canonical Sphere Bases for Simplicial and Cubical Complexes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Paul C. Kainen</p><p>Sphere-bases are constructed for the $\mathbb{Z}_2$ vector space formed by
the $k$-dimensional subcomplexes, of $n$-simplex (or $n$-cube), for which every
$(k{-}1)$-face is contained in a positive even number of $k$-cells; addition is
symmetric difference of the corresponding sets of $k$-cells. The bases consist
of the boundaries of an algorithmically-specified family of $k{+}1$-simplexes
or $k{+}1$-cubes. Geometric properties of these bases are investigated.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Kainen_P/0/1/0/all/0/1">Paul C. Kainen</a></p><p>Sphere-bases are constructed for the $\mathbb{Z}_2$ vector space formed by
the $k$-dimensional subcomplexes, of $n$-simplex (or $n$-cube), for which every
$(k{-}1)$-face is contained in a positive even number of $k$-cells; addition is
symmetric difference of the corresponding sets of $k$-cells. The bases consist
of the boundaries of an algorithmically-specified family of $k{+}1$-simplexes
or $k{+}1$-cubes. Geometric properties of these bases are investigated.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07982'>A Structural Approach to Tree Decompositions of Knots and Spatial Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Corentin Lunel, Arnaud de Mesmay</p><p>Knots are commonly represented and manipulated via diagrams, which are
decorated planar graphs. When such a knot diagram has low treewidth,
parameterized graph algorithms can be leveraged to ensure the fast computation
of many invariants and properties of the knot. It was recently proved that
there exist knots which do not admit any diagram of low treewidth, and the
proof relied on intricate low-dimensional topology techniques. In this work, we
initiate a thorough investigation of tree decompositions of knot diagrams (or
more generally, diagrams of spatial graphs) using ideas from structural graph
theory. We define an obstruction on spatial embeddings that forbids low tree
width diagrams, and we prove that it is optimal with respect to a related width
invariant. We then show the existence of this obstruction for knots of high
representativity, which include for example torus knots, providing a new and
self-contained proof that those do not admit diagrams of low treewidth. This
last step is inspired by a result of Pardon on knot distortion.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lunel_C/0/1/0/all/0/1">Corentin Lunel</a>, <a href="http://arxiv.org/find/cs/1/au:+Mesmay_A/0/1/0/all/0/1">Arnaud de Mesmay</a></p><p>Knots are commonly represented and manipulated via diagrams, which are
decorated planar graphs. When such a knot diagram has low treewidth,
parameterized graph algorithms can be leveraged to ensure the fast computation
of many invariants and properties of the knot. It was recently proved that
there exist knots which do not admit any diagram of low treewidth, and the
proof relied on intricate low-dimensional topology techniques. In this work, we
initiate a thorough investigation of tree decompositions of knot diagrams (or
more generally, diagrams of spatial graphs) using ideas from structural graph
theory. We define an obstruction on spatial embeddings that forbids low tree
width diagrams, and we prove that it is optimal with respect to a related width
invariant. We then show the existence of this obstruction for knots of high
representativity, which include for example torus knots, providing a new and
self-contained proof that those do not admit diagrams of low treewidth. This
last step is inspired by a result of Pardon on knot distortion.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.08036'>Algorithms for Length Spectra of Combinatorial Tori</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vincent Delecroix, Matthijs Ebbens, Francis Lazarus, Ivan Yakovlev</p><p>Consider a weighted, undirected graph cellularly embedded on a topological
surface. The function assigning to each free homotopy class of closed curves
the length of a shortest cycle within this homotopy class is called the marked
length spectrum. The (unmarked) length spectrum is obtained by just listing the
length values of the marked length spectrum in increasing order.
</p>
<p>In this paper, we describe algorithms for computing the (un)marked length
spectra of graphs embedded on the torus. More specifically, we preprocess a
weighted graph of complexity $n$ in time $O(n^2 \log \log n)$ so that, given a
cycle with $\ell$ edges representing a free homotopy class, the length of a
shortest homotopic cycle can be computed in $O(\ell+\log n)$ time. Moreover,
given any positive integer $k$, the first $k$ values of its unmarked length
spectrum can be computed in time $O(k \log n)$.
</p>
<p>Our algorithms are based on a correspondence between weighted graphs on the
torus and polyhedral norms. In particular, we give a weight independent bound
on the complexity of the unit ball of such norms. As an immediate consequence
we can decide if two embedded weighted graphs have the same marked spectrum in
polynomial time. We also consider the problem of comparing the unmarked spectra
and provide a polynomial time algorithm in the unweighted case and a randomized
polynomial time algorithm otherwise.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Delecroix_V/0/1/0/all/0/1">Vincent Delecroix</a>, <a href="http://arxiv.org/find/cs/1/au:+Ebbens_M/0/1/0/all/0/1">Matthijs Ebbens</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazarus_F/0/1/0/all/0/1">Francis Lazarus</a>, <a href="http://arxiv.org/find/cs/1/au:+Yakovlev_I/0/1/0/all/0/1">Ivan Yakovlev</a></p><p>Consider a weighted, undirected graph cellularly embedded on a topological
surface. The function assigning to each free homotopy class of closed curves
the length of a shortest cycle within this homotopy class is called the marked
length spectrum. The (unmarked) length spectrum is obtained by just listing the
length values of the marked length spectrum in increasing order.
</p>
<p>In this paper, we describe algorithms for computing the (un)marked length
spectra of graphs embedded on the torus. More specifically, we preprocess a
weighted graph of complexity $n$ in time $O(n^2 \log \log n)$ so that, given a
cycle with $\ell$ edges representing a free homotopy class, the length of a
shortest homotopic cycle can be computed in $O(\ell+\log n)$ time. Moreover,
given any positive integer $k$, the first $k$ values of its unmarked length
spectrum can be computed in time $O(k \log n)$.
</p>
<p>Our algorithms are based on a correspondence between weighted graphs on the
torus and polyhedral norms. In particular, we give a weight independent bound
on the complexity of the unit ball of such norms. As an immediate consequence
we can decide if two embedded weighted graphs have the same marked spectrum in
polynomial time. We also consider the problem of comparing the unmarked spectra
and provide a polynomial time algorithm in the unweighted case and a randomized
polynomial time algorithm otherwise.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07911'>Quantum Steering Algorithm for Estimating Fidelity of Separability</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aby Philip, Soorya Rethinasamy, Vincent Russo, Mark M. Wilde</p><p>Quantifying entanglement is an important task by which the resourcefulness of
a state can be measured. Here we develop a quantum algorithm that tests for and
quantifies the separability of a general bipartite state, by making use of the
quantum steering effect. Our first separability test consists of a distributed
quantum computation involving two parties: a computationally limited client,
who prepares a purification of the state of interest, and a computationally
unbounded server, who tries to steer the reduced systems to a probabilistic
ensemble of pure product states. To design a practical algorithm, we replace
the role of the server by a combination of parameterized unitary circuits and
classical optimization techniques to perform the necessary computation. The
result is a variational quantum steering algorithm (VQSA), which is our second
separability test that is better suited for the capabilities of quantum
computers available today. This VQSA has an additional interpretation as a
distributed variational quantum algorithm (VQA) that can be executed over a
quantum network, in which each node is equipped with classical and quantum
computers capable of executing VQA. We then simulate our VQSA on noisy quantum
simulators and find favorable convergence properties on the examples tested. We
also develop semidefinite programs, executable on classical computers, that
benchmark the results obtained from our VQSA. Our findings here thus provide a
meaningful connection between steering, entanglement, quantum algorithms, and
quantum computational complexity theory. They also demonstrate the value of a
parameterized mid-circuit measurement in a VQSA and represent a
first-of-its-kind application for a distributed VQA. Finally, the whole
framework generalizes to the case of multipartite states and entanglement.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Philip_A/0/1/0/all/0/1">Aby Philip</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Rethinasamy_S/0/1/0/all/0/1">Soorya Rethinasamy</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Russo_V/0/1/0/all/0/1">Vincent Russo</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Wilde_M/0/1/0/all/0/1">Mark M. Wilde</a></p><p>Quantifying entanglement is an important task by which the resourcefulness of
a state can be measured. Here we develop a quantum algorithm that tests for and
quantifies the separability of a general bipartite state, by making use of the
quantum steering effect. Our first separability test consists of a distributed
quantum computation involving two parties: a computationally limited client,
who prepares a purification of the state of interest, and a computationally
unbounded server, who tries to steer the reduced systems to a probabilistic
ensemble of pure product states. To design a practical algorithm, we replace
the role of the server by a combination of parameterized unitary circuits and
classical optimization techniques to perform the necessary computation. The
result is a variational quantum steering algorithm (VQSA), which is our second
separability test that is better suited for the capabilities of quantum
computers available today. This VQSA has an additional interpretation as a
distributed variational quantum algorithm (VQA) that can be executed over a
quantum network, in which each node is equipped with classical and quantum
computers capable of executing VQA. We then simulate our VQSA on noisy quantum
simulators and find favorable convergence properties on the examples tested. We
also develop semidefinite programs, executable on classical computers, that
benchmark the results obtained from our VQSA. Our findings here thus provide a
meaningful connection between steering, entanglement, quantum algorithms, and
quantum computational complexity theory. They also demonstrate the value of a
parameterized mid-circuit measurement in a VQSA and represent a
first-of-its-kind application for a distributed VQA. Finally, the whole
framework generalizes to the case of multipartite states and entanglement.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07985'>Logarithmic Weisfeiler--Leman and Treewidth</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Levet, Puck Rombach, Nicholas Sieger</p><p>In this paper, we show that the $(3k+4)$-dimensional Weisfeiler--Leman
algorithm can identify graphs of treewidth $k$ in $O(\log n)$ rounds. This
improves the result of Grohe &amp; Verbitsky (ICALP 2006), who previously
established the analogous result for $(4k+3)$-dimensional Weisfeiler--Leman. In
light of the equivalence between Weisfeiler--Leman and the logic $\textsf{FO} +
\textsf{C}$ (Cai, F\"urer, &amp; Immerman, Combinatorica 1992), we obtain an
improvement in the descriptive complexity for graphs of treewidth $k$.
Precisely, if $G$ is a graph of treewidth $k$, then there exists a
$(3k+5)$-variable formula $\varphi$ in $\textsf{FO} + \textsf{C}$ with
quantifier depth $O(\log n)$ that identifies $G$ up to isomorphism.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Levet_M/0/1/0/all/0/1">Michael Levet</a>, <a href="http://arxiv.org/find/cs/1/au:+Rombach_P/0/1/0/all/0/1">Puck Rombach</a>, <a href="http://arxiv.org/find/cs/1/au:+Sieger_N/0/1/0/all/0/1">Nicholas Sieger</a></p><p>In this paper, we show that the $(3k+4)$-dimensional Weisfeiler--Leman
algorithm can identify graphs of treewidth $k$ in $O(\log n)$ rounds. This
improves the result of Grohe &amp; Verbitsky (ICALP 2006), who previously
established the analogous result for $(4k+3)$-dimensional Weisfeiler--Leman. In
light of the equivalence between Weisfeiler--Leman and the logic $\textsf{FO} +
\textsf{C}$ (Cai, F\"urer, &amp; Immerman, Combinatorica 1992), we obtain an
improvement in the descriptive complexity for graphs of treewidth $k$.
Precisely, if $G$ is a graph of treewidth $k$, then there exists a
$(3k+5)$-variable formula $\varphi$ in $\textsf{FO} + \textsf{C}$ with
quantifier depth $O(\log n)$ that identifies $G$ up to isomorphism.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07444'>Polynomial-Time Approximation Schemes for Independent Packing Problems on Fractionally Tree-Independence-Number-Fragile Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Esther Galby, Andrea Munaro, Shizhou Yang</p><p>We investigate a relaxation of the notion of treewidth-fragility, namely
tree-independence-number-fragility. In particular, we obtain polynomial-time
approximation schemes for independent packing problems on fractionally
tree-independence-number-fragile graph classes. Our approach unifies and
extends several known polynomial-time approximation schemes on seemingly
unrelated graph classes, such as classes of intersection graphs of fat objects
in a fixed dimension or proper minor-closed classes. We also study the related
notion of layered tree-independence number, a relaxation of layered treewidth.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Galby_E/0/1/0/all/0/1">Esther Galby</a>, <a href="http://arxiv.org/find/cs/1/au:+Munaro_A/0/1/0/all/0/1">Andrea Munaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shizhou Yang</a></p><p>We investigate a relaxation of the notion of treewidth-fragility, namely
tree-independence-number-fragility. In particular, we obtain polynomial-time
approximation schemes for independent packing problems on fractionally
tree-independence-number-fragile graph classes. Our approach unifies and
extends several known polynomial-time approximation schemes on seemingly
unrelated graph classes, such as classes of intersection graphs of fat objects
in a fixed dimension or proper minor-closed classes. We also study the related
notion of layered tree-independence number, a relaxation of layered treewidth.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07858'>Efficient Yao Graph Construction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Funke, Peter Sanders</p><p>Yao graphs are geometric spanners that connect each point of a given point
set to its nearest neighbor in each of $k$ cones drawn around it. Yao graphs
were introduced to construct minimum spanning trees in $d$ dimensional spaces.
Moreover, they are used for instance in topology control in wireless networks.
An optimal \Onlogn time algorithm to construct Yao graphs for given point set
has been proposed in the literature but -- to the best of our knowledge --
never been implemented. Instead, algorithms with a quadratic complexity are
used in popular packages to construct these graphs. In this paper we present
the first implementation of the optimal Yao graph algorithm. We develop and
tune the data structures required to achieve the O(n log n) bound and detail
algorithmic adaptions necessary to take the original algorithm from theory to
practice. We propose a priority queue data structure that separates static and
dynamic events and might be of independent interest for other sweepline
algorithms. Additionally, we propose a new Yao graph algorithm based on a
uniform grid data structure that performs well for medium-sized inputs. We
evaluate our implementations on a wide variety synthetic and real-world
datasets and show that our implementation outperforms current publicly
available implementations by at least an order of magnitude.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Funke_D/0/1/0/all/0/1">Daniel Funke</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanders_P/0/1/0/all/0/1">Peter Sanders</a></p><p>Yao graphs are geometric spanners that connect each point of a given point
set to its nearest neighbor in each of $k$ cones drawn around it. Yao graphs
were introduced to construct minimum spanning trees in $d$ dimensional spaces.
Moreover, they are used for instance in topology control in wireless networks.
An optimal \Onlogn time algorithm to construct Yao graphs for given point set
has been proposed in the literature but -- to the best of our knowledge --
never been implemented. Instead, algorithms with a quadratic complexity are
used in popular packages to construct these graphs. In this paper we present
the first implementation of the optimal Yao graph algorithm. We develop and
tune the data structures required to achieve the O(n log n) bound and detail
algorithmic adaptions necessary to take the original algorithm from theory to
practice. We propose a priority queue data structure that separates static and
dynamic events and might be of independent interest for other sweepline
algorithms. Additionally, we propose a new Yao graph algorithm based on a
uniform grid data structure that performs well for medium-sized inputs. We
evaluate our implementations on a wide variety synthetic and real-world
datasets and show that our implementation outperforms current publicly
available implementations by at least an order of magnitude.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07923'>FPT Constant-Approximations for Capacitated Clustering to Minimize the Sum of Cluster Radii</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sayan Bandyapadhyay, William Lochet, Saket Saurabh</p><p>Clustering with capacity constraints is a fundamental problem that attracted
significant attention throughout the years. In this paper, we give the first
FPT constant-factor approximation algorithm for the problem of clustering
points in a general metric into $k$ clusters to minimize the sum of cluster
radii, subject to non-uniform hard capacity constraints. In particular, we give
a $(15+\epsilon)$-approximation algorithm that runs in $2^{0(k^2\log k)}\cdot
n^3$ time. When capacities are uniform, we obtain the following improved
approximation bounds: A (4 + $\epsilon$)-approximation with running time
$2^{O(k\log(k/\epsilon))}n^3$, which significantly improves over the FPT
28-approximation of Inamdar and Varadarajan [ESA 2020]; a (2 +
$\epsilon$)-approximation with running time $2^{O(k/\epsilon^2
\cdot\log(k/\epsilon))}dn^3$ and a $(1+\epsilon)$-approximation with running
time $2^{O(kd\log ((k/\epsilon)))}n^{3}$ in the Euclidean space; and a (1 +
$\epsilon$)-approximation in the Euclidean space with running time
$2^{O(k/\epsilon^2 \cdot\log(k/\epsilon))}dn^3$ if we are allowed to violate
the capacities by (1 + $\epsilon$)-factor. We complement this result by showing
that there is no (1 + $\epsilon$)-approximation algorithm running in time
$f(k)\cdot n^{O(1)}$, if any capacity violation is not allowed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bandyapadhyay_S/0/1/0/all/0/1">Sayan Bandyapadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Lochet_W/0/1/0/all/0/1">William Lochet</a>, <a href="http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1">Saket Saurabh</a></p><p>Clustering with capacity constraints is a fundamental problem that attracted
significant attention throughout the years. In this paper, we give the first
FPT constant-factor approximation algorithm for the problem of clustering
points in a general metric into $k$ clusters to minimize the sum of cluster
radii, subject to non-uniform hard capacity constraints. In particular, we give
a $(15+\epsilon)$-approximation algorithm that runs in $2^{0(k^2\log k)}\cdot
n^3$ time. When capacities are uniform, we obtain the following improved
approximation bounds: A (4 + $\epsilon$)-approximation with running time
$2^{O(k\log(k/\epsilon))}n^3$, which significantly improves over the FPT
28-approximation of Inamdar and Varadarajan [ESA 2020]; a (2 +
$\epsilon$)-approximation with running time $2^{O(k/\epsilon^2
\cdot\log(k/\epsilon))}dn^3$ and a $(1+\epsilon)$-approximation with running
time $2^{O(kd\log ((k/\epsilon)))}n^{3}$ in the Euclidean space; and a (1 +
$\epsilon$)-approximation in the Euclidean space with running time
$2^{O(k/\epsilon^2 \cdot\log(k/\epsilon))}dn^3$ if we are allowed to violate
the capacities by (1 + $\epsilon$)-factor. We complement this result by showing
that there is no (1 + $\epsilon$)-approximation algorithm running in time
$f(k)\cdot n^{O(1)}$, if any capacity violation is not allowed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07708'>Enumerating all minimal hitting sets in polynomial total time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marcel Wild</p><p>Consider a hypergraph (=set system) $\mathbb{H}$ whose $h$ hyperedges are
subsets of a set with w elements. We show that the $R$ minimal hitting sets of
$\mathbb{H}$ can be enumerated in polynomial total time $O(Rh^2 w^2)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Wild_M/0/1/0/all/0/1">Marcel Wild</a></p><p>Consider a hypergraph (=set system) $\mathbb{H}$ whose $h$ hyperedges are
subsets of a set with w elements. We show that the $R$ minimal hitting sets of
$\mathbb{H}$ can be enumerated in polynomial total time $O(Rh^2 w^2)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.07984'>Asymptotically Sharp Upper Bound for the Column Subset Selection Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jian-Feng Cai, Zhiqiang Xu, Zili Xu</p><p>This paper investigates the spectral norm version of the column subset
selection problem. Given a matrix $\mathbf{A}\in\mathbb{R}^{n\times d}$ and a
positive integer $k\leq\text{rank}(\mathbf{A})$, the objective is to select
exactly $k$ columns of $\mathbf{A}$ that minimize the spectral norm of the
residual matrix after projecting $\mathbf{A}$ onto the space spanned by the
selected columns. We use the method of interlacing polynomials introduced by
Marcus-Spielman-Srivastava to derive an asymptotically sharp upper bound on the
minimal approximation error, and propose a deterministic polynomial-time
algorithm that achieves this error bound (up to a computational error).
Furthermore, we extend our result to a column partition problem in which the
columns of $\mathbf{A}$ can be partitioned into $r\geq 2$ subsets such that
$\mathbf{A}$ can be well approximated by subsets from various groups. We show
that the machinery of interlacing polynomials also works in this context, and
establish a connection between the relevant expected characteristic polynomials
and the $r$-characteristic polynomials introduced by Ravichandran and Leake. As
a consequence, we prove that the columns of a rank-$d$ matrix
$\mathbf{A}\in\mathbb{R}^{n\times d}$ can be partitioned into $r$ subsets
$S_1,\ldots S_r$, such that the column space of $\mathbf{A}$ can be well
approximated by the span of the columns in the complement of $S_i$ for each
$1\leq i\leq r$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jian-Feng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhiqiang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zili Xu</a></p><p>This paper investigates the spectral norm version of the column subset
selection problem. Given a matrix $\mathbf{A}\in\mathbb{R}^{n\times d}$ and a
positive integer $k\leq\text{rank}(\mathbf{A})$, the objective is to select
exactly $k$ columns of $\mathbf{A}$ that minimize the spectral norm of the
residual matrix after projecting $\mathbf{A}$ onto the space spanned by the
selected columns. We use the method of interlacing polynomials introduced by
Marcus-Spielman-Srivastava to derive an asymptotically sharp upper bound on the
minimal approximation error, and propose a deterministic polynomial-time
algorithm that achieves this error bound (up to a computational error).
Furthermore, we extend our result to a column partition problem in which the
columns of $\mathbf{A}$ can be partitioned into $r\geq 2$ subsets such that
$\mathbf{A}$ can be well approximated by subsets from various groups. We show
that the machinery of interlacing polynomials also works in this context, and
establish a connection between the relevant expected characteristic polynomials
and the $r$-characteristic polynomials introduced by Ravichandran and Leake. As
a consequence, we prove that the columns of a rank-$d$ matrix
$\mathbf{A}\in\mathbb{R}^{n\times d}$ can be partitioned into $r$ subsets
$S_1,\ldots S_r$, such that the column space of $\mathbf{A}$ can be well
approximated by the span of the columns in the complement of $S_i$ for each
$1\leq i\leq r$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.08118'>Parameterised Approximation of the Fixation Probability of the Dominant Mutation in the Multi-Type Moran Process</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Leslie Ann Goldberg, Marc Roth, Tassilo Constantin Schwarz</p><p>The multi-type Moran process is an evolutionary process on a connected graph
$G$ in which each vertex has one of $k$ types and, in each step, a vertex $v$
is chosen to reproduce its type to one of its neighbours. The probability of a
vertex $v$ being chosen for reproduction is proportional to the fitness of the
type of $v$. So far, the literature was almost solely concerned with the
$2$-type Moran process in which each vertex is either healthy (type $0$) or a
mutant (type $1$), and the main problem of interest has been the (approximate)
computation of the so-called fixation probability, i.e., the probability that
eventually all vertices are mutants.
</p>
<p>In this work we initiate the study of approximating fixation probabilities in
the multi-type Moran process on general graphs. Our main result is an FPTRAS
(fixed-parameter tractable randomised approximation scheme) for computing the
fixation probability of the dominant mutation; the parameter is the number of
types and their fitnesses. In the course of our studies we also provide novel
upper bounds on the expected absorption time, i.e., the time that it takes the
multi-type Moran process to reach a state in which each vertex has the same
type.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goldberg_L/0/1/0/all/0/1">Leslie Ann Goldberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_M/0/1/0/all/0/1">Marc Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwarz_T/0/1/0/all/0/1">Tassilo Constantin Schwarz</a></p><p>The multi-type Moran process is an evolutionary process on a connected graph
$G$ in which each vertex has one of $k$ types and, in each step, a vertex $v$
is chosen to reproduce its type to one of its neighbours. The probability of a
vertex $v$ being chosen for reproduction is proportional to the fitness of the
type of $v$. So far, the literature was almost solely concerned with the
$2$-type Moran process in which each vertex is either healthy (type $0$) or a
mutant (type $1$), and the main problem of interest has been the (approximate)
computation of the so-called fixation probability, i.e., the probability that
eventually all vertices are mutants.
</p>
<p>In this work we initiate the study of approximating fixation probabilities in
the multi-type Moran process on general graphs. Our main result is an FPTRAS
(fixed-parameter tractable randomised approximation scheme) for computing the
fixation probability of the dominant mutation; the parameter is the number of
types and their fitnesses. In the course of our studies we also provide novel
upper bounds on the expected absorption time, i.e., the time that it takes the
multi-type Moran process to reach a state in which each vertex has the same
type.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-15T00:30:00Z">Wednesday, March 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, March 14
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/03/14/is-pi-informative/'>Is Pi Informative?</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Some musings on the meanings of information content SF Exploratorium tribute Frank Oppenheimer was a physicist who made pioneering studies of cosmic rays via high-altitude balloons in the late 1940s. He was later the founding directorof the San Francicso Exploratorium. There he hired the physicist Larry Shaw, who became the creator of Pi Day. Today [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>Some musings on the meanings of information content</em><br />
<font color="#000000"></p>
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/03/14/is-pi-informative/frank-longbio/" rel="attachment wp-att-21241"><img data-attachment-id="21241" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/14/is-pi-informative/frank-longbio/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/frank-longbio.jpg?fit=200%2C222&amp;ssl=1" data-orig-size="200,222" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="frank-longbio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/frank-longbio.jpg?fit=200%2C222&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/frank-longbio.jpg?fit=200%2C222&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/frank-longbio.jpg?resize=134%2C148&#038;ssl=1" alt="" width="134" height="148" class="alignright wp-image-21241" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">SF Exploratorium <a href="https://www.exploratorium.edu/files/frank/bio/bio-long.html">tribute</a></font></td>
</tr>
</tbody>
</table>
<p>
Frank Oppenheimer was a physicist who made pioneering studies of cosmic rays via high-altitude balloons in the late 1940s. He was later the founding directorof the San Francicso Exploratorium. There he hired the physicist <a href="https://en.wikipedia.org/wiki/Larry_Shaw_(physicist)">Larry Shaw</a>, who became the creator of Pi Day.</p>
<p>
Today we discuss what information&#8212;if any&#8212;is conveyed by the digits of pi.</p>
<p>
Oppenheimer&#8217;s older brother Julius is better known as J. Robert Oppenheimer. He is the title subject of a major Hollywood <a href="https://en.wikipedia.org/wiki/Oppenheimer_(film)">biopic</a> directed by Christopher Nolan, to be released in July. The film will cover not only his work on the atomic bomb but also the revocation of his security clearance over ties to the Communist Party, of which Frank had been a card-carrying member. Frank lost his faculty position at the University of Minnesota and was blackballed from teaching physics anywhere until gaining a high school position in 1957 and joining the University of Colorado in 1959.</p>
<p>
We are thinking of another movie, <em>Everything, Everywhere, All at Once</em>, which just won the Best Picture Oscar. It involves the <a href="https://en.wikipedia.org/wiki/Multiverse">multiverse</a> as a <a href="https://en.wikipedia.org/wiki/MacGuffin">macguffin</a>. Could pi have a different value in another universe? As card-carrying Platonists, our instinct is to just say <em>no</em>. But a related question lends some subtlety.</p>
<p>
<p><H2> Does Pi Equal 0/(2i)? </H2></p>
<p><p>
I considered titling this post, &#8220;Does Pi Equal Zero?&#8221; I realized that, if anything, it is <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi+i%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{2&#92;pi i}" class="latex" /> that equals zero&#8212;if you are raising <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Be%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{e}" class="latex" /> to that number. Then <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+%3D+%5Cfrac%7B0%7D%7B2i%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi = &#92;frac{0}{2i}}" class="latex" />.</p>
<p>
What I really mean is to ask:</p>
<blockquote><p><b> </b> <em> Does <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" /> have zero information content? </em>
</p></blockquote>
<p><p>
Here is a sense in which the answer is basically yes: Pi comes from a short program. Perhaps the simplest one is </p>
<p align=center><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi+%3D+4%5Cleft%281+-+%5Cfrac%7B1%7D%7B3%7D+%2B+%5Cfrac%7B1%7D%7B5%7D+-+%5Cfrac%7B1%7D%7B7%7D+%2B+%5Cfrac%7B1%7D%7B9%7D+-+%5Cfrac%7B1%7D%7B11%7D+%2B+%5Ccdots%5Cright%29+&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle  &#92;pi = 4&#92;left(1 - &#92;frac{1}{3} + &#92;frac{1}{5} - &#92;frac{1}{7} + &#92;frac{1}{9} - &#92;frac{1}{11} + &#92;cdots&#92;right) " class="latex" /></p>
<p>via the <a href="https://en.wikipedia.org/wiki/Madhava_series">Madhava series</a>. There are less-simple programs that converge more quickly&#8212;plus we long ago covered <a href="https://rjlipton.wpcomstaging.com/2009/03/15/cooks-class-contains-pi/">this</a> and <a href="https://rjlipton.wpcomstaging.com/2010/07/14/making-an-algorithm-an-algorithm-bbp/">this</a>&#8212;but speed of approximation does not matter for the information content of the specification.</p>
<p>
We can also say that the specification is just <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cbigcirc%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;bigcirc}" class="latex" />. Or more clearly, a circle with a diameter: <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cominus%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;ominus}" class="latex" />. That is literally minuscule. By Claude Shannon&#8217;s information theory, this little speck of spec is the information content of pi.</p>
<p>
<p><H2> Making Contact With Our Question </H2></p>
<p><p>
Our question is joined by Carl Sagan&#8217;s novel <a href="https://en.wikipedia.org/wiki/Contact_(novel)">Contact</a>, especially the last two pages. Having been tipped by the aliens to look for evidence of super-intelligence in fundamental constants, Ellie Arroway sets a super-computer onto <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" /> and receives a statistically significant pattern in its expansion. It gives a raster image using only the digits <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B0%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{0}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{1}" class="latex" /> of a nearly perfect circle. Arroway regards this also as a personal message symbolizing her full-circle journey. </p>
<p>
To quote the last page:</p>
<blockquote><p><b> </b> <em> In whatever galaxy you happen to find yourself, you take the circumference of a circle, divide it by a diameter, measure closely enough, and uncover a miracle&#8212;another circle, drawn kilometers downstream of the decimal point. There would be richer messages further in. </em>
</p></blockquote>
<p><p>
This causes a &#8220;wait-a-sec&#8230;&#8221; reaction. If <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" /> has minuscule information content, then how can any meaningful block of information be contained in it? By <em>meaningful</em> we mean that the block has more information than the effort needed to specify the block.</p>
<p>
Hereby hangs a tale. It is almost universally believed that every finite sequence of digits appears somewhere in the base-10 expansion of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" />. It is believed further that <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" /> is <a href="https://en.wikipedia.org/wiki/Normal_number">normal</a>, meaning that for every <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />, every word in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Bk%5D%5En%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{[k]^n}" class="latex" /> appears with frequency converging to <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7B-n%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k^{-n}}" class="latex" /> in the base-<img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> expansion of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" />. Thus, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" /> almost certainly contains <a href="https://en.wikipedia.org/wiki/Waiting_for_Godot">Waiting for Godot</a> in the original French in base 16, taking every two hex digits as an ASCII character. </p>
<p>
But you have to wait a long time to find it&#8212;and specifying an offset <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Br%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{r}" class="latex" /> where it begins expends as much information as is gained by reading it. There is no net gain of information from the tumbling hexadecimals. This reality is consistent with the zero-information picture, in the same sense that the vacuum of space teems with dancing particles and antiparticles that ultimately cancel.</p>
<p>
<p><H2> Baking a Base Into Pi </H2></p>
<p><p>
<em>Contact</em>, however, includes a twist different from having strings in base 10 or base 16. The raster message appears when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" /> is written in base <i>eleven</i>.  We could quibble that Sagan should have written, &#8220;&#8230;kilometers downstream of the <a href="https://en.wikipedia.org/wiki/Undecimal">undecimal</a> point.&#8221; </p>
<p>
Base eleven must count as an &#8220;unusual&#8221; base. Maybe a choice like base 57&#8212;the first Grothendieck <a href="https://hsm.stackexchange.com/questions/6358/story-of-grothendiecks-prime-number">prime</a>&#8212;would be more unusual. Choosing a base is a sneaky way to inflate the resulting expansion of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" /> with more information&#8212;the information from specifying the base.</p>
<p>
Taking this idea further, we could consider bases that are fractional, or algebraic irrational, or even transcendental. We can do expansions in base <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" /> itself. In that base, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" /> has a simple representation: <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+%3D+10_%7B%5Cpi%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi = 10_{&#92;pi}}" class="latex" />.</p>
<p>
We may, however, have to regard cherry-picking the base <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> as a similar statistical fools&#8217; errand to picking the offset <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Br%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{r}" class="latex" /> (in whatever base). Base eleven is simple enough to allow that the <em>elective bias</em> of choosing it is minimal, so that the raster-circle message would retain its significance. But that is in a novel, anway. In reality, the ability to select the base raises the bar of how much information is needed to glean in order to infer structure rather than chance. </p>
<p>
<p><H2> E Replies </H2></p>
<p><p>
The transcendental partner of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" /> in the unifying equation <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Be%5E%7B%5Cpi+i%7D+%2B+1+%3D+0%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{e^{&#92;pi i} + 1 = 0}" class="latex" /> replies to this statistical nullification with thunder:</p>
<blockquote><p><b> </b> <em> e = 2.7<b>18281828</b>&#8230;, you fools. </em>
</p></blockquote>
<p><p>
This is in our native base-ten representation. Perhaps this is the true message from the cosmos, ordaining that we have ten fingers and ten toes, so that no artifice of choosing the base is needed to reveal it.</p>
<p>
There is a real-life claim of a significant find in the base-ten expansion of pi. It is by Arne Bergstrom in a 2014 <a href="https://www.semanticscholar.org/paper/Carl-Sagan's-Conjecture-of-a-Message-in-Pi-Bergstrom/05e8ec7f5875a65ef854a235ffaac8a4b73329b0">paper</a> titled, &#8220;Carl Sagan&#8217;s Conjecture of a Message in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" />.&#8221; It is in the number <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Ctau+%3D+2%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;tau = 2&#92;pi}" class="latex" />, whose primacy over <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" /> we <a href="https://rjlipton.wpcomstaging.com/2021/03/14/the-value-of-pi/">argued</a> two years ago today. From its abstract:</p>
<blockquote><p><b> </b> <em> The present article looks for markers that might possibly support such a hypothesis, and surprisingly finds a sequence of seven successive zeros (actually seven successive nines rounded off) at a depth of 3,256 digits into the representation of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{2&#92;pi}" class="latex" /> in the special case of base ten. Finding such a sequence of zeros within the first 1,000 digits has a probability of 1 in 10,000. No such occurrences happen even remotely for <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{2&#92;pi}" class="latex" /> at any base other than ten, nor even remotely in corresponding representations of other common transcendental numbers, such as <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Be%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{e}" class="latex" />, which appear in physical applications. </em>
</p></blockquote>
<p><p>
The abstract goes on to concede, however, that &#8220;these effects are most probably just numerical coincidences without physical relevance.&#8221; </p>
<p>
The reference to physics brings us full-circle. Non-Euclidean spaces can have notions of &#8220;circle&#8221; defined by equidistance and of &#8220;diameter&#8221; whose ratio is not <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" />. If we ever find that we live in a space that in large scales is curved, however slightly, might this dislodge our conviction that Euclidean space is salient? If so, then we might regard the value <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B3.14159265358...%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{3.14159265358...}" class="latex" /> as having elective bias after all. This change in attitude would be accompanied, so I conjecture, by the pre-actuated infusion of a huge amount of genuine information in the digits of&#8212;the Euclidean value of&#8212;<img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" />.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Where does this leave us in regard to the information content of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" />? How does it differ in this regard from the measure-one set of real numbers in the unit interval that are both algorithmically and statistically random?</p>
<p><P><br />
[fixed pi in base pi = 10, not 1]</p>
<p class="authors">By KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-14T06:39:38Z">Tuesday, March 14 2023, 06:39</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06256'>A Quantum Outlier Theorem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samuel Epstein</p><p>In recent results, it has been proven that all sampling methods produce
outliers. In this paper, we extend these results to quantum information theory.
Projectors of large rank must contain pure quantum states in their images that
are outlying states. Otherwise, the projectors are exotic, in that they have
high mutual information with the halting sequence. Thus quantum coding schemes
that use projections, such as Schumacher compression, must communicate using
outlier quantum states.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1">Samuel Epstein</a></p><p>In recent results, it has been proven that all sampling methods produce
outliers. In this paper, we extend these results to quantum information theory.
Projectors of large rank must contain pure quantum states in their images that
are outlying states. Otherwise, the projectors are exotic, in that they have
high mutual information with the halting sequence. Thus quantum coding schemes
that use projections, such as Schumacher compression, must communicate using
outlier quantum states.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-14T00:30:00Z">Tuesday, March 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06321'>Finding large counterexamples by selectively exploring the Pachner graph</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Benjamin A. Burton, Alexander He</p><p>We often rely on censuses of triangulations to guide our intuition in
$3$-manifold topology. However, this can lead to misplaced faith in conjectures
if the smallest counterexamples are too large to appear in our census. Since
the number of triangulations increases super-exponentially with size, there is
no way to expand a census beyond relatively small triangulations; the current
census only goes up to $10$ tetrahedra. Here, we show that it is feasible to
search for large and hard-to-find counterexamples by using heuristics to
selectively (rather than exhaustively) enumerate triangulations. We use this
idea to find counterexamples to three conjectures which ask, for certain
$3$-manifolds, whether one-vertex triangulations always have a "distinctive"
edge that would allow us to recognise the $3$-manifold.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Burton_B/0/1/0/all/0/1">Benjamin A. Burton</a>, <a href="http://arxiv.org/find/math/1/au:+He_A/0/1/0/all/0/1">Alexander He</a></p><p>We often rely on censuses of triangulations to guide our intuition in
$3$-manifold topology. However, this can lead to misplaced faith in conjectures
if the smallest counterexamples are too large to appear in our census. Since
the number of triangulations increases super-exponentially with size, there is
no way to expand a census beyond relatively small triangulations; the current
census only goes up to $10$ tetrahedra. Here, we show that it is feasible to
search for large and hard-to-find counterexamples by using heuristics to
selectively (rather than exhaustively) enumerate triangulations. We use this
idea to find counterexamples to three conjectures which ask, for certain
$3$-manifolds, whether one-vertex triangulations always have a "distinctive"
edge that would allow us to recognise the $3$-manifold.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-14T00:30:00Z">Tuesday, March 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06354'>Betti Number for Point Sets</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hao Wang</p><p>Topology is the foundation for many industrial applications ranging from CAD
to simulation analysis. Computational topology mostly focuses on structured
data such as mesh, however unstructured dataset such as point set remains a
virgin land for topology scientists. The significance of point-based topology
can never be overemphasized, especially in the area of reverse engineering,
geometric modeling and algorithmic analysis. In this paper, we propose a novel
approach to compute the Betti number for point set data and illustrate its
usefulness in real world examples. To the best of our knowledge, our work is
pioneering and first of its kind in the fields of computational topology.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a></p><p>Topology is the foundation for many industrial applications ranging from CAD
to simulation analysis. Computational topology mostly focuses on structured
data such as mesh, however unstructured dataset such as point set remains a
virgin land for topology scientists. The significance of point-based topology
can never be overemphasized, especially in the area of reverse engineering,
geometric modeling and algorithmic analysis. In this paper, we propose a novel
approach to compute the Betti number for point set data and illustrate its
usefulness in real world examples. To the best of our knowledge, our work is
pioneering and first of its kind in the fields of computational topology.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-14T00:30:00Z">Tuesday, March 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06288'>Generalizing Greenwald-Khanna Streaming Quantile Summaries for Weighted Inputs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sepehr Assadi, Nirmit Joshi, Milind Prabhu, Vihan Shah</p><p>Estimating quantiles, like the median or percentiles, is a fundamental task
in data mining and data science. A (streaming) quantile summary is a data
structure that can process a set S of n elements in a streaming fashion and at
the end, for any phi in (0,1], return a phi-quantile of S up to an eps error,
i.e., return a phi'-quantile with phi'=phi +- eps. We are particularly
interested in comparison-based summaries that only compare elements of the
universe under a total ordering and are otherwise completely oblivious of the
universe. The best known deterministic quantile summary is the 20-year old
Greenwald-Khanna (GK) summary that uses O((1/eps) log(eps n)) space
[SIGMOD'01]. This bound was recently proved to be optimal for all deterministic
comparison-based summaries by Cormode and Vesle\'y [PODS'20].
</p>
<p>In this paper, we study weighted quantiles, a generalization of the quantiles
problem, where each element arrives with a positive integer weight which
denotes the number of copies of that element being inserted. The only known
method of handling weighted inputs via GK summaries is the naive approach of
breaking each weighted element into multiple unweighted items and feeding them
one by one to the summary, which results in a prohibitively large update time
(proportional to the maximum weight of input elements).
</p>
<p>We give the first non-trivial extension of GK summaries for weighted inputs
and show that it takes O((1/eps) log(eps n)) space and O(log(1/eps)+ log
log(eps n)) update time per element to process a stream of length n (under some
quite mild assumptions on the range of weights and eps). En route to this, we
also simplify the original GK summaries for unweighted quantiles.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Assadi_S/0/1/0/all/0/1">Sepehr Assadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1">Nirmit Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Prabhu_M/0/1/0/all/0/1">Milind Prabhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_V/0/1/0/all/0/1">Vihan Shah</a></p><p>Estimating quantiles, like the median or percentiles, is a fundamental task
in data mining and data science. A (streaming) quantile summary is a data
structure that can process a set S of n elements in a streaming fashion and at
the end, for any phi in (0,1], return a phi-quantile of S up to an eps error,
i.e., return a phi'-quantile with phi'=phi +- eps. We are particularly
interested in comparison-based summaries that only compare elements of the
universe under a total ordering and are otherwise completely oblivious of the
universe. The best known deterministic quantile summary is the 20-year old
Greenwald-Khanna (GK) summary that uses O((1/eps) log(eps n)) space
[SIGMOD'01]. This bound was recently proved to be optimal for all deterministic
comparison-based summaries by Cormode and Vesle\'y [PODS'20].
</p>
<p>In this paper, we study weighted quantiles, a generalization of the quantiles
problem, where each element arrives with a positive integer weight which
denotes the number of copies of that element being inserted. The only known
method of handling weighted inputs via GK summaries is the naive approach of
breaking each weighted element into multiple unweighted items and feeding them
one by one to the summary, which results in a prohibitively large update time
(proportional to the maximum weight of input elements).
</p>
<p>We give the first non-trivial extension of GK summaries for weighted inputs
and show that it takes O((1/eps) log(eps n)) space and O(log(1/eps)+ log
log(eps n)) update time per element to process a stream of length n (under some
quite mild assumptions on the range of weights and eps). En route to this, we
also simplify the original GK summaries for unweighted quantiles.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-14T00:30:00Z">Tuesday, March 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06488'>Binary Search with Distance-Dependent Costs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Calvin Leng, David Kempe</p><p>We introduce a search problem generalizing the typical setting of Binary
Search on the line. Similar to the setting for Binary Search, a target is
chosen adversarially on the line, and in response to a query, the algorithm
learns whether the query was correct, too high, or too low. Different from the
Binary Search setting, the cost of a query is a monotone non-decreasing
function of the distance between the query and the correct answer; different
functions can be used for queries that are too high vs. those that are too low.
The algorithm's goal is to identify an adversarially chosen target with minimum
total cost. Note that the algorithm does not even know the cost it incurred
until the end, when the target is revealed. This abstraction captures many
natural settings in which a principal experiments by setting a quantity (such
as an item price, bandwidth, tax rate, medicine dosage, etc.) where the cost or
regret increases the further the chosen setting is from the optimal one.
</p>
<p>First, we show that for arbitrary symmetric cost functions (i.e.,
overshooting vs. undershooting by the same amount leads to the same cost), the
standard Binary Search algorithm is a 4-approximation.
</p>
<p>We then show that when the cost functions are bounded-degree polynomials of
the distance, the problem can be solved optimally using Dynamic Programming;
this relies on a careful encoding of the combined cost of past queries (which,
recall, will only be revealed in the future). We then generalize the setting to
finding a node on a tree; here, the response to a query is the direction on the
tree in which the target is located, and the cost is increasing in the distance
on the tree from the query to the target. Using the k-cut search tree framework
of Berendsohn and Kozma and the ideas we developed for the case of the line, we
give a PTAS when the cost function is a bounded-degree polynomial.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Leng_C/0/1/0/all/0/1">Calvin Leng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kempe_D/0/1/0/all/0/1">David Kempe</a></p><p>We introduce a search problem generalizing the typical setting of Binary
Search on the line. Similar to the setting for Binary Search, a target is
chosen adversarially on the line, and in response to a query, the algorithm
learns whether the query was correct, too high, or too low. Different from the
Binary Search setting, the cost of a query is a monotone non-decreasing
function of the distance between the query and the correct answer; different
functions can be used for queries that are too high vs. those that are too low.
The algorithm's goal is to identify an adversarially chosen target with minimum
total cost. Note that the algorithm does not even know the cost it incurred
until the end, when the target is revealed. This abstraction captures many
natural settings in which a principal experiments by setting a quantity (such
as an item price, bandwidth, tax rate, medicine dosage, etc.) where the cost or
regret increases the further the chosen setting is from the optimal one.
</p>
<p>First, we show that for arbitrary symmetric cost functions (i.e.,
overshooting vs. undershooting by the same amount leads to the same cost), the
standard Binary Search algorithm is a 4-approximation.
</p>
<p>We then show that when the cost functions are bounded-degree polynomials of
the distance, the problem can be solved optimally using Dynamic Programming;
this relies on a careful encoding of the combined cost of past queries (which,
recall, will only be revealed in the future). We then generalize the setting to
finding a node on a tree; here, the response to a query is the direction on the
tree in which the target is located, and the cost is increasing in the distance
on the tree from the query to the target. Using the k-cut search tree framework
of Berendsohn and Kozma and the ideas we developed for the case of the line, we
give a PTAS when the cost function is a bounded-degree polynomial.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-14T00:30:00Z">Tuesday, March 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, March 13
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/03/13/phd-and-post-doctoral-positions-at-augusta-university-apply-by-june-1-2023/'>PhD and Post-doctoral Positions  at Augusta University (apply by June 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Concurrency In Reversible Computations (github.com/CinRC) project is actively seeking a PhD student to fund starting Spring 2024. The funding for an admitted PhD student includes tuition waiver, stipend, health benefits, (international) conference travel and possibly equipment. Funding is currently available for the first three years of the appointment through a new NSF funded project. [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Concurrency In Reversible Computations (<a href="https://github.com/CinRC">https://github.com/CinRC</a>) project is actively seeking a PhD student to fund starting Spring 2024. The funding for an admitted PhD student includes tuition waiver, stipend, health benefits, (international) conference travel and possibly equipment. Funding is currently available for the first three years of the appointment through a new NSF funded project.</p>
<p>Website: <a href="https://spots.augusta.edu/caubert/research/cinrc/phd_ad.html">https://spots.augusta.edu/caubert/research/cinrc/phd_ad.html</a><br />
Email: clement.aubert@math.cnrs.fr</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T18:13:12Z">Monday, March 13 2023, 18:13</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/03/problems-we-assume-are-hard-are-they.html'>Problems we assume are hard. Are they? ALSO- revised version of Demaine-Gasarch-Hajiaghayi is posted!</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;(The latest version of&nbsp;</p><p>Computational Intractability: A Guide to Algorithmic Lower Bounds</p><p>by Demaine-Gasarch-Hajiaghayi is posted&nbsp;here. Its new and improved: (1) we have made all or most of the corrections send to us by proofreaders,&nbsp; (2) there is a chapter on quantum computing, (3) there is an index.&nbsp; Feel free to read it and send us corrections!&nbsp;</p><p>This post is related to it in that most of the problems-assumed-hard mentioned in this post were the basis for chapters of the book.)</p><p><br></p><p>We think SAT is hard because (1) its NPC, and (2) many years of effort have failed to get it into P.&nbsp;</p><p>Imagine a world where we didn't have the Cook-Levin Theorem. We may still think SAT is hard. We may even take it as a hardness assumption to prove other things hard by showing SAT \le A. We may also be curious if they are equivalent and have lots of reductions A \le SAT. The reductions might be Karp or Cook.&nbsp;</p><p>You do not have to imagine this world! We already have it- in different contexts. In other areas of complexity theory there are problems that are assumed hard, but for which there is no analog of Cook-Levin. Are they hard? They seem to be- but the evidence is empirical. Not that there's anything wrong with that.&nbsp;</p><p>I will list out problems that&nbsp;</p><p>a) we assume are hard, for some definition of&nbsp; we and hard.</p><p>b) we have NO proof of that and NO completeness or hardness result.&nbsp; ADDED LATER- a commenter wanted me to clarify this.</p><p>&nbsp;For SAT there is a well defined set of problems, NP, defined independent of any particular problem (that is, NP was NOT defined as all sets Karp-Red to TSP or anything of the sort) and by Cook-Levin we have&nbsp;</p><p>if SAT is in P then NP is contained in P.</p><p>For FPT (the class the commenter was interested in) there IS the result</p><p>if weighed k-SAT is in FPT then W[1] is contained in FPT.</p><p>but W[1] is DEFINED as the set of problems FPT reducible to Weft-1 circuits (some books use a different basic problems) which IN MY OPINION is not a natural class. One may disagree with this of course.&nbsp;</p><p><br></p><p><br></p><p>COUNTERAUGMENT: but W[1] Was defined as all problems FPT-reducible to Weft-1 circuits. And this is not the same&nbsp;</p><p>(I do not include hardness assumptions for crypto because that's not quite the same thing. Also there are just so many of them!)&nbsp;</p><p>I am sure I missed some- which is where YOU come in! Please leave comments with additional problems that I forgot (or perhaps did not know) to include.&nbsp;</p><p>1) 1vs2 cycle: Given a graph that you are guaranteed is 1 cycle or the union of 2 cycles, determine which is the case. This is assumed to be hard to parallelize (we omit details&nbsp;of defining that formally).&nbsp; This has been used for lower bounds in parallelism. See&nbsp;here.</p><p>2) 3SUM: Given x1,..,xn an array of integers, are there 3 that add to 0? There is an O(n^2) algorithm. The hardness assumption is that, for all epsilon, there is no O(n^{2-\epsilon}) algorithm. This assumption has been used to get lower bounds in comp. geom. See the Wikipedia entry&nbsp;here&nbsp;or the introduction of this paper&nbsp;here</p><p>4) APSP (All Pairs Shortest Path) Given a graph G, find for each pair of vertices&nbsp; the length of the shortest path. There is an O(n^3) algorithm. The hardness assumption is that, for all epsilon, there is no O(n^{3-epsilon}) algorithm. This assumption has been used to get lower bounds on graph problems. For more details see the introduction of this paper:&nbsp;here</p><p>5)&nbsp; Weighted-SAT-k: Given a Boolean formula (it can be taken to be in 2CNF form) is there a satisfying assignment that has exactly k of the variables set to TRUE. This is assumed to not be fixed parameter tractable (that is no function f such that this problem is in&nbsp; O(f(k)n^{O(1)}) time). Problems that are FPT-equiv to it are called W[1]-complete and are all thought to not be in FPT. W[2], W[t] are also defined but we omit this. W[1]-complete has also been defined in other ways, but I can't seem to find a Cook-Levin type theorem for them.&nbsp;</p><p>6) Graph Isom.&nbsp; One of he few problems that are in NP but thought to not be NP-complete and, at least for now, is not in P. Babai has shown its in quasi-poly time (n^{(log n)^{O(1)}). There is a notion of GI-hard: problems that, if they are in P then GI is in P. See he Wikipedia entry&nbsp;here. Most of the GI-hard problems are variants of GI, e.g., graph isom. for directed graphs. GI could be in P without unbelievable consequences for complexity and without terrifying consequences for cryptography.&nbsp;</p><p>7) Unique Games Conj: I won't define it formally here, see the Wikipedia entry&nbsp;here. From UGC you get several approximation results are optimal. Does that argue for UGC being true-- having consequences we believe? I would say YES since in some cases the algorithm that gives a good approx has an alpha-approx for some weird number alpha, and assuming UGC you get the SAME alpha as a lower bound.&nbsp;</p><p>8) Existential&nbsp; Theory of the Reals. Easier for you to read the Wikipedia entry&nbsp;here. It is used for problems that are inbetween NP and PSPACE. (ADDED LATER: One of the commenters says that Blum-Shub-Smale showed ETR is complete for the real version of&nbsp; NP, so this item should not be on my list.)&nbsp;</p><p>9) Orthogonal vector conjecture. See this paper:&nbsp;here. This is used to show problems are not in subquadratic time.&nbsp;</p><p>Possible research directions and thoughts</p><p>a) Try to prove a Cook-Levin type theorem for one of these problems.</p><p>b) Build classes analogous to the poly-hiearchy on one of these problems.</p><p>c) Ask bounded-query questions. For example: Are k queries to 3SUM more powerful than k-1 (This is a VERY Gasarchian question.)&nbsp;</p><p>d) Try to prove that one of these problems is actually hard. That seems hard. Perhaps on a weaker model (thats prob already been done for at least one of them.)</p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;(The latest version of&nbsp;</p><p>Computational Intractability: A Guide to Algorithmic Lower Bounds</p><p>by Demaine-Gasarch-Hajiaghayi is posted&nbsp;<a href="https://hardness.mit.edu/">here</a>. Its new and improved: (1) we have made all or most of the corrections send to us by proofreaders,&nbsp; (2) there is a chapter on quantum computing, (3) there is an index.&nbsp; Feel free to read it and send us corrections!&nbsp;</p><p>This post is related to it in that most of the problems-assumed-hard mentioned in this post were the basis for chapters of the book.)</p><p><br /></p><p>We think SAT is hard because (1) its NPC, and (2) many years of effort have failed to get it into P.&nbsp;</p><p>Imagine a world where we didn't have the Cook-Levin Theorem. We may still think SAT is hard. We may even take it as a hardness assumption to prove other things hard by showing SAT \le A. We may also be curious if they are equivalent and have lots of reductions A \le SAT. The reductions might be Karp or Cook.&nbsp;</p><p>You do not have to imagine this world! We already have it- in different contexts. In other areas of complexity theory there are problems that are assumed hard, but for which there is no analog of Cook-Levin. Are they hard? They seem to be- but the evidence is empirical. Not that there's anything wrong with that.&nbsp;</p><p>I will list out problems that&nbsp;</p><p>a) we assume are hard, for some definition of&nbsp; <i>we </i>and <i>hard.</i></p><p>b) we have NO proof of that and NO completeness or hardness result.&nbsp; ADDED LATER- a commenter wanted me to clarify this.</p><p>&nbsp;For SAT there is a well defined set of problems, NP, defined independent of any particular problem (that is, NP was NOT defined as all sets Karp-Red to TSP or anything of the sort) and by Cook-Levin we have&nbsp;</p><p>if SAT is in P then NP is contained in P.</p><p>For FPT (the class the commenter was interested in) there IS the result</p><p>if weighed k-SAT is in FPT then W[1] is contained in FPT.</p><p>but W[1] is DEFINED as the set of problems FPT reducible to Weft-1 circuits (some books use a different basic problems) which IN MY OPINION is not a natural class. One may disagree with this of course.&nbsp;</p><p><br /></p><p><br /></p><p>COUNTERAUGMENT: but W[1] Was defined as all problems FPT-reducible to Weft-1 circuits. And this is not the same&nbsp;</p><p>(I do not include hardness assumptions for crypto because that's not quite the same thing. Also there are just so many of them!)&nbsp;</p><p>I am sure I missed some- which is where YOU come in! Please leave comments with additional problems that I forgot (or perhaps did not know) to include.&nbsp;</p><p>1) 1vs2 cycle: Given a graph that you are guaranteed is 1 cycle or the union of 2 cycles, determine which is the case. This is assumed to be hard to parallelize (we omit details&nbsp;of defining that formally).&nbsp; This has been used for lower bounds in parallelism. See&nbsp;<a href="https://doi.org/10.1109/FOCS.2019.00097">here</a>.</p><p>2) 3SUM: Given x1,..,xn an array of integers, are there 3 that add to 0? There is an O(n^2) algorithm. The hardness assumption is that, for all epsilon, there is no O(n^{2-\epsilon}) algorithm. This assumption has been used to get lower bounds in comp. geom. See the Wikipedia entry&nbsp;<a href="https://en.wikipedia.org/wiki/3SUM">here</a>&nbsp;or the introduction of this paper&nbsp;<a href="https://arxiv.org/pdf/2203.08356.pdf">here</a></p><p>4) APSP (All Pairs Shortest Path) Given a graph G, find for each pair of vertices&nbsp; the length of the shortest path. There is an O(n^3) algorithm. The hardness assumption is that, for all epsilon, there is no O(n^{3-epsilon}) algorithm. This assumption has been used to get lower bounds on graph problems. For more details see the introduction of this paper:&nbsp;<a href="https://arxiv.org/pdf/2203.08356.pdf">here</a></p><p>5)&nbsp; Weighted-SAT-k: Given a Boolean formula (it can be taken to be in 2CNF form) is there a satisfying assignment that has exactly k of the variables set to TRUE. This is assumed to not be fixed parameter tractable (that is no function f such that this problem is in&nbsp; O(f(k)n^{O(1)}) time). Problems that are FPT-equiv to it are called W[1]-complete and are all thought to not be in FPT. W[2], W[t] are also defined but we omit this. W[1]-complete has also been defined in other ways, but I can't seem to find a Cook-Levin type theorem for them.&nbsp;</p><p>6) Graph Isom.&nbsp; One of he few problems that are in NP but thought to not be NP-complete and, at least for now, is not in P. Babai has shown its in quasi-poly time (n^{(log n)^{O(1)}). There is a notion of GI-hard: problems that, if they are in P then GI is in P. See he Wikipedia entry&nbsp;<a href="https://en.wikipedia.org/wiki/Graph_isomorphism_problem">here</a>. Most of the GI-hard problems are variants of GI, e.g., graph isom. for directed graphs. GI could be in P without unbelievable consequences for complexity and without terrifying consequences for cryptography.&nbsp;</p><p>7) Unique Games Conj: I won't define it formally here, see the Wikipedia entry&nbsp;<a href="https://en.wikipedia.org/wiki/Unique_games_conjecture">here</a>. From UGC you get several approximation results are optimal. Does that argue for UGC being true-- having consequences we believe? I would say YES since in some cases the algorithm that gives a good approx has an alpha-approx for some weird number alpha, and assuming UGC you get the SAME alpha as a lower bound.&nbsp;</p><p>8) Existential&nbsp; Theory of the Reals. Easier for you to read the Wikipedia entry&nbsp;<a href="https://en.wikipedia.org/wiki/Existential_theory_of_the_reals">here</a>. It is used for problems that are inbetween NP and PSPACE. (ADDED LATER: One of the commenters says that Blum-Shub-Smale showed ETR is complete for the real version of&nbsp; NP, so this item should not be on my list.)&nbsp;</p><p>9) Orthogonal vector conjecture. See this paper:&nbsp;<a href="https://www.mit.edu/~lijieche/SODA_2019_OV-Equiv-Fullversion.pdf">here</a>. This is used to show problems are not in subquadratic time.&nbsp;</p><p>Possible research directions and thoughts</p><p>a) Try to prove a Cook-Levin type theorem for one of these problems.</p><p>b) Build classes analogous to the poly-hiearchy on one of these problems.</p><p>c) Ask bounded-query questions. For example: Are k queries to 3SUM more powerful than k-1 (This is a VERY Gasarchian question.)&nbsp;</p><p>d) Try to prove that one of these problems is actually hard. That seems hard. Perhaps on a weaker model (thats prob already been done for at least one of them.)</p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T15:39:00Z">Monday, March 13 2023, 15:39</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://francisbach.com/jensen-inequality/'>Revisiting the classics: Jensen’s inequality</a></h3>
        <p class='tr-article-feed'>from <a href='https://francisbach.com'>Francis Bach</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          There are a few mathematical results that any researcher in applied mathematics uses on a daily basis. One of them is Jensen&#8217;s inequality, which allows bounding expectations of functions of random variables. This really happens a lot in any probabilistic arguments but also as a tool to generate inequalities and optimization algorithms. In this blog...
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="justify-text">There are a few mathematical results that any researcher in applied mathematics uses on a daily basis. One of them is Jensen&#8217;s inequality, which allows bounding expectations of functions of random variables. This really happens a lot in any probabilistic arguments but also as a tool to generate inequalities and optimization algorithms. In this blog post, I will present a collection of fun facts about the inequality, from very classical to more obscure. If you know other cool ones, please add them as comments.</p>



<p class="justify-text">But before, <em><strong>let me be very clear</strong></em>: Jensen&#8217;s inequality is often not in the direction that you would hope it to be. So, to avoid embarrassing mistakes, I always draw at least in my mind the figure below before using it.  </p>


<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img src="https://francisbach.com/wp-content/uploads/2023/03/jensen-3.png" alt="" class="wp-image-8873" width="546" height="243" srcset="https://francisbach.com/wp-content/uploads/2023/03/jensen-3.png 1616w, https://francisbach.com/wp-content/uploads/2023/03/jensen-3-300x134.png 300w, https://francisbach.com/wp-content/uploads/2023/03/jensen-3-1024x456.png 1024w, https://francisbach.com/wp-content/uploads/2023/03/jensen-3-768x342.png 768w, https://francisbach.com/wp-content/uploads/2023/03/jensen-3-1536x684.png 1536w, https://francisbach.com/wp-content/uploads/2023/03/jensen-3-850x379.png 850w" sizes="(max-width: 546px) 100vw, 546px" /></figure></div>


<h2>Simplest formulation and proof</h2>



<p class="justify-text">Given a convex function defined on a convex subset \(C\) of \(\mathbb{R}^d\), and a random vector \(X\) with values in \(C\), then $$ f\big( \mathbb{E}[X] \big) \leqslant \mathbb{E} \big[ f(X) \big],$$ as soon as the expectations exist. For a strictly convex function, there is equality if and only if \(X\) is almost surely constant. This is often stated with \(\mu\) taking finitely many values, like in the plot below.</p>



<p class="justify-text"><strong>Proof.</strong> Starting with the standard definition of convexity that corresponds to random variables that take only two values in \(C\), this can be extended by recursion to all random variables taking finitely many values, and then by a density argument, to all random variables. See the <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">Wikipedia</a> page.</p>



<p class="justify-text"><strong>Proof without words.</strong> As nicely explained in this <a href="https://mark.reid.name/blog/behold-jensens-inequality.html">blog post</a> by Mark Reid, a simple argument based on epigraphs leads to the inequality for discrete measures supported on \(x_1,\dots,x_n\), with non-negative weights \(\lambda_1, \dots,\lambda_n\) that sum to one, with an illustration below for \(n=4\): any convex combination of points \((x_i,f(x_i))\) has to be in the red convex polygon, which is above the function.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img loading="lazy" src="https://francisbach.com/wp-content/uploads/2023/03/jensen_multi-3-1024x474.png" alt="" class="wp-image-8889" width="542" height="250" srcset="https://francisbach.com/wp-content/uploads/2023/03/jensen_multi-3-1024x474.png 1024w, https://francisbach.com/wp-content/uploads/2023/03/jensen_multi-3-300x139.png 300w, https://francisbach.com/wp-content/uploads/2023/03/jensen_multi-3-768x355.png 768w, https://francisbach.com/wp-content/uploads/2023/03/jensen_multi-3-1536x711.png 1536w, https://francisbach.com/wp-content/uploads/2023/03/jensen_multi-3-850x393.png 850w, https://francisbach.com/wp-content/uploads/2023/03/jensen_multi-3.png 1549w" sizes="(max-width: 542px) 100vw, 542px" /></figure></div>


<h2>A bit of history</h2>



<p class="justify-text">The result is typically attributed to the Danish mathematician <a href="https://fr.wikipedia.org/wiki/Johan_Jensen">Johan Jensen</a> [<a href="https://zenodo.org/record/2371297/files/article.pdf">1</a>, in French] who proved in 1906 the result for convex functions on the real line (in fact all continuous <a href="https://en.wikipedia.org/wiki/Convex_function">mid-point convex</a> functions), but <a href="https://en.wikipedia.org/wiki/Otto_H%C3%B6lder">Otto Hölder</a> had shown it earlier for twice differentiable functions [<a href="http://gdz.sub.uni-goettingen.de/dms/resolveppn/?PPN=GDZPPN00252421X">2</a>, in German]. It turns out this was known thirty years earlier for uniform measures on finite sets, as shown by Jules Grolous [<a href="https://books.google.fr/books?id=z_BFnsBAx18C&amp;hl=fr&amp;pg=PA401#v=onepage&amp;q&amp;f=true">3</a>], a relatively unknown former student from Ecole Polytechnique. See also [<a href="https://www.jstor.org/stable/pdf/43667702.pdf?refreqid=excelsior%3A29d60497a1ddcba74004c27f25c39cd1&amp;ab_segments=&amp;origin=&amp;initiator=">4</a>] for more details on the history of Jensen&#8217;s inequality.</p>



<h2>Classical applications</h2>



<p class="justify-text">Jensen&#8217;s inequality can be used to derive many other classical inequalities, typically applied to the exponential, logarithm or powers.</p>



<p class="justify-text"><strong>Arithmetic, harmonic, and geometric means.</strong> For \(X\) with positive real values, we have: $$ \mathbb{E}[X]\geqslant \exp \Big( \mathbb{E}\big[ \log(X)\big]\Big)  \ \mbox{ and } \  \mathbb{E}[X]  \geqslant \frac{1}{\mathbb{E}\big[\frac{1}{X}\big]},$$ which corresponds for empirical measures to classical <a href="https://en.wikipedia.org/wiki/HM-GM-AM-QM_inequalities">inequalities between means</a>.</p>



<p class="justify-text"><strong>Young&#8217;s inequality.</strong> For \(p,q&gt;1\) such that \(\frac{1}{p}+\frac{1}{q}=1\), and two non-negative real numbers \(x,y\), we get by Jensen&#8217;s inequality, $$ \log\big(\frac{1}{p} x^p + \frac{1}{q} y^q \big) \geqslant \frac{1}{p} \log(x^p) + \frac{1}{q} \log(y^q) = \log(xy),$$ leading to <a href="https://en.wikipedia.org/wiki/Young%27s_inequality_for_products">Young&#8217;s inequality</a> \(\displaystyle xy \leqslant \frac{1}{p} x^p + \frac{1}{q} y^q.\)</p>



<p class="justify-text"><strong>Hölder&#8217;s inequality.</strong> For any positive \(x_1,\dots,x_n,y_1,\dots,y_n\), we can write $$\sum_{i=1}^n x_i y_i = \sum_{j=1}^n y_j^q \cdot \sum_{i=1}^n x_i y_i^{1-q} \frac{y_i^q}{\sum_{j=1}^n y_j^q} \leqslant \sum_{j=1}^n y_j^q \cdot \Big( \sum_{i=1}^n (x_i y_i^{1-q})^p \frac{y_i}{\sum_{j=1}^n y_j^q} \Big)^{1/p},$$ leading to <a href="https://en.wikipedia.org/wiki/H%C3%B6lder%27s_inequality">Hölder&#8217;s inequality</a> (with the same relationship between \(p\) and \(q\) as above): $$\sum_{i=1}^n x_i y_i \leqslant \Big( \sum_{j=1}^n y_j^q \Big)^{1/q} \Big( \sum_{j=1}^n x_j^p \Big)^{1/p}.$$ This includes also <a href="https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality">Cauchy-Schwarz inequality</a> if \(p=q=2\), and also multiple versions of the &#8220;<a href="https://francisbach.com/the-%ce%b7-trick-or-the-effectiveness-of-reweighted-least-squares/">eta-trick</a>&#8220;.</p>



<h2>Majorization-minimization</h2>



<p class="justify-text">Within data science, Jensen&#8217;s inequality is often used to derive auxiliary functions used in <a href="https://en.wikipedia.org/wiki/MM_algorithm">majorization-minimization</a> algorithms, with two classical examples below.</p>



<p class="justify-text"><strong>Non-negative matrix factorization (NMF).</strong> Given a non-negative matrix \(V \in \mathbb{R}_+^{n \times d}\), the goal of NMF is to decompose it as \(V = WH\) with \(W \in \mathbb{R}_+^{n \times m}\) and \(H \in \mathbb{R}_+^{m \times d}\). This has many applications, in particular in source separation [<a href="https://papers.nips.cc/paper/2000/file/f9d1152547c0bde01830b7e8bd60024c-Paper.pdf">5</a>, <a href="http://perso.ens-lyon.fr/patrice.abry/ENSEIGNEMENTS/14M2SCExam/Bertin.pdf">6</a>].</p>



<p class="justify-text"> A classical cost function which is used to estimate \(W\) and \(H\) is the Kullback-Leibler divergence [<a href="https://papers.nips.cc/paper/2000/file/f9d1152547c0bde01830b7e8bd60024c-Paper.pdf">5</a>] $$ D(V \| WH) = \sum_{i=1}^n \sum_{j=1}^d \Big\{ V_{ij} \log \frac{ V_{ij} }{ ( WH)_{ij} }\  &#8211; V_{ij} + (WH)_{ij} \Big\}.$$ To minimize the cost function above with respect to \(H\) only, the problematic term is \(\log  ( WH)_{ij} = \log \big( \sum_{k=1}^m W_{ik} H_{kj} \big)\), which is a &#8220;log of a sum&#8221;. To turn it into a &#8220;sum of logs&#8221;, we use Jensen&#8217;s inequality for the logarithm, by introducing a probability vector \(q^{ij} \in \mathbb{R}_+^m\) (with non-negative values that sum to one), and lower-bounding $$ \log  ( WH)_{ij} = \log \Big( \sum_{k=1}^m q^{ij}_k \frac{W_{ik} H_{kj} }{q^{ij}_k} \Big) \geqslant \sum_{k=1}^n q^{ij}_{k} \log \frac{W_{ik} H_{kj}}{q^{ij}_k}.$$ For a fixed \(H\), the bound is tight for \(\displaystyle q^{ij}_k = \frac{W_{ik} H_{kj}}{(WH)_{ij}},\) and given all \(q\)&#8217;s, we can minimize with respect to \(H_{ki}\) in closed form to get the update $$H_{kj} \leftarrow H_{kj}    \frac{\sum_{i=1}^n \! V_{ij} W_{ik}  \, /\,  (WH)_{ij} }{\sum_{i&#8217;=1}^n \! W_{i&#8217;k}}.$$ Because we had a tight upper bound at the current \(H\) (before the update), this is a descent algorithm. We can derive a similar update for \(W\). As shown in [<a href="https://papers.nips.cc/paper/2000/file/f9d1152547c0bde01830b7e8bd60024c-Paper.pdf">5</a>], this is a simple parameter-free descent algorithm that converges to a stationary point, often referred to as a multiplicative update algorithm. See a convergence analysis in [<a href="https://perso.telecom-paristech.fr/rbadeau/assets/ieee-tnn-10.pdf">7</a>] and alternatives based on relative smoothness [<a href="https://publications.ut-capitole.fr/id/eprint/25852/1/25852.pdf">8</a>] or on primal-dual formulations [<a href="https://arxiv.org/pdf/1608.01264">9</a>, <a href="https://hal.science/hal-01079229/document">10</a>].</p>



<p class="justify-text"><strong>Expectation-maximization (EM).</strong> The exact same technique of introducing a probability vector within the log and using Jensen&#8217;s inequality is at the core of <a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">EM for latent variable models</a> and <a href="https://en.wikipedia.org/wiki/Evidence_lower_bound">variational inference</a> (in fact NMF is simply a particular instance for a Poisson likelihood), which are two good topics for future posts (see <a href="https://lips.cs.princeton.edu/the-elbo-without-jensen-or-kl/">here</a> for a simple derivation of the &#8220;<a href="https://en.wikipedia.org/wiki/Evidence_lower_bound">evidence lower bound</a>&#8220;).</p>



<h2>Information theory</h2>



<p class="justify-text">Within <a href="https://en.wikipedia.org/wiki/Information_theory">information theory</a>, the concavity of the logarithm and the use of Jensen&#8217;s inequality play a major role in most classical results, e.g., positivity of the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback-Leilbler divergence</a> or <a href="https://en.wikipedia.org/wiki/Data_processing_inequality">data processing inequality</a>. This also extends to all <a href="https://en.wikipedia.org/wiki/F-divergence">f-divergences</a>.</p>



<h2>Operator convexity</h2>



<p class="justify-text">When considering convexity with respect to a generalized inequaility (such as based on the Löwner order), we can extend many of the classical formulas above (relationship between means, Young&#8217;s and Hölder&#8217;s inequality) to matrices. See <a href="https://francisbach.com/matrix-monotony-and-convexity/">earlier post</a> for an introduction. For a certain set of functions (such as the square or the negative logarithm) \(f: \mathbb{R} \to \mathbb{R}\), then for a random symmetric matrix \(X\), we have (for the <a href="https://en.wikipedia.org/wiki/Loewner_order">Löwner order</a>): $$ f\big( \mathbb{E}[X] \big) \preccurlyeq  \mathbb{E} \big[ f(X) \big].$$ An intriguing extension is the operator version of Jensen&#8217;s inequality [<a href="https://arxiv.org/pdf/math/0204049">10</a>], for potentially dependent random variables \((X,Y)\), where \(X\) is symmetric, and the sizes of \(X\) and \(Y\) are compatible: $$ f \Big( \mathbb{E} \big[ Y^\top X Y \big] \Big) \preccurlyeq \mathbb{E} \big[ Y^\top f(X) Y \big]  \ \mbox{ as soon as } \ \mathbb{E}[  Y^\top Y ] = I.$$</p>



<h2>Exact expression of the remainder</h2>



<p class="justify-text">There is a large literature on extensions, refinements on Jensen&#8217;s inequality. I have a cute one of my own, which has probably been derived before. For twice differentiable functions \(f\), we can use <a href="https://en.wikipedia.org/wiki/Taylor%27s_theorem">Taylor formula with integral remainder</a> on the segment between \(X\) and \(\mathbb{E}[X]\), leading to, with \(g(t) =  f\big( t X + (1-t) \mathbb{E}[X]\big)\), $$g(1) = g(0) + g'(0) + \int_0^1 \! g^{\prime \prime}(t)(1-t)dt.$$ Taking expectations, this leads to $$\mathbb{E} \big[f(X)\big] &#8211; f\big( \mathbb{E}[X]\big) = \mathbb{E} \bigg[ \int_0^1 \! ( X &#8211; \mathbb{E}[X])^\top f^{\prime\prime}\big( t X + (1-t) \mathbb{E}[X]\big) ( X &#8211; \mathbb{E}[X]) (1-t) dt \bigg].$$ From this expression, we recover traditional refinements or reversing of the order if \(f^{\prime\prime}\) has bounded eigenvalues. This can for example be used also for characterizing the equality cases in non-strictly convex situations [<a href="https://arxiv.org/pdf/2202.08545.pdf">11</a>, page 31].</p>



<h2>References</h2>



<p class="justify-text">[1] <a href="https://en.wikipedia.org/wiki/Johan_Jensen_(mathematician)"></a>Johan L. Jensen.&nbsp;<a href="https://zenodo.org/record/2371297/files/article.pdf">Sur les fonctions convexes et les inégalités entre les valeurs moyennes.</a>&nbsp;<em>Acta Mathematica</em>,&nbsp;30(1): 175–193, 1906.<br><span style="font-size: revert; color: initial; font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen-Sans, Ubuntu, Cantarell, &quot;Helvetica Neue&quot;, sans-serif;">[2] Otto Hölder, </span><a style="font-size: revert; font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen-Sans, Ubuntu, Cantarell, &quot;Helvetica Neue&quot;, sans-serif;" href="http://gdz.sub.uni-goettingen.de/dms/resolveppn/?PPN=GDZPPN00252421X">Ueber einen Mittelwerthssatz</a><span style="font-size: revert; color: initial; font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen-Sans, Ubuntu, Cantarell, &quot;Helvetica Neue&quot;, sans-serif;">.&nbsp;</span>Nachrichten von der Königl. Gesellschaft der Wissenschaften und der Georg-Augusts-Universität zu&nbsp;Göttingen<span style="font-size: revert; color: initial; font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen-Sans, Ubuntu, Cantarell, &quot;Helvetica Neue&quot;, sans-serif;">, (1):38-47</span>, 1889.<br><span style="font-size: revert; color: initial; font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen-Sans, Ubuntu, Cantarell, &quot;Helvetica Neue&quot;, sans-serif;">[3] Jules Grolous. </span><a style="font-size: revert; font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen-Sans, Ubuntu, Cantarell, &quot;Helvetica Neue&quot;, sans-serif;" href="https://books.google.fr/books?id=z_BFnsBAx18C&amp;hl=fr&amp;pg=PA401#v=onepage&amp;q&amp;f=true">Un théorème sur les fonctions</a><em style="font-size: revert; color: initial; font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen-Sans, Ubuntu, Cantarell, &quot;Helvetica Neue&quot;, sans-serif;">. L’Institut, Journal Universel des Sciences et des Sociétés Savantes en France et à l’Etranger</em><span style="font-size: revert; color: initial; font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen-Sans, Ubuntu, Cantarell, &quot;Helvetica Neue&quot;, sans-serif;">, 3(153):401, 1875.</span><br>[4] D. S. Mitrinović and P. M. Vasić. <a href="https://www.jstor.org/stable/pdf/43667702.pdf?refreqid=excelsior%3A29d60497a1ddcba74004c27f25c39cd1&amp;ab_segments=&amp;origin=&amp;initiator=">The centroid method in inequalities</a>.&nbsp;<em>Publikacije Elektrotehničkog fakulteta. Serija Matematika i fizika</em>&nbsp;498/541:3-16, 1975.<br>[5] Daniel D. Lee and H. Sebastian Seung. <a href="https://papers.nips.cc/paper/2000/file/f9d1152547c0bde01830b7e8bd60024c-Paper.pdf">Algorithms for non-negative matrix factorization</a>.&nbsp;<em>Advances in Neural Information Processing Systems</em>, 13, 2000.<br>[6] Cédric Févotte, Nancy Bertin, and Jean-Louis Durrieu. <a href="http://perso.ens-lyon.fr/patrice.abry/ENSEIGNEMENTS/14M2SCExam/Bertin.pdf">Nonnegative matrix factorization with the Itakura-Saito divergence: With application to music analysis</a>.&nbsp;<em>Neural computation</em>&nbsp;21(3):793-830, 2009.<br>[6] Roland Badeau, Nancy Bertin, and Emmanuel Vincent. <a href="https://perso.telecom-paristech.fr/rbadeau/assets/ieee-tnn-10.pdf">Stability analysis of multiplicative update algorithms and application to nonnegative matrix factorization</a>.&nbsp;<em>IEEE Transactions on Neural Networks</em>,&nbsp;21(12):1869-1881, 2010.<br>[7] Heinz H. Bauschke, Jérôme Bolte, and Marc Teboulle. <a href="https://publications.ut-capitole.fr/id/eprint/25852/1/25852.pdf">A descent lemma beyond Lipschitz gradient continuity: first-order methods revisited and applications</a>. <em>Mathematics of Operations Research</em>&nbsp;42(2):330-348, 2017.<br>[8] Niao He, Zaid Harchaoui, Yichen Wang, and Le Song. <a href="https://arxiv.org/pdf/1608.01264">Fast and simple optimization for Poisson likelihood models</a>.&nbsp;Technical report,<em> arXiv:1608.01264</em>, 2016.<br>[9] Felipe Yanez and Francis Bach. <a href="https://hal.science/hal-01079229/document">Primal-dual algorithms for non-negative matrix factorization with the Kullback-Leibler divergence</a>.&nbsp;<em>International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2017.<br>[10] Frank Hansen, Gert K. Pedersen. <a href="https://arxiv.org/pdf/math/0204049">Jensen&#8217;s Operator Inequality</a>. Technical report,<em> arXiv:0204049</em>, 2002.<br>[11] Francis Bach. <a href="https://arxiv.org/pdf/2202.08545.pdf">Information theory with kernel methods</a>. <em>IEEE Transactions in Information Theor</em>y, 69(2):752-775, 2022.<br></p>



<p><a href=""></a></p>
<p class="authors">By Francis Bach</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T13:47:14Z">Monday, March 13 2023, 13:47</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/03/13/phd-and-postdoc-at-algorithms-group-in-bar-ilan-university-israel-apply-by-june-1-2023/'>PhD and Postdoc at Algorithms group in Bar-Ilan University  (Israel) (apply by June 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I am (Arnold Filtser) looking for both PhD and Postdoc applicants in the broad area of algorithms. We have a strong and thriving algorithms group here in BIU, and you will have many further options for collaboration. My research interest include (but not limited to): Metric Spaces, Low-Distortion Embeddings, Randomized Algorithms, approximation, and streaming algorithms. [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I am (Arnold Filtser) looking for both PhD and Postdoc applicants in the broad area of algorithms. We have a strong and thriving algorithms group here in BIU, and you will have many further options for collaboration. My research interest include (but not limited to): Metric Spaces, Low-Distortion Embeddings, Randomized Algorithms, approximation, and streaming algorithms.</p>
<p>Website: <a href="https://arnold.filtser.com/">https://arnold.filtser.com/</a><br />
Email: filtsea@cs.biu.ac.il</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T10:00:02Z">Monday, March 13 2023, 10:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05614'>On the Existence of Anomalies, The Reals Case</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samuel Epstein</p><p>The Independence Postulate (IP) is a finitary Church-Turing Thesis, saying
mathematical sequences are independent from physical ones. Modelling
observations as infinite sequences of real numbers, IP implies the existence of
anomalies.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1">Samuel Epstein</a></p><p>The Independence Postulate (IP) is a finitary Church-Turing Thesis, saying
mathematical sequences are independent from physical ones. Modelling
observations as infinite sequences of real numbers, IP implies the existence of
anomalies.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05616'>How to Compress the Solution</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samuel Epstein</p><p>Using derandomization, we provide an upper bound on the compression size of
solutions to the graph coloring problem. In general, if solutions to a
combinatorial problem exist with high probability and the probability is
simple, then there exists a simple solution to the problem. Otherwise the
problem instance has high mutual information with the halting problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1">Samuel Epstein</a></p><p>Using derandomization, we provide an upper bound on the compression size of
solutions to the graph coloring problem. In general, if solutions to a
combinatorial problem exist with high probability and the probability is
simple, then there exists a simple solution to the problem. Otherwise the
problem instance has high mutual information with the halting problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05619'>Uniform Tests and Algorithmic Thermodynamic Entropy</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samuel Epstein</p><p>We prove that given a computable metric space and two computable measures,
the set of points that have high universal uniform test scores with respect to
the first measure will have a lower bound with respect to the second measure.
This result is transferred to thermodynamics, showing that algorithmic
thermodynamic entropy must oscillate in the presence of dynamics. Another
application is that outliers will become emergent in computable dynamics of
computable metric spaces.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1">Samuel Epstein</a></p><p>We prove that given a computable metric space and two computable measures,
the set of points that have high universal uniform test scores with respect to
the first measure will have a lower bound with respect to the second measure.
This result is transferred to thermodynamics, showing that algorithmic
thermodynamic entropy must oscillate in the presence of dynamics. Another
application is that outliers will become emergent in computable dynamics of
computable metric spaces.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05989'>DAG Scheduling in the BSP Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: P&#xe1;l Andr&#xe1;s Papp, Georg Anegg, A. N. Yzelman</p><p>We study the problem of scheduling an arbitrary computational DAG on a fixed
number of processors while minimizing the makespan. While previous works have
mostly studied this problem in relatively restricted models, we define and
analyze DAG scheduling in the Bulk Synchronous Parallel (BSP) model, which is a
well-established parallel computing model that captures the communication cost
between processors much more accurately. We provide a detailed taxonomy of
simpler scheduling models that can be understood as variants or special cases
of BSP, and discuss the properties of the problem and the optimum cost in these
models, and how they differ from BSP. This essentially allows us to dissect the
different building blocks of the BSP model, and gain insight into how each of
these influences the scheduling problem.
</p>
<p>We then analyze the hardness of DAG scheduling in BSP in detail. We show that
the problem is solvable in polynomial time for some very simple classes of
DAGs, but it is already NP-hard for in-trees or DAGs of height 2. We also
separately study the subproblem of scheduling communication steps, and we show
that the NP-hardness of this problem can depend on the problem parameters and
the communication rules within the BSP model. Finally, we present and analyze a
natural formulation of our scheduling task as an Integer Linear Program.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Papp_P/0/1/0/all/0/1">P&#xe1;l Andr&#xe1;s Papp</a>, <a href="http://arxiv.org/find/cs/1/au:+Anegg_G/0/1/0/all/0/1">Georg Anegg</a>, <a href="http://arxiv.org/find/cs/1/au:+Yzelman_A/0/1/0/all/0/1">A. N. Yzelman</a></p><p>We study the problem of scheduling an arbitrary computational DAG on a fixed
number of processors while minimizing the makespan. While previous works have
mostly studied this problem in relatively restricted models, we define and
analyze DAG scheduling in the Bulk Synchronous Parallel (BSP) model, which is a
well-established parallel computing model that captures the communication cost
between processors much more accurately. We provide a detailed taxonomy of
simpler scheduling models that can be understood as variants or special cases
of BSP, and discuss the properties of the problem and the optimum cost in these
models, and how they differ from BSP. This essentially allows us to dissect the
different building blocks of the BSP model, and gain insight into how each of
these influences the scheduling problem.
</p>
<p>We then analyze the hardness of DAG scheduling in BSP in detail. We show that
the problem is solvable in polynomial time for some very simple classes of
DAGs, but it is already NP-hard for in-trees or DAGs of height 2. We also
separately study the subproblem of scheduling communication steps, and we show
that the NP-hardness of this problem can depend on the problem parameters and
the communication rules within the BSP model. Finally, we present and analyze a
natural formulation of our scheduling task as an Integer Linear Program.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06001'>Multivariate to Bivariate Reduction for Noncommutative Polynomial Factorization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: V. Arvind, Pushkar S. Joglekar</p><p>Based on a theorem of Bergman we show that multivariate noncommutative
polynomial factorization is deterministic polynomial-time reducible to the
factorization of bivariate noncommutative polynomials. More precisely, we show
the following:
</p>
<p>(1) In the white-box setting, given an n-variate noncommutative polynomial f
in F&lt;X&gt; over a field F (either a finite field or the rationals) as an
arithmetic circuit (or algebraic branching program), computing a complete
factorization of f is deterministic polynomial-time reducible to white-box
factorization of a noncommutative bivariate polynomial g in F&lt;x,y&gt;; the
reduction transforms f into a circuit for g (resp. ABP for g), and given a
complete factorization of g the reduction recovers a complete factorization of
f in polynomial time. We also obtain a similar deterministic polynomial-time
reduction in the black-box setting.
</p>
<p>(2) Additionally, we show over the field of rationals that bivariate linear
matrix factorization of 4 x 4 matrices is at least as hard as factoring
square-free integers. This indicates that reducing noncommutative polynomial
factorization to linear matrix factorization (as done in our recent work
[AJ22]) is unlikely to succeed over the field of rationals even in the
bivariate case.
</p>
<p>In contrast, multivariate linear matrix factorization for 3 x 3 matrices over
rationals is in polynomial time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Arvind_V/0/1/0/all/0/1">V. Arvind</a>, <a href="http://arxiv.org/find/cs/1/au:+Joglekar_P/0/1/0/all/0/1">Pushkar S. Joglekar</a></p><p>Based on a theorem of Bergman we show that multivariate noncommutative
polynomial factorization is deterministic polynomial-time reducible to the
factorization of bivariate noncommutative polynomials. More precisely, we show
the following:
</p>
<p>(1) In the white-box setting, given an n-variate noncommutative polynomial f
in F&lt;X&gt; over a field F (either a finite field or the rationals) as an
arithmetic circuit (or algebraic branching program), computing a complete
factorization of f is deterministic polynomial-time reducible to white-box
factorization of a noncommutative bivariate polynomial g in F&lt;x,y&gt;; the
reduction transforms f into a circuit for g (resp. ABP for g), and given a
complete factorization of g the reduction recovers a complete factorization of
f in polynomial time. We also obtain a similar deterministic polynomial-time
reduction in the black-box setting.
</p>
<p>(2) Additionally, we show over the field of rationals that bivariate linear
matrix factorization of 4 x 4 matrices is at least as hard as factoring
square-free integers. This indicates that reducing noncommutative polynomial
factorization to linear matrix factorization (as done in our recent work
[AJ22]) is unlikely to succeed over the field of rationals even in the
bivariate case.
</p>
<p>In contrast, multivariate linear matrix factorization for 3 x 3 matrices over
rationals is in polynomial time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05965'>Scalable and Efficient Functional Map Computations on Dense Meshes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Robin Magnet, Maks Ovsjanikov</p><p>Spectral geometric methods have brought revolutionary changes to the field of
geometry processing. Of particular interest is the study of the Laplacian
spectrum as a compact, isometry and permutation-invariant representation of a
shape. Some recent works show how the intrinsic geometry of a full shape can be
recovered from its spectrum, but there are approaches that consider the more
challenging problem of recovering the geometry from the spectral information of
partial shapes. In this paper, we propose a possible way to fill this gap. We
introduce a learning-based method to estimate the Laplacian spectrum of the
union of partial non-rigid 3D shapes, without actually computing the 3D
geometry of the union or any correspondence between those partial shapes. We do
so by operating purely in the spectral domain and by defining the union
operation between short sequences of eigenvalues. We show that the approximated
union spectrum can be used as-is to reconstruct the complete geometry [MRC*19],
perform region localization on a template [RTO*19] and retrieve shapes from a
database, generalizing ShapeDNA [RWP06] to work with partialities. Working with
eigenvalues allows us to deal with unknown correspondence, different sampling,
and different discretizations (point clouds and meshes alike), making this
operation especially robust and general. Our approach is data-driven and can
generalize to isometric and non-isometric deformations of the surface, as long
as these stay within the same semantic class (e.g., human bodies or horses), as
well as to partiality artifacts not seen at training time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Magnet_R/0/1/0/all/0/1">Robin Magnet</a>, <a href="http://arxiv.org/find/cs/1/au:+Ovsjanikov_M/0/1/0/all/0/1">Maks Ovsjanikov</a></p><p>Spectral geometric methods have brought revolutionary changes to the field of
geometry processing. Of particular interest is the study of the Laplacian
spectrum as a compact, isometry and permutation-invariant representation of a
shape. Some recent works show how the intrinsic geometry of a full shape can be
recovered from its spectrum, but there are approaches that consider the more
challenging problem of recovering the geometry from the spectral information of
partial shapes. In this paper, we propose a possible way to fill this gap. We
introduce a learning-based method to estimate the Laplacian spectrum of the
union of partial non-rigid 3D shapes, without actually computing the 3D
geometry of the union or any correspondence between those partial shapes. We do
so by operating purely in the spectral domain and by defining the union
operation between short sequences of eigenvalues. We show that the approximated
union spectrum can be used as-is to reconstruct the complete geometry [MRC*19],
perform region localization on a template [RTO*19] and retrieve shapes from a
database, generalizing ShapeDNA [RWP06] to work with partialities. Working with
eigenvalues allows us to deal with unknown correspondence, different sampling,
and different discretizations (point clouds and meshes alike), making this
operation especially robust and general. Our approach is data-driven and can
generalize to isometric and non-isometric deformations of the surface, as long
as these stay within the same semantic class (e.g., human bodies or horses), as
well as to partiality artifacts not seen at training time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06118'>Decomposition of zero-dimensional persistence modules via rooted subsets</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: &#xc1;ngel Javier Alonso, Michael Kerber</p><p>We study the decomposition of zero-dimensional persistence modules, viewed as
functors valued in the category of vector spaces factorizing through sets.
Instead of working directly at the level of vector spaces, we take a step back
and first study the decomposition problem at the level of sets.
</p>
<p>This approach allows us to define the combinatorial notion of rooted subsets.
In the case of a filtered metric space $M$, rooted subsets relate the
clustering behavior of the points of $M$ with the decomposition of the
associated persistence module. In particular, we can identify intervals in such
a decomposition quickly. In addition, rooted subsets can be understood as a
generalization of the elder rule, and are also related to the notion of
constant conqueror of Cai, Kim, M\'emoli and Wang. As an application, we give a
lower bound on the number of intervals that we can expect in the decomposition
of zero-dimensional persistence modules of a density-Rips filtration in
Euclidean space: in the limit, and under very general circumstances, we can
expect that at least 25% of the indecomposable summands are interval modules.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Alonso_A/0/1/0/all/0/1">&#xc1;ngel Javier Alonso</a>, <a href="http://arxiv.org/find/math/1/au:+Kerber_M/0/1/0/all/0/1">Michael Kerber</a></p><p>We study the decomposition of zero-dimensional persistence modules, viewed as
functors valued in the category of vector spaces factorizing through sets.
Instead of working directly at the level of vector spaces, we take a step back
and first study the decomposition problem at the level of sets.
</p>
<p>This approach allows us to define the combinatorial notion of rooted subsets.
In the case of a filtered metric space $M$, rooted subsets relate the
clustering behavior of the points of $M$ with the decomposition of the
associated persistence module. In particular, we can identify intervals in such
a decomposition quickly. In addition, rooted subsets can be understood as a
generalization of the elder rule, and are also related to the notion of
constant conqueror of Cai, Kim, M\'emoli and Wang. As an application, we give a
lower bound on the number of intervals that we can expect in the decomposition
of zero-dimensional persistence modules of a density-Rips filtration in
Euclidean space: in the limit, and under very general circumstances, we can
expect that at least 25% of the indecomposable summands are interval modules.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05799'>Optimal-Hash Exact String Matching Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Thierry Lecroq</p><p>String matching is the problem of finding all the occurrences of a pattern in
a text. We propose improved versions of the fast family of string matching
algorithms based on hashing $q$-grams. The improvement consists of considering
minimal values $q$ such that each $q$-grams of the pattern has a unique hash
value. The new algorithms are fastest than algorithm of the HASH family for
short patterns on large size alphabets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lecroq_T/0/1/0/all/0/1">Thierry Lecroq</a></p><p>String matching is the problem of finding all the occurrences of a pattern in
a text. We propose improved versions of the fast family of string matching
algorithms based on hashing $q$-grams. The improvement consists of considering
minimal values $q$ such that each $q$-grams of the pattern has a unique hash
value. The new algorithms are fastest than algorithm of the HASH family for
short patterns on large size alphabets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05920'>Faster Matroid Partition Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tatsuya Terao</p><p>In the matroid partitioning problem, we are given $k$ matroids $\mathcal{M}_1
= (V, \mathcal{I}_1), \dots , \mathcal{M}_k = (V, \mathcal{I}_k)$ defined over
a common ground set $V$ of $n$ elements, and we need to find a partitionable
set $S \subseteq V$ of largest possible cardinality, denoted by $p$. Here, a
set $S \subseteq V$ is called partitionable if there exists a partition $(S_1,
\dots , S_k)$ of $S$ with $S_i \in \mathcal{I}_i$ for $i = 1, \ldots, k$. In
1986, Cunningham presented a matroid partition algorithm that uses $O(n p^{3/2}
+ k n)$ independence oracle queries, which was the previously known best
algorithm. This query complexity is $O(n^{5/2})$ when $k \leq n$.
</p>
<p>Our main result is to present a matroid partition algorithm that uses
$\tilde{O}(k^{1/3} n p + k n)$ independence oracle queries, which is
$\tilde{O}(n^{7/3})$ when $k \leq n$. This improves upon previous Cunningham's
algorithm. To obtain this, we present a new approach \emph{edge recycling
augmentation}, which can be attained through new ideas: an efficient
utilization of the binary search technique by Nguyen and
Chakrabarty-Lee-Sidford-Singla-Wong and a careful analysis of the number of
independence oracle queries. Our analysis differs significantly from the one
for matroid intersection algorithms, because of the parameter $k$. We also
present a matroid partition algorithm that uses $\tilde{O}((n + k) \sqrt{p})$
rank oracle queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Terao_T/0/1/0/all/0/1">Tatsuya Terao</a></p><p>In the matroid partitioning problem, we are given $k$ matroids $\mathcal{M}_1
= (V, \mathcal{I}_1), \dots , \mathcal{M}_k = (V, \mathcal{I}_k)$ defined over
a common ground set $V$ of $n$ elements, and we need to find a partitionable
set $S \subseteq V$ of largest possible cardinality, denoted by $p$. Here, a
set $S \subseteq V$ is called partitionable if there exists a partition $(S_1,
\dots , S_k)$ of $S$ with $S_i \in \mathcal{I}_i$ for $i = 1, \ldots, k$. In
1986, Cunningham presented a matroid partition algorithm that uses $O(n p^{3/2}
+ k n)$ independence oracle queries, which was the previously known best
algorithm. This query complexity is $O(n^{5/2})$ when $k \leq n$.
</p>
<p>Our main result is to present a matroid partition algorithm that uses
$\tilde{O}(k^{1/3} n p + k n)$ independence oracle queries, which is
$\tilde{O}(n^{7/3})$ when $k \leq n$. This improves upon previous Cunningham's
algorithm. To obtain this, we present a new approach \emph{edge recycling
augmentation}, which can be attained through new ideas: an efficient
utilization of the binary search technique by Nguyen and
Chakrabarty-Lee-Sidford-Singla-Wong and a careful analysis of the number of
independence oracle queries. Our analysis differs significantly from the one
for matroid intersection algorithms, because of the parameter $k$. We also
present a matroid partition algorithm that uses $\tilde{O}((n + k) \sqrt{p})$
rank oracle queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06090'>Simple and efficient four-cycle counting on sparse graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Paul Burkhardt, David G. Harris</p><p>We consider the problem of counting 4-cycles ($C_4$) in a general undirected
graph $G$ of $n$ vertices and $m$ edges (in bipartite graphs, 4-cycles are also
often referred to as $\textit{butterflies}$). There have been a number of
previous algorithms for this problem; some of these are based on fast matrix
multiplication, which is attractive theoretically but not practical, and some
of these are based on randomized hash tables.
</p>
<p>We develop a new simpler algorithm for counting $C_4$, which has several
practical improvements over previous algorithms; for example, it is fully
deterministic and avoids any expensive arithmetic in its inner loops. The
algorithm can also be adapted to count 4-cycles incident to each vertex and
edge. Our algorithm runs in $O(m\bar\delta(G))$ time and $O(n)$ space, where
$\bar \delta(G) \leq O(\sqrt{m})$ is the $\textit{average degeneracy}$
parameter introduced by Burkhardt, Faber &amp; Harris (2020).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Burkhardt_P/0/1/0/all/0/1">Paul Burkhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Harris_D/0/1/0/all/0/1">David G. Harris</a></p><p>We consider the problem of counting 4-cycles ($C_4$) in a general undirected
graph $G$ of $n$ vertices and $m$ edges (in bipartite graphs, 4-cycles are also
often referred to as $\textit{butterflies}$). There have been a number of
previous algorithms for this problem; some of these are based on fast matrix
multiplication, which is attractive theoretically but not practical, and some
of these are based on randomized hash tables.
</p>
<p>We develop a new simpler algorithm for counting $C_4$, which has several
practical improvements over previous algorithms; for example, it is fully
deterministic and avoids any expensive arithmetic in its inner loops. The
algorithm can also be adapted to count 4-cycles incident to each vertex and
edge. Our algorithm runs in $O(m\bar\delta(G))$ time and $O(n)$ space, where
$\bar \delta(G) \leq O(\sqrt{m})$ is the $\textit{average degeneracy}$
parameter introduced by Burkhardt, Faber &amp; Harris (2020).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06102'>Bootstrapping Dynamic Distance Oracles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sebastian Forster, Gramoz Goranci, Yasamin Nazari, Antonis Skarlatos</p><p>Designing approximate all-pairs distance oracles in the fully dynamic setting
is one of the central problems in dynamic graph algorithms. Despite extensive
research on this topic, the first result breaking the $O(\sqrt{n})$ barrier on
the update time for any non-trivial approximation was introduced only recently
by Forster, Goranci and Henzinger [SODA'21] who achieved $m^{1/\rho+o(1)}$
amortized update time with a $O(\log n)^{3\rho-2}$ factor in the approximation
ratio, for any parameter $\rho \geq 1$.
</p>
<p>In this paper, we give the first constant-stretch fully dynamic distance
oracle with a small polynomial update and query time. Prior work required
either at least a poly-logarithmic approximation or much larger update time.
Our result gives a more fine-grained trade-off between stretch and update time,
for instance we can achieve constant stretch of $O(\frac{1}{\rho^2})^{4/\rho}$
in amortized update time $\tilde{O}(n^{\rho})$, and query time
$\tilde{O}(n^{\rho/8})$ for a constant parameter $\rho &lt;1$. Our algorithm is
randomized and assumes an oblivious adversary.
</p>
<p>A core technical idea underlying our construction is to design a black-box
reduction from decremental approximate hub-labeling schemes to fully dynamic
distance oracles, which may be of independent interest. We then apply this
reduction repeatedly to an existing decremental algorithm to bootstrap our
fully dynamic solution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Forster_S/0/1/0/all/0/1">Sebastian Forster</a>, <a href="http://arxiv.org/find/cs/1/au:+Goranci_G/0/1/0/all/0/1">Gramoz Goranci</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazari_Y/0/1/0/all/0/1">Yasamin Nazari</a>, <a href="http://arxiv.org/find/cs/1/au:+Skarlatos_A/0/1/0/all/0/1">Antonis Skarlatos</a></p><p>Designing approximate all-pairs distance oracles in the fully dynamic setting
is one of the central problems in dynamic graph algorithms. Despite extensive
research on this topic, the first result breaking the $O(\sqrt{n})$ barrier on
the update time for any non-trivial approximation was introduced only recently
by Forster, Goranci and Henzinger [SODA'21] who achieved $m^{1/\rho+o(1)}$
amortized update time with a $O(\log n)^{3\rho-2}$ factor in the approximation
ratio, for any parameter $\rho \geq 1$.
</p>
<p>In this paper, we give the first constant-stretch fully dynamic distance
oracle with a small polynomial update and query time. Prior work required
either at least a poly-logarithmic approximation or much larger update time.
Our result gives a more fine-grained trade-off between stretch and update time,
for instance we can achieve constant stretch of $O(\frac{1}{\rho^2})^{4/\rho}$
in amortized update time $\tilde{O}(n^{\rho})$, and query time
$\tilde{O}(n^{\rho/8})$ for a constant parameter $\rho &lt;1$. Our algorithm is
randomized and assumes an oblivious adversary.
</p>
<p>A core technical idea underlying our construction is to design a black-box
reduction from decremental approximate hub-labeling schemes to fully dynamic
distance oracles, which may be of independent interest. We then apply this
reduction repeatedly to an existing decremental algorithm to bootstrap our
fully dynamic solution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06127'>Any-Order Online Interval Selection</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Allan Borodin, Christodoulos Karavasilis</p><p>We consider the problem of online interval scheduling on a single machine,
where intervals arrive online in an order chosen by an adversary, and the
algorithm must output a set of non-conflicting intervals. Traditionally in
scheduling theory, it is assumed that intervals arrive in order of increasing
start times. We drop that assumption and allow for intervals to arrive in any
possible order. We call this variant any-order interval selection (AOIS). We
assume that some online acceptances can be revoked, but a feasible solution
must always be maintained. For unweighted intervals and deterministic
algorithms, this problem is unbounded. Under the assumption that there are at
most $k$ different interval lengths, we give a simple algorithm that achieves a
competitive ratio of $2k$ and show that it is optimal amongst deterministic
algorithms, and a restricted class of randomized algorithms we call memoryless,
contributing to an open question by Adler and Azar 2003; namely whether a
randomized algorithm without access to history can achieve a constant
competitive ratio. We connect our model to the problem of call control on the
line, and show how the algorithms of Garay et al. 1997 can be applied to our
setting, resulting in an optimal algorithm for the case of proportional
weights. We also consider the case of intervals arriving in a random order, and
show that for single-lengthed instances, a one-directional algorithm (i.e.
replacing intervals in one direction), is the only deterministic memoryless
algorithm that can possibly benefit from random arrivals. Finally, we briefly
discuss the case of intervals with arbitrary weights.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Borodin_A/0/1/0/all/0/1">Allan Borodin</a>, <a href="http://arxiv.org/find/cs/1/au:+Karavasilis_C/0/1/0/all/0/1">Christodoulos Karavasilis</a></p><p>We consider the problem of online interval scheduling on a single machine,
where intervals arrive online in an order chosen by an adversary, and the
algorithm must output a set of non-conflicting intervals. Traditionally in
scheduling theory, it is assumed that intervals arrive in order of increasing
start times. We drop that assumption and allow for intervals to arrive in any
possible order. We call this variant any-order interval selection (AOIS). We
assume that some online acceptances can be revoked, but a feasible solution
must always be maintained. For unweighted intervals and deterministic
algorithms, this problem is unbounded. Under the assumption that there are at
most $k$ different interval lengths, we give a simple algorithm that achieves a
competitive ratio of $2k$ and show that it is optimal amongst deterministic
algorithms, and a restricted class of randomized algorithms we call memoryless,
contributing to an open question by Adler and Azar 2003; namely whether a
randomized algorithm without access to history can achieve a constant
competitive ratio. We connect our model to the problem of call control on the
line, and show how the algorithms of Garay et al. 1997 can be applied to our
setting, resulting in an optimal algorithm for the case of proportional
weights. We also consider the case of intervals arriving in a random order, and
show that for single-lengthed instances, a one-directional algorithm (i.e.
replacing intervals in one direction), is the only deterministic memoryless
algorithm that can possibly benefit from random arrivals. Finally, we briefly
discuss the case of intervals with arbitrary weights.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, March 11
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/022'>TR23-022 |  Unprovability of strong complexity lower bounds in bounded arithmetic | 

	Jiatu Li, 

	Igor Carboni Oliveira</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          While there has been progress in establishing the unprovability of complexity statements in lower fragments of bounded arithmetic, understanding the limits of Jerabek&#39;s theory $\textbf{APC}_1$ (2007) and of higher levels of Buss&#39;s hierarchy $\textbf{S}^i_2$ (1986) has been a more elusive task. Even in the more restricted setting of Cook&#39;s theory $\textbf{PV}$ (1975), known results often rely on a less natural formalization that encodes a complexity statement using a collection of sentences instead of a single sentence. This is done to reduce the quantifier complexity of the resulting sentences so that standard witnessing results can be invoked. 

In this work, we establish unprovability results for stronger theories and for sentences of higher quantifier complexity. In particular, we unconditionally show that $\textbf{APC}_1$ cannot prove strong complexity lower bounds separating the third level of the polynomial hierarchy. In more detail, we consider non-uniform average-case separations, and establish that $\textbf{APC}_1$ cannot prove a sentence stating that
* $\forall n \geq n_0\;\exists\,f_n \in \Pi_3\text{-}\textbf{SIZE}[n^d]$ that is $(1/n)$-far from every $\Sigma_3\text{-}\textbf{SIZE}[2^{n^{\delta}}]$ circuit. 
This is a consequence of a much more general result showing that, for every $i \geq 1$, strong separations for $\Pi_{i}\text{-}\textbf{SIZE}[\textrm{poly}(n)]$ versus $\Sigma_{i}\text{-}\textbf{SIZE}[2^{n^{\Omega(1)}}]$ cannot be proved in the theory $\textbf{T}_\textbf{PV}^i$ consisting of all true $\forall \Sigma^b_{i-1}$-sentences in the language of Cook&#39;s theory $\textbf{PV}$. 

Our argument employs a convenient game-theoretic witnessing result that can be applied to sentences of arbitrary quantifier complexity. We combine it with extensions of a technique introduced by Krajicek (2011) that was recently employed by Pich and Santhanam (2021) to establish the unprovability of lower bounds in $\textbf{PV}$ (i.e., the case $i =1$ above, but under a weaker formalization) and in a fragment of $\textbf{APC}_1$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          While there has been progress in establishing the unprovability of complexity statements in lower fragments of bounded arithmetic, understanding the limits of Jerabek&#39;s theory $\textbf{APC}_1$ (2007) and of higher levels of Buss&#39;s hierarchy $\textbf{S}^i_2$ (1986) has been a more elusive task. Even in the more restricted setting of Cook&#39;s theory $\textbf{PV}$ (1975), known results often rely on a less natural formalization that encodes a complexity statement using a collection of sentences instead of a single sentence. This is done to reduce the quantifier complexity of the resulting sentences so that standard witnessing results can be invoked. 

In this work, we establish unprovability results for stronger theories and for sentences of higher quantifier complexity. In particular, we unconditionally show that $\textbf{APC}_1$ cannot prove strong complexity lower bounds separating the third level of the polynomial hierarchy. In more detail, we consider non-uniform average-case separations, and establish that $\textbf{APC}_1$ cannot prove a sentence stating that
* $\forall n \geq n_0\;\exists\,f_n \in \Pi_3\text{-}\textbf{SIZE}[n^d]$ that is $(1/n)$-far from every $\Sigma_3\text{-}\textbf{SIZE}[2^{n^{\delta}}]$ circuit. 
This is a consequence of a much more general result showing that, for every $i \geq 1$, strong separations for $\Pi_{i}\text{-}\textbf{SIZE}[\textrm{poly}(n)]$ versus $\Sigma_{i}\text{-}\textbf{SIZE}[2^{n^{\Omega(1)}}]$ cannot be proved in the theory $\textbf{T}_\textbf{PV}^i$ consisting of all true $\forall \Sigma^b_{i-1}$-sentences in the language of Cook&#39;s theory $\textbf{PV}$. 

Our argument employs a convenient game-theoretic witnessing result that can be applied to sentences of arbitrary quantifier complexity. We combine it with extensions of a technique introduced by Krajicek (2011) that was recently employed by Pich and Santhanam (2021) to establish the unprovability of lower bounds in $\textbf{PV}$ (i.e., the case $i =1$ above, but under a weaker formalization) and in a fragment of $\textbf{APC}_1$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-11T23:55:20Z">Saturday, March 11 2023, 23:55</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, March 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://dstheory.wordpress.com/2023/03/10/thursday-mar-16th-2023-vladimir-braverman-from-rice-university/'>Thursday, Mar 16th, 2023 — Vladimir Braverman from Rice University</a></h3>
        <p class='tr-article-feed'>from <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next Foundations of Data Science virtual talk series on recent advances in adversarially robust streaming will take place on Thursday, March 16th at 1:00 PM Pacific Time (16:00 Eastern Time, 22:00 Central European Time, 21:00 UTC). Vladimir Braverman from Rice University will talk about “Adversarial Robustness of Streaming Algorithms through Importance Sampling”. Details ofContinue reading "Thursday, Mar 16th, 2023 — Vladimir Braverman from Rice&#160;University"
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="has-text-align-justify">The next <a rel="noreferrer noopener" href="https://sites.google.com/view/dstheory/home" target="_blank">Foundations of Data Science</a> virtual talk series on recent advances in <em>adversarially robust streaming</em> will take place on <strong>Thursday, March 16th</strong> at<strong> 1:00 PM Pacific Time</strong> (16:00 Eastern Time, 22:00 Central European Time, 21:00 UTC). <a href="https://profiles.rice.edu/faculty/vladimir-braverman">Vladimir Braverman</a> from<strong> Rice University</strong> will talk about <em>“Adversarial Robustness of Streaming Algorithms through Importance Sampling”</em>.</p>



<p><a href="https://sites.google.com/view/dstheory">Details of the talk (Zoom link) are available here.</a></p>



<p class="has-text-align-justify"><strong>Abstract</strong>: Robustness against adversarial attacks has recently been at the forefront of algorithmic design for machine learning tasks. In the adversarial streaming model, an adversary gives an algorithm a sequence of adaptively chosen updates u1, &#8230; ,un as a data stream. The goal of the algorithm is to compute or approximate some predetermined function for every prefix of the adversarial stream, but the adversary may generate future updates based on previous outputs of the algorithm. In particular, the adversary may gradually learn the random bits internally used by an algorithm to manipulate dependencies in the input. This is especially problematic as many important problems in the streaming model require randomized algorithms, as they are known to not admit any deterministic algorithms that use sublinear space. In this paper, we introduce adversarially robust streaming algorithms for central machine learning and algorithmic tasks, such as regression and clustering, as well as their more general counterparts, subspace embedding, low-rank approximation, and coreset construction. For regression and other numerical linear algebra related tasks, we consider the row arrival streaming model. Our results are based on a simple, but powerful, observation that many importance sampling-based algorithms give rise to adversarial robustness which is in contrast to sketching based algorithms, which are very prevalent in the streaming literature but suffer from adversarial attacks. In addition, we show that the well-known merge and reduce paradigm in streaming is adversarially robust. Since the merge and reduce paradigm allows coreset constructions in the streaming setting, we thus obtain robust algorithms for k-means, k-median, k-center, Bregman clustering, projective clustering, principal component analysis (PCA) and non-negative matrix factorization. To the best of our knowledge, these are the first adversarially robust results for these problems yet require no new algorithmic implementations. Finally, we empirically confirm the robustness of our algorithms on various adversarial attacks and demonstrate that by contrast, some common existing algorithms are not robust.</p>



<p>This is a joint work with Avinatan Hassidim, Yossi Matias, Mariano Schain, Sandeep Silwal, Samson Zhou. This result has appeared in NeurIPS 2021.</p>



<p>&nbsp;The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p>
<p class="authors">By dstheory</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T22:17:33Z">Friday, March 10 2023, 22:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/03/10/subspace-designs-unit-and-distinct-distances-and-piercing-standard-boxes/'>Subspace Designs, Unit and Distinct Distances, and Piercing Standard Boxes.</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A lot of things are happening and let me briefly report on three major advancements in combinatorics. Peter Keevash, Ashwin Sah and Mehtaab Sawhney proved the existence of subspace designs with any given parameters, provided that the dimension of the &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>A lot of things are happening and let me briefly report on three major advancements in combinatorics.</p>
<ol>
<li>Peter Keevash, Ashwin Sah and Mehtaab Sawhney proved the existence of subspace designs with any given parameters, provided that the dimension of the underlying space is sufficiently large in terms of the other parameters of the design and satisfies the obvious necessary divisibility conditions.  Here is the link to the paper: <a href="https://arxiv.org/abs/2212.00870">The existence of subspace designs</a>.</li>
<li>Noga Alon, Matija Bucić, and Lisa Sauermann made an important advance on the study of unit distances and distinct distances in arbitrary normed space. Here is a link to the paper: <a href="https://arxiv.org/abs/2302.09058">Unit and distinct distances in typical norms.</a> The unit distance and distinct distances problems for Euclidean geometry are old and famous, and much attention has been given to the question of what happens to these problems if one considers normed spaces other than the Euclidean plane. Alon, Bucić, and Sauermann give an essentially tight answer to both questions for almost all norms on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /> , in a certain Baire categoric sense.</li>
<li>István Tomon&#8217;s paper: <a href="https://arxiv.org/abs/2209.09887">Lower bounds for piercing and coloring boxes</a>. Here is Tomon&#8217;s abstract from his recent Copenhagen-Jerusalem seminar: Configurations of axis-parallel boxes in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /> are extensively studied in combinatorial and computational geometry. Despite their innocent appearance, there are many old problems involving their structure that are still not well understood. I will talk about a construction, which addresses several of these problems, and shows that configurations of boxes may be more complex than people conjectured.</li>
</ol>
<h3>Subspace designs and q-analogs</h3>
<p>We talked about subspace designs in <a href="https://gilkalai.wordpress.com/2016/11/23/amazing-stefan-glock-daniela-kuhn-allan-lo-deryk-osthus-give-a-new-proof-for-keevashs-theorem-and-more-news-on-designs/">this post</a>  and in particular about the 2016 paper of Michael  Braun, Tuvi Etzion , Patric R. J. Östergard , Alexander Vardy,  and Alfred Wasserman. While preparing this post I learned the sad news that Alexander Vardy, a prominent coding theorist, had passed away a year ago at the young age of 58.</p>
<p>The theme of finding <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" />-analogs to combinatorial results and problems is important both in enumerative and algebraic combinatorics and in extremal combinatorics and it will be interesting to discuss it in some future post. While preparing for that I recalled the famous <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" />&#8211;<a href="https://en.wikipedia.org/wiki/Dyson_conjecture">Dyson conjecture</a> that had been settled by Zeilberger and Bressoud in 1995. I learned that by now there are simpler proofs:  &#8220;A shorter proof, using formal Laurent series, was given in 2004 by Ira Gessel and Guoce Xin, and an even shorter proof, using a quantitative form, due to Karasev and Petrov, and independently to Lason, of Noga Alon&#8217;s Combinatorial Nullstellensatz, was given in 2012 by Gyula Karolyi and Zoltan Lorant Nagy. The latter method was extended, in 2013, by <a href="http://www.math.rutgers.edu/~zeilberg/mamarim/mamarimhtml/qdyson.html">Shalosh B. Ekhad and Doron Zeilberger</a> to derive explicit expressions of any specific coefficient.&#8221; (Wikipedia.)</p>
<h3>Unit and distinct distances</h3>
<p>Here is the abstract of the paper by Alon, Bucić, and Sauermann:</p>
<blockquote><p><em>Erdős&#8217; unit distance problem and Erdős&#8217; distinct distances problem are among the most classical and well-known open problems in all of discrete mathematics. They ask for the maximum number of unit distances, or the minimum number of distinct distances, respectively, determined by $latex <span id="MathJax-Element-1-Frame" class="MathJax"><span id="MathJax-Span-1" class="math"><span id="MathJax-Span-2" class="mrow"><span id="MathJax-Span-3" class="mi">n$</span></span></span></span> points in the Euclidean plane. The question of what happens in these problems if one considers normed spaces other than the Euclidean plane has been raised in the 1980s by Ulam and Erdős and attracted a lot of attention over the years. We give an essentially tight answer to both questions for almost all norms on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" />, in a certain Baire categoric sense.</em></p>
<p><em>For the unit distance problem we prove that for almost all norms ||.|| on <span id="MathJax-Element-3-Frame" class="MathJax"><span id="MathJax-Span-11" class="math"><span id="MathJax-Span-12" class="mrow"><span id="MathJax-Span-13" class="msubsup"><span id="MathJax-Span-14" class="texatom"><span id="MathJax-Span-15" class="mrow"><span id="MathJax-Span-16" class="mi"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /></span></span></span></span></span></span></span>, any set of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> points defines at most <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+d+%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+d+%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+d+%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;frac{1}{2} d &#92;cdot n &#92;log_2 n" class="latex" /> unit distances according to ||.||. We also show that this is essentially tight, by proving that for every norm ||.|| on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" />, for any large <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, we can find $latex <span id="MathJax-Element-8-Frame" class="MathJax"><span id="MathJax-Span-44" class="math"><span id="MathJax-Span-45" class="mrow"><span id="MathJax-Span-46" class="mi">n$</span></span></span></span> points defining at least <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D%28d-1-o%281%29%29%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D%28d-1-o%281%29%29%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D%28d-1-o%281%29%29%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;frac{1}{2}(d-1-o(1))&#92;cdot n &#92;log_2 n" class="latex" /> unit distances according to ||.||.</em></p>
<p><em>For the distinct distances problem, we prove that for almost all norms ||.|| on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /> any set of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> <span id="MathJax-Element-11-Frame" class="MathJax"><span id="MathJax-Span-76" class="math"><span id="MathJax-Span-77" class="mrow"><span id="MathJax-Span-78" class="mi"></span></span></span></span> points defines at least $latex <span id="MathJax-Element-12-Frame" class="MathJax"><span id="MathJax-Span-79" class="math"><span id="MathJax-Span-80" class="mrow"><span id="MathJax-Span-81" class="mo">(</span><span id="MathJax-Span-82" class="mn">1</span><span id="MathJax-Span-83" class="mo">−</span><span id="MathJax-Span-84" class="mi">o</span><span id="MathJax-Span-85" class="mo">(</span><span id="MathJax-Span-86" class="mn">1</span><span id="MathJax-Span-87" class="mo">)</span><span id="MathJax-Span-88" class="mo">)</span><span id="MathJax-Span-89" class="mi">n$</span></span></span></span> distinct distances according to ||.||. This is clearly tight up to the $latex <span id="MathJax-Element-13-Frame" class="MathJax"><span id="MathJax-Span-90" class="math"><span id="MathJax-Span-91" class="mrow"><span id="MathJax-Span-92" class="mi">o</span><span id="MathJax-Span-93" class="mo">(</span><span id="MathJax-Span-94" class="mn">1</span><span id="MathJax-Span-95" class="mo">)$</span></span></span></span> term.</em></p>
<p><em>Our results settle, in a strong and somewhat surprising form, problems and conjectures of Brass, of Matoušek, and of Brass-Moser-Pach. The proofs combine combinatorial and geometric ideas with tools from Linear Algebra, Topology and Algebraic Geometry.</em></p></blockquote>
<p>We discussed the unit distances and distinct distances in many posts over here, and they are also related to problems around Borsuk&#8217;s problem (see also my survey paper <a href="https://arxiv.org/abs/1505.04952">Some old and new problems in combinatorial geometry I: Around <span class="search-hit mathjax">Borsuk&#8217;s</span> problem</a>).</p>
<h3>Standard boxes</h3>
<p>Here is the abstract of Tomon&#8217;s paper.<br />
<img data-attachment-id="23978" data-permalink="https://gilkalai.wordpress.com/2023/03/10/subspace-designs-unit-and-distinct-distances-and-piercing-standard-boxes/tomon/" data-orig-file="https://gilkalai.files.wordpress.com/2023/03/tomon.png" data-orig-size="663,481" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Tomon" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=640" class="alignnone size-full wp-image-23978" src="https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=640" alt="Tomon" srcset="https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=640 640w, https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=150 150w, https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=300 300w, https://gilkalai.files.wordpress.com/2023/03/tomon.png 663w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p>We discussed the intersection pattern of (standard) boxes on several occasions such as <a href="https://gilkalai.wordpress.com/2014/07/03/my-mathematical-dialogue-with-jurgen-eckhoff/">this post</a> about Jurgen Eckhoff.</p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T11:28:42Z">Friday, March 10 2023, 11:28</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04859'>Agnostic PAC Learning of k-juntas Using L2-Polynomial Regression</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mohsen Heidari, Wojciech Szpankowski</p><p>Many conventional learning algorithms rely on loss functions other than the
natural 0-1 loss for computational efficiency and theoretical tractability.
Among them are approaches based on absolute loss (L1 regression) and square
loss (L2 regression). The first is proved to be an \textit{agnostic} PAC
learner for various important concept classes such as \textit{juntas}, and
\textit{half-spaces}. On the other hand, the second is preferable because of
its computational efficiency, which is linear in the sample size. However, PAC
learnability is still unknown as guarantees have been proved only under
distributional restrictions. The question of whether L2 regression is an
agnostic PAC learner for 0-1 loss has been open since 1993 and yet has to be
answered.
</p>
<p>This paper resolves this problem for the junta class on the Boolean cube --
proving agnostic PAC learning of k-juntas using L2 polynomial regression.
Moreover, we present a new PAC learning algorithm based on the Boolean Fourier
expansion with lower computational complexity. Fourier-based algorithms, such
as Linial et al. (1993), have been used under distributional restrictions, such
as uniform distribution. We show that with an appropriate change, one can apply
those algorithms in agnostic settings without any distributional assumption. We
prove our results by connecting the PAC learning with 0-1 loss to the minimum
mean square estimation (MMSE) problem. We derive an elegant upper bound on the
0-1 loss in terms of the MMSE error and show that the sign of the MMSE is a PAC
learner for any concept class containing it.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Heidari_M/0/1/0/all/0/1">Mohsen Heidari</a>, <a href="http://arxiv.org/find/cs/1/au:+Szpankowski_W/0/1/0/all/0/1">Wojciech Szpankowski</a></p><p>Many conventional learning algorithms rely on loss functions other than the
natural 0-1 loss for computational efficiency and theoretical tractability.
Among them are approaches based on absolute loss (L1 regression) and square
loss (L2 regression). The first is proved to be an \textit{agnostic} PAC
learner for various important concept classes such as \textit{juntas}, and
\textit{half-spaces}. On the other hand, the second is preferable because of
its computational efficiency, which is linear in the sample size. However, PAC
learnability is still unknown as guarantees have been proved only under
distributional restrictions. The question of whether L2 regression is an
agnostic PAC learner for 0-1 loss has been open since 1993 and yet has to be
answered.
</p>
<p>This paper resolves this problem for the junta class on the Boolean cube --
proving agnostic PAC learning of k-juntas using L2 polynomial regression.
Moreover, we present a new PAC learning algorithm based on the Boolean Fourier
expansion with lower computational complexity. Fourier-based algorithms, such
as Linial et al. (1993), have been used under distributional restrictions, such
as uniform distribution. We show that with an appropriate change, one can apply
those algorithms in agnostic settings without any distributional assumption. We
prove our results by connecting the PAC learning with 0-1 loss to the minimum
mean square estimation (MMSE) problem. We derive an elegant upper bound on the
0-1 loss in terms of the MMSE error and show that the sign of the MMSE is a PAC
learner for any concept class containing it.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05136'>A New Heuristic for Rectilinear Crossing Minimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fran&#xe7;ois Dor&#xe9;, Enrico Formenti</p><p>A new heuristic for rectilinear crossing minimization is proposed. It is
based on the idea of iteratively repositioning nodes after a first initial
graph drawing. The new position of a node is computed by casting rays from the
node towards graph edges. Each ray receives a mark and the one with the best
mark determines the new position. The heuristic has interesting performances
when compared to the best competitors which can be found in classical graph
drawing libraries like OGDF.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dore_F/0/1/0/all/0/1">Fran&#xe7;ois Dor&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Formenti_E/0/1/0/all/0/1">Enrico Formenti</a></p><p>A new heuristic for rectilinear crossing minimization is proposed. It is
based on the idea of iteratively repositioning nodes after a first initial
graph drawing. The new position of a node is computed by casting rays from the
node towards graph edges. Each ray receives a mark and the one with the best
mark determines the new position. The heuristic has interesting performances
when compared to the best competitors which can be found in classical graph
drawing libraries like OGDF.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05044'>Range Avoidance for Constant-Depth Circuits: Hardness and Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Karthik Gajulapalli, Alexander Golovnev, Satyajeet Nagargoje, Sidhant Saraogi</p><p>Range Avoidance (AVOID) is a total search problem where, given a Boolean
circuit $C\colon\{0,1\}^n\to\{0,1\}^m$, $m&gt;n$, the task is to find a
$y\in\{0,1\}^m$ outside the range of $C$. For an integer $k\geq 2$,
$NC^0_k$-AVOID is a special case of AVOID where each output bit of $C$ depends
on at most $k$ input bits. Ren, Santhanam, and Wang (FOCS 2022) and Guruswami,
Lyu, and Wang (RANDOM 2022) proved that explicit constructions of functions of
high circuit complexity, rigid matrices, optimal linear codes, Ramsey graphs,
and other combinatorial objects reduce to $NC^0_4$-AVOID, thus establishing
conditional hardness of the $NC^0_4$-AVOID problem. On the other hand,
$NC^0_2$-AVOID admits polynomial-time algorithms, leaving the question about
the complexity of $NC^0_3$-AVOID open. We give the first reduction of an
explicit construction question to $NC^0_3$-AVOID. Specifically, we prove that a
polynomial-time algorithm (with an $NP$ oracle) for $NC^0_3$-AVOID for the case
of $m=n+n^{2/3}$ would imply an explicit construction of a rigid matrix, and,
thus, a super-linear lower bound on the size of log-depth circuits. We also
give deterministic polynomial-time algorithms for all $NC^0_k$-AVOID problems
for ${m\geq n^{k-1}/\log(n)}$. Prior work required an $NP$ oracle, and required
larger stretch, $m \geq n^{k-1}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gajulapalli_K/0/1/0/all/0/1">Karthik Gajulapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Golovnev_A/0/1/0/all/0/1">Alexander Golovnev</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagargoje_S/0/1/0/all/0/1">Satyajeet Nagargoje</a>, <a href="http://arxiv.org/find/cs/1/au:+Saraogi_S/0/1/0/all/0/1">Sidhant Saraogi</a></p><p>Range Avoidance (AVOID) is a total search problem where, given a Boolean
circuit $C\colon\{0,1\}^n\to\{0,1\}^m$, $m&gt;n$, the task is to find a
$y\in\{0,1\}^m$ outside the range of $C$. For an integer $k\geq 2$,
$NC^0_k$-AVOID is a special case of AVOID where each output bit of $C$ depends
on at most $k$ input bits. Ren, Santhanam, and Wang (FOCS 2022) and Guruswami,
Lyu, and Wang (RANDOM 2022) proved that explicit constructions of functions of
high circuit complexity, rigid matrices, optimal linear codes, Ramsey graphs,
and other combinatorial objects reduce to $NC^0_4$-AVOID, thus establishing
conditional hardness of the $NC^0_4$-AVOID problem. On the other hand,
$NC^0_2$-AVOID admits polynomial-time algorithms, leaving the question about
the complexity of $NC^0_3$-AVOID open. We give the first reduction of an
explicit construction question to $NC^0_3$-AVOID. Specifically, we prove that a
polynomial-time algorithm (with an $NP$ oracle) for $NC^0_3$-AVOID for the case
of $m=n+n^{2/3}$ would imply an explicit construction of a rigid matrix, and,
thus, a super-linear lower bound on the size of log-depth circuits. We also
give deterministic polynomial-time algorithms for all $NC^0_k$-AVOID problems
for ${m\geq n^{k-1}/\log(n)}$. Prior work required an $NP$ oracle, and required
larger stretch, $m \geq n^{k-1}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04845'>Smoothed Analysis of Sequential Probability Assignment</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alankrita Bhatt, Nika Haghtalab, Abhishek Shetty</p><p>We initiate the study of smoothed analysis for the sequential probability
assignment problem with contexts. We study information-theoretically optimal
minmax rates as well as a framework for algorithmic reduction involving the
maximum likelihood estimator oracle. Our approach establishes a general-purpose
reduction from minimax rates for sequential probability assignment for smoothed
adversaries to minimax rates for transductive learning. This leads to optimal
(logarithmic) fast rates for parametric classes and classes with finite VC
dimension. On the algorithmic front, we develop an algorithm that efficiently
taps into the MLE oracle, for general classes of functions. We show that under
general conditions this algorithmic approach yields sublinear regret.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhatt_A/0/1/0/all/0/1">Alankrita Bhatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Haghtalab_N/0/1/0/all/0/1">Nika Haghtalab</a>, <a href="http://arxiv.org/find/cs/1/au:+Shetty_A/0/1/0/all/0/1">Abhishek Shetty</a></p><p>We initiate the study of smoothed analysis for the sequential probability
assignment problem with contexts. We study information-theoretically optimal
minmax rates as well as a framework for algorithmic reduction involving the
maximum likelihood estimator oracle. Our approach establishes a general-purpose
reduction from minimax rates for sequential probability assignment for smoothed
adversaries to minimax rates for transductive learning. This leads to optimal
(logarithmic) fast rates for parametric classes and classes with finite VC
dimension. On the algorithmic front, we develop an algorithm that efficiently
taps into the MLE oracle, for general classes of functions. We show that under
general conditions this algorithmic approach yields sublinear regret.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04934'>Parallel Strong Connectivity Based on Faster Reachability</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Letong Wang, Xiaojun Dong, Yan Gu, Yihan Sun</p><p>Computing strongly connected components (SCC) is a fundamental problems in
graph processing. As today's real-world graphs are getting larger and larger,
parallel SCC is increasingly important. SCC is challenging in the parallel
setting and is particularly hard on large-diameter graphs. Many existing
parallel SCC implementations can be even slower than Tarjan's sequential
algorithm on large-diameter graphs.
</p>
<p>To tackle this challenge, we propose an efficient parallel SCC implementation
using a new parallel reachability algorithm. Our solution is based on a novel
idea referred to as vertical granularity control (VGC). It breaks the
synchronization barriers to increase parallelism and hide scheduling overhead.
To use VGC in our SCC algorithm, we also design an efficient data structure
called the \emph{parallel hash bag}. It uses parallel dynamic resizing to avoid
redundant work in maintaining frontiers (vertices processed in a round).
</p>
<p>We implement the parallel SCC algorithm by Blelloch et al.\ (J.\ ACM, 2020)
using our new parallel reachability algorithm. We compare our implementation to
the state-of-the-art systems, including GBBS, iSpan, Multi-step, and our highly
optimized Tarjan's (sequential) algorithm, on 18 graphs, including social, web,
$k$-NN, and lattice graphs. On a machine with 96 cores, our implementation is
the fastest on 16 out of 18 graphs. On average (geometric means) over all
graphs, our SCC is 6.0$\times$ faster than the best previous parallel code
(GBBS), 12.8$\times$ faster than Tarjan's sequential algorithms, and
2.7$\times$ faster than the \emph{best existing implementation on each graph}.
</p>
<p>We believe that our techniques are of independent interest. We also apply our
parallel hash bag and VGC scheme to other graph problems, including
connectivity and least-element lists (LE-lists).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Letong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaojun Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yihan Sun</a></p><p>Computing strongly connected components (SCC) is a fundamental problems in
graph processing. As today's real-world graphs are getting larger and larger,
parallel SCC is increasingly important. SCC is challenging in the parallel
setting and is particularly hard on large-diameter graphs. Many existing
parallel SCC implementations can be even slower than Tarjan's sequential
algorithm on large-diameter graphs.
</p>
<p>To tackle this challenge, we propose an efficient parallel SCC implementation
using a new parallel reachability algorithm. Our solution is based on a novel
idea referred to as vertical granularity control (VGC). It breaks the
synchronization barriers to increase parallelism and hide scheduling overhead.
To use VGC in our SCC algorithm, we also design an efficient data structure
called the \emph{parallel hash bag}. It uses parallel dynamic resizing to avoid
redundant work in maintaining frontiers (vertices processed in a round).
</p>
<p>We implement the parallel SCC algorithm by Blelloch et al.\ (J.\ ACM, 2020)
using our new parallel reachability algorithm. We compare our implementation to
the state-of-the-art systems, including GBBS, iSpan, Multi-step, and our highly
optimized Tarjan's (sequential) algorithm, on 18 graphs, including social, web,
$k$-NN, and lattice graphs. On a machine with 96 cores, our implementation is
the fastest on 16 out of 18 graphs. On average (geometric means) over all
graphs, our SCC is 6.0$\times$ faster than the best previous parallel code
(GBBS), 12.8$\times$ faster than Tarjan's sequential algorithms, and
2.7$\times$ faster than the \emph{best existing implementation on each graph}.
</p>
<p>We believe that our techniques are of independent interest. We also apply our
parallel hash bag and VGC scheme to other graph problems, including
connectivity and least-element lists (LE-lists).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04945'>A Survey of Quantum Alternatives to Randomized Algorithms: Monte Carlo Integration and Beyond</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Philip Intallura, Georgios Korpas, Sudeepto Chakraborty, Vyacheslav Kungurtsev, Jakub Marecek</p><p>Monte Carlo sampling is a powerful toolbox of algorithmic techniques widely
used for a number of applications wherein some noisy quantity, or summary
statistic thereof, is sought to be estimated. In this paper, we survey the
literature for implementing Monte Carlo procedures using quantum circuits,
focusing on the potential to obtain a quantum advantage in the computational
speed of these procedures. We revisit the quantum algorithms that could replace
classical Monte Carlo and then consider both the existing quantum algorithms
and the potential quantum realizations that include adaptive enhancements as
alternatives to the classical procedure.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Intallura_P/0/1/0/all/0/1">Philip Intallura</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Korpas_G/0/1/0/all/0/1">Georgios Korpas</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chakraborty_S/0/1/0/all/0/1">Sudeepto Chakraborty</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kungurtsev_V/0/1/0/all/0/1">Vyacheslav Kungurtsev</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Marecek_J/0/1/0/all/0/1">Jakub Marecek</a></p><p>Monte Carlo sampling is a powerful toolbox of algorithmic techniques widely
used for a number of applications wherein some noisy quantity, or summary
statistic thereof, is sought to be estimated. In this paper, we survey the
literature for implementing Monte Carlo procedures using quantum circuits,
focusing on the potential to obtain a quantum advantage in the computational
speed of these procedures. We revisit the quantum algorithms that could replace
classical Monte Carlo and then consider both the existing quantum algorithms
and the potential quantum realizations that include adaptive enhancements as
alternatives to the classical procedure.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05012'>Spatio-Temporal Trajectory Similarity Measures: A Comprehensive Survey and Quantitative Study</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Danlei Hu, Lu Chen, Hanxi Fang, Ziquan Fang, Tianyi Li, Yunjun Gao</p><p>Spatio-temporal trajectory analytics is at the core of smart mobility
solutions, which offers unprecedented information for diversified applications
such as urban planning, infrastructure development, and vehicular networks.
Trajectory similarity measure, which aims to evaluate the distance between two
trajectories, is a fundamental functionality of trajectory analytics. In this
paper, we propose a comprehensive survey that investigates all the most common
and representative spatio-temporal trajectory measures. First, we provide an
overview of spatio-temporal trajectory measures in terms of three hierarchical
perspectives: Non-learning vs. Learning, Free Space vs. Road Network, and
Standalone vs. Distributed. Next, we present an evaluation benchmark by
designing five real-world transformation scenarios. Based on this benchmark,
extensive experiments are conducted to study the effectiveness,
robustness,nefficiency, and scalability of each measure, which offers
guidelines for trajectory measure selection among multiple techniques and
applications such as trajectory data mining, deep learning, and distributed
processing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Danlei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1">Hanxi Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Ziquan Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yunjun Gao</a></p><p>Spatio-temporal trajectory analytics is at the core of smart mobility
solutions, which offers unprecedented information for diversified applications
such as urban planning, infrastructure development, and vehicular networks.
Trajectory similarity measure, which aims to evaluate the distance between two
trajectories, is a fundamental functionality of trajectory analytics. In this
paper, we propose a comprehensive survey that investigates all the most common
and representative spatio-temporal trajectory measures. First, we provide an
overview of spatio-temporal trajectory measures in terms of three hierarchical
perspectives: Non-learning vs. Learning, Free Space vs. Road Network, and
Standalone vs. Distributed. Next, we present an evaluation benchmark by
designing five real-world transformation scenarios. Based on this benchmark,
extensive experiments are conducted to study the effectiveness,
robustness,nefficiency, and scalability of each measure, which offers
guidelines for trajectory measure selection among multiple techniques and
applications such as trajectory data mining, deep learning, and distributed
processing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05067'>Robust optimization with belief functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marc Goerigk, Romain Guillaume, Adam Kasperski, Pawe&#x142; Zieli&#x144;ski</p><p>In this paper, an optimization problem with uncertain objective function
coefficients is considered. The uncertainty is specified by providing a
discrete scenario set, containing possible realizations of the objective
function coefficients. The concept of belief function in the traditional and
possibilistic setting is applied to define a set of admissible probability
distributions over the scenario set. The generalized Hurwicz criterion is then
used to compute a solution. In this paper, the complexity of the resulting
problem is explored. Some exact and approximation methods of solving it are
proposed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goerigk_M/0/1/0/all/0/1">Marc Goerigk</a>, <a href="http://arxiv.org/find/cs/1/au:+Guillaume_R/0/1/0/all/0/1">Romain Guillaume</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasperski_A/0/1/0/all/0/1">Adam Kasperski</a>, <a href="http://arxiv.org/find/cs/1/au:+Zielinski_P/0/1/0/all/0/1">Pawe&#x142; Zieli&#x144;ski</a></p><p>In this paper, an optimization problem with uncertain objective function
coefficients is considered. The uncertainty is specified by providing a
discrete scenario set, containing possible realizations of the objective
function coefficients. The concept of belief function in the traditional and
possibilistic setting is applied to define a set of admissible probability
distributions over the scenario set. The generalized Hurwicz criterion is then
used to compute a solution. In this paper, the complexity of the resulting
problem is explored. Some exact and approximation methods of solving it are
proposed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05250'>Distributed Half-Integral Matching and Beyond</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sameep Dahal, Jukka Suomela</p><p>By prior work, it is known that any distributed graph algorithm that finds a
maximal matching requires $\Omega(\log^* n)$ communication rounds, while it is
possible to find a maximal fractional matching in $O(1)$ rounds in
bounded-degree graphs. However, all prior $O(1)$-round algorithms for maximal
fractional matching use arbitrarily fine-grained fractional values. In
particular, none of them is able to find a half-integral solution, using only
values from $\{0, \frac12, 1\}$. We show that the use of fine-grained
fractional values is necessary, and moreover we give a complete
characterization on exactly how small values are needed: if we consider maximal
fractional matching in graphs of maximum degree $\Delta = 2d$, and any
distributed graph algorithm with round complexity $T(\Delta)$ that only depends
on $\Delta$ and is independent of $n$, we show that the algorithm has to use
fractional values with a denominator at least $2^d$. We give a new algorithm
that shows that this is also sufficient.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dahal_S/0/1/0/all/0/1">Sameep Dahal</a>, <a href="http://arxiv.org/find/cs/1/au:+Suomela_J/0/1/0/all/0/1">Jukka Suomela</a></p><p>By prior work, it is known that any distributed graph algorithm that finds a
maximal matching requires $\Omega(\log^* n)$ communication rounds, while it is
possible to find a maximal fractional matching in $O(1)$ rounds in
bounded-degree graphs. However, all prior $O(1)$-round algorithms for maximal
fractional matching use arbitrarily fine-grained fractional values. In
particular, none of them is able to find a half-integral solution, using only
values from $\{0, \frac12, 1\}$. We show that the use of fine-grained
fractional values is necessary, and moreover we give a complete
characterization on exactly how small values are needed: if we consider maximal
fractional matching in graphs of maximum degree $\Delta = 2d$, and any
distributed graph algorithm with round complexity $T(\Delta)$ that only depends
on $\Delta$ and is independent of $n$, we show that the algorithm has to use
fractional values with a denominator at least $2^d$. We give a new algorithm
that shows that this is also sufficient.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05327'>Direct Access for Answers to Conjunctive Queries with Aggregation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Idan Eldar, Nofar Carmeli, Benny Kimelfeld</p><p>We study the fine-grained complexity of conjunctive queries with grouping and
aggregation. For some common aggregate functions (e.g., min, max, count, sum),
such a query can be phrased as an ordinary conjunctive query over a database
annotated with a suitable commutative semiring. Specifically, we investigate
the ability to evaluate such queries by constructing in log-linear time a data
structure that provides logarithmic-time direct access to the answers ordered
by a given lexicographic order. This task is nontrivial since the number of
answers might be larger than log-linear in the size of the input, and so, the
data structure needs to provide a compact representation of the space of
answers.
</p>
<p>In the absence of aggregation and annotation, past research provides a
sufficient tractability condition on queries and orders. For queries without
self-joins, this condition is not just sufficient, but also necessary (under
conventional lower-bound assumptions in fine-grained complexity). We show that
all past results continue to hold for annotated databases, assuming that the
annotation itself is not part of the lexicographic order. On the other hand, we
show infeasibility for the case of count-distinct that does not have any
efficient representation as a commutative semiring. We then investigate the
ability to include the aggregate and annotation outcome in the lexicographic
order. Among the hardness results, standing out as tractable is the case of a
semiring with an idempotent addition, such as those of min and max. Notably,
this case captures also count-distinct over a logarithmic-size domain.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Eldar_I/0/1/0/all/0/1">Idan Eldar</a>, <a href="http://arxiv.org/find/cs/1/au:+Carmeli_N/0/1/0/all/0/1">Nofar Carmeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Kimelfeld_B/0/1/0/all/0/1">Benny Kimelfeld</a></p><p>We study the fine-grained complexity of conjunctive queries with grouping and
aggregation. For some common aggregate functions (e.g., min, max, count, sum),
such a query can be phrased as an ordinary conjunctive query over a database
annotated with a suitable commutative semiring. Specifically, we investigate
the ability to evaluate such queries by constructing in log-linear time a data
structure that provides logarithmic-time direct access to the answers ordered
by a given lexicographic order. This task is nontrivial since the number of
answers might be larger than log-linear in the size of the input, and so, the
data structure needs to provide a compact representation of the space of
answers.
</p>
<p>In the absence of aggregation and annotation, past research provides a
sufficient tractability condition on queries and orders. For queries without
self-joins, this condition is not just sufficient, but also necessary (under
conventional lower-bound assumptions in fine-grained complexity). We show that
all past results continue to hold for annotated databases, assuming that the
annotation itself is not part of the lexicographic order. On the other hand, we
show infeasibility for the case of count-distinct that does not have any
efficient representation as a commutative semiring. We then investigate the
ability to include the aggregate and annotation outcome in the lexicographic
order. Among the hardness results, standing out as tractable is the case of a
semiring with an idempotent addition, such as those of min and max. Notably,
this case captures also count-distinct over a logarithmic-size domain.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
