<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-04-06T22:30:23Z">Thursday, April 06 2023, 22:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, April 06
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/04/06/phd-postdoc-at-goethe-university-frankfurt-germany-apply-by-june-16-2023/'>PhD / Postdoc at Goethe University Frankfurt, Germany (apply by June 16, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Fully-funded PhD or Postdoc position in “Parameterized Complexity of Network Dynamics” to be carried out under the supervision of Prof. Holger Dell. The 3-year research project at the intersection of parameterized complexity, statistical physics, and graph theory involves the rigorous analysis of dynamic processes on graphs, such as virus or fake news spreading through a [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Fully-funded PhD or Postdoc position in “Parameterized Complexity of Network Dynamics” to be carried out under the supervision of Prof. Holger Dell. The 3-year research project at the intersection of parameterized complexity, statistical physics, and graph theory involves the rigorous analysis of dynamic processes on graphs, such as virus or fake news spreading through a social network.</p>
<p>Website: <a href="https://tcs.uni-frankfurt.de/positions/">https://tcs.uni-frankfurt.de/positions/</a><br />
Email: tcs-applications@dlist.uni-frankfurt.de</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T09:13:46Z">Thursday, April 06 2023, 09:13</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/04/06/neil-jones-1941-2023/'>Neil Jones, 1941–2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Neil Jones, sad to relate, just passed away. He was Professor Emeritus of Computer Science at the University of Copenhagen, which he joined on a permanent basis in 1982 after gaining tenure at Penn State and a full professorship at the University of Kansas. Eric Allender wrote a post on Neil for Lance Fortnow&#8217;s and [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
Neil Jones, sad to relate, just passed away. He was Professor Emeritus of Computer Science at the University of Copenhagen, which he joined on a permanent basis in 1982 after gaining tenure at Penn State and a full professorship at the University of Kansas. </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/06/neil-jones-1941-2023/neil-d-jones-60-aar/" rel="attachment wp-att-21404"><img data-attachment-id="21404" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/06/neil-jones-1941-2023/neil-d-jones-60-aar/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?fit=1312%2C2000&amp;ssl=1" data-orig-size="1312,2000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;JENS ASTRUP&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;NEIL D. JONES FRA DATALOGISK INSTITUT I KBH\r\rBILLEDET KAN FRIT ANVENDES TIL OMTALE AF HANS 60 AARS  DAG&quot;,&quot;created_timestamp&quot;:&quot;&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;NEIL D. JONES 60 AAR&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="NEIL D. JONES 60 AAR" data-image-description="" data-image-caption="&lt;p&gt;NEIL D. JONES FRA DATALOGISK INSTITUT I KBH&lt;/p&gt;
&lt;p&gt;BILLEDET KAN FRIT ANVENDES TIL OMTALE AF HANS 60 AARS  DAG&lt;/p&gt;
" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?fit=197%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?fit=600%2C914&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=200%2C305&#038;ssl=1" alt="" width="200" height="305" class="aligncenter wp-image-21404" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=672%2C1024&amp;ssl=1 672w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=197%2C300&amp;ssl=1 197w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=768%2C1171&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=1008%2C1536&amp;ssl=1 1008w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=1200%2C1829&amp;ssl=1 1200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?w=1312&amp;ssl=1 1312w" sizes="(max-width: 200px) 100vw, 200px" data-recalc-dims="1" /></a> </p>
<p><P><br />
Eric Allender wrote a <a href="https://blog.computationalcomplexity.org">post</a> on Neil for Lance Fortnow&#8217;s and Bill Gasarch&#8217;s famous blog. We point to it, hopefully with their full approval, and add some supplementary remarks. Eric&#8217;s tribute leads with Jones&#8217;s work with Alan Selman characterizing logical spectra via languages in nondeterministic <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28n%29%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{2^{O(n)}}" class="latex" /> time. He quotes remarks by D. Sivakumar that echo what Siva wrote for our <a href="https://rjlipton.wpcomstaging.com/2021/01/29/alan-selman-1941-2021/">memorial</a> to Alan.</p>
<p>
<p><H2> The Space Problem </H2></p>
<p><p>
Steve Cook and Dick Karp started the quest to understand <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{P = NP}}" class="latex" />? What many including Neil have always considered the &#8220;second big problem&#8221; involves the power of space rather than nondeterminism, specifically: is <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BLOGSPACE+%3D+PTIME%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{LOGSPACE = PTIME}}" class="latex" />? Neil, like the rest of us, had his thoughts on the conjecture that they are different, but like the rest of us, did not know for sure. His thoughts on the subject ranged from <a href="https://dblp.uni-trier.de/rec/journals/jcss/Jones75.html">two</a> early <a href="https://dl.acm.org/doi/pdf/10.1145/800119.803883">papers</a> to the last <a href="https://arxiv.org/pdf/2008.02932.pdf">paper</a> on his DBLP page. </p>
<p>
This last paper is joint with Siddharth Bhaskar, Cynthia Kop, and Jakob Simonsen, and is titled, &#8220;Cons-free Programs and Complexity Classes between LOGSPACE and PTIME.&#8221; It appeared at the 2020 joint meeting of the Horn Clauses for Verification and Synthesis (HCVS) and Verification and Program Transformation (VPT) workshops. They call a program &#8220;cons-free&#8221; if it does not allow agglutination of data, not by <FONT SIZE="+1"><tt>cons</tt></FONT> with lists, nor successor, +, or * with integers, nor any allocator of storage. They further consider constraining recursion so as not to mushroom by mandating certain forms of tail recursion. Problems decided by cons-free programs form the class &#8220;<img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BCF%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{CF}}" class="latex" />&#8221; and those further having only tail recursion, &#8220;<img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BCFTR%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{CFTR}}" class="latex" />.&#8221;</p>
<p>
This use of functional languages represents both a more modern viewpoint&#8212;than how complexity was founded on Turing machines in the 1960s&#8212;and an older one, insofar as Lisp and other ideas of functional languages were fertile before the 1960s. They characterize <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+CF%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{P = CF}}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BLOGSPACE+%3D+CFTR%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{LOGSPACE = CFTR}}" class="latex" /> as their form also constraining recursion. The former holds some surprise as the cons-free programs are allowed to run for exponential time. If they are constrained to run in polynomial time, a class intermediate between <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BLOGSPACE%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{LOGSPACE}}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{P}}" class="latex" /> emerges. Is it equivalent to a known class? They leave that open.</p>
<p>
<p><H2> Non-Turing Time </H2></p>
<p><p>
Jones&#8217;s work on other models besides Turing machines caught my attention 30 years ago&#8212;this is Ken writing this section. I was interested in models that have a constant-factor time overhead for universal simulation <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BU%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{U}" class="latex" /> of any other machine <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BM%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{M}" class="latex" />, in contrast to the standard multitape Turing machine model where <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BU%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{U}" class="latex" /> incurs an <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+t%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{O(&#92;log t)}" class="latex" /> time overhead for simulating <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{t}" class="latex" /> steps of machines <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BM%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{M}" class="latex" /> with more tapes than <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BU%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{U}" class="latex" /> has. This <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+t%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;log t}" class="latex" /> factor also shows up in the deterministic time hierarchy theorem, though for natural instances it can be shaved down to <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+t%29%5E%5Cepsilon%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{O(&#92;log t)^&#92;epsilon}" class="latex" /> for any fixed <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;epsilon}" class="latex" /> by techniques of <em>padding and translation</em>. </p>
<p>
Martin F&uuml;rer had <a href="https://dl.acm.org/doi/10.1145/800070.802172">shown</a> that when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> is fixed, the log factor goes away. I was interested in leveraging random-access models that have constant-factor overhead while imposing locality restrictions on the random access. The resulting time hierarchy theorems are only &#8220;tight&#8221; in the sense of needing <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bt_1%28n%29+%3D+o%28t_2%28n%29%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{t_1(n) = o(t_2(n))}" class="latex" />&#8212;in order to construct a language decidable in time <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bt_2%28n%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{t_2(n)}" class="latex" /> but not in time <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BO%28t_1%28n%29%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{O(t_1(n))}" class="latex" />.</p>
<p>
Jones went this one better by building a natural programming-based model that has a time hierarchy for a <em>fixed</em> constant factor. His STOC 1993 <a href="https://dl.acm.org/doi/pdf/10.1145/167088.167244">paper</a> was titled, &#8220;Constant Time Factors <em>Do</em> Matter&#8221; with italics on the <em>Do</em>. This grew into a <a href="https://link.springer.com/article/10.1007/s002360000038">paper</a> in <em>Acta Informatica</em> 2000 with Amir Ben-Amram. It also became the basis for his 1997 <a href="https://www.amazon.com/Computability-Complexity-Programming-Perspective-Foundations/dp/0262100649">textbook</a>, <em>Computability and Complexity: From a Programming Perspective</em>. </p>
<p>
The prominence of &#8220;<img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{P = NP}}" class="latex" />?&#8221; masks that our lack of knowledge of lower bounds takes effect at linear time. For circuit models the status is even worse: we still have not refuted the possibility that every language in deterministic <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28n%29%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{2^{O(n)}}" class="latex" /> time has (possibly nonuniform) <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BO%28n%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{O(n)}" class="latex" />-sized circuits. I thought that a new kind of super-linear lower bound could get a grip on peeling the end of a coiled tape that might then freely unroll. As with <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{P}}" class="latex" /> versus <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BLOGSPACE%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{LOGSPACE}}" class="latex" />, however, getting such a grip remains open.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
I&#8212;Dick again&#8212;worked on related stuff in a 1979 <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/1979/ERL-m-79-54.pdf">paper</a> that had a cast of famous brilliant scholars: &#8220;Random Walks, Universal Traversal Sequences, and the Complexity of Maze Problems&#8221;&#8212;by Romas Aleliunas, Dick Karp, me, Laci Lovasz, and Charlie Rackoff. There were ways to build off this to greater results, particularly Omer Reingold&#8217;s blending-in of Irit Dinur&#8217;s PCP proof technique to <a href="https://omereingold.files.wordpress.com/2014/10/sl.pdf">show</a> that undirected maze problems belong to deterministic logspace. Is there a way to build more off Neil&#8217;s results&#8212;the newer and the older ones?</p>
<p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T04:03:23Z">Thursday, April 06 2023, 04:03</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02358'>Visualizing Quantum Circuit Probability -- estimating computational action for quantum program synthesis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bao Gia Bach, Akash Kundu, Tamal Acharya, Aritra Sarkar</p><p>This research applies concepts from algorithmic probability to Boolean and
quantum combinatorial logic circuits. A tutorial-style introduction to states
and various notions of the complexity of states are presented. Thereafter, the
probability of states in the circuit model of computation is defined. Classical
and quantum gate sets are compared to select some characteristic sets. The
reachability and expressibility in a space-time-bounded setting for these gate
sets are enumerated and visualized. These results are studied in terms of
computational resources, universality and quantum behavior. The article
suggests how applications like geometric quantum machine learning, novel
quantum algorithm synthesis and quantum artificial general intelligence can
benefit by studying circuit probabilities.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Bach_B/0/1/0/all/0/1">Bao Gia Bach</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kundu_A/0/1/0/all/0/1">Akash Kundu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Acharya_T/0/1/0/all/0/1">Tamal Acharya</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sarkar_A/0/1/0/all/0/1">Aritra Sarkar</a></p><p>This research applies concepts from algorithmic probability to Boolean and
quantum combinatorial logic circuits. A tutorial-style introduction to states
and various notions of the complexity of states are presented. Thereafter, the
probability of states in the circuit model of computation is defined. Classical
and quantum gate sets are compared to select some characteristic sets. The
reachability and expressibility in a space-time-bounded setting for these gate
sets are enumerated and visualized. These results are studied in terms of
computational resources, universality and quantum behavior. The article
suggests how applications like geometric quantum machine learning, novel
quantum algorithm synthesis and quantum artificial general intelligence can
benefit by studying circuit probabilities.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02524'>Picturing counting reductions with the ZH-calculus</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tuomas Laakkonen, Konstantinos Meichanetzidis, John van de Wetering</p><p>Counting the solutions to Boolean formulae defines the problem #SAT, which is
complete for the complexity class #P. We use the ZH-calculus, a universal and
complete graphical language for linear maps which naturally encodes counting
problems in terms of diagrams, to give graphical reductions from #SAT to
several related counting problems. Some of these graphical reductions, like to
#2SAT, are substantially simpler than known reductions via the matrix
permanent. Additionally, our approach allows us to consider the case of
counting solutions modulo an integer on equal footing. Finally, since the
ZH-calculus was originally introduced to reason about quantum computing, we
show that the problem of evaluating ZH-diagrams in the fragment corresponding
to the Clifford+T gateset, is in $FP^{\#P}$. Our results show that graphical
calculi represent an intuitive and useful framework for reasoning about
counting problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Laakkonen_T/0/1/0/all/0/1">Tuomas Laakkonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Meichanetzidis_K/0/1/0/all/0/1">Konstantinos Meichanetzidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Wetering_J/0/1/0/all/0/1">John van de Wetering</a></p><p>Counting the solutions to Boolean formulae defines the problem #SAT, which is
complete for the complexity class #P. We use the ZH-calculus, a universal and
complete graphical language for linear maps which naturally encodes counting
problems in terms of diagrams, to give graphical reductions from #SAT to
several related counting problems. Some of these graphical reductions, like to
#2SAT, are substantially simpler than known reductions via the matrix
permanent. Additionally, our approach allows us to consider the case of
counting solutions modulo an integer on equal footing. Finally, since the
ZH-calculus was originally introduced to reason about quantum computing, we
show that the problem of evaluating ZH-diagrams in the fragment corresponding
to the Clifford+T gateset, is in $FP^{\#P}$. Our results show that graphical
calculi represent an intuitive and useful framework for reasoning about
counting problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02555'>Top-Down Lower Bounds for Depth-Four Circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mika G&#xf6;&#xf6;s, Artur Riazanov, Anastasia Sofronova, Dmitry Sokolov</p><p>We present a top-down lower-bound method for depth-$4$ boolean circuits. In
particular, we give a new proof of the well-known result that the parity
function requires depth-$4$ circuits of size exponential in $n^{1/3}$. Our
proof is an application of robust sunflowers and block unpredictability.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goos_M/0/1/0/all/0/1">Mika G&#xf6;&#xf6;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Riazanov_A/0/1/0/all/0/1">Artur Riazanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sofronova_A/0/1/0/all/0/1">Anastasia Sofronova</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokolov_D/0/1/0/all/0/1">Dmitry Sokolov</a></p><p>We present a top-down lower-bound method for depth-$4$ boolean circuits. In
particular, we give a new proof of the well-known result that the parity
function requires depth-$4$ circuits of size exponential in $n^{1/3}$. Our
proof is an application of robust sunflowers and block unpredictability.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02207'>Algorithm and Hardness for Dynamic Attention Maintenance in Large Language Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jan van den Brand, Zhao Song, Tianyi Zhou</p><p>Large language models (LLMs) have made fundamental changes in human life. The
attention scheme is one of the key components over all the LLMs, such as BERT,
GPT-1, Transformers, GPT-2, 3, 3.5 and 4. Inspired by previous theoretical
study of static version of the attention multiplication problem [Zandieh, Han,
Daliri, and Karbasi arXiv 2023, Alman and Song arXiv 2023]. In this work, we
formally define a dynamic version of attention matrix multiplication problem.
There are matrices $Q,K, V \in \mathbb{R}^{n \times d}$, they represent query,
key and value in LLMs. In each iteration we update one entry in $K$ or $V$. In
the query stage, we receive $(i,j) \in [n] \times [d]$ as input, and want to
answer $(D^{-1} A V)_{i,j}$, where $A:=\exp(QK^\top) \in \mathbb{R}^{n \times
n}$ is a square matrix and $D := \mathrm{diag}(A {\bf 1}_n) \in \mathbb{R}^{n
\times n}$ is a diagonal matrix. Here ${\bf 1}_n$ denote a length-$n$ vector
that all the entries are ones.
</p>
<p>We provide two results: an algorithm and a conditional lower bound.
</p>
<p>$\bullet$ On one hand, inspired by the lazy update idea from [Demetrescu and
Italiano FOCS 2000, Sankowski FOCS 2004, Cohen, Lee and Song STOC 2019, Brand
SODA 2020], we provide a data-structure that uses
$O(n^{\omega(1,1,\tau)-\tau})$ amortized update time, and $O(n^{1+\tau})$
worst-case query time.
</p>
<p>$\bullet$ On the other hand, show that unless the hinted matrix vector
multiplication conjecture [Brand, Nanongkai and Saranurak FOCS 2019] is false,
there is no algorithm that can use both $O(n^{\omega(1,1,\tau) - \tau-
\Omega(1)})$ amortized update time, and $O(n^{1+\tau-\Omega(1)})$ worst query
time.
</p>
<p>In conclusion, our algorithmic result is conditionally optimal unless hinted
matrix vector multiplication conjecture is false.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brand_J/0/1/0/all/0/1">Jan van den Brand</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tianyi Zhou</a></p><p>Large language models (LLMs) have made fundamental changes in human life. The
attention scheme is one of the key components over all the LLMs, such as BERT,
GPT-1, Transformers, GPT-2, 3, 3.5 and 4. Inspired by previous theoretical
study of static version of the attention multiplication problem [Zandieh, Han,
Daliri, and Karbasi arXiv 2023, Alman and Song arXiv 2023]. In this work, we
formally define a dynamic version of attention matrix multiplication problem.
There are matrices $Q,K, V \in \mathbb{R}^{n \times d}$, they represent query,
key and value in LLMs. In each iteration we update one entry in $K$ or $V$. In
the query stage, we receive $(i,j) \in [n] \times [d]$ as input, and want to
answer $(D^{-1} A V)_{i,j}$, where $A:=\exp(QK^\top) \in \mathbb{R}^{n \times
n}$ is a square matrix and $D := \mathrm{diag}(A {\bf 1}_n) \in \mathbb{R}^{n
\times n}$ is a diagonal matrix. Here ${\bf 1}_n$ denote a length-$n$ vector
that all the entries are ones.
</p>
<p>We provide two results: an algorithm and a conditional lower bound.
</p>
<p>$\bullet$ On one hand, inspired by the lazy update idea from [Demetrescu and
Italiano FOCS 2000, Sankowski FOCS 2004, Cohen, Lee and Song STOC 2019, Brand
SODA 2020], we provide a data-structure that uses
$O(n^{\omega(1,1,\tau)-\tau})$ amortized update time, and $O(n^{1+\tau})$
worst-case query time.
</p>
<p>$\bullet$ On the other hand, show that unless the hinted matrix vector
multiplication conjecture [Brand, Nanongkai and Saranurak FOCS 2019] is false,
there is no algorithm that can use both $O(n^{\omega(1,1,\tau) - \tau-
\Omega(1)})$ amortized update time, and $O(n^{1+\tau-\Omega(1)})$ worst query
time.
</p>
<p>In conclusion, our algorithmic result is conditionally optimal unless hinted
matrix vector multiplication conjecture is false.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02063'>Set Covering with Our Eyes Wide Shut</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anupam Gupta, Gregory Kehne, Roie Levin</p><p>In the stochastic set cover problem (Grandoni et al., FOCS '08), we are given
a collection $\mathcal{S}$ of $m$ sets over a universe $\mathcal{U}$ of size
$N$, and a distribution $D$ over elements of $\mathcal{U}$. The algorithm draws
$n$ elements one-by-one from $D$ and must buy a set to cover each element on
arrival; the goal is to minimize the total cost of sets bought during this
process. A universal algorithm a priori maps each element $u \in \mathcal{U}$
to a set $S(u)$ such that if $U \subseteq \mathcal{U}$ is formed by drawing $n$
times from distribution $D$, then the algorithm commits to outputting $S(U)$.
Grandoni et al. gave an $O(\log mN)$-competitive universal algorithm for this
stochastic set cover problem.
</p>
<p>We improve unilaterally upon this result by giving a simple, polynomial time
$O(\log mn)$-competitive universal algorithm for the more general prophet
version, in which $U$ is formed by drawing from $n$ different distributions
$D_1, \ldots, D_n$. Furthermore, we show that we do not need full foreknowledge
of the distributions: in fact, a single sample from each distribution suffices.
We show similar results for the 2-stage prophet setting and for the
online-with-a-sample setting.
</p>
<p>We obtain our results via a generic reduction from the single-sample prophet
setting to the random-order setting; this reduction holds for a broad class of
minimization problems that includes all covering problems. We take advantage of
this framework by giving random-order algorithms for non-metric facility
location and set multicover; using our framework, these automatically translate
to universal prophet algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Anupam Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kehne_G/0/1/0/all/0/1">Gregory Kehne</a>, <a href="http://arxiv.org/find/cs/1/au:+Levin_R/0/1/0/all/0/1">Roie Levin</a></p><p>In the stochastic set cover problem (Grandoni et al., FOCS '08), we are given
a collection $\mathcal{S}$ of $m$ sets over a universe $\mathcal{U}$ of size
$N$, and a distribution $D$ over elements of $\mathcal{U}$. The algorithm draws
$n$ elements one-by-one from $D$ and must buy a set to cover each element on
arrival; the goal is to minimize the total cost of sets bought during this
process. A universal algorithm a priori maps each element $u \in \mathcal{U}$
to a set $S(u)$ such that if $U \subseteq \mathcal{U}$ is formed by drawing $n$
times from distribution $D$, then the algorithm commits to outputting $S(U)$.
Grandoni et al. gave an $O(\log mN)$-competitive universal algorithm for this
stochastic set cover problem.
</p>
<p>We improve unilaterally upon this result by giving a simple, polynomial time
$O(\log mn)$-competitive universal algorithm for the more general prophet
version, in which $U$ is formed by drawing from $n$ different distributions
$D_1, \ldots, D_n$. Furthermore, we show that we do not need full foreknowledge
of the distributions: in fact, a single sample from each distribution suffices.
We show similar results for the 2-stage prophet setting and for the
online-with-a-sample setting.
</p>
<p>We obtain our results via a generic reduction from the single-sample prophet
setting to the random-order setting; this reduction holds for a broad class of
minimization problems that includes all covering problems. We take advantage of
this framework by giving random-order algorithms for non-metric facility
location and set multicover; using our framework, these automatically translate
to universal prophet algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02091'>Determinantal Sieving</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eduard Eiben, Tomohiro Koana, Magnus Wahlstr&#xf6;m</p><p>We introduce determinantal sieving, a new, remarkably powerful tool in the
toolbox of algebraic FPT algorithms. Given a polynomial $P(X)$ on a set of
variables $X=\{x_1,\ldots,x_n\}$ and a linear matroid $M=(X,\mathcal{I})$ of
rank $k$, both over a field $\mathbb{F}$ of characteristic 2, in $2^k$
evaluations we can sieve for those terms in the monomial expansion of $P$ which
are multilinear and whose support is a basis for $M$. Alternatively, using
$2^k$ evaluations of $P$ we can sieve for those monomials whose odd support
spans $M$. Applying this framework, we improve on a range of algebraic FPT
algorithms, such as:
</p>
<p>1. Solving $q$-Matroid Intersection in time $O^*(2^{(q-2)k})$ and $q$-Matroid
Parity in time $O^*(2^{qk})$, improving on $O^*(4^{qk})$ (Brand and Pratt,
ICALP 2021)
</p>
<p>2. $T$-Cycle, Colourful $(s,t)$-Path, Colourful $(S,T)$-Linkage in undirected
graphs, and the more general Rank $k$ $(S,T)$-Linkage problem, all in
$O^*(2^k)$ time, improving on $O^*(2^{k+|S|})$ respectively $O^*(2^{|S|+O(k^2
\log(k+|\mathbb{F}|))})$ (Fomin et al., SODA 2023)
</p>
<p>3. Many instances of the Diverse X paradigm, finding a collection of $r$
solutions to a problem with a minimum mutual distance of $d$ in time
$O^*(2^{r(r-1)d/2})$, improving solutions for $k$-Distinct Branchings from time
$2^{O(k \log k)}$ to $O^*(2^k)$ (Bang-Jensen et al., ESA 2021), and for Diverse
Perfect Matchings from $O^*(2^{2^{O(rd)}})$ to $O^*(2^{r^2d/2})$ (Fomin et al.,
STACS 2021)
</p>
<p>All matroids are assumed to be represented over a field of characteristic 2.
Over general fields, we achieve similar results at the cost of using
exponential space by working over the exterior algebra. For a class of
arithmetic circuits we call strongly monotone, this is even achieved without
any loss of running time. However, the odd support sieving result appears to be
specific to working over characteristic 2.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Eiben_E/0/1/0/all/0/1">Eduard Eiben</a>, <a href="http://arxiv.org/find/cs/1/au:+Koana_T/0/1/0/all/0/1">Tomohiro Koana</a>, <a href="http://arxiv.org/find/cs/1/au:+Wahlstrom_M/0/1/0/all/0/1">Magnus Wahlstr&#xf6;m</a></p><p>We introduce determinantal sieving, a new, remarkably powerful tool in the
toolbox of algebraic FPT algorithms. Given a polynomial $P(X)$ on a set of
variables $X=\{x_1,\ldots,x_n\}$ and a linear matroid $M=(X,\mathcal{I})$ of
rank $k$, both over a field $\mathbb{F}$ of characteristic 2, in $2^k$
evaluations we can sieve for those terms in the monomial expansion of $P$ which
are multilinear and whose support is a basis for $M$. Alternatively, using
$2^k$ evaluations of $P$ we can sieve for those monomials whose odd support
spans $M$. Applying this framework, we improve on a range of algebraic FPT
algorithms, such as:
</p>
<p>1. Solving $q$-Matroid Intersection in time $O^*(2^{(q-2)k})$ and $q$-Matroid
Parity in time $O^*(2^{qk})$, improving on $O^*(4^{qk})$ (Brand and Pratt,
ICALP 2021)
</p>
<p>2. $T$-Cycle, Colourful $(s,t)$-Path, Colourful $(S,T)$-Linkage in undirected
graphs, and the more general Rank $k$ $(S,T)$-Linkage problem, all in
$O^*(2^k)$ time, improving on $O^*(2^{k+|S|})$ respectively $O^*(2^{|S|+O(k^2
\log(k+|\mathbb{F}|))})$ (Fomin et al., SODA 2023)
</p>
<p>3. Many instances of the Diverse X paradigm, finding a collection of $r$
solutions to a problem with a minimum mutual distance of $d$ in time
$O^*(2^{r(r-1)d/2})$, improving solutions for $k$-Distinct Branchings from time
$2^{O(k \log k)}$ to $O^*(2^k)$ (Bang-Jensen et al., ESA 2021), and for Diverse
Perfect Matchings from $O^*(2^{2^{O(rd)}})$ to $O^*(2^{r^2d/2})$ (Fomin et al.,
STACS 2021)
</p>
<p>All matroids are assumed to be represented over a field of characteristic 2.
Over general fields, we achieve similar results at the cost of using
exponential space by working over the exterior algebra. For a class of
arithmetic circuits we call strongly monotone, this is even achieved without
any loss of running time. However, the odd support sieving result appears to be
specific to working over characteristic 2.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02124'>The Bit Complexity of Efficient Continuous Optimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mehrdad Ghadiri, Richard Peng, Santosh S. Vempala</p><p>We analyze the bit complexity of efficient algorithms for fundamental
optimization problems, such as linear regression, $p$-norm regression, and
linear programming (LP). State-of-the-art algorithms are iterative, and in
terms of the number of arithmetic operations, they match the current time
complexity of multiplying two $n$-by-$n$ matrices (up to polylogarithmic
factors). However, previous work has typically assumed infinite precision
arithmetic, and due to complicated inverse maintenance techniques, the actual
running times of these algorithms are unknown. To settle the running time and
bit complexity of these algorithms, we demonstrate that a core common
subroutine, known as \emph{inverse maintenance}, is backward-stable.
Additionally, we show that iterative approaches for solving constrained
weighted regression problems can be accomplished with bounded-error
pre-conditioners. Specifically, we prove that linear programs can be solved
approximately in matrix multiplication time multiplied by polylog factors that
depend on the condition number $\kappa$ of the matrix and the inner and outer
radius of the LP problem. $p$-norm regression can be solved approximately in
matrix multiplication time multiplied by polylog factors in $\kappa$. Lastly,
linear regression can be solved approximately in input-sparsity time multiplied
by polylog factors in $\kappa$. Furthermore, we present results for achieving
lower than matrix multiplication time for $p$-norm regression by utilizing
faster solvers for sparse linear systems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghadiri_M/0/1/0/all/0/1">Mehrdad Ghadiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_R/0/1/0/all/0/1">Richard Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1">Santosh S. Vempala</a></p><p>We analyze the bit complexity of efficient algorithms for fundamental
optimization problems, such as linear regression, $p$-norm regression, and
linear programming (LP). State-of-the-art algorithms are iterative, and in
terms of the number of arithmetic operations, they match the current time
complexity of multiplying two $n$-by-$n$ matrices (up to polylogarithmic
factors). However, previous work has typically assumed infinite precision
arithmetic, and due to complicated inverse maintenance techniques, the actual
running times of these algorithms are unknown. To settle the running time and
bit complexity of these algorithms, we demonstrate that a core common
subroutine, known as \emph{inverse maintenance}, is backward-stable.
Additionally, we show that iterative approaches for solving constrained
weighted regression problems can be accomplished with bounded-error
pre-conditioners. Specifically, we prove that linear programs can be solved
approximately in matrix multiplication time multiplied by polylog factors that
depend on the condition number $\kappa$ of the matrix and the inner and outer
radius of the LP problem. $p$-norm regression can be solved approximately in
matrix multiplication time multiplied by polylog factors in $\kappa$. Lastly,
linear regression can be solved approximately in input-sparsity time multiplied
by polylog factors in $\kappa$. Furthermore, we present results for achieving
lower than matrix multiplication time for $p$-norm regression by utilizing
faster solvers for sparse linear systems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02141'>Sequential Linearithmic Time Optimal Unimodal Fitting When Minimizing Univariate Linear Losses</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kaan Gokcesu, Hakan Gokcesu</p><p>This paper focuses on optimal unimodal transformation of the score outputs of
a univariate learning model under linear loss functions. We demonstrate that
the optimal mapping between score values and the target region is a rectangular
function. To produce this optimal rectangular fit for the observed samples, we
propose a sequential approach that can its estimation with each incoming new
sample. Our approach has logarithmic time complexity per iteration and is
optimally efficient.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gokcesu_K/0/1/0/all/0/1">Kaan Gokcesu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gokcesu_H/0/1/0/all/0/1">Hakan Gokcesu</a></p><p>This paper focuses on optimal unimodal transformation of the score outputs of
a univariate learning model under linear loss functions. We demonstrate that
the optimal mapping between score values and the target region is a rectangular
function. To produce this optimal rectangular fit for the observed samples, we
propose a sequential approach that can its estimation with each incoming new
sample. Our approach has logarithmic time complexity per iteration and is
optimally efficient.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02193'>Folklore Sampling is Optimal for Exact Hopsets: Confirming the $\sqrt{n}$ Barrier</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Greg Bodwin, Gary Hoppenworth</p><p>For a graph $G$, a $D$-diameter-reducing exact hopset is a small set of
additional edges $H$ that, when added to $G$, maintains its graph metric but
guarantees that all node pairs have a shortest path in $G \cup H$ using at most
$D$ edges. A shortcut set is the analogous concept for reachability. These
objects have been studied since the early '90s due to applications in parallel,
distributed, dynamic, and streaming graph algorithms.
</p>
<p>For most of their history, the state-of-the-art construction for either
object was a simple folklore algorithm, based on randomly sampling nodes to hit
long paths in the graph. However, recent breakthroughs of Kogan and Parter
[SODA '22] and Bernstein and Wein [SODA '23] have finally improved over the
folklore diameter bound of $\widetilde{O}(n^{1/2})$ for shortcut sets and for
$(1+\epsilon)$-approximate hopsets. For both objects it is now known that one
can use $O(n)$ hop-edges to reduce diameter to $\widetilde{O}(n^{1/3})$. The
only setting where folklore sampling remains unimproved is for exact hopsets.
Can these improvements be continued?
</p>
<p>We settle this question negatively by constructing graphs on which any exact
hopset of $O(n)$ edges has diameter $\widetilde{\Omega}(n^{1/2})$. This
improves on the previous lower bound of $\widetilde{\Omega}(n^{1/3})$ by Kogan
and Parter [FOCS '22]. Using similar ideas, we also polynomially improve the
current lower bounds for shortcut sets, constructing graphs on which any
shortcut set of $O(n)$ edges reduces diameter to $\widetilde{\Omega}(n^{1/4})$.
This improves on the previous lower bound of $\Omega(n^{1/6})$ by Huang and
Pettie [SIAM J. Disc. Math. '18]. We also extend our constructions to provide
lower bounds against $O(p)$-size exact hopsets and shortcut sets for other
values of $p$; in particular, we show that folklore sampling is near-optimal
for exact hopsets in the entire range of $p \in [1, n^2]$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bodwin_G/0/1/0/all/0/1">Greg Bodwin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoppenworth_G/0/1/0/all/0/1">Gary Hoppenworth</a></p><p>For a graph $G$, a $D$-diameter-reducing exact hopset is a small set of
additional edges $H$ that, when added to $G$, maintains its graph metric but
guarantees that all node pairs have a shortest path in $G \cup H$ using at most
$D$ edges. A shortcut set is the analogous concept for reachability. These
objects have been studied since the early '90s due to applications in parallel,
distributed, dynamic, and streaming graph algorithms.
</p>
<p>For most of their history, the state-of-the-art construction for either
object was a simple folklore algorithm, based on randomly sampling nodes to hit
long paths in the graph. However, recent breakthroughs of Kogan and Parter
[SODA '22] and Bernstein and Wein [SODA '23] have finally improved over the
folklore diameter bound of $\widetilde{O}(n^{1/2})$ for shortcut sets and for
$(1+\epsilon)$-approximate hopsets. For both objects it is now known that one
can use $O(n)$ hop-edges to reduce diameter to $\widetilde{O}(n^{1/3})$. The
only setting where folklore sampling remains unimproved is for exact hopsets.
Can these improvements be continued?
</p>
<p>We settle this question negatively by constructing graphs on which any exact
hopset of $O(n)$ edges has diameter $\widetilde{\Omega}(n^{1/2})$. This
improves on the previous lower bound of $\widetilde{\Omega}(n^{1/3})$ by Kogan
and Parter [FOCS '22]. Using similar ideas, we also polynomially improve the
current lower bounds for shortcut sets, constructing graphs on which any
shortcut set of $O(n)$ edges reduces diameter to $\widetilde{\Omega}(n^{1/4})$.
This improves on the previous lower bound of $\Omega(n^{1/6})$ by Huang and
Pettie [SIAM J. Disc. Math. '18]. We also extend our constructions to provide
lower bounds against $O(p)$-size exact hopsets and shortcut sets for other
values of $p$; in particular, we show that folklore sampling is near-optimal
for exact hopsets in the entire range of $p \in [1, n^2]$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02261'>Optimal Sketching Bounds for Sparse Linear Regression</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tung Mai, Alexander Munteanu, Cameron Musco, Anup B. Rao, Chris Schwiegelshohn, David P. Woodruff</p><p>We study oblivious sketching for $k$-sparse linear regression under various
loss functions such as an $\ell_p$ norm, or from a broad class of hinge-like
loss functions, which includes the logistic and ReLU losses. We show that for
sparse $\ell_2$ norm regression, there is a distribution over oblivious
sketches with $\Theta(k\log(d/k)/\varepsilon^2)$ rows, which is tight up to a
constant factor. This extends to $\ell_p$ loss with an additional additive
$O(k\log(k/\varepsilon)/\varepsilon^2)$ term in the upper bound. This
establishes a surprising separation from the related sparse recovery problem,
which is an important special case of sparse regression. For this problem,
under the $\ell_2$ norm, we observe an upper bound of $O(k \log (d)/\varepsilon
+ k\log(k/\varepsilon)/\varepsilon^2)$ rows, showing that sparse recovery is
strictly easier to sketch than sparse regression. For sparse regression under
hinge-like loss functions including sparse logistic and sparse ReLU regression,
we give the first known sketching bounds that achieve $o(d)$ rows showing that
$O(\mu^2 k\log(\mu n d/\varepsilon)/\varepsilon^2)$ rows suffice, where $\mu$
is a natural complexity parameter needed to obtain relative error bounds for
these loss functions. We again show that this dimension is tight, up to lower
order terms and the dependence on $\mu$. Finally, we show that similar
sketching bounds can be achieved for LASSO regression, a popular convex
relaxation of sparse regression, where one aims to minimize
$\|Ax-b\|_2^2+\lambda\|x\|_1$ over $x\in\mathbb{R}^d$. We show that sketching
dimension $O(\log(d)/(\lambda \varepsilon)^2)$ suffices and that the dependence
on $d$ and $\lambda$ is tight.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1">Tung Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Munteanu_A/0/1/0/all/0/1">Alexander Munteanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Cameron Musco</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1">Anup B. Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwiegelshohn_C/0/1/0/all/0/1">Chris Schwiegelshohn</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a></p><p>We study oblivious sketching for $k$-sparse linear regression under various
loss functions such as an $\ell_p$ norm, or from a broad class of hinge-like
loss functions, which includes the logistic and ReLU losses. We show that for
sparse $\ell_2$ norm regression, there is a distribution over oblivious
sketches with $\Theta(k\log(d/k)/\varepsilon^2)$ rows, which is tight up to a
constant factor. This extends to $\ell_p$ loss with an additional additive
$O(k\log(k/\varepsilon)/\varepsilon^2)$ term in the upper bound. This
establishes a surprising separation from the related sparse recovery problem,
which is an important special case of sparse regression. For this problem,
under the $\ell_2$ norm, we observe an upper bound of $O(k \log (d)/\varepsilon
+ k\log(k/\varepsilon)/\varepsilon^2)$ rows, showing that sparse recovery is
strictly easier to sketch than sparse regression. For sparse regression under
hinge-like loss functions including sparse logistic and sparse ReLU regression,
we give the first known sketching bounds that achieve $o(d)$ rows showing that
$O(\mu^2 k\log(\mu n d/\varepsilon)/\varepsilon^2)$ rows suffice, where $\mu$
is a natural complexity parameter needed to obtain relative error bounds for
these loss functions. We again show that this dimension is tight, up to lower
order terms and the dependence on $\mu$. Finally, we show that similar
sketching bounds can be achieved for LASSO regression, a popular convex
relaxation of sparse regression, where one aims to minimize
$\|Ax-b\|_2^2+\lambda\|x\|_1$ over $x\in\mathbb{R}^d$. We show that sketching
dimension $O(\log(d)/(\lambda \varepsilon)^2)$ suffices and that the dependence
on $d$ and $\lambda$ is tight.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02315'>The Laplacian Paradigm in Deterministic Congested Clique</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sebatian Forster, Tijn de Vos</p><p>In this paper, we bring the techniques of the Laplacian paradigm to the
congested clique, while further restricting ourselves to deterministic
algorithms. In particular, we show how to solve a Laplacian system up to
precision $\epsilon$ in $n^{o(1)}\log(1/\epsilon)$ rounds. We show how to
leverage this result within existing interior point methods for solving flow
problems. We obtain an $m^{3/7+o(1)}U^{1/7}$ round algorithm for maximum flow
on a weighted directed graph with maximum weight $U$, and we obtain an
$\tilde{O}(m^{3/7}(n^{0.158}+n^{o(1)}\text{poly}\log W))$ round algorithm for
unit capacity minimum cost flow on a directed graph with maximum cost $W$.
Hereto, we give a novel routine for computing Eulerian orientations in $O(\log
n \log^* n)$ rounds, which we believe may be of separate interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Forster_S/0/1/0/all/0/1">Sebatian Forster</a>, <a href="http://arxiv.org/find/cs/1/au:+Vos_T/0/1/0/all/0/1">Tijn de Vos</a></p><p>In this paper, we bring the techniques of the Laplacian paradigm to the
congested clique, while further restricting ourselves to deterministic
algorithms. In particular, we show how to solve a Laplacian system up to
precision $\epsilon$ in $n^{o(1)}\log(1/\epsilon)$ rounds. We show how to
leverage this result within existing interior point methods for solving flow
problems. We obtain an $m^{3/7+o(1)}U^{1/7}$ round algorithm for maximum flow
on a weighted directed graph with maximum weight $U$, and we obtain an
$\tilde{O}(m^{3/7}(n^{0.158}+n^{o(1)}\text{poly}\log W))$ round algorithm for
unit capacity minimum cost flow on a directed graph with maximum cost $W$.
Hereto, we give a novel routine for computing Eulerian orientations in $O(\log
n \log^* n)$ rounds, which we believe may be of separate interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02360'>On the Power of Threshold-Based Algorithms for Detecting Cycles in the CONGEST Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pierre Fraigniaud, Ma&#xeb;l Luce, Ioan Todinca</p><p>It is known that, for every $k\geq 2$, $C_{2k}$-freeness can be decided by a
generic Monte-Carlo algorithm running in $n^{1-1/\Theta(k^2)}$ rounds in the
CONGEST model. For $2\leq k\leq 5$, faster Monte-Carlo algorithms do exist,
running in $O(n^{1-1/k})$ rounds, based on upper bounding the number of
messages to be forwarded, and aborting search sub-routines for which this
number exceeds certain thresholds. We investigate the possible extension of
these threshold-based algorithms, for the detection of larger cycles. We first
show that, for every $k\geq 6$, there exists an infinite family of graphs
containing a $2k$-cycle for which any threshold-based algorithm fails to detect
that cycle. Hence, in particular, neither $C_{12}$-freeness nor
$C_{14}$-freeness can be decided by threshold-based algorithms. Nevertheless,
we show that $\{C_{12},C_{14}\}$-freeness can still be decided by a
threshold-based algorithm, running in $O(n^{1-1/7})= O(n^{0.857\dots})$ rounds,
which is faster than using the generic algorithm, which would run in
$O(n^{1-1/22})\simeq O(n^{0.954\dots})$ rounds. Moreover, we exhibit an
infinite collection of families of cycles such that threshold-based algorithms
can decide $\mathcal{F}$-freeness for every $\mathcal{F}$ in this collection.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fraigniaud_P/0/1/0/all/0/1">Pierre Fraigniaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Luce_M/0/1/0/all/0/1">Ma&#xeb;l Luce</a>, <a href="http://arxiv.org/find/cs/1/au:+Todinca_I/0/1/0/all/0/1">Ioan Todinca</a></p><p>It is known that, for every $k\geq 2$, $C_{2k}$-freeness can be decided by a
generic Monte-Carlo algorithm running in $n^{1-1/\Theta(k^2)}$ rounds in the
CONGEST model. For $2\leq k\leq 5$, faster Monte-Carlo algorithms do exist,
running in $O(n^{1-1/k})$ rounds, based on upper bounding the number of
messages to be forwarded, and aborting search sub-routines for which this
number exceeds certain thresholds. We investigate the possible extension of
these threshold-based algorithms, for the detection of larger cycles. We first
show that, for every $k\geq 6$, there exists an infinite family of graphs
containing a $2k$-cycle for which any threshold-based algorithm fails to detect
that cycle. Hence, in particular, neither $C_{12}$-freeness nor
$C_{14}$-freeness can be decided by threshold-based algorithms. Nevertheless,
we show that $\{C_{12},C_{14}\}$-freeness can still be decided by a
threshold-based algorithm, running in $O(n^{1-1/7})= O(n^{0.857\dots})$ rounds,
which is faster than using the generic algorithm, which would run in
$O(n^{1-1/22})\simeq O(n^{0.954\dots})$ rounds. Moreover, we exhibit an
infinite collection of families of cycles such that threshold-based algorithms
can decide $\mathcal{F}$-freeness for every $\mathcal{F}$ in this collection.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02498'>Improved Analysis of two Algorithms for Min-Weighted Sum Bin Packing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guillaume Sagnol</p><p>We study the Min-Weighted Sum Bin Packing problem, a variant of the classical
Bin Packing problem in which items have a weight, and each item induces a cost
equal to its weight multiplied by the index of the bin in which it is packed.
This is in fact equivalent to a batch scheduling problem that arises in many
fields of applications such as appointment scheduling or warehouse logistics.
We give improved lower and upper bounds on the approximation ratio of two
simple algorithms for this problem. In particular, we show that the
knapsack-batching algorithm, which iteratively solves knapsack problems over
the set of remaining items to pack the maximal weight in the current bin, has
an approximation ratio of at most 17/10.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sagnol_G/0/1/0/all/0/1">Guillaume Sagnol</a></p><p>We study the Min-Weighted Sum Bin Packing problem, a variant of the classical
Bin Packing problem in which items have a weight, and each item induces a cost
equal to its weight multiplied by the index of the bin in which it is packed.
This is in fact equivalent to a batch scheduling problem that arises in many
fields of applications such as appointment scheduling or warehouse logistics.
We give improved lower and upper bounds on the approximation ratio of two
simple algorithms for this problem. In particular, we show that the
knapsack-batching algorithm, which iteratively solves knapsack problems over
the set of remaining items to pack the maximal weight in the current bin, has
an approximation ratio of at most 17/10.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02558'>A Simple 1.5-Approximation Algorithm for a Wide Range of Max-SMTI Generalizations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gergely Cs&#xe1;ji</p><p>We give a simple approximation algorithm for a common generalization of many
previously studied extensions of the stable matching problem with ties. These
generalizations include the existence of critical vertices in the graph,
amongst whom we must match as much as possible, free edges, that cannot be
blocking edges and $\Delta$-stabilities, which mean that for an edge to block,
the improvement should be large enough on one or both sides. We also introduce
other notions to generalize these even further, which allows our framework to
capture many existing and future applications. We show that our edge
duplicating technique allows us to treat these different types of
generalizations simultaneously, while also making the algorithm, the proofs and
the analysis much simpler and shorter then in previous approaches. In
particular, we answer an open question by \cite{socialstable} about the
existence of a $\frac{3}{2}$-approximation algorithm for the \smti\ problem
with free edges. This demonstrates well that this technique can grasp the
underlying essence of these problems quite well and have the potential to be
able to solve countless future applications as well.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Csaji_G/0/1/0/all/0/1">Gergely Cs&#xe1;ji</a></p><p>We give a simple approximation algorithm for a common generalization of many
previously studied extensions of the stable matching problem with ties. These
generalizations include the existence of critical vertices in the graph,
amongst whom we must match as much as possible, free edges, that cannot be
blocking edges and $\Delta$-stabilities, which mean that for an edge to block,
the improvement should be large enough on one or both sides. We also introduce
other notions to generalize these even further, which allows our framework to
capture many existing and future applications. We show that our edge
duplicating technique allows us to treat these different types of
generalizations simultaneously, while also making the algorithm, the proofs and
the analysis much simpler and shorter then in previous approaches. In
particular, we answer an open question by \cite{socialstable} about the
existence of a $\frac{3}{2}$-approximation algorithm for the \smti\ problem
with free edges. This demonstrates well that this technique can grasp the
underlying essence of these problems quite well and have the potential to be
able to solve countless future applications as well.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02599'>Query lower bounds for log-concave sampling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sinho Chewi, Jaume de Dios Pont, Jerry Li, Chen Lu, Shyam Narayanan</p><p>Log-concave sampling has witnessed remarkable algorithmic advances in recent
years, but the corresponding problem of proving lower bounds for this task has
remained elusive, with lower bounds previously known only in dimension one. In
this work, we establish the following query lower bounds: (1) sampling from
strongly log-concave and log-smooth distributions in dimension $d\ge 2$
requires $\Omega(\log \kappa)$ queries, which is sharp in any constant
dimension, and (2) sampling from Gaussians in dimension $d$ (hence also from
general log-concave and log-smooth distributions in dimension $d$) requires
$\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ queries, which is nearly sharp
for the class of Gaussians. Here $\kappa$ denotes the condition number of the
target distribution. Our proofs rely upon (1) a multiscale construction
inspired by work on the Kakeya conjecture in harmonic analysis, and (2) a novel
reduction that demonstrates that block Krylov algorithms are optimal for this
problem, as well as connections to lower bound techniques based on Wishart
matrices developed in the matrix-vector query literature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Chewi_S/0/1/0/all/0/1">Sinho Chewi</a>, <a href="http://arxiv.org/find/math/1/au:+Pont_J/0/1/0/all/0/1">Jaume de Dios Pont</a>, <a href="http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1">Jerry Li</a>, <a href="http://arxiv.org/find/math/1/au:+Lu_C/0/1/0/all/0/1">Chen Lu</a>, <a href="http://arxiv.org/find/math/1/au:+Narayanan_S/0/1/0/all/0/1">Shyam Narayanan</a></p><p>Log-concave sampling has witnessed remarkable algorithmic advances in recent
years, but the corresponding problem of proving lower bounds for this task has
remained elusive, with lower bounds previously known only in dimension one. In
this work, we establish the following query lower bounds: (1) sampling from
strongly log-concave and log-smooth distributions in dimension $d\ge 2$
requires $\Omega(\log \kappa)$ queries, which is sharp in any constant
dimension, and (2) sampling from Gaussians in dimension $d$ (hence also from
general log-concave and log-smooth distributions in dimension $d$) requires
$\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ queries, which is nearly sharp
for the class of Gaussians. Here $\kappa$ denotes the condition number of the
target distribution. Our proofs rely upon (1) a multiscale construction
inspired by work on the Kakeya conjecture in harmonic analysis, and (2) a novel
reduction that demonstrates that block Krylov algorithms are optimal for this
problem, as well as connections to lower bound techniques based on Wishart
matrices developed in the matrix-vector query literature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-06T00:30:00Z">Thursday, April 06 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, April 05
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01787'>The Planted $k$-SUM Problem: Algorithms, Lower Bounds, Hardness Amplification, and Cryptography</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sagnik Saga, Nikolaj I. Schwartzbach, Prashant Nalini Vasudevan</p><p>In the average-case $k$-SUM problem, given $r$ integers chosen uniformly at
random from $\{0,\ldots,M-1\}$, the objective is to find a set of $k$ numbers
that sum to $0$ modulo $M$ (this set is called a solution). In the related
$k$-XOR problem, given $k$ uniformly random Boolean vectors of length
$\log{M}$, the objective is to find a set of $k$ of them whose bitwise-XOR is
the all-zero vector. Both of these problems have widespread applications in the
study of fine-grained complexity and cryptanalysis.
</p>
<p>The feasibility and complexity of these problems depends on the relative
values of $k$, $r$, and $M$. The dense regime of $M \leq r^k$, where solutions
exist with high probability, is quite well-understood and we have several
non-trivial algorithms and hardness conjectures here. Much less is known about
the sparse regime of $M\gg r^k$, where solutions are unlikely to exist. The
best answers we have for many fundamental questions here are limited to
whatever carries over from the dense or worst-case settings.
</p>
<p>We study the planted $k$-SUM and $k$-XOR problems in the sparse regime. In
these problems, a random solution is planted in a randomly generated instance
and has to be recovered. As $M$ increases past $r^k$, these planted solutions
tend to be the only solutions with increasing probability, potentially becoming
easier to find. We show several results about the complexity and applications
of these problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Saga_S/0/1/0/all/0/1">Sagnik Saga</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwartzbach_N/0/1/0/all/0/1">Nikolaj I. Schwartzbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasudevan_P/0/1/0/all/0/1">Prashant Nalini Vasudevan</a></p><p>In the average-case $k$-SUM problem, given $r$ integers chosen uniformly at
random from $\{0,\ldots,M-1\}$, the objective is to find a set of $k$ numbers
that sum to $0$ modulo $M$ (this set is called a solution). In the related
$k$-XOR problem, given $k$ uniformly random Boolean vectors of length
$\log{M}$, the objective is to find a set of $k$ of them whose bitwise-XOR is
the all-zero vector. Both of these problems have widespread applications in the
study of fine-grained complexity and cryptanalysis.
</p>
<p>The feasibility and complexity of these problems depends on the relative
values of $k$, $r$, and $M$. The dense regime of $M \leq r^k$, where solutions
exist with high probability, is quite well-understood and we have several
non-trivial algorithms and hardness conjectures here. Much less is known about
the sparse regime of $M\gg r^k$, where solutions are unlikely to exist. The
best answers we have for many fundamental questions here are limited to
whatever carries over from the dense or worst-case settings.
</p>
<p>We study the planted $k$-SUM and $k$-XOR problems in the sparse regime. In
these problems, a random solution is planted in a randomly generated instance
and has to be recovered. As $M$ increases past $r^k$, these planted solutions
tend to be the only solutions with increasing probability, potentially becoming
easier to find. We show several results about the complexity and applications
of these problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01800'>Quantum Public-Key Encryption with Tamper-Resilient Public Keys from One-Way Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fuyuki Kitagawa, Tomoyuki Morimae, Ryo Nishimaki, Takashi Yamakawa</p><p>We construct quantum public-key encryption from one-way functions. In our
construction, public keys are quantum, but ciphertexts are classical. Quantum
public-key encryption from one-way functions (or weaker primitives such as
pseudorandom function-like states) are also proposed in some recent works
[Morimae-Yamakawa, eprint:2022/1336; Coladangelo, eprint:2023/282;
Grilo-Sattath-Vu, eprint:2023/345; Barooti-Malavolta-Walter, eprint:2023/306].
However, they have a huge drawback: they are secure only when quantum public
keys can be transmitted to the sender (who runs the encryption algorithm)
without being tampered with by the adversary, which seems to require
unsatisfactory physical setup assumptions such as secure quantum channels. Our
construction is free from such a drawback: it guarantees the secrecy of the
encrypted messages even if we assume only unauthenticated quantum channels.
Thus, the encryption is done with adversarially tampered quantum public keys.
Our construction based only on one-way functions is the first quantum
public-key encryption that achieves the goal of classical public-key
encryption, namely, to establish secure communication over insecure channels.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Kitagawa_F/0/1/0/all/0/1">Fuyuki Kitagawa</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Morimae_T/0/1/0/all/0/1">Tomoyuki Morimae</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nishimaki_R/0/1/0/all/0/1">Ryo Nishimaki</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yamakawa_T/0/1/0/all/0/1">Takashi Yamakawa</a></p><p>We construct quantum public-key encryption from one-way functions. In our
construction, public keys are quantum, but ciphertexts are classical. Quantum
public-key encryption from one-way functions (or weaker primitives such as
pseudorandom function-like states) are also proposed in some recent works
[Morimae-Yamakawa, eprint:2022/1336; Coladangelo, eprint:2023/282;
Grilo-Sattath-Vu, eprint:2023/345; Barooti-Malavolta-Walter, eprint:2023/306].
However, they have a huge drawback: they are secure only when quantum public
keys can be transmitted to the sender (who runs the encryption algorithm)
without being tampered with by the adversary, which seems to require
unsatisfactory physical setup assumptions such as secure quantum channels. Our
construction is free from such a drawback: it guarantees the secrecy of the
encrypted messages even if we assume only unauthenticated quantum channels.
Thus, the encryption is done with adversarially tampered quantum public keys.
Our construction based only on one-way functions is the first quantum
public-key encryption that achieves the goal of classical public-key
encryption, namely, to establish secure communication over insecure channels.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01764'>Minimizing Running Buffers for Tabletop Object Rearrangement: Complexity, Fast Algorithms, and Applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kai Gao, Si Wei Feng, Baichuan Huang, Jingjin Yu</p><p>For rearranging objects on tabletops with overhand grasps, temporarily
relocating objects to some buffer space may be necessary. This raises the
natural question of how many simultaneous storage spaces, or "running buffers",
are required so that certain classes of tabletop rearrangement problems are
feasible. In this work, we examine the problem for both labeled and unlabeled
settings. On the structural side, we observe that finding the minimum number of
running buffers (MRB) can be carried out on a dependency graph abstracted from
a problem instance, and show that computing MRB is NP-hard. We then prove that
under both labeled and unlabeled settings, even for uniform cylindrical
objects, the number of required running buffers may grow unbounded as the
number of objects to be rearranged increases. We further show that the bound
for the unlabeled case is tight. On the algorithmic side, we develop effective
exact algorithms for finding MRB for both labeled and unlabeled tabletop
rearrangement problems, scalable to over a hundred objects under very high
object density. More importantly, our algorithms also compute a sequence
witnessing the computed MRB that can be used for solving object rearrangement
tasks. Employing these algorithms, empirical evaluations reveal that random
labeled and unlabeled instances, which more closely mimics real-world setups,
generally have fairly small MRBs. Using real robot experiments, we demonstrate
that the running buffer abstraction leads to state-of-the-art solutions for
in-place rearrangement of many objects in tight, bounded workspace.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gao_K/0/1/0/all/0/1">Kai Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Si Wei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1">Baichuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jingjin Yu</a></p><p>For rearranging objects on tabletops with overhand grasps, temporarily
relocating objects to some buffer space may be necessary. This raises the
natural question of how many simultaneous storage spaces, or "running buffers",
are required so that certain classes of tabletop rearrangement problems are
feasible. In this work, we examine the problem for both labeled and unlabeled
settings. On the structural side, we observe that finding the minimum number of
running buffers (MRB) can be carried out on a dependency graph abstracted from
a problem instance, and show that computing MRB is NP-hard. We then prove that
under both labeled and unlabeled settings, even for uniform cylindrical
objects, the number of required running buffers may grow unbounded as the
number of objects to be rearranged increases. We further show that the bound
for the unlabeled case is tight. On the algorithmic side, we develop effective
exact algorithms for finding MRB for both labeled and unlabeled tabletop
rearrangement problems, scalable to over a hundred objects under very high
object density. More importantly, our algorithms also compute a sequence
witnessing the computed MRB that can be used for solving object rearrangement
tasks. Employing these algorithms, empirical evaluations reveal that random
labeled and unlabeled instances, which more closely mimics real-world setups,
generally have fairly small MRBs. Using real robot experiments, we demonstrate
that the running buffer abstraction leads to state-of-the-art solutions for
in-place rearrangement of many objects in tight, bounded workspace.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01984'>A statistical framework for analyzing shape in a time series of random geometric objects</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anne van Delft, Andrew J. Blumberg</p><p>We introduce a new framework to analyze shape descriptors that capture the
geometric features of an ensemble of point clouds. At the core of our approach
is the point of view that the data arises as sampled recordings from a metric
space-valued stochastic process, possibly of nonstationary nature, thereby
integrating geometric data analysis into the realm of functional time series
analysis. We focus on the descriptors coming from topological data analysis.
Our framework allows for natural incorporation of spatial-temporal dynamics,
heterogeneous sampling, and the study of convergence rates. Further, we derive
complete invariants for classes of metric space-valued stochastic processes in
the spirit of Gromov, and relate these invariants to so-called ball volume
processes. Under mild dependence conditions, a weak invariance principle in
$D([0,1]\times [0,\mathscr{R}])$ is established for sequential empirical
versions of the latter, assuming the probabilistic structure possibly changes
over time. Finally, we use this result to introduce novel test statistics for
topological change, which are distribution free in the limit under the
hypothesis of stationarity.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Delft_A/0/1/0/all/0/1">Anne van Delft</a>, <a href="http://arxiv.org/find/math/1/au:+Blumberg_A/0/1/0/all/0/1">Andrew J. Blumberg</a></p><p>We introduce a new framework to analyze shape descriptors that capture the
geometric features of an ensemble of point clouds. At the core of our approach
is the point of view that the data arises as sampled recordings from a metric
space-valued stochastic process, possibly of nonstationary nature, thereby
integrating geometric data analysis into the realm of functional time series
analysis. We focus on the descriptors coming from topological data analysis.
Our framework allows for natural incorporation of spatial-temporal dynamics,
heterogeneous sampling, and the study of convergence rates. Further, we derive
complete invariants for classes of metric space-valued stochastic processes in
the spirit of Gromov, and relate these invariants to so-called ball volume
processes. Under mild dependence conditions, a weak invariance principle in
$D([0,1]\times [0,\mathscr{R}])$ is established for sequential empirical
versions of the latter, assuming the probabilistic structure possibly changes
over time. Finally, we use this result to introduce novel test statistics for
topological change, which are distribution free in the limit under the
hypothesis of stationarity.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01374'>Distribution Testing Under the Parity Trace</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Renato Ferreira Pinto Jr., Nathaniel Harms</p><p>Distribution testing is a fundamental statistical task with many
applications, but we are interested in a variety of problems where systematic
mislabelings of the sample prevent us from applying the existing theory. To
apply distribution testing to these problems, we introduce distribution testing
under the parity trace, where the algorithm receives an ordered sample $S$ that
reveals only the least significant bit of each element. This abstraction
reveals connections between the following three problems of interest, allowing
new upper and lower bounds:
</p>
<p>1. In distribution testing with a confused collector, the collector of the
sample may be incapable of distinguishing between nearby elements of a domain
(e.g. a machine learning classifier). We prove bounds for distribution testing
with a confused collector on domains structured as a cycle or a path.
</p>
<p>2. Recent work on the fundamental testing vs. learning question established
tight lower bounds on distribution-free sample-based property testing by
reduction from distribution testing, but the tightness is limited to symmetric
properties. The parity trace allows a broader family of equivalences to
non-symmetric properties, while recovering and strengthening many of the
previous results with a different technique.
</p>
<p>3. We give the first results for property testing in the well-studied trace
reconstruction model, where the goal is to test whether an unknown string $x$
satisfies some property or is far from satisfying that property, given only
independent random traces of $x$.
</p>
<p>Our main technical result is a tight bound of $\widetilde
\Theta\left((n/\epsilon)^{4/5} + \sqrt n/\epsilon^2\right)$ for testing
uniformity of distributions over $[n]$ under the parity trace, leading also to
results for the problems above.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pinto_R/0/1/0/all/0/1">Renato Ferreira Pinto Jr.</a>, <a href="http://arxiv.org/find/cs/1/au:+Harms_N/0/1/0/all/0/1">Nathaniel Harms</a></p><p>Distribution testing is a fundamental statistical task with many
applications, but we are interested in a variety of problems where systematic
mislabelings of the sample prevent us from applying the existing theory. To
apply distribution testing to these problems, we introduce distribution testing
under the parity trace, where the algorithm receives an ordered sample $S$ that
reveals only the least significant bit of each element. This abstraction
reveals connections between the following three problems of interest, allowing
new upper and lower bounds:
</p>
<p>1. In distribution testing with a confused collector, the collector of the
sample may be incapable of distinguishing between nearby elements of a domain
(e.g. a machine learning classifier). We prove bounds for distribution testing
with a confused collector on domains structured as a cycle or a path.
</p>
<p>2. Recent work on the fundamental testing vs. learning question established
tight lower bounds on distribution-free sample-based property testing by
reduction from distribution testing, but the tightness is limited to symmetric
properties. The parity trace allows a broader family of equivalences to
non-symmetric properties, while recovering and strengthening many of the
previous results with a different technique.
</p>
<p>3. We give the first results for property testing in the well-studied trace
reconstruction model, where the goal is to test whether an unknown string $x$
satisfies some property or is far from satisfying that property, given only
independent random traces of $x$.
</p>
<p>Our main technical result is a tight bound of $\widetilde
\Theta\left((n/\epsilon)^{4/5} + \sqrt n/\epsilon^2\right)$ for testing
uniformity of distributions over $[n]$ under the parity trace, leading also to
results for the problems above.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01438'>Tight Space Lower Bound for Pseudo-Deterministic Approximate Counting</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ofer Grossman, Meghal Gupta, Mark Sellke</p><p>We investigate one of the most basic problems in streaming algorithms:
approximating the number of elements in the stream. In 1978, Morris famously
gave a randomized algorithm achieving a constant-factor approximation error for
streams of length at most N in space $O(\log \log N)$. We investigate the
pseudo-deterministic complexity of the problem and prove a tight $\Omega(\log
N)$ lower bound, thus resolving a problem of
Goldwasser-Grossman-Mohanty-Woodruff.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Grossman_O/0/1/0/all/0/1">Ofer Grossman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1">Meghal Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Sellke_M/0/1/0/all/0/1">Mark Sellke</a></p><p>We investigate one of the most basic problems in streaming algorithms:
approximating the number of elements in the stream. In 1978, Morris famously
gave a randomized algorithm achieving a constant-factor approximation error for
streams of length at most N in space $O(\log \log N)$. We investigate the
pseudo-deterministic complexity of the problem and prove a tight $\Omega(\log
N)$ lower bound, thus resolving a problem of
Goldwasser-Grossman-Mohanty-Woodruff.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01225'>A greedy approach for increased vehicle utilization in ridesharing networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aqsa Ashraf Makhdomi, Iqra Altaf Gillani</p><p>In recent years, ridesharing platforms have become a prominent mode of
transportation for the residents of urban areas. As a fundamental problem,
route recommendation for these platforms is vital for their sustenance. The
works done in this direction have recommended routes with higher passenger
demand. Despite the existing works, statistics have suggested that these
services cause increased greenhouse emissions compared to private vehicles as
they roam around in search of riders. This analysis provides finer details
regarding the functionality of ridesharing systems and it reveals that in the
face of their boom, they have not utilized the vehicle capacity efficiently. We
propose to overcome the above limitations and recommend routes that will fetch
multiple passengers simultaneously which will result in increased vehicle
utilization and thereby decrease the effect of these systems on the
environment. As route recommendation is NP-hard, we propose a k-hop-based
sliding window approximation algorithm that reduces the search space from
entire road network to a window. We further demonstrate that maximizing
expected demand is submodular and greedy algorithms can be used to optimize our
objective function within a window. We evaluate our proposed model on
real-world datasets and experimental results demonstrate superior performance
by our proposed model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Makhdomi_A/0/1/0/all/0/1">Aqsa Ashraf Makhdomi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gillani_I/0/1/0/all/0/1">Iqra Altaf Gillani</a></p><p>In recent years, ridesharing platforms have become a prominent mode of
transportation for the residents of urban areas. As a fundamental problem,
route recommendation for these platforms is vital for their sustenance. The
works done in this direction have recommended routes with higher passenger
demand. Despite the existing works, statistics have suggested that these
services cause increased greenhouse emissions compared to private vehicles as
they roam around in search of riders. This analysis provides finer details
regarding the functionality of ridesharing systems and it reveals that in the
face of their boom, they have not utilized the vehicle capacity efficiently. We
propose to overcome the above limitations and recommend routes that will fetch
multiple passengers simultaneously which will result in increased vehicle
utilization and thereby decrease the effect of these systems on the
environment. As route recommendation is NP-hard, we propose a k-hop-based
sliding window approximation algorithm that reduces the search space from
entire road network to a window. We further demonstrate that maximizing
expected demand is submodular and greedy algorithms can be used to optimize our
objective function within a window. We evaluate our proposed model on
real-world datasets and experimental results demonstrate superior performance
by our proposed model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01403'>Randomly Punctured Reed-Solomon Codes Achieve the List Decoding Capacity over Polynomial-Size Alphabets</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zeyu Guo, Zihan Zhang</p><p>This paper shows that, with high probability, randomly punctured Reed-Solomon
codes over fields of polynomial size achieve the list decoding capacity. More
specifically, we prove that for any $\epsilon&gt;0$ and $R\in (0,1)$, with high
probability, randomly punctured Reed-Solomon codes of block length $n$ and rate
$R$ are $\left(1-R-\epsilon, O({1}/{\epsilon})\right)$ list decodable over
alphabets of size at least $2^{\mathrm{poly}(1/\epsilon)}n^2$. This extends the
recent breakthrough of Brakensiek, Gopi, and Makam (STOC 2023) that randomly
punctured Reed-Solomon codes over fields of exponential size attain the
generalized Singleton bound of Shangguan and Tamo (STOC 2020).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zeyu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zihan Zhang</a></p><p>This paper shows that, with high probability, randomly punctured Reed-Solomon
codes over fields of polynomial size achieve the list decoding capacity. More
specifically, we prove that for any $\epsilon&gt;0$ and $R\in (0,1)$, with high
probability, randomly punctured Reed-Solomon codes of block length $n$ and rate
$R$ are $\left(1-R-\epsilon, O({1}/{\epsilon})\right)$ list decodable over
alphabets of size at least $2^{\mathrm{poly}(1/\epsilon)}n^2$. This extends the
recent breakthrough of Brakensiek, Gopi, and Makam (STOC 2023) that randomly
punctured Reed-Solomon codes over fields of exponential size attain the
generalized Singleton bound of Shangguan and Tamo (STOC 2020).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01416'>A $d^{1/2+o(1)}$ Monotonicity Tester for Boolean Functions on $d$-Dimensional Hypergrids</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hadley Black, Deeparnab Chakrabarty, C. Seshadhri</p><p>Monotonicity testing of Boolean functions on the hypergrid, $f:[n]^d \to
\{0,1\}$, is a classic topic in property testing. Determining the non-adaptive
complexity of this problem is an important open question. For arbitrary $n$,
[Black-Chakrabarty-Seshadhri, SODA 2020] describe a tester with query
complexity $\widetilde{O}(\varepsilon^{-4/3}d^{5/6})$. This complexity is
independent of $n$, but has a suboptimal dependence on $d$. Recently,
[Braverman-Khot-Kindler-Minzer, ITCS 2023] and [Black-Chakrabarty-Seshadhri,
STOC 2023] describe $\widetilde{O}(\varepsilon^{-2} n^3\sqrt{d})$ and
$\widetilde{O}(\varepsilon^{-2} n\sqrt{d})$-query testers, respectively. These
testers have an almost optimal dependence on $d$, but a suboptimal polynomial
dependence on $n$.
</p>
<p>In this paper, we describe a non-adaptive, one-sided monotonicity tester with
query complexity $O(\varepsilon^{-2} d^{1/2 + o(1)})$, independent of $n$. Up
to the $d^{o(1)}$-factors, our result resolves the non-adaptive complexity of
monotonicity testing for Boolean functions on hypergrids. The independence of
$n$ yields a non-adaptive, one-sided $O(\varepsilon^{-2} d^{1/2 + o(1)})$-query
monotonicity tester for Boolean functions $f:\mathbb{R}^d \to \{0,1\}$
associated with an arbitrary product measure.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Black_H/0/1/0/all/0/1">Hadley Black</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarty_D/0/1/0/all/0/1">Deeparnab Chakrabarty</a>, <a href="http://arxiv.org/find/cs/1/au:+Seshadhri_C/0/1/0/all/0/1">C. Seshadhri</a></p><p>Monotonicity testing of Boolean functions on the hypergrid, $f:[n]^d \to
\{0,1\}$, is a classic topic in property testing. Determining the non-adaptive
complexity of this problem is an important open question. For arbitrary $n$,
[Black-Chakrabarty-Seshadhri, SODA 2020] describe a tester with query
complexity $\widetilde{O}(\varepsilon^{-4/3}d^{5/6})$. This complexity is
independent of $n$, but has a suboptimal dependence on $d$. Recently,
[Braverman-Khot-Kindler-Minzer, ITCS 2023] and [Black-Chakrabarty-Seshadhri,
STOC 2023] describe $\widetilde{O}(\varepsilon^{-2} n^3\sqrt{d})$ and
$\widetilde{O}(\varepsilon^{-2} n\sqrt{d})$-query testers, respectively. These
testers have an almost optimal dependence on $d$, but a suboptimal polynomial
dependence on $n$.
</p>
<p>In this paper, we describe a non-adaptive, one-sided monotonicity tester with
query complexity $O(\varepsilon^{-2} d^{1/2 + o(1)})$, independent of $n$. Up
to the $d^{o(1)}$-factors, our result resolves the non-adaptive complexity of
monotonicity testing for Boolean functions on hypergrids. The independence of
$n$ yields a non-adaptive, one-sided $O(\varepsilon^{-2} d^{1/2 + o(1)})$-query
monotonicity tester for Boolean functions $f:\mathbb{R}^d \to \{0,1\}$
associated with an arbitrary product measure.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01600'>Minimum Cost Flow in the CONGEST Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tijn de Vos</p><p>We consider the CONGEST model on a network with $n$ nodes, $m$ edges,
diameter $D$, and integer costs and capacities bounded by $\text{poly} n$. In
this paper, we show how to find an exact solution to the minimum cost flow
problem in $n^{1/2+o(1)}(\sqrt{n}+D)$ rounds, improving the state of the art
algorithm with running time $m^{3/7+o(1)}(\sqrt nD^{1/4}+D)$ [Forster et al.
FOCS 2021], which only holds for the special case of unit capacity graphs. For
certain graphs, we achieve even better results. In particular, for planar
graphs, expander graphs, $n^{o(1)}$-genus graphs, $n^{o(1)}$-treewidth graphs,
and excluded-minor graphs our algorithm takes $n^{1/2+o(1)}D$ rounds. We obtain
this result by combining recent results on Laplacian solvers in the CONGEST
model [Forster et al. FOCS 2021, Anagnostides et al. DISC 2022] with a CONGEST
implementation of the LP solver of Lee and Sidford [FOCS 2014], and finally
show that we can round the approximate solution to an exact solution. Our
algorithm solves certain linear programs, that generalize minimum cost flow, up
to additive error $\epsilon$ in $n^{1/2+o(1)}(\sqrt{n}+D)\log^3 (1/\epsilon)$
rounds.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Vos_T/0/1/0/all/0/1">Tijn de Vos</a></p><p>We consider the CONGEST model on a network with $n$ nodes, $m$ edges,
diameter $D$, and integer costs and capacities bounded by $\text{poly} n$. In
this paper, we show how to find an exact solution to the minimum cost flow
problem in $n^{1/2+o(1)}(\sqrt{n}+D)$ rounds, improving the state of the art
algorithm with running time $m^{3/7+o(1)}(\sqrt nD^{1/4}+D)$ [Forster et al.
FOCS 2021], which only holds for the special case of unit capacity graphs. For
certain graphs, we achieve even better results. In particular, for planar
graphs, expander graphs, $n^{o(1)}$-genus graphs, $n^{o(1)}$-treewidth graphs,
and excluded-minor graphs our algorithm takes $n^{1/2+o(1)}D$ rounds. We obtain
this result by combining recent results on Laplacian solvers in the CONGEST
model [Forster et al. FOCS 2021, Anagnostides et al. DISC 2022] with a CONGEST
implementation of the LP solver of Lee and Sidford [FOCS 2014], and finally
show that we can round the approximate solution to an exact solution. Our
algorithm solves certain linear programs, that generalize minimum cost flow, up
to additive error $\epsilon$ in $n^{1/2+o(1)}(\sqrt{n}+D)\log^3 (1/\epsilon)$
rounds.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01623'>Algorithms for the Generalized Poset Sorting Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shaofeng H.-C. Jiang, Wenqian Wang, Yubo Zhang, Yuhao Zhang</p><p>We consider a generalized poset sorting problem (GPS), in which we are given
a query graph $G = (V, E)$ and an unknown poset $\mathcal{P}(V, \prec)$ that is
defined on the same vertex set $V$, and the goal is to make as few queries as
possible to edges in $G$ in order to fully recover $\mathcal{P}$, where each
query $(u, v)$ returns the relation between $u, v$, i.e., $u \prec v$, $v \prec
u$ or $u \not \sim v$. This generalizes both the poset sorting problem [Faigle
et al., SICOMP 88] and the generalized sorting problem [Huang et al., FOCS 11].
</p>
<p>We give algorithms with $\tilde{O}(n\cdot \mathrm{poly}(k))$ query complexity
when $G$ is a complete bipartite graph or $G$ is stochastic under the \ER
model, where $k$ is the \emph{width} of the poset, and these generalize
[Daskalakis et al., SICOMP 11] which only studies complete graph $G$. Both
results are based on a unified framework that reduces the poset sorting to
partitioning the vertices with respect to a given pivot element, which may be
of independent interest.
</p>
<p>Our study of GPS also leads to a new $\tilde{O}(n^{1 - 1 / (2W)})$
competitive ratio for the so-called weighted generalized sorting problem where
$W$ is the number of distinct weights in the query graph. This problem was
considered as an open question in [Charikar et al., JCSS 02], and our result
makes important progress as it yields the first nontrivial $\tilde{O}(n)$ ratio
for general weighted query graphs (and better ratio if $W$ is bounded). We
obtain this via an $\tilde{O}(nk + n^{1.5})$ query complexity algorithm for the
case where every edge in $G$ is guaranteed to be comparable in the poset, which
generalizes the state-of-the-art $\tilde{O}(n^{1.5})$ bound for generalized
sorting [Huang et al., FOCS 11].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shaofeng H.-C. Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenqian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yubo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuhao Zhang</a></p><p>We consider a generalized poset sorting problem (GPS), in which we are given
a query graph $G = (V, E)$ and an unknown poset $\mathcal{P}(V, \prec)$ that is
defined on the same vertex set $V$, and the goal is to make as few queries as
possible to edges in $G$ in order to fully recover $\mathcal{P}$, where each
query $(u, v)$ returns the relation between $u, v$, i.e., $u \prec v$, $v \prec
u$ or $u \not \sim v$. This generalizes both the poset sorting problem [Faigle
et al., SICOMP 88] and the generalized sorting problem [Huang et al., FOCS 11].
</p>
<p>We give algorithms with $\tilde{O}(n\cdot \mathrm{poly}(k))$ query complexity
when $G$ is a complete bipartite graph or $G$ is stochastic under the \ER
model, where $k$ is the \emph{width} of the poset, and these generalize
[Daskalakis et al., SICOMP 11] which only studies complete graph $G$. Both
results are based on a unified framework that reduces the poset sorting to
partitioning the vertices with respect to a given pivot element, which may be
of independent interest.
</p>
<p>Our study of GPS also leads to a new $\tilde{O}(n^{1 - 1 / (2W)})$
competitive ratio for the so-called weighted generalized sorting problem where
$W$ is the number of distinct weights in the query graph. This problem was
considered as an open question in [Charikar et al., JCSS 02], and our result
makes important progress as it yields the first nontrivial $\tilde{O}(n)$ ratio
for general weighted query graphs (and better ratio if $W$ is bounded). We
obtain this via an $\tilde{O}(nk + n^{1.5})$ query complexity algorithm for the
case where every edge in $G$ is guaranteed to be comparable in the poset, which
generalizes the state-of-the-art $\tilde{O}(n^{1.5})$ bound for generalized
sorting [Huang et al., FOCS 11].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01744'>Dynamic treewidth</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tuukka Korhonen, Konrad Majewski, Wojciech Nadara, Micha&#x142; Pilipczuk, Marek Soko&#x142;owski</p><p>We present a data structure that for a dynamic graph $G$ that is updated by
edge insertions and deletions, maintains a tree decomposition of $G$ of width
at most $6k+5$ under the promise that the treewidth of $G$ never grows above
$k$. The amortized update time is ${\cal O}_k(2^{\sqrt{\log n}\log\log n})$,
where $n$ is the vertex count of $G$ and the ${\cal O}_k(\cdot)$ notation hides
factors depending on $k$. In addition, we also obtain the dynamic variant of
Courcelle's Theorem: for any fixed property $\varphi$ expressible in the
$\mathsf{CMSO}_2$ logic, the data structure can maintain whether $G$ satisfies
$\varphi$ within the same time complexity bounds. To a large extent, this
answers a question posed by Bodlaender [WG 1993].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Korhonen_T/0/1/0/all/0/1">Tuukka Korhonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Majewski_K/0/1/0/all/0/1">Konrad Majewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadara_W/0/1/0/all/0/1">Wojciech Nadara</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Micha&#x142; Pilipczuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokolowski_M/0/1/0/all/0/1">Marek Soko&#x142;owski</a></p><p>We present a data structure that for a dynamic graph $G$ that is updated by
edge insertions and deletions, maintains a tree decomposition of $G$ of width
at most $6k+5$ under the promise that the treewidth of $G$ never grows above
$k$. The amortized update time is ${\cal O}_k(2^{\sqrt{\log n}\log\log n})$,
where $n$ is the vertex count of $G$ and the ${\cal O}_k(\cdot)$ notation hides
factors depending on $k$. In addition, we also obtain the dynamic variant of
Courcelle's Theorem: for any fixed property $\varphi$ expressible in the
$\mathsf{CMSO}_2$ logic, the data structure can maintain whether $G$ satisfies
$\varphi$ within the same time complexity bounds. To a large extent, this
answers a question posed by Bodlaender [WG 1993].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01781'>Mixing predictions for online metric algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Antonios Antoniadis, Christian Coester, Marek Eli&#xe1;&#x161;, Adam Polak, Bertrand Simon</p><p>A major technique in learning-augmented online algorithms is combining
multiple algorithms or predictors. Since the performance of each predictor may
vary over time, it is desirable to use not the single best predictor as a
benchmark, but rather a dynamic combination which follows different predictors
at different times. We design algorithms that combine predictions and are
competitive against such dynamic combinations for a wide class of online
problems, namely, metrical task systems. Against the best (in hindsight)
unconstrained combination of $\ell$ predictors, we obtain a competitive ratio
of $O(\ell^2)$, and show that this is best possible. However, for a benchmark
with slightly constrained number of switches between different predictors, we
can get a $(1+\epsilon)$-competitive algorithm. Moreover, our algorithms can be
adapted to access predictors in a bandit-like fashion, querying only one
predictor at a time. An unexpected implication of one of our lower bounds is a
new structural insight about covering formulations for the $k$-server problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Antoniadis_A/0/1/0/all/0/1">Antonios Antoniadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Coester_C/0/1/0/all/0/1">Christian Coester</a>, <a href="http://arxiv.org/find/cs/1/au:+Elias_M/0/1/0/all/0/1">Marek Eli&#xe1;&#x161;</a>, <a href="http://arxiv.org/find/cs/1/au:+Polak_A/0/1/0/all/0/1">Adam Polak</a>, <a href="http://arxiv.org/find/cs/1/au:+Simon_B/0/1/0/all/0/1">Bertrand Simon</a></p><p>A major technique in learning-augmented online algorithms is combining
multiple algorithms or predictors. Since the performance of each predictor may
vary over time, it is desirable to use not the single best predictor as a
benchmark, but rather a dynamic combination which follows different predictors
at different times. We design algorithms that combine predictions and are
competitive against such dynamic combinations for a wide class of online
problems, namely, metrical task systems. Against the best (in hindsight)
unconstrained combination of $\ell$ predictors, we obtain a competitive ratio
of $O(\ell^2)$, and show that this is best possible. However, for a benchmark
with slightly constrained number of switches between different predictors, we
can get a $(1+\epsilon)$-competitive algorithm. Moreover, our algorithms can be
adapted to access predictors in a bandit-like fashion, querying only one
predictor at a time. An unexpected implication of one of our lower bounds is a
new structural insight about covering formulations for the $k$-server problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01790'>VC Set Systems in Minor-free (Di)Graphs and Applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hung Le, Christian Wulff-Nilsen</p><p>A recent line of work on VC set systems in minor-free (undirected) graphs,
starting from Li and Parter, who constructed a new VC set system for planar
graphs, has given surprising algorithmic results. In this work, we initialize a
more systematic study of VC set systems for minor-free graphs and their
applications in both undirected graphs and directed graphs (a.k.a digraphs).
More precisely:
</p>
<p>- We propose a new variant of Li-Parter set system for undirected graphs.
</p>
<p>- We extend our set system to $K_h$-minor-free digraphs and show that its VC
dimension is $O(h^2)$.
</p>
<p>- We show that the system of directed balls in minor-free digraphs has VC
dimension at most $h-1$.
</p>
<p>- On the negative side, we show that VC set system constructed from shortest
path trees of planar digraphs does not have a bounded VC dimension.
</p>
<p>The highlight of our work is the results for digraphs, as we are not aware of
known algorithmic work on constructing and exploiting VC set systems for
digraphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Hung Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Wulff_Nilsen_C/0/1/0/all/0/1">Christian Wulff-Nilsen</a></p><p>A recent line of work on VC set systems in minor-free (undirected) graphs,
starting from Li and Parter, who constructed a new VC set system for planar
graphs, has given surprising algorithmic results. In this work, we initialize a
more systematic study of VC set systems for minor-free graphs and their
applications in both undirected graphs and directed graphs (a.k.a digraphs).
More precisely:
</p>
<p>- We propose a new variant of Li-Parter set system for undirected graphs.
</p>
<p>- We extend our set system to $K_h$-minor-free digraphs and show that its VC
dimension is $O(h^2)$.
</p>
<p>- We show that the system of directed balls in minor-free digraphs has VC
dimension at most $h-1$.
</p>
<p>- On the negative side, we show that VC set system constructed from shortest
path trees of planar digraphs does not have a bounded VC dimension.
</p>
<p>The highlight of our work is the results for digraphs, as we are not aware of
known algorithmic work on constructing and exploiting VC set systems for
digraphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01806'>Connected and Autonomous Vehicle Scheduling Problems: Some Models and Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Evgeny R. Gafarov, Frank Werner</p><p>In this paper, we consider scheduling problems that arise in connected and
autonomous vehicle systems. For four variants of such problems, mathematical
models and solution algorithms are presented. In particular, three polynomial
algorithms and a branch and bound algorithms are developed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gafarov_E/0/1/0/all/0/1">Evgeny R. Gafarov</a>, <a href="http://arxiv.org/find/math/1/au:+Werner_F/0/1/0/all/0/1">Frank Werner</a></p><p>In this paper, we consider scheduling problems that arise in connected and
autonomous vehicle systems. For four variants of such problems, mathematical
models and solution algorithms are presented. In particular, three polynomial
algorithms and a branch and bound algorithms are developed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01889'>Chasing Positive Bodies</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sayan Bhattacharya, Niv Buchbinder, Roie Levin, Thatchaphol Saranurak</p><p>We study the problem of chasing positive bodies in $\ell_1$: given a sequence
of bodies $K_{t}=\{x^{t}\in\mathbb{R}_{+}^{n}\mid C^{t}x^{t}\geq
1,P^{t}x^{t}\leq 1\}$ revealed online, where $C^{t}$ and $P^{t}$ are
nonnegative matrices, the goal is to (approximately) maintain a point $x_t \in
K_t$ such that $\sum_t \|x_t - x_{t-1}\|_1$ is minimized. This captures the
fully-dynamic low-recourse variant of any problem that can be expressed as a
mixed packing-covering linear program and thus also the fractional version of
many central problems in dynamic algorithms such as set cover, load balancing,
hyperedge orientation, minimum spanning tree, and matching.
</p>
<p>We give an $O(\log d)$-competitive algorithm for this problem, where $d$ is
the maximum row sparsity of any matrix $C^t$. This bypasses and improves
exponentially over the lower bound of $\sqrt{n}$ known for general convex
bodies. Our algorithm is based on iterated information projections, and, in
contrast to general convex body chasing algorithms, is entirely memoryless.
</p>
<p>We also show how to round our solution dynamically to obtain the first fully
dynamic algorithms with competitive recourse for all the stated problems above;
i.e. their recourse is less than the recourse of every other algorithm on every
update sequence, up to polylogarithmic factors. This is a significantly
stronger notion than the notion of absolute recourse in the dynamic algorithms
literature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1">Sayan Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Buchbinder_N/0/1/0/all/0/1">Niv Buchbinder</a>, <a href="http://arxiv.org/find/cs/1/au:+Levin_R/0/1/0/all/0/1">Roie Levin</a>, <a href="http://arxiv.org/find/cs/1/au:+Saranurak_T/0/1/0/all/0/1">Thatchaphol Saranurak</a></p><p>We study the problem of chasing positive bodies in $\ell_1$: given a sequence
of bodies $K_{t}=\{x^{t}\in\mathbb{R}_{+}^{n}\mid C^{t}x^{t}\geq
1,P^{t}x^{t}\leq 1\}$ revealed online, where $C^{t}$ and $P^{t}$ are
nonnegative matrices, the goal is to (approximately) maintain a point $x_t \in
K_t$ such that $\sum_t \|x_t - x_{t-1}\|_1$ is minimized. This captures the
fully-dynamic low-recourse variant of any problem that can be expressed as a
mixed packing-covering linear program and thus also the fractional version of
many central problems in dynamic algorithms such as set cover, load balancing,
hyperedge orientation, minimum spanning tree, and matching.
</p>
<p>We give an $O(\log d)$-competitive algorithm for this problem, where $d$ is
the maximum row sparsity of any matrix $C^t$. This bypasses and improves
exponentially over the lower bound of $\sqrt{n}$ known for general convex
bodies. Our algorithm is based on iterated information projections, and, in
contrast to general convex body chasing algorithms, is entirely memoryless.
</p>
<p>We also show how to round our solution dynamically to obtain the first fully
dynamic algorithms with competitive recourse for all the stated problems above;
i.e. their recourse is less than the recourse of every other algorithm on every
update sequence, up to polylogarithmic factors. This is a significantly
stronger notion than the notion of absolute recourse in the dynamic algorithms
literature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01954'>Strong spatial mixing for colorings on trees and its algorithmic applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zongchen Chen, Kuikui Liu, Nitya Mani, Ankur Moitra</p><p>Strong spatial mixing (SSM) is an important quantitative notion of
correlation decay for Gibbs distributions arising in statistical physics,
probability theory, and theoretical computer science. A longstanding conjecture
is that the uniform distribution on proper $q$-colorings on a $\Delta$-regular
tree exhibits SSM whenever $q \ge \Delta+1$. Moreover, it is widely believed
that as long as SSM holds on bounded-degree trees with $q$ colors, one would
obtain an efficient sampler for $q$-colorings on all bounded-degree graphs via
simple Markov chain algorithms. It is surprising that such a basic question is
still open, even on trees, but then again it also highlights how much we still
have to learn about random colorings. In this paper, we show the following:
</p>
<p>(1) For any $\Delta \ge 3$, SSM holds for random $q$-colorings on trees of
maximum degree $\Delta$ whenever $q \ge \Delta + 3$. Thus we almost fully
resolve the aforementioned conjecture. Our result substantially improves upon
the previously best bound which requires $q \ge 1.59\Delta+\gamma^*$ for an
absolute constant $\gamma^* &gt; 0$.
</p>
<p>(2) For any $\Delta\ge 3$ and girth $g = \Omega_\Delta(1)$, we establish
optimal mixing of the Glauber dynamics for $q$-colorings on graphs of maximum
degree $\Delta$ and girth $g$ whenever $q \ge \Delta+3$. Our approach is based
on a new general reduction from spectral independence on large-girth graphs to
SSM on trees that is of independent interest.
</p>
<p>Using the same techniques, we also prove near-optimal bounds on weak spatial
mixing (WSM), a closely-related notion to SSM, for the antiferromagnetic Potts
model on trees.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zongchen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kuikui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mani_N/0/1/0/all/0/1">Nitya Mani</a>, <a href="http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1">Ankur Moitra</a></p><p>Strong spatial mixing (SSM) is an important quantitative notion of
correlation decay for Gibbs distributions arising in statistical physics,
probability theory, and theoretical computer science. A longstanding conjecture
is that the uniform distribution on proper $q$-colorings on a $\Delta$-regular
tree exhibits SSM whenever $q \ge \Delta+1$. Moreover, it is widely believed
that as long as SSM holds on bounded-degree trees with $q$ colors, one would
obtain an efficient sampler for $q$-colorings on all bounded-degree graphs via
simple Markov chain algorithms. It is surprising that such a basic question is
still open, even on trees, but then again it also highlights how much we still
have to learn about random colorings. In this paper, we show the following:
</p>
<p>(1) For any $\Delta \ge 3$, SSM holds for random $q$-colorings on trees of
maximum degree $\Delta$ whenever $q \ge \Delta + 3$. Thus we almost fully
resolve the aforementioned conjecture. Our result substantially improves upon
the previously best bound which requires $q \ge 1.59\Delta+\gamma^*$ for an
absolute constant $\gamma^* &gt; 0$.
</p>
<p>(2) For any $\Delta\ge 3$ and girth $g = \Omega_\Delta(1)$, we establish
optimal mixing of the Glauber dynamics for $q$-colorings on graphs of maximum
degree $\Delta$ and girth $g$ whenever $q \ge \Delta+3$. Our approach is based
on a new general reduction from spectral independence on large-girth graphs to
SSM on trees that is of independent interest.
</p>
<p>Using the same techniques, we also prove near-optimal bounds on weak spatial
mixing (WSM), a closely-related notion to SSM, for the antiferromagnetic Potts
model on trees.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.01958'>Online Time-Windows TSP with Predictions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shuchi Chawla, Dimitris Christou</p><p>In the Time-Windows TSP (TW-TSP) we are given requests at different locations
on a network; each request is endowed with a reward and an interval of time;
the goal is to find a tour that visits as much reward as possible during the
corresponding time window. For the online version of this problem, where each
request is revealed at the start of its time window, no finite competitive
ratio can be obtained. We consider a version of the problem where the algorithm
is presented with predictions of where and when the online requests will
appear, without any knowledge of the quality of this side information.
</p>
<p>Vehicle routing problems such as the TW-TSP can be very sensitive to errors
or changes in the input due to the hard time-window constraints, and it is
unclear whether imperfect predictions can be used to obtain a finite
competitive ratio. We show that good performance can be achieved by explicitly
building slack into the solution. Our main result is an online algorithm that
achieves a competitive ratio logarithmic in the diameter of the underlying
network, matching the performance of the best offline algorithm to within
factors that depend on the quality of the provided predictions. The competitive
ratio degrades smoothly as a function of the quality and we show that this
dependence is tight within constant factors.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chawla_S/0/1/0/all/0/1">Shuchi Chawla</a>, <a href="http://arxiv.org/find/cs/1/au:+Christou_D/0/1/0/all/0/1">Dimitris Christou</a></p><p>In the Time-Windows TSP (TW-TSP) we are given requests at different locations
on a network; each request is endowed with a reward and an interval of time;
the goal is to find a tour that visits as much reward as possible during the
corresponding time window. For the online version of this problem, where each
request is revealed at the start of its time window, no finite competitive
ratio can be obtained. We consider a version of the problem where the algorithm
is presented with predictions of where and when the online requests will
appear, without any knowledge of the quality of this side information.
</p>
<p>Vehicle routing problems such as the TW-TSP can be very sensitive to errors
or changes in the input due to the hard time-window constraints, and it is
unclear whether imperfect predictions can be used to obtain a finite
competitive ratio. We show that good performance can be achieved by explicitly
building slack into the solution. Our main result is an online algorithm that
achieves a competitive ratio logarithmic in the diameter of the underlying
network, matching the performance of the best offline algorithm to within
factors that depend on the quality of the provided predictions. The competitive
ratio degrades smoothly as a function of the quality and we show that this
dependence is tight within constant factors.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-05T00:30:00Z">Wednesday, April 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, April 04
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/04/neil-jones-1941-2023.html'>Neil Jones (1941-2023)</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p></p>♦Eric Allender graciously agreed to write this remembrance of Neil Jones.<br><p></p><p>Neil Jones passed away on March 27.</p><p>Neil's work had a profound impact on the field of computational complexity theory, although he was primarily known for his work in other areas of computer science.&nbsp; For example, his 1998 ACM Fellow citation is "For outstanding contributions to semantics-directed compilation, especially partial evaluation, and to the theory of computation, formal models and their practical realization."&nbsp; Note that there's no mention of "complexity" (except as it is bundled together with "theory of computation" -- and Jones also published in the area of computability theory).</p><p>So what were some ways that Neil influenced the development of computational complexity theory?</p><p>In 1972, in the 4th STOC conference, Neil collaborated with Alan Selman, to show that a notion that logicians had been studying since the 1950's coincided exactly with a natural complexity class.&nbsp; More specifically, given a logical formula F, the "spectrum" of F is the set of numbers {n : F has a finite model of size n}.&nbsp; What kinds of sets can be the spectrum of a first-order formula?&nbsp; Is this class of sets closed under complement?&nbsp; These were some of the questions that logicians had struggled with.&nbsp; Jones and Selman gave a precise characterization, as NE (nondeterministic exponential time).&nbsp; Thus the complement of every spectrum is a spectrum if and only if NE=coNE.&nbsp; As D. Sivakumar points out in a LinkedIn comment on Neil's death: "The following year, Fagin proved that generalized spectra coincide with NP, and descriptive complexity theory was born."</p><p>Of course, a lot of other things were happening in the late 60's and early 70's:&nbsp; Savitch proved Savitch's Theorem.&nbsp; The first NP-completeness results appeared.&nbsp; It appears that several people were trying to build on Savitch's theorem, to show that everything in P can be done in log2 space, and this motivated Steve Cook to define a problem ("Path Systems") and show (1) certain algorithms for Path Systems could not be implemented in small space, and (2) Path Systems has a small-space algorithm iff everything in P does.&nbsp; This result of Cook's was similar in flavor to a theorem of Savitch, showing that a problem he called "Threadable Mazes" was in L if and only if NL=L.&nbsp; Although these notions were clearly in the air, Jones (and -- simultaneously -- Meyer &amp; Stockmeyer) were the first to explicitly formalize the notion of logspace reducibility (including closure under composition), and to notice that the NP-completeness results of Cook and Karp held also under logspace reducibility.&nbsp; And Jones was the first one to go ahead and develop the general theory of logspace reducibility and the theory of completeness for subclasses of P (first for P itself (with Laaser), and later for NL (with Laaser and Lien)).&nbsp; I think that this is when people started to get the idea that completeness was not a special property that only a few problems shared.&nbsp; Rather: Nearly EVERY natural computational problem was likely to be complete for some reasonable complexity class.</p><p>Notably, Jones also recognized that logspace was overkill, when considering reductions.&nbsp; He also wanted to have a really restricted notion of reducibility, so that one could talk meaningfully about problems being complete for L.&nbsp; To this end, he defined "log-rudimentary" reducibility.&nbsp; This was quite natural for him, since he had work previously on Smullyan's "Rudimentary Relations".&nbsp; But log-rudimentary reductions never really caught on.&nbsp; Instead, after Furst, Saxe, and Sipser kickstarted the study of AC0 circuits, a notion of AC0 reducibility was developed by Chandra, Stockmeyer, and Vishkin in the mid-1980's, which turned out to be very useful in classifying problems as being complete in various subclasses of P.&nbsp; Much later, in 1991, I published a paper with Vivek Gore, showing that Neil's log-rudimentary reductions are precisely the same thing as uniform AC0 reducibility.&nbsp; Thus Neil Jones had the insight to define and study a notion that would not become mainstream for another decade, and which still provides the best tool for classifying the complexity of natural problems in subclasses of P.</p><p>I only had the pleasure of meeting Neil once, during a visit to Copenhagen in 2004, although we would occasionally exchange some e-mail about topics in complexity.&nbsp; It is interesting to note that the most recent paper on Neil's DBLP page deals with complexity classes.&nbsp; I haven't spent much time looking at the paper, but I do see that the authors define a complexity class that lies between NL and P.&nbsp; It might be interesting to see if this class coincides with SAC1 (also known as LogCFL).</p><p>I thank Lance and Bill for encouraging me to write a few lines about Neil's importance to the field.&nbsp;</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p></p><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvZYTofhc2zPgPq7_2CuI3JUbXlbSvpWL3xla-H8c4gpWz_wXGCjQQLGt3sNl3XP0E5PZ4qIzpnwddhMX1FzqbzTnicWf_oROVBk6TEzBq7novIBCrqlQ1-qj_KNB0LqJGeM6TXNGzx8yoFR4UyDOqme79mlKdSRpbGJrA0G-L_1m8nJF-1w/s885/Neil_D._Jones.jpg" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" data-original-height="885" data-original-width="657" height="200" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvZYTofhc2zPgPq7_2CuI3JUbXlbSvpWL3xla-H8c4gpWz_wXGCjQQLGt3sNl3XP0E5PZ4qIzpnwddhMX1FzqbzTnicWf_oROVBk6TEzBq7novIBCrqlQ1-qj_KNB0LqJGeM6TXNGzx8yoFR4UyDOqme79mlKdSRpbGJrA0G-L_1m8nJF-1w/w149-h200/Neil_D._Jones.jpg" width="149" /></a></div><i>Eric Allender graciously agreed to write this remembrance of Neil Jones.<br /></i><p></p><p><a href="https://en.wikipedia.org/wiki/Neil_D._Jones">Neil Jones</a> passed away on March 27.</p><p>Neil's work had a profound impact on the field of computational complexity theory, although he was primarily known for his work in other areas of computer science.&nbsp; For example, his 1998 ACM Fellow citation is "For outstanding contributions to semantics-directed compilation, especially partial evaluation, and to the theory of computation, formal models and their practical realization."&nbsp; Note that there's no mention of "complexity" (except as it is bundled together with "theory of computation" -- and Jones also published in the area of computability theory).</p><p>So what were some ways that Neil influenced the development of computational complexity theory?</p><p>In 1972, in the 4th STOC conference, Neil <a href="https://doi.org/10.1145/800152.804909">collaborated</a> with Alan Selman, to show that a notion that logicians had been studying since the 1950's coincided exactly with a natural complexity class.&nbsp; More specifically, given a logical formula F, the "spectrum" of F is the set of numbers {n : F has a finite model of size n}.&nbsp; What kinds of sets can be the spectrum of a first-order formula?&nbsp; Is this class of sets closed under complement?&nbsp; These were some of the questions that logicians had struggled with.&nbsp; Jones and Selman gave a precise characterization, as NE (nondeterministic exponential time).&nbsp; Thus the complement of every spectrum is a spectrum if and only if NE=coNE.&nbsp; As D. Sivakumar points out in a <a href="https://www.linkedin.com/feed/update/urn:li:activity:7047571379897921536?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7047571379897921536%2C7048828674200006656%29&amp;replyUrn=urn%3Ali%3Acomment%3A%28activity%3A7047571379897921536%2C7048876431841378304%29">LinkedIn comment</a> on Neil's death: "The following year, Fagin proved that generalized spectra coincide with NP, and descriptive complexity theory was born."</p><p>Of course, a lot of other things were happening in the late 60's and early 70's:&nbsp; Savitch proved Savitch's Theorem.&nbsp; The first NP-completeness results appeared.&nbsp; It appears that several people were trying to build on Savitch's theorem, to show that everything in P can be done in log<sup>2</sup> space, and this motivated Steve Cook to define a problem ("Path Systems") and show (1) certain algorithms for Path Systems could not be implemented in small space, and (2) Path Systems has a small-space algorithm iff everything in P does.&nbsp; This result of Cook's was similar in flavor to a theorem of Savitch, showing that a problem he called "Threadable Mazes" was in L if and only if NL=L.&nbsp; Although these notions were clearly in the air, Jones (and -- simultaneously -- Meyer &amp; Stockmeyer) were the first to explicitly formalize the notion of logspace reducibility (including closure under composition), and to notice that the NP-completeness results of Cook and Karp held also under logspace reducibility.&nbsp; And Jones was the first one to go ahead and develop the general theory of logspace reducibility and the theory of completeness for subclasses of P (first for P itself (with Laaser), and later for NL (with Laaser and Lien)).&nbsp; I think that this is when people started to get the idea that completeness was not a special property that only a few problems shared.&nbsp; Rather: Nearly EVERY natural computational problem was likely to be complete for some reasonable complexity class.</p><p>Notably, Jones also recognized that logspace was overkill, when considering reductions.&nbsp; He also wanted to have a really restricted notion of reducibility, so that one could talk meaningfully about problems being complete for L.&nbsp; To this end, he <a href="https://doi.org/10.1016/S0022-0000(75)80050-X">defined</a> "log-rudimentary" reducibility.&nbsp; This was quite natural for him, since he had work previously on Smullyan's "Rudimentary Relations".&nbsp; But log-rudimentary reductions never really caught on.&nbsp; Instead, after Furst, Saxe, and Sipser kickstarted the study of AC<sup>0</sup> circuits, a notion of AC<sup>0</sup> reducibility was developed by Chandra, Stockmeyer, and Vishkin in the mid-1980's, which turned out to be very useful in classifying problems as being complete in various subclasses of P.&nbsp; Much later, in 1991, I published a <a href="https://doi.org/10.1016/0020-0190(91)90015-A">paper</a> with Vivek Gore, showing that Neil's log-rudimentary reductions are precisely the same thing as uniform AC<sup>0</sup> reducibility.&nbsp; Thus Neil Jones had the insight to define and study a notion that would not become mainstream for another decade, and which still provides the best tool for classifying the complexity of natural problems in subclasses of P.</p><p>I only had the pleasure of meeting Neil once, during a visit to Copenhagen in 2004, although we would occasionally exchange some e-mail about topics in complexity.&nbsp; It is interesting to note that the most <a href="https://doi.org/10.48550/arXiv.2008.02932">recent paper</a> on Neil's <a href="https://dblp.org/pid/j/NeilDJones.html">DBLP page</a> deals with complexity classes.&nbsp; I haven't spent much time looking at the paper, but I do see that the authors define a complexity class that lies between NL and P.&nbsp; It might be interesting to see if this class coincides with SAC<sup>1</sup> (also known as LogCFL).</p><p>I thank Lance and Bill for encouraging me to write a few lines about Neil's importance to the field.&nbsp;</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-04T19:05:00Z">Tuesday, April 04 2023, 19:05</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.00391'>The communication complexity of functions with large outputs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lila Fontes, Sophie Laplante, Mathieu Lauriere, Alexandre Nolin</p><p>We study the two-party communication complexity of functions with large
outputs, and show that the communication complexity can greatly vary depending
on what output model is considered. We study a variety of output models,
ranging from the open model, in which an external observer can compute the
outcome, to the XOR model, in which the outcome of the protocol should be the
bitwise XOR of the players' local outputs. This model is inspired by XOR games,
which are widely studied two-player quantum games. We focus on the question of
error-reduction in these new output models. For functions of output size k,
applying standard error reduction techniques in the XOR model would introduce
an additional cost linear in k. We show that no dependency on k is necessary.
Similarly, standard randomness removal techniques, incur a multiplicative cost
of $2^k$ in the XOR model. We show how to reduce this factor to O(k). In
addition, we prove analogous error reduction and randomness removal results in
the other models, separate all models from each other, and show that some
natural problems, including Set Intersection and Find the First Difference,
separate the models when the Hamming weights of their inputs is bounded.
Finally, we show how to use the rank lower bound technique for our weak output
models.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fontes_L/0/1/0/all/0/1">Lila Fontes</a>, <a href="http://arxiv.org/find/cs/1/au:+Laplante_S/0/1/0/all/0/1">Sophie Laplante</a>, <a href="http://arxiv.org/find/cs/1/au:+Lauriere_M/0/1/0/all/0/1">Mathieu Lauriere</a>, <a href="http://arxiv.org/find/cs/1/au:+Nolin_A/0/1/0/all/0/1">Alexandre Nolin</a></p><p>We study the two-party communication complexity of functions with large
outputs, and show that the communication complexity can greatly vary depending
on what output model is considered. We study a variety of output models,
ranging from the open model, in which an external observer can compute the
outcome, to the XOR model, in which the outcome of the protocol should be the
bitwise XOR of the players' local outputs. This model is inspired by XOR games,
which are widely studied two-player quantum games. We focus on the question of
error-reduction in these new output models. For functions of output size k,
applying standard error reduction techniques in the XOR model would introduce
an additional cost linear in k. We show that no dependency on k is necessary.
Similarly, standard randomness removal techniques, incur a multiplicative cost
of $2^k$ in the XOR model. We show how to reduce this factor to O(k). In
addition, we prove analogous error reduction and randomness removal results in
the other models, separate all models from each other, and show that some
natural problems, including Set Intersection and Find the First Difference,
separate the models when the Hamming weights of their inputs is bounded.
Finally, we show how to use the rank lower bound technique for our weak output
models.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-04T00:30:00Z">Tuesday, April 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.00430'>Gallai-like characterization of strong cocomparability graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jing Huang</p><p>Strong cocomparability graphs are the reflexive graphs whose adjacency matrix
can be rearranged by a simultaneous row and column permutation to avoid the
submatrix with rows $01, 10$. Strong cocomparability graphs form a subclass of
cocomparability graphs (i.e., the complements of comparability graphs) and can
be recognized in polynomial time. In his seminal paper, Gallai characterized
cocomparability graphs in terms of a forbidden structure called asteroids.
Gallai proved that cocomparability graphs are precisely those reflexive graphs
which do not contain asteroids.
</p>
<p>In this paper, we give a characterization of strong cocomparability graphs
which is analogous to Gallai's characterization for cocomparability graphs. We
prove that strong cocomparability graphs are precisely those reflexive graphs
which do not contain weak edge-asteroids (a weaker version of asteroids). Our
characterization also leads to a polynomial time recognition algorithm for
strong cocomparability graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Huang_J/0/1/0/all/0/1">Jing Huang</a></p><p>Strong cocomparability graphs are the reflexive graphs whose adjacency matrix
can be rearranged by a simultaneous row and column permutation to avoid the
submatrix with rows $01, 10$. Strong cocomparability graphs form a subclass of
cocomparability graphs (i.e., the complements of comparability graphs) and can
be recognized in polynomial time. In his seminal paper, Gallai characterized
cocomparability graphs in terms of a forbidden structure called asteroids.
Gallai proved that cocomparability graphs are precisely those reflexive graphs
which do not contain asteroids.
</p>
<p>In this paper, we give a characterization of strong cocomparability graphs
which is analogous to Gallai's characterization for cocomparability graphs. We
prove that strong cocomparability graphs are precisely those reflexive graphs
which do not contain weak edge-asteroids (a weaker version of asteroids). Our
characterization also leads to a polynomial time recognition algorithm for
strong cocomparability graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-04T00:30:00Z">Tuesday, April 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.00051'>Almost Linear Constant-Factor Sketching for $\ell_1$ and Logistic Regression</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Munteanu, Simon Omlor, David Woodruff</p><p>We improve upon previous oblivious sketching and turnstile streaming results
for $\ell_1$ and logistic regression, giving a much smaller sketching dimension
achieving $O(1)$-approximation and yielding an efficient optimization problem
in the sketch space. Namely, we achieve for any constant $c&gt;0$ a sketching
dimension of $\tilde{O}(d^{1+c})$ for $\ell_1$ regression and $\tilde{O}(\mu
d^{1+c})$ for logistic regression, where $\mu$ is a standard measure that
captures the complexity of compressing the data. For $\ell_1$-regression our
sketching dimension is near-linear and improves previous work which either
required $\Omega(\log d)$-approximation with this sketching dimension, or
required a larger $\operatorname{poly}(d)$ number of rows. Similarly, for
logistic regression previous work had worse $\operatorname{poly}(\mu d)$
factors in its sketching dimension. We also give a tradeoff that yields a
$1+\varepsilon$ approximation in input sparsity time by increasing the total
size to $(d\log(n)/\varepsilon)^{O(1/\varepsilon)}$ for $\ell_1$ and to $(\mu
d\log(n)/\varepsilon)^{O(1/\varepsilon)}$ for logistic regression. Finally, we
show that our sketch can be extended to approximate a regularized version of
logistic regression where the data-dependent regularizer corresponds to the
variance of the individual logistic losses.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Munteanu_A/0/1/0/all/0/1">Alexander Munteanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Omlor_S/0/1/0/all/0/1">Simon Omlor</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David Woodruff</a></p><p>We improve upon previous oblivious sketching and turnstile streaming results
for $\ell_1$ and logistic regression, giving a much smaller sketching dimension
achieving $O(1)$-approximation and yielding an efficient optimization problem
in the sketch space. Namely, we achieve for any constant $c&gt;0$ a sketching
dimension of $\tilde{O}(d^{1+c})$ for $\ell_1$ regression and $\tilde{O}(\mu
d^{1+c})$ for logistic regression, where $\mu$ is a standard measure that
captures the complexity of compressing the data. For $\ell_1$-regression our
sketching dimension is near-linear and improves previous work which either
required $\Omega(\log d)$-approximation with this sketching dimension, or
required a larger $\operatorname{poly}(d)$ number of rows. Similarly, for
logistic regression previous work had worse $\operatorname{poly}(\mu d)$
factors in its sketching dimension. We also give a tradeoff that yields a
$1+\varepsilon$ approximation in input sparsity time by increasing the total
size to $(d\log(n)/\varepsilon)^{O(1/\varepsilon)}$ for $\ell_1$ and to $(\mu
d\log(n)/\varepsilon)^{O(1/\varepsilon)}$ for logistic regression. Finally, we
show that our sketch can be extended to approximate a regularized version of
logistic regression where the data-dependent regularizer corresponds to the
variance of the individual logistic losses.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-04T00:30:00Z">Tuesday, April 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.00419'>Mini-batch $k$-means terminates within $O(d/\epsilon)$ iterations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gregory Schwartzman</p><p>We answer the question: "Does local progress (on batches) imply global
progress (on the entire dataset) for mini-batch $k$-means?". Specifically, we
consider mini-batch $k$-means which terminates only when the improvement in the
quality of the clustering on the sampled batch is below some threshold.
</p>
<p>Although at first glance it appears that this algorithm might execute
forever, we answer the above question in the affirmative and show that if the
batch is of size $\tilde{\Omega}((d/\epsilon)^2)$, it must terminate within
$O(d/\epsilon)$ iterations with high probability, where $d$ is the dimension of
the input, and $\epsilon$ is a threshold parameter for termination. This is
true regardless of how the centers are initialized. When the algorithm is
initialized with the $k$-means++ initialization scheme, it achieves an
approximation ratio of $O(\log k)$ (the same as the full-batch version).
</p>
<p>Finally, we show the applicability of our results to the mini-batch $k$-means
algorithm implemented in the scikit-learn (sklearn) python library.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Schwartzman_G/0/1/0/all/0/1">Gregory Schwartzman</a></p><p>We answer the question: "Does local progress (on batches) imply global
progress (on the entire dataset) for mini-batch $k$-means?". Specifically, we
consider mini-batch $k$-means which terminates only when the improvement in the
quality of the clustering on the sampled batch is below some threshold.
</p>
<p>Although at first glance it appears that this algorithm might execute
forever, we answer the above question in the affirmative and show that if the
batch is of size $\tilde{\Omega}((d/\epsilon)^2)$, it must terminate within
$O(d/\epsilon)$ iterations with high probability, where $d$ is the dimension of
the input, and $\epsilon$ is a threshold parameter for termination. This is
true regardless of how the centers are initialized. When the algorithm is
initialized with the $k$-means++ initialization scheme, it achieves an
approximation ratio of $O(\log k)$ (the same as the full-batch version).
</p>
<p>Finally, we show the applicability of our results to the mini-batch $k$-means
algorithm implemented in the scikit-learn (sklearn) python library.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-04T00:30:00Z">Tuesday, April 04 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, April 03
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/04/03/alef-corner-deep-learning-2020-2030-2040/'>Alef Corner: Deep Learning 2020, 2030, 2040</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Deep learning 2020 Deep learning 2030 Deep learning 2040
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><img data-attachment-id="24112" data-permalink="https://gilkalai.wordpress.com/img-20230228-wa0000/" data-orig-file="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0000.jpg" data-orig-size="1000,1000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IMG-20230228-WA0000" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0000.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0000.jpg?w=640" class="alignnone size-full wp-image-24112" src="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0000.jpg?w=640" alt="IMG-20230228-WA0000" srcset="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0000.jpg?w=640 640w, https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0000.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0000.jpg?w=300 300w, https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0000.jpg?w=768 768w, https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0000.jpg 1000w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p><strong><span style="color: #ff0000">Deep learning 2020</span></strong></p>
<p><img data-attachment-id="24113" data-permalink="https://gilkalai.wordpress.com/2023/04/03/alef-corner-deep-learning-2020-2030-2040/img-20230228-wa0002/" data-orig-file="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0002.jpg" data-orig-size="1000,1000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IMG-20230228-WA0002" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0002.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0002.jpg?w=640" class="alignnone size-full wp-image-24113" src="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0002.jpg?w=640" alt="IMG-20230228-WA0002" srcset="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0002.jpg?w=640 640w, https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0002.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0002.jpg?w=300 300w, https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0002.jpg?w=768 768w, https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0002.jpg 1000w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p><strong><span style="color: #ff0000">Deep learning 2030</span></strong></p>
<p><img data-attachment-id="24115" data-permalink="https://gilkalai.wordpress.com/2023/04/03/alef-corner-deep-learning-2020-2030-2040/img-20230228-wa0001/" data-orig-file="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0001.jpg" data-orig-size="1000,1000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IMG-20230228-WA0001" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0001.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0001.jpg?w=640" class="alignnone size-full wp-image-24115" src="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0001.jpg?w=640" alt="IMG-20230228-WA0001" srcset="https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0001.jpg?w=640 640w, https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0001.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0001.jpg?w=300 300w, https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0001.jpg?w=768 768w, https://gilkalai.files.wordpress.com/2023/04/img-20230228-wa0001.jpg 1000w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p><strong><span style="color: #ff0000">Deep learning 2040</span></strong></p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-03T20:36:02Z">Monday, April 03 2023, 20:36</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/042'>TR23-042 |  On small-depth Frege proofs for PHP | 

	Johan Håstad</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study Frege proofs for the one-to-one graph Pigeon Hole Principle
defined on the $n\times n$ grid where $n$ is odd.
We are interested in the case where each formula
in the proof is a depth $d$ formula in the basis given by
$\land$, $\lor$, and $\neg$.  We prove that in this situation the
proof needs to be of size exponential in $n^{\Omega (1/d)}$.
If we restrict the size of each line in the proof to be of
size $M$ then the number of lines needed is exponential
in $n/(\log M)^{O(d)}$.   The main technical component of
the proofs is to design a new family of random restrictions
and to prove the appropriate switching lemmas.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study Frege proofs for the one-to-one graph Pigeon Hole Principle
defined on the $n\times n$ grid where $n$ is odd.
We are interested in the case where each formula
in the proof is a depth $d$ formula in the basis given by
$\land$, $\lor$, and $\neg$.  We prove that in this situation the
proof needs to be of size exponential in $n^{\Omega (1/d)}$.
If we restrict the size of each line in the proof to be of
size $M$ then the number of lines needed is exponential
in $n/(\log M)^{O(d)}$.   The main technical component of
the proofs is to design a new family of random restrictions
and to prove the appropriate switching lemmas.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-03T11:46:42Z">Monday, April 03 2023, 11:46</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://processalgebra.blogspot.com/2023/04/theoretics-status-update.html'>TheoretiCS: Status update</a></h3>
        <p class='tr-article-feed'>from <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Thomas Schwentick, Meena Mahajan and Pascal Weil (Chair, Secretary and Treasurer of the TheoretiCS Foundation, respectively) sent me the following information on TheoretiCS, which I am happy to share with our community with their permission. I encourage everyone to support the journal by submitting their best work to it!<br></p><p>TheoretiCS was officially launched in 
December 2021 and we wish to present you with the current status of the 
project. You can find more precise information on the journal's site, theoretics-journal.org.<br>
<br>
The first papers were submitted right away in December 2021, and some 
were published in 2022: Volume 1 (2022) has two papers. Volume 2 (2023) 
already has five published papers, more are very near acceptance and 
there is a healthy list of papers under review, with more papers 
submitted every month.<br>
<br>
Our intention was to have a journal that covers the whole of Theoretical
 Computer Science, and this is reflected in the list of published 
papers. We also wanted to have an open-access journal (it operates under
 the so-called diamond open access paradigm, which means that no charges
 are levied to read it, nor to publish in it), and one that involves the
 theoretical computer science community as much as possible. This was 
done by first establishing an Advisory Board, where the majority of the 
members are representatives of many of the most prominent conferences of
 the domain. The Advisory Board selected a pair of remarkable 
Editors-in-Chief (Javier Esparza, TU München, and Uri Zwick, Tel-Aviv 
University) and then worked with the EiCs to assemble a prestigious 
Editorial Board. The Advisory Board continues to meet regularly, with 
the EiCs, to help steer the journal.<br>
<br>
We also wanted to innovate in the reviewing process, streamlining it 
without compromising in any way the quality of the papers — as we are 
aiming to become one of the very top journals in the field. The 
Editorial Board has a so-called Phase 1 process which typically lasts 
between 2 and 3 months, which determines whether the paper is of the 
caliber expected for the journal (quality of the results and quality of 
the exposition, relatively wide interest), under the assumption that the
 proofs are correct. When this Phase 1 concludes positively, Phase 2 
starts, with the objective of verifying the proofs and, possibly, making
 constructive suggestions to the authors as to how to better present 
their results. The result, we hope, is a higher quality for the papers 
published, and also a shorter response time for most of the papers which
 will end up being rejected. As of early 2023, on average, a decision 
for Phase 1 was reached 64 days after submission, within the three-month
 commitment the Editorial Board made. 85% of the papers got a Phase 1 
decision within 94 days.<br>
<br>
TheoretiCS remains a work in progress, though we now have something to 
show for our efforts. The long-term success of the journal will however 
continue to depend on the support of the scientific community it wants 
to serve. Your support is precious in this context, and we hope you will
 spread the word and encourage people around you to submit their best 
papers to TheoretiCS.<br>
<br>
With best regards,<br>
<br>Thomas Schwentick, Meena Mahajan and Pascal Weil,<br>
respectively Chair, Secretary and Treasurer of the TheoretiCS Foundation</p><p>By Luca Aceto</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><i>Thomas Schwentick, Meena Mahajan and Pascal Weil (Chair, Secretary and Treasurer of the TheoretiCS Foundation, respectively) sent me the following information on <a href="https://theoretics.episciences.org/" target="_blank">TheoretiCS</a>, which I am happy to share with our community with their permission. I encourage everyone to support the journal by submitting their best work to it!</i><br /></p><p>TheoretiCS was officially launched in 
December 2021 and we wish to present you with the current status of the 
project. You can find more precise information on the journal's site, <a data-saferedirecturl="https://www.google.com/url?q=http://theoretics-journal.org&amp;source=gmail&amp;ust=1680603853854000&amp;usg=AOvVaw0Ae4R2w9GxS1LLNOrTxwv2" href="http://theoretics-journal.org" rel="noreferrer" target="_blank">theoretics-journal.org</a>.<br />
<br />
The first papers were submitted right away in December 2021, and some 
were published in 2022: <a href="https://theoretics.episciences.org/volume/view/id/691" target="_blank">Volume 1</a> (2022) has two papers. <a href="https://theoretics.episciences.org/volume/view/id/692" target="_blank">Volume 2</a> (2023) 
already has five published papers, more are very near acceptance and 
there is a healthy list of papers under review, with more papers 
submitted every month.<br />
<br />
Our intention was to have a journal that covers the whole of Theoretical
 Computer Science, and this is reflected in the list of published 
papers. We also wanted to have an open-access journal (it operates under
 the so-called diamond open access paradigm, which means that no charges
 are levied to read it, nor to publish in it), and one that involves the
 theoretical computer science community as much as possible. This was 
done by first establishing an Advisory Board, where the majority of the 
members are representatives of many of the most prominent conferences of
 the domain. The Advisory Board selected a pair of remarkable 
Editors-in-Chief (Javier Esparza, TU München, and Uri Zwick, Tel-Aviv 
University) and then worked with the EiCs to assemble a prestigious 
Editorial Board. The Advisory Board continues to meet regularly, with 
the EiCs, to help steer the journal.<br />
<br />
We also wanted to innovate in the reviewing process, streamlining it 
without compromising in any way the quality of the papers — as we are 
aiming to become one of the very top journals in the field. The 
Editorial Board has a so-called Phase 1 process which typically lasts 
between 2 and 3 months, which determines whether the paper is of the 
caliber expected for the journal (quality of the results and quality of 
the exposition, relatively wide interest), under the assumption that the
 proofs are correct. When this Phase 1 concludes positively, Phase 2 
starts, with the objective of verifying the proofs and, possibly, making
 constructive suggestions to the authors as to how to better present 
their results. The result, we hope, is a higher quality for the papers 
published, and also a shorter response time for most of the papers which
 will end up being rejected. As of early 2023, on average, a decision 
for Phase 1 was reached 64 days after submission, within the three-month
 commitment the Editorial Board made. 85% of the papers got a Phase 1 
decision within 94 days.<br />
<br />
TheoretiCS remains a work in progress, though we now have something to 
show for our efforts. The long-term success of the journal will however 
continue to depend on the support of the scientific community it wants 
to serve. Your support is precious in this context, and we hope you will
 spread the word and encourage people around you to submit their best 
papers to TheoretiCS.<br />
<br />
With best regards,<br />
<br />Thomas Schwentick, Meena Mahajan and Pascal Weil,<br />
respectively Chair, Secretary and Treasurer of the TheoretiCS Foundation</p><p class="authors">By Luca Aceto</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-03T10:33:00Z">Monday, April 03 2023, 10:33</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.18063'>The Many Qualities of a New Directly Accessible Compression Scheme</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Domenico Cantone, Simone Faro</p><p>We present a new variable-length computation-friendly encoding scheme, named
SFDC (Succinct Format with Direct aCcesibility), that supports direct and fast
accessibility to any element of the compressed sequence and achieves
compression ratios often higher than those offered by other solutions in the
literature. The SFDC scheme provides a flexible and simple representation
geared towards either practical efficiency or compression ratios, as required.
For a text of length $n$ over an alphabet of size $\sigma$ and a fixed
parameter $\lambda$, the access time of the proposed encoding is proportional
to the length of the character's code-word, plus an expected
$\mathcal{O}((F_{\sigma - \lambda + 3} - 3)/F_{\sigma+1})$ overhead, where
$F_j$ is the $j$-th number of the Fibonacci sequence. In the overall it uses
$N+\mathcal{O}\big(n \left(\lambda - (F_{\sigma+3}-3)/F_{\sigma+1}\big) \right)
= N + \mathcal{O}(n)$ bits, where $N$ is the length of the encoded string.
Experimental results show that the performance of our scheme is, in some
respects, comparable with the performance of DACs and Wavelet Tees, which are
among of the most efficient schemes. In addition our scheme is configured as a
\emph{computation-friendly compression} scheme, as it counts several features
that make it very effective in text processing tasks. In the string matching
problem, that we take as a case study, we experimentally prove that the new
scheme enables results that are up to 29 times faster than standard
string-matching techniques on plain texts.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cantone_D/0/1/0/all/0/1">Domenico Cantone</a>, <a href="http://arxiv.org/find/cs/1/au:+Faro_S/0/1/0/all/0/1">Simone Faro</a></p><p>We present a new variable-length computation-friendly encoding scheme, named
SFDC (Succinct Format with Direct aCcesibility), that supports direct and fast
accessibility to any element of the compressed sequence and achieves
compression ratios often higher than those offered by other solutions in the
literature. The SFDC scheme provides a flexible and simple representation
geared towards either practical efficiency or compression ratios, as required.
For a text of length $n$ over an alphabet of size $\sigma$ and a fixed
parameter $\lambda$, the access time of the proposed encoding is proportional
to the length of the character's code-word, plus an expected
$\mathcal{O}((F_{\sigma - \lambda + 3} - 3)/F_{\sigma+1})$ overhead, where
$F_j$ is the $j$-th number of the Fibonacci sequence. In the overall it uses
$N+\mathcal{O}\big(n \left(\lambda - (F_{\sigma+3}-3)/F_{\sigma+1}\big) \right)
= N + \mathcal{O}(n)$ bits, where $N$ is the length of the encoded string.
Experimental results show that the performance of our scheme is, in some
respects, comparable with the performance of DACs and Wavelet Tees, which are
among of the most efficient schemes. In addition our scheme is configured as a
\emph{computation-friendly compression} scheme, as it counts several features
that make it very effective in text processing tasks. In the string matching
problem, that we take as a case study, we experimentally prove that the new
scheme enables results that are up to 29 times faster than standard
string-matching techniques on plain texts.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-03T00:30:00Z">Monday, April 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.18222'>Shipper collaboration matching: fast enumeration of triangular transports with high cooperation effects</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Akifumi Kira, Nobuo Terajima, Yasuhiko Watanabe, Hirotaka Yamamoto</p><p>The logistics industry in Japan is facing a severe shortage of labor.
Therefore, there is an increasing need for joint transportation allowing large
amounts of cargo to be transported using fewer trucks. In recent years, the use
of artificial intelligence and other new technologies has gained wide attention
for improving matching efficiency. However, it is difficult to develop a system
that can instantly respond to requests because browsing through enormous
combinations of two transport lanes is time consuming. In this study, we focus
on a form of joint transportation called triangular transportation and
enumerate the combinations with high cooperation effects. The proposed
algorithm makes good use of hidden inequalities, such as the distance axiom, to
narrow down the search range without sacrificing accuracy. Numerical
experiments show that the proposed algorithm is thousands of times faster than
simple brute force. With this technology as the core engine, we developed a
joint transportation matching system. The system has already been in use by
over 150 companies as of October 2022, and was featured in a collection of
logistics digital transformation cases published by Japan's Ministry of Land,
Infrastructure, Transport and Tourism.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kira_A/0/1/0/all/0/1">Akifumi Kira</a>, <a href="http://arxiv.org/find/cs/1/au:+Terajima_N/0/1/0/all/0/1">Nobuo Terajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Watanabe_Y/0/1/0/all/0/1">Yasuhiko Watanabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamamoto_H/0/1/0/all/0/1">Hirotaka Yamamoto</a></p><p>The logistics industry in Japan is facing a severe shortage of labor.
Therefore, there is an increasing need for joint transportation allowing large
amounts of cargo to be transported using fewer trucks. In recent years, the use
of artificial intelligence and other new technologies has gained wide attention
for improving matching efficiency. However, it is difficult to develop a system
that can instantly respond to requests because browsing through enormous
combinations of two transport lanes is time consuming. In this study, we focus
on a form of joint transportation called triangular transportation and
enumerate the combinations with high cooperation effects. The proposed
algorithm makes good use of hidden inequalities, such as the distance axiom, to
narrow down the search range without sacrificing accuracy. Numerical
experiments show that the proposed algorithm is thousands of times faster than
simple brute force. With this technology as the core engine, we developed a
joint transportation matching system. The system has already been in use by
over 150 companies as of October 2022, and was featured in a collection of
logistics digital transformation cases published by Japan's Ministry of Land,
Infrastructure, Transport and Tourism.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-03T00:30:00Z">Monday, April 03 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, April 01
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/041'>TR23-041 |  The communication complexity of functions with large outputs | 

	Sophie Laplante, 

	Mathieu Lauriere, 

	Lila Fontes, 

	Alexandre Nolin</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study the two-party communication complexity of functions with large outputs, and show that the communication complexity can greatly vary depending on what output model is considered. We study a variety of output models, ranging from the open model, in which an external observer can compute the outcome, to the XOR model, in which the outcome of the protocol should be the bitwise XOR of the players’ local outputs. This model is inspired by XOR games, which are widely studied two-player quantum games.
We focus on the question of error-reduction in these new output models. For functions of output size k, applying standard error reduction techniques in the XOR model would introduce an additional cost linear in k. We show that no dependency on k is necessary. Similarly, standard randomness removal techniques, incur a multiplicative cost of 2k in the XOR model. We show how to reduce this factor to O(k).
In addition, we prove analogous error reduction and randomness removal results in the other models, separate all models from each other, and show that some natural problems – including Set Intersection and Find the First Difference – separate the models when the Hamming weights of their inputs is bounded. Finally, we show how to use the rank lower bound technique for our weak output models.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study the two-party communication complexity of functions with large outputs, and show that the communication complexity can greatly vary depending on what output model is considered. We study a variety of output models, ranging from the open model, in which an external observer can compute the outcome, to the XOR model, in which the outcome of the protocol should be the bitwise XOR of the players’ local outputs. This model is inspired by XOR games, which are widely studied two-player quantum games.
We focus on the question of error-reduction in these new output models. For functions of output size k, applying standard error reduction techniques in the XOR model would introduce an additional cost linear in k. We show that no dependency on k is necessary. Similarly, standard randomness removal techniques, incur a multiplicative cost of 2k in the XOR model. We show how to reduce this factor to O(k).
In addition, we prove analogous error reduction and randomness removal results in the other models, separate all models from each other, and show that some natural problems – including Set Intersection and Find the First Difference – separate the models when the Hamming weights of their inputs is bounded. Finally, we show how to use the rank lower bound technique for our weak output models.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-01T22:18:55Z">Saturday, April 01 2023, 22:18</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7188'>Quips are what I’ve got</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In the comments on my last post&#8212;the one about the open letter calling for a six-month pause on AI scaling&#8212;a commenter named Hans Holander berates me over and over, as have others before him, for my failure to see that GPT is just a hoax and scam with no “true” intelligence. Below is my reply: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In the comments on my <a href="https://scottaaronson.blog/?p=7174">last post</a>&#8212;the one about the open letter calling for a six-month pause on AI scaling&#8212;a commenter named Hans Holander berates me over and over, as have others before him, for my failure to see that GPT is just a hoax and scam with no “true” intelligence.  Below is my reply: probably one of the most revealing things I’ve ever written (which is saying something).</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>The great irony here is that <em>if</em> you’re right—and you’re obviously 3000% confident that you’re right—then by my lights, there is no reason whatsoever to pause the scaling of Large Language Models, as your fellow LLM skeptics have urged.  If LLMs are mere &#8220;stochastic parrots,&#8221; and if further scaling will do nothing to alleviate their parroticity, then there’d seem to be little danger that they&#8217;ll ever form grounded plans to take over the world, or even help evil people form such plans. And soon it will be clear to everyone that LLMs are just a gigantic boondoggle that don’t help them solve their problems, and the entire direction will be abandoned. All a six-month pause would accomplish would be to delay this much-needed reckoning.</p>



<p>More broadly, though, do you see the problem with “just following your conscience” in this subject? There’s no way to operationalize “follow your conscience,” except “do the thing that will make the highest moral authorities that you recognize not be disappointed in you, not consider you a coward or a monster or a failure.” But what if there’s no agreement among the highest moral authorities that you recognize, or the people who set themselves up as the moral authorities? What if people will call you a coward or a monster or a failure, will even do so right in your comment section, <em>regardless</em> of what you choose?</p>



<p>This, of course, is hardly the first time in my life I’ve been in this situation, condemned for X and equally condemned for not(X).  I’ve never known how to navigate it.  When presented with diametrically opposed views about morality or the future of civilization, all confidently held by people who I consider smart and grounded, I can switch back and forth between the perspectives like with the Necker cube or the duck-rabbit.  But I don’t have any confident worldview of my own.  What I have are mostly quips, and jokes, and metaphors, and realizing when one thing contradicts a different thing, and lectures (many people do seem to like my lectures) where I lay out all the different considerations, and sometimes I also have neat little technical observations that occasionally even get dignified with the name of “theorems” and published in papers.</p>



<p>A quarter-century ago, though I remember like yesterday, I was an undergrad at Cornell, and belonged to a scholarship house called Telluride, where house-members had responsibilities for upkeep and governance and whatnot and would write periodic reviews of each other&#8217;s performance.  And I once got a scathing performance review, which took me to task for shirking my housework, and bringing my problem sets to the house meetings.  (These were meetings where the great issues of the day were debated&#8212;like whether or not to allocate $50 for fixing a light, and how guilty to feel over hiring maintenance workers and thereby participating in capitalist exploitation.)  And then there was this: &#8220;Scott&#8217;s contributions to house meetings are often limited to clever quips that, while amusing, do not advance the meeting agenda at all.&#8221;  </p>



<p>I’m not like Eliezer Yudkowsky, nor am I even like the anti-Eliezer people. I don’t, in the end, have any belief system at all with which to decide questions of a global or even cosmic magnitude, like whether the progress of AI should be paused or not. Mostly all I’ve got are the quips and the jokes, and the trying to do right on the smaller questions.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>And anyone who doesn’t like this post can consider it an April Fools (hey, Eliezer <a href="https://www.lesswrong.com/posts/j9Q8bRmwCgXRYAgcJ/miri-announces-new-death-with-dignity-strategy">did the same</a> last year!).</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-01T21:11:47Z">Saturday, April 01 2023, 21:11</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/04/01/postdoc-at-institute-of-mathematics-czech-academy-of-sciences-apply-by-april-30-2023/'>postdoc at Institute of Mathematics, Czech Academy of Sciences (apply by April 30, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          (Extended deadline) The Institute of Mathematics of the Czech Academy of Sciences is seeking a researcher for the project “Logic and unsatisfiability”. Applications are invited from candidates who have completed their PhD within the last 5 years (or will have completed it before the time of hiring), and who have a strong background in proof [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>(Extended deadline) The Institute of Mathematics of the Czech Academy of Sciences is seeking a researcher for the project “Logic and unsatisfiability”. Applications are invited from candidates who have completed their PhD within the last 5 years (or will have completed it before the time of hiring), and who have a strong background in proof complexity or bounded arithmetic.</p>
<p>Website: <a href="http://www.math.cas.cz/recrutements/postes.php">http://www.math.cas.cz/recrutements/postes.php</a><br />
Email: thapen@math.cas.cz</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-01T19:25:48Z">Saturday, April 01 2023, 19:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/04/whos-on-april-first.html'>Who's on April First</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;</p>♦<br>Carlos May waving to the crowd on April 1, 1972<p>Instead of the usual April Fools’ Day post, I present one of the best April Fools Day stunts ever. Here’s the text from an old Parade Magazine clipping I dug up recently that was published on April 1, 1985.</p><p>When it comes to innovative and wacky ideas in baseball, Bill Veeck was a true legend. As a team owner and promoter, Veeck was known for his creative approach to the sport, from planting ivy on the walls at Wrigley Field&nbsp;to his famous "exploding scoreboard" at Comiskey Park. But did you know about the time Veeck pulled off an unforgettable April Fools' stunt by having the 1972 Chicago White Sox wear the names from the classic "Who's on First?" sketch?</p><p>It was April 1, 1972, and the Chicago White Sox were getting ready to play a game that would go down in history. Bill Veeck had decided to pay homage to the iconic comedy routine by Bud Abbott and Lou Costello, considered by many the greatest comedy sketch ever performed. For those unfamiliar with the sketch, it revolves around a series of misunderstandings based on the names of the players on a fictional baseball team. The names sound like common phrases, leading to a hilariously confusing conversation.</p><p>In Veeck's version of the stunt, the White Sox players would take the field with the names of the "Who's on First?" team on the back of their jerseys. The players, initially skeptical of the idea, eventually embraced the spirit of April Fools' Day and played along.</p><p>As the game commenced, fans were treated to a scene straight out of the Abbott and Costello routine. Instead of their usual names, the players' jerseys featured names like "Who," "What," "I Don't Know," "Why," "Because," "Tomorrow," and "Today." Here was the starting lineup:</p><p></p><ol><li>Who - First Base: Dick Allen</li><li>What - Second Base: Mike Andrews</li><li>I Don't Know - Third Base: Bill Melton</li><li>Why - Left Field: Carlos May</li><li>Because - Center Field: Ken Berry</li><li>Abbott - Right Field: Jay Johnstone</li><li>I Don't Care - Shortstop: Luis Aparicio</li><li>Today - Catcher: Ed Herrmann</li><li>Tomorrow - Pitcher: Wilbur Wood</li></ol>The right fielder is never named in the sketch. Pat Kelly pinch hit for Johnstone in the 6th wearing “Costello”.&nbsp;<p></p><p>The confusion was not only limited to the fans in the stadium. The opposing team and the umpires struggled to keep track of the game, often leading to comical misunderstandings on the field. For instance, the umpire might have shouted, "Who's out!" only to be met with the response, "No, Who's on first!"</p><p>Though some traditional baseball fans were initially taken aback by the stunt, the majority embraced the humor, making the game one of the most memorable in White Sox history. It was a testament to Veeck's genius that he could seamlessly blend comedy with the sport he loved.</p><p>The "Who's on First?" game became a cherished part of baseball lore and added to the legend of Bill Veeck. It demonstrated his willingness to think outside the box, engage fans, and remind everyone that, at its core, baseball should be a source of fun and entertainment.</p><p>The 1972 Chicago White Sox "Who's on First?" April Fools' Day game captured the spirit of Bill Veeck's inventive approach to baseball. As we celebrate April Fools' Day this year, let's remember the time when the White Sox took the field with the most confusing lineup in baseball history and showed us all that, sometimes, laughter truly is the best medicine.</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;</p><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgUtAqIYgEqirBv-z2YRBAEYrFBAawDGs1NjdMsbwYKeoNs_ma5zlR9yyRD5ifxav8zQt3FhOBV8_xLQjScraH3UoscL-RS-nmYPpzQvEuZW9frJXlc1txBOpoTsGz5lUtJ1dAmArOvA2dagN1l-J5Uda-v959LDoBiidDWUZCQQVSsc7LUoA/s1024/baseball.jpg" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="769" data-original-width="1024" height="240" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgUtAqIYgEqirBv-z2YRBAEYrFBAawDGs1NjdMsbwYKeoNs_ma5zlR9yyRD5ifxav8zQt3FhOBV8_xLQjScraH3UoscL-RS-nmYPpzQvEuZW9frJXlc1txBOpoTsGz5lUtJ1dAmArOvA2dagN1l-J5Uda-v959LDoBiidDWUZCQQVSsc7LUoA/w320-h240/baseball.jpg" width="320" /></a></div><br /><div class="separator" style="clear: both; text-align: center;">Carlos May waving to the crowd on April 1, 1972</div><p><i>Instead of the usual April Fools’ Day post, I present one of the best April Fools Day stunts ever. Here’s the text from an old Parade Magazine clipping I dug up recently that was published on April 1, 1985.</i></p><p>When it comes to innovative and wacky ideas in baseball, Bill Veeck was a true legend. As a team owner and promoter, Veeck was known for his creative approach to the sport, from planting ivy on the walls at Wrigley Field&nbsp;to his famous "exploding scoreboard" at Comiskey Park. But did you know about the time Veeck pulled off an unforgettable April Fools' stunt by having the 1972 Chicago White Sox wear the names from the classic "Who's on First?" sketch?</p><p>It was April 1, 1972, and the Chicago White Sox were getting ready to play a game that would go down in history. Bill Veeck had decided to pay homage to the <a href="https://youtu.be/sShMA85pv8M">iconic comedy routine</a> by Bud Abbott and Lou Costello, considered by many the greatest comedy sketch ever performed. For those unfamiliar with the sketch, it revolves around a series of misunderstandings based on the names of the players on a fictional baseball team. The names sound like common phrases, leading to a hilariously confusing conversation.</p><p>In Veeck's version of the stunt, the White Sox players would take the field with the names of the "Who's on First?" team on the back of their jerseys. The players, initially skeptical of the idea, eventually embraced the spirit of April Fools' Day and played along.</p><p>As the game commenced, fans were treated to a scene straight out of the Abbott and Costello routine. Instead of their usual names, the players' jerseys featured names like "Who," "What," "I Don't Know," "Why," "Because," "Tomorrow," and "Today." Here was the starting lineup:</p><p></p><ol style="text-align: left;"><li>Who - First Base: Dick Allen</li><li>What - Second Base: Mike Andrews</li><li>I Don't Know - Third Base: Bill Melton</li><li>Why - Left Field: Carlos May</li><li>Because - Center Field: Ken Berry</li><li>Abbott - Right Field: Jay Johnstone</li><li>I Don't Care - Shortstop: Luis Aparicio</li><li>Today - Catcher: Ed Herrmann</li><li>Tomorrow - Pitcher: Wilbur Wood</li></ol><div>The right fielder is never named in the sketch. Pat Kelly pinch hit for Johnstone in the 6th wearing “Costello”.&nbsp;</div><p></p><p>The confusion was not only limited to the fans in the stadium. The opposing team and the umpires struggled to keep track of the game, often leading to comical misunderstandings on the field. For instance, the umpire might have shouted, "Who's out!" only to be met with the response, "No, Who's on first!"</p><p>Though some traditional baseball fans were initially taken aback by the stunt, the majority embraced the humor, making the game one of the most memorable in White Sox history. It was a testament to Veeck's genius that he could seamlessly blend comedy with the sport he loved.</p><p>The "Who's on First?" game became a cherished part of baseball lore and added to the legend of Bill Veeck. It demonstrated his willingness to think outside the box, engage fans, and remind everyone that, at its core, baseball should be a source of fun and entertainment.</p><p>The 1972 Chicago White Sox "Who's on First?" April Fools' Day game captured the spirit of Bill Veeck's inventive approach to baseball. As we celebrate April Fools' Day this year, let's remember the time when the White Sox took the field with the most confusing lineup in baseball history and showed us all that, sometimes, laughter truly is the best medicine.</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-01T14:04:00Z">Saturday, April 01 2023, 14:04</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://decentralizedthoughts.github.io/2023-04-01-hotstuff-2/'>What is the difference between PBFT, Tendermint, HotStuff, and HotStuff-2?</a></h3>
        <p class='tr-article-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We recently published our work HotStuff-2 on eprint, introducing a two-phase HotStuff variant which simultaneously achieves $O(n^2)$ worst-case communication, optimistically linear communication, a two-phase commit regime within a view, and optimistic responsiveness in partially-synchronous BFT. The main takeaway is that two phases are enough for BFT after all. In this...
        
        </div>

        <div class='tr-article-summary'>
        
          
          We recently published our work HotStuff-2 on eprint, introducing a two-phase HotStuff variant which simultaneously achieves $O(n^2)$ worst-case communication, optimistically linear communication, a two-phase commit regime within a view, and optimistic responsiveness in partially-synchronous BFT. The main takeaway is that two phases are enough for BFT after all. In this...
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-01T05:00:00Z">Saturday, April 01 2023, 05:00</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
