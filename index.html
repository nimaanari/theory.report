<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2022-11-27T01:30:15Z">Sunday, November 27 2022, 01:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, November 26
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/26/postdoc-at-university-of-toronto-apply-by-december-15-2022/'>Postdoc at University of Toronto (apply by December 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The theory group at the University of Toronto anticipates up to three postdoctoral positions beginning September 2023. We seek candidates from all areas of theoretical computer science including algorithms, complexity theory, cryptography, differential privacy, distributed computing, graph theory, quantum computing, and theoretical aspects of machine learning. Website: www.cs.toronto.edu/theory/positions.html Email: sachdeva@cs.toronto.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The theory group at the University of Toronto anticipates up to three postdoctoral positions beginning September 2023. We seek candidates from all areas of theoretical computer science including algorithms, complexity theory, cryptography, differential privacy, distributed computing, graph theory, quantum computing, and theoretical aspects of machine learning.</p>
<p>Website: <a href="https://www.cs.toronto.edu/theory/positions.html">https://www.cs.toronto.edu/theory/positions.html</a><br />
Email: sachdeva@cs.toronto.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-26T17:07:36Z">Saturday, November 26 2022, 17:07</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2022/169'>TR22-169 |  Extractors for Images of Varieties | 

	Zeyu Guo, 

	Ben Lee Volk, 

	Akhil Jalan, 

	David Zuckerman</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We construct explicit deterministic extractors for polynomial images of varieties, that is, distributions sampled by applying a low-degree polynomial map $f : \mathbb{F}_q^r \to \mathbb{F}_q^n$ to an element sampled uniformly at random from a $k$-dimensional variety $V \subseteq \mathbb{F}_q^r$. This class of sources generalizes both polynomial sources, studied by Dvir, Gabizon and Wigderson (FOCS 2007, Comput. Complex. 2009), and variety sources, studied by Dvir (CCC 2009, Comput. Complex. 2012).

  Assuming certain natural non-degeneracy conditions on the map $f$ and the variety $V$, which in particular ensure that the source has enough min-entropy, we extract almost all the min-entropy of the distribution. Unlike the Dvir-Gabizon-Wigderson and Dvir results, our construction works over large enough finite fields of arbitrary characteristic. One key part of our construction is an improved deterministic rank extractor for varieties. As a by-product, we obtain explicit Noether normalization lemmas for affine varieties and affine algebras.

  Additionally, we generalize a construction of affine extractors with exponentially small error due to Bourgain, Dvir and Leeman (Comput. Complex. 2016) by extending it to all finite prime fields of quasipolynomial size.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We construct explicit deterministic extractors for polynomial images of varieties, that is, distributions sampled by applying a low-degree polynomial map $f : \mathbb{F}_q^r \to \mathbb{F}_q^n$ to an element sampled uniformly at random from a $k$-dimensional variety $V \subseteq \mathbb{F}_q^r$. This class of sources generalizes both polynomial sources, studied by Dvir, Gabizon and Wigderson (FOCS 2007, Comput. Complex. 2009), and variety sources, studied by Dvir (CCC 2009, Comput. Complex. 2012).

  Assuming certain natural non-degeneracy conditions on the map $f$ and the variety $V$, which in particular ensure that the source has enough min-entropy, we extract almost all the min-entropy of the distribution. Unlike the Dvir-Gabizon-Wigderson and Dvir results, our construction works over large enough finite fields of arbitrary characteristic. One key part of our construction is an improved deterministic rank extractor for varieties. As a by-product, we obtain explicit Noether normalization lemmas for affine varieties and affine algebras.

  Additionally, we generalize a construction of affine extractors with exponentially small error due to Bourgain, Dvir and Leeman (Comput. Complex. 2016) by extending it to all finite prime fields of quasipolynomial size.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-26T12:06:05Z">Saturday, November 26 2022, 12:06</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, November 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/24/postdoc-at-national-university-of-singapore-apply-by-february-15-2023/'>Postdoc at National University of Singapore (apply by February 15, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Postdoc positions hosted by Prashant Nalini Vasudevan. Looking for candidates with a strong background in theory interested in the foundations of cryptography, information-theoretic cryptography, or related areas of complexity theory and algorithms. See website for more details. Website: www.comp.nus.edu.sg/~prashant/ads.html Email: prashant@comp.nus.edu.sg
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Postdoc positions hosted by Prashant Nalini Vasudevan. Looking for candidates with a strong background in theory interested in the foundations of cryptography, information-theoretic cryptography, or related areas of complexity theory and algorithms. See website for more details.</p>
<p>Website: <a href="https://www.comp.nus.edu.sg/~prashant/ads.html">https://www.comp.nus.edu.sg/~prashant/ads.html</a><br />
Email: prashant@comp.nus.edu.sg</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T11:49:05Z">Thursday, November 24 2022, 11:49</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2022/168'>TR22-168 |  A Proof of the Generalized Union-Closed Set Conjecture assuming the Union-Closed Set Conjecture | 

	Zubayir Kazi</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Abstract The Union Closed Set Conjecture states that if a set system X\subseteq\mathcal{P}([n]) is closed under pairwise unions, then there exists a\in[n] in at least half of the sets of X. We show that there is a very natural generalization of the union closed set conjecture which gives a lower bound for k-set subsets of [n]. This a stronger version of a Conjecture of (Nagel, 2022). We then prove the Conjecture conditional on the Union Closed Set Conjecture using invariants of Union-Closed sets. Additionally, we prove that there exists a k-set in .38^{k}|F| sets of a union closed set X for every n\geq k&gt;0 using the recent improvements in (Gilmer, 2022) and (Alweiss et al, 2022). We explain why our result suggests a lack of sharpness of the original conjecture.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Abstract The Union Closed Set Conjecture states that if a set system X\subseteq\mathcal{P}([n]) is closed under pairwise unions, then there exists a\in[n] in at least half of the sets of X. We show that there is a very natural generalization of the union closed set conjecture which gives a lower bound for k-set subsets of [n]. This a stronger version of a Conjecture of (Nagel, 2022). We then prove the Conjecture conditional on the Union Closed Set Conjecture using invariants of Union-Closed sets. Additionally, we prove that there exists a k-set in .38^{k}|F| sets of a union closed set X for every n\geq k&gt;0 using the recent improvements in (Gilmer, 2022) and (Alweiss et al, 2022). We explain why our result suggests a lack of sharpness of the original conjecture.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T10:14:14Z">Thursday, November 24 2022, 10:14</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://decentralizedthoughts.github.io/2022-11-24-two-round-HS/'>Two Round HotStuff</a></h3>
        <p class='tr-article-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In the first part of this post we describe a single-shot variation of Two Round HotStuff (see the HotStuff v1 paper) using Locked Broadcast that follows a similar path as our previous post on Paxos and Linear PBFT. In the second part, we describe a fully pipelined multi-shot State Machine...
        
        </div>

        <div class='tr-article-summary'>
        
          
          In the first part of this post we describe a single-shot variation of Two Round HotStuff (see the HotStuff v1 paper) using Locked Broadcast that follows a similar path as our previous post on Paxos and Linear PBFT. In the second part, we describe a fully pipelined multi-shot State Machine...
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T09:00:00Z">Thursday, November 24 2022, 09:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2022/11/23/tcs-talk-wednesday-november-30-nicole-wein-dimacs/'>TCS+ talk: Wednesday, November 30 — Nicole Wein, DIMACS</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, November 30th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Nicole Wein from DIMACS will speak about &#8220;Online List Labeling: Breaking the Barrier&#8221; (abstract below). You can reserve a spot as an individual or a group to join [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p></p>


<p>The next TCS+ talk will take place this coming Wednesday, November 30th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <a href="http://people.csail.mit.edu/nwein/"><strong>Nicole Wein</strong></a> from DIMACS will speak about &#8220;<em>Online List Labeling: Breaking the <img src="https://s0.wp.com/latex.php?latex=%5Clog%5E2+n&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog%5E2+n&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5E2+n&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log^2 n" class="latex" /> Barrier</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote">
<p>Abstract: The online list labeling problem is a basic primitive in data structures. The goal is to store a dynamically-changing set of n items in an array of m slots, while keeping the elements in sorted order. To do so, some items may need to be moved over time, and the goal is to minimize the number of items moved per insertion/deletion. When <img src="https://s0.wp.com/latex.php?latex=m+%3D+Cn&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m+%3D+Cn&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m+%3D+Cn&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m = Cn" class="latex" /> for some constant <img src="https://s0.wp.com/latex.php?latex=C%3E1&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3E1&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3E1&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&gt;1" class="latex" />, an upper bound of <img src="https://s0.wp.com/latex.php?latex=O%28%5Clog%5E2+n%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28%5Clog%5E2+n%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28%5Clog%5E2+n%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(&#92;log^2 n)" class="latex" /> items moved per insertion/deletion has been known since 1981. There is a matching lower bound for deterministic algorithms, but for randomized algorithms, the best known lower bound is <img src="https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Omega(&#92;log n)" class="latex" />, leaving a gap between upper and lower bounds. We improve the upper bound, providing a randomized data structure with expected <img src="https://s0.wp.com/latex.php?latex=O%28%5Clog%5E%7B3%2F2%7D+n%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28%5Clog%5E%7B3%2F2%7D+n%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28%5Clog%5E%7B3%2F2%7D+n%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(&#92;log^{3/2} n)" class="latex" /> items moved per insertion/deletion.</p>
<p>Joint work with Michael Bender, Alexander Conway, Martin Farach-Colton, Hanna Komlos, and William Kuszmaul</p>
</blockquote><p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T04:20:07Z">Thursday, November 24 2022, 04:20</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12862'>Shortest Odd Paths in Conservative Graphs: Connections and Complexity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ildik&#xf3; Schlotter, Andr&#xe1;s Seb&#x151;</p><p>We present some reductions between optimization problems for undirected
conservative graphs, that is, edge-weighted graphs without negative cycles. We
settle the complexity of some of them, and exhibit some remaining challenges.
Our key result is that the shortest odd path problem between two given
vertices, and its variants, such as the shortest odd cycle problem through a
given vertex, turn out to be NP-hard, deciding a long-standing question by
Lov\'asz (Open Problem 27 in Schrijver's book, 2003), in the negative. The
complexity of finding a shortest odd cycle for conservative weights or of
finding an odd $T$-join of minimum cardinality remains open. We finally relate
these problems to relevant, solved or hopeful variants.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Schlotter_I/0/1/0/all/0/1">Ildik&#xf3; Schlotter</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebo_A/0/1/0/all/0/1">Andr&#xe1;s Seb&#x151;</a></p><p>We present some reductions between optimization problems for undirected
conservative graphs, that is, edge-weighted graphs without negative cycles. We
settle the complexity of some of them, and exhibit some remaining challenges.
Our key result is that the shortest odd path problem between two given
vertices, and its variants, such as the shortest odd cycle problem through a
given vertex, turn out to be NP-hard, deciding a long-standing question by
Lov\'asz (Open Problem 27 in Schrijver's book, 2003), in the negative. The
complexity of finding a shortest odd cycle for conservative weights or of
finding an odd $T$-join of minimum cardinality remains open. We finally relate
these problems to relevant, solved or hopeful variants.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T01:30:00Z">Thursday, November 24 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12982'>The Stochastic Arrival Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Thomas Webster</p><p>We study a new modification of the Arrival problem, which allows for nodes
that exhibit random as well as controlled behaviour, in addition to switching
nodes. We study the computational complexity of these extensions, building on
existing work on Reachability Switching Games. In particular, we show for
versions of the arrival problem involving just switching and random nodes it is
\PP{}-hard to decide if their value is greater than a half and we give a PSPACE
decision algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Webster_T/0/1/0/all/0/1">Thomas Webster</a></p><p>We study a new modification of the Arrival problem, which allows for nodes
that exhibit random as well as controlled behaviour, in addition to switching
nodes. We study the computational complexity of these extensions, building on
existing work on Reachability Switching Games. In particular, we show for
versions of the arrival problem involving just switching and random nodes it is
\PP{}-hard to decide if their value is greater than a half and we give a PSPACE
decision algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T01:30:00Z">Thursday, November 24 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.13217'>On the Complexity of Finding a Diverse and Representative Committee using a Monotone, Separable Positional Multiwinner Voting Rule</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kunal Relia</p><p>Fairness in multiwinner elections, a growing line of research in
computational social choice, primarily concerns the use of constraints to
ensure fairness. Recent work proposed a model to find a diverse \emph{and}
representative committee and studied the model's computational aspects.
However, the work gave complexity results under major assumptions on how the
candidates and the voters are grouped. Here, we close this gap and classify the
complexity of finding a diverse and representative committee using a monotone,
separable positional multiwinner voting rule, conditioned \emph{only} on the
assumption that P $\neq$ NP.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Relia_K/0/1/0/all/0/1">Kunal Relia</a></p><p>Fairness in multiwinner elections, a growing line of research in
computational social choice, primarily concerns the use of constraints to
ensure fairness. Recent work proposed a model to find a diverse \emph{and}
representative committee and studied the model's computational aspects.
However, the work gave complexity results under major assumptions on how the
candidates and the voters are grouped. Here, we close this gap and classify the
complexity of finding a diverse and representative committee using a monotone,
separable positional multiwinner voting rule, conditioned \emph{only} on the
assumption that P $\neq$ NP.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T01:30:00Z">Thursday, November 24 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12541'>Deterministic Approximation Algorithms for Volumes of Spectrahedra</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mahmut Levent Do&#x11f;an, Jonathan Leake, Mohan Ravichandran</p><p>We give a method for computing asymptotic formulas and approximations for the
volumes of spectrahedra, based on the maximum-entropy principle from
statistical physics. The method gives an approximate volume formula based on a
single convex optimization problem of minimizing $-\log \det P$ over the
spectrahedron. Spectrahedra can be described as affine slices of the convex
cone of positive semi-definite (PSD) matrices, and the method yields efficient
deterministic approximation algorithms and asymptotic formulas whenever the
number of affine constraints is sufficiently dominated by the dimension of the
PSD cone.
</p>
<p>Our approach is inspired by the work of Barvinok and Hartigan who used an
analogous framework for approximately computing volumes of polytopes.
Spectrahedra, however, possess a remarkable feature not shared by polytopes, a
new fact that we also prove: central sections of the set of density matrices
(the quantum version of the simplex) all have asymptotically the same volume.
This allows for very general approximation algorithms, which apply to large
classes of naturally occurring spectrahedra.
</p>
<p>We give two main applications of this method. First, we apply this method to
what we call the "multi-way Birkhoff spectrahedron" and obtain an explicit
asymptotic formula for its volume. This spectrahedron is the set of quantum
states with maximal entanglement (i.e., the quantum states having univariant
quantum marginals equal to the identity matrix) and is the quantum analog of
the multi-way Birkhoff polytope. Second, we apply this method to explicitly
compute the asymptotic volume of central sections of the set of density
matrices.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dogan_M/0/1/0/all/0/1">Mahmut Levent Do&#x11f;an</a>, <a href="http://arxiv.org/find/cs/1/au:+Leake_J/0/1/0/all/0/1">Jonathan Leake</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravichandran_M/0/1/0/all/0/1">Mohan Ravichandran</a></p><p>We give a method for computing asymptotic formulas and approximations for the
volumes of spectrahedra, based on the maximum-entropy principle from
statistical physics. The method gives an approximate volume formula based on a
single convex optimization problem of minimizing $-\log \det P$ over the
spectrahedron. Spectrahedra can be described as affine slices of the convex
cone of positive semi-definite (PSD) matrices, and the method yields efficient
deterministic approximation algorithms and asymptotic formulas whenever the
number of affine constraints is sufficiently dominated by the dimension of the
PSD cone.
</p>
<p>Our approach is inspired by the work of Barvinok and Hartigan who used an
analogous framework for approximately computing volumes of polytopes.
Spectrahedra, however, possess a remarkable feature not shared by polytopes, a
new fact that we also prove: central sections of the set of density matrices
(the quantum version of the simplex) all have asymptotically the same volume.
This allows for very general approximation algorithms, which apply to large
classes of naturally occurring spectrahedra.
</p>
<p>We give two main applications of this method. First, we apply this method to
what we call the "multi-way Birkhoff spectrahedron" and obtain an explicit
asymptotic formula for its volume. This spectrahedron is the set of quantum
states with maximal entanglement (i.e., the quantum states having univariant
quantum marginals equal to the identity matrix) and is the quantum analog of
the multi-way Birkhoff polytope. Second, we apply this method to explicitly
compute the asymptotic volume of central sections of the set of density
matrices.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T01:30:00Z">Thursday, November 24 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12887'>Complexity Framework For Forbidden Subgraphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Matthew Johnson, Barnaby Martin, Jelle J. Oostveen, Sukanya Pandey, Dani&#xeb;l Paulusma, Siani Smith, Erik Jan van Leeuwen</p><p>For any finite set $\mathcal{H} = \{H_1,\ldots,H_p\}$ of graphs, a graph is
$\mathcal{H}$-subgraph-free if it does not contain any of $H_1,\ldots,H_p$ as a
subgraph. We propose a meta-theorem to classify if problems are "efficiently
solvable" or "computationally hard" on $\mathcal{H}$-subgraph-free graphs. The
conditions are that the problem should be efficiently solvable on graphs of
bounded treewidth, computationally hard on subcubic graphs, and computational
hardness is preserved under edge subdivision. We show that all problems
satisfying these conditions are efficiently solvable if $\mathcal{H}$ contains
a disjoint union of one or more paths and subdivided claws, and are
computationally hard otherwise. To illustrate the broad applicability of our
framework, we study covering or packing problems, network design problems and
width parameter problems. We apply the framework to obtain a dichotomy between
polynomial-time solvability and NP-completeness. For other problems we obtain a
dichotomy between almost-linear-time solvability and having no
subquadratic-time algorithm (conditioned on some hardness hypotheses). In this
way we strengthen results in the literature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Johnson_M/0/1/0/all/0/1">Matthew Johnson</a>, <a href="http://arxiv.org/find/math/1/au:+Martin_B/0/1/0/all/0/1">Barnaby Martin</a>, <a href="http://arxiv.org/find/math/1/au:+Oostveen_J/0/1/0/all/0/1">Jelle J. Oostveen</a>, <a href="http://arxiv.org/find/math/1/au:+Pandey_S/0/1/0/all/0/1">Sukanya Pandey</a>, <a href="http://arxiv.org/find/math/1/au:+Paulusma_D/0/1/0/all/0/1">Dani&#xeb;l Paulusma</a>, <a href="http://arxiv.org/find/math/1/au:+Smith_S/0/1/0/all/0/1">Siani Smith</a>, <a href="http://arxiv.org/find/math/1/au:+Leeuwen_E/0/1/0/all/0/1">Erik Jan van Leeuwen</a></p><p>For any finite set $\mathcal{H} = \{H_1,\ldots,H_p\}$ of graphs, a graph is
$\mathcal{H}$-subgraph-free if it does not contain any of $H_1,\ldots,H_p$ as a
subgraph. We propose a meta-theorem to classify if problems are "efficiently
solvable" or "computationally hard" on $\mathcal{H}$-subgraph-free graphs. The
conditions are that the problem should be efficiently solvable on graphs of
bounded treewidth, computationally hard on subcubic graphs, and computational
hardness is preserved under edge subdivision. We show that all problems
satisfying these conditions are efficiently solvable if $\mathcal{H}$ contains
a disjoint union of one or more paths and subdivided claws, and are
computationally hard otherwise. To illustrate the broad applicability of our
framework, we study covering or packing problems, network design problems and
width parameter problems. We apply the framework to obtain a dichotomy between
polynomial-time solvability and NP-completeness. For other problems we obtain a
dichotomy between almost-linear-time solvability and having no
subquadratic-time algorithm (conditioned on some hardness hypotheses). In this
way we strengthen results in the literature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T01:30:00Z">Thursday, November 24 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12954'>Quantum-Classical Tradeoffs in the Random Oracle Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yassine Hamoudi, Qipeng Liu, Makrand Sinha</p><p>We study tradeoffs between quantum and classical queries for hybrid
algorithms that have black-box access to a random oracle. Although there are
several established techniques for proving query lower bounds for both quantum
and classical algorithms, there is no such widely applicable technique for
hybrid algorithms and the optimal tradeoffs for many fundamental problems are
still unknown $\unicode{x2013}$ an optimal tradeoff for the search problem was
only shown recently by Rosmanis, although not in the random oracle model. For
another fundamental problem, collision finding, the optimal tradeoff was not
known.
</p>
<p>In this work, we develop a framework for recording a query transcript for
quantum-classical algorithms that represents the knowledge gained by the
algorithm. The main feature of this framework is to allow us to record queries
in two incompatible bases $\unicode{x2013}$ classical queries in the standard
basis and quantum queries in the Fourier basis $\unicode{x2013}$ in a
consistent way. We call the framework the hybrid compressed oracle as it
naturally interpolates between the classical way of recording queries and the
compressed oracle framework of Zhandry for recording quantum queries. We
demonstrate its applicability by giving a simpler proof of the optimal
quantum-classical tradeoff for search and by showing an optimal tradeoff for
collision finding.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Hamoudi_Y/0/1/0/all/0/1">Yassine Hamoudi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Liu_Q/0/1/0/all/0/1">Qipeng Liu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sinha_M/0/1/0/all/0/1">Makrand Sinha</a></p><p>We study tradeoffs between quantum and classical queries for hybrid
algorithms that have black-box access to a random oracle. Although there are
several established techniques for proving query lower bounds for both quantum
and classical algorithms, there is no such widely applicable technique for
hybrid algorithms and the optimal tradeoffs for many fundamental problems are
still unknown $\unicode{x2013}$ an optimal tradeoff for the search problem was
only shown recently by Rosmanis, although not in the random oracle model. For
another fundamental problem, collision finding, the optimal tradeoff was not
known.
</p>
<p>In this work, we develop a framework for recording a query transcript for
quantum-classical algorithms that represents the knowledge gained by the
algorithm. The main feature of this framework is to allow us to record queries
in two incompatible bases $\unicode{x2013}$ classical queries in the standard
basis and quantum queries in the Fourier basis $\unicode{x2013}$ in a
consistent way. We call the framework the hybrid compressed oracle as it
naturally interpolates between the classical way of recording queries and the
compressed oracle framework of Zhandry for recording quantum queries. We
demonstrate its applicability by giving a simpler proof of the optimal
quantum-classical tradeoff for search and by showing an optimal tradeoff for
collision finding.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T01:30:00Z">Thursday, November 24 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12511'>Scalable and Effective Conductance-based Graph Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Longlong Lin, Rong-Hua Li, Tao Jia</p><p>Conductance-based graph clustering has been recognized as a fundamental
operator in numerous graph analysis applications. Despite the significant
success of conductance-based graph clustering, existing algorithms are either
hard to obtain satisfactory clustering qualities, or have high time and space
complexity to achieve provable clustering qualities. To overcome these
limitations, we devise a powerful \textit{peeling}-based graph clustering
framework \textit{PCon}. We show that many existing solutions can be reduced to
our framework. Namely, they first define a score function for each vertex, then
iteratively remove the vertex with the smallest score. Finally, they output the
result with the smallest conductance during the peeling process. Based on our
framework, we propose two novel algorithms \textit{PCon\_core} and
\emph{PCon\_de} with linear time and space complexity, which can efficiently
and effectively identify clusters from massive graphs with more than a few
billion edges. Surprisingly, we prove that \emph{PCon\_de} can identify
clusters with near-constant approximation ratio, resulting in an important
theoretical improvement over the well-known quadratic Cheeger bound. Empirical
results on real-life and synthetic datasets show that our algorithms can
achieve 5$\sim$42 times speedup with a high clustering accuracy, while using
1.4$\sim$7.8 times less memory than the baseline algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Longlong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Rong-Hua Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_T/0/1/0/all/0/1">Tao Jia</a></p><p>Conductance-based graph clustering has been recognized as a fundamental
operator in numerous graph analysis applications. Despite the significant
success of conductance-based graph clustering, existing algorithms are either
hard to obtain satisfactory clustering qualities, or have high time and space
complexity to achieve provable clustering qualities. To overcome these
limitations, we devise a powerful \textit{peeling}-based graph clustering
framework \textit{PCon}. We show that many existing solutions can be reduced to
our framework. Namely, they first define a score function for each vertex, then
iteratively remove the vertex with the smallest score. Finally, they output the
result with the smallest conductance during the peeling process. Based on our
framework, we propose two novel algorithms \textit{PCon\_core} and
\emph{PCon\_de} with linear time and space complexity, which can efficiently
and effectively identify clusters from massive graphs with more than a few
billion edges. Surprisingly, we prove that \emph{PCon\_de} can identify
clusters with near-constant approximation ratio, resulting in an important
theoretical improvement over the well-known quadratic Cheeger bound. Empirical
results on real-life and synthetic datasets show that our algorithms can
achieve 5$\sim$42 times speedup with a high clustering accuracy, while using
1.4$\sim$7.8 times less memory than the baseline algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T01:30:00Z">Thursday, November 24 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12751'>SAH: Shifting-aware Asymmetric Hashing for Reverse $k$-Maximum Inner Product Search</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Qiang Huang, Yanhao Wang, Anthony K. H. Tung</p><p>This paper investigates a new yet challenging problem called Reverse
$k$-Maximum Inner Product Search (R$k$MIPS). Given a query (item) vector, a set
of item vectors, and a set of user vectors, the problem of R$k$MIPS aims to
find a set of user vectors whose inner products with the query vector are one
of the $k$ largest among the query and item vectors. We propose the first
subquadratic-time algorithm, i.e., Shifting-aware Asymmetric Hashing (SAH), to
tackle the R$k$MIPS problem. To speed up the Maximum Inner Product Search
(MIPS) on item vectors, we design a shifting-invariant asymmetric
transformation and develop a novel sublinear-time Shifting-Aware Asymmetric
Locality Sensitive Hashing (SA-ALSH) scheme. Furthermore, we devise a new
blocking strategy based on the Cone-Tree to effectively prune user vectors (in
a batch). We prove that SAH achieves a theoretical guarantee for solving the
RMIPS problem. Experimental results on five real-world datasets show that SAH
runs 4$\sim$8$\times$ faster than the state-of-the-art methods for R$k$MIPS
while achieving F1-scores of over 90\%. The code is available at
\url{github.com/HuangQiang/SAH}.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tung_A/0/1/0/all/0/1">Anthony K. H. Tung</a></p><p>This paper investigates a new yet challenging problem called Reverse
$k$-Maximum Inner Product Search (R$k$MIPS). Given a query (item) vector, a set
of item vectors, and a set of user vectors, the problem of R$k$MIPS aims to
find a set of user vectors whose inner products with the query vector are one
of the $k$ largest among the query and item vectors. We propose the first
subquadratic-time algorithm, i.e., Shifting-aware Asymmetric Hashing (SAH), to
tackle the R$k$MIPS problem. To speed up the Maximum Inner Product Search
(MIPS) on item vectors, we design a shifting-invariant asymmetric
transformation and develop a novel sublinear-time Shifting-Aware Asymmetric
Locality Sensitive Hashing (SA-ALSH) scheme. Furthermore, we devise a new
blocking strategy based on the Cone-Tree to effectively prune user vectors (in
a batch). We prove that SAH achieves a theoretical guarantee for solving the
RMIPS problem. Experimental results on five real-world datasets show that SAH
runs 4$\sim$8$\times$ faster than the state-of-the-art methods for R$k$MIPS
while achieving F1-scores of over 90\%. The code is available at
\url{https://github.com/HuangQiang/SAH}.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T01:30:00Z">Thursday, November 24 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12833'>Worst-Case to Expander-Case Reductions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Amir Abboud, Nathan Wallheimer</p><p>In recent years, the expander decomposition method was used to develop many
graph algorithms, resulting in major improvements to longstanding complexity
barriers. This powerful hammer has led the community to (1) believe that most
problems are as easy on worst-case graphs as they are on expanders, and (2)
suspect that expander decompositions are the key to breaking the remaining
longstanding barriers in fine-grained complexity.
</p>
<p>We set out to investigate the extent to which these two things are true (and
for which problems). Towards this end, we put forth the concept of worst-case
to expander-case self-reductions. We design a collection of such reductions for
fundamental graph problems, verifying belief (1) for them. The list includes
$k$-Clique, $4$-Cycle, Maximum Cardinality Matching, Vertex-Cover, and Minimum
Dominating Set. Interestingly, for most (but not all) of these problems the
proof is via a simple gadget reduction, not via expander decompositions,
showing that this hammer is effectively useless against the problem and
contradicting (2).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Abboud_A/0/1/0/all/0/1">Amir Abboud</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallheimer_N/0/1/0/all/0/1">Nathan Wallheimer</a></p><p>In recent years, the expander decomposition method was used to develop many
graph algorithms, resulting in major improvements to longstanding complexity
barriers. This powerful hammer has led the community to (1) believe that most
problems are as easy on worst-case graphs as they are on expanders, and (2)
suspect that expander decompositions are the key to breaking the remaining
longstanding barriers in fine-grained complexity.
</p>
<p>We set out to investigate the extent to which these two things are true (and
for which problems). Towards this end, we put forth the concept of worst-case
to expander-case self-reductions. We design a collection of such reductions for
fundamental graph problems, verifying belief (1) for them. The list includes
$k$-Clique, $4$-Cycle, Maximum Cardinality Matching, Vertex-Cover, and Minimum
Dominating Set. Interestingly, for most (but not all) of these problems the
proof is via a simple gadget reduction, not via expander decompositions,
showing that this hammer is effectively useless against the problem and
contradicting (2).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T01:30:00Z">Thursday, November 24 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.13118'>Branch-and-Bound with Barrier: Dominance and Suboptimality Detection for DD-Based Branch-and-Bound</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vianney Copp&#xe9;, Xavier Gillard, Pierre Schaus</p><p>The branch-and-bound algorithm based on decision diagrams introduced by
Bergman et al. in 2016 is a framework for solving discrete optimization
problems with a dynamic programming formulation. It works by compiling a series
of bounded-width decision diagrams that can provide lower and upper bounds for
any given subproblem. Eventually, every part of the search space will be either
explored or pruned by the algorithm, thus proving optimality. This paper
presents new ingredients to speed up the search by exploiting the structure of
dynamic programming models. The key idea is to prevent the repeated exploration
of nodes corresponding to the same dynamic programming states by storing and
querying thresholds in a data structure called the Barrier. These thresholds
are based on dominance relations between partial solutions previously found.
They can be further strengthened by integrating the filtering techniques
introduced by Gillard et al. in 2021. Computational experiments show that the
pruning brought by the Barrier allows to significantly reduce the number of
nodes expanded by the algorithm. This results in more benchmark instances of
difficult optimization problems being solved in less time while using narrower
decision diagrams.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Coppe_V/0/1/0/all/0/1">Vianney Copp&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Gillard_X/0/1/0/all/0/1">Xavier Gillard</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaus_P/0/1/0/all/0/1">Pierre Schaus</a></p><p>The branch-and-bound algorithm based on decision diagrams introduced by
Bergman et al. in 2016 is a framework for solving discrete optimization
problems with a dynamic programming formulation. It works by compiling a series
of bounded-width decision diagrams that can provide lower and upper bounds for
any given subproblem. Eventually, every part of the search space will be either
explored or pruned by the algorithm, thus proving optimality. This paper
presents new ingredients to speed up the search by exploiting the structure of
dynamic programming models. The key idea is to prevent the repeated exploration
of nodes corresponding to the same dynamic programming states by storing and
querying thresholds in a data structure called the Barrier. These thresholds
are based on dominance relations between partial solutions previously found.
They can be further strengthened by integrating the filtering techniques
introduced by Gillard et al. in 2021. Computational experiments show that the
pruning brought by the Barrier allows to significantly reduce the number of
nodes expanded by the algorithm. This results in more benchmark instances of
difficult optimization problems being solved in less time while using narrower
decision diagrams.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-24T01:30:00Z">Thursday, November 24 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, November 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/23/2023-summer-research-intern-at-adobe-research-at-adobe-research-apply-by-february-1-2023/'>2023 Summer Research Intern at Adobe Research at Adobe Research (apply by February 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Summer (TCS) Research Intern positions are available to work with Zhao Song at Adobe Research. The position is for 3-4 months in summer 2023, start date flexible. CV and a recommendation letter from Ph.D. advisor is required to be sent before ddl. Website: www.adobe.com/careers/university/internships.html Email: zsong@adobe.com
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Summer (TCS) Research Intern positions are available to work with Zhao Song at Adobe Research. The position is for 3-4 months in summer 2023, start date flexible. CV and a recommendation letter from Ph.D. advisor is required to be sent before ddl.</p>
<p>Website: <a href="https://www.adobe.com/careers/university/internships.html">https://www.adobe.com/careers/university/internships.html</a><br />
Email: zsong@adobe.com</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T23:16:50Z">Wednesday, November 23 2022, 23:16</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2022/167'>TR22-167 |  Parallel Repetition for the GHZ Game: Exponential Decay | 

	Mark Braverman, 

	Subhash Khot, 

	Dor Minzer</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We show that the value of the $n$-fold repeated GHZ game is at most $2^{-\Omega(n)}$, improving upon the polynomial bound established by Holmgren and Raz. Our result is established via a reduction to approximate subgroup type questions from additive combinatorics.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We show that the value of the $n$-fold repeated GHZ game is at most $2^{-\Omega(n)}$, improving upon the polynomial bound established by Holmgren and Raz. Our result is established via a reduction to approximate subgroup type questions from additive combinatorics.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T22:17:41Z">Wednesday, November 23 2022, 22:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/23/faculty-any-rank-at-penn-state-apply-by-november-15-2022/'>FACULTY (ANY RANK) at PENN STATE (apply by November 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Applications are invited for tenure-track positions at all levels across all areas of theoretical computer science. Review of applications started on 11/15/2022 and will continue until the positions is filled. Website: academicjobsonline.org/ajo/jobs/23484 Email: ablanca@cse.psu.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Applications are invited for tenure-track positions at all levels across all areas of theoretical computer science. Review of applications started on 11/15/2022 and will continue until the positions is filled.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/23484">https://academicjobsonline.org/ajo/jobs/23484</a><br />
Email: ablanca@cse.psu.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T15:58:56Z">Wednesday, November 23 2022, 15:58</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2022/166'>TR22-166 |  Characterizing the Multi-Pass Streaming Complexity for Solving Boolean CSPs Exactly | 

	Raghuvansh Saxena, 

	Gillat Kol, 

	Dmitry Paramonov, 

	Huacheng Yu</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study boolean constraint satisfaction problems (CSPs) $\mathrm{Max}\text{-}\mathrm{CSP}^f_n$ for all predicates $f: \{ 0, 1 \} ^k \to \{ 0, 1 \}$. In these problems, given an integer $v$ and a list of constraints over $n$ boolean variables, each obtained by applying $f$ to a sequence of literals, we wish to decide if there is an assignment to the variables that satisfies at least $v$ constraints. We consider these problems in the streaming model, where the algorithm makes a small number of passes over the list of constraints.

Our first and main result is the following complete characterization: For every predicate $f$, the streaming space complexity of the $\mathrm{Max}\text{-}\mathrm{CSP}^f_n$ problem is $\tilde{\Theta}(n^{\mathrm{deg}(f)})$, where $\mathrm{deg}(f)$ is the degree of $f$ when viewed as a multilinear polynomial. While the upper bound is obtained by a (very simple) one-pass streaming algorithm, our lower bound shows that a better space complexity is impossible even with constant-pass streaming algorithms. 

Building on our techniques, we are also able to get an optimal $\Omega(n^2)$ lower bound on the space complexity of constant-pass streaming algorithms for the well studied $\mathrm{Max}\text{-}\mathrm{CUT}$ problem, even though it is not technically a $\mathrm{Max}\text{-}\mathrm{CSP}^f_n$ problem as, e.g., negations of variables and repeated constraints are not allowed.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study boolean constraint satisfaction problems (CSPs) $\mathrm{Max}\text{-}\mathrm{CSP}^f_n$ for all predicates $f: \{ 0, 1 \} ^k \to \{ 0, 1 \}$. In these problems, given an integer $v$ and a list of constraints over $n$ boolean variables, each obtained by applying $f$ to a sequence of literals, we wish to decide if there is an assignment to the variables that satisfies at least $v$ constraints. We consider these problems in the streaming model, where the algorithm makes a small number of passes over the list of constraints.

Our first and main result is the following complete characterization: For every predicate $f$, the streaming space complexity of the $\mathrm{Max}\text{-}\mathrm{CSP}^f_n$ problem is $\tilde{\Theta}(n^{\mathrm{deg}(f)})$, where $\mathrm{deg}(f)$ is the degree of $f$ when viewed as a multilinear polynomial. While the upper bound is obtained by a (very simple) one-pass streaming algorithm, our lower bound shows that a better space complexity is impossible even with constant-pass streaming algorithms. 

Building on our techniques, we are also able to get an optimal $\Omega(n^2)$ lower bound on the space complexity of constant-pass streaming algorithms for the well studied $\mathrm{Max}\text{-}\mathrm{CUT}$ problem, even though it is not technically a $\mathrm{Max}\text{-}\mathrm{CSP}^f_n$ problem as, e.g., negations of variables and repeated constraints are not allowed.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T07:12:10Z">Wednesday, November 23 2022, 07:12</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=6830'>Dismantling Quantum Hype with Tim Nguyen</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Happy Thanksgiving to my American readers! While I enjoy a family holiday-week vacation in exotic Dallas&#8212;and yes, I will follow up on my old JFK post by visiting Dealey Plaza&#8212;please enjoy the following Thanksgiving victuals: I recently recorded a 3-hour (!) YouTube video with Timothy Nguyen, host of the Cartesian Cafe. Our episode is entitled [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Happy Thanksgiving to my American readers!  While I enjoy a family holiday-week vacation in exotic Dallas&#8212;and yes, I <em>will</em> follow up on my old <a href="https://scottaaronson.blog/?p=1596">JFK post</a> by visiting Dealey Plaza&#8212;please enjoy the following Thanksgiving victuals:</p>



<p>I recently recorded a 3-hour (!) YouTube video with <a href="https://timothynguyen.org/">Timothy Nguyen</a>, host of the <a href="https://timothynguyen.org/videos/#cartesian-cafe">Cartesian Cafe</a>.  Our episode is entitled <a href="https://www.youtube.com/watch?v=qs0D9sdbKPU">Quantum Computing: Dismantling the Hype</a>.  In it, I teach a sort of <em>extremely</em> compressed version of my <a href="https://www.scottaaronson.com/qclec.pdf">undergraduate Intro to Quantum Information Science course</a>, unburdening myself about whatever Tim prompts me to explain: the basic rules of quantum information, <a href="https://en.wikipedia.org/wiki/Quantum_circuit">quantum circuits</a>, the <a href="https://arxiv.org/abs/1712.06349">quantum black-box model</a>, the <a href="https://en.wikipedia.org/wiki/Deutsch%E2%80%93Jozsa_algorithm">Deutsch-Jozsa algorithm</a>, <a href="https://en.wikipedia.org/wiki/BQP">BQP</a> and its relationship to classical complexity classes, and sampling-based quantum supremacy experiments.  This is a lot more technical than an average podcast, a lot <em>less</em> technical than an actual course, and hopefully just right for some nonempty subset of readers.</p>



<p>Outside of his podcasting career, some of you might recognize Nguyen as the coauthor, with Theo Polya, of a <a href="https://timothynguyen.files.wordpress.com/2021/02/geometric_unity.pdf">rebuttal of &#8220;Geometric Unity.&#8221;</a>  This latter is the proposal by the financier, podcaster, and leading &#8220;Intellectual Dark Web&#8221; figure <a href="https://en.wikipedia.org/wiki/Eric_Weinstein">Eric Weinstein</a> for a unified theory of particle physics.  Now, I slightly know Weinstein, and have even found him fascinating, eloquent, and correct about various issues.  So, in an <a href="https://www.youtube.com/watch?v=wd-0COLM8oc">addendum to the main video</a>, Nguyen chats with me about his experience critiquing Weinstein&#8217;s theory, and also about something where my knowledge is far greater: namely, my <a href="https://arxiv.org/abs/quant-ph/0206089">2002 rebuttal</a> of some of the central claims in Stephen Wolfram&#8217;s <em><a href="https://en.wikipedia.org/wiki/A_New_Kind_of_Science">A New Kind of Science</a></em>, and whether there are any updates to that story twenty years later.</p>



<p>Enjoy!</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T04:12:34Z">Wednesday, November 23 2022, 04:12</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.11839'>Celeste is PSPACE-hard</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lily Chung, Erik D. Demaine</p><p>We investigate the complexity of the platform video game Celeste. We prove
that navigating Celeste is PSPACE-hard in five different ways, corresponding to
different subsets of the game mechanics. In particular, we prove the game
PSPACE-hard even without player input.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chung_L/0/1/0/all/0/1">Lily Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Demaine_E/0/1/0/all/0/1">Erik D. Demaine</a></p><p>We investigate the complexity of the platform video game Celeste. We prove
that navigating Celeste is PSPACE-hard in five different ways, corresponding to
different subsets of the game mechanics. In particular, we prove the game
PSPACE-hard even without player input.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12447'>Quantum algorithms and the power of forgetting</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andrew M. Childs, Matthew Coudron, Amin Shiraz Gilani</p><p>The so-called welded tree problem provides an example of a black-box problem
that can be solved exponentially faster by a quantum walk than by any classical
algorithm. Given the name of a special ENTRANCE vertex, a quantum walk can find
another distinguished EXIT vertex using polynomially many queries, though
without finding any particular path from ENTRANCE to EXIT. It has been an open
problem for twenty years whether there is an efficient quantum algorithm for
finding such a path, or if the path-finding problem is hard even for quantum
computers. We show that a natural class of efficient quantum algorithms
provably cannot find a path from ENTRANCE to EXIT. Specifically, we consider
algorithms that, within each branch of their superposition, always store a set
of vertex labels that form a connected subgraph including the ENTRANCE, and
that only provide these vertex labels as inputs to the oracle. While this does
not rule out the possibility of a quantum algorithm that efficiently finds a
path, it is unclear how an algorithm could benefit by deviating from this
behavior. Our no-go result suggests that, for some problems, quantum algorithms
must necessarily forget the path they take to reach a solution in order to
outperform classical computation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Childs_A/0/1/0/all/0/1">Andrew M. Childs</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Coudron_M/0/1/0/all/0/1">Matthew Coudron</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Gilani_A/0/1/0/all/0/1">Amin Shiraz Gilani</a></p><p>The so-called welded tree problem provides an example of a black-box problem
that can be solved exponentially faster by a quantum walk than by any classical
algorithm. Given the name of a special ENTRANCE vertex, a quantum walk can find
another distinguished EXIT vertex using polynomially many queries, though
without finding any particular path from ENTRANCE to EXIT. It has been an open
problem for twenty years whether there is an efficient quantum algorithm for
finding such a path, or if the path-finding problem is hard even for quantum
computers. We show that a natural class of efficient quantum algorithms
provably cannot find a path from ENTRANCE to EXIT. Specifically, we consider
algorithms that, within each branch of their superposition, always store a set
of vertex labels that form a connected subgraph including the ENTRANCE, and
that only provide these vertex labels as inputs to the oracle. While this does
not rule out the possibility of a quantum algorithm that efficiently finds a
path, it is unclear how an algorithm could benefit by deviating from this
behavior. Our no-go result suggests that, for some problems, quantum algorithms
must necessarily forget the path they take to reach a solution in order to
outperform classical computation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12456'>Exponential separations using guarded extension variables</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Emre Yolcu, Marijn J.H. Heule</p><p>We study the complexity of proof systems augmenting resolution with inference
rules that allow, given a formula $\Gamma$ in conjunctive normal form, deriving
clauses that are not necessarily logically implied by $\Gamma$ but whose
addition to $\Gamma$ preserves satisfiability. When the derived clauses are
allowed to introduce variables not occurring in $\Gamma$, the systems we
consider become equivalent to extended resolution. We are concerned with the
versions of these systems without new variables. They are called BC${}^-$,
RAT${}^-$, SBC${}^-$, and GER${}^-$, denoting respectively blocked clauses,
resolution asymmetric tautologies, set-blocked clauses, and generalized
extended resolution. Each of these systems formalizes some restricted version
of the ability to make assumptions that hold "without loss of generality,"
which is commonly used informally to simplify or shorten proofs.
</p>
<p>Except for SBC${}^-$, these systems are known to be exponentially weaker than
extended resolution. They are, however, all equivalent to it under a relaxed
notion of simulation that allows the translation of the formula along with the
proof when moving between proof systems. By taking advantage of this fact, we
construct formulas that separate RAT${}^-$ from GER${}^-$ and vice versa. With
the same strategy, we also separate SBC${}^-$ from RAT${}^-$. Additionally, we
give polynomial-size SBC${}^-$ proofs of the pigeonhole principle, which
separates SBC${}^-$ from GER${}^-$ by a previously known lower bound. These
results also separate the three systems from BC${}^-$ since they all simulate
it. We thus give an almost complete picture of their relative strengths.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yolcu_E/0/1/0/all/0/1">Emre Yolcu</a>, <a href="http://arxiv.org/find/cs/1/au:+Heule_M/0/1/0/all/0/1">Marijn J.H. Heule</a></p><p>We study the complexity of proof systems augmenting resolution with inference
rules that allow, given a formula $\Gamma$ in conjunctive normal form, deriving
clauses that are not necessarily logically implied by $\Gamma$ but whose
addition to $\Gamma$ preserves satisfiability. When the derived clauses are
allowed to introduce variables not occurring in $\Gamma$, the systems we
consider become equivalent to extended resolution. We are concerned with the
versions of these systems without new variables. They are called BC${}^-$,
RAT${}^-$, SBC${}^-$, and GER${}^-$, denoting respectively blocked clauses,
resolution asymmetric tautologies, set-blocked clauses, and generalized
extended resolution. Each of these systems formalizes some restricted version
of the ability to make assumptions that hold "without loss of generality,"
which is commonly used informally to simplify or shorten proofs.
</p>
<p>Except for SBC${}^-$, these systems are known to be exponentially weaker than
extended resolution. They are, however, all equivalent to it under a relaxed
notion of simulation that allows the translation of the formula along with the
proof when moving between proof systems. By taking advantage of this fact, we
construct formulas that separate RAT${}^-$ from GER${}^-$ and vice versa. With
the same strategy, we also separate SBC${}^-$ from RAT${}^-$. Additionally, we
give polynomial-size SBC${}^-$ proofs of the pigeonhole principle, which
separates SBC${}^-$ from GER${}^-$ by a previously known lower bound. These
results also separate the three systems from BC${}^-$ since they all simulate
it. We thus give an almost complete picture of their relative strengths.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.11987'>The Tight Spanning Ratio of the Rectangle Delaunay Triangulation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andr&#xe8; van Renssen, Yuan Sha, Yucheng Sun, Sampson Wong</p><p>Spanner construction is a well-studied problem and Delaunay triangulations
are among the most popular spanners. Tight bounds are known if the Delaunay
triangulation is constructed using an equilateral triangle, a square, or a
regular hexagon. However, all other shapes have remained elusive. In this paper
we extend the restricted class of spanners for which tight bounds are known. We
prove that Delaunay triangulations constructed using rectangles with aspect
ratio $\A$ have spanning ratio at most $\sqrt{2} \sqrt{1+\A^2 + \A \sqrt{\A^2 +
1}}$, which matches the known lower bound.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Renssen_A/0/1/0/all/0/1">Andr&#xe8; van Renssen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sha_Y/0/1/0/all/0/1">Yuan Sha</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yucheng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_S/0/1/0/all/0/1">Sampson Wong</a></p><p>Spanner construction is a well-studied problem and Delaunay triangulations
are among the most popular spanners. Tight bounds are known if the Delaunay
triangulation is constructed using an equilateral triangle, a square, or a
regular hexagon. However, all other shapes have remained elusive. In this paper
we extend the restricted class of spanners for which tight bounds are known. We
prove that Delaunay triangulations constructed using rectangles with aspect
ratio $\A$ have spanning ratio at most $\sqrt{2} \sqrt{1+\A^2 + \A \sqrt{\A^2 +
1}}$, which matches the known lower bound.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12203'>Edge Multiway Cut and Node Multiway Cut are NP-complete on subcubic graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Matthew Johnson, Barnaby Martin, Siani Smith, Sukanya Pandey, Daniel Paulusma, Erik Jan van Leeuwen</p><p>We show that Edge Multiway Cut (also called Multiterminal Cut) and Node
Multiway Cut are NP-complete on graphs of maximum degree $3$ (also known as
subcubic graphs). This improves on a previous degree bound of $11$. Our
NP-completeness result holds even for subcubic graphs that are planar.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1">Matthew Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_B/0/1/0/all/0/1">Barnaby Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_S/0/1/0/all/0/1">Siani Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_S/0/1/0/all/0/1">Sukanya Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Paulusma_D/0/1/0/all/0/1">Daniel Paulusma</a>, <a href="http://arxiv.org/find/cs/1/au:+Leeuwen_E/0/1/0/all/0/1">Erik Jan van Leeuwen</a></p><p>We show that Edge Multiway Cut (also called Multiterminal Cut) and Node
Multiway Cut are NP-complete on graphs of maximum degree $3$ (also known as
subcubic graphs). This improves on a previous degree bound of $11$. Our
NP-completeness result holds even for subcubic graphs that are planar.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.11846'>Labeled Nearest Neighbor Search and Metric Spanners via Locality Sensitive Orderings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arnold Filtser</p><p>Chan, Har-Peled, and Jones [SICOMP 2020] developed locality-sensitive
orderings (LSO) for Euclidean space. A $(\tau,\rho)$-LSO is a collection
$\Sigma$ of orderings such that for every $x,y\in\mathbb{R}^d$ there is an
ordering $\sigma\in\Sigma$, where all the points between $x$ and $y$ w.r.t.
$\sigma$ are in the $\rho$-neighborhood of either $x$ or $y$. In essence, LSO
allow one to reduce problems to the $1$-dimensional line. Later, Filtser and Le
[STOC 2022] developed LSO's for doubling metrics, general metric spaces, and
minor free graphs.
</p>
<p>For Euclidean and doubling spaces, the number of orderings in the LSO is
exponential in the dimension, which made them mainly useful for the low
dimensional regime. In this paper, we develop new LSO's for Euclidean,
$\ell_p$, and doubling spaces that allow us to trade larger stretch for a much
smaller number of orderings. We then use our new LSO's (as well as the previous
ones) to construct path reporting low hop spanners, fault tolerant spanners,
reliable spanners, and light spanners for different metric spaces.
</p>
<p>While many nearest neighbor search (NNS) data structures were constructed for
metric spaces with implicit distance representations (where the distance
between two metric points can be computed using their names, e.g. Euclidean
space), for other spaces almost nothing is known. In this paper we initiate the
study of the labeled NNS problem, where one is allowed to artificially assign
labels (short names) to metric points. We use LSO's to construct efficient
labeled NNS data structures in this model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Filtser_A/0/1/0/all/0/1">Arnold Filtser</a></p><p>Chan, Har-Peled, and Jones [SICOMP 2020] developed locality-sensitive
orderings (LSO) for Euclidean space. A $(\tau,\rho)$-LSO is a collection
$\Sigma$ of orderings such that for every $x,y\in\mathbb{R}^d$ there is an
ordering $\sigma\in\Sigma$, where all the points between $x$ and $y$ w.r.t.
$\sigma$ are in the $\rho$-neighborhood of either $x$ or $y$. In essence, LSO
allow one to reduce problems to the $1$-dimensional line. Later, Filtser and Le
[STOC 2022] developed LSO's for doubling metrics, general metric spaces, and
minor free graphs.
</p>
<p>For Euclidean and doubling spaces, the number of orderings in the LSO is
exponential in the dimension, which made them mainly useful for the low
dimensional regime. In this paper, we develop new LSO's for Euclidean,
$\ell_p$, and doubling spaces that allow us to trade larger stretch for a much
smaller number of orderings. We then use our new LSO's (as well as the previous
ones) to construct path reporting low hop spanners, fault tolerant spanners,
reliable spanners, and light spanners for different metric spaces.
</p>
<p>While many nearest neighbor search (NNS) data structures were constructed for
metric spaces with implicit distance representations (where the distance
between two metric points can be computed using their names, e.g. Euclidean
space), for other spaces almost nothing is known. In this paper we initiate the
study of the labeled NNS problem, where one is allowed to artificially assign
labels (short names) to metric points. We use LSO's to construct efficient
labeled NNS data structures in this model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.11923'>Towards Optimal Coreset Construction for $(k,z)$-Clustering: Breaking the Quadratic Dependency on $k$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lingxiao Huang, Jian Li, Xuan Wu</p><p>Constructing small-sized coresets for various clustering problems has
attracted significant attention recently. We provide efficient coreset
construction algorithms for $(k, z)$-Clustering with improved coreset sizes in
several metric spaces. In particular, we provide an
$\tilde{O}_z(k^{(2z+2)/(z+2)}\varepsilon^{-2})$-sized coreset for $(k,
z)$-Clustering for all $z\geq 1$ in Euclidean space, improving upon the best
known $\tilde{O}_z(k^2\varepsilon^{-2})$ size upper bound [Cohen-Addad, Larsen,
Saulpic, Schwiegelshohn. STOC'22], breaking the quadratic dependency on $k$ for
the first time (when $k\leq \varepsilon^{-1}$). For example, our coreset size
for Euclidean $k$-Median is $\tilde{O}(k^{4/3} \varepsilon^{-2})$, improving
the best known result $\tilde{O}(\min\left\{k^2\varepsilon^{-2},
k\varepsilon^{-3}\right\})$ by a factor $k^{2/3}$ when $k\leq
\varepsilon^{-1}$; for Euclidean $k$-Means, our coreset size is
$\tilde{O}(k^{3/2} \varepsilon^{-2})$, improving the best known result
$\tilde{O}(\min\left\{k^2\varepsilon^{-2}, k\varepsilon^{-4}\right\})$ by a
factor $k^{1/2}$ when $k\leq \varepsilon^{-2}$. We also obtain optimal or
improved coreset sizes for general metric space, metric space with bounded
doubling dimension, and shortest path metric when the underlying graph has
bounded treewidth, for all $z\geq 1$. Our algorithm largely follows the
framework developed by Cohen-Addad et al. with some minor but useful changes.
Our technical contribution mainly lies in the analysis. An important
improvement in our analysis is a new notion of $\alpha$-covering of distance
vectors with a novel error metric, which allows us to provide a tighter
variance bound. Another useful technical ingredient is terminal embedding with
additive errors, for bounding the covering number in the Euclidean case.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xuan Wu</a></p><p>Constructing small-sized coresets for various clustering problems has
attracted significant attention recently. We provide efficient coreset
construction algorithms for $(k, z)$-Clustering with improved coreset sizes in
several metric spaces. In particular, we provide an
$\tilde{O}_z(k^{(2z+2)/(z+2)}\varepsilon^{-2})$-sized coreset for $(k,
z)$-Clustering for all $z\geq 1$ in Euclidean space, improving upon the best
known $\tilde{O}_z(k^2\varepsilon^{-2})$ size upper bound [Cohen-Addad, Larsen,
Saulpic, Schwiegelshohn. STOC'22], breaking the quadratic dependency on $k$ for
the first time (when $k\leq \varepsilon^{-1}$). For example, our coreset size
for Euclidean $k$-Median is $\tilde{O}(k^{4/3} \varepsilon^{-2})$, improving
the best known result $\tilde{O}(\min\left\{k^2\varepsilon^{-2},
k\varepsilon^{-3}\right\})$ by a factor $k^{2/3}$ when $k\leq
\varepsilon^{-1}$; for Euclidean $k$-Means, our coreset size is
$\tilde{O}(k^{3/2} \varepsilon^{-2})$, improving the best known result
$\tilde{O}(\min\left\{k^2\varepsilon^{-2}, k\varepsilon^{-4}\right\})$ by a
factor $k^{1/2}$ when $k\leq \varepsilon^{-2}$. We also obtain optimal or
improved coreset sizes for general metric space, metric space with bounded
doubling dimension, and shortest path metric when the underlying graph has
bounded treewidth, for all $z\geq 1$. Our algorithm largely follows the
framework developed by Cohen-Addad et al. with some minor but useful changes.
Our technical contribution mainly lies in the analysis. An important
improvement in our analysis is a new notion of $\alpha$-covering of distance
vectors with a novel error metric, which allows us to provide a tighter
variance bound. Another useful technical ingredient is terminal embedding with
additive errors, for bounding the covering number in the Euclidean case.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.11856'>String Covering: A Survey</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Neerja Mhaskar, W. F. Smyth</p><p>The study of strings is an important combinatorial field that precedes the
digital computer. Strings can be very long, trillions of letters, so it is
important to find compact representations. Here we first survey various forms
of one potential compaction methodology, the cover of a given string x,
initially proposed in a simple form in 1990, but increasingly of interest as
more sophisticated variants have been discovered. We then consider covering by
a seed; that is, a cover of a superstring of x. We conclude with many proposals
for research directions that could make significant contributions to string
processing in future.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mhaskar_N/0/1/0/all/0/1">Neerja Mhaskar</a>, <a href="http://arxiv.org/find/cs/1/au:+Smyth_W/0/1/0/all/0/1">W. F. Smyth</a></p><p>The study of strings is an important combinatorial field that precedes the
digital computer. Strings can be very long, trillions of letters, so it is
important to find compact representations. Here we first survey various forms
of one potential compaction methodology, the cover of a given string x,
initially proposed in a simple form in 1990, but increasingly of interest as
more sophisticated variants have been discovered. We then consider covering by
a seed; that is, a cover of a superstring of x. We conclude with many proposals
for research directions that could make significant contributions to string
processing in future.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.11860'>Upper and Lower Bounds on the Smoothed Complexity of the Simplex Method</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sophie Huiberts, Yin Tat Lee, Xinzhi Zhang</p><p>The simplex method for linear programming is known to be highly efficient in
practice, and understanding its performance from a theoretical perspective is
an active research topic. The framework of smoothed analysis, first introduced
by Spielman and Teng (JACM '04) for this purpose, defines the smoothed
complexity of solving a linear program with $d$ variables and $n$ constraints
as the expected running time when Gaussian noise of variance $\sigma^2$ is
added to the LP data. We prove that the smoothed complexity of the simplex
method is $O(\sigma^{-3/2} d^{13/4}\log^{7/4} n)$, improving the dependence on
$1/\sigma$ compared to the previous bound of $O(\sigma^{-2} d^2\sqrt{\log n})$.
We accomplish this through a new analysis of the \emph{shadow bound}, key to
earlier analyses as well. Illustrating the power of our new method, we use our
method to prove a nearly tight upper bound on the smoothed complexity of
two-dimensional polygons.
</p>
<p>We also establish the first non-trivial lower bound on the smoothed
complexity of the simplex method, proving that the \emph{shadow vertex simplex
method} requires at least $\Omega \Big(\min \big(\sigma^{-1/2}
d^{-1/2}\log^{-1/4} d,2^d \big) \Big)$ pivot steps with high probability. A key
part of our analysis is a new variation on the extended formulation for the
regular $2^k$-gon. We end with a numerical experiment that suggests this
analysis could be further improved.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huiberts_S/0/1/0/all/0/1">Sophie Huiberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yin Tat Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinzhi Zhang</a></p><p>The simplex method for linear programming is known to be highly efficient in
practice, and understanding its performance from a theoretical perspective is
an active research topic. The framework of smoothed analysis, first introduced
by Spielman and Teng (JACM '04) for this purpose, defines the smoothed
complexity of solving a linear program with $d$ variables and $n$ constraints
as the expected running time when Gaussian noise of variance $\sigma^2$ is
added to the LP data. We prove that the smoothed complexity of the simplex
method is $O(\sigma^{-3/2} d^{13/4}\log^{7/4} n)$, improving the dependence on
$1/\sigma$ compared to the previous bound of $O(\sigma^{-2} d^2\sqrt{\log n})$.
We accomplish this through a new analysis of the \emph{shadow bound}, key to
earlier analyses as well. Illustrating the power of our new method, we use our
method to prove a nearly tight upper bound on the smoothed complexity of
two-dimensional polygons.
</p>
<p>We also establish the first non-trivial lower bound on the smoothed
complexity of the simplex method, proving that the \emph{shadow vertex simplex
method} requires at least $\Omega \Big(\min \big(\sigma^{-1/2}
d^{-1/2}\log^{-1/4} d,2^d \big) \Big)$ pivot steps with high probability. A key
part of our analysis is a new variation on the extended formulation for the
regular $2^k$-gon. We end with a numerical experiment that suggests this
analysis could be further improved.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.11912'>Quasi-stable Coloring for Graph Compression: Approximating Max-Flow, Linear Programs, and Centrality</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Moe Kayali, Dan Suciu</p><p>We propose quasi-stable coloring, an approximate version of stable coloring.
Stable coloring, also called color refinement, is a well-studied technique in
graph theory for classifying vertices, which can be used to build compact,
lossless representations of graphs. However, its usefulness is limited due to
its reliance on strict symmetries. Real data compresses very poorly using color
refinement. We propose the first, to our knowledge, approximate color
refinement scheme, which we call quasi-stable coloring. By using approximation,
we alleviate the need for strict symmetry, and allow for a tradeoff between the
degree of compression and the accuracy of the representation. We study three
applications: Linear Programming, Max-Flow, and Betweenness Centrality, and
provide theoretical evidence in each case that a quasi-stable coloring can lead
to good approximations on the reduced graph. Next, we consider how to compute a
maximal quasi-stable coloring: we prove that, in general, this problem is
NP-hard, and propose a simple, yet effective algorithm based on heuristics.
Finally, we evaluate experimentally the quasi-stable coloring technique on
several real graphs and applications, comparing with prior approximation
techniques.
</p>
<p>A reference implementation and the experiment code are available at
github.com/mkyl/QuasiStableColors.jl
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kayali_M/0/1/0/all/0/1">Moe Kayali</a>, <a href="http://arxiv.org/find/cs/1/au:+Suciu_D/0/1/0/all/0/1">Dan Suciu</a></p><p>We propose quasi-stable coloring, an approximate version of stable coloring.
Stable coloring, also called color refinement, is a well-studied technique in
graph theory for classifying vertices, which can be used to build compact,
lossless representations of graphs. However, its usefulness is limited due to
its reliance on strict symmetries. Real data compresses very poorly using color
refinement. We propose the first, to our knowledge, approximate color
refinement scheme, which we call quasi-stable coloring. By using approximation,
we alleviate the need for strict symmetry, and allow for a tradeoff between the
degree of compression and the accuracy of the representation. We study three
applications: Linear Programming, Max-Flow, and Betweenness Centrality, and
provide theoretical evidence in each case that a quasi-stable coloring can lead
to good approximations on the reduced graph. Next, we consider how to compute a
maximal quasi-stable coloring: we prove that, in general, this problem is
NP-hard, and propose a simple, yet effective algorithm based on heuristics.
Finally, we evaluate experimentally the quasi-stable coloring technique on
several real graphs and applications, comparing with prior approximation
techniques.
</p>
<p>A reference implementation and the experiment code are available at
https://github.com/mkyl/QuasiStableColors.jl
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.11961'>Online facility location with timed-requests and congestion</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arghya Chakraborty, Rahul Vaze</p><p>The classic online facility location problem deals with finding the optimal
set of facilities in an online fashion when demand requests arrive one at a
time and facilities need to be opened to service these requests. In this work,
we study two variants of the online facility location problem; (1) timed
requests and (2) congestion. Both of these variants are motivated by the
applications to real life and the previously known results on online facility
location cannot be directly adapted to analyse them.
</p>
<p>Timed requests : In this variant, each demand request is a pair $(x,t)$ where
the $x$ is the standard location of the demand while $t$ is the corresponding
weight of the request. The cost of servicing request $(x,t)$ at facility $F$ is
$t\cdot d(x,F')$ where $F'$ is the set of facilities available at the time of
request $(x,t)$. For this variant, we present an online algorithm attaining a
competitive ratio of $\mathcal{O}(\log n)$ in the secretarial model for the
timed requests and show that it is optimal.
</p>
<p>Congestion : The congestion variant considers the case when there is an
additional congestion cost that grows with the number of requests served by
each request. For this variant, when the congestion cost is a monomial, we show
that there exists an algorithm attaining a constant competitive ratio. This
constant is a function of the exponent of the monomial and the facility opening
cost but independent of the number of requests.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1">Arghya Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaze_R/0/1/0/all/0/1">Rahul Vaze</a></p><p>The classic online facility location problem deals with finding the optimal
set of facilities in an online fashion when demand requests arrive one at a
time and facilities need to be opened to service these requests. In this work,
we study two variants of the online facility location problem; (1) timed
requests and (2) congestion. Both of these variants are motivated by the
applications to real life and the previously known results on online facility
location cannot be directly adapted to analyse them.
</p>
<p>Timed requests : In this variant, each demand request is a pair $(x,t)$ where
the $x$ is the standard location of the demand while $t$ is the corresponding
weight of the request. The cost of servicing request $(x,t)$ at facility $F$ is
$t\cdot d(x,F')$ where $F'$ is the set of facilities available at the time of
request $(x,t)$. For this variant, we present an online algorithm attaining a
competitive ratio of $\mathcal{O}(\log n)$ in the secretarial model for the
timed requests and show that it is optimal.
</p>
<p>Congestion : The congestion variant considers the case when there is an
additional congestion cost that grows with the number of requests served by
each request. For this variant, when the congestion cost is a monomial, we show
that there exists an algorithm attaining a constant competitive ratio. This
constant is a function of the exponent of the monomial and the facility opening
cost but independent of the number of requests.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.11967'>Support Size Estimation: The Power of Conditioning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Diptarka Chakraborty, Gunjan Kumar, Kuldeep S. Meel</p><p>We consider the problem of estimating the support size of a distribution $D$.
Our investigations are pursued through the lens of distribution testing and
seek to understand the power of conditional sampling (denoted as COND), wherein
one is allowed to query the given distribution conditioned on an arbitrary
subset $S$. The primary contribution of this work is to introduce a new
approach to lower bounds for the COND model that relies on using powerful tools
from information theory and communication complexity.
</p>
<p>Our approach allows us to obtain surprisingly strong lower bounds for the
COND model and its extensions.
</p>
<p>1) We bridge the longstanding gap between the upper ($O(\log \log n +
\frac{1}{\epsilon^2})$) and the lower bound $\Omega(\sqrt{\log \log n})$ for
COND model by providing a nearly matching lower bound. Surprisingly, we show
that even if we get to know the actual probabilities along with COND samples,
still $\Omega(\log \log n + \frac{1}{\epsilon^2 \log (1/\epsilon)})$ queries
are necessary.
</p>
<p>2) We obtain the first non-trivial lower bound for COND equipped with an
additional oracle that reveals the conditional probabilities of the samples (to
the best of our knowledge, this subsumes all of the models previously studied):
in particular, we demonstrate that $\Omega(\log \log \log n +
\frac{1}{\epsilon^2 \log (1/\epsilon)})$ queries are necessary.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1">Diptarka Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1">Gunjan Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Meel_K/0/1/0/all/0/1">Kuldeep S. Meel</a></p><p>We consider the problem of estimating the support size of a distribution $D$.
Our investigations are pursued through the lens of distribution testing and
seek to understand the power of conditional sampling (denoted as COND), wherein
one is allowed to query the given distribution conditioned on an arbitrary
subset $S$. The primary contribution of this work is to introduce a new
approach to lower bounds for the COND model that relies on using powerful tools
from information theory and communication complexity.
</p>
<p>Our approach allows us to obtain surprisingly strong lower bounds for the
COND model and its extensions.
</p>
<p>1) We bridge the longstanding gap between the upper ($O(\log \log n +
\frac{1}{\epsilon^2})$) and the lower bound $\Omega(\sqrt{\log \log n})$ for
COND model by providing a nearly matching lower bound. Surprisingly, we show
that even if we get to know the actual probabilities along with COND samples,
still $\Omega(\log \log n + \frac{1}{\epsilon^2 \log (1/\epsilon)})$ queries
are necessary.
</p>
<p>2) We obtain the first non-trivial lower bound for COND equipped with an
additional oracle that reveals the conditional probabilities of the samples (to
the best of our knowledge, this subsumes all of the models previously studied):
in particular, we demonstrate that $\Omega(\log \log \log n +
\frac{1}{\epsilon^2 \log (1/\epsilon)})$ queries are necessary.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12063'>Generalized Private Selection and Testing with High Confidence</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Edith Cohen, Xin Lyu, Jelani Nelson, Tam&#xe1;s Sarl&#xf3;s, Uri Stemmer</p><p>Composition theorems are general and powerful tools that facilitate privacy
accounting across multiple data accesses from per-access privacy bounds.
However they often result in weaker bounds compared with end-to-end analysis.
Two popular tools that mitigate that are the exponential mechanism (or report
noisy max) and the sparse vector technique, generalized in a recent private
selection framework by Liu and Talwar (STOC 2019). In this work, we propose a
flexible framework of private selection and testing that generalizes the one
proposed by Liu and Talwar, supporting a wide range of applications. We apply
our framework to solve several fundamental tasks, including query releasing,
top-$k$ selection, and stable selection, with improved confidence-accuracy
tradeoffs. Additionally, for online settings, we apply our private testing to
design a mechanism for adaptive query releasing, which improves the sample
complexity dependence on the confidence parameter for the celebrated private
multiplicative weights algorithm of Hardt and Rothblum (FOCS 2010).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cohen_E/0/1/0/all/0/1">Edith Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1">Xin Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nelson_J/0/1/0/all/0/1">Jelani Nelson</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarlos_T/0/1/0/all/0/1">Tam&#xe1;s Sarl&#xf3;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1">Uri Stemmer</a></p><p>Composition theorems are general and powerful tools that facilitate privacy
accounting across multiple data accesses from per-access privacy bounds.
However they often result in weaker bounds compared with end-to-end analysis.
Two popular tools that mitigate that are the exponential mechanism (or report
noisy max) and the sparse vector technique, generalized in a recent private
selection framework by Liu and Talwar (STOC 2019). In this work, we propose a
flexible framework of private selection and testing that generalizes the one
proposed by Liu and Talwar, supporting a wide range of applications. We apply
our framework to solve several fundamental tasks, including query releasing,
top-$k$ selection, and stable selection, with improved confidence-accuracy
tradeoffs. Additionally, for online settings, we apply our private testing to
design a mechanism for adaptive query releasing, which improves the sample
complexity dependence on the confidence parameter for the celebrated private
multiplicative weights algorithm of Hardt and Rothblum (FOCS 2010).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12101'>Efficient Sampling Algorithms for Approximate Motif Counting in Temporal Graph Streams</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jingjing Wang, Yanhao Wang, Wenjun Jiang, Yuchen Li, Kian-Lee Tan</p><p>A great variety of complex systems, from user interactions in communication
networks to transactions in financial markets, can be modeled as temporal
graphs consisting of a set of vertices and a series of timestamped and directed
edges. Temporal motifs are generalized from subgraph patterns in static graphs
which consider edge orderings and durations in addition to topologies. Counting
the number of occurrences of temporal motifs is a fundamental problem for
temporal network analysis. However, existing methods either cannot support
temporal motifs or suffer from performance issues. Moreover, they cannot work
in the streaming model where edges are observed incrementally over time. In
this paper, we focus on approximate temporal motif counting via random
sampling. We first propose two sampling algorithms for temporal motif counting
in the offline setting. The first is an edge sampling (ES) algorithm for
estimating the number of instances of any temporal motif. The second is an
improved edge-wedge sampling (EWS) algorithm that hybridizes edge sampling with
wedge sampling for counting temporal motifs with $3$ vertices and $3$ edges.
Furthermore, we propose two algorithms to count temporal motifs incrementally
in temporal graph streams by extending the ES and EWS algorithms referred to as
SES and SEWS. We provide comprehensive analyses of the theoretical bounds and
complexities of our proposed algorithms. Finally, we perform extensive
experimental evaluations of our proposed algorithms on several real-world
temporal graphs. The results show that ES and EWS have higher efficiency,
better accuracy, and greater scalability than state-of-the-art sampling methods
for temporal motif counting in the offline setting. Moreover, SES and SEWS
achieve up to three orders of magnitude speedups over ES and EWS while having
comparable estimation errors for temporal motif counting in the streaming
setting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingjing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Wenjun Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuchen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_K/0/1/0/all/0/1">Kian-Lee Tan</a></p><p>A great variety of complex systems, from user interactions in communication
networks to transactions in financial markets, can be modeled as temporal
graphs consisting of a set of vertices and a series of timestamped and directed
edges. Temporal motifs are generalized from subgraph patterns in static graphs
which consider edge orderings and durations in addition to topologies. Counting
the number of occurrences of temporal motifs is a fundamental problem for
temporal network analysis. However, existing methods either cannot support
temporal motifs or suffer from performance issues. Moreover, they cannot work
in the streaming model where edges are observed incrementally over time. In
this paper, we focus on approximate temporal motif counting via random
sampling. We first propose two sampling algorithms for temporal motif counting
in the offline setting. The first is an edge sampling (ES) algorithm for
estimating the number of instances of any temporal motif. The second is an
improved edge-wedge sampling (EWS) algorithm that hybridizes edge sampling with
wedge sampling for counting temporal motifs with $3$ vertices and $3$ edges.
Furthermore, we propose two algorithms to count temporal motifs incrementally
in temporal graph streams by extending the ES and EWS algorithms referred to as
SES and SEWS. We provide comprehensive analyses of the theoretical bounds and
complexities of our proposed algorithms. Finally, we perform extensive
experimental evaluations of our proposed algorithms on several real-world
temporal graphs. The results show that ES and EWS have higher efficiency,
better accuracy, and greater scalability than state-of-the-art sampling methods
for temporal motif counting in the offline setting. Moreover, SES and SEWS
achieve up to three orders of magnitude speedups over ES and EWS while having
comparable estimation errors for temporal motif counting in the streaming
setting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12136'>Minimum-Cost Temporal Walks under Waiting-Time Constraints in Linear Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Filippo Brunelli (UPCit&#xe9;, IRIF (UMR\_8243)), Laurent Viennot (UPCit&#xe9;, IRIF (UMR\_8243))</p><p>In a temporal graph, each edge is available at specific points in time. Such
an availability point is often represented by a ''temporal edge'' that can be
traversed from its tail only at a specific departure time, for arriving in its
head after a specific travel time. In such a graph, the connectivity from one
node to another is naturally captured by the existence of a temporal path where
temporal edges can be traversed one after the other. When imposing constraints
on how much time it is possible to wait at a node in-between two temporal
edges, it then becomes interesting to consider temporal walks where it is
allowed to visit several times the same node, possibly at different times. We
study the complexity of computing minimum-cost temporal walks from a single
source under waiting-time constraints in a temporal graph, and ask under which
conditions this problem can be solved in linear time. Our main result is a
linear time algorithm when temporal edges are provided in input by
non-decreasing departure time and also by non-decreasing arrival time. We use
an algebraic framework for manipulating abstract costs, enabling the
optimization of a large variety of criteria or even combinations of these. It
allows to improve previous results for several criteria such as number of edges
or overall waiting time. This result is somehow optimal: a logarithmic factor
in the time complexity appears to be necessary if the input contains only one
ordering of the temporal edges (either by arrival times or departure times).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brunelli_F/0/1/0/all/0/1">Filippo Brunelli</a> (UPCit&#xe9;, IRIF (UMR\_8243)), <a href="http://arxiv.org/find/cs/1/au:+Viennot_L/0/1/0/all/0/1">Laurent Viennot</a> (UPCit&#xe9;, IRIF (UMR\_8243))</p><p>In a temporal graph, each edge is available at specific points in time. Such
an availability point is often represented by a ''temporal edge'' that can be
traversed from its tail only at a specific departure time, for arriving in its
head after a specific travel time. In such a graph, the connectivity from one
node to another is naturally captured by the existence of a temporal path where
temporal edges can be traversed one after the other. When imposing constraints
on how much time it is possible to wait at a node in-between two temporal
edges, it then becomes interesting to consider temporal walks where it is
allowed to visit several times the same node, possibly at different times. We
study the complexity of computing minimum-cost temporal walks from a single
source under waiting-time constraints in a temporal graph, and ask under which
conditions this problem can be solved in linear time. Our main result is a
linear time algorithm when temporal edges are provided in input by
non-decreasing departure time and also by non-decreasing arrival time. We use
an algebraic framework for manipulating abstract costs, enabling the
optimization of a large variety of criteria or even combinations of these. It
allows to improve previous results for several criteria such as number of edges
or overall waiting time. This result is somehow optimal: a logarithmic factor
in the time complexity appears to be necessary if the input contains only one
ordering of the temporal edges (either by arrival times or departure times).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12225'>Reversible Programming: A Case Study of Two String-Matching Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Robert Gl&#xfc;ck (Copenhagen University), Tetsuo Yokoyama (Nanzan University)</p><p>String matching is a fundamental problem in algorithm. This study examines
the development and construction of two reversible string-matching algorithms:
a naive string-matching algorithm and the Rabin-Karp algorithm. The algorithms
are used to introduce reversible computing concepts, beginning from basic
reversible programming techniques to more advanced considerations about the
injectivization of the polynomial hash-update function employed by the
Rabin-Karp algorithm. The results are two clean input-preserving reversible
algorithms that require no additional space and have the same asymptotic time
complexity as their classic irreversible originals. This study aims to
contribute to the body of reversible algorithms and to the discipline of
reversible programming.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gluck_R/0/1/0/all/0/1">Robert Gl&#xfc;ck</a> (Copenhagen University), <a href="http://arxiv.org/find/cs/1/au:+Yokoyama_T/0/1/0/all/0/1">Tetsuo Yokoyama</a> (Nanzan University)</p><p>String matching is a fundamental problem in algorithm. This study examines
the development and construction of two reversible string-matching algorithms:
a naive string-matching algorithm and the Rabin-Karp algorithm. The algorithms
are used to introduce reversible computing concepts, beginning from basic
reversible programming techniques to more advanced considerations about the
injectivization of the polynomial hash-update function employed by the
Rabin-Karp algorithm. The results are two clean input-preserving reversible
algorithms that require no additional space and have the same asymptotic time
complexity as their classic irreversible originals. This study aims to
contribute to the body of reversible algorithms and to the discipline of
reversible programming.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12226'>On Structural Parameterizations of Star Coloring</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sriram Bhyravarapu, I. Vinod Reddy</p><p>A Star Coloring of a graph G is a proper vertex coloring such that every path
on four vertices uses at least three distinct colors. The minimum number of
colors required for such a star coloring of G is called star chromatic number,
denoted by \chi_s(G). Given a graph G and a positive integer k, the STAR
COLORING PROBLEM asks whether $G$ has a star coloring using at most k colors.
This problem is NP-complete even on restricted graph classes such as bipartite
graphs.
</p>
<p>In this paper, we initiate a study of STAR COLORING from the parameterized
complexity perspective. We show that STAR COLORING is fixed-parameter tractable
when parameterized by (a) neighborhood diversity, (b) twin-cover, and (c) the
combined parameters clique-width and the number of colors.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhyravarapu_S/0/1/0/all/0/1">Sriram Bhyravarapu</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_I/0/1/0/all/0/1">I. Vinod Reddy</a></p><p>A Star Coloring of a graph G is a proper vertex coloring such that every path
on four vertices uses at least three distinct colors. The minimum number of
colors required for such a star coloring of G is called star chromatic number,
denoted by \chi_s(G). Given a graph G and a positive integer k, the STAR
COLORING PROBLEM asks whether $G$ has a star coloring using at most k colors.
This problem is NP-complete even on restricted graph classes such as bipartite
graphs.
</p>
<p>In this paper, we initiate a study of STAR COLORING from the parameterized
complexity perspective. We show that STAR COLORING is fixed-parameter tractable
when parameterized by (a) neighborhood diversity, (b) twin-cover, and (c) the
combined parameters clique-width and the number of colors.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12389'>The Burer-Monteiro SDP method can fail even above the Barvinok-Pataki bound</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Liam O&#x27;Carroll, Vaidehi Srinivas, Aravindan Vijayaraghavan</p><p>The most widely used technique for solving large-scale semidefinite programs
(SDPs) in practice is the non-convex Burer-Monteiro method, which explicitly
maintains a low-rank SDP solution for memory efficiency. There has been much
recent interest in obtaining a better theoretical understanding of the
Burer-Monteiro method. When the maximum allowed rank $p$ of the SDP solution is
above the Barvinok-Pataki bound (where a globally optimal solution of rank at
most $p$ is guaranteed to exist), a recent line of work established convergence
to a global optimum for generic or smoothed instances of the problem. However,
it was open whether there even exists an instance in this regime where the
Burer-Monteiro method fails. We prove that the Burer-Monteiro method can fail
for the Max-Cut SDP on $n$ vertices when the rank is above the Barvinok-Pataki
bound ($p \ge \sqrt{2n}$). We provide a family of instances that have spurious
local minima even when the rank $p = n/2$. Combined with existing guarantees,
this settles the question of the existence of spurious local minima for the
Max-Cut formulation in all ranges of the rank and justifies the use of beyond
worst-case paradigms like smoothed analysis to obtain guarantees for the
Burer-Monteiro method.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+OCarroll_L/0/1/0/all/0/1">Liam O&#x27;Carroll</a>, <a href="http://arxiv.org/find/math/1/au:+Srinivas_V/0/1/0/all/0/1">Vaidehi Srinivas</a>, <a href="http://arxiv.org/find/math/1/au:+Vijayaraghavan_A/0/1/0/all/0/1">Aravindan Vijayaraghavan</a></p><p>The most widely used technique for solving large-scale semidefinite programs
(SDPs) in practice is the non-convex Burer-Monteiro method, which explicitly
maintains a low-rank SDP solution for memory efficiency. There has been much
recent interest in obtaining a better theoretical understanding of the
Burer-Monteiro method. When the maximum allowed rank $p$ of the SDP solution is
above the Barvinok-Pataki bound (where a globally optimal solution of rank at
most $p$ is guaranteed to exist), a recent line of work established convergence
to a global optimum for generic or smoothed instances of the problem. However,
it was open whether there even exists an instance in this regime where the
Burer-Monteiro method fails. We prove that the Burer-Monteiro method can fail
for the Max-Cut SDP on $n$ vertices when the rank is above the Barvinok-Pataki
bound ($p \ge \sqrt{2n}$). We provide a family of instances that have spurious
local minima even when the rank $p = n/2$. Combined with existing guarantees,
this settles the question of the existence of spurious local minima for the
Max-Cut formulation in all ranges of the rank and justifies the use of beyond
worst-case paradigms like smoothed analysis to obtain guarantees for the
Burer-Monteiro method.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12431'>Choose your witnesses wisely</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dylan Hyatt-Denesik, Afrouz Jabal Ameli, Laura Sanit&#xe0;</p><p>This paper addresses a graph optimization problem, called the Witness Tree
problem, which seeks a spanning tree of a graph minimizing a certain non-linear
objective function. This problem is of interest because it plays a crucial role
in the analysis of the best approximation algorithms for two fundamental
network design problems: Steiner Tree and Node-Tree Augmentation. We will show
how a wiser choice of witness trees leads to an improved approximation for
Node-Tree Augmentation, and for Steiner Tree in special classes of graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hyatt_Denesik_D/0/1/0/all/0/1">Dylan Hyatt-Denesik</a>, <a href="http://arxiv.org/find/cs/1/au:+Ameli_A/0/1/0/all/0/1">Afrouz Jabal Ameli</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanita_L/0/1/0/all/0/1">Laura Sanit&#xe0;</a></p><p>This paper addresses a graph optimization problem, called the Witness Tree
problem, which seeks a spanning tree of a graph minimizing a certain non-linear
objective function. This problem is of interest because it plays a crucial role
in the analysis of the best approximation algorithms for two fundamental
network design problems: Steiner Tree and Node-Tree Augmentation. We will show
how a wiser choice of witness trees leads to an improved approximation for
Node-Tree Augmentation, and for Steiner Tree in special classes of graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12441'>Query Complexity of Inversion Minimization on Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ivan Hu, Dieter van Melkebeek, Andrew Morgan</p><p>We consider the following computational problem: Given a rooted tree and a
ranking of its leaves, what is the minimum number of inversions of the leaves
that can be attained by ordering the tree? This variation of the problem of
counting inversions in arrays originated in mathematical psychology, with the
evaluation of the Mann--Whitney statistic for detecting differences between
distributions as a special case.
</p>
<p>We study the complexity of the problem in the comparison-query model, used
for problems like sorting and selection. For many types of trees with $n$
leaves, we establish lower bounds close to the strongest known in the model,
namely the lower bound of $\log_2(n!)$ for sorting $n$ items. We show:
</p>
<p>(a) $\log_2((\alpha(1-\alpha)n)!) - O(\log n)$ queries are needed whenever
the tree has a subtree that contains a fraction $\alpha$ of the leaves. This
implies a lower bound of $\log_2((\frac{k}{(k+1)^2}n)!) - O(\log n)$ for trees
of degree $k$.
</p>
<p>(b) $\log_2(n!) - O(\log n)$ queries are needed in case the tree is binary.
</p>
<p>(c) $\log_2(n!) - O(k \log k)$ queries are needed for certain classes of
trees of degree $k$, including perfect trees with even $k$.
</p>
<p>The lower bounds are obtained by developing two novel techniques for a
generic problem $\Pi$ in the comparison-query model and applying them to
inversion minimization on trees. Both techniques can be described in terms of
the Cayley graph of the symmetric group with adjacent-rank transpositions as
the generating set. Consider the subgraph consisting of the edges between
vertices with the same value under $\Pi$. We show that the size of any decision
tree for $\Pi$ must be at least:
</p>
<p>(i) the number of connected components of this subgraph, and
</p>
<p>(ii) the factorial of the average degree of the complementary subgraph,
divided by $n$.
</p>
<p>Lower bounds on query complexity then follow by taking the base-2 logarithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hu_I/0/1/0/all/0/1">Ivan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Melkebeek_D/0/1/0/all/0/1">Dieter van Melkebeek</a>, <a href="http://arxiv.org/find/cs/1/au:+Morgan_A/0/1/0/all/0/1">Andrew Morgan</a></p><p>We consider the following computational problem: Given a rooted tree and a
ranking of its leaves, what is the minimum number of inversions of the leaves
that can be attained by ordering the tree? This variation of the problem of
counting inversions in arrays originated in mathematical psychology, with the
evaluation of the Mann--Whitney statistic for detecting differences between
distributions as a special case.
</p>
<p>We study the complexity of the problem in the comparison-query model, used
for problems like sorting and selection. For many types of trees with $n$
leaves, we establish lower bounds close to the strongest known in the model,
namely the lower bound of $\log_2(n!)$ for sorting $n$ items. We show:
</p>
<p>(a) $\log_2((\alpha(1-\alpha)n)!) - O(\log n)$ queries are needed whenever
the tree has a subtree that contains a fraction $\alpha$ of the leaves. This
implies a lower bound of $\log_2((\frac{k}{(k+1)^2}n)!) - O(\log n)$ for trees
of degree $k$.
</p>
<p>(b) $\log_2(n!) - O(\log n)$ queries are needed in case the tree is binary.
</p>
<p>(c) $\log_2(n!) - O(k \log k)$ queries are needed for certain classes of
trees of degree $k$, including perfect trees with even $k$.
</p>
<p>The lower bounds are obtained by developing two novel techniques for a
generic problem $\Pi$ in the comparison-query model and applying them to
inversion minimization on trees. Both techniques can be described in terms of
the Cayley graph of the symmetric group with adjacent-rank transpositions as
the generating set. Consider the subgraph consisting of the edges between
vertices with the same value under $\Pi$. We show that the size of any decision
tree for $\Pi$ must be at least:
</p>
<p>(i) the number of connected components of this subgraph, and
</p>
<p>(ii) the factorial of the average degree of the complementary subgraph,
divided by $n$.
</p>
<p>Lower bounds on query complexity then follow by taking the base-2 logarithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.12496'>An Algorithmic Bridge Between Hamming and Levenshtein Distances</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Elazar Goldenberg, Tomasz Kociumaka, Robert Krauthgamer, Barna Saha</p><p>The edit distance between strings classically assigns unit cost to every
character insertion, deletion, and substitution, whereas the Hamming distance
only allows substitutions. In many real-life scenarios, insertions and
deletions (abbreviated indels) appear frequently but significantly less so than
substitutions. To model this, we consider substitutions being cheaper than
indels, with cost $1/a$ for a parameter $a\ge 1$. This basic variant, denoted
$ED_a$, bridges classical edit distance ($a=1$) with Hamming distance
($a\to\infty$), leading to interesting algorithmic challenges: Does the time
complexity of computing $ED_a$ interpolate between that of Hamming distance
(linear time) and edit distance (quadratic time)? What about approximating
$ED_a$?
</p>
<p>We first present a simple deterministic exact algorithm for $ED_a$ and
further prove that it is near-optimal assuming the Orthogonal Vectors
Conjecture. Our main result is a randomized algorithm computing a
$(1+\epsilon)$-approximation of $ED_a(X,Y)$, given strings $X,Y$ of total
length $n$ and a bound $k\ge ED_a(X,Y)$. For simplicity, let us focus on $k\ge
1$ and a constant $\epsilon &gt; 0$; then, our algorithm takes $\tilde{O}(n/a +
ak^3)$ time. Unless $a=\tilde{O}(1)$ and for small enough $k$, this running
time is sublinear in $n$. We also consider a very natural version that asks to
find a $(k_I, k_S)$-alignment -- an alignment with at most $k_I$ indels and
$k_S$ substitutions. In this setting, we give an exact algorithm and, more
importantly, an $\tilde{O}(nk_I/k_S + k_S\cdot k_I^3)$-time
$(1,1+\epsilon)$-bicriteria approximation algorithm. The latter solution is
based on the techniques we develop for $ED_a$ for $a=\Theta(k_S / k_I)$. These
bounds are in stark contrast to unit-cost edit distance, where state-of-the-art
algorithms are far from achieving $(1+\epsilon)$-approximation in sublinear
time, even for a favorable choice of $k$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goldenberg_E/0/1/0/all/0/1">Elazar Goldenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Kociumaka_T/0/1/0/all/0/1">Tomasz Kociumaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Krauthgamer_R/0/1/0/all/0/1">Robert Krauthgamer</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_B/0/1/0/all/0/1">Barna Saha</a></p><p>The edit distance between strings classically assigns unit cost to every
character insertion, deletion, and substitution, whereas the Hamming distance
only allows substitutions. In many real-life scenarios, insertions and
deletions (abbreviated indels) appear frequently but significantly less so than
substitutions. To model this, we consider substitutions being cheaper than
indels, with cost $1/a$ for a parameter $a\ge 1$. This basic variant, denoted
$ED_a$, bridges classical edit distance ($a=1$) with Hamming distance
($a\to\infty$), leading to interesting algorithmic challenges: Does the time
complexity of computing $ED_a$ interpolate between that of Hamming distance
(linear time) and edit distance (quadratic time)? What about approximating
$ED_a$?
</p>
<p>We first present a simple deterministic exact algorithm for $ED_a$ and
further prove that it is near-optimal assuming the Orthogonal Vectors
Conjecture. Our main result is a randomized algorithm computing a
$(1+\epsilon)$-approximation of $ED_a(X,Y)$, given strings $X,Y$ of total
length $n$ and a bound $k\ge ED_a(X,Y)$. For simplicity, let us focus on $k\ge
1$ and a constant $\epsilon &gt; 0$; then, our algorithm takes $\tilde{O}(n/a +
ak^3)$ time. Unless $a=\tilde{O}(1)$ and for small enough $k$, this running
time is sublinear in $n$. We also consider a very natural version that asks to
find a $(k_I, k_S)$-alignment -- an alignment with at most $k_I$ indels and
$k_S$ substitutions. In this setting, we give an exact algorithm and, more
importantly, an $\tilde{O}(nk_I/k_S + k_S\cdot k_I^3)$-time
$(1,1+\epsilon)$-bicriteria approximation algorithm. The latter solution is
based on the techniques we develop for $ED_a$ for $a=\Theta(k_S / k_I)$. These
bounds are in stark contrast to unit-cost edit distance, where state-of-the-art
algorithms are far from achieving $(1+\epsilon)$-approximation in sublinear
time, even for a favorable choice of $k$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T01:30:00Z">Wednesday, November 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gradientscience.org/modeldiff/'>ModelDiff: A Framework for Comparing Learning Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://gradientscience.org/'>Gradient Science</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          

<!--  -->
<!--  -->









<!--  -->
<!-- 
 -->
<!--  -->


<!--  -->
<!-- chart.js -->


<p>

    Paper



   Code

<br>

In our recent paper, we introduce a general framework, ModelDiff, for comparing machine learning models trained with two different algorithms. In this post, we illustrate our framework by example, comparing models trained from scratch and models fine-tuned from ImageNet.
</p>

Comparing Learning Algorithms

<p>Building ML training pipelines involves many design choices. Even putting the choice of our training dataset aside,  we have to decide on a model architecture, an optimization method to train the model, and whether to include one or more regularization techniques. On top of all this, we have to play with a bunch of hyperparameters until we get models that perform well enough on our validation set. This entire pipeline—the aggregate of all train-time design choices—is a learning algorithm, a function mapping training datasets to ML models.</p>

<p>Often, seemingly minor or innocuous tweaks to such a learning algorithm can affect the behavior of the resulting models in subtle and unintended ways. For example, pruning techniques that sparsify models prior to deployment end up hurting performance on underrepresented subpopulations. Random cropping—a standard data augmentation scheme that improves model performance—amplifies texture bias in image classification tasks.</p>

<p>We often want to know how a given design choice modulates the specific features that models learn. To that end, our latest work develops a general framework (called ModelDiff) for performing fine-grained, feature-based comparisons of any two learning algorithms.</p>

<p>In rest of this post, we will introduce our framework by walking through a specific case study: exploring the effect of ImageNet pre-training on the Waterbirds dataset. In this case study (spoiler alert), we’ll use ModelDiff to find that pre-trained models rely on the presence of a human face in the background to predict “landbird!” 
Importantly, we’ll do this without having any prior hypotheses, domain knowledge, or dataset annotations.</p>

<p>♦</p>

Case Study: Using ModelDiff to study pre-training

<p>A common design choice in supervised learning is whether to train a model from scratch or fine-tune it from one pre-trained on a larger dataset. (A standard choice for this larger dataset is the ImageNet dataset.)</p>

<p>In this case study, we consider the Waterbirds dataset, for which the task is to classify images of birds overlaid on random backgrounds as either “landbirds” or “waterbirds.” Indeed, on Waterbirds, fine-tuning a pre-trained ImageNet model (rather than training from scratch) significantly improves overall performance.</p>

<p>But is that all pre-training does? In particular, what other (possibly undesirable) impact does pre-training have on the fine-grained behavior of the learned model?</p>

A data-centric perspective

<p>The perspective we adopt in our paper is that models are different insofar as they use different features of the data to make predictions. But how do we know what features models use? This is where our method, ModelDiff, comes in. The core idea behind ModelDiff is that:</p>



Models that use different features to arrive at their final predictions should
rely on different training examples to make these predictions.



<p>For instance, suppose we were comparing a texture-biased model to a shape-biased one: when faced with a test example containing a cat in a specific pose, the texture-biased model will rely on cats from the training set with similar texture (e.g., fur), whereas the shape-biased model will rely more on cats in a similar pose.</p>

<p>Below, we translate this intuition into a practical algorithm, applying ModelDiff to our problem of comparing pre-trained models to those trained from scratch:</p>

Step 1: Tracing predictions back to training data with datamodels

<p>To understand which training examples models rely on, we use datamodels—an approach to understanding how instance-wise predictions of (deep) models depend on individual examples in the training dataset $S$. If you’re not familiar with datamodels, we recommend reading our previous posts, or (if you’re in a rush) reading the summary below:</p>




&nbsp; A primer on datamodels (Click to expand)

Linear datamodels. A linear datamodel $\theta_x$ for a test example $x$ is a linear function that takes as input a set of training data indices  $S’ \subset [n]$ and predicts the model output on $x$ if we were to train a model on just the corresponding training examples. It turns out that these linear datamodels can surprisingly accurately predict  how counterfactual changes to the training dataset change final model predictions! That is, we have that
$$\theta_x^\top 1_{S'} \approx \mathbb{E}[\text{margin on $x$ of classifier trained on S’}],$$
where $\mathbf{1}_{S’} \in \{0,1\}^n $ is the indicator vector of $S’$ in the training set $S$. Intuitively,  the datamodel weight $(\theta_{x})_i$ signifies the contribution of the $i$-th training example to the model’s performance on test example $x$.
<br>
<br>
Datamodels as representations. As highlighted in the original paper on datamodels, we can view each linear datamodel $\theta_x$ as a representation (or embedding) of its corresponding test example $x$. It turns out that there are two key properties that arise from this perspective that naturally facilitate comparisons between the corresponding learning algorithms:
<br>
<ul>
<li>Consistent basis:  For a fixed training dataset $S$, all
linear datamodels share the same basis. That is, coordinate $i$ always
corresponds to the importance of the $i$-th training example, regardless of what
learning algorithm we use. This conveniently allows for model-agnostic
comparisons between learning algorithms that may have entirely different latent
representations.</li>
<li>Predictiveness:  By design, datamodel vectors are causally predictive of model behavior. Trained models—potentially with different algorithms—that have (distributionally) different outputs on example $x$ end up with dissimilar datamodels for example $x$.</li>
</ul>

Taken together, these two properties enable a fine-grained analysis of models in terms of how they use training data to make predictions. 




<p><br></p>

<p>The first step in our pipeline is to compute two sets of datamodels 
\(\{\theta^{(1)}_{x_i}: x_i \in T\}\) and 
\(\{\theta^{(2)}_{x_i}: x_i \in T\}\)
for the test set $T$, each set corresponding to one learning algorithm. In our case study here, the two sets of datamodels correspond to Waterbirds models trained with and without ImageNet pre-training, respectively.</p>

<p>But before we go ahead, simply visualizing test images and their corresponding “most important training examples” (i.e., those corresponding to the highest datamodel weights) already suggests that models trained with/without ImageNet pre-training are influenced by qualitatively very different training examples:</p>


    
    Choose an Image
    
    
        ♦
        ♦
    



Step 2: Isolating differences with residual datamodels

<p>The datamodels $\theta^{(1)}_x$ and $\theta^{(2)}_x$ describe how each algorithm uses the training data to make a prediction on a given example $x$. What we’re really interested in, however, are the differences in how these two algorithms use the training data. To isolate these differences,  we compute two residual datamodels, $\theta^{(1 \setminus 2)}_x$ and $\theta^{(2 \setminus 1)}_x$ for each example $x$.  As illustrated below, the residual datamodel ${\theta}^{(1\setminus 2)}_x$ represents the training direction that influences ImageNet-pretrained models on example $x$ after “projecting away” the component that also influences models trained from scratch:</p>

<p>♦</p>

<p>where $\widehat{\theta}_x$ denotes the $\ell_2$-normalized version of datamodel $\theta_x$. Analogously, the residual datamodel  $\theta^{(2 \setminus 1)}_x$ encodes a weighted combination of training examples that influence predictions of models trained from scratch but not of models pre-trained on ImageNet.</p>

Step 3: Extracting distinguishing subpopulations with PCA

<p>The outputs of Step 2 above—i.e., the two sets of residual datamodels  ${\theta^{(1 \setminus 2)}_i}$ and ${\theta^{(2 \setminus 1)}_i}$—capture how models trained with and without ImageNet pre-training differ, but only at the per-example level.  Our goal, however, is to understand global differences in model behavior. To this end, we use principal component analysis (PCA) to distill the residual datamodels into distinguishing training directions, i.e., representative directions in training set space (i.e., in  $\mathbb{R}^{n}$) that generally influence predictions of models trained with one algorithm but not the other.</p>

<p>More concretely, we apply PCA to both sets of residual datamodels \(\{\theta^{(1 \setminus 2)}_i\}\) and \(\{\theta^{(2 \setminus 1)}_i\}\). The output is a set of principal components $v_j \in \mathbb{R}^n$—we can think of each component as a weighted combination of training examples.</p>

<p>In our paper, we show how to quantify the importance of a given weighted combination of training examples to each algorithm: as shown in the plot below, the top principal components of the residual datamodels \(\{\theta^{(1 \setminus 2)}_i\}\) are important to Algorithm 1 (pre-training then fine tuning) but not to Algorithm 2 (training from scratch); and vice-versa for \(\{\theta^{(1 \setminus 2)}_i\}\).</p>

<p>♦</p>

Caption:
Each red (resp. green) point represent distinguishing training direction—a weighted combination of training examples that influence predictions of models pre-trained on ImageNet significantly more (resp. less) than that of models trained from scratch. The $x$ and $y$ coordinates of each point represent the fraction of explained variance under Algorithm 1 (pre-training) and Algorithm 2 (training from scratch). 


<p>We can now take each principal component and look at the test examples whose residual datamodels are most aligned with that direction: this yields a set of subpopulations distinguishing learning Algorithm 1 from 2, and vice versa.</p>

Verifying subpopulations found by ModelDiff
<p>How do we verify though that the distinguishing subpopulations ModelDiff output
actually capture meaningful differences in model behavior?</p>

<p>Let’s start by visualizing these subpopulations. That is, let’s take a look at
the subpopulations surfaced by distinguishing directions annotated as
$\textbf{A}$ and $\textbf{B}$ in the scatterplot above:</p>


♦
♦


Caption: The subpopulations surfaced by the directions annotated $\textbf{A}$ (left)
and $\textbf{B}$ (right) in the scatterplot above. The former has a common feature that is important 
to from-scratch models but not to pre-trained ones; the latter has a common feature that is important
to pre-trained models but not to from-scratch ones.


<p>It seems these surfaced subpopulations indeed highlight semantically meaningful features! For example,</p>

<ol>
  <li>Subpopulation $\textbf{A}$ has images of yellow landbirds or images of yellow blotches in the background. This suggests that models trained from scratch (but not ImageNet-pretrained models) spuriously rely on a “yellow color” feature to predict landbirds.</li>
  <li>Subpopulation $\textbf{B}$ surfaces images of landbirds with human faces in the background. This suggests ImageNet-pretrained models finetuned on Waterbirds (but not those trained from scratch) spuriously rely on a “human face” feature to predict landbirds.</li>
</ol>

<p>Ok, so these are plausible hypotheses, but can we go a step further and actually test whether these inferred features—yellow color and human face—influence model behavior as we suspect they do? Yes, via explicit counterfactual experiments!</p>

<p>Indeed, if ImageNet-pretrained models rely on a “human face” feature, simply adding a face to image backgrounds should consistently change the behavior of these models (but not of models trained from scratch). Similarly, just adding a small yellow patch to images should influence models trained from scratch, but not those that are pre-trained on ImageNet. Is that the case?</p>

<p>It turns out that it is! The plots below demonstrate the effect of adding a yellow patch or a human face on the confidence of models in predicting the class “landbird”.</p>

<p>♦</p>

Caption: Treatment effect of distinguishing feature transformations. Adding a yellow square patch to images makes models trained with and without ImageNet pre-training, on average, 9% more and 2% less confident in predicting the label "landbird." On the other hand, adding a human face to image backgrounds makes models trained with and without ImageNet pre-training, on average, 3% and 0% more confident in predicting the label "landbird."


<p>In summary, ModelDiff allowed us to find that ImageNet pre-training significantly reduces dependence on some of the spurious correlations (e.g., yellow color $\rightarrow$ landbird) but also introduces new ones (e.g., human face $\rightarrow$ landbird).</p>

Takeaways

<p>In this post, we introduced a general framework, ModelDiff, for fine-grained, feature-based comparisons of any two learning algorithms. Our framework is general in that we can compare any set of learning algorithms that are applied to a common training set. (For instance, one could even compare a neural network to a random forest classifier.)</p>

<p>In our paper, we further showcase using two other case studies—one on data augmentation and another on SGD hyperparameters—how ModelDiff can help us understand how standard design choices impact model behavior in a fine-grained manner.</p>

<p>More broadly, our framework demonstrates how adopting a data-centric lens and abstracting away internal details of a given model can help us probe properties of learning algorithms.</p>
















 function main() {
     const BASE_DIR = "/assets/modeldiff/";
     
     // Generation
     var genImage1 = document.getElementById('gen0-1');
     var genImage2 = document.getElementById('gen0-2');
     var genSrcs = range(4).map((name) => BASE_DIR + 'dm' + name + "_query.png");
     function genMapper(origSrc, id) {
           genImage1.src = origSrc;
           genImage2.src = origSrc.replace("_query.png", ".png");
     }
     activate_one_widget('gen', genSrcs, genMapper);
 }
 window.onload = main;


        
        </div>

        <div class='tr-article-summary'>
        
          
          <meta charset="utf-8" />

<!-- <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> -->
<!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"> -->

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous" />

<link rel="stylesheet" type="text/css" href="/assets/css/style.css" />

<link rel="stylesheet" href="/assets/multilabel/style.css" />

<link rel="stylesheet" type="text/css" href="/assets/data-transfer/style.css" />

<!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css"> -->
<!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script> -->
<!-- <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script> -->
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha384-tsQFqpEReu7ZLhBV2VZlAu7zcOV+rXbYlF2cqB8txI/8aZajjp4Bqd+V6D5IgvKT" crossorigin="anonymous"></script>

<!-- <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css"> -->
<!-- chart.js -->
<script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>

<p><a class="bbutton" style="float: left; width: 45%;" href="https://arxiv.org/abs/2211.12491">
<i class="fas fa-file-pdf"></i>
    Paper
</a>
<a class="bbutton" style="float: left; width: 45%;" href="https://github.com/MadryLab/modeldiff">
<i class="fab fa-github"></i>
   Code
</a>
<br />
<i>
In our recent paper, we introduce a general framework, ModelDiff, for comparing machine learning models trained with two different algorithms. In this post, we illustrate our framework by example, comparing models trained from scratch and models fine-tuned from ImageNet.
</i></p>

<h2 id="comparing-learning-algorithms">Comparing Learning Algorithms</h2>

<p>Building ML training pipelines involves many design choices. Even putting the choice of our training dataset aside,  we have to decide on a model architecture, an optimization method to train the model, and whether to include one or more regularization techniques. On top of all this, we have to play with a bunch of hyperparameters until we get models that perform well enough on our validation set. This entire pipeline—the aggregate of all train-time design choices—is a <em>learning algorithm</em>, a function mapping training datasets to ML models.</p>

<p>Often, seemingly minor or innocuous tweaks to such a learning algorithm can affect the behavior of the resulting models in subtle and unintended ways. For example, pruning techniques that sparsify models prior to deployment end up <a href="https://arxiv.org/abs/1911.05248">hurting performance on underrepresented subpopulations</a>. Random cropping—a standard data augmentation scheme that improves model performance—<a href="https://arxiv.org/abs/1911.09071">amplifies texture bias</a> in image classification tasks.</p>

<p>We often want to know how a given design choice modulates the specific features that models learn. To that end, <a href="https://arxiv.org/abs/2211.12491">our latest work</a> develops a general framework (called <em>ModelDiff</em>) for performing fine-grained, feature-based comparisons of any two learning algorithms.</p>

<p>In rest of this post, we will introduce our framework by walking through a specific case study: exploring the effect of ImageNet pre-training on the Waterbirds dataset. In this case study (spoiler alert), we’ll use ModelDiff to find that pre-trained models rely on the presence of a human face in the background to predict “landbird!” 
Importantly, we’ll do this without having any prior hypotheses, domain knowledge, or dataset annotations.</p>

<p><img src="/assets/modeldiff/face_summary.png" style="width: 100%; max-width: 100%;" /></p>

<h2 id="case-study-using-modeldiff-to-study-pre-training">Case Study: Using ModelDiff to study pre-training</h2>

<p>A common design choice in supervised learning is whether to train a model from scratch or fine-tune it from one pre-trained on a larger dataset. (A standard choice for this larger dataset is the ImageNet dataset.)</p>

<p>In this case study, we consider the <a href="https://arxiv.org/pdf/1911.08731.pdf">Waterbirds</a> dataset, for which the task is to classify images of birds overlaid on random backgrounds as either “landbirds” or “waterbirds.” Indeed, on Waterbirds, fine-tuning a pre-trained ImageNet model (rather than training from scratch) significantly improves overall performance.</p>

<p>But is that <em>all</em> pre-training does? In particular, what other (possibly undesirable) impact does pre-training have on the fine-grained behavior of the learned model?</p>

<h3 id="a-data-centric-perspective">A data-centric perspective</h3>

<p>The perspective we adopt in <a href="https://arxiv.org/abs/2211.12491">our paper</a> is that models are different insofar as they use different features of the data to make predictions. But how do we know what features models use? This is where our method, ModelDiff, comes in. The core idea behind ModelDiff is that:</p>

<div style="background:#EEE; padding: 20px; text-align: center;margin-bottom: 20px;">
<em>
Models that use different features to arrive at their final predictions should
rely on different training examples to make these predictions.
</em>
</div>

<p>For instance, suppose we were comparing a texture-biased model to a shape-biased one: when faced with a test example containing a cat in a specific pose, the texture-biased model will rely on cats from the training set with similar texture (e.g., fur), whereas the shape-biased model will rely more on cats in a similar pose.</p>

<p>Below, we translate this intuition into a practical algorithm, applying ModelDiff to our problem of comparing pre-trained models to those trained from scratch:</p>

<h3 id="step-1-tracing-predictions-back-to-training-data-with-datamodels">Step 1: Tracing predictions back to training data with datamodels</h3>

<p>To understand which training examples models rely on, we use <em>datamodels</em>—an approach to understanding how instance-wise predictions of (deep) models depend on individual examples in the training dataset $S$. If you’re not familiar with datamodels, we recommend reading our <a href="https://gradientscience.org/datamodels-1/">previous</a> <a href="https://gradientscience.org/datamodels-2/">posts</a>, or (if you’re in a rush) reading the summary below:</p>
<section class="container">
<div>
<div class="checkboxdiv">
<input id="ac-1" name="accordion-1" type="checkbox" style="display: none;" />
<label for="ac-1"><span id="titlespan" class="fas fa-chevron-right"></span><strong>&nbsp; A primer on datamodels</strong> (Click to expand)</label>
<article class="small">
<strong>Linear datamodels.</strong> A linear datamodel $\theta_x$ for a test example $x$ is a linear function that takes as input a set of training data indices  $S’ \subset [n]$ and predicts the model output on $x$ if we were to train a model on just the corresponding training examples. It turns out that these linear datamodels can surprisingly accurately predict  how counterfactual changes to the training dataset change final model predictions! That is, we have that
$$\theta_x^\top 1_{S'} \approx \mathbb{E}[\text{margin on $x$ of classifier trained on S’}],$$
where $\mathbf{1}_{S’} \in \{0,1\}^n $ is the indicator vector of $S’$ in the training set $S$. Intuitively,  the datamodel weight $(\theta_{x})_i$ signifies the contribution of the $i$-th training example to the model’s performance on test example $x$.
<br />
<br />
<strong>Datamodels as representations.</strong> As highlighted in the original paper on datamodels, we can view each linear datamodel $\theta_x$ as a representation (or embedding) of its corresponding test example $x$. It turns out that there are two key properties that arise from this perspective that naturally facilitate comparisons between the corresponding learning algorithms:
<br />
<ul>
<li><strong>Consistent basis</strong>:  For a fixed training dataset $S$, all
linear datamodels share the same basis. That is, coordinate $i$ always
corresponds to the importance of the $i$-th training example, regardless of what
learning algorithm we use. This conveniently allows for model-agnostic
comparisons between learning algorithms that may have entirely different latent
representations.</li>
<li><strong>Predictiveness</strong>:  By design, datamodel vectors are causally predictive of model behavior. Trained models—potentially with different algorithms—that have (distributionally) different outputs on example $x$ end up with dissimilar datamodels for example $x$.</li>
</ul>

Taken together, these two properties enable a fine-grained analysis of models in terms of how they use training data to make predictions. 
</article>
</div>
</div>
</section>
<p><br /></p>

<p>The first step in our pipeline is to compute two sets of datamodels 
\(\{\theta^{(1)}_{x_i}: x_i \in T\}\) and 
\(\{\theta^{(2)}_{x_i}: x_i \in T\}\)
for the test set $T$, each set corresponding to one learning algorithm. In our case study here, the two sets of datamodels correspond to Waterbirds models trained with and without ImageNet pre-training, respectively.</p>

<p>But before we go ahead, simply visualizing test images and their corresponding “most important training examples” (i.e., those corresponding to the highest datamodel weights) already suggests that models trained with/without ImageNet pre-training are influenced by qualitatively very different training examples:</p>

<div class="widget">
    <div class="choices_one_full" id="gen">
    <span class="widgetheading" id="genclass">Choose an Image</span>
    </div>
    <div style="border-right: 3px white solid;">
        <img id="gen0-1" class="image-container" style="width: 0%; margin: 0;" />
        <img id="gen0-2" class="image-container" style="width: 100%; margin: 0;" />
    </div>
</div>
<div style="clear:both;"></div>

<h3 id="step-2-isolating-differences-with-residual-datamodels">Step 2: Isolating differences with residual datamodels</h3>

<p>The datamodels $\theta^{(1)}_x$ and $\theta^{(2)}_x$ describe how each algorithm uses the training data to make a prediction on a given example $x$. What we’re really interested in, however, are the <em>differences</em> in how these two algorithms use the training data. To isolate these differences,  we compute two <em>residual datamodels</em>, $\theta^{(1 \setminus 2)}_x$ and $\theta^{(2 \setminus 1)}_x$ for each example $x$.  As illustrated below, the residual datamodel ${\theta}^{(1\setminus 2)}_x$ represents the training direction that influences ImageNet-pretrained models on example $x$ after “projecting away” the component that also influences models trained from scratch:</p>

<p><img src="/assets/modeldiff/residual_dm.png" style="width: 40%;" /></p>

<p>where $\widehat{\theta}_x$ denotes the $\ell_2$-normalized version of datamodel $\theta_x$. Analogously, the residual datamodel  $\theta^{(2 \setminus 1)}_x$ encodes a weighted combination of training examples that influence predictions of models trained from scratch but not of models pre-trained on ImageNet.</p>

<h3 id="step-3-extracting-distinguishing-subpopulations-with-pca">Step 3: Extracting distinguishing subpopulations with PCA</h3>

<p>The outputs of Step 2 above—i.e., the two sets of residual datamodels  ${\theta^{(1 \setminus 2)}_i}$ and ${\theta^{(2 \setminus 1)}_i}$—capture how models trained with and without ImageNet pre-training differ, but only at the per-example level.  Our goal, however, is to understand <em>global</em> differences in model behavior. To this end, we use principal component analysis (PCA) to distill the residual datamodels into <em>distinguishing training directions</em>, i.e., representative directions in training set space (i.e., in  $\mathbb{R}^{n}$) that generally influence predictions of models trained with one algorithm but not the other.</p>

<p>More concretely, we apply PCA to both sets of residual datamodels \(\{\theta^{(1 \setminus 2)}_i\}\) and \(\{\theta^{(2 \setminus 1)}_i\}\). The output is a set of principal components $v_j \in \mathbb{R}^n$—we can think of each component as a weighted combination of training examples.</p>

<p>In <a href="https://arxiv.org/abs/2211.12491">our paper</a>, we show how to quantify the importance of a given weighted combination of training examples to each algorithm: as shown in the plot below, the top principal components of the residual datamodels \(\{\theta^{(1 \setminus 2)}_i\}\) are important to Algorithm 1 (pre-training then fine tuning) but not to Algorithm 2 (training from scratch); and vice-versa for \(\{\theta^{(1 \setminus 2)}_i\}\).</p>

<p><img src="/assets/modeldiff/explained_variance.png" style="width: 50%;" /></p>
<div class="footnote" style="padding-left: 10px;">
<strong>Caption</strong>:
Each red (resp. green) point represent distinguishing training direction—a weighted combination of training examples that influence predictions of models pre-trained on ImageNet significantly more (resp. less) than that of models trained from scratch. The $x$ and $y$ coordinates of each point represent the fraction of explained variance under Algorithm 1 (pre-training) and Algorithm 2 (training from scratch). 
</div>

<p>We can now take each principal component and look at the test examples whose residual datamodels are most aligned with that direction: this yields a set of <em>subpopulations</em> distinguishing learning Algorithm 1 from 2, and vice versa.</p>

<h3 id="verifying-subpopulations-found-by-modeldiff">Verifying subpopulations found by ModelDiff</h3>
<p>How do we verify though that the distinguishing subpopulations ModelDiff output
actually capture meaningful differences in model behavior?</p>

<p>Let’s start by visualizing these subpopulations. That is, let’s take a look at
the subpopulations surfaced by distinguishing directions annotated as
$\textbf{A}$ and $\textbf{B}$ in the scatterplot above:</p>

<div style="text-align: center; width: 100%;">
<img src="/assets/modeldiff/subpop_face.png" style="width: 45%; margin-right: 2%; display: inline;" />
<img src="/assets/modeldiff/subpop_yellow.png" style="width: 45%; margin-left: 2%; display: inline;" />
</div>
<div class="footnote" style="padding-left: 10px">
<strong>Caption</strong>: The subpopulations surfaced by the directions annotated $\textbf{A}$ (left)
and $\textbf{B}$ (right) in the scatterplot above. The former has a common feature that is important 
to from-scratch models but not to pre-trained ones; the latter has a common feature that is important
to pre-trained models but not to from-scratch ones.
</div>

<p>It seems these surfaced subpopulations indeed highlight semantically meaningful features! For example,</p>

<ol>
  <li>Subpopulation $\textbf{A}$ has images of yellow landbirds or images of yellow blotches in the background. This suggests that models trained from scratch (but not ImageNet-pretrained models) spuriously rely on a “yellow color” feature to predict landbirds.</li>
  <li>Subpopulation $\textbf{B}$ surfaces images of landbirds with human faces in the background. This suggests ImageNet-pretrained models finetuned on Waterbirds (but not those trained from scratch) spuriously rely on a “human face” feature to predict landbirds.</li>
</ol>

<p>Ok, so these are plausible hypotheses, but can we go a step further and actually <em>test</em> whether these inferred features—yellow color and human face—influence model behavior as we suspect they do? Yes, via explicit counterfactual experiments!</p>

<p>Indeed, if ImageNet-pretrained models rely on a “human face” feature, simply adding a face to image backgrounds should consistently change the behavior of these models (but not of models trained from scratch). Similarly, just adding a small yellow patch to images should influence models trained from scratch, but not those that are pre-trained on ImageNet. Is that the case?</p>

<p>It turns out that it is! The plots below demonstrate the effect of adding a yellow patch or a human face on the confidence of models in predicting the class “landbird”.</p>

<p><img src="/assets/modeldiff/counterfactuals_both.png" /></p>
<div class="footnote" style="padding-left: 10px;">
<strong>Caption</strong>: Treatment effect of distinguishing feature transformations. Adding a yellow square patch to images makes models trained with and without ImageNet pre-training, on average, 9% more and 2% less confident in predicting the label "landbird." On the other hand, adding a human face to image backgrounds makes models trained with and without ImageNet pre-training, on average, 3% and 0% more confident in predicting the label "landbird."
</div>

<p>In summary, ModelDiff allowed us to find that ImageNet pre-training significantly reduces dependence on some of the spurious correlations (e.g., yellow color $\rightarrow$ landbird) but also introduces new ones (e.g., human face $\rightarrow$ landbird).</p>

<h2 id="takeaways">Takeaways</h2>

<p>In this post, we introduced a general framework, ModelDiff, for fine-grained, feature-based comparisons of any two learning algorithms. Our framework is general in that we can compare <em>any</em> set of learning algorithms that are applied to a common training set. (For instance, one could even compare a neural network to a random forest classifier.)</p>

<p>In <a href="https://arxiv.org/abs/2211.12491">our paper</a>, we further showcase using two other case studies—one on data augmentation and another on SGD hyperparameters—how ModelDiff can help us understand how standard design choices impact model behavior in a fine-grained manner.</p>

<p>More broadly, our framework demonstrates how adopting a data-centric lens and abstracting away internal details of a given model can help us probe properties of learning algorithms.</p>

<script src="/assets/scripts/onload.js"></script>

<script src="https://cdn.jsdelivr.net/gh/nicolaspanel/numjs@0.15.1/dist/numjs.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/mathjs@6.6.0/dist/math.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>

<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

<script>
 function main() {
     const BASE_DIR = "/assets/modeldiff/";
     
     // Generation
     var genImage1 = document.getElementById('gen0-1');
     var genImage2 = document.getElementById('gen0-2');
     var genSrcs = range(4).map((name) => BASE_DIR + 'dm' + name + "_query.png");
     function genMapper(origSrc, id) {
           genImage1.src = origSrc;
           genImage2.src = origSrc.replace("_query.png", ".png");
     }
     activate_one_widget('gen', genSrcs, genMapper);
 }
 window.onload = main;

</script>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-23T00:00:00Z">Wednesday, November 23 2022, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, November 22
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2022/165'>TR22-165 |  Separation of the factorization norm and randomized communication complexity | 

	TsunMing Cheung, 

	Hamed Hatami, 

	Kaave Hosseini, 

	Morgan Shirley</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In an influential paper, Linial and Shraibman (STOC &#39;07) introduced  the factorization norm as a powerful tool for proving lower bounds against randomized and quantum communication complexities. They showed that the logarithm of the approximate $\gamma_2$-factorization norm is a lower bound for these parameters and asked whether a stronger lower bound that replaces approximate $\gamma_2$ norm with the $\gamma_2$ norm holds.
    
    We answer the question of Linial and Shraibman in the negative by exhibiting a $2^n\times2^n $ Boolean matrix with $\gamma_2$ norm $2^{\Omega(n)}$ and randomized communication complexity $O(\log n)$. 

 As a corollary, we recover the recent result of Chattopadhyay, Lovett, and Vinyals (CCC &#39;19) that deterministic protocols with access to an Equality oracle are exponentially weaker than (one-sided error) randomized protocols.  In fact,  as a stronger consequence, our result implies an exponential separation between the power of  unambiguous nondeterministic protocols with access to Equality oracle and (one-sided error) randomized protocols, which answers a question of  Pitassi, Shirley, and Shraibman (ITSC &#39;23). 

Our result also  implies a conjecture of Sherif (Ph.D. thesis) that the $\gamma_2$ norm of the Integer Inner Product function (IIP) in dimension 3 or higher is exponential in its input size.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In an influential paper, Linial and Shraibman (STOC &#39;07) introduced  the factorization norm as a powerful tool for proving lower bounds against randomized and quantum communication complexities. They showed that the logarithm of the approximate $\gamma_2$-factorization norm is a lower bound for these parameters and asked whether a stronger lower bound that replaces approximate $\gamma_2$ norm with the $\gamma_2$ norm holds.
    
    We answer the question of Linial and Shraibman in the negative by exhibiting a $2^n\times2^n $ Boolean matrix with $\gamma_2$ norm $2^{\Omega(n)}$ and randomized communication complexity $O(\log n)$. 

 As a corollary, we recover the recent result of Chattopadhyay, Lovett, and Vinyals (CCC &#39;19) that deterministic protocols with access to an Equality oracle are exponentially weaker than (one-sided error) randomized protocols.  In fact,  as a stronger consequence, our result implies an exponential separation between the power of  unambiguous nondeterministic protocols with access to Equality oracle and (one-sided error) randomized protocols, which answers a question of  Pitassi, Shirley, and Shraibman (ITSC &#39;23). 

Our result also  implies a conjecture of Sherif (Ph.D. thesis) that the $\gamma_2$ norm of the Integer Inner Product function (IIP) in dimension 3 or higher is exponential in its input size.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-22T23:24:49Z">Tuesday, November 22 2022, 23:24</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/'>AI will change the world, but won’t take it over by playing “3-dimensional chess”.</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          By Boaz Barak and&#160;Ben Edelman [Cross-posted on Lesswrong ; See also Boaz’s posts on longtermism and AGI via scaling , as well as other &#8220;philosophizing&#8221; posts. This post also puts us in Aaronson&#8217;s &#8220;Reform AI Alignment&#8221; religion] [Disclaimer:&#160;Predictions are very hard, especially about the future. In fact, this is one of the points of this essay. Hence, &#8230; Continue reading AI will change the world, but won’t take it over by playing “3-dimensional chess”.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>By <a href="https://www.boazbarak.org/">Boaz Barak</a> and&nbsp;<a href="https://www.benjaminedelman.com/">Ben Edelman</a></p>



<p><em>[Cross-posted on <a href="https://www.lesswrong.com/posts/zB3ukZJqt3pQDw9jz/ai-will-change-the-world-but-won-t-take-it-over-by-playing-3">Lesswrong</a> ;  See also Boaz’s posts on </em><a href="https://windowsontheory.org/2022/05/23/why-i-am-not-a-longtermist/"><em><u>longtermism</u></em></a><em> and </em><a href="https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/"><em><u>AGI via scaling</u></em></a> , as well as other &#8220;<a href="https://windowsontheory.org/category/philosophizing/">philosophizing</a>&#8221; posts. This post also puts us in Aaronson&#8217;s <a href="https://scottaaronson.blog/?p=6821">&#8220;Reform AI Alignment&#8221; </a>religion<em>] </em></p>



<p><em>[Disclaimer:&nbsp;Predictions are very hard, especially about the future. In fact, this is one of the points of this essay. Hence, while for concreteness, we phrase our claims as if we are confident about them, these are not mathematically proven facts. However we do believe that the claims below are more likely to be true than false, and, even more confidently, believe some of the ideas herein are underrated in current discussions around risks from future AI systems.]</em></p>



<p>In the past, the word “computer” was used to denote a person that performs calculations. Such people were highly skilled and were crucial to scientific enterprises. As described in the book “<a href="https://en.wikipedia.org/wiki/Hidden_Figures_(book)"><u>Hidden Figures</u></a>”, until the 1960s, NASA still used human computers for the space mission. However, these days a $10 calculator can instantly perform calculations beyond the capabilities of every human on earth.</p>



<p>On a high level, the situation in Chess and other games is similar. Humans used to be the reigning champions in Chess and Go, but have now been surpassed by computers. Yet, while the success of computers in performing calculations has not engendered fears of them “taking over the world,” the growing powers of AI systems have more people increasingly worried about their long-term implications. Some reasons why the success of AI systems such as&nbsp;<a href="https://www.deepmind.com/blog/alphazero-shedding-new-light-on-chess-shogi-and-go"><u>AlphaZero</u></a> in Go and Chess is more concerning than the success of calculation programs include</p>



<ol>
<li>Unlike when working with numerical computation programs, it seems that in Chess and Go humans are entirely “unnecessary.” There is no need to have a “human in the loop”. Computer systems are so powerful that no meaningful competition is possible between even the best human players and software running on commodity laptops.<sup><a href="#footnotes">[1]</a></sup><br>&nbsp;</li>



<li>Unlike the numerical algorithms used for calculations, we do not understand the inner workings of AI chess systems, especially ones trained without any hand-designed knowledge. These systems are to a large extent “black boxes,” which even their creators do not fully understand and hence cannot fully predict or control.<br>&nbsp;</li>



<li>Moreover, AlphaZero was trained using a paradigm known as&nbsp;<a href="https://en.wikipedia.org/wiki/Reinforcement_learning"><u>reinforcement learning</u></a> or RL (see also this&nbsp;<a href="https://rltheorybook.github.io/"><u>book</u></a>). At a high level, RL can be described as training an agent to learn a&nbsp;<em>strategy</em> (i.e., a rule to decide on a move or action based on the history of all prior ones) in order to maximize a long-term reward (e.g., “win the game”). The result is a system that is capable of executing actions that may seem wrong in the short term (e.g., sacrificing a queen) but will help achieve the long-term goal.&nbsp;</li>
</ol>



<p>While RL so far has had very limited success outside specific realms such as games or low-complexity settings, the success of (non-RL) deep learning systems such as&nbsp;<a href="https://en.wikipedia.org/wiki/GPT-3"><u>GPT-3</u></a> or<a href="https://openai.com/dall-e-2/"><u> Dall-E</u></a> in open-ended text or image generation has raised fears of future AI systems that could both act in the real world, interacting with humans, physical, and digital systems, and do so in the pursuit of long term goals that may not be “aligned” with the interests of humanity. The fear is that such systems could become so powerful that they could end up destroying much or all of humanity. We refer to the above scenario as the&nbsp;<strong>loss of control</strong> scenario. It is distinct from other potential risks of Artificial Intelligence, including the risks of AI being used by humans to develop more lethal weapons, better ways for repressive regimes to surveil their population or more effective ways of spreading misinformation.</p>



<p>In this essay,&nbsp;<strong>we claim that the “loss of control” scenario rests on a few key assumptions that are not justified by our current understanding of artificial intelligence research</strong>. (This doesn’t mean the assumptions are necessarily wrong—just that we don’t believe the preponderance of the evidence supports them.)&nbsp; To be clear, we are not “AI skeptics” by any means. We fully believe that over the next few decades, AI will continue to make breakthrough advances, and AI systems will surpass current human performance in many creative and technical fields, including, but not limited to, software engineering, hacking, marketing, visual design, (at least some components of) scientific discovery, and more. We are also not “techno-optimists.” The world already faces risks, and even existential ones, from the actions of humans. People who have had control over nuclear weapons over the course of history include Joseph Stalin, Kim Jong-un, Vladimir Putin, and many others whose moral judgment is suspect, to say the least. Nuclear weapons are not the only way humans can and have caused suffering on a mass scale; whether it is biological, chemical, or even so-called “conventional” weapons, climate change, exploitation of resources and people, or others, humans have a long history of pain and destruction. Like any new technology, AI will be (and in fact already has been) used by humans for warfare, manipulations, and other illicit goals. These risks are real and should be studied, but are not the focus of this essay.</p>



<h2><strong>Our argument: an executive summary.</strong></h2>



<p>The loss of control scenario is typically described as a “battle” between AIs and humans, in which AIs would eventually win due to their superior abilities. However, unlike in Chess games, humans can and will use all the tools at their disposal, including many tools (e.g., code-completion engines, optimizers for protein folding, etc..) that are currently classified as “Artificial Intelligence”. So to understand the balance of power, we need to distinguish between systems or agents that have only&nbsp;<strong>short-term goals</strong>, versus systems that&nbsp;<strong>plan their own long-term strategies</strong>.&nbsp;</p>



<p>The distinction above applies not just to artificial systems but also to human occupations as well. As an example, software developers, architects, engineers, or artists have&nbsp;<em>short-term</em> goals, in the sense that they provide some particular&nbsp;<em>product</em> (piece of software, design for a bridge, artwork, scientific paper) that can stand and be evaluated on its own merits. In contrast, leaders of companies and countries set&nbsp;<em>long-term goals</em> in the sense that they need to come up with a strategy that will yield benefits in the long run and cannot be assessed with confidence until it is implemented.<sup><a href="#footnotes">[2</a><a href="#fnh8xhqamyb87">]</a></sup>&nbsp;</p>



<p>We already have at least partial “short-term AI”, even if not at the level of replacing e.g., human software engineers. The existence of successful “long-term AI” that can come up with strategies which are enacted over a scale of, say, years is still an open question, but for the sake of this essay we accept that assumption.</p>



<p>We believe that when evaluating the loss-of-control scenario, the relevant competition is not between humans and AI systems, but rather between humans aided with short-term AI systems and long-term AI systems (themselves possibly aided with short-term components). One thought experiment we have in mind is a competition between two firms: one with a human CEO, but with AI engineers and advisors, and the other a fully AI firm.</p>



<p>While it might seem “obvious” that eventually AI would be far superior to humans in all endeavors, including being a CEO, we argue that this is not so obviously the case. We agree that future AIs could possess superior information processing and cognitive skills &#8211; a.k.a. “intelligence” &#8211; compared to humans. But the evidence so far suggests the&nbsp;<strong>advantages of these skills would be much more significant in some fields than in others</strong>. We believe that this is uncontroversial &#8211; for example, it’s not far-fetched to claim that AI would make much better chess players than kindergarten teachers. Specifically, there are&nbsp;<strong>“diminishing returns”</strong> for superior information-processing capabilities in the context of setting<strong> longer-term goals or strategies</strong>. The long time horizon and the relevance of interactions among high numbers of agents (who are themselves often difficult to predict) make real-life large-scale systems&nbsp;<strong>“chaotic”</strong> in the sense that even with superior analytic abilities, they are still unpredictable (see Figure 1).</p>



<p>As a consequence, we believe the<strong> main fields where AI systems will yield advantages will be in short-term domains</strong>. An AI engineer will be much more useful than an AI CEO (see also Table 2). We do not claim that it would be impossible to build an AI system that can conceive and execute long-term plans; only that this would not be where AI would have a “competitive advantage”. Short-term goals that can be evaluated and graded also mesh much better with the current paradigm of training AI systems on vast amounts of data.</p>



<p>We believe it&nbsp;<strong>will be possible to construct very useful AIs with only short-term goals,</strong> and in fact that the vast majority of AI’s power will come from such short-term systems. Even if a long-term AI system is built, it will likely&nbsp;<strong>not have a significant advantage over humans assisted with short-term AIs</strong>. There can be many risks even from short-term AI systems, but such machines cannot by design have any long-term goals, including the goal of taking over the world and killing all humans.<sup><a href="#footnotes">[3</a><a href="#fnk2m16hjnqf">]</a></sup></p>



<p><strong>Perspective.&nbsp;</strong>Our analysis also has a lesson for AI safety research. Traditionally, approaches to mitigate the behavior of bad actors include</p>



<ul>
<li><strong>Prevention:&nbsp;</strong>We prevent break-ins by putting locks on our doors, we prevent hacks by securing our systems, etc…&nbsp;</li>



<li><strong>Deterrence:&nbsp;</strong>Another way we prevent bad actions is by ensuring that the negative consequences for these actions will outweigh benefits. This is one basis for the penal system, as well as the “mutually assured destruction” paradigm that has kept Russia and US from a nuclear war.</li>



<li><strong>Alignment:</strong> We try to educate children and adults and socialize them to our values, so they are not motivated to pursue the actions we consider as bad.</li>
</ul>



<p>Much of AI safety research (wrt to the “loss of control” scenario) has been focused on the third approach, with the expectation that these systems may be so powerful that prevention and deterrence will be impossible. However, it is unclear to us that this will be the case. For example, it may well be that humans, aided by short-term AI systems, could vastly expand the scope of formally verified secure systems, and so prevent hacking attacks against sensitive resources. A huge advantage of research on prevention is that it is highly relevant not just to protect against hypothetical future bad AI actors, but also against current malicious humans. Such research might greatly&nbsp;<em>benefit&nbsp;</em>from advances in AI code-completion engines and other tools, hence belying the notion that there is a “zero-sum game” between “AI safety” and “AI capabilities” research.&nbsp;</p>



<p>Furthermore, one advantage of studying AI systems, as opposed to other organisms, is that we can try to extract useful modules and representations for them. (Indeed, this is already done in “transfer learning.”) Hence, it may be possible to extract useful and beneficial “short-term AI” even from long-term systems. Such restricted systems would still give most of the utility, but with less risk. Once again, increasing the capabilities of short-term AI systems will empower humans that are assisted by such systems.<br>&nbsp;</p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img src="https://lh5.googleusercontent.com/CrDF9kngAXpxxa1YLkXY1hdD7K2YMgMgvc8U8joLPJDX-PZyXIGMqR21cd7ebrszWUCK_VJEN2DcpHcb9NLbi6Y3Fi_HKlRzvirnv5wv_K2DW9md2s2WVpghmkoppI2Qros6HDeGRcwh7ZZHO9dWCAult2H-m1xjeiTgwy0O1GXtFShyNuk4EsopMR0rFQ" alt="" width="566" height="383" /></figure></div>


<p><strong>Figure 1:</strong> Cartoon of the feasibility of predicting future events and the level of ability (i.e., cognitive skill / compute / data) required to do so (approximately) optimally. As the horizon grows, events have more inherent uncertainty and also require more skills/data to predict. However, many realistic systems are&nbsp;<em>chaotic</em> and become unpredictable at some finite horizon.<sup><a href="#footnotes">[4</a><a href="#fnmrfsb0zx5hf">]</a></sup>&nbsp; At that point, even sophisticated agents cannot predict better than baseline heuristics, which require only a bounded level of skill.<br>&nbsp;</p>



<figure class="wp-block-table"><table><tbody><tr><td><em>Profession</em></td><td><em>Cognitive Score (standard deviations)</em></td><td><em>Annual Earnings&nbsp;</em></td></tr><tr><td><strong>Mayors</strong></td><td><strong>6.2 ( ≈ +0.6σ )</strong></td><td><strong>679K SEK</strong></td></tr><tr><td><strong>Parliamentarians</strong></td><td><strong>6.4 ( ≈ +0.7σ )</strong></td><td><strong>802K SEK</strong></td></tr><tr><td><strong>CEOs (10-24 employees)</strong></td><td><strong>5.8 ( ≈ +0.4σ )</strong></td><td><strong>675K SEK</strong></td></tr><tr><td><strong>CEOs (25-249 employees)</strong></td><td><strong>6.2 ( ≈ +0.6σ )</strong></td><td><strong>1,046K SEK</strong></td></tr><tr><td><strong>CEOs (≥ 250 employees)</strong></td><td><strong>6.7 ( ≈ +0.85σ )</strong></td><td><strong>1,926K SEK</strong></td></tr><tr><td>Medical Doctors</td><td>7.4 ( ≈ +1.2σ )</td><td>640K SEK</td></tr><tr><td>Lawyers and Judges</td><td>6.8 ( ≈ +0.9σ )</td><td>568K SEK</td></tr><tr><td>Economists</td><td>7 ( ≈ +1σ )</td><td>530K SEK</td></tr><tr><td>Political Scientists</td><td>6.8 ( ≈ +0.9σ )</td><td>513 SEK</td></tr></tbody></table></figure>



<p><strong>Table 2:</strong> Cognitive scores for Swedish men in various “elite” occupations, based on Swedish army entrance examinations, taken from&nbsp;<a href="https://academic.oup.com/qje/article-abstract/132/4/1877/3859758?redirectedFrom=fulltext"><u>Dal Bó et al</u></a> (Table II). Emphases ours: bold text corresponds to jobs that (in our view) require longer horizon decision-making across time or number of people. Note that despite being apparently less cognitively demanding, the “bold” professions are higher paying.</p>



<h2><strong>A digression: what is intelligence</strong></h2>



<p>Merriam-Webster&nbsp;<a href="https://www.merriam-webster.com/dictionary/intelligence"><u>defines</u></a> intelligence as “the skilled use of reason”, “the ability to learn or understand or to deal with new or trying situations”, or “to apply knowledge to manipulate one&#8217;s environment or to think abstractly.” Intelligence is similar to&nbsp;<em>computation</em>, in the sense that its main components are the ability to take in observations (aka “inputs”) and use reasoning (aka “algorithms”) to decide on actions (aka “outputs”). In fact, in the currently dominant paradigm of AI, performance is primarily determined by the amount of computation performed during learning, and AI systems consist of enormous homogeneous circuits executing a series of simple operations on (a large quantity of) inputs and learned knowledge.&nbsp;<a href="https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies"><u>Bostrom</u></a> (Chapter 3) defines three forms of “superintelligence”: “speed superintelligence”, “collective superintelligence” and “quality superintelligence”. In the language of computing, speed super-intelligence corresponds to clock speed of processors, while collective super-intelligence corresponds to massive parallelism. “Quality superintelligence” is not well defined, but is presumably some type of emergent phenomenon from passing some thresholds of speed and parallelism.</p>



<p><br>A fundamental phenomenon in computing is&nbsp;<em>universality:</em> there are many&nbsp;<em>restricted</em> computational models (finite state automata, context-free grammars, simply-typed lambda calculus), but once a computational model passes a certain threshold or&nbsp;<em>phase transition</em>, it becomes universal (a.k.a. “Turing complete”), and all universal models are equivalent to one another in computational power. For example, in a cellular automata, even though each cell is very restricted (can only store a constant amount of memory and process a finite rule based only on the state of its immediate neighbors), given enough cells we can simulate any arbitrarily complex machine.<sup><a href="#footnotes">[5]</a></sup>&nbsp; Once a system passes the universality transition, it is not bottlenecked any more by the complexity of an individual unit, but rather by the resources in the system as a whole.</p>



<p>In the animal kingdom, we seem to have undergone a similar phase transition, whereby humans are qualitatively more intelligent than any other animal or creature. It also seems to be the case that with the invention of language, the printing press, and the Internet, we (like cellular automata) are able to combine large numbers of humans to achieve feats of collective intelligence that are beyond any one individual. In particular, the fruits of the scientific revolution of the 1500-1600s increased the scale of GDP by 10,000-fold (to the extent such comparisons are meaningful) and the distance we can measure in space a trillion-fold, all with the same brains used by our hunter-gatherer ancestors (or&nbsp;<a href="https://www.frontiersin.org/articles/10.3389/fevo.2022.963568/full"><u>maybe</u></a> somewhat&nbsp;<a href="https://www.frontiersin.org/articles/10.3389/fevo.2021.742639/full"><u>smaller</u></a> ones).&nbsp;</p>



<p><a href="https://www.pnas.org/doi/full/10.1073/pnas.1100290108"><u>Arguably</u></a>, the fact humans are far better than chimpanzees at culturally transmitting knowledge is more significant than the gap in intelligence between individuals of the two species. Ever since the development of language, the intelligence of an individual human has&nbsp;<em>not</em> been a bottleneck for the achievements of humanity. The brilliance of individuals like Newton may have been crucial for speeding up the Scientific Revolution, but there have been brilliant individuals for millennia. The crucial difference between Newton and Archimedes is not that Newton was smarter, but rather that he lived at a later time and thus was able to stand on the shoulders of more giants. As another example, a collection of humans, aided by Internet-connected computers, can do much better at pretty much any intelligence feat (including but not limited to IQ exams) than any single human.&nbsp;<br>&nbsp;</p>



<figure class="wp-block-image"><img src="https://lh3.googleusercontent.com/ENKzULhufaFT8CI2c_l-YKNl5XldYKJA8CjBtw9TrV6NFao1pEhyk9pmyDHSsA1iY0aZG-zJxv1wVb7zaF6zaZnyptxKs2CXe5zaS-40ZR_m_Sf59X2HorWz1xZdGFd-aSfhdgpjPPRfYpj5OWBbZMqkpCZEj9sdeGIcRXN1tjjxucVZPUcgbKyHiGLmkA" alt="" /></figure>



<p><strong>Figure 3:</strong> Measures of human progress both in terms of GDP and the scale of objects we can measure. Taken from&nbsp;<a href="https://windowsontheory.org/2022/05/03/philosophy-of-science-and-the-blockchain-a-book-review/"><u>this blog post</u></a>, with the first figure from&nbsp;<a href="https://ourworldindata.org/grapher/world-gdp-over-the-last-two-millennia"><u>Our World in Data</u></a>, and data for second figure from Terence Tao’s&nbsp;<a href="https://terrytao.wordpress.com/2010/10/10/the-cosmic-distance-ladder-ver-4-1/"><u>cosmic ladder presentation</u></a>.</p>



<p><br>The “loss of control” scenario posits a&nbsp;<em>second phase transition</em>, whereby once AI systems become more powerful, they would not merely enable humans to achieve more objectives quicker but would themselves become as qualitatively superior to humans as humans are to other animals. We are suggesting an alternative future scenario, in which while AI would provide powerful new capabilities to human society that can (and unfortunately likely will) be used for ill as well as good, the AI systems themselves would not be the inevitable leaders of this society.</p>



<p>Indeed, our societies and firms do not currently select our leaders to be the top individuals in intellectual capacity. The evidence is very limited that “natural talent for leadership” (to the extent it exists) is as measurable and transferable as talent for chess, math, or athletics. There are many examples of leaders who have been extremely successful in one setting but failed in another which seems rather similar.<sup><a href="#footnotes">[6]</a></sup>&nbsp;</p>



<p>Whether or not an AI system should be considered an “individual” is a matter for debate, but regardless, it is not at all clear that such individuals would be the leaders of the society, rather than being employed in domains such as software development and scientific discovery, where their superior information-processing capabilities would provide the most competitive advantage. Bostrom (Table 8 in Chapter 6) lists several potential “cognitive superpowers” that an AI system might develop. One category is&nbsp;<em>“hacking”</em>,&nbsp;<em>“technology research”</em>, and&nbsp;<em>“economic productivity”</em>. These are skills that correspond to jobs that are not in the domain of CEOs or leaders, but rather engineers, middle managers, scientists, etc. AI systems may well be able to assist or even replace such individuals, but this does not mean such systems will be the leaders of companies or countries.</p>



<p>Another task Bostrom considers is&nbsp;<em>“intelligence amplification”</em> which is the ability to improve AI systems. Again, it is quite possible that AI systems would help in improving other or the same AI systems, but this on its own does not imply that they would become infinitely powerful. Specifically, if indeed stronger AI would arrive through “scaling” of massive computational resources, then there would be&nbsp;<a href="https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/"><u>some hard limits</u></a> on the ability to improve AI’s power solely through software updates. It is not at all clear that in terms of energy efficiency, AI systems would be much better (if at all) than humans. If the gains from scaling are far more important than gains from improved algorithms/architectures, then intelligence amplification might be primarily a function of resource acquisition rather than algorithmic research.</p>



<p>A third task listed is&nbsp;<em>“social manipulation.”</em> Here we must admit we are skeptical. Anyone who has ever tried to convince a dog to part with a bone or a child with a toy could attest to the diminishing returns that an intelligence advantage has in such a situation.&nbsp;</p>



<p>Finally, Boston lists the cognitive superpower of&nbsp;<em>“strategizing”</em>, which is the ability to make long-term plans to achieve distant goals. This is the point we focus on in this essay. In short, our belief is that the chaotic nature of the real world implies diminishing returns to “three-dimensional chess” strategies that are beyond the comprehension of mere humans. Hence we do not believe that this would be a domain where AI systems have a strong competitive advantage.</p>



<h2><br><strong>A thought experiment: “The AI CEO vs. the AI advisor”</strong></h2>



<p>Before we delve into the technical(-ish) analysis, let us consider a thought experiment. At its heart, our argument is that the power of AI systems, present and future, will not come from the ability to make long-term strategic plans (“three-dimensional chess”) but rather from the ability to produce pieces of work that can be evaluated on their own terms. In short, we believe that even if a long-term malicious AI system is constructed, it will not have an insurmountable advantage over humans that are assisted with short-term AIs. To examine this, let us imagine two possible scenarios for how future AI could assist humans in making strategic decisions, such as running a company:</p>



<ul>
<li>In the&nbsp;<strong>“AI Advisor”</strong> model, leaders could use AI to come up with simulations of the impact of decisions and possibly make some suggestions. However, humans would ultimately make the decision and evaluate their results. Key for this is that an AI would be able not just to produce a recommendation for a decision but explain how this decision would lead to improvement in some interpretable metric (e.g., revenue, market share, etc..). For example, a decision might be “let’s sell this product at a loss so we can increase our market share.”<br>&nbsp;</li>



<li>In the&nbsp;<strong>“AI CEO”</strong> model, AIs could use their superior powers to choose an optimal long-term&nbsp;<em>strategy</em> as opposed to an individual decision. The strategy would not be “greedy”, in the sense of a sequence of steps each making progress on measurable goals, and it would not have any compact analysis of why it is good. Also, the only way to accrue the benefits of the strategy would be to continue pursuing it in the long term. Hence users would have to trust the AI and follow its recommendations blindly. For example, think of the case in Chess where an AI figures out that the best move is to sacrifice the queen because for any one of the possible opponent’s moves, there is a countermove, and so on and so forth. The only explanation for why this strategy is a good one may consist of an exponentially big game tree up to a certain depth.</li>
</ul>



<p>Our sense is that there is strong evidence that AI would be incredibly useful for making low-level decisions (i.e., optimizing objectives under constraints) once the high-level strategy was set. Indeed, by far the most exciting advances for deep learning have&nbsp;<em>not</em> been through reinforcement learning, but rather through techniques such as supervised and unsupervised learning. (With the major exception being games like Chess and Go, though even there, given the&nbsp;<a href="https://lichess.org/broadcast/tcec-season-21-superfinal--stockfish-vs-leela-chess-zero/rounds-1-100/Mtixisaw"><u>success</u></a> of non-RL engines such as<a href="https://towardsdatascience.com/dissecting-stockfish-part-2-in-depth-look-at-a-chess-engine-2643cdc35c9a"><u> Stockfish&nbsp;</u></a>versions 12 and later, it is not clear RL is needed.) There is less evidence that “AI advisors” would be useful for setting high-level strategies, but it is certainly plausible. In particular, the power of prompt-based generative models suggests that AI could be useful for generating realistic simulations that can help better convey the impact of various decisions and events. So, while “AI engineers” might be more useful than “AI advisors”, the latter might well have their role as well.&nbsp;</p>



<p>In contrast, we believe that there is little to no evidence for the benefits of “three-dimensional chess” strategies of the type required for the “AI CEO” scenario. The real world (unlike the game of chess or even poker), involves a significant amount of unpredictability and chaos, which makes highly elaborate strategies depending on complex branching trees of moves and counter-moves far less useful. We also find it unlikely that savvy corporate boards would place blind trust in an AI CEO given that (as mentioned above) evaluation of even human CEOs tends to be controversial.&nbsp;</p>



<p>There is an alternative viewpoint, which is that an AI CEO would basically be equivalent to a human CEO but with superhuman “intuition” or “gut feeling” that they cannot explain but somehow leads to decisions that yield enormous benefits in the long term. While this viewpoint cannot be ruled out, there is no evidence in current deep learning successes to support it. Moreover, often great CEO’s “gut feelings” are less about particular decisions, but more about the relative importance of particular metrics (e.g., prioritizing market share or user experience over short-term profits).&nbsp;</p>



<p>In any case, even if one does not agree with our judgment of the relative likelihoods of the above scenarios, we hope that this essay will help sharpen the questions that need to be studied, as well as what lessons can we draw about them from the progress so far of AI systems.</p>



<h1><strong>Technical Analysis</strong></h1>



<h2><br><strong>1. Key hypotheses behind the “Loss of Control” Scenario</strong></h2>



<p>For the sake of the discussion below, let’s assume that at some future time there exists an artificial intelligence system that in a unified way achieves performance far superior to that achieved by all humans today across many fields. This is a necessary assumption for the “loss of control” scenario and an assumption we accept in this essay. For the sake of simplicity, below we refer to such AI systems as “powerful”.</p>



<p>We will also assume that powerful AI will be constructed following the general paradigm that has been so successful in the last decade of machine learning. Specifically, the system will be obtained by going through a large amount of data and computational steps to find some instantiation (a.k.a. “parameters” or “weights”) of it that optimizes some chosen objective. Depending on the choice of the objective, this paradigm includes supervised learning (“classify this image”), unsupervised learning (“predict the next token”), reinforcement learning (“win the game”), and more.</p>



<p><br>For the loss of control scenario to occur, the following two hypotheses must be true:<br>&nbsp;</p>



<blockquote class="wp-block-quote">
<p><strong>Loss-of-Control Hypothesis 1:</strong> There will exist a powerful AI that has long-term goals.</p>
</blockquote>



<p>For an AI to have misaligned long-term goals, it needs to have some long-term goals in the first place. There is a question of how to define the “goals” of an AI system or even a human for that matter. In this essay, we say that an agent has a goal X if, looking retrospectively at the history of the agent’s actions, the most parsimonious explanation for its actions was that it was attempting to achieve X, subject to other constraints or objectives. For example, while chess experts often find it hard to understand why an engine such as AlphaZero makes a specific move, by the end of the game, they often understand the reasoning retrospectively and the sub-goals it was pursuing.</p>



<p>In our parlance, a goal is “long-term” if it has a similar horizon to goals such as&nbsp;<em>“take over the world and kill all the humans”</em> —requiring planning over large scales of time, complexity, and number of agents involved.<sup><a href="#footnotes">[7]</a></sup>&nbsp;&nbsp;</p>



<p>In contrast, we consider goals such as “win a chess game”, “come up with a plan for a bridge that minimizes cost and can carry X traffic”, or “write a piece of software that meets the requirements Y”, as short-term goals.&nbsp; As another example, “come up with a mix of stocks to invest today that will maximize return next week” is a short-term goal, while “come up with a strategy for our company that will maximize our market cap over the next decade” or “come up with a strategy for our country that will maximize our GDP for the next generation” would be long-term goals. The distinction between “short-term goals AI” and “long-term goals AI” is somewhat similar to the distinction between “Tool AI” and “Agent AI” (see&nbsp;<a href="https://www.gwern.net/Tool-AI"><u>here</u></a>). However, what we call “short-term AI” encompasses much more than “Tool AI”, and absolutely includes systems that can take actions such as driving cars, executing trading actions, and so on and so forth.</p>



<p>We claim that for the “loss of control” scenario to materialize, we need not only Hypothesis 1 but also the following stronger hypothesis:</p>



<blockquote class="wp-block-quote">
<p><strong>Loss-of-Control Hypothesis 2:&nbsp;</strong>In several key domains,&nbsp;<em>only</em> AIs with long-term goals will be powerful.</p>
</blockquote>



<p><br>By this, we mean that AIs with long-term goals would completely dominate other AIs, in that they would be much more useful for any user (or for furthering their own goals). In particular,&nbsp; a country, company or organization that restricts itself to only using AIs with short term goals would be at a severe competitive disadvantage compared to one that uses AIs with long-term goals.</p>



<p>Why is Hypothesis 2 necessary for the “loss of control” scenario? The reason is that this scenario requires the “misaligned long-term powerful AI” to be not merely more powerful than humanity as it exists today, but more powerful than humanity in the future. Future humans will have at their disposal the assistance of short-term AIs.</p>



<h2><strong>2. Understanding the validity of the hypotheses</strong></h2>



<p>We now make the following claims, which we believe cast significant doubt on Hypothesis 2.</p>



<p><br><strong>Claim 1: There are diminishing returns to information-processing skills with longer horizons.</strong></p>



<p>Consider the task of predicting the consequences of a particular action in the future. In any sufficiently complex real-life scenario, the further away we attempt to predict, the more there is inherent uncertainty. For example, we can use advanced methods to predict the weather over a short time frame, but the further away the prediction, the more the system “regresses to the mean”, and&nbsp;<a href="https://www.globalagtechinitiative.com/digital-farming/data-management/weather-forecasting-how-does-it-work-and-how-reliable-is-it/"><u>the less advantage</u></a> that highly complex models have over simpler ones (see Figure 4). As in meteorology, this story seems to play out similarly in&nbsp;<a href="https://www.federalreserve.gov/econres/feds/the-accuracy-of-forecasts-prepared-for-the-federal-open-market-committee.htm"><u>macroeconomic forecasting</u></a>.&nbsp; In general, we expect prediction success to behave like Figure 1 below—the error increases with the horizon until it plateaus to a baseline level of some simple heuristic(s). Hence while initially highly sophisticated models can beat simpler ones by a wide margin, this advantage eventually diminishes with the time horizon.</p>



<p>Tetlock’s&nbsp;<a href="https://www.lesswrong.com/posts/dvYeSKDRd68GcrWoe/ten-commandments-for-aspiring-superforecasters"><u>first commandment</u></a> to potential superforecasters is to triage: “Don’t waste time either on “clocklike” questions (where simple rules of thumb can get you close to the right answer) or on impenetrable “cloud-like” questions (where even fancy statistical models can’t beat the dart-throwing chimp). Concentrate on questions in the Goldilocks zone of difficulty, where effort pays off the most.”&nbsp; Another way to say it is that outside of the Goldilocks zone, more effort or cognitive power does not give much returns.&nbsp;</p>



<figure class="wp-block-image size-large"><a href="https://windowsontheory.files.wordpress.com/2022/11/image.png"><img data-attachment-id="8474" data-permalink="https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/image-9/" data-orig-file="https://windowsontheory.files.wordpress.com/2022/11/image.png" data-orig-size="1224,440" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://windowsontheory.files.wordpress.com/2022/11/image.png?w=300" data-large-file="https://windowsontheory.files.wordpress.com/2022/11/image.png?w=656" src="https://windowsontheory.files.wordpress.com/2022/11/image.png?w=1024" alt="" class="wp-image-8474" srcset="https://windowsontheory.files.wordpress.com/2022/11/image.png?w=1024 1024w, https://windowsontheory.files.wordpress.com/2022/11/image.png?w=150 150w, https://windowsontheory.files.wordpress.com/2022/11/image.png?w=300 300w, https://windowsontheory.files.wordpress.com/2022/11/image.png?w=768 768w, https://windowsontheory.files.wordpress.com/2022/11/image.png 1224w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure>



<p><br><strong>Figure 4:&nbsp;</strong>&nbsp;Left: Historical weather prediction accuracy data taken from a&nbsp;<a href="https://qr.ae/pvVKIJ"><u>Quora answer of Mikko Strahlendorff</u></a>. With technological advances, accuracy has improved significantly, but prediction accuracy sharply decays with time. Right: Figure on relative applicability of different methods from&nbsp;<a href="https://www.globalagtechinitiative.com/digital-farming/data-management/weather-forecasting-how-does-it-work-and-how-reliable-is-it/"><u>Brent Shaw</u></a>. Computationally intensive numerical prediction applies in a “goldilocks zone” of days to weeks.</p>



<p>In a variety of human endeavors, it seems that the cognitive skills needed to make decisions display a similar phenomenon. Occupations involving making decisions on the mid-range horizon, such as engineering, law, and medicine, require higher cognitive skills than those requiring long-term decisions such as CEOs or Politicians (see Table 3).</p>



<p>One argument people make is that intelligence is not just about IQ or “<a href="https://www.lesswrong.com/posts/aiQabnugDhcrFtr9n/the-power-of-intelligence"><u>booksmarts</u></a>”. We do not dispute this. However, we do believe that the key potential advantage of AI systems over their human counterparts would be the ability to quickly process large amounts of information, which in humans is approximated by scores such as IQ. If that skill were key to successful leadership of companies or countries, then we would expect CEOs and leaders to come from the top 0.1% (≈ +3σ)&nbsp; of the distribution of such scores. The data does not bear this out.<sup><a href="#footnotes">[8]</a></sup>&nbsp;</p>



<p><strong>Claim 2:</strong>&nbsp;<strong>It may be possible to extract powerful short-term modules from long-term systems.</strong></p>



<p>For Hypothesis 2 to be true, it should not be possible to take a powerful AI system with long-term goals, and extract from it modules that would be just as powerful in the key domains, but would have short-term goals. However, a nascent body of work identifies and extracts useful representations and sub-modules in deep neural networks. See, for example, this recent investigation of&nbsp;<a href="https://arxiv.org/abs/2111.09259"><u>AlphaZero</u></a>. We remark that some components of AlphaZero also inspired advances to the Stockfish Chess Engine (which is not trained using RL and involves a lot of hand-coded features), and whose latest version&nbsp;<a href="https://ccrl.chessdom.com/ccrl/4040/"><u>does in fact beat</u></a> RL trained methods a-la AlphaZero.</p>



<p>A related issue is that a consistent theme of theoretical computer science is that verification is easier than solving or proving. Hence even a complex system could explain its reasoning to a simple verifier, even if that reasoning required a significant effort to discover. There are similar examples in human affairs: e.g., even though the discovery of quantum mechanics took thousands of years and multiple scientific revolutions, we can still teach it to undergraduates today whose brains are no better than those of the ancient Greeks.&nbsp;</p>



<h2><br><strong>2.1 The impact of the deep learning paradigm on Hypothesis 2</strong></h2>



<p><br>The following claims have to do with the way we believe advanced AI systems will be constructed. We believe it is fair to assume that the paradigm of using massive data and computation to create such systems, by optimizing with respect to a certain objective, will continue to be used. Indeed, it is the success of this paradigm that has caused the rise in concerns about AI in the first place.&nbsp; In particular, we want to make a clear distinction between the&nbsp;<em>training objective</em>, which the system is designed to optimize, versus the goals that the system appears to follow during its&nbsp;<em>deployment</em>.</p>



<p><strong>Claim 3: There may be fundamental “scaling laws” governing the amount of performance AI systems can achieve as a function of the data and computational resources.</strong></p>



<p>One of the original worries in the AI risk literature is the “<a href="https://edoras.sdsu.edu/~vinge/misc/singularity.html"><u>singularity</u></a>” scenario, by which an AI system continuously improves its own performance without limit. However, this assumes that a system can improve itself by rewriting its code, without requiring additional hardware resources.&nbsp; If there are hard limits to what can be achieved with a certain level of resources, then such self-improvements will also hit diminishing returns. There has been significant evidence for&nbsp;<a href="https://arxiv.org/abs/1909.12673"><u>the</u></a> “<a href="https://arxiv.org/abs/2001.08361"><u>scaling</u></a>&nbsp;<a href="https://arxiv.org/abs/2203.15556"><u>laws</u></a>” hypothesis in recent years.</p>



<p><br><br><img src="https://lh4.googleusercontent.com/b_3ZFahE15wnxQCDcRBEnnbGytqGJayIVfztpee7Ff3X8DkyqQT6VCpLABMnBUMy0dRaNpbQdpiWrwYGz_C-NSxovBP9E48nRixKyFT0PgnqhYdaxEUAeXMVxCtsT9ib4RSvhd7fvYgS3ZUJjg5HuQVpfwke49K8Ytys3mVX7hdCUbDugfkL42FnEZYi5Q" style="width:450px;"><br><strong>Figure 5:</strong> Scaling laws as computed by&nbsp;<a href="https://arxiv.org/abs/2203.15556"><u>Hoffman et al</u></a> (“Chinchilla”), see Figure A4 there. While the scaling laws are shaped differently from those of&nbsp;<a href="https://arxiv.org/abs/2001.08361"><u>Kaplan et al</u></a>, the qualitative point we make remains the same.</p>



<p><strong>Claim 4: When training with reinforcement learning, the gradient signal may decrease exponentially with the length of the horizon.</strong></p>



<p>Consider training a system that chooses a sequence of actions, and only gets a reward after H steps (where H is known as the “horizon”). If at any step there is some probability of an action leading to a “dead end” then the chances of getting a meaningful signal decrease&nbsp;<em>exponentially</em> with H. This is a fundamental obstacle to reinforcement learning and its applicability in open-ended situations with a very large space of actions, and a non-trivial cost for any interaction. In particular, one reason AlphaZero was successful was that in games such as chess, the space of legal moves is very constrained, and in the artificial context of a game it is possible to “reset” to a particular position: that is, one can try out different actions and see what their consequences are, and then go back to the same position. This is not possible when interacting in the real world.</p>



<p><br>&nbsp;As a corollary of Claim 4, we claim the following:</p>



<p><strong>Claim 5: There will be powerful AI systems that are trained with short-term objective functions.</strong></p>



<p>By this, we mean models that are trained on a reward/loss function that only depends on a relatively short span of actions/outputs. A canonical example of this is next-token prediction. That is, even if the eventual&nbsp;<em>deployment</em> of the model will involve it making actions and decisions over a long time horizon, its&nbsp;<em>training</em> will involve optimizing short-term rewards.</p>



<p>&nbsp;One might think that the model&#8217;s training does not matter as much, since once it is deployed in the real world, much of what it will learn will be “on the job”. However, this is not at all clear. Suppose the average worker reads/hears about 10 pages per day, which is roughly 5K tokens, leading to roughly 2M tokens per year. In contrast, future AIs will likely be trained on a trillion tokens or so, corresponding to the amount a worker will see in 5 million years! This means that while “fine-tuning” or “in context” learning can and will occur, many of the fundamental capabilities of the systems will be fixed at the time of training (as appears to be the case for pre-trained language models that are fine-tuned with human feedback).</p>



<p><strong>Claim 6: For a long-term goal to necessarily emerge from a system trained with a short-term objective, it must be correlated or causally related to that objective.</strong></p>



<p>If we assume that powerful AIs will be trained with short-term objectives, then Hypothesis 2 requires that (in several key domains)&nbsp;<em>every</em> such system will develop long-term goals. In fact, for the loss-of-control scenario to hold, every such system should develop more-or-less the same sort of goal (e.g., “take over the world”).</p>



<p>While it is certainly possible for systems that evolve from simple rules to develop complex behavior (e.g.,&nbsp;<a href="https://en.wikipedia.org/wiki/Cellular_automaton"><u>cellular automata</u></a>), for a long-term goal to&nbsp;<em>consistently emerge</em> from mere short-term training, there should be some causal relation (or at least persistent correlation)&nbsp; between the long-term goal and the short-term training objective. This is because an AI system can be modeled as a maximizer of the objective on which it was trained. Thus for such a system to&nbsp;<em>always</em> pursue a particular long-term goal, that goal should be correlated with maximizing the training objective.</p>



<p>We illustrate this with an example. Consider an AI software developer which is trained to receive a specification of a software task (say, given by some unit tests) and then come up with a module implementing it, obtaining a reward if the module passes the tests. Now suppose that in actual deployment, the system is also writing the tests that would be used to check its future outputs. We might worry that the system would develop a “long-term” goal to maximize total reward by writing one faulty test, taking the “hit” on it, and receiving a low reward, but then getting high rewards on future tasks. However, that worry would be unfounded, since the AI software developer system is trained to maximize the reward for each task separately, as opposed to maximizing the sum of rewards over time over adaptively chosen inputs of its own making.</p>



<p>Indeed, this situation can already happen today. Next-token prediction models such as GPT-3 are trained on the reward of the perplexity over a single token, but when they are deployed, we typically generate a long sequence of tokens. Now consider a model that simply outputs an endless repetition of the word “blah”. The first few repetitions would get very low rewards, since they are completely unexpected, but once n is large enough (e.g. 10 or so), if you’ve already seen n “blah”s then the probability that the n+1 st word is also “blah” is very high.&nbsp; So if the model were to be maximizing total reward, it may well be worth “taking the hit” by outputting a few blahs. The key point is that GPT-3 does&nbsp;<em>not</em> do that. Since it is trained on predicting the next token for human-generated (as opposed to the text generated by itself), it will optimize for this short-term objective rather than the long-term one.</p>



<p>We believe the example above generalizes to many other cases. An AI system trained in the current paradigm is, by default, a maximizer of the objective it was trained on, rather than an autonomous agent that pursues goals of its own design. The shorter the horizon and more well-defined the objective is, the less likely that optimizing it will lead to systems that appear to take elaborate plans to pursue far-reaching (good or bad) long-term goals.&nbsp;</p>



<h1><br><strong>Summary</strong></h1>



<p>Given the above, we believe that while AI will continue to yield breakthroughs in many areas of human endeavor, we will not see a unitary nigh-omnipotent AI system that acts autonomously to pursue long-term goals. Concretely, even if a successful long-term AI system could be constructed, we believe that this is not a domain where AI will have a significant “competitive advantage” over humans.</p>



<p>Rather, based on what we know, it is likely that AI systems will have a “sweet spot” of a not-too-long horizon in which they can provide significant benefits. For strategic and long-term decisions that are far beyond this sweet spot, the superior information processing skills of AIs will give diminishing returns. (Although AIs will likely supply valuable input and analysis to the decision makers.).&nbsp; An AI engineer may well dominate a human engineer (or at least one that is not aided by AI tools), but an AI CEO’s advantage will be much more muted, if any, over its human counterpart. Like our world, such a world will still involve much conflict and competition, with all sides aided by advanced technology, but without one system that dominates all others.</p>



<p>If our analysis holds, then it also suggests different approaches to mitigating AI risk than have been considered in the “AI safety” community. Currently, the prevailing wisdom in that community is that AI systems with long-term goals are a given, and hence the approach to mitigate their risk is to “align” these goals with human values. However, perhaps more evidence should be placed on building just-as-powerful AI systems that are restricted to short time horizons. Such systems could also be used to monitor and control other AIs, whether autonomous or directed by humans. This includes monitoring and hardening systems against hacking, detecting misinformation, and more. Regardless, we believe that more research needs to be done on understanding the internal representations of deep learning systems, and what features and strategies emerge from the training process (so we are happy that the AI safety community is putting increasing resources into “interpretability” research). There is&nbsp;<a href="https://arxiv.org/abs/2106.07682"><u>some evidence</u></a> that the same internal representations emerge regardless of the choices made in training.</p>



<p>There are also some technical research directions that would affect whether our argument is correct. For instance, we are interested in seeing work on the impacts of noise and unpredictability on the performance of reinforcement learning algorithms; in particular, on the&nbsp;<em>relative</em> performance of models of varying complexity (i.e.&nbsp;<a href="https://arxiv.org/abs/2104.03113"><u>scaling</u></a>&nbsp;<a href="https://arxiv.org/abs/2210.00849"><u>laws</u></a> for RL).</p>



<p><strong>Acknowledgments: </strong>Thanks to Yafah Edelman for comments on an earlier version of this essay.</p>



<h2 id="footnotes"><strong>Footnotes</strong></h2>



<ol>
<li>During the 90s-2000s, human-engine teams were able to consistently beat engines in&nbsp;<a href="https://en.wikipedia.org/wiki/Advanced_chess"><u>“advanced chess”</u></a> tournaments, but no major advanced chess tournament seems to have taken place since the release of AlphaZero and the resulting jump in engine strength, presumably because the human half of each team would be superfluous.</li>



<li>The success of a bridge does hinge on its long-term stability, but stability can be tested before the bridge is built, and coming up with measures for load-bearing and other desiderata is standard practice in the engineering profession. An AI trained using such a short-term evaluation suite as its reward function may still “<a href="https://arxiv.org/abs/2210.10760"><u>overoptimize</u></a>” against the metric, a la Goodhart’s Law, but this can likely be addressed with regularization techniques.</li>



<li>It may be the case that, for subtle reasons, if we try to train an AI with only short-term goals—e.g. by training in a series of short episodes—we could accidentally end up with an AI that has long-term goals. See Claim 6 below. But avoiding this pitfall seems like an easier problem than “aligning” the goals of an AI that is explicitly meant to care about the long-term.</li>



<li>We don’t mean that they satisfy&nbsp;<a href="https://en.wikipedia.org/wiki/Chaos_theory#Chaotic_dynamics"><u>all the formal requirements</u></a> to be defined as a chaotic system; though sensitivity to initial conditions is crucial.</li>



<li>For a nice illustration, see Sam Trajtenberg’s construction of&nbsp;<a href="https://twitter.com/boazbaraktcs/status/1586798286463270914?s=20&amp;t=bEhHVwKP7N6yyp_s2K2HRw"><u>Minecraft in Minecraft</u></a>, or this construction of&nbsp;<a href="https://www.youtube.com/watch?v=xP5-iIeKXE8"><u>Life in Life</u></a>.</li>



<li>Steve Jobs at Apple vs NeXT is one such example; success and failure can themselves be difficult to distinguish even with the benefit of hindsight, as in the case of&nbsp;<a href="https://www.newyorker.com/magazine/2022/11/07/was-jack-welch-the-greatest-ceo-of-his-day-or-the-worst"><u>Jack Welch</u></a>.</li>



<li>For example, such planning might require setting up many companies to earn large amounts of funds, conducting successful political campaigns in several countries, constructing laboratories without being detected, etc. Some such “take-over scenarios” are listed by Bostrom, as well as&nbsp;<a href="https://forum.effectivealtruism.org/posts/zzFbZyGP6iz8jLe9n/agi-ruin-a-list-of-lethalities"><u>Yudkowski</u></a> and&nbsp;<a href="https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html"><u>Urban</u></a>.</li>



<li>It is hypothetically possible that companies would be better off en masse if they hired smarter CEOs than they currently do, but given the high compensation CEOs receive this doesn’t seem like a particularly plausible equilibrium.</li>
</ol>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-22T14:05:27Z">Tuesday, November 22 2022, 14:05</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.10669'>Littlewood-Richardson coefficients and Kostka number</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sagar Shrivastava</p><p>Littlewood-Richardson (LR) coefficients and Kostka Numbers appear in
representation theory and combinatorics related to GLn . It is known that
Kostka numbers can be represented as special Littlewood-Rischardson
coefficient. In this paper, we show how one can represent LR coefficient in
terms of Kostka numbers, and use the formulation to give a polynomial time
algorithm for the same, hence showing that they belong to the same class of
decision problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Shrivastava_S/0/1/0/all/0/1">Sagar Shrivastava</a></p><p>Littlewood-Richardson (LR) coefficients and Kostka Numbers appear in
representation theory and combinatorics related to GLn . It is known that
Kostka numbers can be represented as special Littlewood-Rischardson
coefficient. In this paper, we show how one can represent LR coefficient in
terms of Kostka numbers, and use the formulation to give a polynomial time
algorithm for the same, hence showing that they belong to the same class of
decision problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-22T01:30:00Z">Tuesday, November 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.10471'>Prophet-Inequalities over Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andreas Abels, Elias Pitschmann, Daniel Schmand</p><p>In this paper, we introduce an over-time variant of the well-known
prophet-inequality with i.i.d. random variables. Instead of stopping with one
realized value at some point in the process, we decide for each step how long
we select the value. Then we cannot select another value until this period is
over. The goal is to maximize the expectation of the sum of selected values. We
describe the structure of the optimal stopping rule and give upper and lower
bounds on the prophet-inequality. - Which, in online algorithms terminology,
corresponds to bounds on the competitive ratio of an online algorithm.
</p>
<p>We give a surprisingly simple algorithm with a single threshold that results
in a prophet-inequality of $\approx 0.396$ for all input lengths $n$.
Additionally, as our main result, we present a more advanced algorithm
resulting in a prophet-inequality of $\approx 0.598$ when the number of steps
tends to infinity. We complement our results by an upper bound that shows that
the best possible prophet-inequality is at most $1/\varphi \approx 0.618$,
where $\varphi$ denotes the golden ratio. As part of the proof, we give an
advanced bound on the weighted mediant.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Abels_A/0/1/0/all/0/1">Andreas Abels</a>, <a href="http://arxiv.org/find/cs/1/au:+Pitschmann_E/0/1/0/all/0/1">Elias Pitschmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmand_D/0/1/0/all/0/1">Daniel Schmand</a></p><p>In this paper, we introduce an over-time variant of the well-known
prophet-inequality with i.i.d. random variables. Instead of stopping with one
realized value at some point in the process, we decide for each step how long
we select the value. Then we cannot select another value until this period is
over. The goal is to maximize the expectation of the sum of selected values. We
describe the structure of the optimal stopping rule and give upper and lower
bounds on the prophet-inequality. - Which, in online algorithms terminology,
corresponds to bounds on the competitive ratio of an online algorithm.
</p>
<p>We give a surprisingly simple algorithm with a single threshold that results
in a prophet-inequality of $\approx 0.396$ for all input lengths $n$.
Additionally, as our main result, we present a more advanced algorithm
resulting in a prophet-inequality of $\approx 0.598$ when the number of steps
tends to infinity. We complement our results by an upper bound that shows that
the best possible prophet-inequality is at most $1/\varphi \approx 0.618$,
where $\varphi$ denotes the golden ratio. As part of the proof, we give an
advanced bound on the weighted mediant.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-22T01:30:00Z">Tuesday, November 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.10507'>Efficient Determinant Maximization for All Matroids</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adam Brown, Aditi Laddha, Madhusudhan Pittu, Mohit Singh</p><p>Determinant maximization provides an elegant generalization of problems in
many areas, including convex geometry, statistics, machine learning, fair
allocation of goods, and network design. In an instance of the determinant
maximization problem, we are given a collection of vectors $v_1,\ldots, v_n \in
\mathbb{R}^d$, and the goal is to pick a subset $S\subseteq [n]$ of given
vectors to maximize the determinant of the matrix $\sum_{i \in S} v_iv_i^\top$,
where the picked set of vectors $S$ must satisfy some combinatorial constraint
such as cardinality constraint ($|S| \leq k$) or matroid constraint ($S$ is a
basis of a matroid defined on $[n]$).
</p>
<p>In this work, we give a combinatorial algorithm for the determinant
maximization problem under a matroid constraint that achieves
$O(d^{O(d)})$-approximation for any matroid of rank $r\geq d$. This complements
the recent result of~\cite{BrownLPST22} that achieves a similar bound for
matroids of rank $r\leq d$, relying on a geometric interpretation of the
determinant. Our result matches the best-known estimation
algorithms~\cite{madan2020maximizing} for the problem, which could estimate the
objective value but could not give an approximate solution with a similar
guarantee. Our work follows the framework developed by~\cite{BrownLPST22} of
using matroid intersection based algorithms for determinant maximization. To
overcome the lack of a simple geometric interpretation of the objective when $r
\geq d$, our approach combines ideas from combinatorial optimization with
algebraic properties of the determinant. We also critically use the properties
of a convex programming relaxation of the problem introduced
by~\cite{madan2020maximizing}.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brown_A/0/1/0/all/0/1">Adam Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Laddha_A/0/1/0/all/0/1">Aditi Laddha</a>, <a href="http://arxiv.org/find/cs/1/au:+Pittu_M/0/1/0/all/0/1">Madhusudhan Pittu</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1">Mohit Singh</a></p><p>Determinant maximization provides an elegant generalization of problems in
many areas, including convex geometry, statistics, machine learning, fair
allocation of goods, and network design. In an instance of the determinant
maximization problem, we are given a collection of vectors $v_1,\ldots, v_n \in
\mathbb{R}^d$, and the goal is to pick a subset $S\subseteq [n]$ of given
vectors to maximize the determinant of the matrix $\sum_{i \in S} v_iv_i^\top$,
where the picked set of vectors $S$ must satisfy some combinatorial constraint
such as cardinality constraint ($|S| \leq k$) or matroid constraint ($S$ is a
basis of a matroid defined on $[n]$).
</p>
<p>In this work, we give a combinatorial algorithm for the determinant
maximization problem under a matroid constraint that achieves
$O(d^{O(d)})$-approximation for any matroid of rank $r\geq d$. This complements
the recent result of~\cite{BrownLPST22} that achieves a similar bound for
matroids of rank $r\leq d$, relying on a geometric interpretation of the
determinant. Our result matches the best-known estimation
algorithms~\cite{madan2020maximizing} for the problem, which could estimate the
objective value but could not give an approximate solution with a similar
guarantee. Our work follows the framework developed by~\cite{BrownLPST22} of
using matroid intersection based algorithms for determinant maximization. To
overcome the lack of a simple geometric interpretation of the objective when $r
\geq d$, our approach combines ideas from combinatorial optimization with
algebraic properties of the determinant. We also critically use the properties
of a convex programming relaxation of the problem introduced
by~\cite{madan2020maximizing}.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-22T01:30:00Z">Tuesday, November 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.10516'>PIM-tree: A Skew-resistant Index for Processing-in-Memory</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hongbo Kang, Yiwei Zhao, Guy E. Blelloch, Laxman Dhulipala, Yan Gu, Charles McGuffey, Phillip B. Gibbons</p><p>The performance of today's in-memory indexes is bottlenecked by the memory
latency/bandwidth wall. Processing-in-memory (PIM) is an emerging approach that
potentially mitigates this bottleneck, by enabling low-latency memory access
whose aggregate memory bandwidth scales with the number of PIM nodes. There is
an inherent tension, however, between minimizing inter-node communication and
achieving load balance in PIM systems, in the presence of workload skew. This
paper presents PIM-tree, an ordered index for PIM systems that achieves both
low communication and high load balance, regardless of the degree of skew in
the data and the queries. Our skew-resistant index is based on a novel division
of labor between the multi-core host CPU and the PIM nodes, which leverages the
strengths of each. We introduce push-pull search, which dynamically decides
whether to push queries to a PIM-tree node (CPU -&gt; PIM-node) or pull the node's
keys back to the CPU (PIM-node -&gt; CPU) based on workload skew. Combined with
other PIM-friendly optimizations (shadow subtrees and chunked skip lists), our
PIM-tree provides high-throughput, (guaranteed) low communication, and
(guaranteed) high load balance, for batches of point queries, updates, and
range scans.
</p>
<p>We implement the PIM-tree structure, in addition to prior proposed PIM
indexes, on the latest PIM system from UPMEM, with 32 CPU cores and 2048 PIM
nodes. On workloads with 500 million keys and batches of one million queries,
the throughput using PIM-trees is up to 69.7x and 59.1x higher than the two
best prior methods. As far as we know these are the first implementations of an
ordered index on a real PIM system.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kang_H/0/1/0/all/0/1">Hongbo Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yiwei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Blelloch_G/0/1/0/all/0/1">Guy E. Blelloch</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1">Laxman Dhulipala</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+McGuffey_C/0/1/0/all/0/1">Charles McGuffey</a>, <a href="http://arxiv.org/find/cs/1/au:+Gibbons_P/0/1/0/all/0/1">Phillip B. Gibbons</a></p><p>The performance of today's in-memory indexes is bottlenecked by the memory
latency/bandwidth wall. Processing-in-memory (PIM) is an emerging approach that
potentially mitigates this bottleneck, by enabling low-latency memory access
whose aggregate memory bandwidth scales with the number of PIM nodes. There is
an inherent tension, however, between minimizing inter-node communication and
achieving load balance in PIM systems, in the presence of workload skew. This
paper presents PIM-tree, an ordered index for PIM systems that achieves both
low communication and high load balance, regardless of the degree of skew in
the data and the queries. Our skew-resistant index is based on a novel division
of labor between the multi-core host CPU and the PIM nodes, which leverages the
strengths of each. We introduce push-pull search, which dynamically decides
whether to push queries to a PIM-tree node (CPU -&gt; PIM-node) or pull the node's
keys back to the CPU (PIM-node -&gt; CPU) based on workload skew. Combined with
other PIM-friendly optimizations (shadow subtrees and chunked skip lists), our
PIM-tree provides high-throughput, (guaranteed) low communication, and
(guaranteed) high load balance, for batches of point queries, updates, and
range scans.
</p>
<p>We implement the PIM-tree structure, in addition to prior proposed PIM
indexes, on the latest PIM system from UPMEM, with 32 CPU cores and 2048 PIM
nodes. On workloads with 500 million keys and batches of one million queries,
the throughput using PIM-trees is up to 69.7x and 59.1x higher than the two
best prior methods. As far as we know these are the first implementations of an
ordered index on a real PIM system.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-22T01:30:00Z">Tuesday, November 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.10556'>A Distanced Matching Game, Decremental APSP in Expanders, and Faster Deterministic Algorithms for Graph Cut Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Julia Chuzhoy</p><p>Expander graphs play a central role in graph theory and algorithms. With a
number of powerful algorithmic tools developed around them, such as the
Cut-Matching game, expander pruning, expander decomposition, and algorithms for
decremental All-Pairs Shortest Paths (APSP) in expanders, to name just a few,
the use of expanders in the design of graph algorithms has become ubiquitous.
Specific applications of interest to us are fast deterministic algorithms for
cut problems in static graphs, and algorithms for dynamic distance-based graph
problems, such as APSP.
</p>
<p>Unfortunately, the use of expanders in these settings incurs a number of
drawbacks. For example, the best currently known algorithm for decremental APSP
in constant-degree expanders can only achieve a $(\log
n)^{O(1/\epsilon^2)}$-approximation with $n^{1+O(\epsilon)}$ total update time
for any $\epsilon$. All currently known algorithms for the Cut Player in the
Cut-Matching game are either randomized, or provide rather weak guarantees.
This, in turn, leads to somewhat weak algorithmic guarantees for several
central cut problems: for example, the best current almost linear time
deterministic algorithm for Sparsest Cut can only achieve approximation factor
$(\log n)^{\omega(1)}$. Lastly, when relying on expanders in distance-based
problems, such as dynamic APSP, via current methods, it seems inevitable that
one has to settle for approximation factors that are at least $\Omega(\log n)$.
</p>
<p>In this paper we propose the use of well-connected graphs, and introduce a
new algorithmic toolkit for such graphs that, in a sense, mirrors the above
mentioned algorithmic tools for expanders. One of these new tools is the
Distanced Matching game, an analogue of the Cut-Matching game for
well-connected graphs. We demonstrate the power of these new tools by obtaining
better results for several of the problems mentioned above.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chuzhoy_J/0/1/0/all/0/1">Julia Chuzhoy</a></p><p>Expander graphs play a central role in graph theory and algorithms. With a
number of powerful algorithmic tools developed around them, such as the
Cut-Matching game, expander pruning, expander decomposition, and algorithms for
decremental All-Pairs Shortest Paths (APSP) in expanders, to name just a few,
the use of expanders in the design of graph algorithms has become ubiquitous.
Specific applications of interest to us are fast deterministic algorithms for
cut problems in static graphs, and algorithms for dynamic distance-based graph
problems, such as APSP.
</p>
<p>Unfortunately, the use of expanders in these settings incurs a number of
drawbacks. For example, the best currently known algorithm for decremental APSP
in constant-degree expanders can only achieve a $(\log
n)^{O(1/\epsilon^2)}$-approximation with $n^{1+O(\epsilon)}$ total update time
for any $\epsilon$. All currently known algorithms for the Cut Player in the
Cut-Matching game are either randomized, or provide rather weak guarantees.
This, in turn, leads to somewhat weak algorithmic guarantees for several
central cut problems: for example, the best current almost linear time
deterministic algorithm for Sparsest Cut can only achieve approximation factor
$(\log n)^{\omega(1)}$. Lastly, when relying on expanders in distance-based
problems, such as dynamic APSP, via current methods, it seems inevitable that
one has to settle for approximation factors that are at least $\Omega(\log n)$.
</p>
<p>In this paper we propose the use of well-connected graphs, and introduce a
new algorithmic toolkit for such graphs that, in a sense, mirrors the above
mentioned algorithmic tools for expanders. One of these new tools is the
Distanced Matching game, an analogue of the Cut-Matching game for
well-connected graphs. We demonstrate the power of these new tools by obtaining
better results for several of the problems mentioned above.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-22T01:30:00Z">Tuesday, November 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
