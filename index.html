<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-06-05T22:30:40Z">Monday, June 05 2023, 22:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, June 05
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/'>The (local) unit of intelligence is FLOPs</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          [Crossposting again on&#160;Lesswrong and&#160;Windowsontheory, with the hope I am not overstaying my welcome in LW.] Wealth can be measured by dollars. This is not a perfect measurement: it’s hard to account for purchasing power and circumstances when comparing people across varying countries or time periods. However, within a particular place and time, one can measure &#8230; Continue reading The (local) unit of intelligence is&#160;FLOPs
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><em>[Crossposting again on&nbsp;</em><a href="https://www.lesswrong.com/"><em><u>Lesswrong</u></em></a><em> and&nbsp;</em><a href="https://windowsontheory.org/"><em><u>Windowsontheory</u></em></a><em>, with the hope I am not overstaying my welcome in LW.]</em></p>



<p><br>Wealth can be measured by <em>dollars</em>. This is not a perfect measurement: it’s hard to account for purchasing power and circumstances when comparing people across varying countries or time periods. However, within a particular place and time, one can measure wealth in the local currency. It still does not capture everything (e.g., future earnings, social connections). But generally, all else being roughly equal, the more dollars one has, the wealthier one is.</p>



<p>How do we measure intelligence? I am not interested in measuring the intelligence of individual humans or individual animals. Nor am I looking for a universal absolute scale of intelligence on which we could rank humans, elephants, and GPT4. (Indeed, it doesn’t seem that a one-dimensional comparison can be made; for example, we seem to be more intelligent than elephants on most dimensions, but they do have an&nbsp;<a href="https://www.sciencedirect.com/science/article/pii/S014976340700070X"><u>impressive memory</u></a>.)&nbsp; Rather, I want to compare different&nbsp;<em>species</em> within the same genus or different&nbsp;<em>models</em> within the same general architecture (e.g., Transformers).&nbsp;</p>



<p>I think it’s fair to say that the local unit of intelligence for animal species is&nbsp;<em>neurons</em>. While elephants have larger brains than humans, within the genus&nbsp;<em>Homo</em>, to a first approximation, the bigger the brain, the more intelligent the species.&nbsp;</p>



<figure class="wp-block-image"><img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/e5d88d991fc175c7676c6ada658142cd44b9887c69c15521.png" alt="" /></figure>



<p>(Figure from&nbsp;<a href="https://chomsky.info/20140826/"><u>Bolihus et al.</u></a>)</p>



<p>I claim that within the current architectures and training frameworks of large language models,&nbsp;<strong>the local unit of intelligence is FLOPs</strong>. That is, as long as we follow the current paradigm of training transformer-based architectures within best practices of scaling compute and data, the more compute resources (FLOPs) invested in training the model, the more intelligent it is. This is an imperfect measurement, but probably one that is better than trying to give models “IQ exams” that were designed for humans (and even there have&nbsp;<a href="https://erikhoel.substack.com/p/your-iq-isnt-160-no-ones-is"><u>dubious value</u></a>).&nbsp; Another way to say this is that the intelligence of the model scales with the number of&nbsp;<strong>“load-bearing gradient steps”</strong> that have gone into training it.</p>



<p>So far, it might seem like a tautology, but as I claimed in the&nbsp;<a href="https://windowsontheory.org/2023/05/19/gpt-as-an-intelligence-forklift/"><u>“intelligence forklift” post</u></a>, this does have some implications. In particular, current general-purpose models such as ChatGPT are built in two phases. The first phase is a&nbsp;<strong>pretraining phase</strong>, in which the model is trained in a Trillion or more gradient steps on the next-token prediction task. The second phase is the&nbsp;<strong>adaptation/fine-tuning phase</strong>, in which, whether through instruction-tuning, reinforcement learning on human feedback (RLHF) or other methods, the model is “fine tuned” using fewer than a million gradient steps to be a better instruction-following or chatting agent. In other words, more than 99.9% (maybe as much as 99.9999%) of the FLOPs / gradient steps in training the model are invested during its pretraining phase. (One reason that the fine-tuning phase involves much fewer gradient steps is that, while the first phase can use any static data grabbed from the Internet, the second phase requires data that was especially collected for this task and often needs human labeling as well.)&nbsp;</p>



<p>The adaptation phase can make a huge difference in the usefulness of the model. The&nbsp;<a href="https://chat.lmsys.org/?arena"><u>chatbot arena</u></a> doesn’t even contain non-fine-tuned models, and we can see that smaller but well-tuned models can put up a decent fight against ones that have at least 10 times the parameters (and so roughly at least 100 times the training compute). Unlike sashimi, language models should not be consumed raw. &nbsp;</p>



<figure class="wp-block-image"><img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/fb47b643997a81bbcc3b8b7ef043ec132b28ff4071de246f.png" alt="" /></figure>



<p><br>However, their “intelligence” is ultimately derived from the FLOPs invested in the base models. (See also <a href="https://arxiv.org/abs/2305.15717"><u>this paper </u></a>on the limitations of fine-tuning to close capability gaps.) Fine-tuning, whether using RL or not, is the proverbial “<a href="https://medium.com/syncedreview/yann-lecun-cake-analogy-2-0-a361da560dae"><u>cherry on the cake</u></a>” and the pre-trained model captures more than 99.9% of the intelligence of the model.  That pretrained model is <a href="https://www.lesswrong.com/s/N7nDePaNabJdnbXeE/p/vJFdjigzmcXMhNTsx"><u>not an agent</u></a> and <a href="https://astralcodexten.substack.com/p/janus-simulators"><u>does not have goals</u></a> though it can “play one on TV” in the sense of coming up with plans and proposed actions if prompted to do so. (In LW language, a <a href="https://www.lesswrong.com/tag/simulator-theory">simulator</a>.) This is why a pretrained model can be modeled as an <a href="https://www.lesswrong.com/posts/wDL6wiqg3c6WFisHq/gpt-as-an-intelligence-forklift"><u>“intelligence forklift”</u></a>. Just like a forklift supplies strength but is useless without someone driving it, so does the pretrained model supply intelligence, but that intelligence needs to be directed via fine-tuning, conditioning on prompts, etc.  Another way to think of the pre-trained model is as the bee colony and the adapter as the queen. (That is, if the queen bee was actually telling bees what to do rather than just <a href="https://www.perfectbee.com/learn-about-bees/the-life-of-bees/role-queen-bee"><u>laying eggs</u></a>.)</p>



<figure class="wp-block-image"><img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/da45c0196d68d4c0a178bc2d54360510fa6ca80b2caa40ec.png" alt="" /></figure>



<p>In that sense, while I agree with&nbsp;<a href="https://gwern.net/tool-ai"><u>Gwern</u></a> that agentic models are more&nbsp;<em>useful</em> and that<em> “we don’t want low log-loss error on ImageNet, we want to refind a particular personal photo”</em> , I disagree that&nbsp;<em>“Agent AIs [will be] more intelligent than Tool AIs.”&nbsp;</em>Intelligence and usefulness are not the same thing.</p>



<h2 class="wp-block-heading">Implications for alignment</h2>



<p>If the pre-trained model does not have goals, then there is no sense in “aligning” it. Rather, there is a separation of concerns, with a highly intelligent but goal-less pre-trained model (“forklift”) and a not-so-intelligent but goal-directed adaptor (“driver”). It is the latter one that we need to align:</p>



<blockquote class="wp-block-quote">
<p><strong>The component of an AI system that needs to be aligned is not the component that accounts for its intelligence.</strong></p>
</blockquote>



<p>That is a hopeful lesson since the adaptor can be a much smaller (e.g. have drastically&nbsp;<a href="https://arxiv.org/abs/2106.09685"><u>fewer parameters</u></a>) and tractable object. However, it does not mean that the alignment problem is easy and that we are insulated from the complexities of the pretrained model:</p>



<blockquote class="wp-block-quote">
<p><strong>A forklift with a speed of 1000mph might not be actively trying to kill you, but this could still be the end result.</strong></p>
</blockquote>



<p>In particular, we don’t understand the biases the pre-trained model inherits from the data, nor the way that these may play out when we use the model in applications. However, it does seem that for a pretrained model to be as good at its job as possible, it should learn all the biases in its data but not be constrained to any of them. It should be able to adapt to any context real or imagined and be the “perfect actor” that can take on any character’s personality.</p>



<p>The traditional “anthropomorphic” view of intelligence is as something that “belongs” to an individual or&nbsp;<em>agent&nbsp;</em>and that this agent has some sort of preferences or goals (a.k.a a&nbsp;<em>utility function</em>). Hence a potential future super-intelligent AI was thought of as an “alien” that pursues some goals. Under this viewpoint, we want to either “box” the alien to control its impact or “align” its goals to ours. Both of these options treat the AI system as a single component encompassing both goals and intelligence. However, if goals and intelligence parts correspond to different components, we may be able to&nbsp;<strong>“take the alien’s brain for a ride”</strong> and build a variety of systems that share the same&nbsp;<em>capabilities</em> but have very different objectives and profiles.</p>



<p>To be clear, the “intelligence forklift” view does not preclude building an “anti-aligned” agent on top of a pre-trained model that is&nbsp;<em>malicious</em>,&nbsp;<em>dishonest</em>, and&nbsp;<em>harmful</em>. It just means that such an agent would not have an automatic intelligence advantage over other agents (including humans) since all of them can have access to a shared “intelligence engine” provided by the goal-less pretrained models. This is what I illustrated as “scenario 2” in this figure (taken from my&nbsp;<a href="https://www.lesswrong.com/posts/wDL6wiqg3c6WFisHq/gpt-as-an-intelligence-forklift"><u>previous post</u></a>):</p>



<figure class="wp-block-image"><img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/67505f5594ae360d8e9d1949c3e201489116d2d8c1ee48ba.png" alt="" /></figure>



<h2 class="wp-block-heading"><strong>What about “self play”?</strong></h2>



<p>The above assumes that the intelligence component of a model is obtained by executing gradient steps on static data, but what if this data is itself generated by the model? This is what happened with games such as Go and Chess. Originally models were trained by predicting the next move of human games scraped from the Internet, but to improve beyond the quality of these data, models needed to play against themselves and generate new games. They could then filter out only the most successful ones and hence generate data that is of higher quality than the original games they trained on. (Eventually, it turned out that with this approach you don’t need to start with&nbsp;<em>any</em> data for games such as Chess and Go, hence the “Zero” in AlphaZero.)&nbsp;&nbsp;</p>



<p>Self-play makes a lot of sense in games where there is a very clear notion of winning and losing, but what would be the analog for language models? I don’t know the answer to this in general, but in the realm of scientific literature, there is an analogous process. The model could play the roles of authors and reviewers alike, generate new papers, subject them to peer review, revise and resubmit, etc. At least in fields that don’t require “wet labs”, this could lead to the model simulating the scientific literature of 2024, then 2025, and so on and so forth. Models that manage to do this would be amazing and would speed up scientific progress tremendously. However, I believe they could still be (just more powerful) “intelligence forklifts”. Model outputs influencing its inputs can lead to a &#8220;positive feedback loop,&#8221; and so this is not certain. But I do not see an inherent reason why models could not be arbitrarily intelligent and still completely without goals. In the <a href="https://astralcodexten.substack.com/p/janus-simulators"><u>words of Scott Alexander</u></a>, no matter how intelligent they are, models could still be “enlightened” and realize that</p>



<blockquote class="wp-block-quote">
<p><strong>“once you stop obsessing over the character you’re playing, you notice the GIANT SUPER-ACCURATE WORLD MODEL TAKING UP 99.99% OF YOUR BRAIN.”</strong><br>&nbsp;</p>
</blockquote>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T18:22:58Z">Monday, June 05 2023, 18:22</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/06/05/mathematics-of-the-impossible-draft-of-a-book/'>Mathematics of the impossible, draft of a book</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I posted a first draft of the book, here. It has more material than the previous blog posts, including a chapter on communication complexity. I plan a major revision, including adding several chapters, but it seems that won&#8217;t happen right away, so I am releasing what I have for now. Any comments are appreciated, either [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I posted a first draft of the book, <a href="https://www.ccs.neu.edu/home/viola/papers/moti.pdf">here</a>. It has more material than the previous blog posts, including a chapter on communication complexity. I plan a major revision, including adding several chapters, but it seems that won&#8217;t happen right away, so I am releasing what I have for now. Any comments are appreciated, either on this blog or via email.</p>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T17:23:16Z">Monday, June 05 2023, 17:23</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/06/05/tenure-track-faculty-at-the-australian-national-university-apply-by-may-31-2024/'>Tenure-track faculty at The Australian National University (apply by May 31, 2024)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Tenure-track faculty members in the School of Computing at the Australian National University. Please see the link below for more information. Website: jobs.anu.edu.au/jobs/tenure-track-lecturer-senior-lecturer-associate-professor-school-of-computing-canberra-act-act-australia Email: ahadn.zehmakan@anu.edu.au
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Tenure-track faculty members in the School of Computing at the Australian National University. Please see the link below for more information.</p>
<p>Website: <a href="https://jobs.anu.edu.au/jobs/tenure-track-lecturer-senior-lecturer-associate-professor-school-of-computing-canberra-act-act-australia">https://jobs.anu.edu.au/jobs/tenure-track-lecturer-senior-lecturer-associate-professor-school-of-computing-canberra-act-act-australia</a><br />
Email: ahadn.zehmakan@anu.edu.au</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T06:20:52Z">Monday, June 05 2023, 06:20</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/085'>TR23-085 |  Average-Case PAC-Learning from Nisan&#39;s Natural Proofs | 

	Ari Karchmer</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Carmosino et al. (2016) demonstrated that natural proofs of circuit lower bounds imply algorithms for learning circuits with membership queries over the uniform distribution. Indeed, they exercised this implication to obtain a quasi-polynomial time learning algorithm for ${AC}^0[p]$ circuits, for any prime $p$, by leveraging the existing natural proofs from Razborov (1987) and Smolensky (1987). This achievement raises a logical question: can existing natural proofs be adapted into learning algorithms that utilize random examples and learn over unknown, arbitrary example distributions? 

In this work, we show that natural circuit lower bounds proven by specific communication complexity arguments (e.g., Nisan (1994)) witness a ``yes&#39;&#39; answer to this question, under the one limitation of average-case learning. Our primary technical contribution demonstrates a connection between the complexity of learning a concept class in the average-case, and the randomized communication complexity of an evaluation game associated with the class.  We apply this finding to derive polynomial time average-case PAC-learning algorithms that use only random examples from arbitrary and unknown distributions, for any concept class that may be evaluated by (for instance) a majority vote of linear threshold functions.

Additionally, our work contributes to a better understanding of the optimal parameters in XOR lemmas for communication complexity. We address a question posed by Viola and Wigderson (2007) by demonstrating that certain enhancements of parameters in their XOR lemmas are false, assuming the existence of one-way functions.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Carmosino et al. (2016) demonstrated that natural proofs of circuit lower bounds imply algorithms for learning circuits with membership queries over the uniform distribution. Indeed, they exercised this implication to obtain a quasi-polynomial time learning algorithm for ${AC}^0[p]$ circuits, for any prime $p$, by leveraging the existing natural proofs from Razborov (1987) and Smolensky (1987). This achievement raises a logical question: can existing natural proofs be adapted into learning algorithms that utilize random examples and learn over unknown, arbitrary example distributions? 

In this work, we show that natural circuit lower bounds proven by specific communication complexity arguments (e.g., Nisan (1994)) witness a ``yes&#39;&#39; answer to this question, under the one limitation of average-case learning. Our primary technical contribution demonstrates a connection between the complexity of learning a concept class in the average-case, and the randomized communication complexity of an evaluation game associated with the class.  We apply this finding to derive polynomial time average-case PAC-learning algorithms that use only random examples from arbitrary and unknown distributions, for any concept class that may be evaluated by (for instance) a majority vote of linear threshold functions.

Additionally, our work contributes to a better understanding of the optimal parameters in XOR lemmas for communication complexity. We address a question posed by Viola and Wigderson (2007) by demonstrating that certain enhancements of parameters in their XOR lemmas are false, assuming the existence of one-way functions.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T05:39:55Z">Monday, June 05 2023, 05:39</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/06/quantifiers-to-parenthesize-or-not-to.html'>Quantifiers: To Parenthesize or not to Parenthesize?  Matrix of Formula: To Bracket or not to Bracket?</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;For the book&nbsp;</p><p>Computational&nbsp; Intractability: A Guide to Algorithmic Lower Bounds</p><p>by Demaine-Gasarch-Hajiaghayi&nbsp;</p><p>(See&nbsp; here&nbsp;for a link to a first draft.)&nbsp;</p><p>we had to make some choices about which notation to use. One of the least important ones was the following:&nbsp;</p><p>When defining NP, and in a few other places should we use:&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (\exists y)(\forall y)[B(x,y)]</p><p>or&nbsp;</p><p>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;\exists x : \forall y : B(x,y)<br></p><p>or&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; something else.</p><p>We ended up doing it the second way.&nbsp; But I wondered, which, if either, is standard. So I looked in many math and theoretical CS books looking for places they used quantifiers. Here is what I found</p><p>a) Most papers and books really don't use quantifiers at all!&nbsp; This surprised me.&nbsp;</p><p>b) When quantifiers are used, they are used in definitions, not theorems.&nbsp;</p><p>c) One exception is in logic when they deal with formulas as objects onto themselves.&nbsp; For example, the inductive definition of a formula will have a step:</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;If f(x_1,...,x_n) is a formula then (\exists x_i)[f(x_1,...,x_n)] is a formula.&nbsp;</p><p>d) Here is a list of the few places I saw quantifiers used and if they used parenthesis or not. I say if it has parenthesis (abbreviated Parens)&nbsp; or not, and if the matrix of the formula is in square brackets, no brackets, or something ese.&nbsp;</p><p>Cook's classic paper&nbsp;.&nbsp;Page 154 Parens, no Brackets (1971)&nbsp;</p><p>Stockmeyer's paper where he defines PH.&nbsp; Page 6 Parens and Brackets&nbsp; (1976)<br></p><p>Computers and Intractability by Garey &amp; Johnson. Page 164. Parens and Brackets (1979)</p><p>Morass-like construction of aleph_2 trees in L by Devlin.&nbsp; Page 2 Parens and matrix in Parens (1979)</p><p>Descriptive Complexity by Immerman.&nbsp;Page 38 Parens no Brackets (1999)&nbsp;</p><p>Bounded Queries in Recursion Theory by Gasarch and Martin. Parens and Brackets&nbsp; Throughout the book.&nbsp; (1999)</p><p>Complexity Theory from Godel to Feynman&nbsp;by Rudich. No Parens, No Brackets in Def of PH. (2003)&nbsp;</p><p>Parameterized Complexity Theory&nbsp;by Flum &amp; Grohe. Page 81 no Parens and no Brackets.&nbsp;</p><p>Computational Complexity: A Modern Approach&nbsp;by Arora &amp; Barak. Page 40. No Parens No Brackets.(2007)&nbsp;</p><p>Computational Complexity: A Conceptual Prospective&nbsp;by Goldreich.&nbsp; Page 114 no parents, no brackets (2008)&nbsp;</p><p>On Quantifer Rank Equivalence between linear orders by Siders.&nbsp;On page 417 they use quantifiers to state a theorem, which is unusual. Parens no brackets.<br></p><p>Presburger arithmetic, Rational Generating Functions, and quasi polynomials&nbsp;by Woods. Parens no&nbsp; Brackets. (2012)&nbsp;<br></p><p>Who witness's the Witness by Abel et al.&nbsp;On Page 69 (which the pointer takes you to) No Parens, no brackets. Colons between quantifiers (2018).</p><p>e) What to make of all this?</p><p>First off- the RARITY of the use of quantifiers really surprised me. The only place I saw them used a lot was my book, co-authored with Georgie Martin,&nbsp;&nbsp;Bounded Queries in Recursion Theory. Perhaps it would have sold better if I didn't use so many quantifiers. Oh well.&nbsp;</p><p>Second off- Later works don't use parens and brackets. This is most clear if you just look at Complexity Theory Books&nbsp;</p><p>Garey &amp; Johnson - 1979- parens and brackets</p><p>Flun &amp; Grohe- 1998- no parens and no brackts</p><p>Immerman- 1999 - parens but no brackets (this is the one exception)&nbsp;</p><p>Arora &amp; Barack- 2007 no parens and&nbsp; no brackets</p><p>Goldreich-2008- no parens and no brackets</p><p>If you have a complexity theory book around that is not on this list, look up the definition of NP and the definition of the Poly Hierarchy and see (a) if they use parens around the quantifiers, and (b) if they use square brackets or no brackets of something else. Please leave a comment about it so I test the conjecture that parenthesis are just so 1979.&nbsp;</p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;For the book&nbsp;</p><p><b>Computational&nbsp; Intractability: A Guide to Algorithmic Lower Bounds</b></p><p>by Demaine-Gasarch-Hajiaghayi&nbsp;</p><p>(See&nbsp; <a href="https://hardness.mit.edu/">here</a>&nbsp;for a link to a first draft.)&nbsp;</p><p>we had to make some choices about which notation to use. One of the least important ones was the following:&nbsp;</p><p>When defining NP, and in a few other places should we use:&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (\exists y)(\forall y)[B(x,y)]</p><p>or&nbsp;</p><p><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp; &nbsp;\exists x : \forall y : B(x,y)</span><br /></p><p><span>or&nbsp;</span></p><p><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; something else.</span></p><p>We ended up doing it the second way.&nbsp; But I wondered, which, if either, is standard. So I looked in many math and theoretical CS books looking for places they used quantifiers. Here is what I found</p><p>a) Most papers and books really don't use quantifiers at all!&nbsp; This surprised me.&nbsp;</p><p>b) When quantifiers are used, they are used in definitions, not theorems.&nbsp;</p><p>c) One exception is in logic when they deal with formulas as objects onto themselves.&nbsp; For example, the inductive definition of a formula will have a step:</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;If f(x_1,...,x_n) is a formula then (\exists x_i)[f(x_1,...,x_n)] is a formula.&nbsp;</p><p>d) Here is a list of the few places I saw quantifiers used and if they used parenthesis or not. I say if it has parenthesis (abbreviated Parens)&nbsp; or not, and if the matrix of the formula is in square brackets, no brackets, or something ese.&nbsp;</p><p><i><a href="https://dl.acm.org/doi/pdf/10.1145/800157.805047">Cook's classic paper</a>&nbsp;.&nbsp;</i>Page 154 Parens, no Brackets (1971)&nbsp;</p><p><a href="https://www.sciencedirect.com/science/article/pii/030439757690061X?via%3Dihub"><i>Stockmeyer's paper where he defines PH</i></a>.&nbsp; Page 6 Parens and Brackets&nbsp; (1976)<br /></p><p><i>Computers and Intractability</i> by Garey &amp; Johnson. Page 164. Parens and Brackets (1979)</p><p><i>Morass-like construction of aleph_2 trees in L</i> by Devlin.&nbsp; Page 2 Parens and matrix in Parens (1979)</p><p><i>Descriptive Complexity by Immerman.</i>&nbsp;Page 38 Parens no Brackets (1999)&nbsp;</p><p><i>Bounded Queries in Recursion Theory </i>by Gasarch and Martin. Parens and Brackets&nbsp; Throughout the book.&nbsp; (1999)</p><p><i>Complexity Theory from Godel to Feynman</i>&nbsp;by Rudich. No Parens, No Brackets in Def of PH. (2003)&nbsp;</p><p><a href="http://yaroslavvb.com/upload/flum.pdf">Parameterized Complexity Theory</a>&nbsp;by Flum &amp; Grohe. Page 81 no Parens and no Brackets.&nbsp;</p><p><i><a href="https://theory.cs.princeton.edu/complexity/book.pdf">Computational Complexity: A Modern Approach</a>&nbsp;</i>by Arora &amp; Barak. Page 40. No Parens No Brackets.(2007)&nbsp;</p><p><a href="https://theswissbay.ch/pdf/Gentoomen%20Library/Theory%20Of%20Computation/Oded_Goldreich-Computational_Complexity__A_Conceptual_Perspective%282008%29.pdf">Computational Complexity: A Conceptual Prospective</a>&nbsp;by Goldreich.&nbsp; Page 114 no parents, no brackets (2008)&nbsp;</p><p><i><a href="https://www.sciencedirect.com/science/article/pii/S0890540109002338">On Quantifer Rank Equivalence between linear orders by Siders</a>.&nbsp;</i>On page 417 they use quantifiers to state a theorem, which is unusual. Parens no brackets.<br /></p><p><a href="https://arxiv.org/abs/1211.0020"><i>Presburger arithmetic, Rational Generating Functions, and quasi polynomials</i></a>&nbsp;by Woods. Parens no&nbsp; Brackets. (2012)&nbsp;<br /></p><p><a href="https://erikdemaine.org/papers/Witness_TCS/paper.pdf#page=69">Who witness's the Witness by Abel et al.</a>&nbsp;On Page 69 (which the pointer takes you to) No Parens, no brackets. Colons between quantifiers (2018).</p><p>e) What to make of all this?</p><p>First off- the RARITY of the use of quantifiers really surprised me. The only place I saw them used a lot was my book, co-authored with Georgie Martin,&nbsp;&nbsp;<i>Bounded Queries in Recursion Theory. </i>Perhaps it would have sold better if I didn't use so many quantifiers. Oh well.&nbsp;</p><p>Second off- Later works don't use parens and brackets. This is most clear if you just look at Complexity Theory Books&nbsp;</p><p>Garey &amp; Johnson - 1979- parens and brackets</p><p>Flun &amp; Grohe- 1998- no parens and no brackts</p><p>Immerman- 1999 - parens but no brackets (this is the one exception)&nbsp;</p><p>Arora &amp; Barack- 2007 no parens and&nbsp; no brackets</p><p>Goldreich-2008- no parens and no brackets</p><p>If you have a complexity theory book around that is not on this list, look up the definition of NP and the definition of the Poly Hierarchy and see (a) if they use parens around the quantifiers, and (b) if they use square brackets or no brackets of something else. Please leave a comment about it so I test the conjecture that parenthesis are just so 1979.&nbsp;</p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><span><br /></span></p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T02:42:00Z">Monday, June 05 2023, 02:42</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.01193'>Complexity of Motion Planning of Arbitrarily Many Robots: Gadgets, Petri Nets, and Counter Machines</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Joshua Ani, Michael Coulombe, Erik D. Demaine, Yevhenii Diomidov, Timothy Gomez, Dylan Hendrickson, Jayson Lynch</p><p>We extend the motion-planning-through-gadgets framework to several new
scenarios involving various numbers of robots/agents, and analyze the
complexity of the resulting motion-planning problems. While past work considers
just one robot or one robot per player, most of our models allow for one or
more locations to spawn new robots in each time step, leading to arbitrarily
many robots. In the 0-player context, where all motion is deterministically
forced, we prove that deciding whether any robot ever reaches a specified
location is undecidable, by representing a counter machine. In the 1-player
context, where the player can choose how to move the robots, we prove
equivalence to Petri nets, EXPSPACE-completeness for reaching a specified
location, PSPACE-completeness for reconfiguration, and ACKERMANN-completeness
for reconfiguration when robots can be destroyed in addition to spawned.
Finally, we consider a variation on the standard 2-player context where,
instead of one robot per player, we have one robot shared by the players, along
with a ko rule to prevent immediately undoing the previous move. We prove this
impartial 2-player game EXPTIME-complete.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ani_J/0/1/0/all/0/1">Joshua Ani</a>, <a href="http://arxiv.org/find/cs/1/au:+Coulombe_M/0/1/0/all/0/1">Michael Coulombe</a>, <a href="http://arxiv.org/find/cs/1/au:+Demaine_E/0/1/0/all/0/1">Erik D. Demaine</a>, <a href="http://arxiv.org/find/cs/1/au:+Diomidov_Y/0/1/0/all/0/1">Yevhenii Diomidov</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_T/0/1/0/all/0/1">Timothy Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Hendrickson_D/0/1/0/all/0/1">Dylan Hendrickson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lynch_J/0/1/0/all/0/1">Jayson Lynch</a></p><p>We extend the motion-planning-through-gadgets framework to several new
scenarios involving various numbers of robots/agents, and analyze the
complexity of the resulting motion-planning problems. While past work considers
just one robot or one robot per player, most of our models allow for one or
more locations to spawn new robots in each time step, leading to arbitrarily
many robots. In the 0-player context, where all motion is deterministically
forced, we prove that deciding whether any robot ever reaches a specified
location is undecidable, by representing a counter machine. In the 1-player
context, where the player can choose how to move the robots, we prove
equivalence to Petri nets, EXPSPACE-completeness for reaching a specified
location, PSPACE-completeness for reconfiguration, and ACKERMANN-completeness
for reconfiguration when robots can be destroyed in addition to spawned.
Finally, we consider a variation on the standard 2-player context where,
instead of one robot per player, we have one robot shared by the players, along
with a ko rule to prevent immediately undoing the previous move. We prove this
impartial 2-player game EXPTIME-complete.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T00:30:00Z">Monday, June 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.01233'>Trade-offs between Entanglement and Communication</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Srinivasan Arunachalam, Uma Girish</p><p>We study the advantages of quantum communication models over classical
communication models that are equipped with a limited number of qubits of
entanglement. In this direction, we give explicit partial functions on $n$ bits
for which reducing the entanglement increases the classical communication
complexity exponentially. Our separations are as follows. For every $k\ge 1$:
</p>
<p>$Q\|^*$ versus $R2^*$: We show that quantum simultaneous protocols with
$\tilde{\Theta}(k^5 \log^3 n)$ qubits of entanglement can exponentially
outperform two-way randomized protocols with $O(k)$ qubits of entanglement.
This resolves an open problem from [Gav08] and improves the state-of-the-art
separations between quantum simultaneous protocols with entanglement and
two-way randomized protocols without entanglement [Gav19, GRT22].
</p>
<p>$R\|^*$ versus $Q\|^*$: We show that classical simultaneous protocols with
$\tilde{\Theta}(k \log n)$ qubits of entanglement can exponentially outperform
quantum simultaneous protocols with $O(k)$ qubits of entanglement, resolving an
open question from [GKRW06, Gav19]. The best result prior to our work was a
relational separation against protocols without entanglement [GKRW06].
</p>
<p>$R\|^*$ versus $R1^*$: We show that classical simultaneous protocols with
$\tilde{\Theta}(k\log n)$ qubits of entanglement can exponentially outperform
randomized one-way protocols with $O(k)$ qubits of entanglement. Prior to our
work, only a relational separation was known [Gav08].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Arunachalam_S/0/1/0/all/0/1">Srinivasan Arunachalam</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Girish_U/0/1/0/all/0/1">Uma Girish</a></p><p>We study the advantages of quantum communication models over classical
communication models that are equipped with a limited number of qubits of
entanglement. In this direction, we give explicit partial functions on $n$ bits
for which reducing the entanglement increases the classical communication
complexity exponentially. Our separations are as follows. For every $k\ge 1$:
</p>
<p>$Q\|^*$ versus $R2^*$: We show that quantum simultaneous protocols with
$\tilde{\Theta}(k^5 \log^3 n)$ qubits of entanglement can exponentially
outperform two-way randomized protocols with $O(k)$ qubits of entanglement.
This resolves an open problem from [Gav08] and improves the state-of-the-art
separations between quantum simultaneous protocols with entanglement and
two-way randomized protocols without entanglement [Gav19, GRT22].
</p>
<p>$R\|^*$ versus $Q\|^*$: We show that classical simultaneous protocols with
$\tilde{\Theta}(k \log n)$ qubits of entanglement can exponentially outperform
quantum simultaneous protocols with $O(k)$ qubits of entanglement, resolving an
open question from [GKRW06, Gav19]. The best result prior to our work was a
relational separation against protocols without entanglement [GKRW06].
</p>
<p>$R\|^*$ versus $R1^*$: We show that classical simultaneous protocols with
$\tilde{\Theta}(k\log n)$ qubits of entanglement can exponentially outperform
randomized one-way protocols with $O(k)$ qubits of entanglement. Prior to our
work, only a relational separation was known [Gav08].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T00:30:00Z">Monday, June 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.01718'>Discreteness of asymptotic tensor ranks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jop Bri&#xeb;t, Matthias Christandl, Itai Leigh, Amir Shpilka, Jeroen Zuiddam</p><p>Tensor parameters that are amortized or regularized over large tensor powers,
often called "asymptotic" tensor parameters, play a central role in several
areas including algebraic complexity theory (constructing fast matrix
multiplication algorithms), quantum information (entanglement cost and
distillable entanglement), and additive combinatorics (bounds on cap sets,
sunflower-free sets, etc.). Examples are the asymptotic tensor rank, asymptotic
slice rank and asymptotic subrank. Recent works (Costa-Dalai,
Blatter-Draisma-Rupniewski, Christandl-Gesmundo-Zuiddam) have investigated
notions of discreteness (no accumulation points) or "gaps" in the values of
such tensor parameters.
</p>
<p>We prove a general discreteness theorem for asymptotic tensor parameters of
order-three tensors and use this to prove that (1) over any finite field, the
asymptotic subrank and the asymptotic slice rank have no accumulation points,
and (2) over the complex numbers, the asymptotic slice rank has no accumulation
points.
</p>
<p>Central to our approach are two new general lower bounds on the asymptotic
subrank of tensors, which measures how much a tensor can be diagonalized. The
first lower bound says that the asymptotic subrank of any concise three-tensor
is at least the cube-root of the smallest dimension. The second lower bound
says that any three-tensor that is "narrow enough" (has one dimension much
smaller than the other two) has maximal asymptotic subrank.
</p>
<p>Our proofs rely on new lower bounds on the maximum rank in matrix subspaces
that are obtained by slicing a three-tensor in the three different directions.
We prove that for any concise tensor the product of any two such maximum ranks
must be large, and as a consequence there are always two distinct directions
with large max-rank.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Briet_J/0/1/0/all/0/1">Jop Bri&#xeb;t</a>, <a href="http://arxiv.org/find/cs/1/au:+Christandl_M/0/1/0/all/0/1">Matthias Christandl</a>, <a href="http://arxiv.org/find/cs/1/au:+Leigh_I/0/1/0/all/0/1">Itai Leigh</a>, <a href="http://arxiv.org/find/cs/1/au:+Shpilka_A/0/1/0/all/0/1">Amir Shpilka</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuiddam_J/0/1/0/all/0/1">Jeroen Zuiddam</a></p><p>Tensor parameters that are amortized or regularized over large tensor powers,
often called "asymptotic" tensor parameters, play a central role in several
areas including algebraic complexity theory (constructing fast matrix
multiplication algorithms), quantum information (entanglement cost and
distillable entanglement), and additive combinatorics (bounds on cap sets,
sunflower-free sets, etc.). Examples are the asymptotic tensor rank, asymptotic
slice rank and asymptotic subrank. Recent works (Costa-Dalai,
Blatter-Draisma-Rupniewski, Christandl-Gesmundo-Zuiddam) have investigated
notions of discreteness (no accumulation points) or "gaps" in the values of
such tensor parameters.
</p>
<p>We prove a general discreteness theorem for asymptotic tensor parameters of
order-three tensors and use this to prove that (1) over any finite field, the
asymptotic subrank and the asymptotic slice rank have no accumulation points,
and (2) over the complex numbers, the asymptotic slice rank has no accumulation
points.
</p>
<p>Central to our approach are two new general lower bounds on the asymptotic
subrank of tensors, which measures how much a tensor can be diagonalized. The
first lower bound says that the asymptotic subrank of any concise three-tensor
is at least the cube-root of the smallest dimension. The second lower bound
says that any three-tensor that is "narrow enough" (has one dimension much
smaller than the other two) has maximal asymptotic subrank.
</p>
<p>Our proofs rely on new lower bounds on the maximum rank in matrix subspaces
that are obtained by slicing a three-tensor in the three different directions.
We prove that for any concise tensor the product of any two such maximum ranks
must be large, and as a consequence there are always two distinct directions
with large max-rank.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T00:30:00Z">Monday, June 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.01723'>Efficient Quantum State Synthesis with One Query</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gregory Rosenthal</p><p>We present a polynomial-time quantum algorithm making a single query (in
superposition) to a classical oracle, such that for every state $|\psi\rangle$
there exists a choice of oracle that makes the algorithm construct an
exponentially close approximation of $|\psi\rangle$. Previous algorithms for
this problem either used a linear number of queries and polynomial time
[arXiv:1607.05256], or a constant number of queries and polynomially many
ancillae but no nontrivial bound on the runtime [arXiv:2111.02999]. As
corollaries we do the following:
</p>
<p>- We simplify the proof that statePSPACE $\subseteq$ stateQIP
[arXiv:2108.07192] (a quantum state analogue of PSPACE $\subseteq$ IP) and show
that a constant number of rounds of interaction suffices.
</p>
<p>- We show that QAC$\mathsf{_f^0}$ lower bounds for constructing explicit
states would imply breakthrough circuit lower bounds for computing explicit
boolean functions.
</p>
<p>- We prove that every $n$-qubit state can be constructed to within 0.01 error
by an $O(2^n/n)$-size circuit over an appropriate finite gate set. More
generally we give a size-error tradeoff which, by a counting argument, is
optimal for any finite gate set.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Rosenthal_G/0/1/0/all/0/1">Gregory Rosenthal</a></p><p>We present a polynomial-time quantum algorithm making a single query (in
superposition) to a classical oracle, such that for every state $|\psi\rangle$
there exists a choice of oracle that makes the algorithm construct an
exponentially close approximation of $|\psi\rangle$. Previous algorithms for
this problem either used a linear number of queries and polynomial time
[<a href="/abs/1607.05256">arXiv:1607.05256</a>], or a constant number of queries and polynomially many
ancillae but no nontrivial bound on the runtime [<a href="/abs/2111.02999">arXiv:2111.02999</a>]. As
corollaries we do the following:
</p>
<p>- We simplify the proof that statePSPACE $\subseteq$ stateQIP
[<a href="/abs/2108.07192">arXiv:2108.07192</a>] (a quantum state analogue of PSPACE $\subseteq$ IP) and show
that a constant number of rounds of interaction suffices.
</p>
<p>- We show that QAC$\mathsf{_f^0}$ lower bounds for constructing explicit
states would imply breakthrough circuit lower bounds for computing explicit
boolean functions.
</p>
<p>- We prove that every $n$-qubit state can be constructed to within 0.01 error
by an $O(2^n/n)$-size circuit over an appropriate finite gate set. More
generally we give a size-error tradeoff which, by a counting argument, is
optimal for any finite gate set.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T00:30:00Z">Monday, June 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.01528'>Does it pay to optimize AUC?</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Baojian Zhou, Steven Skiena</p><p>The Area Under the ROC Curve (AUC) is an important model metric for
evaluating binary classifiers, and many algorithms have been proposed to
optimize AUC approximately. It raises the question of whether the generally
insignificant gains observed by previous studies are due to inherent
limitations of the metric or the inadequate quality of optimization.
</p>
<p>To better understand the value of optimizing for AUC, we present an efficient
algorithm, namely AUC-opt, to find the provably optimal AUC linear classifier
in $\mathbb{R}^2$, which runs in $\mathcal{O}(n_+ n_- \log (n_+ n_-))$ where
$n_+$ and $n_-$ are the number of positive and negative samples respectively.
Furthermore, it can be naturally extended to $\mathbb{R}^d$ in
$\mathcal{O}((n_+n_-)^{d-1}\log (n_+n_-))$ by calling AUC-opt in
lower-dimensional spaces recursively. We prove the problem is NP-complete when
$d$ is not fixed, reducing from the \textit{open hemisphere problem}.
</p>
<p>Experiments show that compared with other methods, AUC-opt achieves
statistically significant improvements on between 17 to 40 in $\mathbb{R}^2$
and between 4 to 42 in $\mathbb{R}^3$ of 50 t-SNE training datasets. However,
generally the gain proves insignificant on most testing datasets compared to
the best standard classifiers. Similar observations are found for nonlinear AUC
methods under real-world datasets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Baojian Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Skiena_S/0/1/0/all/0/1">Steven Skiena</a></p><p>The Area Under the ROC Curve (AUC) is an important model metric for
evaluating binary classifiers, and many algorithms have been proposed to
optimize AUC approximately. It raises the question of whether the generally
insignificant gains observed by previous studies are due to inherent
limitations of the metric or the inadequate quality of optimization.
</p>
<p>To better understand the value of optimizing for AUC, we present an efficient
algorithm, namely AUC-opt, to find the provably optimal AUC linear classifier
in $\mathbb{R}^2$, which runs in $\mathcal{O}(n_+ n_- \log (n_+ n_-))$ where
$n_+$ and $n_-$ are the number of positive and negative samples respectively.
Furthermore, it can be naturally extended to $\mathbb{R}^d$ in
$\mathcal{O}((n_+n_-)^{d-1}\log (n_+n_-))$ by calling AUC-opt in
lower-dimensional spaces recursively. We prove the problem is NP-complete when
$d$ is not fixed, reducing from the \textit{open hemisphere problem}.
</p>
<p>Experiments show that compared with other methods, AUC-opt achieves
statistically significant improvements on between 17 to 40 in $\mathbb{R}^2$
and between 4 to 42 in $\mathbb{R}^3$ of 50 t-SNE training datasets. However,
generally the gain proves insignificant on most testing datasets compared to
the best standard classifiers. Similar observations are found for nonlinear AUC
methods under real-world datasets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T00:30:00Z">Monday, June 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.01678'>No-dimensional Tverberg Partitions Revisited</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sariel Har-Peled, Eliot W. Robson</p><p>$ \newcommand{\epsA}{\Mh{\delta}} \newcommand{\Re}{\mathbb{R}}
\newcommand{\reals}{\mathbb{R}} \newcommand{\SetX}{\mathsf{X}}
\newcommand{\diam}{\Delta} \newcommand{\Mh}[1]{#1} \newcommand{\query}{q}
\newcommand{\eps}{\varepsilon} \newcommand{\VorX}[1]{\mathcal{V} \pth{#1}}
\newcommand{\IntRange}[1]{[ #1 ]} \newcommand{\Space}{\overline{\mathsf{m}}}
\newcommand{\pth}[2][\!]{#1\left({#2}\right)}
\newcommand{\polylog}{\mathrm{polylog}} \newcommand{\N}{\mathbb N}
\newcommand{\Z}{\mathbb Z} \newcommand{\pt}{p} \newcommand{\distY}[2]{\left\|
{#1} - {#2} \right\|} \newcommand{\PP}{P} \newcommand{\ptq}{q}
\newcommand{\pts}{s}$ Given a set $\PP \subset \Re^d$ of $n$ points, with
diameter $\diam$, and a parameter $\epsA \in (0,1)$, it is known that there is
a partition of $\PP$ into sets $\PP_1, \ldots, \PP_t$, each of size
$O(1/\epsA^2)$, such that their convex-hulls all intersect a common ball of
radius $\epsA \diam$. We prove that a random partition, with a simple
alteration step, yields the desired partition, resulting in a linear time
algorithm. Previous proofs were either existential (i.e., at least exponential
time), or required much bigger sets. In addition, the algorithm and its proof
of correctness are significantly simpler than previous work, and the constants
are slightly better.
</p>
<p>In addition, we provide a linear time algorithm for computing a ``fuzzy''
centerpoint. We also prove a no-dimensional weak $\eps$-net theorem with an
improved constant.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Har_Peled_S/0/1/0/all/0/1">Sariel Har-Peled</a>, <a href="http://arxiv.org/find/cs/1/au:+Robson_E/0/1/0/all/0/1">Eliot W. Robson</a></p><p>$ \newcommand{\epsA}{\Mh{\delta}} \newcommand{\Re}{\mathbb{R}}
\newcommand{\reals}{\mathbb{R}} \newcommand{\SetX}{\mathsf{X}}
\newcommand{\diam}{\Delta} \newcommand{\Mh}[1]{#1} \newcommand{\query}{q}
\newcommand{\eps}{\varepsilon} \newcommand{\VorX}[1]{\mathcal{V} \pth{#1}}
\newcommand{\IntRange}[1]{[ #1 ]} \newcommand{\Space}{\overline{\mathsf{m}}}
\newcommand{\pth}[2][\!]{#1\left({#2}\right)}
\newcommand{\polylog}{\mathrm{polylog}} \newcommand{\N}{\mathbb N}
\newcommand{\Z}{\mathbb Z} \newcommand{\pt}{p} \newcommand{\distY}[2]{\left\|
{#1} - {#2} \right\|} \newcommand{\PP}{P} \newcommand{\ptq}{q}
\newcommand{\pts}{s}$ Given a set $\PP \subset \Re^d$ of $n$ points, with
diameter $\diam$, and a parameter $\epsA \in (0,1)$, it is known that there is
a partition of $\PP$ into sets $\PP_1, \ldots, \PP_t$, each of size
$O(1/\epsA^2)$, such that their convex-hulls all intersect a common ball of
radius $\epsA \diam$. We prove that a random partition, with a simple
alteration step, yields the desired partition, resulting in a linear time
algorithm. Previous proofs were either existential (i.e., at least exponential
time), or required much bigger sets. In addition, the algorithm and its proof
of correctness are significantly simpler than previous work, and the constants
are slightly better.
</p>
<p>In addition, we provide a linear time algorithm for computing a ``fuzzy''
centerpoint. We also prove a no-dimensional weak $\eps$-net theorem with an
improved constant.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T00:30:00Z">Monday, June 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.01349'>The Maximum Matrix Contraction Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dimitri Watel (ENSIIE, CEDRIC - OC), Pierre-Louis Poirion (CEDRIC - OC)</p><p>In this paper, we introduce the Maximum Matrix Contraction problem, where we
aim to contract as much as possible a binary matrix in order to maximize its
density. We study the complexity and the polynomial approximability of the
problem. Especially, we prove this problem to be NP-Complete and that every
algorithm solving this problem is at most a $2\sqrt{n}$-approximation algorithm
where n is the number of ones in the matrix. We then focus on efficient
algorithms to solve the problem: an integer linear program and three
heuristics.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Watel_D/0/1/0/all/0/1">Dimitri Watel</a> (ENSIIE, CEDRIC - OC), <a href="http://arxiv.org/find/cs/1/au:+Poirion_P/0/1/0/all/0/1">Pierre-Louis Poirion</a> (CEDRIC - OC)</p><p>In this paper, we introduce the Maximum Matrix Contraction problem, where we
aim to contract as much as possible a binary matrix in order to maximize its
density. We study the complexity and the polynomial approximability of the
problem. Especially, we prove this problem to be NP-Complete and that every
algorithm solving this problem is at most a $2\sqrt{n}$-approximation algorithm
where n is the number of ones in the matrix. We then focus on efficient
algorithms to solve the problem: an integer linear program and three
heuristics.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T00:30:00Z">Monday, June 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.01073'>Improved Algorithms for Distance Selection and Related Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Haitao Wang, Yiming Zhao</p><p>In this paper, we propose new techniques for solving geometric optimization
problems involving interpoint distances of a point set in the plane. Given a
set $P$ of $n$ points in the plane and an integer $1 \leq k \leq \binom{n}{2}$,
the distance selection problem is to find the $k$-th smallest interpoint
distance among all pairs of points of $P$. The previously best deterministic
algorithm solves the problem in $O(n^{4/3} \log^2 n)$ time [Katz and Sharir,
SIAM J. Comput. 1997 and SoCG 1993]. In this paper, we improve their algorithm
to $O(n^{4/3} \log n)$ time. Using similar techniques, we also give improved
algorithms on both the two-sided and the one-sided discrete Fr\'{e}chet
distance with shortcuts problem for two point sets in the plane. For the
two-sided problem (resp., one-sided problem), we improve the previous work
[Avraham, Filtser, Kaplan, Katz, and Sharir, ACM Trans. Algorithms 2015 and
SoCG 2014] by a factor of roughly $\log^2(m+n)$ (resp., $(m+n)^{\epsilon}$),
where $m$ and $n$ are the sizes of the two input point sets, respectively.
Other problems whose solutions can be improved by our techniques include the
reverse shortest path problems for unit-disk graphs. Our techniques are quite
general and we believe they will find many other applications in future.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haitao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yiming Zhao</a></p><p>In this paper, we propose new techniques for solving geometric optimization
problems involving interpoint distances of a point set in the plane. Given a
set $P$ of $n$ points in the plane and an integer $1 \leq k \leq \binom{n}{2}$,
the distance selection problem is to find the $k$-th smallest interpoint
distance among all pairs of points of $P$. The previously best deterministic
algorithm solves the problem in $O(n^{4/3} \log^2 n)$ time [Katz and Sharir,
SIAM J. Comput. 1997 and SoCG 1993]. In this paper, we improve their algorithm
to $O(n^{4/3} \log n)$ time. Using similar techniques, we also give improved
algorithms on both the two-sided and the one-sided discrete Fr\'{e}chet
distance with shortcuts problem for two point sets in the plane. For the
two-sided problem (resp., one-sided problem), we improve the previous work
[Avraham, Filtser, Kaplan, Katz, and Sharir, ACM Trans. Algorithms 2015 and
SoCG 2014] by a factor of roughly $\log^2(m+n)$ (resp., $(m+n)^{\epsilon}$),
where $m$ and $n$ are the sizes of the two input point sets, respectively.
Other problems whose solutions can be improved by our techniques include the
reverse shortest path problems for unit-disk graphs. Our techniques are quite
general and we believe they will find many other applications in future.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T00:30:00Z">Monday, June 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.01186'>Labeled Interleaving Distance for Reeb Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fangfei Lan, Salman Parsa, Bei Wang</p><p>Merge trees, contour trees, and Reeb graphs are graph-based topological
descriptors that capture topological changes of (sub)level sets of scalar
fields. Comparing scalar fields using their topological descriptors has many
applications in topological data analysis and visualization of scientific data.
Recently, Munch and Stefanou introduced a labeled interleaving distance for
comparing two labeled merge trees, which enjoys a number of theoretical and
algorithmic properties. In particular, the labeled interleaving distance
between merge trees can be computed in polynomial time. In this work, we define
the labeled interleaving distance for labeled Reeb graphs. We then prove that
the (ordinary) interleaving distance between Reeb graphs equals the minimum of
the labeled interleaving distance over all labelings. We also provide an
efficient algorithm for computing the labeled interleaving distance between two
labeled contour trees (which are special types of Reeb graphs that arise from
simply-connected domains). In the case of merge trees, the notion of the
labeled interleaving distance was used by Gasparovic et al. to prove that the
(ordinary) interleaving distance on the set of (unlabeled) merge trees is
intrinsic. As our final contribution, we present counterexamples showing that,
on the contrary, the (ordinary) interleaving distance on (unlabeled) Reeb
graphs (and contour trees) is not intrinsic. It turns out that, under mild
conditions on the labelings, the labeled interleaving distance is a metric on
isomorphism classes of Reeb graphs, analogous to the ordinary interleaving
distance. This provides new metrics on large classes of Reeb graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lan_F/0/1/0/all/0/1">Fangfei Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Parsa_S/0/1/0/all/0/1">Salman Parsa</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bei Wang</a></p><p>Merge trees, contour trees, and Reeb graphs are graph-based topological
descriptors that capture topological changes of (sub)level sets of scalar
fields. Comparing scalar fields using their topological descriptors has many
applications in topological data analysis and visualization of scientific data.
Recently, Munch and Stefanou introduced a labeled interleaving distance for
comparing two labeled merge trees, which enjoys a number of theoretical and
algorithmic properties. In particular, the labeled interleaving distance
between merge trees can be computed in polynomial time. In this work, we define
the labeled interleaving distance for labeled Reeb graphs. We then prove that
the (ordinary) interleaving distance between Reeb graphs equals the minimum of
the labeled interleaving distance over all labelings. We also provide an
efficient algorithm for computing the labeled interleaving distance between two
labeled contour trees (which are special types of Reeb graphs that arise from
simply-connected domains). In the case of merge trees, the notion of the
labeled interleaving distance was used by Gasparovic et al. to prove that the
(ordinary) interleaving distance on the set of (unlabeled) merge trees is
intrinsic. As our final contribution, we present counterexamples showing that,
on the contrary, the (ordinary) interleaving distance on (unlabeled) Reeb
graphs (and contour trees) is not intrinsic. It turns out that, under mild
conditions on the labelings, the labeled interleaving distance is a metric on
isomorphism classes of Reeb graphs, analogous to the ordinary interleaving
distance. This provides new metrics on large classes of Reeb graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T00:30:00Z">Monday, June 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.01097'>Fast Matrix Multiplication Without Tears: A Constraint Programming Approach</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arnaud Deza, Chang Liu, Pashootan Vaezipoor, Elias B. Khalil</p><p>It is known that the multiplication of an $N \times M$ matrix with an $M
\times P$ matrix can be performed using fewer multiplications than what the
naive $NMP$ approach suggests. The most famous instance of this is Strassen's
algorithm for multiplying two $2\times 2$ matrices in 7 instead of 8
multiplications. This gives rise to the constraint satisfaction problem of fast
matrix multiplication, where a set of $R &lt; NMP$ multiplication terms must be
chosen and combined such that they satisfy correctness constraints on the
output matrix. Despite its highly combinatorial nature, this problem has not
been exhaustively examined from that perspective, as evidenced for example by
the recent deep reinforcement learning approach of AlphaTensor. In this work,
we propose a simple yet novel Constraint Programming approach to find
non-commutative algorithms for fast matrix multiplication or provide proof of
infeasibility otherwise. We propose a set of symmetry-breaking constraints and
valid inequalities that are particularly helpful in proving infeasibility. On
the feasible side, we find that exploiting solver performance variability in
conjunction with a sparsity-based problem decomposition enables finding
solutions for larger (feasible) instances of fast matrix multiplication. Our
experimental results using CP Optimizer demonstrate that we can find fast
matrix multiplication algorithms for matrices up to $3\times 3$ in a short
amount of time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Deza_A/0/1/0/all/0/1">Arnaud Deza</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaezipoor_P/0/1/0/all/0/1">Pashootan Vaezipoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Khalil_E/0/1/0/all/0/1">Elias B. Khalil</a></p><p>It is known that the multiplication of an $N \times M$ matrix with an $M
\times P$ matrix can be performed using fewer multiplications than what the
naive $NMP$ approach suggests. The most famous instance of this is Strassen's
algorithm for multiplying two $2\times 2$ matrices in 7 instead of 8
multiplications. This gives rise to the constraint satisfaction problem of fast
matrix multiplication, where a set of $R &lt; NMP$ multiplication terms must be
chosen and combined such that they satisfy correctness constraints on the
output matrix. Despite its highly combinatorial nature, this problem has not
been exhaustively examined from that perspective, as evidenced for example by
the recent deep reinforcement learning approach of AlphaTensor. In this work,
we propose a simple yet novel Constraint Programming approach to find
non-commutative algorithms for fast matrix multiplication or provide proof of
infeasibility otherwise. We propose a set of symmetry-breaking constraints and
valid inequalities that are particularly helpful in proving infeasibility. On
the feasible side, we find that exploiting solver performance variability in
conjunction with a sparsity-based problem decomposition enables finding
solutions for larger (feasible) instances of fast matrix multiplication. Our
experimental results using CP Optimizer demonstrate that we can find fast
matrix multiplication algorithms for matrices up to $3\times 3$ in a short
amount of time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T00:30:00Z">Monday, June 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.01536'>Parameterized Complexity of Broadcasting in Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fedor V. Fomin, Pierre Fraigniaud, Petr A. Golovach</p><p>The task of the broadcast problem is, given a graph G and a source vertex s,
to compute the minimum number of rounds required to disseminate a piece of
information from s to all vertices in the graph. It is assumed that, at each
round, an informed vertex can transmit the information to at most one of its
neighbors. The broadcast problem is known to NP-hard. We show that the problem
is FPT when parametrized by the size k of a feedback edge-set, or by the size k
of a vertex-cover, or by k=n-t where t is the input deadline for the broadcast
protocol to complete.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fomin_F/0/1/0/all/0/1">Fedor V. Fomin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fraigniaud_P/0/1/0/all/0/1">Pierre Fraigniaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Golovach_P/0/1/0/all/0/1">Petr A. Golovach</a></p><p>The task of the broadcast problem is, given a graph G and a source vertex s,
to compute the minimum number of rounds required to disseminate a piece of
information from s to all vertices in the graph. It is assumed that, at each
round, an informed vertex can transmit the information to at most one of its
neighbors. The broadcast problem is known to NP-hard. We show that the problem
is FPT when parametrized by the size k of a feedback edge-set, or by the size k
of a vertex-cover, or by k=n-t where t is the input deadline for the broadcast
protocol to complete.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-05T00:30:00Z">Monday, June 05 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, June 04
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/06/04/soddys-quadlet.html'>Soddy’s quadlet</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Soddy’s hexlet is a famous system of nine spheres in three-dimensional Euclidean space, consisting of a ring of six spheres, tangent in consecutive pairs, and a ring of three spheres, tangent in pairs, with every sphere in one ring tangent to every sphere of the other ring. The easy way to construct it is to observe that its properties are invariant under Möbius transformations, as long as you count planes as spheres, and parallel planes as tangent spheres. If you take two of the three spheres in the three-sphere ring to be parallel planes, the rest have to form seven congruent spheres, six of them in a ring around the seventh. Any other form of the hexlet can be obtained by a Möbius transformation from this one.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Soddy’s hexlet is a famous system of nine spheres in three-dimensional Euclidean space, consisting of a ring of six spheres, tangent in consecutive pairs, and a ring of three spheres, tangent in pairs, with every sphere in one ring tangent to every sphere of the other ring. The easy way to construct it is to observe that its properties are invariant under Möbius transformations, as long as you count planes as spheres, and parallel planes as tangent spheres. If you take two of the three spheres in the three-sphere ring to be parallel planes, the rest have to form seven congruent spheres, six of them in a ring around the seventh. Any other form of the hexlet can be obtained by a Möbius transformation from this one.</p>

<p style="text-align:center"><img src="/blog/assets/2023/hexlet.gif" alt="Soddy's hexlet, in the form of seven congruent spheres between two parallel planes" title="CC-BY-SA 3.0 image File:Hexlet annular opt.gif by WillowW from Wikimedia commons" /></p>

<p>But there’s another way of constructing the same shape, coming from four-dimensional polyhedral geometry, which can also be used to construct another related pair of interlocking rings of spheres.</p>

<p>By analogy, consider a cube in 3d, and start growing a sphere with its center at the center of the cube. As you grow the sphere, it will start to bulge out through the faces of the cube, which cut it in six circles. Initially, those circles will be small and disjoint from each other, but as they grow larger they will eventually touch at the midpoint of a cube edge, and then cross each other. At the time when any two of the growing circles touch each other, all six will touch four others, by the symmetries of the cube. In this way, we have generated a configuration of six circles, on the surface of a sphere, each touching four others with the same touching pattern as the square faces of a cube.</p>

<p style="text-align:center"><img src="/blog/assets/2023/cube-midsphere.png" alt="A cube and its midsphere" title="CC-BY-SA 4.0 image File:Skeleton 6, size m, sphere.png by Watchduck from Wikimedia commons" style="width:100%;max-width:480px" /></p>

<p>Now do the same thing in 4d with the <a href="https://en.wikipedia.org/wiki/Duoprism">(3,6)-duoprism</a>, the Cartesian product of an equilateral triangle and a regular hexagon. The resulting 4-dimensional polytope has facets of two type: six triangular prisms (attached to each other on their triangle faces) and three hexagonal prisms (attached to each other on their hexagon faces). Rectangular faces connect triangular prisms to a hexagonal prism. There is a choice for how big to make the triangle edges relative to the hexagon edges. You want them to be in the proportion \(\sqrt3:1\), so that both kinds of prism have an inscribed sphere touching all their faces. Instead, the only figures I could find of the duoprism show it with edges in the wrong proportion \(1:1\), generating square faces. But I want the rectangular one.</p>

<p style="text-align:center"><img src="/blog/assets/2023/6-3-duoprism.png" alt="Skeleton of the square (3,6)-duoprism" title="CC-BY image File:6-3 duoprism.png by Tomruen from Wikimedia commons, created using Robert Webb's Stella software, http://www.software3d.com/Stella.php" style="width:100%;max-width:540px" /></p>

<p>Grow a hypersphere from the center of the duoprism. As it grows, it will intersect the prism facets of the duosphere in spheres, centered at the centers of the prisms. Initially small and disjoint, these spheres will grow until they become the inscribed spheres of the prisms, touching each other at the center of each triangle, hexagon, or rectangle of the duoprism. You have created a hexlet, simultaneously drawn on a sphere and inscribed in the faces of a duoprism! You can map it into the usual hexlet of three-dimensional Euclidean geometry (instead of three-dimensional spherical geometry) by a stereographic projection from the hypersphere to a flat three-dimensional space.</p>

<p>Almost all the other duoprisms do not have this coincidence, that when you adjust the proportions to make one kind of prism have inscribed spheres, the other one does the same thing with the same proportions. There’s only one other duoprism for which this works: the (4,4)-duoprism, better known as the <a href="https://en.wikipedia.org/wiki/Hypercube">4-hypercube</a> or <a href="https://en.wikipedia.org/wiki/Hypercube">tesseract</a>. In this case, all the facets are the same, and all the 2-faces are the same. If we grow a hypersphere, centered at the center of the hypercube, it will cross the hypercube facets (which are cubes) in spheres. When these spheres grow to the size where they are inscribed in each cube facet, they will be tangent to each other at the centers of the square two-dimensional faces of the hypercube. At this point, you will have formed two rings of four tangent spheres, tangent in consecutive pairs, with every sphere in one ring tangent to every sphere of the other ring. We could call it the “quadlet”.</p>

<p>Now that you’ve constructed a quadlet on a hypersphere in 4d, you can apply a stereographic projection to get the same quadlet as a collection of ordinary spheres in 3-dimensional Euclidean space. One of the more symmetric ways of doing this projection takes one of the two 4-sphere rings to two unit spheres sandwiched between two parallel planes at distance 4 from each other.  The four spheres of the other ring all have radius 2, and wrap around the central two unit spheres. It’s not obvious to me that these two parallel planes, two unit spheres, and four radius-2 spheres can all be tangent in this pattern, unless we calculate the coordinates of their tangencies or use reasoning based on the spheres inscribed on the facets of a hypercube, for which the same pattern of tangencies is obvious.</p>

<p style="text-align:center"><img src="/blog/assets/2023/quadlet.svg" alt="Soddy's quadlet, in the form of four radius-2 spheres and two radius-1 spheres between two parallel planes, top and side view" /></p>

<p>You can rotate the four radius-2 spheres around the axis formed by the central unit spheres arbitrarily without changing the pattern of tangencies. This is more or less analogous to the fact that with the hexlet, you can start the ring of six tangent spheres at any sphere tangent to all three spheres of the other ring, and then add spheres to the ring one by one, keeping each sphere tangent to its predecessor in the same ring and to all the spheres of the other ring. It will always close up after six spheres to form a hexlet. You can also fix in place the six-sphere ring, choose any sphere tangent to all of them to start the three-sphere ring, and it will always close up after three spheres to form a hexlet. And once you have one of the four-sphere rings of a quadlet, you can choose any sphere tangent to all four to start the other ring, and it will always close up after four spheres to form a quadlet. For the hexlet, this becomes obvious after we do a Möbius transformation to take it into the form with two parallel planes and seven congruent spheres. For the quadlet, it is similarly obvious by doing a Möbius transformation to take it into a form with two parallel planes in one ring and four congruent spheres in the other. The only way for the remaining two spheres to complete the first ring is for them to fill the hole between the four congruent spheres, one directly on top of each other. They might not be the same size as each other but one more Möbius transformation makes them so. So just like the hexlet, all quadlets are Möbius-equivalent.</p>

<p>Incidentally, the fact that you can get systems of three-dimensional tangent spheres from four-dimensional polytopes is not particularly new. I used it long ago in my paper with Kuperberg and Ziegler, “<a href="https://arxiv.org/abs/math.CO/0204007">Fat 4-polytopes and fatter 3-spheres</a>”, to get a finite set of spheres with high kissing number from the <a href="https://en.wikipedia.org/wiki/120-cell">120-cell</a> and its relatives. For more on the connection between sphere packings and 4-polytopes, including the construction of the hexlet from the duoprism, see <a href="https://dr-how.github.io/">Hao Chen’s papers</a> and especially “<a href="https://arxiv.org/abs/1306.2515">Apollonian ball packings and stacked polytopes</a>”.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/110488812675802711">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-04T17:30:00Z">Sunday, June 04 2023, 17:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/084'>TR23-084 |  Time-Space Lower Bounds for Bounded-Error Computation in the Random-Query Model | 

	Itai Dinur</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The random-query model was introduced by Raz and Zhan at ITCS 2020 as a new model of space-bounded computation. In this model, a branching program of length $T$ and width $2^{S}$ attempts to compute a function $f:\{0,1\}^n \rightarrow \{0,1 \}$. However, instead of receiving direct access to the input bits $(x_1,\ldots,x_n)$, the input is given in pairs of the form $(i_j, x_{i_j}) \in \{1,\ldots,n\} \times \{0,1\}$ for $j = 1,2,\ldots,T$, where the indices $i_1,\ldots,i_T$ are chosen at random from a pre-fixed distribution. 

Raz and Zhan proved that any branching program in the random-query model with the independent distribution (where $\{i_j\}_{j = 1,\ldots,T}$ are uniform and independent) that computes a function $f$ with  sensitivity $k$ satisfies $T \cdot (S + \log n) \geq \Omega(n \cdot k)$. 
This gives a quadratic time-space lower bound for many natural functions which have sensitivity $\Omega(n)$, such as XOR and Majority. The bound was proved in the zero-error regime, where for each input, the branching program is required to output a value with high probability, and given that a value is output, it must be correct with probability $1$. 

Furthermore, Raz and Zhan conjectured that (up to logarithmic factors in $n$) a quadratic time-space lower bound still holds for the XOR function in the more conventional bounded-error regime, where for each input, the output must be correct with high probability.

In this paper, we prove this conjecture. More generally, let $f:\{0,1\}^n \rightarrow \{0,1 \}$ have average sensitivity (or total influence) $\mathrm{I}[f]$. We prove that any branching program in the random-query model with the independent distribution that computes $f$ in the bounded-error regime satisfies $T \cdot S  \geq \tilde{\Omega}(n) \cdot \mathrm{I}[f]$ (where $\tilde{\Omega}$ hides logarithmic factors in $n$). Moreover, we prove a quadratic time-space lower bound for the Majority function, even though its total influence is $\Theta(\sqrt{n})$.

Our proof is based on a reduction from a communication complexity problem.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The random-query model was introduced by Raz and Zhan at ITCS 2020 as a new model of space-bounded computation. In this model, a branching program of length $T$ and width $2^{S}$ attempts to compute a function $f:\{0,1\}^n \rightarrow \{0,1 \}$. However, instead of receiving direct access to the input bits $(x_1,\ldots,x_n)$, the input is given in pairs of the form $(i_j, x_{i_j}) \in \{1,\ldots,n\} \times \{0,1\}$ for $j = 1,2,\ldots,T$, where the indices $i_1,\ldots,i_T$ are chosen at random from a pre-fixed distribution. 

Raz and Zhan proved that any branching program in the random-query model with the independent distribution (where $\{i_j\}_{j = 1,\ldots,T}$ are uniform and independent) that computes a function $f$ with  sensitivity $k$ satisfies $T \cdot (S + \log n) \geq \Omega(n \cdot k)$. 
This gives a quadratic time-space lower bound for many natural functions which have sensitivity $\Omega(n)$, such as XOR and Majority. The bound was proved in the zero-error regime, where for each input, the branching program is required to output a value with high probability, and given that a value is output, it must be correct with probability $1$. 

Furthermore, Raz and Zhan conjectured that (up to logarithmic factors in $n$) a quadratic time-space lower bound still holds for the XOR function in the more conventional bounded-error regime, where for each input, the output must be correct with high probability.

In this paper, we prove this conjecture. More generally, let $f:\{0,1\}^n \rightarrow \{0,1 \}$ have average sensitivity (or total influence) $\mathrm{I}[f]$. We prove that any branching program in the random-query model with the independent distribution that computes $f$ in the bounded-error regime satisfies $T \cdot S  \geq \tilde{\Omega}(n) \cdot \mathrm{I}[f]$ (where $\tilde{\Omega}$ hides logarithmic factors in $n$). Moreover, we prove a quadratic time-space lower bound for the Majority function, even though its total influence is $\Theta(\sqrt{n})$.

Our proof is based on a reduction from a communication complexity problem.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-04T02:29:40Z">Sunday, June 04 2023, 02:29</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/083'>TR23-083 |  Trade-offs between Entanglement and Communication | 

	Srinivasan A, 

	Uma Girish</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study the advantages of quantum communication models over classical communication models that are equipped with a limited number of qubits of entanglement. In this direction, we give explicit partial functions on $n$ bits for which reducing the entanglement increases the classical communication complexity exponentially. Our separations are as follows. For every $k\ge 1$:
  $Q\|^*$ versus $R2^*$: We show that quantum simultaneous protocols with $\tilde{\Theta}(k^5 \log^3 n)$ qubits of entanglement can exponentially outperform two-way randomized protocols with $O(k)$ qubits of entanglement. This resolves an open problem from [Gav08] and improves the state-of-the-art separations between quantum simultaneous protocols with entanglement and two-way randomized protocols without entanglement [Gav19, GRT22].
  $R\|^*$ versus $Q\|^*$: We show that classical simultaneous protocols with $\tilde{\Theta}(k \log n)$ qubits of entanglement can exponentially outperform quantum simultaneous protocols with $O(k)$ qubits of entanglement, resolving an open question from [GKRW06, Gav19]. The best result prior to our work was a relational separation against protocols without entanglement [GKRW06].
  $R\|^*$ versus $R1^*$: We show that classical simultaneous protocols with $\tilde{\Theta}(k\log n)$ qubits of entanglement can exponentially outperform randomized one-way protocols with $O(k)$ qubits of entanglement. Prior to our work, only a relational separation was known [Gav08].
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study the advantages of quantum communication models over classical communication models that are equipped with a limited number of qubits of entanglement. In this direction, we give explicit partial functions on $n$ bits for which reducing the entanglement increases the classical communication complexity exponentially. Our separations are as follows. For every $k\ge 1$:
  $Q\|^*$ versus $R2^*$: We show that quantum simultaneous protocols with $\tilde{\Theta}(k^5 \log^3 n)$ qubits of entanglement can exponentially outperform two-way randomized protocols with $O(k)$ qubits of entanglement. This resolves an open problem from [Gav08] and improves the state-of-the-art separations between quantum simultaneous protocols with entanglement and two-way randomized protocols without entanglement [Gav19, GRT22].
  $R\|^*$ versus $Q\|^*$: We show that classical simultaneous protocols with $\tilde{\Theta}(k \log n)$ qubits of entanglement can exponentially outperform quantum simultaneous protocols with $O(k)$ qubits of entanglement, resolving an open question from [GKRW06, Gav19]. The best result prior to our work was a relational separation against protocols without entanglement [GKRW06].
  $R\|^*$ versus $R1^*$: We show that classical simultaneous protocols with $\tilde{\Theta}(k\log n)$ qubits of entanglement can exponentially outperform randomized one-way protocols with $O(k)$ qubits of entanglement. Prior to our work, only a relational separation was known [Gav08].
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-04T02:27:27Z">Sunday, June 04 2023, 02:27</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, June 03
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/'>Topping the Hat</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          An &#8220;einstein&#8221; that doesn&#8217;t need flipping Siobhan Roberts is a Canadian science journalist, biographer, and historian of mathematics. She has an article that appeared in print in yesterday&#8217;s New York Times. It is on a second breakthrough by a team of mathematicians, improving their solution to a famous problem on tiling as we covered last [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>An &#8220;einstein&#8221; that doesn&#8217;t need flipping</em><br />
<font color="#000000"></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/sr2/" rel="attachment wp-att-21687"><img data-attachment-id="21687" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/sr2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/sr2.jpeg?fit=182%2C249&amp;ssl=1" data-orig-size="182,249" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="sr2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/sr2.jpeg?fit=182%2C249&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/sr2.jpeg?fit=182%2C249&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/sr2.jpeg?resize=121%2C166&#038;ssl=1" alt="" width="121" height="166" class="alignright wp-image-21687" data-recalc-dims="1" /></a></p>
<p>
Siobhan Roberts is a Canadian science journalist, biographer, and historian of mathematics. She has an <a href="https://www.nytimes.com/2023/06/01/science/puzzles-mathematics-tiling.html?action=click&#038;module=Well&#038;pgtype=Homepage&#038;section=Science">article</a> that appeared in print in yesterday&#8217;s New York Times. It is on a second breakthrough by a team of mathematicians, improving their solution to a famous problem on <a href="https://en.wikipedia.org/wiki/Aperiodic_tiling">tiling</a> as we <a href="https://rjlipton.wpcomstaging.com/2023/03/31/a-new-tiling/">covered</a> last March.</p>
<p><p>
Yesterday, while reading the Times, I must admit that I was surprised. I was reading Section A, with tons of stuff on the war in Ukraine and the debt ceiling deal and on the Republican primaries for president. I was not expecting to see a math theorem given such prominence. </p>
<p>
I knew Roberts&#8217;s previous work on math such as a terrific <a href="https://www.amazon.com/Genius-At-Play-Curious-Horton/dp/1620405954/ref=tmm_pap_swatch_0?_encoding=UTF8&#038;qid=&#038;sr=">book</a> a while ago on John Horton Conway. He discovered the Conway groups in mathematical symmetry and invented the aptly named <em>surreal numbers</em> as well as the cult classic <a href="https://en.wikipedia.org/wiki/Conway's_Game_of_Life">Game of Life</a>. Moving to Princeton in 1987, he deployed cards, ropes, dice, coat hangers, and even the odd Slinky as props to improve his lectures; see our <a href="https://rjlipton.wpcomstaging.com/2020/04/14/john-horton-conway-1937-2020/">memorial</a> for more. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/conwaybook/" rel="attachment wp-att-21688"><img data-attachment-id="21688" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/conwaybook/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/conwaybook.jpg?fit=329%2C499&amp;ssl=1" data-orig-size="329,499" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="conwaybook" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/conwaybook.jpg?fit=198%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/conwaybook.jpg?fit=329%2C499&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/conwaybook.jpg?resize=110%2C166&#038;ssl=1" alt="" width="110" height="166" class="aligncenter wp-image-21688" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/conwaybook.jpg?w=329&amp;ssl=1 329w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/conwaybook.jpg?resize=198%2C300&amp;ssl=1 198w" sizes="(max-width: 110px) 100vw, 110px" data-recalc-dims="1" /></a></p>
<p><H2> The Problem </H2></p>
<p><p>
Roberts begins by recapping the original solution:</p>
<blockquote><p><b> </b> <em> In March, a team of mathematical tilers announced their solution to a storied problem: They had discovered an elusive &#8220;Einstein&#8221;&#8212; a single shape that tiles a plane, or an infinite two-dimensional flat surface, but only in a non-repeating pattern. &#8220;I&#8217;ve always wanted to make a discovery,&#8221; David Smith, the shape hobbyist whose original find spurred the research, said at the time. </em>
</p></blockquote>
<p><p>
The other members of the team are Craig Kaplan and Chaim Goodman-Strauss (to the left of Smith below) and Joseph Myers:</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/fourtilers2/" rel="attachment wp-att-21707"><img data-attachment-id="21707" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/fourtilers2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/FourTilers2.png?fit=861%2C250&amp;ssl=1" data-orig-size="861,250" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="FourTilers2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/FourTilers2.png?fit=300%2C87&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/FourTilers2.png?fit=600%2C174&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/FourTilers2.png?resize=574%2C167&#038;ssl=1" alt="" width="574" height="167" class="aligncenter wp-image-21707" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/FourTilers2.png?w=861&amp;ssl=1 861w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/FourTilers2.png?resize=300%2C87&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/FourTilers2.png?resize=768%2C223&amp;ssl=1 768w" sizes="(max-width: 574px) 100vw, 574px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">Composite crop of several sources</FONT>
</td>
</tr>
</table>
<p>
The rub with the tile that the collaborators named &#8220;the hat&#8221; is that it needed to be flipped into its mirror image to create a set that can tile the plane. This is evident in the following grid&#8212;note that the blue hats have their upper notch on the left not right: </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/grid2/" rel="attachment wp-att-21709"><img data-attachment-id="21709" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/grid2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/grid2.jpg?fit=3273%2C1961&amp;ssl=1" data-orig-size="3273,1961" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="grid2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/grid2.jpg?fit=300%2C180&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/grid2.jpg?fit=600%2C360&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/grid2.jpg?resize=545%2C327&#038;ssl=1" alt="" width="545" height="327" class="aligncenter wp-image-21709" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/grid2.jpg?w=3273&amp;ssl=1 3273w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/grid2.jpg?resize=300%2C180&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/grid2.jpg?resize=1024%2C614&amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/grid2.jpg?resize=768%2C460&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/grid2.jpg?resize=1536%2C920&amp;ssl=1 1536w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/grid2.jpg?resize=2048%2C1227&amp;ssl=1 2048w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/grid2.jpg?resize=1200%2C719&amp;ssl=1 1200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/grid2.jpg?w=1800&amp;ssl=1 1800w" sizes="(max-width: 545px) 100vw, 545px" data-recalc-dims="1" /></a></p>
<p><P></p>
<p><H2> The New Solution </H2></p>
<p><p>
To remove this hitch and obtain the strongest possible result, the team needed to achieve two objectives:</p>
<ol>
<li>
Create a single shape that can tile the plane without being flipped, but only aperiodically. </p>
<li>
Show that the shape <em>plus its flip</em> cannot tile the plane periodically.
</ol>
<p>
Note that the second clause makes the &#8220;but only aperiodically&#8221; part of the first clause redundant. The key with the second clause is that the team could begin with work already done for their original result, which included the flip. Indeed, they had created a whole continuum of tiles <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BT%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{T}" class="latex" /> with the same properties as the original &#8220;hat.&#8221; </p>
<p>
There were two other dimensions of freedom for the team to explore:</p>
<ul>
<li>
Modify the edges of the tiles in ways other than the continuum. </p>
<li>
Combine basic tiles <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BT%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{T}" class="latex" /> into &#8220;supertiles&#8221; <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{S}" class="latex" />. One possible idea is that would be OK for <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{S}" class="latex" /> to include copies of both <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BT%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{T}" class="latex" /> and flips <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BT%27%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{T&#039;}" class="latex" /> so long as <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{S}" class="latex" /> can tile the plane without <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{S}" class="latex" /> itself being flipped.
</ul>
<p>
It appears from the new <a href="https://arxiv.org/abs/2305.17743">paper</a> that the second dimension is <b>not</b> used&#8212;or rather, ideas like it are used in the proofs but not in the definition of the new <em>einstein</em> tiles. The former dimension, however, made profit out of a step that at first seemed to <em>undo</em> the work they had done before. They had already observed the key point in their original March <a href="https://arxiv.org/abs/2303.10798">paper</a>, from which we reproduce this snippet:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/tile11snippet/" rel="attachment wp-att-21697"><img data-attachment-id="21697" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/tile11snippet/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Tile11snippet.png?fit=762%2C514&amp;ssl=1" data-orig-size="762,514" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Tile11snippet" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Tile11snippet.png?fit=300%2C202&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Tile11snippet.png?fit=600%2C405&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Tile11snippet.png?resize=574%2C386&#038;ssl=1" alt="" width="574" height="386" class="aligncenter wp-image-21697" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Tile11snippet.png?w=762&amp;ssl=1 762w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Tile11snippet.png?resize=300%2C202&amp;ssl=1 300w" sizes="(max-width: 574px) 100vw, 574px" data-recalc-dims="1" /></a></p>
<p><P><br />
That is to say, &#8220;<img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Br%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{r}" class="latex" />&#8221; defines the dimension of their original continuum which changes the relative lengths of edges of the polygon. The case <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Br%3D1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{r=1}" class="latex" /> is an isolated point at which aperiodicity breaks down&#8212;because it makes equal-length edges that permit sudden new ways tiles can fit. This is exploited by the simple columns of what they call &#8220;Tile(1,1)&#8221; and its flip in the figure. The key property of Tile(1,1) proved in the new paper is:</p>
<p><P align=center> Tile(1,1) <em>can</em> tile the plane <em>without</em> being flipped&#8212;<em>but only aperiodically</em>. </p>
<p><P><br />
Further and most important, the new paper shows that by altering the edges of Tile(1,1) in any of a whole spectrum of ways represented in the figure below (which is rotated from ones in the paper and NYT article), one can rule out the flips and preserve the aperiodic tilings without flips:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/spectres/" rel="attachment wp-att-21694"><img data-attachment-id="21694" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/spectres/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/spectres.png?fit=1142%2C714&amp;ssl=1" data-orig-size="1142,714" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="spectres" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/spectres.png?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/spectres.png?fit=600%2C375&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/spectres.png?resize=571%2C357&#038;ssl=1" alt="" width="571" height="357" class="aligncenter wp-image-21694" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/spectres.png?w=1142&amp;ssl=1 1142w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/spectres.png?resize=300%2C188&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/spectres.png?resize=1024%2C640&amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/spectres.png?resize=768%2C480&amp;ssl=1 768w" sizes="(max-width: 571px) 100vw, 571px" data-recalc-dims="1" /></a></p>
<p><P><br />
These tiles, which they call &#8220;Spectres,&#8221; are the new objection-free einsteins. They prove properties of a whole space of these tiles, fed by two main lines of hierarchical supertile constructions. Thus the case <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Br%3D1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{r=1}" class="latex" /> is like a Grand Central Station for connecting to the other dimensions.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
What could be the payoff of this wonderful discovery? Perhaps a new drug? A new solution to a potential Nobel level problem? Or something else?</p>
<p>
Dan Shechtman was awarded the 2011 Nobel Prize in Chemistry for the discovery of natural <a href="https://en.wikipedia.org/wiki/Quasicrystal">quasicrystals</a>, making him one of six Israelis who have won the Nobel Prize in Chemistry.</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/dans/" rel="attachment wp-att-21695"><img data-attachment-id="21695" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/03/topping-the-hat/dans/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/dans.jpg?fit=340%2C357&amp;ssl=1" data-orig-size="340,357" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="dans" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/dans.jpg?fit=286%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/dans.jpg?fit=340%2C357&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/dans.jpg?resize=340%2C357&#038;ssl=1" alt="" width="340" height="357" class="aligncenter size-full wp-image-21695" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/dans.jpg?w=340&amp;ssl=1 340w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/dans.jpg?resize=286%2C300&amp;ssl=1 286w" sizes="(max-width: 340px) 100vw, 340px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">Meeting at NIST in 1985 where Shechtman (on left) explains the atomic structure of quasicrystals: NIST <a href="https://www.nist.gov/nist-and-nobel/dan-shechtman/nobel-moment-dan-shechtman">source</a></FONT>
</td>
</tr>
</table>
<p>
Quasicrystals are defined by being aperiodic&#8212;the connection to the tiling problem is express in the Wikipedia page linked above. Will the new tiling results reported this spring lead to an insight worthy of a major award outside mathematics&#8212;a Nobel perhaps?</p>
<p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-03T18:56:00Z">Saturday, June 03 2023, 18:56</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, June 02
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/06/02/postdoc-at-hamburg-university-of-technology-apply-by-june-22-2023/'>Postdoc at Hamburg University of Technology (apply by June 22, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A postdoctoral research position (3 years, salary grade E-14) in theoretical computer science is available at The Institute for Algorithms and Complexity at Hamburg University of Technology. The successful candidate is expected to work on algorithms, discrete/combinatorial optimization and operations research with applications in data science (in collaboration with DASHH &#8211; Data Science in Hamburg) [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>A postdoctoral research position (3 years, salary grade E-14) in theoretical computer science is available at The Institute for Algorithms and Complexity at Hamburg University of Technology. The successful candidate is expected to work on algorithms, discrete/combinatorial optimization and operations research with applications in data science (in collaboration with DASHH &#8211; Data Science in Hamburg)</p>
<p>Website: <a href="https://www.tuhh.de/algo/jobs/postdoc/senior-positions">https://www.tuhh.de/algo/jobs/postdoc/senior-positions</a><br />
Email: algo@tuhh.de</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-02T11:50:09Z">Friday, June 02 2023, 11:50</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/06/01/combinatorics-or-logic/'>Combinatorics or Logic?</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Or is it number theory? Julius B&#252;chi was a Swiss mathematician who taught at Purdue University for many years. His is arguably a case of influence&#8212;in multiple fields&#8212;far exceeding a modest number of publications. A number of those, both at DBLP and his collected works, came after his untimely passing in 1984. His influence in [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>Or is it number theory?</em><br />
<font color="#000000"></p>
<p>
Julius B&uuml;chi was a Swiss mathematician who taught at Purdue University for many years. His is arguably a case of influence&#8212;in multiple fields&#8212;far exceeding a modest number of publications. A number of those, both at <a href="https://dblp.org/pid/05/1329.html">DBLP</a> and his <a href="https://link.springer.com/book/10.1007/978-1-4613-8928-6?page=3#toc">collected works</a>, came after his untimely passing in 1984. His influence in logic was furthered by his association with Saunders Mac Lane; in computer science, through his PhD student Lawrence Landweber and a group of computer science logicians that included Paul Young. </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/06/01/combinatorics-or-logic/jbuchi/" rel="attachment wp-att-21667"><img data-attachment-id="21667" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/01/combinatorics-or-logic/jbuchi/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jbuchi.jpeg?fit=200%2C200&amp;ssl=1" data-orig-size="200,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="jbuchi" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jbuchi.jpeg?fit=200%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jbuchi.jpeg?fit=200%2C200&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jbuchi.jpeg?resize=200%2C200&#038;ssl=1" alt="" width="200" height="200" class="aligncenter size-full wp-image-21667" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jbuchi.jpeg?w=200&amp;ssl=1 200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jbuchi.jpeg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 200px) 100vw, 200px" data-recalc-dims="1" /></a></p>
<p><P><br />
Today we talk about a new book by Jeffrey Shallit that may extend this influence further.<br />
<span id="more-21664"></span></p>
<p>
We <a href="https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/">recently</a> wrote about the seminal 1958 paper on finite automata by Michael Rabin and Dana Scott and its place in the early history of theory in the decade before and after. B&uuml;chi contributed by associating to a finite automaton <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BM%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{M}" class="latex" /> the language of <em>infinite</em> words over the alphabet of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BM%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{M}" class="latex" /> that cause <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BM%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{M}" class="latex" /> to be in an accepting state infinitely often. Another of B&uuml;chi&#8217;s close associates, Dirk Siefkes, wrote in his intro to B&uuml;chi&#8217;s collected works:</p>
<blockquote><p><b> </b> <em> He is probably best known for using finite automata as combinatorial devices to obtain strong results on decidability and definability in monadic second-order theories, and extending the method to infinite combinatorial tools. </em>
</p></blockquote>
<p><p>
Siefkes goes on to observe how Rabin extended B&uuml;chi&#8217;s method to general infinite binary trees, modeled via a logical theory with two successor functions, and how melding this with work by Robert McNaughton yielded rich decidability and determinacy results for monadic second-order formulas over this logic.</p>
<p>
<p><H2> Into Number Theory </H2></p>
<p><p>
B&uuml;chi posed a question that at first seems innocuous:</p>
<blockquote><p><b> </b> <em> Are there five non-consecutive natural numbers <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Ba_1%2Ca_2%2Ca_3%2Ca_4%2Ca_5%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{a_1,a_2,a_3,a_4,a_5}" class="latex" /> that satisfy the recurrence <a name="recur"></p>
<p align=center><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a_i%5E2+%3D+2a_%7Bi-1%7D%5E2+-+a_%7Bi-2%7D%5E2+%2B+2+%5C+%5C+%5C+%5C+%5C+%281%29&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle  a_i^2 = 2a_{i-1}^2 - a_{i-2}^2 + 2 &#92; &#92; &#92; &#92; &#92; (1)" class="latex" /></p>
<p></a> for <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bi%3D3%2C4%2C5%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{i=3,4,5}" class="latex" />? </em>
</p></blockquote>
<p><p>
The entire infinite sequence of integers satisfies the recurrence since <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bi%5E2+%2B+%28i-2%29%5E2+-+2%28i-1%29%5E2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{i^2 + (i-2)^2 - 2(i-1)^2}" class="latex" /> always equals 2. An example of four non-consecutive integers that do so is <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B6%2C23%2C32%2C39%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{6,23,32,39}" class="latex" />. But this sequence does not extend because <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B2%5Ccdot+39%5E2+-+32%5E2+%2B+2+%3D+2020%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{2&#92;cdot 39^2 - 32^2 + 2 = 2020}" class="latex" /> is not a perfect square. </p>
<p>
No example of five is known. However, no one has ruled out that such sequences of length <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> exist for every finite <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" />. What B&uuml;chi proved is:</p>
<blockquote><p><b>Theorem 1</b> <em> If there exists <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> such that the only length-<img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> sequences of natural numbers satisfying the recurrence (<a href="#recur">1</a>) are consecutive integers, then the undecidability of Hilbert&#8217;s Tenth Problem applies all the way down to <b>quadratic</b> equations, indeed ones of the form <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BAy+%3D+B%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{Ay = B}" class="latex" /> where <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{A}" class="latex" /> is a matrix of integers, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BB%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{B}" class="latex" /> is a vector of integers, and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> is a vector of squared variables. Moreover, existential sentences over Presburger arithmetic plus the predicate &#8220;<img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{z}" class="latex" /> is a perfect square&#8221; would become undecidable. </em>
</p></blockquote>
<p><p>
The technical <em>tour-de-force</em> is how B&uuml;chi makes a length-<img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> sequence of nonconsecutive natural numbers that satisfy the recurrence become the only obstacle to a scheme for defining the graph of multiplication <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bz+%3D+x+%5Ccdot+y%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{z = x &#92;cdot y}" class="latex" /> from predicates about perfect squares. The theory of addition and multiplication is of course undecidable&#8212;thanks to Kurt G&ouml;del and Alan Turing. </p>
<p>
<p><H2> B&uuml;chi&#8217;s Own Arithmetic </H2></p>
<p><p>
B&uuml;chi added a different predicate to Presburger arithmetic. Let <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BV_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{V_k}" class="latex" /> denote the largest power of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> dividing <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />. The resulting first-order theory <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BFO%28N%2C+%2B%2C+V_k%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{FO(N, +, V_k)}" class="latex" /> is named in honor of B&uuml;chi.</p>
<p>
This theory is decidable. And the big observation is that this is more powerful than we perhaps realized. Ken and I find this quite interesting. </p>
<p>
The theory is decidable, but just barely. The addition of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BV_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{V_k}" class="latex" /> to Presburger makes the theory much stronger. So strong that adding two independent <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BV_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{V_k}" class="latex" />&#8216;s, that is <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BFO%28N%2C+%2B%2C+V_k%2C+V_%5Cell%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{FO(N, +, V_k, V_&#92;ell)}" class="latex" /> where <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;ell}" class="latex" /> are relatively prime, is dangerous, since <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BFO%28N%2C+%2B%2C+V_k%2C+V_%5Cell%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{FO(N, +, V_k, V_&#92;ell)}" class="latex" /> becomes undecidable. This is neat. Indeed, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BFO%28N%2C+%2B%2C+V_k%2C+V_%5Cell%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{FO(N, +, V_k, V_&#92;ell)}" class="latex" /> has the power of all of <a href="https://en.wikipedia.org/wiki/Peano_axioms">Peano arithmetic</a>. </p>
<p>
The power possessed by <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BFO%28N%2C+%2B%2C+V_k%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{FO(N, +, V_k)}" class="latex" /> with a single <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BV_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{V_k}" class="latex" /> is to describe finite automata over a <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" />-letter alphabet. This plays both into why <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BFO%28N%2C+%2B%2C+V_k%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{FO(N, +, V_k)}" class="latex" /> is decidable and into the applications collected by Shallit.</p>
<p>
<p><H2> A New Book </H2></p>
<p><p>
Jeffrey Shallit recently sent a private message about his new book: </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/06/01/combinatorics-or-logic/walnut-book-cover/" rel="attachment wp-att-21668"><img data-attachment-id="21668" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/01/combinatorics-or-logic/walnut-book-cover/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/walnut-book-cover.jpg?fit=1700%2C2560&amp;ssl=1" data-orig-size="1700,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="walnut-book-cover" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/walnut-book-cover.jpg?fit=199%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/walnut-book-cover.jpg?fit=600%2C904&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/walnut-book-cover.jpg?resize=199%2C300&#038;ssl=1" alt="" width="199" height="300" class="aligncenter size-medium wp-image-21668" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/walnut-book-cover.jpg?resize=199%2C300&amp;ssl=1 199w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/walnut-book-cover.jpg?resize=680%2C1024&amp;ssl=1 680w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/walnut-book-cover.jpg?resize=768%2C1157&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/walnut-book-cover.jpg?resize=1020%2C1536&amp;ssl=1 1020w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/walnut-book-cover.jpg?resize=1360%2C2048&amp;ssl=1 1360w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/walnut-book-cover.jpg?resize=1200%2C1807&amp;ssl=1 1200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/walnut-book-cover.jpg?w=1700&amp;ssl=1 1700w" sizes="(max-width: 199px) 100vw, 199px" data-recalc-dims="1" /></a></p>
<p><P><br />
He wrote: </p>
<blockquote><p><b> </b> <em> I thought maybe you might possibly be interested in my new <a href="https://cs.uwaterloo.ca/~shallit/walnut-book.html">book</a>, which is about how a decision procedure for <a href="https://en.wikipedia.org/wiki/Buchi_arithmetic">B&uuml;chi arithmetic</a>&#8211;namely, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BFO%28N%2C+%2B%2C+V_k%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{FO(N, +, V_k)}" class="latex" />&#8211;can be used to prove hundreds of old and new results in number theory, combinatorics on words, and automatic sequences. There is probably no big theoretical advance in the book, just a recognition that existing results might be more useful than we suspected. </em>
</p></blockquote>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/06/01/combinatorics-or-logic/jshallit/" rel="attachment wp-att-21669"><img data-attachment-id="21669" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/01/combinatorics-or-logic/jshallit/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jshallit.jpeg?fit=214%2C125&amp;ssl=1" data-orig-size="214,125" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="jshallit" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jshallit.jpeg?fit=214%2C125&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jshallit.jpeg?fit=214%2C125&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jshallit.jpeg?resize=214%2C125&#038;ssl=1" alt="" width="214" height="125" class="aligncenter size-full wp-image-21669" data-recalc-dims="1" /></a></p>
<p><p>
The book comes with a software package called <a href="https://cs.uwaterloo.ca/~shallit/walnut.html"><em>Walnut</em></a>, which was written by Hamoon Mousavi while a student in Shallit&#8217;s department, and has been added to by other Waterloo students since. It executes a <a href="https://projecteuclid.org/journals/bulletin-of-the-belgian-mathematical-society-simon-stevin/volume-1/issue-2/Logic-and-p-recognizable-sets-of-integers/10.36045/bbms/1103408547.full">rendition</a> of B&uuml;chi&#8217;s and others&#8217; automata-based decision strategy. </p>
<p>
<p><H2> An Example </H2></p>
<p><p>
Here is a simple example that begins the number theory chapter of the book. </p>
<blockquote><p><b>Proposition.</b> <em> The numbers <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B2n%2B1%7D+-+1%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{2^{2n+1} - 1}" class="latex" /> for <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cgeq+0%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n &#92;geq 0}" class="latex" /> cannot be written as the sum of two natural numbers, each having an even number of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B1%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{1}" class="latex" />s in its binary representation. Every other number greater than <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B4%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{4}" class="latex" /> can be so written. </em>
</p></blockquote>
<p><p>
Via a finite automaton that distinguishes &#8220;even&#8221; from &#8220;odd&#8221; and its use of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%2B%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{+}" class="latex" /> but not multiplication, this can be formulated in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BFO%28N%2C+%2B%2C+V_2%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{FO(N, +, V_2)}" class="latex" />. The software then cranks out a proof. </p>
<p>
Further examples require absorbing the notion of <a href="https://en.wikipedia.org/wiki/Automatic_sequence">automatic sequence</a> in the book&#8217;s title, and we&#8217;ll stop here. Incidentally, the worst-case running time of <em>Walnut</em> on a formula with <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Br%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{r}" class="latex" />-many alternating quantifiers built via an <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N}" class="latex" />-state finite automaton with output is </p>
<p align=center><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++2%5E%7B2%5E%7B%5Ccdot%5E%7B%5Ccdot%5E%7B%5Ccdot%5E%7B2%5E%7BN%5E%7BO%281%29%7D%7D%7D%7D%7D%7D%7D+&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle  2^{2^{&#92;cdot^{&#92;cdot^{&#92;cdot^{2^{N^{O(1)}}}}}}} " class="latex" /></p>
<p>where there are <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Br%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{r}" class="latex" />-many <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{2}" class="latex" />s. The examples in the book&#8212;and maybe almost all examples one would devise using the approaches in the book&#8212;all halt within reasonable time. Why this is observed to hold might be a topic for another post.</p>
<p>
<p><H2> What Is Combinatorics? </H2></p>
<p><p>
Igor Pak, who is a professor in the Mathematics Department at UCLA and works in the Combinatorics Group, has this to say on his <a href="https://www.math.ucla.edu/~pak/">webpages</a>:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/06/01/combinatorics-or-logic/ipak/" rel="attachment wp-att-21670"><img data-attachment-id="21670" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/01/combinatorics-or-logic/ipak/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/ipak.jpeg?fit=262%2C192&amp;ssl=1" data-orig-size="262,192" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ipak" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/ipak.jpeg?fit=262%2C192&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/ipak.jpeg?fit=262%2C192&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/ipak.jpeg?resize=262%2C192&#038;ssl=1" alt="" width="262" height="192" class="aligncenter size-full wp-image-21670" data-recalc-dims="1" /></a></p>
<p>
He says: </p>
<blockquote><p><b> </b> <em> Combinatorics is a pretty diverse area and hard to characterize. Of course, combinatorics is about counting, but it is a lot more than just that. See <a href="https://www.math.ucla.edu/~pak/hidden/papers/Quotes/Combinatorics-quotes.htm">here</a> for more quotes about it.</p>
<p>
As you all know, my field is Combinatorics. I care about it. I blog about it endlessly. I want to see it blossom. I am happy to see it accepted by the broad mathematical community. It&#8217;s a joy to see it represented at (most) top universities and recognized with major awards. It&#8217;s all mostly good.</p>
<p>
Of course, not everyone is on board. This is normal. Changing views is hard. Some people and institutions continue insisting that Combinatorics is mostly a trivial nonsense (or at least large parts of it). This is an old fight best not rehashed again. </em>
</p></blockquote>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Enjoy Jeffrey&#8217;s book&#8212;thanks. See <a href="https://www.cambridge.org/core/books/logical-approach-to-automatic-sequences/FF19494217F62C05003B28EDFC83020C">here</a> to buy it. Ken&#8217;s current student Chen Xu already owns it and is referencing it for some of his work.</p>
<p><P><br />
[&#8220;integers&#8221; -> &#8220;natural numbers&#8221; in a few places; inserted &#8220;of length k&#8221; in sentence before B&uuml;chi&#8217;s theorem]]</p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-02T02:13:18Z">Friday, June 02 2023, 02:13</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.00083'>Bell sampling from quantum circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dominik Hangleiter, Michael J. Gullans</p><p>A central challenge in the verification of quantum computers is benchmarking
their performance as a whole and demonstrating their computational
capabilities. In this work, we find a model of quantum computation, Bell
sampling, that can be used for both of those tasks and thus provides an ideal
stepping stone towards fault-tolerance. In Bell sampling, we measure two copies
of a state prepared by a quantum circuit in the transversal Bell basis. We show
that the Bell samples are classically intractable to produce and at the same
time constitute what we call a circuit shadow: from the Bell samples we can
efficiently extract information about the quantum circuit preparing the state,
as well as diagnose circuit errors. In addition to known properties that can be
efficiently extracted from Bell samples, we give two new and efficient
protocols, a test for the depth of the circuit and an algorithm to estimate a
lower bound to the number of T gates in the circuit. With some additional
measurements, our algorithm learns a full description of states prepared by
circuits with low T -count.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Hangleiter_D/0/1/0/all/0/1">Dominik Hangleiter</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Gullans_M/0/1/0/all/0/1">Michael J. Gullans</a></p><p>A central challenge in the verification of quantum computers is benchmarking
their performance as a whole and demonstrating their computational
capabilities. In this work, we find a model of quantum computation, Bell
sampling, that can be used for both of those tasks and thus provides an ideal
stepping stone towards fault-tolerance. In Bell sampling, we measure two copies
of a state prepared by a quantum circuit in the transversal Bell basis. We show
that the Bell samples are classically intractable to produce and at the same
time constitute what we call a circuit shadow: from the Bell samples we can
efficiently extract information about the quantum circuit preparing the state,
as well as diagnose circuit errors. In addition to known properties that can be
efficiently extracted from Bell samples, we give two new and efficient
protocols, a test for the depth of the circuit and an algorithm to estimate a
lower bound to the number of T gates in the circuit. With some additional
measurements, our algorithm learns a full description of states prepared by
circuits with low T -count.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-02T00:30:00Z">Friday, June 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.00125'>Graph Colouring is Hard for Algorithms Based on Hilbert's Nullstellensatz and Gr\"{o}bner Bases</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Massimo Lauria, Jakob Nordstr&#xf6;m</p><p>We consider the graph $k$-colouring problem encoded as a set of polynomial
equations in the standard way over $0/1$-valued variables. We prove that there
are bounded-degree graphs that do not have legal $k$-colourings but for which
the polynomial calculus proof system defined in [Clegg et al '96, Alekhnovich
et al '02] requires linear degree, and hence exponential size, to establish
this fact. This implies a linear degree lower bound for any algorithms based on
Gr\"{o}bner bases solving graph $k$-colouring using this encoding. The same
bound applies also for the algorithm studied in a sequence of papers [De Loera
et al '08,'09,'11,'15] based on Hilbert's Nullstellensatz proofs for a slightly
different encoding, thus resolving an open problem mentioned in [De Loera et al
'08,'09,'11] and [Li '16]. We obtain our results by combining the polynomial
calculus degree lower bound for functional pigeonhole principle (FPHP) formulas
over bounded-degree bipartite graphs in [Mik\v{s}a and Nordstr\"{o}m '15] with
a reduction from FPHP to $k$-colouring derivable by polynomial calculus in
constant degree.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lauria_M/0/1/0/all/0/1">Massimo Lauria</a>, <a href="http://arxiv.org/find/cs/1/au:+Nordstrom_J/0/1/0/all/0/1">Jakob Nordstr&#xf6;m</a></p><p>We consider the graph $k$-colouring problem encoded as a set of polynomial
equations in the standard way over $0/1$-valued variables. We prove that there
are bounded-degree graphs that do not have legal $k$-colourings but for which
the polynomial calculus proof system defined in [Clegg et al '96, Alekhnovich
et al '02] requires linear degree, and hence exponential size, to establish
this fact. This implies a linear degree lower bound for any algorithms based on
Gr\"{o}bner bases solving graph $k$-colouring using this encoding. The same
bound applies also for the algorithm studied in a sequence of papers [De Loera
et al '08,'09,'11,'15] based on Hilbert's Nullstellensatz proofs for a slightly
different encoding, thus resolving an open problem mentioned in [De Loera et al
'08,'09,'11] and [Li '16]. We obtain our results by combining the polynomial
calculus degree lower bound for functional pigeonhole principle (FPHP) formulas
over bounded-degree bipartite graphs in [Mik\v{s}a and Nordstr\"{o}m '15] with
a reduction from FPHP to $k$-colouring derivable by polynomial calculus in
constant degree.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-02T00:30:00Z">Friday, June 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.00420'>Logics with probabilistic team semantics and the Boolean negation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Miika Hannula, Minna Hirvonen, Juha Kontinen, Yasir Mahmood, Arne Meier, Jonni Virtema</p><p>We study the expressivity and the complexity of various logics in
probabilistic team semantics with the Boolean negation. In particular, we study
the extension of probabilistic independence logic with the Boolean negation,
and a recently introduced logic FOPT. We give a comprehensive picture of the
relative expressivity of these logics together with the most studied logics in
probabilistic team semantics setting, as well as relating their expressivity to
a numerical variant of second-order logic. In addition, we introduce novel
entropy atoms and show that the extension of first-order logic by entropy atoms
subsumes probabilistic independence logic. Finally, we obtain some results on
the complexity of model checking, validity, and satisfiability of our logics.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hannula_M/0/1/0/all/0/1">Miika Hannula</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirvonen_M/0/1/0/all/0/1">Minna Hirvonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kontinen_J/0/1/0/all/0/1">Juha Kontinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_Y/0/1/0/all/0/1">Yasir Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Meier_A/0/1/0/all/0/1">Arne Meier</a>, <a href="http://arxiv.org/find/cs/1/au:+Virtema_J/0/1/0/all/0/1">Jonni Virtema</a></p><p>We study the expressivity and the complexity of various logics in
probabilistic team semantics with the Boolean negation. In particular, we study
the extension of probabilistic independence logic with the Boolean negation,
and a recently introduced logic FOPT. We give a comprehensive picture of the
relative expressivity of these logics together with the most studied logics in
probabilistic team semantics setting, as well as relating their expressivity to
a numerical variant of second-order logic. In addition, we introduce novel
entropy atoms and show that the extension of first-order logic by entropy atoms
subsumes probabilistic independence logic. Finally, we obtain some results on
the complexity of model checking, validity, and satisfiability of our logics.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-02T00:30:00Z">Friday, June 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.00299'>Robust Estimation of Surface Curvature Information from Point Cloud Data</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jared Spang</p><p>This paper surveys and evaluates some popular state of the art methods for
algorithmic curvature and normal estimation. In addition to surveying existing
methods we also propose a new method for robust curvature estimation and
evaluate it against existing methods thus demonstrating its superiority to
existing methods in the case of significant data noise. Throughout this paper
we are concerned with computation in low dimensional spaces (N &lt; 10) and
primarily focus on the computation of the Weingarten map and quantities that
may be derived from this; however, the algorithms discussed are theoretically
applicable in any dimension. One thing that is common to all these methods is
their basis in an estimated graph structure. For any of these methods to work
the local geometry of the manifold must be exploited; however, in the case of
point cloud data it is often difficult to discover a robust manifold structure
underlying the data, even in simple cases, which can greatly influence the
results of these algorithms. We hope that in pushing these algorithms to their
limits we are able to discover, and perhaps resolve, many major pitfalls that
may affect potential users and future researchers hoping to improve these
methods
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Spang_J/0/1/0/all/0/1">Jared Spang</a></p><p>This paper surveys and evaluates some popular state of the art methods for
algorithmic curvature and normal estimation. In addition to surveying existing
methods we also propose a new method for robust curvature estimation and
evaluate it against existing methods thus demonstrating its superiority to
existing methods in the case of significant data noise. Throughout this paper
we are concerned with computation in low dimensional spaces (N &lt; 10) and
primarily focus on the computation of the Weingarten map and quantities that
may be derived from this; however, the algorithms discussed are theoretically
applicable in any dimension. One thing that is common to all these methods is
their basis in an estimated graph structure. For any of these methods to work
the local geometry of the manifold must be exploited; however, in the case of
point cloud data it is often difficult to discover a robust manifold structure
underlying the data, even in simple cases, which can greatly influence the
results of these algorithms. We hope that in pushing these algorithms to their
limits we are able to discover, and perhaps resolve, many major pitfalls that
may affect potential users and future researchers hoping to improve these
methods
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-02T00:30:00Z">Friday, June 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.00266'>A polynomial-time iterative algorithm for random graph matching with non-vanishing correlation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jian Ding, Zhangsong Li</p><p>We propose an efficient algorithm for matching two correlated
Erd\H{o}s--R\'enyi graphs with $n$ vertices whose edges are correlated through
a latent vertex correspondence. When the edge density $q= n^{- \alpha+o(1)}$
for a constant $\alpha \in [0,1)$, we show that our algorithm has polynomial
running time and succeeds to recover the latent matching as long as the edge
correlation is non-vanishing. This is closely related to our previous work on a
polynomial-time algorithm that matches two Gaussian Wigner matrices with
non-vanishing correlation, and provides the first polynomial-time random graph
matching algorithm (regardless of the regime of $q$) when the edge correlation
is below the square root of the Otter's constant (which is $\approx 0.338$).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1">Jian Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhangsong Li</a></p><p>We propose an efficient algorithm for matching two correlated
Erd\H{o}s--R\'enyi graphs with $n$ vertices whose edges are correlated through
a latent vertex correspondence. When the edge density $q= n^{- \alpha+o(1)}$
for a constant $\alpha \in [0,1)$, we show that our algorithm has polynomial
running time and succeeds to recover the latent matching as long as the edge
correlation is non-vanishing. This is closely related to our previous work on a
polynomial-time algorithm that matches two Gaussian Wigner matrices with
non-vanishing correlation, and provides the first polynomial-time random graph
matching algorithm (regardless of the regime of $q$) when the edge correlation
is below the square root of the Otter's constant (which is $\approx 0.338$).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-02T00:30:00Z">Friday, June 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.00269'>Best $L_p$ Isotonic Regressions, $p \in \{0, 1, \infty\}$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Quentin F.Stout</p><p>Given a real-valued weighted function $f$ on a finite dag, the $L_p$ isotonic
regression of $f$, $p \in [0,\infty]$, is unique except when $p \in [0,1] \cup
\{\infty\}$. We are interested in determining a ``best'' isotonic regression
for $p \in \{0, 1, \infty\}$, where by best we mean a regression satisfying
stronger properties than merely having minimal norm. One approach is to use
strict $L_p$ regression, which is the limit of the best $L_q$ approximation as
$q$ approaches $p$, and another is lex regression, which is based on lexical
ordering of regression errors. For $L_\infty$ the strict and lex regressions
are unique and the same. For $L_1$, strict $q \scriptstyle\searrow 1$ is
unique, but we show that $q \scriptstyle\nearrow 1$ may not be, and even when
it is unique the two limits may not be the same. For $L_0$, in general neither
of the strict and lex regressions are unique, nor do they always have the same
set of optimal regressions, but by expanding the objectives of $L_p$
optimization to $p &lt; 0$ we show $p{ \scriptstyle \nearrow} 0$ is the same as
lex regression. We also give algorithms for computing the best $L_p$ isotonic
regression in certain situations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Stout_Q/0/1/0/all/0/1">Quentin F.Stout</a></p><p>Given a real-valued weighted function $f$ on a finite dag, the $L_p$ isotonic
regression of $f$, $p \in [0,\infty]$, is unique except when $p \in [0,1] \cup
\{\infty\}$. We are interested in determining a ``best'' isotonic regression
for $p \in \{0, 1, \infty\}$, where by best we mean a regression satisfying
stronger properties than merely having minimal norm. One approach is to use
strict $L_p$ regression, which is the limit of the best $L_q$ approximation as
$q$ approaches $p$, and another is lex regression, which is based on lexical
ordering of regression errors. For $L_\infty$ the strict and lex regressions
are unique and the same. For $L_1$, strict $q \scriptstyle\searrow 1$ is
unique, but we show that $q \scriptstyle\nearrow 1$ may not be, and even when
it is unique the two limits may not be the same. For $L_0$, in general neither
of the strict and lex regressions are unique, nor do they always have the same
set of optimal regressions, but by expanding the objectives of $L_p$
optimization to $p &lt; 0$ we show $p{ \scriptstyle \nearrow} 0$ is the same as
lex regression. We also give algorithms for computing the best $L_p$ isotonic
regression in certain situations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-02T00:30:00Z">Friday, June 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.00338'>Last Switch Dependent Bandits with Monotone Payoff Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ayoub Foussoul, Vineet Goyal, Orestis Papadigenopoulos, Assaf Zeevi</p><p>In a recent work, Laforgue et al. introduce the model of last switch
dependent (LSD) bandits, in an attempt to capture nonstationary phenomena
induced by the interaction between the player and the environment. Examples
include satiation, where consecutive plays of the same action lead to decreased
performance, or deprivation, where the payoff of an action increases after an
interval of inactivity. In this work, we take a step towards understanding the
approximability of planning LSD bandits, namely, the (NP-hard) problem of
computing an optimal arm-pulling strategy under complete knowledge of the
model. In particular, we design the first efficient constant approximation
algorithm for the problem and show that, under a natural monotonicity
assumption on the payoffs, its approximation guarantee (almost) matches the
state-of-the-art for the special and well-studied class of recharging bandits
(also known as delay-dependent). In this attempt, we develop new tools and
insights for this class of problems, including a novel higher-dimensional
relaxation and the technique of mirroring the evolution of virtual states. We
believe that these novel elements could potentially be used for approaching
richer classes of action-induced nonstationary bandits (e.g., special instances
of restless bandits). In the case where the model parameters are initially
unknown, we develop an online learning adaptation of our algorithm for which we
provide sublinear regret guarantees against its full-information counterpart.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Foussoul_A/0/1/0/all/0/1">Ayoub Foussoul</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_V/0/1/0/all/0/1">Vineet Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Papadigenopoulos_O/0/1/0/all/0/1">Orestis Papadigenopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeevi_A/0/1/0/all/0/1">Assaf Zeevi</a></p><p>In a recent work, Laforgue et al. introduce the model of last switch
dependent (LSD) bandits, in an attempt to capture nonstationary phenomena
induced by the interaction between the player and the environment. Examples
include satiation, where consecutive plays of the same action lead to decreased
performance, or deprivation, where the payoff of an action increases after an
interval of inactivity. In this work, we take a step towards understanding the
approximability of planning LSD bandits, namely, the (NP-hard) problem of
computing an optimal arm-pulling strategy under complete knowledge of the
model. In particular, we design the first efficient constant approximation
algorithm for the problem and show that, under a natural monotonicity
assumption on the payoffs, its approximation guarantee (almost) matches the
state-of-the-art for the special and well-studied class of recharging bandits
(also known as delay-dependent). In this attempt, we develop new tools and
insights for this class of problems, including a novel higher-dimensional
relaxation and the technique of mirroring the evolution of virtual states. We
believe that these novel elements could potentially be used for approaching
richer classes of action-induced nonstationary bandits (e.g., special instances
of restless bandits). In the case where the model parameters are initially
unknown, we develop an online learning adaptation of our algorithm for which we
provide sublinear regret guarantees against its full-information counterpart.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-02T00:30:00Z">Friday, June 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.00432'>Time and Space Optimal Massively Parallel Algorithm for the 2-Ruling Set Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: M&#xe9;lanie Cambus, Fabian Kuhn, Shreyas Pai, Jara Uitto</p><p>In this work, we present a constant-round algorithm for the $2$-ruling set
problem in the Congested Clique model. As a direct consequence, we obtain a
constant round algorithm in the MPC model with linear space-per-machine and
optimal total space. Our results improve on the $O(\log \log \log n)$-round
algorithm by [HPS, DISC'14] and the $O(\log \log \Delta)$-round algorithm by
[GGKMR, PODC'18]. Our techniques can also be applied to the semi-streaming
model to obtain an $O(1)$-pass algorithm. Our main technical contribution is a
novel sampling procedure that returns a small subgraph such that almost all
nodes in the input graph are adjacent to the sampled subgraph. An MIS on the
sampled subgraph provides a $2$-ruling set for a large fraction of the input
graph. As a technical challenge, we must handle the remaining part of the
graph, which might still be relatively large. We overcome this challenge by
showing useful structural properties of the remaining graph and show that
running our process twice yields a $2$-ruling set of the original input graph
with high probability.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cambus_M/0/1/0/all/0/1">M&#xe9;lanie Cambus</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhn_F/0/1/0/all/0/1">Fabian Kuhn</a>, <a href="http://arxiv.org/find/cs/1/au:+Pai_S/0/1/0/all/0/1">Shreyas Pai</a>, <a href="http://arxiv.org/find/cs/1/au:+Uitto_J/0/1/0/all/0/1">Jara Uitto</a></p><p>In this work, we present a constant-round algorithm for the $2$-ruling set
problem in the Congested Clique model. As a direct consequence, we obtain a
constant round algorithm in the MPC model with linear space-per-machine and
optimal total space. Our results improve on the $O(\log \log \log n)$-round
algorithm by [HPS, DISC'14] and the $O(\log \log \Delta)$-round algorithm by
[GGKMR, PODC'18]. Our techniques can also be applied to the semi-streaming
model to obtain an $O(1)$-pass algorithm. Our main technical contribution is a
novel sampling procedure that returns a small subgraph such that almost all
nodes in the input graph are adjacent to the sampled subgraph. An MIS on the
sampled subgraph provides a $2$-ruling set for a large fraction of the input
graph. As a technical challenge, we must handle the remaining part of the
graph, which might still be relatively large. We overcome this challenge by
showing useful structural properties of the remaining graph and show that
running our process twice yields a $2$-ruling set of the original input graph
with high probability.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-02T00:30:00Z">Friday, June 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, June 01
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/082'>TR23-082 |  Self-Improvement for Circuit-Analysis Problems | 

	Ryan Williams</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Many results in fine-grained complexity reveal intriguing consequences from solving various SAT problems even slightly faster than exhaustive search. We prove a ``self-improving&#39;&#39; (or ``bootstrapping&#39;&#39;) theorem for Circuit-SAT, $\#$Circuit-SAT, and its fully-quantified version: solving one of these problems faster for ``large&#39;&#39; circuit sizes implies a significant speed-up for ``smaller&#39;&#39; circuit sizes. Our general arguments work for a variety of models solving circuit-analysis problems, including non-uniform circuits and randomized models of computation.

We derive striking consequences for the complexities of these problems. For example, we show that certain fine-grained improvements on the runtime exponents of polynomial-time versions of Circuit-SAT would imply *subexponential-time* algorithms for Circuit-SAT on $2^{o(n)}$-size circuits, refuting the Exponential Time Hypothesis. We also show how slightly faster $\#$Circuit-SAT algorithms on large circuits can be used to prove lower bounds against uniform circuits with symmetric gates for functions in deterministic linear time. Our result suggests an ``algorithmic method&#39;&#39; approach for uniform circuit lower bounds, which trades non-uniformity for a substantial reduction in the complexity of the hard function.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Many results in fine-grained complexity reveal intriguing consequences from solving various SAT problems even slightly faster than exhaustive search. We prove a ``self-improving&#39;&#39; (or ``bootstrapping&#39;&#39;) theorem for Circuit-SAT, $\#$Circuit-SAT, and its fully-quantified version: solving one of these problems faster for ``large&#39;&#39; circuit sizes implies a significant speed-up for ``smaller&#39;&#39; circuit sizes. Our general arguments work for a variety of models solving circuit-analysis problems, including non-uniform circuits and randomized models of computation.

We derive striking consequences for the complexities of these problems. For example, we show that certain fine-grained improvements on the runtime exponents of polynomial-time versions of Circuit-SAT would imply *subexponential-time* algorithms for Circuit-SAT on $2^{o(n)}$-size circuits, refuting the Exponential Time Hypothesis. We also show how slightly faster $\#$Circuit-SAT algorithms on large circuits can be used to prove lower bounds against uniform circuits with symmetric gates for functions in deterministic linear time. Our result suggests an ``algorithmic method&#39;&#39; approach for uniform circuit lower bounds, which trades non-uniformity for a substantial reduction in the complexity of the hard function.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T14:41:12Z">Thursday, June 01 2023, 14:41</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/081'>TR23-081 |  Constant-Round Arguments from One-Way Functions | 

	Noga Amit, 

	Guy Rothblum</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study the following question: what cryptographic assumptions are needed for obtaining constant-round computationally-sound argument systems? We focus on argument systems with almost-linear verification time for subclasses of $\mathbf{P}$, such as depth-bounded computations.
Kilian&#39;s celebrated work [STOC 1992] provides such 4-message arguments for $\mathbf{P}$ (actually, for $\mathbf{NP}$) using collision-resistant hash functions. 
We show that $one$-$way\ functions$ suffice for obtaining constant-round arguments of almost-linear verification time for languages in $\mathbf{P}$ that have log-space uniform circuits of linear depth and polynomial size. More generally, the complexity of the verifier scales with the circuit depth.  Furthermore, our argument systems (like Kilian&#39;s) are doubly-efficient; that is, the honest prover strategy can be implemented in polynomial-time. 
Unconditionally sound interactive proofs for this class of computations do not rely on any cryptographic assumptions, but they require a linear number of rounds [Goldwasser, Kalai and Rothblum, STOC 2008]. Constant-round interactive proof systems of linear verification complexity are not known even for $\mathbf{NC}$ (indeed, even for $\mathbf{AC}^1$).
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study the following question: what cryptographic assumptions are needed for obtaining constant-round computationally-sound argument systems? We focus on argument systems with almost-linear verification time for subclasses of $\mathbf{P}$, such as depth-bounded computations.
Kilian&#39;s celebrated work [STOC 1992] provides such 4-message arguments for $\mathbf{P}$ (actually, for $\mathbf{NP}$) using collision-resistant hash functions. 
We show that $one$-$way\ functions$ suffice for obtaining constant-round arguments of almost-linear verification time for languages in $\mathbf{P}$ that have log-space uniform circuits of linear depth and polynomial size. More generally, the complexity of the verifier scales with the circuit depth.  Furthermore, our argument systems (like Kilian&#39;s) are doubly-efficient; that is, the honest prover strategy can be implemented in polynomial-time. 
Unconditionally sound interactive proofs for this class of computations do not rely on any cryptographic assumptions, but they require a linear number of rounds [Goldwasser, Kalai and Rothblum, STOC 2008]. Constant-round interactive proof systems of linear verification complexity are not known even for $\mathbf{NC}$ (indeed, even for $\mathbf{AC}^1$).
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T05:42:37Z">Thursday, June 01 2023, 05:42</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.19504'>Self-Replicating Hierarchical Structures Emerge in a Binary Cellular Automaton</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bo Yang</p><p>We have discovered a novel transition rule for binary cellular automata (CA)
that yields self-replicating structures across two spatial and temporal scales
from sparsely populated random initial conditions. Lower-level, shapeshifting
clusters frequently follow a transient attractor trajectory, generating new
clusters, some of which periodically self-duplicate. When the initial
distribution of live cells is sufficiently sparse, these clusters coalesce into
larger formations that also self-replicate. These formations may further form
the boundaries of an expanding complex on an even larger scale. This rule,
dubbed ``Outlier,'' is rotationally symmetric and applies to 2D Moore
neighborhoods. It was evolved through Genetic Programming during an extensive
automated search for rules that foster open-ended evolution in CA. While
self-replicating structures, both crafted and emergent, have been created in CA
with state sets intentionally designed for this purpose, the Outlier may be the
first known rule to facilitate emergent self-replication across two spatial
scales in simple binary CA.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/nlin/1/au:+Yang_B/0/1/0/all/0/1">Bo Yang</a></p><p>We have discovered a novel transition rule for binary cellular automata (CA)
that yields self-replicating structures across two spatial and temporal scales
from sparsely populated random initial conditions. Lower-level, shapeshifting
clusters frequently follow a transient attractor trajectory, generating new
clusters, some of which periodically self-duplicate. When the initial
distribution of live cells is sufficiently sparse, these clusters coalesce into
larger formations that also self-replicate. These formations may further form
the boundaries of an expanding complex on an even larger scale. This rule,
dubbed ``Outlier,'' is rotationally symmetric and applies to 2D Moore
neighborhoods. It was evolved through Genetic Programming during an extensive
automated search for rules that foster open-ended evolution in CA. While
self-replicating structures, both crafted and emergent, have been created in CA
with state sets intentionally designed for this purpose, the Outlier may be the
first known rule to facilitate emergent self-replication across two spatial
scales in simple binary CA.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T00:30:00Z">Thursday, June 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.19777'>On the Shortest Lattice Vector vs. the Shortest Basis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yael Eisenberg, Itamar Rot, Muli Safra</p><p>Given an arbitrary basis for a mathematical lattice, to find a ``good" basis
for it is one of the classic and important algorithmic problems. In this note,
we give a new and simpler proof of a theorem by Regavim (arXiv:0706.1234): we
construct a 18-dimensional lattice that does not have a basis that satisfies
the following two properties simultaneously: 1. The basis includes the shortest
non-zero lattice vector. 2. The basis is shortest, that is, minimizes the
longest basis vector (alternatively: the sum or the sum-of-squares of the basis
vectors). The vectors' length can be measured in any $\ell^q$ norm, for $q\in
\mathbb{N}_+$ (albeit, via another lattice, of a somewhat larger dimension).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Eisenberg_Y/0/1/0/all/0/1">Yael Eisenberg</a>, <a href="http://arxiv.org/find/math/1/au:+Rot_I/0/1/0/all/0/1">Itamar Rot</a>, <a href="http://arxiv.org/find/math/1/au:+Safra_M/0/1/0/all/0/1">Muli Safra</a></p><p>Given an arbitrary basis for a mathematical lattice, to find a ``good" basis
for it is one of the classic and important algorithmic problems. In this note,
we give a new and simpler proof of a theorem by Regavim (<a href="/abs/0706.1234">arXiv:0706.1234</a>): we
construct a 18-dimensional lattice that does not have a basis that satisfies
the following two properties simultaneously: 1. The basis includes the shortest
non-zero lattice vector. 2. The basis is shortest, that is, minimizes the
longest basis vector (alternatively: the sum or the sum-of-squares of the basis
vectors). The vectors' length can be measured in any $\ell^q$ norm, for $q\in
\mathbb{N}_+$ (albeit, via another lattice, of a somewhat larger dimension).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T00:30:00Z">Thursday, June 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.19320'>On the algebraic proof complexity of Tensor Isomorphism</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicola Galesi, Joshua A. Grochow, Toniann Pitassi, Adrian She</p><p>The Tensor Isomorphism problem (TI) has recently emerged as having
connections to multiple areas of research within complexity and beyond, but the
current best upper bound is essentially the brute force algorithm. Being an
algebraic problem, TI (or rather, proving that two tensors are non-isomorphic)
lends itself very naturally to algebraic and semi-algebraic proof systems, such
as the Polynomial Calculus (PC) and Sum of Squares (SoS). For its combinatorial
cousin Graph Isomorphism, essentially optimal lower bounds are known for
approaches based on PC and SoS (Berkholz &amp; Grohe, SODA '17). Our main results
are an $\Omega(n)$ lower bound on PC degree or SoS degree for Tensor
Isomorphism, and a nontrivial upper bound for testing isomorphism of tensors of
bounded rank.
</p>
<p>We also show that PC cannot perform basic linear algebra in sub-linear
degree, such as comparing the rank of two matrices, or deriving $BA=I$ from
$AB=I$. As linear algebra is a key tool for understanding tensors, we introduce
a strictly stronger proof system, PC+Inv, which allows as derivation rules all
substitution instances of the implication $AB=I \rightarrow BA=I$. We
conjecture that even PC+Inv cannot solve TI in polynomial time either, but
leave open getting lower bounds on PC+Inv for any system of equations, let
alone those for TI. We also highlight many other open questions about proof
complexity approaches to TI.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Galesi_N/0/1/0/all/0/1">Nicola Galesi</a>, <a href="http://arxiv.org/find/cs/1/au:+Grochow_J/0/1/0/all/0/1">Joshua A. Grochow</a>, <a href="http://arxiv.org/find/cs/1/au:+Pitassi_T/0/1/0/all/0/1">Toniann Pitassi</a>, <a href="http://arxiv.org/find/cs/1/au:+She_A/0/1/0/all/0/1">Adrian She</a></p><p>The Tensor Isomorphism problem (TI) has recently emerged as having
connections to multiple areas of research within complexity and beyond, but the
current best upper bound is essentially the brute force algorithm. Being an
algebraic problem, TI (or rather, proving that two tensors are non-isomorphic)
lends itself very naturally to algebraic and semi-algebraic proof systems, such
as the Polynomial Calculus (PC) and Sum of Squares (SoS). For its combinatorial
cousin Graph Isomorphism, essentially optimal lower bounds are known for
approaches based on PC and SoS (Berkholz &amp; Grohe, SODA '17). Our main results
are an $\Omega(n)$ lower bound on PC degree or SoS degree for Tensor
Isomorphism, and a nontrivial upper bound for testing isomorphism of tensors of
bounded rank.
</p>
<p>We also show that PC cannot perform basic linear algebra in sub-linear
degree, such as comparing the rank of two matrices, or deriving $BA=I$ from
$AB=I$. As linear algebra is a key tool for understanding tensors, we introduce
a strictly stronger proof system, PC+Inv, which allows as derivation rules all
substitution instances of the implication $AB=I \rightarrow BA=I$. We
conjecture that even PC+Inv cannot solve TI in polynomial time either, but
leave open getting lower bounds on PC+Inv for any system of equations, let
alone those for TI. We also highlight many other open questions about proof
complexity approaches to TI.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T00:30:00Z">Thursday, June 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.19756'>Concentrated Geo-Privacy</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuting Liang, Ke Yi</p><p>This paper proposes concentrated geo-privacy (CGP), a privacy notion that can
be considered as the counterpart of concentrated differential privacy (CDP) for
geometric data. Compared with the previous notion of geo-privacy [ABCP13,
CABP13], which is the counterpart of standard differential privacy, CGP offers
many benefits including simplicity of the mechanism, lower noise scale in high
dimensions, and better composability known as advanced composition. The last
one is the most important, as it allows us to design complex mechanisms using
smaller building blocks while achieving better utilities. To complement this
result, we show that the previous notion of geo-privacy inherently does not
admit advanced composition even using its approximate version. Next, we study
three problems on private geometric data: the identity query, k nearest
neighbors, and convex hulls. While the first problem has been previously
studied, we give the first mechanisms for the latter two under geo-privacy. For
all three problems, composability is essential in obtaining good utility
guarantees on the privatized query answer.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yuting Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_K/0/1/0/all/0/1">Ke Yi</a></p><p>This paper proposes concentrated geo-privacy (CGP), a privacy notion that can
be considered as the counterpart of concentrated differential privacy (CDP) for
geometric data. Compared with the previous notion of geo-privacy [ABCP13,
CABP13], which is the counterpart of standard differential privacy, CGP offers
many benefits including simplicity of the mechanism, lower noise scale in high
dimensions, and better composability known as advanced composition. The last
one is the most important, as it allows us to design complex mechanisms using
smaller building blocks while achieving better utilities. To complement this
result, we show that the previous notion of geo-privacy inherently does not
admit advanced composition even using its approximate version. Next, we study
three problems on private geometric data: the identity query, k nearest
neighbors, and convex hulls. While the first problem has been previously
studied, we give the first mechanisms for the latter two under geo-privacy. For
all three problems, composability is essential in obtaining good utility
guarantees on the privatized query answer.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T00:30:00Z">Thursday, June 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.19475'>Doubly Constrained Fair Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: John Dickerson, Seyed A. Esmaeili, Jamie Morgenstern, Claire Jie Zhang</p><p>The remarkable attention which fair clustering has received in the last few
years has resulted in a significant number of different notions of fairness.
Despite the fact that these notions are well-justified, they are often
motivated and studied in a disjoint manner where one fairness desideratum is
considered exclusively in isolation from the others. This leaves the
understanding of the relations between different fairness notions as an
important open problem in fair clustering. In this paper, we take the first
step in this direction. Specifically, we consider the two most prominent
demographic representation fairness notions in clustering: (1) Group Fairness
(GF), where the different demographic groups are supposed to have close to
population-level representation in each cluster and (2) Diversity in Center
Selection (DS), where the selected centers are supposed to have close to
population-level representation of each group. We show that given a constant
approximation algorithm for one constraint (GF or DS only) we can obtain a
constant approximation solution that satisfies both constraints simultaneously.
Interestingly, we prove that any given solution that satisfies the GF
constraint can always be post-processed at a bounded degradation to the
clustering cost to additionally satisfy the DS constraint while the reverse is
not true. Furthermore, we show that both GF and DS are incompatible (having an
empty feasibility set in the worst case) with a collection of other
distance-based fairness notions. Finally, we carry experiments to validate our
theoretical findings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1">John Dickerson</a>, <a href="http://arxiv.org/find/cs/1/au:+Esmaeili_S/0/1/0/all/0/1">Seyed A. Esmaeili</a>, <a href="http://arxiv.org/find/cs/1/au:+Morgenstern_J/0/1/0/all/0/1">Jamie Morgenstern</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Claire Jie Zhang</a></p><p>The remarkable attention which fair clustering has received in the last few
years has resulted in a significant number of different notions of fairness.
Despite the fact that these notions are well-justified, they are often
motivated and studied in a disjoint manner where one fairness desideratum is
considered exclusively in isolation from the others. This leaves the
understanding of the relations between different fairness notions as an
important open problem in fair clustering. In this paper, we take the first
step in this direction. Specifically, we consider the two most prominent
demographic representation fairness notions in clustering: (1) Group Fairness
(GF), where the different demographic groups are supposed to have close to
population-level representation in each cluster and (2) Diversity in Center
Selection (DS), where the selected centers are supposed to have close to
population-level representation of each group. We show that given a constant
approximation algorithm for one constraint (GF or DS only) we can obtain a
constant approximation solution that satisfies both constraints simultaneously.
Interestingly, we prove that any given solution that satisfies the GF
constraint can always be post-processed at a bounded degradation to the
clustering cost to additionally satisfy the DS constraint while the reverse is
not true. Furthermore, we show that both GF and DS are incompatible (having an
empty feasibility set in the worst case) with a collection of other
distance-based fairness notions. Finally, we carry experiments to validate our
theoretical findings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T00:30:00Z">Thursday, June 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.19588'>Active causal structure learning with advice</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Davin Choo, Themis Gouleakis, Arnab Bhattacharyya</p><p>We introduce the problem of active causal structure learning with advice. In
the typical well-studied setting, the learning algorithm is given the essential
graph for the observational distribution and is asked to recover the underlying
causal directed acyclic graph (DAG) $G^*$ while minimizing the number of
interventions made. In our setting, we are additionally given side information
about $G^*$ as advice, e.g. a DAG $G$ purported to be $G^*$. We ask whether the
learning algorithm can benefit from the advice when it is close to being
correct, while still having worst-case guarantees even when the advice is
arbitrarily bad. Our work is in the same space as the growing body of research
on algorithms with predictions. When the advice is a DAG $G$, we design an
adaptive search algorithm to recover $G^*$ whose intervention cost is at most
$O(\max\{1, \log \psi\})$ times the cost for verifying $G^*$; here, $\psi$ is a
distance measure between $G$ and $G^*$ that is upper bounded by the number of
variables $n$, and is exactly 0 when $G=G^*$. Our approximation factor matches
the state-of-the-art for the advice-less setting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Choo_D/0/1/0/all/0/1">Davin Choo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gouleakis_T/0/1/0/all/0/1">Themis Gouleakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_A/0/1/0/all/0/1">Arnab Bhattacharyya</a></p><p>We introduce the problem of active causal structure learning with advice. In
the typical well-studied setting, the learning algorithm is given the essential
graph for the observational distribution and is asked to recover the underlying
causal directed acyclic graph (DAG) $G^*$ while minimizing the number of
interventions made. In our setting, we are additionally given side information
about $G^*$ as advice, e.g. a DAG $G$ purported to be $G^*$. We ask whether the
learning algorithm can benefit from the advice when it is close to being
correct, while still having worst-case guarantees even when the advice is
arbitrarily bad. Our work is in the same space as the growing body of research
on algorithms with predictions. When the advice is a DAG $G$, we design an
adaptive search algorithm to recover $G^*$ whose intervention cost is at most
$O(\max\{1, \log \psi\})$ times the cost for verifying $G^*$; here, $\psi$ is a
distance measure between $G$ and $G^*$ that is upper bounded by the number of
variables $n$, and is exactly 0 when $G=G^*$. Our approximation factor matches
the state-of-the-art for the advice-less setting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T00:30:00Z">Thursday, June 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.19659'>Improving Expressivity of Graph Neural Networks using Localization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anant Kumar, Shrutimoy Das, Shubhajit Roy, Binita Maity, Anirban Dasgupta</p><p>In this paper, we propose localized versions of Weisfeiler-Leman (WL)
algorithms in an effort to both increase the expressivity, as well as decrease
the computational overhead. We focus on the specific problem of subgraph
counting and give localized versions of $k-$WL for any $k$. We analyze the
power of Local $k-$WL and prove that it is more expressive than $k-$WL and at
most as expressive as $(k+1)-$WL. We give a characterization of patterns whose
count as a subgraph and induced subgraph are invariant if two graphs are Local
$k-$WL equivalent. We also introduce two variants of $k-$WL: Layer $k-$WL and
recursive $k-$WL. These methods are more time and space efficient than applying
$k-$WL on the whole graph. We also propose a fragmentation technique that
guarantees the exact count of all induced subgraphs of size at most 4 using
just $1-$WL. The same idea can be extended further for larger patterns using
$k&gt;1$. We also compare the expressive power of Local $k-$WL with other GNN
hierarchies and show that given a bound on the time-complexity, our methods are
more expressive than the ones mentioned in Papp and Wattenhofer[2022a].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Anant Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Shrutimoy Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Shubhajit Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Maity_B/0/1/0/all/0/1">Binita Maity</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasgupta_A/0/1/0/all/0/1">Anirban Dasgupta</a></p><p>In this paper, we propose localized versions of Weisfeiler-Leman (WL)
algorithms in an effort to both increase the expressivity, as well as decrease
the computational overhead. We focus on the specific problem of subgraph
counting and give localized versions of $k-$WL for any $k$. We analyze the
power of Local $k-$WL and prove that it is more expressive than $k-$WL and at
most as expressive as $(k+1)-$WL. We give a characterization of patterns whose
count as a subgraph and induced subgraph are invariant if two graphs are Local
$k-$WL equivalent. We also introduce two variants of $k-$WL: Layer $k-$WL and
recursive $k-$WL. These methods are more time and space efficient than applying
$k-$WL on the whole graph. We also propose a fragmentation technique that
guarantees the exact count of all induced subgraphs of size at most 4 using
just $1-$WL. The same idea can be extended further for larger patterns using
$k&gt;1$. We also compare the expressive power of Local $k-$WL with other GNN
hierarchies and show that given a bound on the time-complexity, our methods are
more expressive than the ones mentioned in Papp and Wattenhofer[2022a].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T00:30:00Z">Thursday, June 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.19666'>Efficient Algorithms for Exact Graph Matching on Correlated Stochastic Block Models with Constant Correlation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Joonhyuk Yang, Dongpil Shin, Hye Won Chung</p><p>We consider the problem of graph matching, or learning vertex correspondence,
between two correlated stochastic block models (SBMs). The graph matching
problem arises in various fields, including computer vision, natural language
processing and bioinformatics, and in particular, matching graphs with inherent
community structure has significance related to de-anonymization of correlated
social networks. Compared to the correlated Erdos-Renyi (ER) model, where
various efficient algorithms have been developed, among which a few algorithms
have been proven to achieve the exact matching with constant edge correlation,
no low-order polynomial algorithm has been known to achieve exact matching for
the correlated SBMs with constant correlation. In this work, we propose an
efficient algorithm for matching graphs with community structure, based on the
comparison between partition trees rooted from each vertex, by extending the
idea of Mao et al. (2021) to graphs with communities. The partition tree
divides the large neighborhoods of each vertex into disjoint subsets using
their edge statistics to different communities. Our algorithm is the first
low-order polynomial-time algorithm achieving exact matching between two
correlated SBMs with high probability in dense graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Joonhyuk Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_D/0/1/0/all/0/1">Dongpil Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1">Hye Won Chung</a></p><p>We consider the problem of graph matching, or learning vertex correspondence,
between two correlated stochastic block models (SBMs). The graph matching
problem arises in various fields, including computer vision, natural language
processing and bioinformatics, and in particular, matching graphs with inherent
community structure has significance related to de-anonymization of correlated
social networks. Compared to the correlated Erdos-Renyi (ER) model, where
various efficient algorithms have been developed, among which a few algorithms
have been proven to achieve the exact matching with constant edge correlation,
no low-order polynomial algorithm has been known to achieve exact matching for
the correlated SBMs with constant correlation. In this work, we propose an
efficient algorithm for matching graphs with community structure, based on the
comparison between partition trees rooted from each vertex, by extending the
idea of Mao et al. (2021) to graphs with communities. The partition tree
divides the large neighborhoods of each vertex into disjoint subsets using
their edge statistics to different communities. Our algorithm is the first
low-order polynomial-time algorithm achieving exact matching between two
correlated SBMs with high probability in dense graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T00:30:00Z">Thursday, June 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.19673'>Quantum Speedups for Bayesian Network Structure Learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Juha Harviainen (1), Kseniya Rychkova (2), Mikko Koivisto (1) ((1) University of Helsinki, (2) IQM)</p><p>The Bayesian network structure learning (BNSL) problem asks for a directed
acyclic graph that maximizes a given score function. For networks with $n$
nodes, the fastest known algorithms run in time $O(2^n n^2)$ in the worst case,
with no improvement in the asymptotic bound for two decades. Inspired by recent
advances in quantum computing, we ask whether BNSL admits a polynomial quantum
speedup, that is, whether the problem can be solved by a quantum algorithm in
time $O(c^n)$ for some constant $c$ less than $2$. We answer the question in
the affirmative by giving two algorithms achieving $c \leq 1.817$ and $c \leq
1.982$ assuming the number of potential parent sets is, respectively,
subexponential and $O(1.453^n)$. Both algorithms assume the availability of a
quantum random access memory.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Harviainen_J/0/1/0/all/0/1">Juha Harviainen</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Rychkova_K/0/1/0/all/0/1">Kseniya Rychkova</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Koivisto_M/0/1/0/all/0/1">Mikko Koivisto</a> (1) ((1) University of Helsinki, (2) IQM)</p><p>The Bayesian network structure learning (BNSL) problem asks for a directed
acyclic graph that maximizes a given score function. For networks with $n$
nodes, the fastest known algorithms run in time $O(2^n n^2)$ in the worst case,
with no improvement in the asymptotic bound for two decades. Inspired by recent
advances in quantum computing, we ask whether BNSL admits a polynomial quantum
speedup, that is, whether the problem can be solved by a quantum algorithm in
time $O(c^n)$ for some constant $c$ less than $2$. We answer the question in
the affirmative by giving two algorithms achieving $c \leq 1.817$ and $c \leq
1.982$ assuming the number of potential parent sets is, respectively,
subexponential and $O(1.453^n)$. Both algorithms assume the availability of a
quantum random access memory.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T00:30:00Z">Thursday, June 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.19706'>Optimal Decision Trees for Separable Objectives: Pushing the Limits of Dynamic Programming</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jacobus G. M. van der Linden, Mathijs M. de Weerdt, Emir Demirovi&#x107;</p><p>Global optimization of decision trees has shown to be promising in terms of
accuracy, size, and consequently human comprehensibility. However, many of the
methods used rely on general-purpose solvers for which scalability remains an
issue. Dynamic programming methods have been shown to scale much better because
they exploit the tree structure by solving subtrees as independent subproblems.
However, this only works when an objective can be optimized separately for
subtrees. We explore this relationship in detail and show necessary and
sufficient conditions for such separability and generalize previous dynamic
programming approaches into a framework that can optimize any combination of
separable objectives and constraints. Experiments on four application domains
show the general applicability of this framework, while outperforming the
scalability of general-purpose solvers by a large margin.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Linden_J/0/1/0/all/0/1">Jacobus G. M. van der Linden</a>, <a href="http://arxiv.org/find/cs/1/au:+Weerdt_M/0/1/0/all/0/1">Mathijs M. de Weerdt</a>, <a href="http://arxiv.org/find/cs/1/au:+Demirovic_E/0/1/0/all/0/1">Emir Demirovi&#x107;</a></p><p>Global optimization of decision trees has shown to be promising in terms of
accuracy, size, and consequently human comprehensibility. However, many of the
methods used rely on general-purpose solvers for which scalability remains an
issue. Dynamic programming methods have been shown to scale much better because
they exploit the tree structure by solving subtrees as independent subproblems.
However, this only works when an objective can be optimized separately for
subtrees. We explore this relationship in detail and show necessary and
sufficient conditions for such separability and generalize previous dynamic
programming approaches into a framework that can optimize any combination of
separable objectives and constraints. Experiments on four application domains
show the general applicability of this framework, while outperforming the
scalability of general-purpose solvers by a large margin.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T00:30:00Z">Thursday, June 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/080'>TR23-080 |  Improved Learning from Kolmogorov Complexity | 

	Valentine Kabanets, 

	Halley Goldberg</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Carmosino, Impagliazzo, Kabanets, and Kolokolova (CCC, 2016) showed that the existence of natural properties in the sense of Razborov and Rudich (JCSS, 1997) implies PAC learning algorithms in the sense of Valiant (Comm. ACM, 1984), for boolean functions in $\P/\poly$, under the uniform distribution and with membership queries. It is still an open problem to get from natural properties learning algorithms that do not rely on membership queries but rather use randomly drawn labeled examples.  

        Natural properties may be understood as an average-case version of MCSP, the problem of deciding the minimum size of a circuit computing a given truth-table. Problems related to MCSP include those concerning time-bounded Kolmogorov complexity. MKTP, for example, asks for the KT-complexity of a given string. KT-complexity is a relaxation of circuit size, as it does away with the requirement that a short description of a string be interpreted as a boolean circuit.    
        In this work, under assumptions of MKTP and the related problem $\mktp$ being easy on average, we get  learning algorithms for boolean functions in $\P/\poly$ that       
        \begin{itemize}
            \item  work over any distribution $D$ samplable by a family of polynomial-size circuits (given explicitly in the case of $\MKTP$), 
            \item  only use randomly drawn labeled examples from $D$, and
            \item are agnostic (do not require the target function to belong to the hypothesis class). 
        \end{itemize}
        Our results build upon the recent work of Hirahara and Nanashima (FOCS, 2021) who showed similar learning consequences but under a stronger assumption that $\NP$ is easy on average.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Carmosino, Impagliazzo, Kabanets, and Kolokolova (CCC, 2016) showed that the existence of natural properties in the sense of Razborov and Rudich (JCSS, 1997) implies PAC learning algorithms in the sense of Valiant (Comm. ACM, 1984), for boolean functions in $\P/\poly$, under the uniform distribution and with membership queries. It is still an open problem to get from natural properties learning algorithms that do not rely on membership queries but rather use randomly drawn labeled examples.  

        Natural properties may be understood as an average-case version of MCSP, the problem of deciding the minimum size of a circuit computing a given truth-table. Problems related to MCSP include those concerning time-bounded Kolmogorov complexity. MKTP, for example, asks for the KT-complexity of a given string. KT-complexity is a relaxation of circuit size, as it does away with the requirement that a short description of a string be interpreted as a boolean circuit.    
        In this work, under assumptions of MKTP and the related problem $\mktp$ being easy on average, we get  learning algorithms for boolean functions in $\P/\poly$ that       
        \begin{itemize}
            \item  work over any distribution $D$ samplable by a family of polynomial-size circuits (given explicitly in the case of $\MKTP$), 
            \item  only use randomly drawn labeled examples from $D$, and
            \item are agnostic (do not require the target function to belong to the hypothesis class). 
        \end{itemize}
        Our results build upon the recent work of Hirahara and Nanashima (FOCS, 2021) who showed similar learning consequences but under a stronger assumption that $\NP$ is easy on average.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T00:07:23Z">Thursday, June 01 2023, 00:07</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/079'>TR23-079 |  Mutual Empowerment between  Circuit Obfuscation and Circuit Minimization | 

	Russell Impagliazzo, 

	Valentine Kabanets, 

	Ilya Volkovich</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study close connections between Indistinguishability Obfuscation ($IO$) and the Minimum Circuit Size Problem ($MCSP$), and argue that algorithms for one of $MCSP$ or $IO$ would empower the other one. Some of our main results are:

\begin{itemize}
    \item If there exists a perfect (imperfect) $IO$ that is computationally secure against nonuniform polynomial-size circuits, then for all $k \in \mathbb{N}$: $NP \cap ZPP^{MCSP} \not \subseteq SIZE[n^k]$ ($MA \cap ZPP^{MCSP} \not \subseteq SIZE[n^k]$). 
    
    \item  In addition, if there exists a perfect $IO$ that is computationally secure against nonuniform polynomial-size circuits, then $NEXP \cap ZPEXP^{MCSP} \not \subseteq P/poly.$
    
    \item If $MCSP \in BPP$, then statistical security and computational security for $IO$ are equivalent.
    
    \item If computationally-secure perfect $IO$ exists, then $MCSP \in BPP$ iff $NP = ZPP$.

    \item If computationally-secure perfect $IO$ exists, then $ZPEXP \neq BPP$.
    
\end{itemize}

To the best of our knowledge, this is the first consequence of strong circuit lower bounds from the existence of an $IO$. The results are obtained via a construction of an optimal \emph{universal distinguisher}, computable in randomized polynomial time with access to the $MCSP$ oracle, that will distinguish any two circuit-samplable distributions with the advantage that is the statistical distance between these two distributions minus some negligible error term. This is our main technical contribution. As another immediate application, we get a simple proof of the result by Allender and Das (Inf. Comput., 2017) that $SZK \subseteq BPP^{MCSP}$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study close connections between Indistinguishability Obfuscation ($IO$) and the Minimum Circuit Size Problem ($MCSP$), and argue that algorithms for one of $MCSP$ or $IO$ would empower the other one. Some of our main results are:

\begin{itemize}
    \item If there exists a perfect (imperfect) $IO$ that is computationally secure against nonuniform polynomial-size circuits, then for all $k \in \mathbb{N}$: $NP \cap ZPP^{MCSP} \not \subseteq SIZE[n^k]$ ($MA \cap ZPP^{MCSP} \not \subseteq SIZE[n^k]$). 
    
    \item  In addition, if there exists a perfect $IO$ that is computationally secure against nonuniform polynomial-size circuits, then $NEXP \cap ZPEXP^{MCSP} \not \subseteq P/poly.$
    
    \item If $MCSP \in BPP$, then statistical security and computational security for $IO$ are equivalent.
    
    \item If computationally-secure perfect $IO$ exists, then $MCSP \in BPP$ iff $NP = ZPP$.

    \item If computationally-secure perfect $IO$ exists, then $ZPEXP \neq BPP$.
    
\end{itemize}

To the best of our knowledge, this is the first consequence of strong circuit lower bounds from the existence of an $IO$. The results are obtained via a construction of an optimal \emph{universal distinguisher}, computable in randomized polynomial time with access to the $MCSP$ oracle, that will distinguish any two circuit-samplable distributions with the advantage that is the statistical distance between these two distributions minus some negligible error term. This is our main technical contribution. As another immediate application, we get a simple proof of the result by Allender and Das (Inf. Comput., 2017) that $SZK \subseteq BPP^{MCSP}$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-01T00:00:41Z">Thursday, June 01 2023, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, May 31
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/05/31/linkage.html'>Linkage</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The state space of a \(2\times 2\times 2\) Rubik’s cube under half-turns turns out to be yet another way of describing the Nauru graph.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <ul>
  <li>
    <p><a href="https://mathstodon.xyz/@kisonecat/110372922533677135">The state space of a \(2\times 2\times 2\) Rubik’s cube under half-turns</a> turns out to be yet another way of describing the <a href="https://en.wikipedia.org/wiki/Nauru_graph">Nauru graph</a>.</p>
  </li>
  <li>
    <p><a href="https://arstechnica.com/science/2023/05/french-painters-inspire-new-insights-into-the-physics-of-soap-bubbles/">French painters inspire new insights into the physics of soap bubbles</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110393699679704026">\(\mathbb{M}\)</a>):</span> Jennifer Ouelette in <em>Ars Technica</em> on how blowing bubbles through a long narrow air tube affects their size, based on a preprint “<a href="https://storage.pardot.com/640833/1683834035YRiFuKjN/FA10159_min.pdf">Unstable growth of bubbles from a constriction</a>” by Marc Grosjean and Elise Lorenceau.</p>
  </li>
  <li>
    <p>Good news for teaching faculty in my department <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110397234546657594">\(\mathbb{M}\)</a>):</span> my friend and colleague <a href="https://www.ics.uci.edu/~mikes/">Michael Shindler</a> just got tenure, as an associate professor of teaching. Michael is local: he was an undergraduate here before getting a Ph.D. in theoretical computer science with Adam Meyerson at UCLA, and then taught at the University of Southern California before returning to us as an assistant professor of teaching. Whenever I see an exceptionally bright undergraduate asking to take my graduate data structures class, it’s almost always because they were encouraged along the way by Michael.</p>

    <p>The “professor of teaching” series is relatively new for us, added about five years ago alongside our “Unit 18” lecturers (named for their union) and replacing our previous “lecturer with security of employment” series. Compared to other regular-rank faculty they have a higher teaching load and lower but nonzero research expectations, typically focusing on computer science education. They can also advise doctoral students (and Michael is doing so). Although we have hired some into the more senior ranks, Michael is the first to go through the tenure process. He says that when he recently went to SIGCSE, the question everyone wanted to ask him was: is it true that computer science education specialists can be senate faculty in your department? It is true, and they can get tenure for doing it.</p>
  </li>
  <li>
    <p><a href="https://www.atlasobscura.com/articles/dodecahedrons-roman-empire">The mysterious dodecahedrons of the Roman empire</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110405305127131102">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=35937540">via</a>, <a href="https://en.wikipedia.org/wiki/Roman_dodecahedron">see also</a>). One plausible theory: they are <a href="https://en.wikipedia.org/wiki/Spool_knitting">spool knitting</a> devices for making gloves.</p>
  </li>
  <li>
    <p><a href="https://www.thisiscolossal.com/2023/04/charles-brooks-architecture-music/">Architecturally-styled photographs of the interior of musical instruments</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@colossal@mastodon.art/110356933574807837">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://www.nytimes.com/2023/05/21/science/math-puzzles-integer-sequences.html">The <em>New York Times</em> has a profile by Siobhan Roberts on the Online Encyclopedia of Integer Sequences, celebrating its 50th anniversary</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110411066621174831">\(\mathbb{M}\)</a>,</span> <a href="https://web.archive.org/web/20230522005810/https://www.nytimes.com/2023/05/21/science/math-puzzles-integer-sequences.html">archived</a>).</p>
  </li>
  <li>
    <p>In 3d, every polyhedron has a combinatorially equivalent form with rational (or integer) coordinates, but in higher dimensions that isn’t true <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110420402994075366">\(\mathbb{M}\)</a>).</span> Daniel Bernstein in The Matroid Union examines <a href="http://matroidunion.org/?p=4868">connections between irrational polytope constructions and matroid theory</a>.</p>
  </li>
  <li>
    <p><a href="https://eccc.weizmann.ac.il/report/2023/076/">A pseudodeterministic algorithm for finding primes</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@fortnow@fediscience.org/110429540761716309">\(\mathbb{M}\)</a>,</span> <a href="https://blog.computationalcomplexity.org/2023/05/finding-primes-pseudodeterministically.html">via</a>), by Lijie Chen, Zhenjian Lu, Igor Carboni Oliveira, Hanlin Ren and Rahul Santhanam. More precisely, this is a randomized algorithm for finding an \(n\)-bit prime number that runs in time polynomial in \(n\) and, with high probability, for infinitely many \(n\), outputs the same prime whenever you run it.</p>
  </li>
  <li>
    <p><a href="https://cacm.acm.org/magazines/2023/6/273222-the-silent-revolution-of-sat/fulltext">The silent (r)evolution of SAT</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@Jose_A_Alonso/110430153381835143">\(\mathbb{M}\)</a>),</span> new survey in <em>CACM</em> on SAT-solvers and their applications, by Johannes K. Fichte, Daniel Le Berre, Markus Hecher, and Stefan Szeider.</p>
  </li>
  <li>
    <p><a href="https://torrentfreak.com/music-company-asks-google-to-delist-youtube-downloader-wikipedia-article-230528/">Music industry requests Google to censor Wikipedia</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110448051373386779">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=36106741">via</a>). The Wikipedia article in question: <a href="https://en.wikipedia.org/wiki/Comparison_of_YouTube_downloaders">Comparison of YouTube downloaders</a>. It’s not a great example of a high-quality Wikipedia article but the precedent of asking for censorship of any mention or discussion of content piracy (beyond going after the pirates themselves) is extremely troubling.</p>
  </li>
  <li>
    <p><a href="https://dailynous.com/2023/05/25/am-i-the-unethical-one-a-philosophy-professor-his-cheating-students/">Ethics professor asks “Am I the unethical one?”</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110450109807128058">\(\mathbb{M}\)</a>,</span> <a href="https://www.insidehighered.com/news/quick-takes/2023/05/26/philosophy-professor-uses-fake-online-answers-catch-cheating">via</a>) after setting an online trap for cheating students and catching nearly half his class.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2305.17743">A chiral aperiodic monotile</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@csk/110454792622698781">\(\mathbb{M}\)</a>,</span> <a href="https://mathstodon.xyz/@csk/110454664118770148">see also</a>), like the hat (actually, exactly like an equilateral hat) but with no flipping required. It’s called the spectre. New preprint by Smith, Myers, Kaplan, and Goodman-Strauss.</p>
  </li>
  <li>
    <p><a href="https://gantry.io/blog/papers-to-know-20230110/">Supposedly practical application and deployment of cuckoo hashing in the TikTok recommendation system</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110459570741633679">\(\mathbb{M}\)</a>,</span> <a href="https://en.wikipedia.org/wiki/Special:Diff/1157764695">via</a>). For more, see “<a href="https://arxiv.org/abs/2209.07663">Monolith: Real time recommendation system with
collisionless embedding table</a>”, Liu et al. The cuckoo hashing is what makes this “collisionless”, and is used to map sparse feature data to something more dense.</p>
  </li>
  <li>
    <p>Interesting “near-miss” of two integer sequences <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@jsiehler/110429683229584306">\(\mathbb{M}\)</a>):</span> <a href="https://oeis.org/A000240">OEIS A000240</a>, counting permutations with one fixed point, and <a href="https://oeis.org/A182390">OEIS A182390</a>, generated by a recurrence involving XOR. The rencontres numbers (the first sequence) also have a similar recurrence, but with \(\pm\) in place of \(\oplus\), and some binary-representation coincidence causes them to be equal for surprisingly many terms.</p>
  </li>
</ul><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-31T18:49:00Z">Wednesday, May 31 2023, 18:49</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/'>Questions and Concerns About Google’s Quantum Supremacy Claim</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Yosi Rinott, Tomer Shoham, and I wrote our third paper regarding our statistical study of the Google 2019 supremacy experiment.&#160; Our paper presents statistical analysis that may shed light on the quality and reliability of the data and the statistical &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Yosi Rinott, Tomer Shoham, and I wrote our third paper regarding our statistical study of the Google 2019 supremacy experiment.&nbsp; Our paper presents statistical analysis that may shed light on the quality and reliability of the data and the statistical methods of the Google experiment. Comments, corrections and discussion are most welcome.</p>
<p>The title of the Google 2019 paper was &#8220;Quantum supremacy using a programmable superconducting processor&#8221;. As the readers may remember, the supremacy claim has largely been refuted by several research groups; see <a href="https://gilkalai.wordpress.com/2021/03/10/amazing-feng-pan-and-pan-zhang-announced-a-way-to-spoof-classically-simulate-the-googles-quantum-supremacy-circuit/">this post</a>, <a href="https://gilkalai.wordpress.com/2022/08/06/ordinary-computers-can-beat-googles-quantum-computer-after-all/">this one</a>, and <a href="https://gilkalai.wordpress.com/2022/10/25/remarkable-limitations-of-linear-cross-entropy-as-a-measure-for-quantum-advantage-by-xun-gao-marcin-kalinowski-chi-ning-chou-mikhail-d-lukin-boaz-barak-and-soonwon-choi/">this one</a>. The calibration process of the Google experiment weakens the claim of a “programmable processor”, and some of our findings from the second paper as well as a few of the findings from the new paper further weaken this claim (see below).</p>
<h3 style="text-align: center"><a href="https://arxiv.org/abs/2305.01064">Questions and Concerns About Google’s Quantum Supremacy Claim</a></h3>
<blockquote><p><em><strong>Abstract:</strong>&nbsp; <span dir="ltr" role="presentation">In October 2019,</span> <span dir="ltr" role="presentation">Nature</span> <span dir="ltr" role="presentation">published a paper <a href="https://www.nature.com/articles/s41586-019-1666-5">[5]</a> describing an ex</span><span dir="ltr" role="presentation">perimental work that was performed at Google.</span> <span dir="ltr" role="presentation">The paper claims </span><span dir="ltr" role="presentation">to demonstrate quantum (computational) supremacy on a 53-qubit </span><span dir="ltr" role="presentation">quantum computer. Since then we have been involved in a long-term </span><span dir="ltr" role="presentation">project to study various statistical aspects of the Google experiment.</span></em></p>
<p><em><span dir="ltr" role="presentation">In <a href="https://gilkalai.files.wordpress.com/2022/08/sts836.pdf">[32]</a> we studied Google’s statistical framework that we found to be </span><span dir="ltr" role="presentation">very sound and offered some technical improvements. This document </span><span dir="ltr" role="presentation">describes three main concerns (based on statistical analysis) about </span><span dir="ltr" role="presentation">the Google 2019 experiment.</span> <span dir="ltr" role="presentation">The first concern is that the data do </span><span dir="ltr" role="presentation">not agree with Google’s noise model (or any other specific model). </span><span dir="ltr" role="presentation">The second concern is that a crucial formula for a priori estimation of </span><span dir="ltr" role="presentation">the fidelity is surprisingly simple and seems to involve an unexpected </span><span dir="ltr" role="presentation">independence assumption, and yet it gives very accurate predictions. </span><span dir="ltr" role="presentation">The third concern is about surprising statistical properties of the cal</span><span dir="ltr" role="presentation">ibration process</span></em></p></blockquote>
<h2>Some findings of this paper</h2>
<p>1. There is a large gap between the samples of the Google experiment and the Google noise mode, and any other specific noise model. The gap between the empirical distribution and the model is asymmetric.</p>
<p>2. There are large fluctuations of the empirical behavior which are not understood. Consequently, there is evidence that the distance between the Google noise model and uniform distribution is smaller (when the number of qubits is n &gt; 16) than the distance between the experimental samples and the Google noise model.</p>
<p>3. The empirical behavior of the samples is not stationary.</p>
<p>4. While the empirical distribution is not stationary the XEB fidelity is stable along the samples. Moreover, “high energy events” that lead to abrupt increase in errors that are reported for later experiments with the Sycamore quantum computer cannot be detected in the 2019 quantum supremacy experiment.</p>
<p>5. The predictive power of Formula (77) for the XEB fidelity estimates is statistically surprising: the subsumed independence between components of systems such as quantum computers, which are known to be sensitive to noise and errors caused by interactions with their environment, is striking.</p>
<p>6. The systematic bias of the predictions of Formula (77) for patch circuits seems statistically surprising, and the Google explanation is not convincing.</p>
<p>7. The behavior of the fidelities of the two patches for patch circuits is very different; This appears to be in tension with Formula (77). ( We were not yet provided with the data needed to check this matter.)</p>
<p>8. The success of the experiments fully depends on the very large effect of the calibration adjustments. There are large differences between the effects of the calibration adjustments for different 2-gates, and even for different appearances of the same 2-gate.</p>
<p>9. The calibration adjustments are surprisingly effective, especially given the stated local nature of the calibration. Mathematically speaking, we witness a local optimization process reaching a critical point of a function depending on hundreds of parameters.</p>
<h2><span style="color: #0000ff">A few problems of general interest</span></h2>
<p>Scrutinizing a scientific work necessarily involves punctiliousness and nitpicking, but there are several issues that we find of general interest.</p>
<p><span style="color: #0000ff">(a) What is the statistical methodology for analyzing samples obtained from noisy quantum computers and for finding appropriate models to describe the empirical data?</span></p>
<p><span style="color: #0000ff">(b) We suggest that the statistical independence assumption in a certain predictive model is very surprising. What could be the scientific framework and methodology to study this matter?</span></p>
<p><span style="color: #0000ff">(c) We find it surprising that a local optimization process (namely, a process that separately optimizes each variable) of a function of many variables, reaches a critical point. What could be further tools to study this matter?</span></p>
<p><span style="color: #0000ff">(d) What are the tools to study if an empirical behavior is non-stationary and perhaps even inherently unpredictable?</span></p>
<p><span style="color: #0000ff">(e) What is the appropriate methodology and ethics for scrutinizing major scientific works, and how is it possible to bridge the gap between theoreticians (like us) and experimentalists?</span></p>
<h2>What&#8217;s next</h2>
<p>We are in the process of&nbsp; writing a paper on readout errors, gate errors, and Fourier expansion. On the theoretical side, we will study the effect of gate errors on the Fourier expansion, which is of interest in and of itself and could serve as some sanity test for various aspects of the Google 2019 experiment. (The effect of readout errors is well understood &#8211; it is essentially the noise operator that I have been studying extensively since the mid-1980s.) On the technical side, this will be our first work where we use simulators for noisy quantum circuits, and we currently use both the Google and the IBM simulators. Then, we may apply some of our statistical tools at other NISQ experiments, and will even try to reproduce, using an IBM quantum computer, a certain random circuit experiment with 6 qubits.</p>
<h2>Pictorial Summary</h2>
<h3>Concern I</h3>
<p>There is a large gap between the samples of the Google quantum supremacy experiments and the Google noise model. In fact, the samples are far away from any noise model we are aware of. There is evidence that the distance between the Google noise model and uniform distribution is smaller (when<br />
the number of qubits is n &gt; 16) than the distance between the experimental samples and the Google noise model. We studied other properties of the empirical distribution like its behavior in different scales, its non-stationary nature, and its Fourier behavior, and there is more to be done mainly for data coming from other NISQ experiments and data from simulators of noisy circuits.</p>
<p><a href="https://gilkalai.files.wordpress.com/2023/05/fig2-kts2.jpg"><img data-attachment-id="24445" data-permalink="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/fig2-kts2/" data-orig-file="https://gilkalai.files.wordpress.com/2023/05/fig2-kts2.jpg" data-orig-size="1367,599" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Fig2-KTS2" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/05/fig2-kts2.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/05/fig2-kts2.jpg?w=640" class="alignnone size-full wp-image-24445" src="https://gilkalai.files.wordpress.com/2023/05/fig2-kts2.jpg?w=640" alt="Fig2-KTS2" srcset="https://gilkalai.files.wordpress.com/2023/05/fig2-kts2.jpg?w=640 640w, https://gilkalai.files.wordpress.com/2023/05/fig2-kts2.jpg?w=1278 1278w, https://gilkalai.files.wordpress.com/2023/05/fig2-kts2.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2023/05/fig2-kts2.jpg?w=300 300w, https://gilkalai.files.wordpress.com/2023/05/fig2-kts2.jpg?w=768 768w, https://gilkalai.files.wordpress.com/2023/05/fig2-kts2.jpg?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"  ></a></p>
<h3><span style="color: #ff0000"><span dir="ltr" role="presentation">The left-hand side scatterplots display theoretical vs.</span> <span dir="ltr" role="presentation">empirical </span><span dir="ltr" role="presentation">frequencies of the Google sample (file 0) with</span> <span dir="ltr" role="presentation">n</span> <span dir="ltr" role="presentation">= 12. The right-hand side </span><span dir="ltr" role="presentation">scatterplots display theoretical vs.</span> <span dir="ltr" role="presentation">our simulated empirical frequencies ac</span><span dir="ltr" role="presentation">cording to Google’s noise model (1) with</span> <span dir="ltr" role="presentation">φ</span> <span dir="ltr" role="presentation">= 0</span><span dir="ltr" role="presentation">.</span><span dir="ltr" role="presentation">3701.</span></span></h3>
<h3></h3>
<h3>Concern II</h3>
<p>The remarkable predictive power of Formula (77) is statistically surprising: the subsumed independence between components of the quantum computer, is striking. The close agreement of the experimental XEB fidelities between the patch circuits and full circuits shows an unexplained systematic deviation from the predictions of Formula (77). On the other hand, confirmations [13, 23] and replications [33, 35] lend support to the claims in the Google paper. There are various matters that remain to be explored. For example, (i) using simulations of noisy circuits, the magnitude of the difference between the two sides of Formula (77) (Gao et al. [11]) could be estimated, and (ii) the individual values in Formula (77) could be used to study the different XEB fidelities of the two patches in patch circuits.</p>
<p><a href="https://gilkalai.files.wordpress.com/2023/05/fig9-krs.jpg"><img data-attachment-id="24447" data-permalink="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/fig9-krs/" data-orig-file="https://gilkalai.files.wordpress.com/2023/05/fig9-krs.jpg" data-orig-size="1696,835" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="FIG9-KRS" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/05/fig9-krs.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/05/fig9-krs.jpg?w=640" class="alignnone size-full wp-image-24447" src="https://gilkalai.files.wordpress.com/2023/05/fig9-krs.jpg?w=640" alt="FIG9-KRS" srcset="https://gilkalai.files.wordpress.com/2023/05/fig9-krs.jpg?w=640 640w, https://gilkalai.files.wordpress.com/2023/05/fig9-krs.jpg?w=1280 1280w, https://gilkalai.files.wordpress.com/2023/05/fig9-krs.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2023/05/fig9-krs.jpg?w=300 300w, https://gilkalai.files.wordpress.com/2023/05/fig9-krs.jpg?w=768 768w, https://gilkalai.files.wordpress.com/2023/05/fig9-krs.jpg?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"  ></a></p>
<h3><span style="color: #ff0000"><span dir="ltr" role="presentation"><strong>The striking prediction power of Formula (77):</strong> Comparison between average XEB fidelity for full, elided, and </span><span dir="ltr" role="presentation">patch circuits with (77).</span></span></h3>
<h3>Concern III</h3>
<p>The calibration process accounts for systematic errors for 2-gates and applies certain adjustments to the definition of the circuits. These adjustments are local, namely the adjustments for a 2-gate involving qubits x and y primarily depend on outcomes for 1- and 2-circuits on these qubits. Some statistical findings regarding the calibration process are: (i) The effects of the calibration is large even for a single 2-gate; (ii) there is a large difference between the effect for different 2-gates and even different appearances of the same 2-gate, and; (iii) the effectiveness of the 2-gate calibrations is remarkable. We note that these findings enhance the tension between the calibration process and Google’s claim for a “programmable quantum computer.” The effectiveness of the calibration process is especially surprising in view of the local nature of the calibration: mathematically speaking, we witness a local optimization process reaching a critical point of a function depending on hundreds of parameters.</p>
<h2><a href="https://gilkalai.files.wordpress.com/2023/04/caliba.png"><img data-attachment-id="24164" data-permalink="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/caliba/" data-orig-file="https://gilkalai.files.wordpress.com/2023/04/caliba.png" data-orig-size="1842,712" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="calibA" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/04/caliba.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/04/caliba.png?w=640" class="alignnone size-full wp-image-24164" src="https://gilkalai.files.wordpress.com/2023/04/caliba.png?w=640" alt="calibA" srcset="https://gilkalai.files.wordpress.com/2023/04/caliba.png?w=640 640w, https://gilkalai.files.wordpress.com/2023/04/caliba.png?w=1278 1278w, https://gilkalai.files.wordpress.com/2023/04/caliba.png?w=150 150w, https://gilkalai.files.wordpress.com/2023/04/caliba.png?w=300 300w, https://gilkalai.files.wordpress.com/2023/04/caliba.png?w=768 768w, https://gilkalai.files.wordpress.com/2023/04/caliba.png?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"  ></a></h2>
<p><span style="color: #ff0000"><strong>The remarkable effectiveness of the calibration.</strong> The effect of removing the calibration for the kth 2-gate of a circuit for the first Google file (file 0) with n = 12. Note that the same 2-gate occurs periodically along the circuit, indicated by the vertical black dashed lines. Here we remove all ingredients of the calibration: both the 1-gate rotations and 2-gate adjustments.</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2023/04/calibb.png"><img src="https://gilkalai.files.wordpress.com/2023/04/calibb.png?w=640" alt="calibB"></a></p>
<p><span style="color: #ff0000"><strong>The remarkable effectiveness of the calibration II.</strong> The effect of removing the 2-gate adjustments involving the kth 2-gate of a circuit. (The same 2-gate occurs periodically along the circuit.) The 2-gate involving the qubits (3,3) and (3,4) has consistently large effect.</span></p>
<p><span style="color: #0000ff"><span dir="ltr" role="presentation">To make matters clear, the calibration is not about tightening the screws </span><span dir="ltr" role="presentation">in Sycamore; rather, it is about change in the program. We can think about </span><span dir="ltr" role="presentation">the calibration process as a change in the model that would greatly reduce </span><span dir="ltr" role="presentation">certain systematic forms of noise. For example, if we discovered that a certain </span><span dir="ltr" role="presentation">1-gate that is supposed to apply a 90-degree rotation systematically performs </span><span dir="ltr" role="presentation">an 80-degree rotation, rather than changing the engineering of the 1-gate, we </span><span dir="ltr" role="presentation">would change the definition of the circuit.</span></span></p>
<h2>(no) Conclusion</h2>
<p><span style="color: #000000">&#8220;We laid the dry facts and findings, and we let the readers make their own interpretation, or rather take note of our concerns and wait for more experimental data from future experiments.&#8221;</span></p>
<h2>Was the Google experiment a &#8220;Programmable quantum computer?&#8221;</h2>
<p>The title of the Google 2019 paper was &#8220;Quantum supremacy using a programmable superconducting processor&#8221;. As we mentioned, the supremacy claim has largely (but not fully) been refuted. There are also doubts regarding the claim that the Sycamore 2019 experiment represents a &#8220;programmable processor&#8221; as the calibration process and other matters weaken this. (This was pointed out in a comment from October 2019 by <a href="https://scottaaronson.blog/?p=4372#comment-1822373">Craig Gidney</a> from the Google team and also a few months later by a commentator <a href="https://scottaaronson.blog/?p=5159#comment-1869118">&#8220;Till&#8221;</a> . Till&#8217;s comment led to interesting discussion regarding the nature of the calibration, which was earlier believed by many to represent physical changes in the device.)</p>
<p>Some findings of our papers further weaken the Google claim for &#8220;programmable device&#8221;. The Google paper describes about 1000 experiments on various circuits but, as it turns out, all these experiments depend on the random choices made for the largest ten circuits, and this fact is also in contrast with the &#8220;programmable&#8221; claim.&nbsp; (It was quite possible to choose a different random circuit in every case.) A related concern is that improvements of the calibration process were interlaced with the experiment, and that the last minute calibration procedure for the EFGH circuits represented a substantial improvement.&nbsp; We note that while the general principles of the calibration process are publicly available, the precise details are a commercial secret. Of course, concerns regarding the Google calibration process may reflect on other Sycamore experiments.</p>
<h2>Our earlier papers</h2>
<p>We wrote two earlier papers:</p>
<ol>
<li>Y. Rinott, T. Shoham, and G. Kalai, <a href="https://gilkalai.files.wordpress.com/2022/08/sts836.pdf">Statistical Aspects of the Quantum Supremacy Demonstration,</a>&nbsp;Statistical Science&nbsp; (2022)</li>
<li><span style="color: initial">G. Kalai, Y. Rinott and T. Shoham, </span><a href="https://gilkalai.files.wordpress.com/2022/10/cc22a19.pdf"><span dir="ltr" role="presentation">Google’s 2019 “Quantum Supremacy” Claims:&nbsp;</span><span dir="ltr" role="presentation">Data, Documentation, &amp; Discussion</span></a>&nbsp; (see <a href="https://gilkalai.wordpress.com/2022/10/07/the-google-supremacy-experiment-data-information-discussions-and-three-questions/">this post</a>.)</li>
</ol>
<h2>Data</h2>
<p>The question of appropriate methodology,&nbsp; ethics, and culture for scrutinizing major scientific works is related to the replication crisis that we mentioned in <a href="https://gilkalai.wordpress.com/2023/05/30/physics-related-news-israel-joining-cern-pugwash-and-global-zero-the-replication-crisis-and-max-the-damon/">an earlier post</a>. There we described our policy regarding data requests. Our experience was overall rather positive. (Things went rather slowly but we were slow as well.) We still did not get the individual terms of Formula (77) (namely, the error rate for individual 1-gates and 2-gates) but the Google team promised to try to push toward getting this information.</p>
<h2>Disclaimer</h2>
<p><span dir="ltr" role="presentation">(From our paper:) &#8220;A few months after the publication of the Google paper we initiated what has </span><span dir="ltr" role="presentation">become a long-term project to study various statistical aspects of the Google </span><span dir="ltr" role="presentation">experiment and to scrutinize the Google paper.</span> <span dir="ltr" role="presentation">This is a good place to </span><span dir="ltr" role="presentation">mention that Google’s quantum supremacy claim appeared to refute Kalai’s </span><span dir="ltr" role="presentation">theory regarding quantum computation ([15, 16, 18]) and Kalai’s specific pre</span><span dir="ltr" role="presentation">diction that NISQ systems cannot demonstrate `quantum supremacy.&#8217; This </span><span style="color: initial">fact influenced and may have biased Kalai’s assessment of Google’s quan</span><span dir="ltr" role="presentation">tum supremacy claim.</span> <span dir="ltr" role="presentation">(Recent improved classical algorithms have largely </span><span dir="ltr" role="presentation">refuted Google’s quantum supremacy claim and therefore the Google results </span><span dir="ltr" role="presentation">no longer refute Kalai’s theory.)&#8221;</span></p>
<p>For my argument see <a href="https://gilkalai.wordpress.com/2020/12/29/the-argument-against-quantum-computers-a-very-short-introduction/">this post</a> and <a href="https://gilkalai.wordpress.com/2022/11/05/inaugural-address-at-the-hungarian-academy-of-science-the-quantum-computer-a-miracle-or-mirage/">this one</a>.</p>
<h2>A few more figures</h2>
<h2><a href="https://gilkalai.files.wordpress.com/2023/05/fig5-kts2.jpg"><img data-attachment-id="24453" data-permalink="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/fig5-kts2/" data-orig-file="https://gilkalai.files.wordpress.com/2023/05/fig5-kts2.jpg" data-orig-size="1722,642" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Fig5-KTS2" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/05/fig5-kts2.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/05/fig5-kts2.jpg?w=640" class="alignnone size-full wp-image-24453" src="https://gilkalai.files.wordpress.com/2023/05/fig5-kts2.jpg?w=640" alt="Fig5-KTS2" srcset="https://gilkalai.files.wordpress.com/2023/05/fig5-kts2.jpg?w=640 640w, https://gilkalai.files.wordpress.com/2023/05/fig5-kts2.jpg?w=1280 1280w, https://gilkalai.files.wordpress.com/2023/05/fig5-kts2.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2023/05/fig5-kts2.jpg?w=300 300w, https://gilkalai.files.wordpress.com/2023/05/fig5-kts2.jpg?w=768 768w, https://gilkalai.files.wordpress.com/2023/05/fig5-kts2.jpg?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"  ></a></h2>
<p>Zooming in on the empirical frequency of bitstrings with amplitudes between the median and the 0.55 quantile. The left plot is the empirical occurrences of the bitstrings in Google file 0, n=12. The right plot is based on a simulation with φ = 0.3862. The red line describes the expected number of bitstrings of the Google noise model, and the blue dashed line is 3 standard deviations from the expectation. (We plan to test if these fluctuations are present in samples from IBM quantum computers.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2023/05/fig6-krs.jpg"><img data-attachment-id="24454" data-permalink="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/fig6-krs/" data-orig-file="https://gilkalai.files.wordpress.com/2023/05/fig6-krs.jpg" data-orig-size="1639,628" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="FIG6-KRS" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/05/fig6-krs.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/05/fig6-krs.jpg?w=640" class="alignnone size-full wp-image-24454" src="https://gilkalai.files.wordpress.com/2023/05/fig6-krs.jpg?w=640" alt="FIG6-KRS" srcset="https://gilkalai.files.wordpress.com/2023/05/fig6-krs.jpg?w=640 640w, https://gilkalai.files.wordpress.com/2023/05/fig6-krs.jpg?w=1280 1280w, https://gilkalai.files.wordpress.com/2023/05/fig6-krs.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2023/05/fig6-krs.jpg?w=300 300w, https://gilkalai.files.wordpress.com/2023/05/fig6-krs.jpg?w=768 768w, https://gilkalai.files.wordpress.com/2023/05/fig6-krs.jpg?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"  ></a> Comparing the two halves of the Google samples: the black vertical lines are the ℓ1 distance of the occurrences of bitstrings when we partition the samples into two halves according to the sampling order. The histograms give the ℓ1 distances between the occurrences of bitstrings for random partitions of the bitstrings into two halves.&nbsp; <a href="https://gilkalai.files.wordpress.com/2023/05/fig7-krs.jpg"><img data-attachment-id="24455" data-permalink="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/fig7-krs/" data-orig-file="https://gilkalai.files.wordpress.com/2023/05/fig7-krs.jpg" data-orig-size="1691,638" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="FIG7-KRS" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/05/fig7-krs.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/05/fig7-krs.jpg?w=640" class="alignnone size-full wp-image-24455" src="https://gilkalai.files.wordpress.com/2023/05/fig7-krs.jpg?w=640" alt="FIG7-KRS" srcset="https://gilkalai.files.wordpress.com/2023/05/fig7-krs.jpg?w=640 640w, https://gilkalai.files.wordpress.com/2023/05/fig7-krs.jpg?w=1278 1278w, https://gilkalai.files.wordpress.com/2023/05/fig7-krs.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2023/05/fig7-krs.jpg?w=300 300w, https://gilkalai.files.wordpress.com/2023/05/fig7-krs.jpg?w=768 768w, https://gilkalai.files.wordpress.com/2023/05/fig7-krs.jpg?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"  ></a> Drifts in the fractions of ones. We divided the 500,000 bitstrings into 250 groups of 2,000 bitstrings each, according to the sampling order. For each group calculated the fraction of bitstring having a “1” bit in some place in the bitstring. The Figure shows the fractions of ones in locations 11 and 12 for one circuit (file 0) with n = 12. (The red lines are linear regression fits to the data points.) The trend is consistent along the different circuits and is different for different locations in the bitstrings. <a href="https://gilkalai.files.wordpress.com/2023/05/fig8-krs.jpg"><img data-attachment-id="24457" data-permalink="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/fig8-krs/" data-orig-file="https://gilkalai.files.wordpress.com/2023/05/fig8-krs.jpg" data-orig-size="1703,819" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="FIG8-KRS" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/05/fig8-krs.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/05/fig8-krs.jpg?w=640" class="alignnone size-full wp-image-24457" src="https://gilkalai.files.wordpress.com/2023/05/fig8-krs.jpg?w=640" alt="FIG8-KRS" srcset="https://gilkalai.files.wordpress.com/2023/05/fig8-krs.jpg?w=640 640w, https://gilkalai.files.wordpress.com/2023/05/fig8-krs.jpg?w=1280 1280w, https://gilkalai.files.wordpress.com/2023/05/fig8-krs.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2023/05/fig8-krs.jpg?w=300 300w, https://gilkalai.files.wordpress.com/2023/05/fig8-krs.jpg?w=768 768w, https://gilkalai.files.wordpress.com/2023/05/fig8-krs.jpg?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"  ></a></p>
<p>A histogram of differences between the empirical distribution and the values given by the Google noise model, n = 12, Google file 0, φ = 0.3701. What can explain the apparent asymmetry in the gaps between the empirical distribution and the model? Is an explanation at all necessary?</p>
<p><a href="https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg"><img data-attachment-id="24458" data-permalink="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/table3-krs/" data-orig-file="https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg" data-orig-size="1395,897" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Table3-KRS" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg?w=640" class="alignnone size-full wp-image-24458" src="https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg?w=640" alt="Table3-KRS" srcset="https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg?w=640 640w, https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg?w=1280 1280w, https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg?w=300 300w, https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg?w=768 768w, https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"  ></a></p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-31T17:36:59Z">Wednesday, May 31 2023, 17:36</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/05/31/postdoc-at-warwick-apply-by-june-25-2023-at-university-of-warwick-apply-by-june-25-2023/'>Postdoc at Warwick (apply by June 25, 2023) at University of Warwick (apply by June 25, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A postdoc position in algebraic/geometric complexity theory at the University of Warwick, under the supervision of Christian Ikenmeyer, is available. Listed as &#8220;Research Fellow (107507-0523)&#8221; on Warwick&#8217;s website. Website: atsv7.wcn.co.uk/search_engine/jobs.cgi?SID=amNvZGU9MTg5MTIyMCZ2dF90ZW1wbGF0ZT0xNDU3Jm93bmVyPTUwNjI0NTImb3duZXJ0eXBlPWZhaXImYnJhbmRfaWQ9MCZ2YWNfeHRyYTUwNjI0NTIuNTJfNTA2MjQ1Mj0yMzk5MjEmcG9zdGluZ19jb2RlPTYzNQ== Email: christian.ikenmeyer@warwick.ac.uk
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>A postdoc position in algebraic/geometric complexity theory at the University of Warwick, under the supervision of Christian Ikenmeyer, is available. Listed as &#8220;Research Fellow (107507-0523)&#8221; on Warwick&#8217;s website.</p>
<p>Website: <a href="https://atsv7.wcn.co.uk/search_engine/jobs.cgi?SID=amNvZGU9MTg5MTIyMCZ2dF90ZW1wbGF0ZT0xNDU3Jm93bmVyPTUwNjI0NTImb3duZXJ0eXBlPWZhaXImYnJhbmRfaWQ9MCZ2YWNfeHRyYTUwNjI0NTIuNTJfNTA2MjQ1Mj0yMzk5MjEmcG9zdGluZ19jb2RlPTYzNQ==">https://atsv7.wcn.co.uk/search_engine/jobs.cgi?SID=amNvZGU9MTg5MTIyMCZ2dF90ZW1wbGF0ZT0xNDU3Jm93bmVyPTUwNjI0NTImb3duZXJ0eXBlPWZhaXImYnJhbmRfaWQ9MCZ2YWNfeHRyYTUwNjI0NTIuNTJfNTA2MjQ1Mj0yMzk5MjEmcG9zdGluZ19jb2RlPTYzNQ==</a><br />
Email: christian.ikenmeyer@warwick.ac.uk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-31T11:12:58Z">Wednesday, May 31 2023, 11:12</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.18514'>Polynomial-time classical sampling of high-temperature quantum Gibbs states</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chao Yin, Andrew Lucas</p><p>The computational complexity of simulating quantum many-body systems
generally scales exponentially with the number of particles. This enormous
computational cost prohibits first principles simulations of many important
problems throughout science, ranging from simulating quantum chemistry to
discovering the thermodynamic phase diagram of quantum materials or
high-density neutron stars. We present a classical algorithm that samples from
a high-temperature quantum Gibbs state in a computational (product state)
basis. The runtime grows polynomially with the number of particles, while error
vanishes polynomially. This algorithm provides an alternative strategy to
existing quantum Monte Carlo methods for overcoming the sign problem. Our
result implies that measurement-based quantum computation on a Gibbs state can
provide exponential speed up only at sufficiently low temperature, and further
constrains what tasks can be exponentially faster on quantum computers.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Yin_C/0/1/0/all/0/1">Chao Yin</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Lucas_A/0/1/0/all/0/1">Andrew Lucas</a></p><p>The computational complexity of simulating quantum many-body systems
generally scales exponentially with the number of particles. This enormous
computational cost prohibits first principles simulations of many important
problems throughout science, ranging from simulating quantum chemistry to
discovering the thermodynamic phase diagram of quantum materials or
high-density neutron stars. We present a classical algorithm that samples from
a high-temperature quantum Gibbs state in a computational (product state)
basis. The runtime grows polynomially with the number of particles, while error
vanishes polynomially. This algorithm provides an alternative strategy to
existing quantum Monte Carlo methods for overcoming the sign problem. Our
result implies that measurement-based quantum computation on a Gibbs state can
provide exponential speed up only at sufficiently low temperature, and further
constrains what tasks can be exponentially faster on quantum computers.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-31T00:30:00Z">Wednesday, May 31 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.18356'>RT-kNNS Unbound: Using RT Cores to Accelerate Unrestricted Neighbor Search</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vani Nagarajan, Durga Mandarapu, Milind Kulkarni</p><p>The problem of identifying the k-Nearest Neighbors (kNNS) of a point has
proven to be very useful both as a standalone application and as a subroutine
in larger applications. Given its far-reaching applicability in areas such as
machine learning and point clouds, extensive research has gone into leveraging
GPU acceleration to solve this problem. Recent work has shown that using Ray
Tracing cores in recent GPUs to accelerate kNNS is much more efficient compared
to traditional acceleration using shader cores. However, the existing
translation of kNNS to a ray tracing problem imposes a constraint on the search
space for neighbors. Due to this, we can only use RT cores to accelerate
fixed-radius kNNS, which requires the user to set a search radius a priori and
hence can miss neighbors. In this work, we propose TrueKNN, the first unbounded
RT-accelerated neighbor search. TrueKNN adopts an iterative approach where we
incrementally grow the search space until all points have found their k
neighbors. We show that our approach is orders of magnitude faster than
existing approaches and can even be used to accelerate fixed-radius neighbor
searches.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nagarajan_V/0/1/0/all/0/1">Vani Nagarajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandarapu_D/0/1/0/all/0/1">Durga Mandarapu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_M/0/1/0/all/0/1">Milind Kulkarni</a></p><p>The problem of identifying the k-Nearest Neighbors (kNNS) of a point has
proven to be very useful both as a standalone application and as a subroutine
in larger applications. Given its far-reaching applicability in areas such as
machine learning and point clouds, extensive research has gone into leveraging
GPU acceleration to solve this problem. Recent work has shown that using Ray
Tracing cores in recent GPUs to accelerate kNNS is much more efficient compared
to traditional acceleration using shader cores. However, the existing
translation of kNNS to a ray tracing problem imposes a constraint on the search
space for neighbors. Due to this, we can only use RT cores to accelerate
fixed-radius kNNS, which requires the user to set a search radius a priori and
hence can miss neighbors. In this work, we propose TrueKNN, the first unbounded
RT-accelerated neighbor search. TrueKNN adopts an iterative approach where we
incrementally grow the search space until all points have found their k
neighbors. We show that our approach is orders of magnitude faster than
existing approaches and can even be used to accelerate fixed-radius neighbor
searches.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-31T00:30:00Z">Wednesday, May 31 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.18519'>Quantum chi-squared tomography and mutual information testing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Steven T. Flammia, Ryan O&#x27;Donnell</p><p>For quantum state tomography on rank-$r$ dimension-$d$ states, we show that
$\widetilde{O}(r^{.5}d^{1.5}/\epsilon) \leq \widetilde{O}(d^2/\epsilon)$ copies
suffice for accuracy $\epsilon$ with respect to (Bures) $\chi^2$-divergence,
and $\widetilde{O}(rd/\epsilon)$ copies suffice for accuracy $\epsilon$ with
respect to quantum relative entropy. The best previous bound was
$\widetilde{O}(rd/\epsilon) \leq \widetilde{O}(d^2/\epsilon)$ with respect to
infidelity; our results are an improvement since \[ \text{infidelity} \leq
\text{relative entropy} \leq \text{$\chi^2$-divergence}.\] For algorithms that
are required to use single-copy measurements, we show that
$\widetilde{O}(r^{1.5} d^{1.5}/\epsilon) \leq \widetilde{O}(d^3/\epsilon)$
copies suffice for $\chi^2$-divergence, and $\widetilde{O}(r^{2} d/\epsilon)$
suffice for relative entropy.
</p>
<p>Using this tomography algorithm, we show that
$\widetilde{O}(d^{2.5}/\epsilon)$ copies of a $d\times d$-dimensional bipartite
state suffice to test if it has quantum mutual information 0 or at least
$\epsilon$. As a corollary, we also improve the best known sample complexity
for the classical version of mutual information testing to
$\widetilde{O}(d/\epsilon)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Flammia_S/0/1/0/all/0/1">Steven T. Flammia</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+ODonnell_R/0/1/0/all/0/1">Ryan O&#x27;Donnell</a></p><p>For quantum state tomography on rank-$r$ dimension-$d$ states, we show that
$\widetilde{O}(r^{.5}d^{1.5}/\epsilon) \leq \widetilde{O}(d^2/\epsilon)$ copies
suffice for accuracy $\epsilon$ with respect to (Bures) $\chi^2$-divergence,
and $\widetilde{O}(rd/\epsilon)$ copies suffice for accuracy $\epsilon$ with
respect to quantum relative entropy. The best previous bound was
$\widetilde{O}(rd/\epsilon) \leq \widetilde{O}(d^2/\epsilon)$ with respect to
infidelity; our results are an improvement since \[ \text{infidelity} \leq
\text{relative entropy} \leq \text{$\chi^2$-divergence}.\] For algorithms that
are required to use single-copy measurements, we show that
$\widetilde{O}(r^{1.5} d^{1.5}/\epsilon) \leq \widetilde{O}(d^3/\epsilon)$
copies suffice for $\chi^2$-divergence, and $\widetilde{O}(r^{2} d/\epsilon)$
suffice for relative entropy.
</p>
<p>Using this tomography algorithm, we show that
$\widetilde{O}(d^{2.5}/\epsilon)$ copies of a $d\times d$-dimensional bipartite
state suffice to test if it has quantum mutual information 0 or at least
$\epsilon$. As a corollary, we also improve the best known sample complexity
for the classical version of mutual information testing to
$\widetilde{O}(d/\epsilon)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-31T00:30:00Z">Wednesday, May 31 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
