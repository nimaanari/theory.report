<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-01-09T10:35:39Z">Monday, January 09 2023, 10:35</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, January 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02462'>Measuring a Priori Voting Power -- Taking Delegations Seriously</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rachael Colley, Th&#xe9;o Delemazure, Hugo Gilbert</p><p>In this paper, we introduce new power indices to measure the criticality of
voters involved in different elections where delegations play a key role,
namely, two variants of the proxy voting setting and a liquid democracy
setting. First, we argue that our power indices are natural extensions of the
Penrose-Banzhaf index in classic simple voting games, illustrating their
intuitions. We show that recursive formulas can compute these indices for
weighted voting games in pseudo-polynomial time. Last, we highlight theoretical
properties and provide numerical results to illustrate how introducing
delegation options modifies the voting power of voters.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Colley_R/0/1/0/all/0/1">Rachael Colley</a>, <a href="http://arxiv.org/find/cs/1/au:+Delemazure_T/0/1/0/all/0/1">Th&#xe9;o Delemazure</a>, <a href="http://arxiv.org/find/cs/1/au:+Gilbert_H/0/1/0/all/0/1">Hugo Gilbert</a></p><p>In this paper, we introduce new power indices to measure the criticality of
voters involved in different elections where delegations play a key role,
namely, two variants of the proxy voting setting and a liquid democracy
setting. First, we argue that our power indices are natural extensions of the
Penrose-Banzhaf index in classic simple voting games, illustrating their
intuitions. We show that recursive formulas can compute these indices for
weighted voting games in pseudo-polynomial time. Last, we highlight theoretical
properties and provide numerical results to illustrate how introducing
delegation options modifies the voting power of voters.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T01:30:00Z">Monday, January 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02616'>On the Width of the Regular $n$-Simplex</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sariel Har-Peled, Eliot W. Robson</p><p>Consider the regular $n$-simplex $\Delta_n$ - it is formed by the convex-hull
of $n+1$ points in Euclidean space, with each pair of points being in distance
exactly one from each other. We prove an exact bound on the width of $\Delta_n$
which is $\approx \sqrt{2/n}$. Specifically, $ \mathrm{width}(\Delta_n) =
\sqrt{\frac{2}{n + 1}}$ if $n$ is odd, and $ \mathrm{width}(\Delta_n) =
\sqrt{\frac{2(n+1)}{n(n+2)}} $ if $n$ is even. While this bound is well known
[GK92, Ale77], we provide a self-contained elementary proof that might (or
might not) be of interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Har_Peled_S/0/1/0/all/0/1">Sariel Har-Peled</a>, <a href="http://arxiv.org/find/cs/1/au:+Robson_E/0/1/0/all/0/1">Eliot W. Robson</a></p><p>Consider the regular $n$-simplex $\Delta_n$ - it is formed by the convex-hull
of $n+1$ points in Euclidean space, with each pair of points being in distance
exactly one from each other. We prove an exact bound on the width of $\Delta_n$
which is $\approx \sqrt{2/n}$. Specifically, $ \mathrm{width}(\Delta_n) =
\sqrt{\frac{2}{n + 1}}$ if $n$ is odd, and $ \mathrm{width}(\Delta_n) =
\sqrt{\frac{2(n+1)}{n(n+2)}} $ if $n$ is even. While this bound is well known
[GK92, Ale77], we provide a self-contained elementary proof that might (or
might not) be of interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T01:30:00Z">Monday, January 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02569'>Finding and Counting Patterns in Sparse Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Balagopal Komarath, Anant Kumar, Suchismita Mishra, Aditi Sethia</p><p>We consider algorithms for finding and counting small, fixed graphs in sparse
host graphs. In the non-sparse setting, the parameters treedepth and treewidth
play a crucial role in fast, constant-space and polynomial-space algorithms
respectively. We discover two new parameters that we call matched treedepth and
matched treewidth. We show that finding and counting patterns with low matched
treedepth and low matched treewidth can be done asymptotically faster than the
existing algorithms when the host graphs are sparse for many patterns. As an
application to finding and counting fixed-size patterns, we discover
$\otilde(m^3)$-time \footnote{$\otilde$ hides factors that are logarithmic in
the input size.}, constant-space algorithms for cycles of length at most $11$
and $\otilde(m^2)$-time, polynomial-space algorithms for paths of length at
most $10$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Komarath_B/0/1/0/all/0/1">Balagopal Komarath</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Anant Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Suchismita Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethia_A/0/1/0/all/0/1">Aditi Sethia</a></p><p>We consider algorithms for finding and counting small, fixed graphs in sparse
host graphs. In the non-sparse setting, the parameters treedepth and treewidth
play a crucial role in fast, constant-space and polynomial-space algorithms
respectively. We discover two new parameters that we call matched treedepth and
matched treewidth. We show that finding and counting patterns with low matched
treedepth and low matched treewidth can be done asymptotically faster than the
existing algorithms when the host graphs are sparse for many patterns. As an
application to finding and counting fixed-size patterns, we discover
$\otilde(m^3)$-time \footnote{$\otilde$ hides factors that are logarithmic in
the input size.}, constant-space algorithms for cycles of length at most $11$
and $\otilde(m^2)$-time, polynomial-space algorithms for paths of length at
most $10$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T01:30:00Z">Monday, January 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02457'>Better Differentially Private Approximate Histograms and Heavy Hitters using the Misra-Gries Sketch</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Christian Janos Lebeda, Jakub T&#x11b;tek</p><p>We consider the problem of computing differentially private approximate
histograms and heavy hitters in a stream of elements. In the non-private
setting, this is often done using the sketch of Misra and Gries [Science of
Computer Programming, 1982]. Chan, Li, Shi, and Xu [PETS 2012] describe a
differentially private version of the Misra-Gries sketch, but the amount of
noise it adds can be large and scales linearly with the size of the sketch: the
more accurate the sketch is, the more noise this approach has to add. We
present a better mechanism for releasing Misra-Gries sketch under
$(\varepsilon,\delta)$-differential privacy. It adds noise with magnitude
independent of the size of the sketch size, in fact, the maximum error coming
from the noise is the same as the best known in the private non-streaming
setting, up to a constant factor. Our mechanism is simple and likely to be
practical. We also give a simple post-processing step of the Misra-Gries sketch
that does not increase the worst-case error guarantee. It is sufficient to add
noise to this new sketch with less than twice the magnitude of the
non-streaming setting. This improves on the previous result for
$\varepsilon$-differential privacy where the noise scales linearly to the size
of the sketch.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lebeda_C/0/1/0/all/0/1">Christian Janos Lebeda</a>, <a href="http://arxiv.org/find/cs/1/au:+Tetek_J/0/1/0/all/0/1">Jakub T&#x11b;tek</a></p><p>We consider the problem of computing differentially private approximate
histograms and heavy hitters in a stream of elements. In the non-private
setting, this is often done using the sketch of Misra and Gries [Science of
Computer Programming, 1982]. Chan, Li, Shi, and Xu [PETS 2012] describe a
differentially private version of the Misra-Gries sketch, but the amount of
noise it adds can be large and scales linearly with the size of the sketch: the
more accurate the sketch is, the more noise this approach has to add. We
present a better mechanism for releasing Misra-Gries sketch under
$(\varepsilon,\delta)$-differential privacy. It adds noise with magnitude
independent of the size of the sketch size, in fact, the maximum error coming
from the noise is the same as the best known in the private non-streaming
setting, up to a constant factor. Our mechanism is simple and likely to be
practical. We also give a simple post-processing step of the Misra-Gries sketch
that does not increase the worst-case error guarantee. It is sufficient to add
noise to this new sketch with less than twice the magnitude of the
non-streaming setting. This improves on the previous result for
$\varepsilon$-differential privacy where the noise scales linearly to the size
of the sketch.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T01:30:00Z">Monday, January 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02507'>Perturbation results for distance-edge-monitoring numbers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chenxu Yang, Ralf Klasing, Changxiang He, Yaping Mao</p><p>Foucaud et al. recently introduced and initiated the study of a new
graph-theoretic concept in the area of network monitoring. Let $G=(V, E)$ be a
graph. A set of vertices $M \subseteq V(G)$ is a distance-edge-monitoring set
of $G$ if any edges in $G$ can be monitored by a vertex in $M$. The
distance-edge-monitoring number $\operatorname{dem}(G)$ is the minimum
cardinality of a distance-edge-monitoring set of $G$. In this paper, we first
show that $\operatorname{dem}(G\setminus e)- \operatorname{dem}(G)\leq 2$ for
any graph $G$ and edge $e \in E(G)$. Moreover, the bound is sharp. Next, we
construct two graphs $G$ and $H$ to show that
$\operatorname{dem}(G)-\operatorname{dem}(G-u)$ and
$\operatorname{dem}(H-v)-\operatorname{dem}(H)$ can be arbitrarily large, where
$u \in V(G)$ and $v \in V(H)$. We also study the relationship between
$\operatorname{dem}(H)$ and $\operatorname{dem}(G)$ for $H\subset G$. In the
end, we give an algorithm to judge whether the distance-edge-monitoring set
still remain in the resulting graph when any edge of a graph $G$ is deleted.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chenxu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Klasing_R/0/1/0/all/0/1">Ralf Klasing</a>, <a href="http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1">Changxiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yaping Mao</a></p><p>Foucaud et al. recently introduced and initiated the study of a new
graph-theoretic concept in the area of network monitoring. Let $G=(V, E)$ be a
graph. A set of vertices $M \subseteq V(G)$ is a distance-edge-monitoring set
of $G$ if any edges in $G$ can be monitored by a vertex in $M$. The
distance-edge-monitoring number $\operatorname{dem}(G)$ is the minimum
cardinality of a distance-edge-monitoring set of $G$. In this paper, we first
show that $\operatorname{dem}(G\setminus e)- \operatorname{dem}(G)\leq 2$ for
any graph $G$ and edge $e \in E(G)$. Moreover, the bound is sharp. Next, we
construct two graphs $G$ and $H$ to show that
$\operatorname{dem}(G)-\operatorname{dem}(G-u)$ and
$\operatorname{dem}(H-v)-\operatorname{dem}(H)$ can be arbitrarily large, where
$u \in V(G)$ and $v \in V(H)$. We also study the relationship between
$\operatorname{dem}(H)$ and $\operatorname{dem}(G)$ for $H\subset G$. In the
end, we give an algorithm to judge whether the distance-edge-monitoring set
still remain in the resulting graph when any edge of a graph $G$ is deleted.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T01:30:00Z">Monday, January 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, January 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/01/08/teaching-faculty-at-university-of-michigan-apply-by-january-22-2023/'>Teaching faculty at University of Michigan (apply by January 22, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Michigan CSE is hiring for multiple long-term, career-oriented teaching faculty positions. We are seeking passionate individuals to join our community of teaching-focused faculty, and who will support our teaching mission and further our goal of creating a diverse, inclusive, and representative Computer Science community within our department and in the field at large. Website: cse.umich.edu/cse/jobs/ [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Michigan CSE is hiring for multiple long-term, career-oriented teaching faculty positions. We are seeking passionate individuals to join our community of teaching-focused faculty, and who will support our teaching mission and further our goal of creating a diverse, inclusive, and representative Computer Science community within our department and in the field at large.</p>
<p>Website: <a href="https://cse.umich.edu/cse/jobs/">https://cse.umich.edu/cse/jobs/</a><br />
Email: awdeorio@umich.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-08T17:17:00Z">Sunday, January 08 2023, 17:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://decentralizedthoughts.github.io/2023-01-08-re-rand-cred/'>Pairing-based Anonymous Credentials and the Power of Re-randomization</a></h3>
        <p class='tr-article-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          David Chaum wrote in 1985: Large-scale automated transaction systems are imminent. The architecture chosen for these systems may have a long-term impact on the centralization of our economic system, on some of our basic liberties, and even on our democracy. The initial choice of direction will gather economic and societal...
        
        </div>

        <div class='tr-article-summary'>
        
          
          David Chaum wrote in 1985: Large-scale automated transaction systems are imminent. The architecture chosen for these systems may have a long-term impact on the centralization of our economic system, on some of our basic liberties, and even on our democracy. The initial choice of direction will gather economic and societal...
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-08T09:00:00Z">Sunday, January 08 2023, 09:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/002'>TR23-002 |  Diagonalization Games | 

	Noga Alon, 

	Olivier Bousquet, 

	Kasper Green Larsen, 

	Shay Moran, 

	Shlomo Moran</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study several variants of a combinatorial game which is based on Cantor&#39;s diagonal argument. The game is between two players called Kronecker and Cantor. The names of the players are motivated by the known fact  that Leopold Kronecker did not appreciate Georg Cantor&#39;s arguments about the infinite, and even referred to him as a ``scientific charlatan&#39;&#39;. 

In the game Kronecker maintains a list of m binary vectors, 
each of length n, and Cantor&#39;s goal is to produce a new binary vector which is different from each of Kronecker&#39;s vectors, or prove that no such vector exists. Cantor does not see Kronecker&#39;s vectors but he is allowed to ask queries of the form  ``What is bit number j of vector number i? What is the minimal number of queries with which Cantor can achieve his goal? How much better can Cantor do if he is allowed to pick his queries \emph{adaptively}, based on Kronecker&#39;s previous replies?

The case when m=n is solved by diagonalization using n (non-adaptive) queries. We study this game more generally, and prove an optimal bound in the adaptive case and nearly tight upper and lower bounds in the non-adaptive case.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study several variants of a combinatorial game which is based on Cantor&#39;s diagonal argument. The game is between two players called Kronecker and Cantor. The names of the players are motivated by the known fact  that Leopold Kronecker did not appreciate Georg Cantor&#39;s arguments about the infinite, and even referred to him as a ``scientific charlatan&#39;&#39;. 

In the game Kronecker maintains a list of m binary vectors, 
each of length n, and Cantor&#39;s goal is to produce a new binary vector which is different from each of Kronecker&#39;s vectors, or prove that no such vector exists. Cantor does not see Kronecker&#39;s vectors but he is allowed to ask queries of the form  ``What is bit number j of vector number i? What is the minimal number of queries with which Cantor can achieve his goal? How much better can Cantor do if he is allowed to pick his queries \emph{adaptively}, based on Kronecker&#39;s previous replies?

The case when m=n is solved by diagonalization using n (non-adaptive) queries. We study this game more generally, and prove an optimal bound in the adaptive case and nearly tight upper and lower bounds in the non-adaptive case.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-08T02:36:41Z">Sunday, January 08 2023, 02:36</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://minorfree.github.io/tree-shortcutting/'>Shortcutting Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://minorfree.github.io'>Hung Le</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Over the past two years or so, I have been thinking about a cute problem, which turned out to be much more useful to my research than I initially thought. Here it is: Tree Shortcutting Problem: Given an edge-weighted tree \(T\), add (weighted) edges to \(T\), called shortcuts, to get a graph \(K\) such that: \(d_K(u,v) = d_T(u,v)~\quad \forall u,v\in V(T)\). That is, \(K\) preserves distances in \(T\). For every \(u,v\in V(T)\), there exists a shortest path from \(u\) to \(v\) in \(K\) containing at most \(k\) edges for some \(k\geq 2\). The goal is to minimize the product \(k \cdot \mathrm{tw}(K)\), where \(\mathrm{tw}(K)\) is the treewidth of \(K\).
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Over the past two years or so, I have been thinking about a cute problem, which turned out to be much more useful to my research than I initially thought. Here it is:</p>

<hr />
<p><strong>Tree Shortcutting Problem</strong>: Given an edge-weighted tree \(T\), add (weighted) edges to \(T\), called <em>shortcuts</em>, to get a graph \(K\) such that:</p>
<ol>
  <li>\(d_K(u,v) = d_T(u,v)~\quad \forall u,v\in V(T)\). That is, \(K\) preserves distances in \(T\).</li>
  <li>For every \(u,v\in V(T)\), there exists a shortest path from \(u\) to \(v\) in \(K\) containing at most \(k\) edges for some \(k\geq 2\).</li>
</ol>

<p>The goal is to minimize the product \(k \cdot \mathrm{tw}(K)\), where \(\mathrm{tw}(K)\) is the treewidth of \(K\).</p>

<hr />

<p><img src="/assets/figs/shortcut.svg" alt="" /></p>

<p><em>Figure 1: An emulator \(K\) obtained by adding one edge to the tree \(T\) has hop bound \(3\) and treewidth \(2\). Compared to \(T\), the hop bound decreases by 1 while the treewidth increases by 1.</em></p>

<p>Such a graph \(K\) is called a <em>low-hop and low-treewidth emulator</em> of the tree \(T\).  The parameter \(k\) is called the <em>hop bound</em> of \(K\). It is expected that there will be some trade-off between the hop bound and the treewidth. We are interested in minimizing \(k \cdot \mathrm{tw}(K)\). This product directly affects parameters in our application; see the conclusion section for more details.</p>

<p>For readers who are not familar with treeewidth, see  <a href="https://en.wikipedia.org/wiki/Treewidth">here</a> and <a href="https://www.win.tue.nl/~nikhil/courses/2015/2WO08/treewidth-erickson.pdf">here</a> for an excellent introduction, and why treewidth is an interesting graph parameter.</p>

<blockquote>
  <p><strong>Remark 1:</strong> The tree shortcutting problem is already non-trivial for unweighted trees; the shortcuts must be weighted though. Furthermore, for each edge \((u,v)\) added to \(K\), the weight of the edge will be \(d_T(u,v)\). Thus, in the construction below, we do not explicitly assign weights to the added edges.</p>
</blockquote>

<p>A version of a tree shortcutting problem where one seeks to minimize <em>the number of edges of \(K\)</em>, given a hop bound \(k\), was studied extensively (see <a href="http://www.math.tau.ac.il/~haimk/adv-ds-2008/Alon-Schieber.ps">1</a>,<a href="https://dl.acm.org/doi/abs/10.5555/640186.640193">2</a>,<a href="https://arxiv.org/abs/1005.4155">3</a>,<a href="https://dl.acm.org/doi/10.1145/800070.802185">4</a>, including my own work <a href="https://arxiv.org/abs/2107.14221">with</a> <a href="https://arxiv.org/abs/2112.09124">others</a>), arising in the context of spanners and minimum spanning tree problem. What is interesting there IMO is that we see all kinds of crazy slowly growing functions in computer science: for \(k = 2\), the number of edges of \(K\) is \(\Theta(n \log n)\);  for \(k = 3\), the number of edges of \(K\) is \(\Theta(n \log\log n)\); for \(k = 4\), the number of edges is \(\Theta(n \log^* n)\); \(\ldots\) [too difficult to describe]; and for \(k = \alpha(n)\), the number of edges is   \(\Theta(n)\). Here, as you might guess, \(\alpha(\cdot)\) is the notorious (one parameter) inverse Ackermann function. (The \(\Theta\) notation in the number of edges means there exist matching lower bounds.) I hope to cover this problem in a future blog post.</p>

<p>Now back to our tree shortcutting problem. Let \(n = \lvert V(T) \rvert\). There are two extreme regimes that I am aware of:</p>

<ol>
  <li>Hop bound \(k=2\) and treewidth \(\mathrm{tw}(K) = O(\log n)\). This is a relatively simple exercise.</li>
  <li>Hop bound \(k=O(\log n)\) and treewidth \(\mathrm{tw}(K) = O(1)\). This regime is harder to prove; trying to show this for a path graph will be an insightful exercise. It follows from a well-known fact [1] that any tree decomposition of width \(t\) can be turned into a tree decomposition of width \(O(t)\) and depth \(O(\log n)\).</li>
</ol>

<p>The two regimes might suggest that a lower bound \(k\cdot \mathrm{tw}(K) = \Omega(\log n)\) for any \(k\). In our recent paper [2], we show that this is not the case:</p>

<hr />
<p><strong>Theorem 1</strong>: There exists an emulator \(K\) for any \(n\)-vertex tree \(T\) such that \(h(K) = O(\log  \log n)\) and \(\mathrm{tw}(K) = O(\log \log n)\).</p>

<hr />

<p>Theorem 1 implies that one can get an emulator with \(k\cdot \mathrm{tw}(K) = O((\log \log n)^2)\), which is exponentially smaller than \(O(\log(n))\). The goal of this post is to discuss the proof of Theorem 1. See the conclusion section for a more thorough discussion on other aspects of Theorem 1, in particular, the construction time and application.</p>

<p>For the tree shortcutting problem, it is often insightful to look into the <strong>path graph with \(n\) vertices</strong>, which is a special case. Once we solve the path graph, extending the ideas to trees is not that difficult.</p>

<h1 id="1-the-path-graph">1. The Path Graph</h1>

<p>The (unweighted )path graph \(P_n\) is a path of \(n\) vertices. To simplify the presentation, assume that \(\sqrt{n}\) is an integer. The construction is recursive and described in the pseudo-code below.  First we divide \(P_n\) into \(\sqrt{n}\) sub paths of size \(\sqrt{n}\) each. Denote the endpoints of these subpaths by \(b_i = i\sqrt{n}\) for \(1\leq i\leq\sqrt{n}\). We call \({b_i}_{i}\) boundary vertices.  We have two types of recursions: (1) top level recursion – lines 2 and 3 – and (2) subpath recursion – lines 5 to 9. The intuition of the top level recursion is a bit tricky and we will get to that later. See Figure 2.</p>

<p><img src="/assets/figs/recursion.svg" alt="" /></p>

<p><em>Figure 2: (a) The recursive construction applied to the path \(P_n\). (b) Gluing \(\mathcal T_B\) and all \(\{\mathcal T_i\}\) to obtain a tree decomposition \(\mathcal{T}\) of \(K\) via red edges.</em></p>

<p>The subpath recursion is natural: recursively shortcut each subpath \(P[b_i,b_{i+1}]\) (line 6). The subpath recursion returns the shortcut graph \(K_i\) and its tree decomposition \(\mathcal T_i\).  Next, we add edges from each boundary vertex \(b_i, b_{i+1}\) of the subpath to all other vertices on the subpath (lines 7 and 8). This step guarantees that each vertex of the subpath can “jump” to the boundary vertices using only <strong>one edge</strong>. In terms of tree decomposition, it means that we add both \(b_i\) and \(b_{i+1}\) to every bag of \(\mathcal T_i\) (line 9).</p>

<p>The top level recursion serves two purposes: (i) creating a low hop emulator  for boundary vertices (recall that each vertex can jump to a boundary vertex in the same subpath using one edge) and  (ii) gluing \({\mathcal T_i}\) together. More precisely, let \(P_{\sqrt{n}}\) be a path of boundary vertices, i.e., \(b_i\) is adjacent to \(b_{i+1}\) in  \(P_{\sqrt{n}}\). We shortcut \(P_{\sqrt{n}}\) recursively, getting the shortcut graph \(K_B\) and its tree decomposition \(\mathcal T_B\) (line 3). Since \((b_i,b_{i+1})\) is an edge in \(P_{\sqrt{n}}\), there must be a bag in \(\mathcal T_B\) containing both \(b_i,b_{i+1}\); that is, the bag \(X\) in line 11 exists. See Figure 2(b). Recall that in line 9, every bag in \(\mathcal T_i\) contains both \(b_i,b_{i+1}\), and that \(K_B\) and \(K_i\) only share two boundary vertices \(b_i,b_{i+1}\). Thus, we can connect \(X\) to an arbitrary bag of \(\mathcal T_i\) as done in line 12. This completes the shortcutting algorithm.</p>

<hr />
<p><span style="font-variant: small-caps">PathShortcutting</span>\((P_n)\)</p>
<blockquote>
  <p>\(1.\) \(B \leftarrow {0,\sqrt{n}, 2\sqrt{n}, \ldots, n}\) and \(b_i \leftarrow i\sqrt{n}\) for every \(0\leq i \leq \sqrt{n}\)<br />
\(2.\) \(P_{\sqrt{n}} \leftarrow\) unweighted path graph with vertex set \(B\).<br />
\(3.\) \((K_B,\mathcal T_B) \leftarrow\)<span style="font-variant: small-caps">PathShortcutting</span>\((P_{\sqrt{n}})\)<br />
\(4.\) \(K\leftarrow K_B,\quad \mathcal{T}\leftarrow \mathcal T_B\)<br />
\(5.\) for \(i\leftarrow 0\) to \(\sqrt{n}-1\)<br />
\(6.\)     \((K_i,\mathcal T_i) \leftarrow\)<span style="font-variant: small-caps">PathShortcutting</span>\((P_{n}[b_i, b_{i+1}])\)<br />
\(7.\)      for each \(v\in P_{n}[b_i, b_{i+1}]\)<br />
\(8.\)           \(E(K_i)\leftarrow {(v,b_i), (v,b_{i+1})}\) <br />
\(9.\)            add both \({v_i,v_{i+1}}\) to every bag of \(\mathcal T_i\)<br />
\(10.\)     \(K\leftarrow K \cup K_i\) <br />
\(11.\)     Let \(X\) be a bag in \(\mathcal{T}\) containing both \(b_i,b_{i+1}\)<br />
\(12.\)     Add \(\mathcal T_i\) to \(\mathcal{T}\) by connecting \(X\) to an arbitrary bag of \(\mathcal T_i\) <br />
\(13.\) return \((K,\mathcal{T})\)</p>
</blockquote>

<hr />

<p>It is not difficult to show that \(\mathcal{T}\) indeed is a tree decomposition of \(K\). Thus, we focus on analyzing the hop bound and the treewidth.</p>

<blockquote>
  <p><strong>Remark 2:</strong> For notational convenience, we include \(0\) in the set \(B\) though \(0\not\in P_n\). When calling the recursion, one could simply drop 0.</p>
</blockquote>

<p><img src="/assets/figs/hopbound.svg" alt="" /></p>

<p><em>Figure 3: A low-hop path from \(u\) to \(v\).</em></p>

<p><strong>Analyzing the hop bound \(h(K)\).</strong>   Let \(u\) and \(v\) be any two vertices of \(P_{n}\); w.l.o.g, assume that \(u \leq v\), and \(h(n)\) be the hop bound. Let \(b_{u}\) and \(b_v\) be two boundary vertices of the subpaths containing \(u\) and \(v\), respectively, such that \(b_u,b_v \in P[u,v]\). See Figure 3. As mentioned above, line 8 of the algorithms guarantees that there are two edges \((u,b_u)\) and \((b_v,v)\) in \(K\), and the top level recursion (line 3) guarantees that there is a shortest path of hop length  \(h(\sqrt{n})\) between \(b_u\) and \(b_v\) in \(K_B\). Thus we have:</p>

\[h(n) \leq h(\sqrt{n}) + 2\]

<p>which solves to \(h(n)= O(\log\log n)\).</p>

<p><strong>Analyzing the treewidth \(\mathrm{tw}(K)\).</strong> Note that the treewidth of   \(\mathcal T_B\) and all \({\mathcal{T_i}}\) (before adding boundary vertices in line 9) is bounded by \(\mathrm{tw}(\sqrt{n})\). Line 9 increases the treewidth of  \({\mathcal{T_i}}\) by at most \(2\). Since the treewidth of \(K\) is the maximum treewidth \(\mathcal T_B\) and all \({\mathcal{T_i}}\), we have:</p>

\[\mathrm{tw}(n) \leq \mathrm{tw}(\sqrt{n}) + 2\]

<p>which solves to \(\mathrm{tw}(n)= O(\log\log n)\).</p>

<p>This completes the proof of Theorem 1 for the path graph \(P_n\).</p>

<h1 id="2-trees">2. Trees</h1>

<p>What is needed to extend the construction of a path graph to a general tree? Two properties we exploited in the construction of \(P_n\):</p>

<ol>
  <li>\(P_n\) can be decomposed into \(\sqrt{n}\) (connected) subpaths.</li>
  <li>Each subpath in the decomposition has at most two boundary vertices.</li>
</ol>

<p>Property 2 implies that the total number of boundary vertices is about \(\sqrt{n}\), which plays a key role in analyzing the top level recursion.</p>

<p>It is well known that we can obtain a somewhat similar but weaker decomposition for trees: one can decompose a tree of \(n\) vertices to roughly \(\sqrt{n}\) connected subtrees such that the number of boundary vertices is \(\sqrt{n}\). (A vertex is a boundary vertex of a subtree if it is incident to an edge not in the subtree.) This decomposition is weaker in the sense that a subtree could have more than 2, and indeed up to \(\Omega(\sqrt{n})\), boundary vertices.  Is this enough?</p>

<p>Not quite. To glue the tree decomposition \(\mathcal T_i\) to \(\mathcal{T}\) (and effectively to \(\mathcal T_B\)), we rely on the fact that there is a bag \(X\in \mathcal T_B\) containing both boundary vertices in line 11. The  analogy for trees would be: there exists a bag \(X\) containing all boundary vertices of each subtree. This is problematic if a subtree has \(\Omega(\sqrt{n})\) boundary vertices.</p>

<p>Then how abound guaranteeing that each subtree has \(O(1)\) vertices, say 3 vertices. Will this be enough? The answer is pathetically no. To guarantee 3 vertices in the same bag, one has to add a clique of size 3 between the boundary vertices in the top level recursion. What it means is that, the graph between boundary vertices on which we recursively call the shortcuting procedure is <em>no longer a tree</em>. Thus, we really need a decomposition where every subtree has <strong>at most 2 boundary vertices</strong>.</p>

<hr />
<p><strong>Lemma 1:</strong> Let \(T\) be any tree of \(n\) vertices, one can decompose \(T\) into a collection \(\mathcal{D}\) of \(O(\sqrt{n})\) subtrees such that every tree \(T’\in \mathcal{D}\) has \(\lvert V(T’)\rvert \leq \sqrt{n}\) and at most 2 boundary vertices.</p>

<hr />

<p>Lemma 1 is all we need to prove Theorem 1, following exactly the same construction for the path graph \(P_n\); the details are left to readers.</p>

<blockquote>
  <p><strong>Remark 3:</strong> In developing our shortcutting tree result, we were unaware that Lemma 1 was already known in the literature. A reviewer later pointed out that one can get Lemma 1 from a weaker decomposition using <em>least common ancestor closure</em> [3], which I reproduce below.</p>
</blockquote>

<p><strong>Proof of Lemma 1:</strong> First, decompose \(T\) into a collection \(\mathcal{D}’\) of \(O(\sqrt{n})\) subtrees such that each tree in \(\mathcal{D}’\) has size at most \(\sqrt{n}\) and that the total number of boundary vertices is \(O(\sqrt{n})\). As mentioned above, this decomposition is well known; see Claim 1 in our paper [2] for a proof.</p>

<p>Let \(A_1\) be the set of boundary vertices; \(\lvert A_1\rvert = O(\sqrt{n})\). Root \(T\) at an arbitrary vertex. Let \(A_2\) be the set containing the ancestor of every pair of vertices in \(A_1\). Let \(B = A_1\cup A_2\).</p>

<p>It is not hard to see that \(\lvert A_2\rvert  \leq \lvert A_1\rvert - 1  = O(\sqrt{n})\). Thus, \(\lvert B\rvert = O(\sqrt{n})\). Furthermore, every connected component of \(T\setminus B\) has at most \(\sqrt{n}\) vertices and has edges to at most 2 vertices in \(B\). The set \(B\) induces a decomposition \(\mathcal{D}\) of \(T\) claimed in Lemma 1.</p>

<h1 id="3-conclusion">3. Conclusion</h1>

<p>The emulator in Theorem 1 can be constructed in time \(O(n \log \log n)\); see Theorem 10 our paper [2] for more details. The major open problem is:</p>

<p><strong>Open problem:</strong> Is \(O((\log \log n)^2)\) the best possible bound for the product \(\mathrm{tw}(K)\cdot h(K)\)?</p>

<p>This open problem is intimately connected to another problem: embedding  planar graphs of diameter \(D\) into low treewidth graphs with additive distortion at most \(+\epsilon D\) for any \(\epsilon \in (0,1)\). More precisely, though not explicitly stated [2], one of our main results is:</p>

<hr />
<p><strong>Theorem 2:</strong> If one can construct an emulator \(K\) of treewidth \(\mathrm{tw}(n)\) and hop bound \(h(n)\) for any tree of \(n\) vertices, then one can embed any planar graphs with \(n\) vertices and diameter \(D\) into  a graph of treewidth \(O(h(n)\cdot \mathrm{tw}(n)/\epsilon)\) and additive distortion \(+\epsilon D\) for any given \(\epsilon \in (0,1)\).</p>

<hr />

<p>That is, the product of treewdith and hop bound directly bounds the treewdith of the embedding. Theorem 1 give us an embedding with treewidth \(O((\log\log n)^2/\epsilon)\), which has various algorithmic applications [2]. My belief is that the bound \(O((\log \log n)^2)\) is the best possible.</p>

<h1 id="4-references">4. References</h1>

<p>[1] Bodlaender, H.L. and Hagerup, T. (1995). Parallel algorithms with optimal speedup for bounded treewidth. In ICALP ‘95, 268-279.</p>

<p>[2] Filtser, A. and Hung, L. (2022). Low Treewidth Embeddings of Planar and Minor-Free Metrics. ArXiv preprint <a href="https://arxiv.org/abs/2203.15627">arXiv:2203.15627</a>.</p>

<p>[3] Fomin, F.V., Lokshtanov, D., Saurabh, S. and Zehavi, M. (2019). Kernelization: theory of parameterized preprocessing. Cambridge University Press.</p><p class="authors">By Hung Le</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-08T00:00:00Z">Sunday, January 08 2023, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, January 06
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/'>Cargo Cult Redo</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Richard Feynman during his 1974 commencement address at the California Institute of Technology coined the term cargo cult science. The term was just used over at the blog of Scott Aaronson at Shtetl-Optimized. Read his post and skip the rest here if you will. Or read the rest here and then his post. As Wikipedia&#8217;s [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
Richard Feynman during his 1974 commencement address at the California Institute of Technology coined the term <a href="https://en.wikipedia.org/wiki/Cargo_cult_science">cargo cult science</a>. The term was just used over at the blog of Scott Aaronson at <a href="https://scottaaronson.blog">Shtetl-Optimized</a>. Read his post and skip the rest here if you will. Or read the rest here and then his post.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/rf/" rel="attachment wp-att-20780"><img data-attachment-id="20780" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/rf/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?fit=220%2C311&amp;ssl=1" data-orig-size="220,311" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rf" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?fit=212%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?fit=220%2C311&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?resize=169%2C169&#038;ssl=1" alt="" width="169" height="169" class="aligncenter size-full wp-image-20780" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 169px) 100vw, 169px" data-recalc-dims="1" /></a></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/sa/" rel="attachment wp-att-20786"><img data-attachment-id="20786" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/sa/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?fit=169%2C169&amp;ssl=1" data-orig-size="169,169" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sa" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?fit=169%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?fit=169%2C169&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?resize=169%2C169&#038;ssl=1" alt="" width="169" height="169" class="aligncenter size-full wp-image-20786" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?w=169&amp;ssl=1 169w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 169px) 100vw, 169px" data-recalc-dims="1" /></a></p>
<p><P></p>
<p>
As Wikipedia&#8217;s page says, cargo cults are religious practices that have appeared in many traditional tribal societies&#8212;often caused by interactions with technologically advanced cultures. Cargo cult <em>science</em>, as explained more pithily on <a href="https://coffeeandjunk.com/cargo-cult-science/">this page</a>, means following others&#8217; procedures uncritically and expecting the same results without having ascertained whether the needed conditions apply in your particular setting.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/plane-4/" rel="attachment wp-att-20800"><img data-attachment-id="20800" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/plane-4/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/plane-3.jpeg?fit=%2C&amp;ssl=1" data-orig-size="" data-comments-opened="1" data-image-meta="[]" data-image-title="plane" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/plane-3.jpeg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/plane-3.jpeg?fit=1024%2C1024&amp;ssl=1" decoding="async" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/plane-3.jpeg?w=600&#038;ssl=1" alt="" class="aligncenter size-full wp-image-20800" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Factoring is Hard? </H2></p>
<p><p>
Factoring large numbers is the key to the security of the famous <a href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)">RSA</a> method. The 2048-bit RSA system is a real encryption method that is used in practice&#8212;2048 is the size of the numbers that must be hard to factor.</p>
<p>
An obvious idea is to try and use quantum computers to factor these numbers. The trouble is that the known methods do not seem to work on 2048-bit numbers. The quantum computers that we can build in the near future are way too small for running these quantum algorithms. </p>
<p>
<p><H2> Factoring is Easy? </H2></p>
<p><p>
However a group of Chinese researchers have just published a <a href="https://arxiv.org/pdf/2212.12372.pdf">paper</a> claiming that they can&#8212;although they have not yet done so&#8212;break 2048-bit RSA. </p>
<blockquote><p><b> </b> <em> Bao Yan, Ziqi Tan, Shijie Wei, Haocong Jiang, Weilong Wang, Hong Wang, Lan Luo, Qianheng Duan, Yiting Liu, Wenhao Shi, Yangyang Fei, Xiangdong Meng, Yu Han, Zheng Shan, Jiachen Chen, Xuhao Zhu, Chuanyu Zhang, Feitong Jin, Hekang Li, Chao Song, Zhen Wang, Zhi Ma, H. Wang, and Gui-Lu Long </em>
</p></blockquote>
<p><p>
This is something to take seriously. It might not be correct, but it&#8217;s not obviously wrong. This would break a real encryption method since 2048-bit RSA is used in practice. </p>
<p>
Scott <a href="https://scottaaronson.blog">factoring</a> says:</p>
<blockquote><p><b> </b> <em> The paper claims <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;dots}" class="latex" /> well, it&#8217;s hard to pin down what it claims, but it&#8217;s certainly given many people the impression that there&#8217;s been a decisive advance on how to factor huge integers, and thereby break the RSA cryptosystem, using a near-term quantum computer. Not by using Shor&#8217;s Algorithm, mind you, but by using the deceptively similarly named Schnorr&#8217;s Algorithm. The latter is a classical algorithm based on lattices, which the authors then &#8220;enhance&#8221; using the heuristic quantum optimization method called QAOA.</p>
<p>
All told, this is one of the most actively misleading quantum computing papers I&#8217;ve seen in 25 years, and I&#8217;ve seen <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;dots}" class="latex" /> many. Having said that, this actually isn&#8217;t the first time I&#8217;ve encountered the strange idea that the exponential quantum speedup for factoring integers, which we know about from Shor&#8217;s algorithm, should somehow &#8220;rub off&#8221; onto quantum optimization heuristics that embody none of the actual insights of Shor&#8217;s algorithm, as if by sympathetic magic. Since this idea needs a name, I&#8217;d hereby like to propose:</em><br />
<font color="#0044cc"><br />
<em>Cargo Cult Quantum Factoring</em><br />
<font color="#000000"></p>
</blockquote>
<p><p>
An interesting question is: Why would China allow this paper to be public given the huge importance of RSA? Could this be a sign that it is not real?</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
There it is&#8212;&#8220;Cargo Cult&#8221; in quantum algorithmic science&#8212;used by Scott. No doubt that it would have been approved by Feynman. </p>
<p><P><br />
[fixed &#8220;cargo cult&#8221;&#8211;>cargo cult <em>science</em>]</p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T16:39:51Z">Friday, January 06 2023, 16:39</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01924'>Diagonalization Games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Noga Alon, Olivier Bousquet, Kasper Green Larsen, Shay Moran, Shlomo Moran</p><p>We study several variants of a combinatorial game which is based on Cantor's
diagonal argument.
</p>
<p>The game is between two players called Kronecker and Cantor. The names of the
players are motivated by the known fact that Leopold Kronecker did not
appreciate Georg Cantor's arguments about the infinite, and even referred to
him as a "scientific charlatan". In the game Kronecker maintains a list of m
binary vectors, each of length n, and Cantor's goal is to produce a new binary
vector which is different from each of Kronecker's vectors, or prove that no
such vector exists. Cantor does not see Kronecker's vectors but he is allowed
to ask queries of the form"What is bit number j of vector number i?" What is
the minimal number of queries with which Cantor can achieve his goal? How much
better can Cantor do if he is allowed to pick his queries \emph{adaptively},
based on Kronecker's previous replies? The case when m=n is solved by
diagonalization using n (non-adaptive) queries. We study this game more
generally, and prove an optimal bound in the adaptive case and nearly tight
upper and lower bounds in the non-adaptive case.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Alon_N/0/1/0/all/0/1">Noga Alon</a>, <a href="http://arxiv.org/find/math/1/au:+Bousquet_O/0/1/0/all/0/1">Olivier Bousquet</a>, <a href="http://arxiv.org/find/math/1/au:+Larsen_K/0/1/0/all/0/1">Kasper Green Larsen</a>, <a href="http://arxiv.org/find/math/1/au:+Moran_S/0/1/0/all/0/1">Shay Moran</a>, <a href="http://arxiv.org/find/math/1/au:+Moran_S/0/1/0/all/0/1">Shlomo Moran</a></p><p>We study several variants of a combinatorial game which is based on Cantor's
diagonal argument.
</p>
<p>The game is between two players called Kronecker and Cantor. The names of the
players are motivated by the known fact that Leopold Kronecker did not
appreciate Georg Cantor's arguments about the infinite, and even referred to
him as a "scientific charlatan". In the game Kronecker maintains a list of m
binary vectors, each of length n, and Cantor's goal is to produce a new binary
vector which is different from each of Kronecker's vectors, or prove that no
such vector exists. Cantor does not see Kronecker's vectors but he is allowed
to ask queries of the form"What is bit number j of vector number i?" What is
the minimal number of queries with which Cantor can achieve his goal? How much
better can Cantor do if he is allowed to pick his queries \emph{adaptively},
based on Kronecker's previous replies? The case when m=n is solved by
diagonalization using n (non-adaptive) queries. We study this game more
generally, and prove an optimal bound in the adaptive case and nearly tight
upper and lower bounds in the non-adaptive case.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02161'>Streaming Zero-Knowledge Proofs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Graham Cormode, Marcel Dall&#x27;Agnol, Tom Gur, Chris Hickey</p><p>We initiate the study of zero-knowledge proofs for data streams. Streaming
interactive proofs (SIPs) are well-studied protocols whereby a space-bounded
algorithm with one-pass access to a massive stream of data communicates with a
powerful but untrusted prover to verify a computation that requires large
space.
</p>
<p>We define the notion of zero-knowledge in the streaming setting and construct
zero-knowledge SIPs for the two main building blocks in the streaming
interactive proofs literature: the sumcheck and polynomial evaluation
protocols. To the best of our knowledge all known streaming interactive proofs
are based on either of these tools, and indeed, this allows us to obtain
zero-knowledge SIPs for central streaming problems such as index, frequency
moments, and inner product. Our protocols are efficient in terms of time and
space, as well as communication: the space complexity is $\mathrm{polylog}(n)$
and, after a non-interactive setup that uses a random string of near-linear
length, the remaining parameters are $n^{o(1)}$.
</p>
<p>En route, we develop a toolkit for designing zero-knowledge data stream
protocols, consisting of an algebraic streaming commitment protocol and a
temporal commitment protocol. The analysis of our protocols relies on delicate
algebraic and information-theoretic arguments and reductions from average-case
communication complexity.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cormode_G/0/1/0/all/0/1">Graham Cormode</a>, <a href="http://arxiv.org/find/cs/1/au:+DallAgnol_M/0/1/0/all/0/1">Marcel Dall&#x27;Agnol</a>, <a href="http://arxiv.org/find/cs/1/au:+Gur_T/0/1/0/all/0/1">Tom Gur</a>, <a href="http://arxiv.org/find/cs/1/au:+Hickey_C/0/1/0/all/0/1">Chris Hickey</a></p><p>We initiate the study of zero-knowledge proofs for data streams. Streaming
interactive proofs (SIPs) are well-studied protocols whereby a space-bounded
algorithm with one-pass access to a massive stream of data communicates with a
powerful but untrusted prover to verify a computation that requires large
space.
</p>
<p>We define the notion of zero-knowledge in the streaming setting and construct
zero-knowledge SIPs for the two main building blocks in the streaming
interactive proofs literature: the sumcheck and polynomial evaluation
protocols. To the best of our knowledge all known streaming interactive proofs
are based on either of these tools, and indeed, this allows us to obtain
zero-knowledge SIPs for central streaming problems such as index, frequency
moments, and inner product. Our protocols are efficient in terms of time and
space, as well as communication: the space complexity is $\mathrm{polylog}(n)$
and, after a non-interactive setup that uses a random string of near-linear
length, the remaining parameters are $n^{o(1)}$.
</p>
<p>En route, we develop a toolkit for designing zero-knowledge data stream
protocols, consisting of an algebraic streaming commitment protocol and a
temporal commitment protocol. The analysis of our protocols relies on delicate
algebraic and information-theoretic arguments and reductions from average-case
communication complexity.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02227'>Optimal lower bounds for Quantum Learning via Information Theory</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shima Bab Hadiashar, Ashwin Nayak, Pulkit Sinha</p><p>Although a concept class may be learnt more efficiently using quantum samples
as compared with classical samples in certain scenarios, Arunachalam and de
Wolf (JMLR, 2018) proved that quantum learners are asymptotically no more
efficient than classical ones in the quantum PAC and Agnostic learning models.
They established lower bounds on sample complexity via quantum state
identification and Fourier analysis. In this paper, we derive optimal lower
bounds for quantum sample complexity in both the PAC and agnostic models via an
information-theoretic approach. The proofs are arguably simpler, and the same
ideas can potentially be used to derive optimal bounds for other problems in
quantum learning theory.
</p>
<p>We then turn to a quantum analogue of the Coupon Collector problem, a classic
problem from probability theory also of importance in the study of PAC
learning. Arunachalam, Belovs, Childs, Kothari, Rosmanis, and de Wolf (TQC,
2020) characterized the quantum sample complexity of this problem up to
constant factors. First, we show that the information-theoretic approach
mentioned above provably does not yield the optimal lower bound. As a
by-product, we get a natural ensemble of pure states in arbitrarily high
dimensions which are not easily (simultaneously) distinguishable, while the
ensemble has close to maximal Holevo information. Second, we discover that the
information-theoretic approach yields an asymptotically optimal bound for an
approximation variant of the problem. Finally, we derive a sharp lower bound
for the Quantum Coupon Collector problem, with the exact leading order term,
via the Holevo-Curlander bounds on the distinguishability of an ensemble. All
the aspects of the Quantum Coupon Collector problem we study rest on properties
of the spectrum of the associated Gram matrix, which may be of independent
interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Hadiashar_S/0/1/0/all/0/1">Shima Bab Hadiashar</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nayak_A/0/1/0/all/0/1">Ashwin Nayak</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sinha_P/0/1/0/all/0/1">Pulkit Sinha</a></p><p>Although a concept class may be learnt more efficiently using quantum samples
as compared with classical samples in certain scenarios, Arunachalam and de
Wolf (JMLR, 2018) proved that quantum learners are asymptotically no more
efficient than classical ones in the quantum PAC and Agnostic learning models.
They established lower bounds on sample complexity via quantum state
identification and Fourier analysis. In this paper, we derive optimal lower
bounds for quantum sample complexity in both the PAC and agnostic models via an
information-theoretic approach. The proofs are arguably simpler, and the same
ideas can potentially be used to derive optimal bounds for other problems in
quantum learning theory.
</p>
<p>We then turn to a quantum analogue of the Coupon Collector problem, a classic
problem from probability theory also of importance in the study of PAC
learning. Arunachalam, Belovs, Childs, Kothari, Rosmanis, and de Wolf (TQC,
2020) characterized the quantum sample complexity of this problem up to
constant factors. First, we show that the information-theoretic approach
mentioned above provably does not yield the optimal lower bound. As a
by-product, we get a natural ensemble of pure states in arbitrarily high
dimensions which are not easily (simultaneously) distinguishable, while the
ensemble has close to maximal Holevo information. Second, we discover that the
information-theoretic approach yields an asymptotically optimal bound for an
approximation variant of the problem. Finally, we derive a sharp lower bound
for the Quantum Coupon Collector problem, with the exact leading order term,
via the Holevo-Curlander bounds on the distinguishability of an ensemble. All
the aspects of the Quantum Coupon Collector problem we study rest on properties
of the spectrum of the associated Gram matrix, which may be of independent
interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02051'>A Distance-Geometric Method for Recovering Robot Joint Angles From an RGB Image</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ivan Bili&#x107;, Filip Mari&#x107;, Ivan Markovi&#x107;, Ivan Petrovi&#x107;</p><p>Autonomous manipulation systems operating in domains where human intervention
is difficult or impossible (e.g., underwater, extraterrestrial or hazardous
environments) require a high degree of robustness to sensing and communication
failures. Crucially, motion planning and control algorithms require a stream of
accurate joint angle data provided by joint encoders, the failure of which may
result in an unrecoverable loss of functionality. In this paper, we present a
novel method for retrieving the joint angles of a robot manipulator using only
a single RGB image of its current configuration, opening up an avenue for
recovering system functionality when conventional proprioceptive sensing is
unavailable. Our approach, based on a distance-geometric representation of the
configuration space, exploits the knowledge of a robot's kinematic model with
the goal of training a shallow neural network that performs a 2D-to-3D
regression of distances associated with detected structural keypoints. It is
shown that the resulting Euclidean distance matrix uniquely corresponds to the
observed configuration, where joint angles can be recovered via
multidimensional scaling and a simple inverse kinematics procedure. We evaluate
the performance of our approach on real RGB images of a Franka Emika Panda
manipulator, showing that the proposed method is efficient and exhibits solid
generalization ability. Furthermore, we show that our method can be easily
combined with a dense refinement technique to obtain superior results.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bilic_I/0/1/0/all/0/1">Ivan Bili&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Maric_F/0/1/0/all/0/1">Filip Mari&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Markovic_I/0/1/0/all/0/1">Ivan Markovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrovic_I/0/1/0/all/0/1">Ivan Petrovi&#x107;</a></p><p>Autonomous manipulation systems operating in domains where human intervention
is difficult or impossible (e.g., underwater, extraterrestrial or hazardous
environments) require a high degree of robustness to sensing and communication
failures. Crucially, motion planning and control algorithms require a stream of
accurate joint angle data provided by joint encoders, the failure of which may
result in an unrecoverable loss of functionality. In this paper, we present a
novel method for retrieving the joint angles of a robot manipulator using only
a single RGB image of its current configuration, opening up an avenue for
recovering system functionality when conventional proprioceptive sensing is
unavailable. Our approach, based on a distance-geometric representation of the
configuration space, exploits the knowledge of a robot's kinematic model with
the goal of training a shallow neural network that performs a 2D-to-3D
regression of distances associated with detected structural keypoints. It is
shown that the resulting Euclidean distance matrix uniquely corresponds to the
observed configuration, where joint angles can be recovered via
multidimensional scaling and a simple inverse kinematics procedure. We evaluate
the performance of our approach on real RGB images of a Franka Emika Panda
manipulator, showing that the proposed method is efficient and exhibits solid
generalization ability. Furthermore, we show that our method can be easily
combined with a dense refinement technique to obtain superior results.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02129'>Algorithms and Complexity for Computing Nash Equilibria in Adversarial Team Games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ioannis Anagnostides, Fivos Kalogiannis, Ioannis Panageas, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Stephen McAleer</p><p>Adversarial team games model multiplayer strategic interactions in which a
team of identically-interested players is competing against an adversarial
player in a zero-sum game. Such games capture many well-studied settings in
game theory, such as congestion games, but go well-beyond to environments
wherein the cooperation of one team -- in the absence of explicit communication
-- is obstructed by competing entities; the latter setting remains poorly
understood despite its numerous applications. Since the seminal work of Von
Stengel and Koller (GEB `97), different solution concepts have received
attention from an algorithmic standpoint. Yet, the complexity of the standard
Nash equilibrium has remained open.
</p>
<p>In this paper, we settle this question by showing that computing a Nash
equilibrium in adversarial team games belongs to the class continuous local
search (CLS), thereby establishing CLS-completeness by virtue of the recent
CLS-hardness result of Rubinstein and Babichenko (STOC `21) in potential games.
To do so, we leverage linear programming duality to prove that any
$\epsilon$-approximate stationary strategy for the team can be extended in
polynomial time to an $O(\epsilon)$-approximate Nash equilibrium, where the
$O(\cdot)$ notation suppresses polynomial factors in the description of the
game. As a consequence, we show that the Moreau envelop of a suitable best
response function acts as a potential under certain natural gradient-based
dynamics.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Anagnostides_I/0/1/0/all/0/1">Ioannis Anagnostides</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalogiannis_F/0/1/0/all/0/1">Fivos Kalogiannis</a>, <a href="http://arxiv.org/find/cs/1/au:+Panageas_I/0/1/0/all/0/1">Ioannis Panageas</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlatakis_Gkaragkounis_E/0/1/0/all/0/1">Emmanouil-Vasileios Vlatakis-Gkaragkounis</a>, <a href="http://arxiv.org/find/cs/1/au:+McAleer_S/0/1/0/all/0/1">Stephen McAleer</a></p><p>Adversarial team games model multiplayer strategic interactions in which a
team of identically-interested players is competing against an adversarial
player in a zero-sum game. Such games capture many well-studied settings in
game theory, such as congestion games, but go well-beyond to environments
wherein the cooperation of one team -- in the absence of explicit communication
-- is obstructed by competing entities; the latter setting remains poorly
understood despite its numerous applications. Since the seminal work of Von
Stengel and Koller (GEB `97), different solution concepts have received
attention from an algorithmic standpoint. Yet, the complexity of the standard
Nash equilibrium has remained open.
</p>
<p>In this paper, we settle this question by showing that computing a Nash
equilibrium in adversarial team games belongs to the class continuous local
search (CLS), thereby establishing CLS-completeness by virtue of the recent
CLS-hardness result of Rubinstein and Babichenko (STOC `21) in potential games.
To do so, we leverage linear programming duality to prove that any
$\epsilon$-approximate stationary strategy for the team can be extended in
polynomial time to an $O(\epsilon)$-approximate Nash equilibrium, where the
$O(\cdot)$ notation suppresses polynomial factors in the description of the
game. As a consequence, we show that the Moreau envelop of a suitable best
response function acts as a potential under certain natural gradient-based
dynamics.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02178'>Sum Labelling Graphs of Maximum Degree Two</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Henning Fernau, Kshitij Gajjar</p><p>The concept of sum labelling was introduced in 1990 by Harary. A graph is a
sum graph if its vertices can be labelled by distinct positive integers in such
a way that two vertices are connected by an edge if and only if the sum of
their labels is the label of another vertex in the graph. It is easy to see
that every sum graph has at least one isolated vertex, and every graph can be
made a sum graph by adding at most $n^2$ isolated vertices to it. The minimum
number of isolated vertices that need to be added to a graph to make it a sum
graph is called the sum number of the graph.
</p>
<p>The sum number of several prominent graph classes (e.g., cycles, trees,
complete graphs) is already well known. We examine the effect of taking the
disjoint union of graphs on the sum number. In particular, we provide a
complete characterization of the sum number of graphs of maximum degree two,
since every such graph is the disjoint union of paths and cycles.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Fernau_H/0/1/0/all/0/1">Henning Fernau</a>, <a href="http://arxiv.org/find/math/1/au:+Gajjar_K/0/1/0/all/0/1">Kshitij Gajjar</a></p><p>The concept of sum labelling was introduced in 1990 by Harary. A graph is a
sum graph if its vertices can be labelled by distinct positive integers in such
a way that two vertices are connected by an edge if and only if the sum of
their labels is the label of another vertex in the graph. It is easy to see
that every sum graph has at least one isolated vertex, and every graph can be
made a sum graph by adding at most $n^2$ isolated vertices to it. The minimum
number of isolated vertices that need to be added to a graph to make it a sum
graph is called the sum number of the graph.
</p>
<p>The sum number of several prominent graph classes (e.g., cycles, trees,
complete graphs) is already well known. We examine the effect of taking the
disjoint union of graphs on the sum number. In particular, we provide a
complete characterization of the sum number of graphs of maximum degree two,
since every such graph is the disjoint union of paths and cycles.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01778'>Quantum relaxation for quadratic programs over orthogonal matrices</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andrew Zhao, Nicholas C. Rubin</p><p>Quadratic programming over the (special) orthogonal group encompasses a broad
class of optimization problems such as group synchronization, point-set
registration, and simultaneous localization and mapping. Such problems are
instances of the little noncommutative Grothendieck problem (LNCG), a natural
generalization of quadratic combinatorial optimization where, instead of binary
decision variables, one optimizes over orthogonal matrices. In this work, we
establish an embedding of this class of LNCG problems over the orthogonal group
onto a quantum Hamiltonian. This embedding is accomplished by identifying
orthogonal matrices with their double cover (Pin and Spin group) elements,
which we represent as quantum states. We connect this construction to the
theory of free fermions, which provides a physical interpretation of the
derived LNCG Hamiltonian as a two-body interacting-fermion model due to the
quadratic nature of the problem. Determining extremal states of this
Hamiltonian provides an outer approximation to the original problem, analogous
to classical relaxations of the problem via semidefinite programming. When
optimizing over the special orthogonal group, our quantum relaxation naturally
obeys additional, powerful constraints based on the convex hull of rotation
matrices. The classical size of this convex-hull representation is exponential
in matrix dimension, whereas the quantum representation requires only a linear
number of qubits. Finally, to project the relaxed solution into the feasible
space, we employ rounding procedures which return orthogonal matrices from
appropriate measurements of the quantum state. Through numerical experiments we
provide evidence that this quantum relaxation can produce high-quality
approximations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Zhao_A/0/1/0/all/0/1">Andrew Zhao</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Rubin_N/0/1/0/all/0/1">Nicholas C. Rubin</a></p><p>Quadratic programming over the (special) orthogonal group encompasses a broad
class of optimization problems such as group synchronization, point-set
registration, and simultaneous localization and mapping. Such problems are
instances of the little noncommutative Grothendieck problem (LNCG), a natural
generalization of quadratic combinatorial optimization where, instead of binary
decision variables, one optimizes over orthogonal matrices. In this work, we
establish an embedding of this class of LNCG problems over the orthogonal group
onto a quantum Hamiltonian. This embedding is accomplished by identifying
orthogonal matrices with their double cover (Pin and Spin group) elements,
which we represent as quantum states. We connect this construction to the
theory of free fermions, which provides a physical interpretation of the
derived LNCG Hamiltonian as a two-body interacting-fermion model due to the
quadratic nature of the problem. Determining extremal states of this
Hamiltonian provides an outer approximation to the original problem, analogous
to classical relaxations of the problem via semidefinite programming. When
optimizing over the special orthogonal group, our quantum relaxation naturally
obeys additional, powerful constraints based on the convex hull of rotation
matrices. The classical size of this convex-hull representation is exponential
in matrix dimension, whereas the quantum representation requires only a linear
number of qubits. Finally, to project the relaxed solution into the feasible
space, we employ rounding procedures which return orthogonal matrices from
appropriate measurements of the quantum state. Through numerical experiments we
provide evidence that this quantum relaxation can produce high-quality
approximations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01977'>Exact and Heuristic Approaches to Speeding Up the MSM Time Series Distance Computation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jana Holznigenkemper, Christian Komusiewicz, Bernhard Seeger</p><p>The computation of a distance of two time series is time-consuming for any
elastic distance function that accounts for misalignments. Among those
functions, DTW is the most prominent. However, a recent extensive evaluation
has shown that the move-split merge (MSM) metric is superior to DTW regarding
the analytical accuracy of 1-NN classifier. Unfortunately, the runtime of the
standard dynamic programming algorithm for MSM distance computation is
$\Omega(n^2)$, where $n$ is the length of the longest time series. In this
paper, we provide approaches to reducing the cost of MSM distance computations
by using lower and upper bounds for early pruning paths in the underlying
dynamic programming table. For the case of one time series being a constant, we
present a linear-time algorithm. In addition, we propose new linear-time
heuristics and adapt heuristics known from DTW to computing the MSM distance.
One heuristic employs the metric property of MSM and the previously introduced
linear-time algorithm. Our experimental studies achieve substantial speed-ups
in our approaches compared to previous MSM algorithms. In particular, the
running time for MSM is faster for a majority of data sets than a
state-of-the-art DTW distance computation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Holznigenkemper_J/0/1/0/all/0/1">Jana Holznigenkemper</a>, <a href="http://arxiv.org/find/cs/1/au:+Komusiewicz_C/0/1/0/all/0/1">Christian Komusiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Seeger_B/0/1/0/all/0/1">Bernhard Seeger</a></p><p>The computation of a distance of two time series is time-consuming for any
elastic distance function that accounts for misalignments. Among those
functions, DTW is the most prominent. However, a recent extensive evaluation
has shown that the move-split merge (MSM) metric is superior to DTW regarding
the analytical accuracy of 1-NN classifier. Unfortunately, the runtime of the
standard dynamic programming algorithm for MSM distance computation is
$\Omega(n^2)$, where $n$ is the length of the longest time series. In this
paper, we provide approaches to reducing the cost of MSM distance computations
by using lower and upper bounds for early pruning paths in the underlying
dynamic programming table. For the case of one time series being a constant, we
present a linear-time algorithm. In addition, we propose new linear-time
heuristics and adapt heuristics known from DTW to computing the MSM distance.
One heuristic employs the metric property of MSM and the previously introduced
linear-time algorithm. Our experimental studies achieve substantial speed-ups
in our approaches compared to previous MSM algorithms. In particular, the
running time for MSM is faster for a majority of data sets than a
state-of-the-art DTW distance computation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02053'>Max-Min Diversification with Fairness Constraints: Exact and Approximation Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yanhao Wang, Michael Mathioudakis, Jia Li, Francesco Fabbri</p><p>Diversity maximization aims to select a diverse and representative subset of
items from a large dataset. It is a fundamental optimization task that finds
applications in data summarization, feature selection, web search, recommender
systems, and elsewhere. However, in a setting where data items are associated
with different groups according to sensitive attributes like sex or race, it is
possible that algorithmic solutions for this task, if left unchecked, will
under- or over-represent some of the groups. Therefore, we are motivated to
address the problem of \emph{max-min diversification with fairness
constraints}, aiming to select $k$ items to maximize the minimum distance
between any pair of selected items while ensuring that the number of items
selected from each group falls within predefined lower and upper bounds. In
this work, we propose an exact algorithm based on integer linear programming
that is suitable for small datasets as well as a
$\frac{1-\varepsilon}{5}$-approximation algorithm for any $\varepsilon \in (0,
1)$ that scales to large datasets. Extensive experiments on real-world datasets
demonstrate the superior performance of our proposed algorithms over existing
ones.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathioudakis_M/0/1/0/all/0/1">Michael Mathioudakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fabbri_F/0/1/0/all/0/1">Francesco Fabbri</a></p><p>Diversity maximization aims to select a diverse and representative subset of
items from a large dataset. It is a fundamental optimization task that finds
applications in data summarization, feature selection, web search, recommender
systems, and elsewhere. However, in a setting where data items are associated
with different groups according to sensitive attributes like sex or race, it is
possible that algorithmic solutions for this task, if left unchecked, will
under- or over-represent some of the groups. Therefore, we are motivated to
address the problem of \emph{max-min diversification with fairness
constraints}, aiming to select $k$ items to maximize the minimum distance
between any pair of selected items while ensuring that the number of items
selected from each group falls within predefined lower and upper bounds. In
this work, we propose an exact algorithm based on integer linear programming
that is suitable for small datasets as well as a
$\frac{1-\varepsilon}{5}$-approximation algorithm for any $\varepsilon \in (0,
1)$ that scales to large datasets. Extensive experiments on real-world datasets
demonstrate the superior performance of our proposed algorithms over existing
ones.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, January 05
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/001'>TR23-001 |  New Lower Bounds against Homogeneous Non-Commutative Circuits | 

	Prerona Chatterjee, 

	Pavel Hrubes</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We give several new lower bounds on size of homogeneous non-commutative circuits. We present an explicit homogeneous bivariate polynomial of degree $d$ which requires homogeneous non-commutative circuit of size $\Omega(d/\log d)$. For an $n$-variate polynomial with $n&gt;1$, the result can be improved to $\Omega(nd)$, if $d\leq n$,  or $\Omega(nd \frac{\log n}{\log d})$, if $d\geq n$.
  Under the same assumptions, we also give a quadratic lower bound for the ordered version of the central symmetric polynomial.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We give several new lower bounds on size of homogeneous non-commutative circuits. We present an explicit homogeneous bivariate polynomial of degree $d$ which requires homogeneous non-commutative circuit of size $\Omega(d/\log d)$. For an $n$-variate polynomial with $n&gt;1$, the result can be improved to $\Omega(nd)$, if $d\leq n$,  or $\Omega(nd \frac{\log n}{\log d})$, if $d\geq n$.
  Under the same assumptions, we also give a quadratic lower bound for the ordered version of the central symmetric polynomial.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T12:43:37Z">Thursday, January 05 2023, 12:43</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/01/05/greatest-hits-2015-2022-part-ii/'>Greatest Hits 2015-2022, Part II</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This is the second part of Greatest Hits 2015-2022, Part I. Here are popular and favorite posts published in 2019-2022. 2019 Supremacy and Sensitivity (and Sunflowers) Test your intuition 38 was contributed in March 2019 by my youngest son Lior. &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>This is the second part of <a href="https://gilkalai.wordpress.com/2023/01/01/greatest-hits-2015-2022-part-i/">Greatest Hits 2015-2022</a>, Part I. Here are popular and favorite posts published in 2019-2022.</p>
<h2>2019 Supremacy and Sensitivity (and Sunflowers)</h2>
<p>Test your intuition 38 was contributed in March 2019 by my youngest son Lior. <a href="https://gilkalai.wordpress.com/2019/03/18/tyi38-lior-kalai-monty-hall-meets-survivor/" rel="bookmark">TYI38 Lior Kalai: Monty Hall Meets Survivor</a>. Aside from the problem itself, the post contained beautiful pictures of my family, and, two days after the post was published, I added the startling breaking news about Karen Uhlenbeck being awarded the Abel Prize.</p>
<p>Also in March 2019, the post <a href="https://gilkalai.wordpress.com/2019/03/26/10-milestones-in-the-history-of-mathematics-according-to-nati-and-me/" rel="bookmark">10 Milestones in the History of Mathematics according to Nati and Me</a> drew many views and many comments. And in April 2019 I made an unusual invitation:  <a href="https://gilkalai.wordpress.com/2019/04/23/an-invitation-to-a-conference-visions-in-mathematics-towards-2000/" rel="bookmark">An Invitation to a Conference: Visions in Mathematics towards 2000,</a> with links to videos and many pictures of us 20 years younger.  This followed by a post discussing a bold statement made at the conference by Misha Gromov <a href="https://gilkalai.wordpress.com/2019/04/25/are-natural-mathematical-problems-bad-problems/" rel="bookmark">Are Natural Mathematical Problems Bad Problems?</a></p>
<h3>Quantum supremacy</h3>
<p>In August 2019 I presented a new paper and a CERN colloquium:  <a href="https://gilkalai.wordpress.com/2019/08/21/the-argument-against-quantum-computers-a-cern-colloquium-and-a-new-paper/" rel="bookmark">The Argument against Quantum Computers – a CERN Colloquium and a New Paper</a>, a month later on September 22, 2019, a paper by a team from Google was leaked with a demonstration of quantum supremacy, which, if true, would refute my argument. I found the leaked paper rather unconvincing and raised some concerns about it in this post: <a href="https://gilkalai.wordpress.com/2019/09/23/quantum-computers-amazing-progress-google-ibm-and-extraordinary-but-probably-false-supremacy-claims-google/" rel="bookmark">Quantum computers: amazing progress (Google &amp; IBM), and extraordinary but probably false supremacy claims (Google).</a></p>
<p>Two weeks later I wrote <a href="https://gilkalai.wordpress.com/2019/10/13/the-story-of-poincare-and-his-friend-the-baker/" rel="bookmark">The story of Poincaré and his friend the baker,</a> where I raised another concern regarding the calibration process of the paper, and this concern was amply discussed in the comment section.  Following the appearance of the Google paper itself on October 21, 2019, and some responses from the Google team,  I wrote on November 11, 2019 a new post <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/" rel="bookmark">Gil’s Collegial Quantum Supremacy Skepticism FAQ.</a> Some further updates and discussion can be found in the Dec. 27 post <a href="https://gilkalai.wordpress.com/2019/12/27/the-google-quantum-supremacy-demo/" rel="bookmark">The Google Quantum Supremacy Demo and the Jerusalem HQCA debate</a>.</p>
<h3>2019 mathematical news</h3>
<p>The mathematical news that was most exciting to me in 2019 was reported in August. <a href="https://gilkalai.wordpress.com/2019/08/23/amazing-ryan-alweiss-shachar-lovett-kewen-wu-jiapeng-zhang-made-dramatic-progress-on-the-sunflower-conjecture/" rel="bookmark">Amazing: Ryan Alweiss, Shachar Lovett, Kewen Wu, Jiapeng Zhang made dramatic progress on the Sunflower Conjecture.</a> This was a problem I had first heard about as an undergraduate, I thought about it over the years, and we ran polymath 10 for attacking it. I also was excited about other possible applications, but did not imagine it would be related to Jeff Kahn and mine expectation threshold conjecture. But indeed it was related: <a href="https://gilkalai.wordpress.com/2019/10/30/amazing-keith-frankston-jeff-kahn-bhargav-narayanan-jinyoung-park-thresholds-versus-fractional-expectation-thresholds/" rel="bookmark">Amazing! Keith Frankston, Jeff Kahn, Bhargav Narayanan, Jinyoung Park: Thresholds versus fractional expectation-thresholds</a>;</p>
<p>Other great results were: <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/" rel="bookmark">Amazing: Hao Huang Proved the Sensitivity Conjecture!</a> (July);  <a href="https://gilkalai.wordpress.com/2019/05/10/sansation-in-the-morning-news-yaroslav-shitov-counterexamples-to-hedetniemis-conjecture/" rel="bookmark">A sensation in the morning news – Yaroslav Shitov: Counterexamples to Hedetniemi’s conjecture</a> (May); <a href="https://gilkalai.wordpress.com/2019/06/28/another-sensation-annika-heckel-non-concentration-of-the-chromatic-number-of-a-random-graph/" rel="bookmark">Another sensation – Annika Heckel: Non-concentration of the chromatic number of a random graph</a> (June); <a href="https://gilkalai.wordpress.com/2019/02/02/konstantin-tikhomrov-the-probability-that-a-bernoulli-matrix-is-singular/" rel="bookmark">Konstantin Tikhomirov: The Probability that a Bernoulli Matrix is Singular</a> (February); <a href="https://gilkalai.wordpress.com/2019/09/22/jeff-kahn-and-jinyoung-park-maximal-independent-sets-and-a-new-isoperimetric-inequality-for-the-hamming-cube/" rel="bookmark">Jeff Kahn and Jinyoung Park: Maximal independent sets and a new isoperimetric inequality for the Hamming cube; </a><a href="https://gilkalai.wordpress.com/2019/07/23/matan-harel-frank-mousset-and-wojciech-samotij-and-the-the-infamous-upper-tail-problem/" rel="bookmark">Matan Harel, Frank Mousset, and Wojciech Samotij and the “the infamous upper tail” problem; </a><a href="https://gilkalai.wordpress.com/2019/02/16/attila-pors-universality-result-for-tverberg-partitions/" rel="bookmark">Attila Por’s Universality Result for Tverberg Partitions; </a><a href="https://gilkalai.wordpress.com/2019/07/20/isabella-novik-and-hailun-zheng-neighborly-centrally-symmetric-spheres-exist-in-all-dimensions/" rel="bookmark">Isabella Novik and Hailun Zheng: Neighborly centrally symmetric spheres exist in all dimensions!</a>; <a href="https://gilkalai.wordpress.com/2019/03/22/danny-nguyen-and-igor-pak-presburger-arithmetic-problem-solved/" rel="bookmark">Danny Nguyen and Igor Pak: Presburger Arithmetic Problem Solved!</a> And in number theory <a href="https://gilkalai.wordpress.com/2019/03/09/8866128975287528%c2%b3-8778405442862239%c2%b3-2736111468807040%c2%b3/" rel="bookmark">8866128975287528³+(-8778405442862239)³+(-2736111468807040)³</a>;</p>
<p>We had two great guest posts: <a href="https://gilkalai.wordpress.com/2019/07/17/dan-romik-on-the-riemann-zeta-function/" rel="bookmark">Dan Romik on the Riemann zeta function</a>, and <a href="https://gilkalai.wordpress.com/2019/07/09/imre-barany-limit-shape/" rel="bookmark">Imre Bárány: Limit shape.</a></p>
<p>In 2019 I also wrote about <a href="https://gilkalai.wordpress.com/2019/01/02/jean/">Jean Bourgain</a> and about <a href="https://gilkalai.wordpress.com/2019/05/01/the-last-paper-of-catherine-renyi-and-alfred-renyi-counting-k-trees/" rel="bookmark">The last paper of Catherine Rényi and Alfréd Rényi: Counting k-Trees.</a></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/talab.png"><img loading="lazy" data-attachment-id="16899" data-permalink="https://gilkalai.wordpress.com/2019/02/16/attila-pors-universality-result-for-tverberg-partitions/rainbow-2/" data-orig-file="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png" data-orig-size="983,711" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rainbow" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=640" class="alignnone  wp-image-16899" src="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=274&#038;h=198" alt="rainbow" width="274" height="198" srcset="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=274&amp;h=198 274w, https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=548&amp;h=396 548w, https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=150&amp;h=108 150w, https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=300&amp;h=217 300w" sizes="(max-width: 274px) 100vw, 274px" /></a></p>
<p><span style="color: #ff0000">A drawing explaining Attila Por&#8217;s construction</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png"><img loading="lazy" data-attachment-id="16725" data-permalink="https://gilkalai.wordpress.com/2019/01/02/jean/jean-joram/" data-orig-file="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png" data-orig-size="1586,1238" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Jean-Joram" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=640" class="alignnone  wp-image-16725" src="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=217&#038;h=169" alt="Jean-Joram" width="217" height="169" srcset="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=217&amp;h=169 217w, https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=434&amp;h=338 434w, https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=150&amp;h=117 150w, https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=300&amp;h=234 300w" sizes="(max-width: 217px) 100vw, 217px" /></a></p>
<p><span style="color: #ff0000">Jean Bourgain and Joram Lindenstrauss</span></p>
<h2>2020 To cheer you up in difficult times</h2>
<h3>Mathematical news</h3>
<p>The post about mathematical news that excited both the readers and me the most appeared in January: <a href="https://gilkalai.wordpress.com/2020/01/17/amazing-zhengfeng-ji-anand-natarajan-thomas-vidick-john-wright-and-henry-yuen-proved-that-mip-re-and-thus-disproved-connes-1976-embedding-conjecture-and-provided-a-negative-answer-to-tsirelso/" rel="bookmark">Amazing: Zhengfeng Ji, Anand Natarajan, Thomas Vidick, John Wright, and Henry Yuen proved that MIP* = RE and thus disproved Connes 1976 Embedding Conjecture, and provided a negative answer to Tsirelson’s problem. </a>My final correspondence with Boris Tsirelson was about this breakthrough and I wrote about him in this post <a href="https://gilkalai.wordpress.com/2020/04/03/trees-not-cubes-memories-of-boris-tsirelson/" rel="bookmark">Trees not Cubes! Memories of Boris Tsirelson</a>.</p>
<p>Two other exciting and popular posts with 2020 major mathematical news came in July and December. The July post was <a href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/" rel="bookmark">To cheer you up in difficult times 7: Bloom and Sisask just broke the logarithm barrier for Roth’s theorem!;</a> And in December <a href="https://gilkalai.wordpress.com/2020/12/21/to-cheer-you-up-in-difficult-times-15-yuansi-chen-achieved-a-major-breakthrough-on-bourgains-slicing-problem-and-the-kannan-lovasz-and-simonovits-conjecture/" rel="bookmark">To Cheer You Up in Difficult Times 15: Yuansi Chen Achieved a Major Breakthrough on Bourgain’s Slicing Problem and the Kannan, Lovász and Simonovits Conjecture</a></p>
<h3>To cheer you up in difficult times (Math news, and fun)</h3>
<p><a href="https://gilkalai.wordpress.com/2020/05/08/to-cheer-you-up-in-difficult-times-3-a-guest-post-by-noam-lifshitz-on-the-new-hypercontractivity-inequality-of-peter-keevash-noam-lifshitz-eoin-long-and-dor-minzer/" rel="bookmark">To cheer you up in difficult times 3: A guest post by Noam Lifshitz on the new hypercontractivity inequality of Peter Keevash, Noam Lifshitz, Eoin Long and Dor Minzer</a>; <a href="https://gilkalai.wordpress.com/2020/05/30/to-cheer-you-up-in-difficult-times-5-a-new-elementary-proof-of-the-prime-number-theorem-by-florian-k-richter/" rel="bookmark">To cheer you up in difficult times 5: A New Elementary Proof of the Prime Number Theorem by Florian K. Richter;</a> <a href="https://gilkalai.wordpress.com/2020/06/26/to-cheer-you-up-in-difficult-times-6-play-rani-sharims-two-player-games-of-life-read-maya-bar-hillel-presentation-on-catching-lies-with-statistics-and-more/" rel="bookmark">To cheer you up in difficult times 6: Play Rani Sharim’s two-player games of life, read Maya Bar-Hillel presentation on catching lies with statistics, and more.</a><a href="https://gilkalai.wordpress.com/2020/08/01/to-cheer-you-up-in-difficult-times-8-nathan-keller-and-ohad-klein-proved-tomaszewskis-conjecture-on-randomly-signed-sums/" rel="bookmark">;To Cheer you up in Difficult Times 8: Nathan Keller and Ohad Klein Proved Tomaszewski’s Conjecture on Randomly Signed Sums</a>;  <a href="https://gilkalai.wordpress.com/2020/08/14/to-cheer-you-up-in-difficult-times-9-alexey-pokrovskiy-proved-that-rotas-basis-conjecture-holds-asymptotically/" rel="bookmark">To cheer you up in difficult times 9: Alexey Pokrovskiy proved that Rota’s Basis Conjecture holds asymptotically</a>; <a href="https://gilkalai.wordpress.com/2020/09/23/to-cheer-you-up-in-difficult-times-12-asaf-ferber-and-david-conlon-found-new-lower-bounds-for-diagonal-ramsey-numbers/" rel="bookmark">To cheer you up in difficult times 12: Asaf Ferber and David Conlon found new lower bounds for diagonal Ramsey numbers</a>; <a href="https://gilkalai.wordpress.com/2020/10/11/three-games-to-cheer-you-up/" rel="bookmark">Three games to cheer you up.</a></p>
<p>The first post which explicitly aimed cheering up our readers was from mid-March when it had become clear that the Corvid outbreak is going to overshadow our lives. <a href="https://gilkalai.wordpress.com/2020/03/14/to-cheer-you-up-in-complicated-times-a-book-proof-by-rom-pinchasi-and-alexandr-polyanskii-for-a-1978-conjecture-by-erdos-and-purdy/" rel="bookmark">To cheer you up in complicated times – A book proof by Rom Pinchasi and Alexandr Polyanskii for a 1978 Conjecture by Erdős and Purdy!</a></p>
<p>Other mathematical news from 2019 were <a href="https://gilkalai.wordpress.com/2020/01/27/ringel-conjecture-solved-congratulations-to-richard-montgomery-alexey-pokrovskiy-and-benny-sudakov/" rel="bookmark">Ringel Conjecture, Solved! Congratulations to Richard Montgomery, Alexey Pokrovskiy, and Benny Sudakov;</a> In February <a href="https://gilkalai.wordpress.com/2020/02/28/remarkable-new-stochastic-methods-in-abf-ronen-eldan-and-renan-gross-found-a-new-proof-for-kkl-and-settled-a-conjecture-by-talagrand/" rel="bookmark">Remarkable New Stochastic Methods in ABF: Ronen Eldan and Renan Gross Found a New Proof for KKL and Settled a Conjecture by Talagrand;</a> <a href="https://gilkalai.wordpress.com/2020/03/22/kelman-kindler-lifshitz-minzer-and-safra-towards-the-entropy-influence-conjecture/" rel="bookmark">Kelman, Kindler, Lifshitz, Minzer, and Safra: Towards the Entropy-Influence Conjecture</a>; <a href="https://gilkalai.wordpress.com/2020/07/24/noam-lifshitz-a-new-hypercontractivity-inequality-the-proof/" rel="bookmark">Noam Lifshitz: A new hypercontractivity inequality — The proof!</a></p>
<h3>Quantum news and matters</h3>
<p>In December 2020 I wrote about an attempt to establish quantum supremacy using a photonic device: <a href="https://gilkalai.wordpress.com/2020/12/06/photonic-huge-quantum-advantage/" rel="bookmark">Photonic Huge Quantum Advantage ???</a>, This time, an algorithm from a 2014 paper by Guy Kindler and me sufficed to refute the fantastic claims. A few days later I wrote <a href="https://gilkalai.wordpress.com/2020/12/29/the-argument-against-quantum-computers-a-very-short-introduction/" rel="bookmark">The Argument Against Quantum Computers – A Very Short Introduction</a>, which has become one of the blog&#8217;s blockbusters.</p>
<h2>2021 Erdős-Faber-Lovász and Diverse Matters</h2>
<p><strong>Discussion about Diversity:</strong> the post <a href="https://gilkalai.wordpress.com/2021/09/22/to-cheer-you-up-in-difficult-times-31-federico-ardilas-four-axioms-for-cultivating-diversity/" rel="bookmark">To Cheer You Up in Difficult Times 31: Federico Ardila’s Four Axioms for Cultivating Diversity</a>, led to heated discussions mainly on Facebook.</p>
<p><strong>Celebrations and discussions:</strong> The post <a href="https://gilkalai.wordpress.com/2021/03/17/cheerful-news-in-difficult-times-the-abel-prize-is-awarded-to-laszlo-lovasz-and-avi-wigderson/" rel="bookmark">Cheerful News in Difficult Times: The Abel Prize is Awarded to László Lovász and Avi Wigderson,</a> contains a lot of pictures of Avi and Laci and their families (and in a few cases of my family), and it was followed by the most viewed 2021 post presenting a debate between Avi Wigderson and me, which goes deeply into the connection between (computer science) theory, practice, and mathematics: <a href="https://gilkalai.wordpress.com/2021/04/22/the-probabilistic-proof-that-2400-593-is-a-prime-a-revolutionary-new-type-of-mathematical-proof-or-not-a-proof-at-all/" rel="bookmark">The probabilistic proof that 2^400-593 is a prime: a revolutionary new type of mathematical proof, or not a proof at all?</a></p>
<p><strong>Mathematical news from 2021:</strong> <a href="https://gilkalai.wordpress.com/2021/01/14/to-cheer-you-up-in-difficult-times-17-amazing-the-erdos-faber-lovasz-conjecture-for-large-n-was-proved-by-dong-yeap-kang-tom-kelly-daniela-kuhn-abhishek-methuku-and-deryk-osthus/" rel="bookmark">To cheer you up in difficult times 17: Amazing! The Erdős-Faber-Lovász conjecture (for large n) was proved by Dong Yeap Kang, Tom Kelly, Daniela Kühn, Abhishek Methuku, and Deryk Osthus!</a>; <a href="https://gilkalai.wordpress.com/2021/02/08/to-cheer-you-up-in-difficult-times-20-ben-green-presents-super-polynomial-lower-bounds-for-off-diagonal-van-der-waerden-numbers-w3k/" rel="bookmark">To cheer you up in difficult times 20: Ben Green presents super-polynomial lower bounds for off-diagonal van der Waerden numbers W(3,k)</a><a href="https://gilkalai.wordpress.com/2021/02/25/to-cheer-you-up-in-difficult-times-21-giles-gardam-lecture-and-new-result-on-kaplanskys-conjectures/" rel="bookmark">;To cheer you up in difficult times 21: Giles Gardam lecture and new result on Kaplansky’s conjectures</a>; <a href="https://gilkalai.wordpress.com/2021/09/17/to-cheer-you-up-in-difficult-times-30-irit-dinur-shai-evra-ron-livne-alex-lubotzky-and-shahar-mozes-constructed-locally-testable-codes-with-constant-rate-distance-and-locality/" rel="bookmark">To Cheer you up in difficult times 30: Irit Dinur, Shai Evra, Ron Livne, Alex Lubotzky, and Shahar Mozes Constructed Locally Testable Codes with Constant Rate, Distance, and Locality.</a> <a href="https://gilkalai.wordpress.com/2021/12/11/to-cheer-you-up-in-difficult-times-34-ringel-circle-problem-solved-by-james-davies-chaya-keller-linda-kleist-shakhar-smorodinsky-and-bartosz-walczak/" rel="bookmark">To cheer you up in difficult times 34: Ringel Circle Problem solved by James Davies, Chaya Keller, Linda Kleist, Shakhar Smorodinsky, and Bartosz Walczak;</a> <a href="https://gilkalai.wordpress.com/2021/01/21/amazing-simpler-and-more-general-proofs-for-the-g-theorem-by-stavros-argyrios-papadakis-and-vasiliki-petrotou-and-by-karim-adiprasito-stavros-argyrios-papadakis-and-vasiliki-petrotou/" rel="bookmark">Amazing: Simpler and more general proofs for the g-theorem by Stavros Argyrios Papadakis and Vasiliki Petrotou, and by Karim Adiprasito, Stavros Argyrios Papadakis, and Vasiliki Petrotou.</a></p>
<p><strong>Two collections of startling mathematical news:</strong> <a href="https://gilkalai.wordpress.com/2021/05/20/to-cheer-you-up-in-difficult-times-25-some-mathematical-news-part-2/" rel="bookmark">To cheer you up in difficult times 25: some mathematical news! (Part 2)</a> and <a href="https://gilkalai.wordpress.com/2021/03/23/to-cheer-you-up-in-difficult-times-22-some-mathematical-news-part-1/" rel="bookmark">To cheer you up in difficult times 22: some mathematical news! (Part 1)</a></p>
<p><strong>Memorabilia</strong>: <a href="https://gilkalai.wordpress.com/2021/02/19/nostalgia-corner-john-riordans-referee-report-of-my-first-paper/" rel="bookmark">Nostalgia corner: John Riordan’s referee report of my first paper</a>;  <a href="https://gilkalai.wordpress.com/2021/05/14/to-cheer-you-up-in-difficult-times-23-the-original-hand-written-slides-of-terry-taos-2015-einstein-lecture-in-jerusalem/" rel="bookmark">To cheer you up in difficult times 23: the original hand-written slides of Terry Tao’s 2015 Einstein Lecture in Jerusalem</a></p>
<p><strong>Quantum matters:  </strong><a href="https://gilkalai.wordpress.com/2021/03/10/amazing-feng-pan-and-pan-zhang-announced-a-way-to-spoof-classically-simulate-the-googles-quantum-supremacy-circuit/" rel="bookmark">Amazing: Feng Pan and Pan Zhang Announced a Way to “Spoof” (Classically Simulate) the Google’s Quantum Supremacy Circuit!;</a> This work and several related works largely (but not fully) refuted  Google&#8217;s 2019 quantum supremacy claim.</p>
<p><strong>Free will:</strong> <a href="https://gilkalai.wordpress.com/2021/08/18/to-cheer-you-up-in-difficult-times-29-free-will-predictability-and-quantum-computers/" rel="bookmark">To cheer you up in difficult times 29: Free will, predictability and quantum computers</a></p>
<p><strong>A post about my papers</strong>:  <a href="https://gilkalai.wordpress.com/2021/08/05/let-me-tell-you-about-three-of-my-recent-papers/" rel="bookmark">Let me tell you about three of my recent papers;</a></p>
<p><strong>Open problems:</strong> <a href="https://gilkalai.wordpress.com/2021/01/10/open-problem-session-of-huji-combsem-problem-5-gil-kalai-the-3%e1%b5%88-problem/" rel="bookmark">The 3ᵈ problem</a>; <a href="https://gilkalai.wordpress.com/2020/11/25/open-problem-session-of-huji-combsem-problem-1-nati-linial-turan-type-theorems-for-simplicial-complexes/" rel="bookmark">Turan type theorems for simplicial complexes.</a></p>
<p><strong>Are we up for a new polymath project?</strong>: <a href="https://gilkalai.wordpress.com/2021/01/29/possible-future-polymath-projects-2009-2021/" rel="bookmark">Possible future Polymath projects (2009, 2021)</a></p>
<h2>2022 The expectation threshold conjecture</h2>
<p><strong>Blogging from ICM 2022:</strong>  I <a href="https://gilkalai.wordpress.com/category/icm2022/">slowly blogged about various events</a> and lectures from ICM 2022. The most popular post about ICM2022 was about verifying mathematical proofs using computers and especially LEAN: <a href="https://gilkalai.wordpress.com/2022/07/17/icm-2022-kevin-buzzard-the-rise-of-formalism-in-mathematics/" rel="bookmark">ICM 2022. Kevin Buzzard: The Rise of Formalism in Mathematics.</a> I attempted to report on <a href="https://gilkalai.wordpress.com/2022/07/13/icm-2022-langlands-day/" rel="bookmark">ICM 2022: Langlands Day</a> which I followed on Zoom, and I gave a live report from Helsinki on <a href="https://gilkalai.wordpress.com/2022/07/06/icm-2022-awarding-ceremonies-1/" rel="bookmark">ICM 2022 awarding ceremonies (1)</a>.</p>
<p>Because of Russia&#8217;s invasion of Ukraine, the ICM originally planned for St. Petersburg turned into a virtual event, but the opening ceremonies and lectures of the medalists took place with live audience in Helsinki.</p>
<p><a href="https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png"><img loading="lazy" data-attachment-id="23796" data-permalink="https://gilkalai.wordpress.com/2023/01/05/greatest-hits-2015-2022-part-ii/israeli-del2/" data-orig-file="https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png" data-orig-size="1024,637" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="israeli-del2" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=640" class="alignnone  wp-image-23796" src="https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=389&#038;h=242" alt="israeli-del2" width="389" height="242" srcset="https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=389&amp;h=242 389w, https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=778&amp;h=484 778w, https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=150&amp;h=93 150w, https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=300&amp;h=187 300w, https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=768&amp;h=478 768w" sizes="(max-width: 389px) 100vw, 389px" /></a></p>
<p><span style="color: #ff0000">The Israeli delegation to the 2022 general assembly of the IMU. With Tammy Ziegler and Mina Teicher. </span></p>
<p><strong>The mathematical news that caught most attention:</strong>  A conjecture of Jeff Kahn and me is now fully resolved: <a href="https://gilkalai.wordpress.com/2022/04/02/amazing-jinyoung-park-and-huy-tuan-pham-settled-the-expectation-threshold-conjecture/" rel="bookmark">Amazing: Jinyoung Park and Huy Tuan Pham settled the expectation threshold conjecture!</a>  &#8230; and major progress on Frankl&#8217;s conjecture: <a href="https://gilkalai.wordpress.com/2022/11/17/amazing-justin-gilmer-gave-a-constant-lower-bound-for-the-union-closed-sets-conjecture/" rel="bookmark">Amazing: Justin Gilmer gave a constant lower bound for the union-closed sets conjecture</a></p>
<p><strong>Other news</strong>:  <a href="https://gilkalai.wordpress.com/2022/05/20/oliver-janzer-and-benny-sudakov-settled-the-erdos-sauer-problem/" rel="bookmark">Oliver Janzer and Benny Sudakov Settled the Erdős-Sauer Problem; </a> <a href="https://gilkalai.wordpress.com/2022/10/15/boaz-klartag-and-joseph-lehec-the-slice-conjecture-up-to-polylogarithmic-factor/" rel="bookmark">Bo’az Klartag and Joseph Lehec: The Slice Conjecture Up to Polylogarithmic Factor! </a>;</p>
<p><strong>News about polytopes and combinatorial geometry:</strong> <a href="https://gilkalai.wordpress.com/2022/04/29/joshua-hinman-proved-baranys-conjecture-on-face-numbers-of-polytopes-and-lei-xue-proved-a-lower-bound-conjecture-by-grunbaum/" rel="bookmark">Joshua Hinman proved Bárány’s conjecture on face numbers of polytopes, and Lei Xue proved a lower bound conjecture by Grünbaum; </a><a href="https://gilkalai.wordpress.com/2022/10/19/james-davies-every-finite-colouring-of-the-plane-contains-a-monochromatic-pair-of-points-at-an-odd-distance-from-each-other/" rel="bookmark">James Davies: Every finite colouring of the plane contains a monochromatic pair of points at an odd distance from each other.</a>; <a href="https://gilkalai.wordpress.com/2022/03/05/chaim-even-zohar-tsviqa-lakrec-and-ran-tessler-present-the-amplituhedron-bcfw-triangulation/" rel="bookmark">Chaim Even-Zohar, Tsviqa Lakrec, and Ran Tessler present: The Amplituhedron BCFW Triangulation</a>; <a href="https://gilkalai.wordpress.com/2022/08/19/alexander-a-gaifullin-many-27-vertex-triangulations-of-manifolds-like-the-octonionic-projective-plane-not-even-one-was-known-before/" rel="bookmark">Alexander A. Gaifullin: Many 27-vertex Triangulations of Manifolds Like the Octonionic Projective Plane (Not Even One Was Known Before).</a></p>
<p><strong>Quantum matters:</strong>  <a href="https://gilkalai.wordpress.com/2022/11/05/inaugural-address-at-the-hungarian-academy-of-science-the-quantum-computer-a-miracle-or-mirage/" rel="bookmark">Inaugural address at the Hungarian Academy of Science: The Quantum Computer – A Miracle or Mirage</a>;</p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T11:01:54Z">Thursday, January 05 2023, 11:01</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=6957'>Cargo Cult Quantum Factoring</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Just days after we celebrated my wife&#8217;s 40th birthday, she came down with COVID, meaning she&#8217;s been isolating and I&#8217;ve been spending almost all my time dealing with our kids. But if experience has taught me anything, it&#8217;s that the quantum hype train never slows down. In the past 24 hours, at least four people [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Just days after we celebrated <a href="https://scottaaronson.blog/?p=6946">my wife&#8217;s 40th birthday</a>, she came down with COVID, meaning she&#8217;s been isolating and I&#8217;ve been spending almost all my time dealing with our kids.</p>



<p>But if experience has taught me anything, it&#8217;s that the quantum hype train never slows down.  In the past 24 hours, at least four people have emailed to ask me about a <a href="https://arxiv.org/abs/2212.12372">new paper</a> entitled &#8220;Factoring integers with sublinear resources on a superconducting quantum processor.&#8221;  Even the security expert Bruce Schneier, while skeptical, took the paper <a href="https://www.schneier.com/blog/archives/2023/01/breaking-rsa-with-a-quantum-computer.html">surprisingly seriously</a>.</p>



<p>The paper claims &#8230; well, it&#8217;s hard to pin down what it claims, but it&#8217;s certainly <em>given many people the impression</em> that there&#8217;s been a decisive advance on how to factor huge integers, and thereby break the RSA cryptosystem, using a near-term quantum computer.  <em>Not</em> by using <a href="https://en.wikipedia.org/wiki/Shor%27s_algorithm">Shor&#8217;s Algorithm</a>, mind you, but by using the deceptively similarly named <a href="https://link.springer.com/chapter/10.1007/3-540-46416-6_24">Schnorr&#8217;s Algorithm</a>.  The latter is a classical algorithm based on lattices, which the authors then &#8220;enhance&#8221; using the heuristic quantum optimization method called <a href="https://arxiv.org/abs/1411.4028">QAOA</a>.</p>



<p>For those who don&#8217;t care to read further, here is my 3-word review:</p>



<h2>No.  Just No.</h2>



<p>And here&#8217;s my slightly longer review:</p>



<p><em>Schnorr ≠ Shor</em>.  Yes, even when Schnorr&#8217;s algorithm is dubiously “enhanced” using QAOA&#8212;a quantum algorithm that, incredibly, for all the hundreds of papers written about it, has not yet been convincingly argued to yield any speedup for any problem whatsoever (besides, as it were, the problem of <a href="https://arxiv.org/abs/1602.07674">reproducing its own pattern of errors</a>) (<a href="https://arxiv.org/abs/2208.06909">one possible recent exception</a> from Sami Boulebnane and Ashley Montanaro).</p>



<p>In the new paper, the authors spend page after page saying-without-saying that it <em>might</em> soon become possible to break RSA-2048, using a NISQ (i.e., non-fault-tolerant) quantum computer.  They do so via two time-tested strategems:</p>



<ol>
<li>the detailed exploration of irrelevancies (mostly, optimization of the number of <em>qubits</em>, while ignoring the number of <em>gates</em>), and</li>



<li>complete silence about the <strong>one crucial point</strong>.</li>
</ol>



<p>Then, finally, they come clean about the one crucial point in a single sentence of the Conclusion section:</p>



<blockquote class="wp-block-quote">
<p>It should be pointed out that the quantum speedup of the algorithm is unclear due to the ambiguous convergence of QAOA.</p>
</blockquote>



<p>“Unclear” is an understatement here.  It seems to me that a miracle would be required for the approach here to yield any benefit at all, compared to just running the classical Schnorr&#8217;s algorithm on your laptop.  And if the latter were able to break RSA, it would&#8217;ve already done so.</p>



<p>All told, this is one of the most actively misleading quantum computing papers I’ve seen in 25 years, and I’ve seen &#8230; many.  Having said that, this actually <em>isn&#8217;t</em> the first time I&#8217;ve encountered the strange idea that the exponential quantum speedup for factoring integers, which we know about from Shor’s algorithm, should somehow “rub off” onto quantum optimization heuristics that embody none of the actual insights of Shor&#8217;s algorithm, as if by sympathetic magic.  Since this idea needs a name, I&#8217;d hereby like to propose <strong>Cargo Cult Quantum Factoring</strong>.</p>



<p>And with that, I feel I&#8217;ve adequately discharged my duties here to sanity and truth.  If I&#8217;m slow to answer comments, it&#8217;ll be because I&#8217;m dealing with two screaming kids.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T05:06:20Z">Thursday, January 05 2023, 05:06</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://decentralizedthoughts.github.io/2023-01-05-player-replaceability-II/'>Player Replaceability - Towards Adaptive Security and Sub-quadratic Communication Simultaneously (Part II)</a></h3>
        <p class='tr-article-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This is part II of a two-part post on player-replaceability. Part I can be found here. Towards Adaptive Security for a Committee-based Protocol The protocol described in the previous post achieved sub-quadratic communication. At a high-level, the key idea is to randomly sample an appropriate number parties in a committee,...
        
        </div>

        <div class='tr-article-summary'>
        
          
          This is part II of a two-part post on player-replaceability. Part I can be found here. Towards Adaptive Security for a Committee-based Protocol The protocol described in the previous post achieved sub-quadratic communication. At a high-level, the key idea is to randomly sample an appropriate number parties in a committee,...
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T05:00:00Z">Thursday, January 05 2023, 05:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://decentralizedthoughts.github.io/2023-01-05-player-replaceability-I/'>Player Replaceability - Towards Adaptive Security and Sub-quadratic Communication Simultaneously (Part I)</a></h3>
        <p class='tr-article-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This is part I of a two-part post on the concept of player-replaceability. In Nakamoto consensus, proof-of-work (PoW) provides us with an interesting set of properties with respect to the adaptivity of the adversary: Unpredictability. Block winners are elected uniformly at random proportional to their computation power, thus, an adversary...
        
        </div>

        <div class='tr-article-summary'>
        
          
          This is part I of a two-part post on the concept of player-replaceability. In Nakamoto consensus, proof-of-work (PoW) provides us with an interesting set of properties with respect to the adaptivity of the adversary: Unpredictability. Block winners are elected uniformly at random proportional to their computation power, thus, an adversary...
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T05:00:00Z">Thursday, January 05 2023, 05:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01589'>Quantum Feasibility Labeling for NP-complete Vertex Coloring Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Junpeng Zhan</p><p>Many important science and engineering problems can be converted into
NP-complete problems which are of significant importance in computer science
and mathematics. Currently, neither existing classical nor quantum algorithms
can solve these problems in polynomial time. To overcome this difficulty, this
paper proposes a quantum feasibility labeling (QFL) algorithm to label all
possible solutions to the vertex coloring problem, which is a well-known
NP-complete problem. The variational quantum search (VQS) algorithm proposed in
my previous work has been demonstrated, up to 26 qubits, to achieve an
exponential speedup in finding good element(s) from an unstructured database.
Using the labels and the associated possible solutions as input, the VQS can
find all feasible solutions to the vertex coloring problem. The number of
qubits and the circuit depth required by the QFL each is a polynomial function
of the number of vertices, the number of edges, and the number of colors of a
vertex coloring problem. The QFL together with the VQS could be the first
algorithm to solve an NP-complete problem in polynomial time, provided that the
VQS is proved to be efficient for any number of qubits.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Zhan_J/0/1/0/all/0/1">Junpeng Zhan</a></p><p>Many important science and engineering problems can be converted into
NP-complete problems which are of significant importance in computer science
and mathematics. Currently, neither existing classical nor quantum algorithms
can solve these problems in polynomial time. To overcome this difficulty, this
paper proposes a quantum feasibility labeling (QFL) algorithm to label all
possible solutions to the vertex coloring problem, which is a well-known
NP-complete problem. The variational quantum search (VQS) algorithm proposed in
my previous work has been demonstrated, up to 26 qubits, to achieve an
exponential speedup in finding good element(s) from an unstructured database.
Using the labels and the associated possible solutions as input, the VQS can
find all feasible solutions to the vertex coloring problem. The number of
qubits and the circuit depth required by the QFL each is a polynomial function
of the number of vertices, the number of edges, and the number of colors of a
vertex coloring problem. The QFL together with the VQS could be the first
algorithm to solve an NP-complete problem in polynomial time, provided that the
VQS is proved to be efficient for any number of qubits.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01676'>New Lower Bounds against Homogeneous Non-Commutative Circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prerona Chatterjee, Pavel Hrube&#x161;</p><p>We give several new lower bounds on size of homogeneous non-commutative
circuits. We present an explicit homogeneous bivariate polynomial of degree $d$
which requires homogeneous non-commutative circuit of size $\Omega(d/\log d)$.
For an $n$-variate polynomial with $n&gt;1$, the result can be improved to
$\Omega(nd)$, if $d\leq n$, or $\Omega(nd \frac{\log n}{\log d})$, if $d\geq
n$.
</p>
<p>Under the same assumptions, we also give a quadratic lower bound for the
ordered version of the central symmetric polynomial.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_P/0/1/0/all/0/1">Prerona Chatterjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hrubes_P/0/1/0/all/0/1">Pavel Hrube&#x161;</a></p><p>We give several new lower bounds on size of homogeneous non-commutative
circuits. We present an explicit homogeneous bivariate polynomial of degree $d$
which requires homogeneous non-commutative circuit of size $\Omega(d/\log d)$.
For an $n$-variate polynomial with $n&gt;1$, the result can be improved to
$\Omega(nd)$, if $d\leq n$, or $\Omega(nd \frac{\log n}{\log d})$, if $d\geq
n$.
</p>
<p>Under the same assumptions, we also give a quadratic lower bound for the
ordered version of the central symmetric polynomial.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01696'>Parameterised and Fine-grained Subgraph Counting, modulo $2$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Leslie Ann Goldberg, Marc Roth</p><p>Given a class of graphs $\mathcal{H}$, the problem
$\oplus\mathsf{Sub}(\mathcal{H})$ is defined as follows. The input is a graph
$H\in \mathcal{H}$ together with an arbitrary graph $G$. The problem is to
compute, modulo $2$, the number of subgraphs of $G$ that are isomorphic to $H$.
The goal of this research is to determine for which classes $\mathcal{H}$ the
problem $\oplus\mathsf{Sub}(\mathcal{H})$ is fixed-parameter tractable (FPT),
i.e., solvable in time $f(|H|)\cdot |G|^{O(1)}$.
</p>
<p>Curticapean, Dell, and Husfeldt (ESA 2021) conjectured that
$\oplus\mathsf{Sub}(\mathcal{H})$ is FPT if and only if the class of allowed
patterns $\mathcal{H}$ is "matching splittable", which means that for some
fixed $B$, every $H \in \mathcal{H}$ can be turned into a matching (a graph in
which every vertex has degree at most $1$) by removing at most $B$ vertices.
</p>
<p>Assuming the randomised Exponential Time Hypothesis, we prove their
conjecture for (I) all hereditary pattern classes $\mathcal{H}$, and (II) all
tree pattern classes, i.e., all classes $\mathcal{H}$ such that every $H\in
\mathcal{H}$ is a tree.
</p>
<p>We also establish almost tight fine-grained upper and lower bounds for the
case of hereditary patterns (I).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goldberg_L/0/1/0/all/0/1">Leslie Ann Goldberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_M/0/1/0/all/0/1">Marc Roth</a></p><p>Given a class of graphs $\mathcal{H}$, the problem
$\oplus\mathsf{Sub}(\mathcal{H})$ is defined as follows. The input is a graph
$H\in \mathcal{H}$ together with an arbitrary graph $G$. The problem is to
compute, modulo $2$, the number of subgraphs of $G$ that are isomorphic to $H$.
The goal of this research is to determine for which classes $\mathcal{H}$ the
problem $\oplus\mathsf{Sub}(\mathcal{H})$ is fixed-parameter tractable (FPT),
i.e., solvable in time $f(|H|)\cdot |G|^{O(1)}$.
</p>
<p>Curticapean, Dell, and Husfeldt (ESA 2021) conjectured that
$\oplus\mathsf{Sub}(\mathcal{H})$ is FPT if and only if the class of allowed
patterns $\mathcal{H}$ is "matching splittable", which means that for some
fixed $B$, every $H \in \mathcal{H}$ can be turned into a matching (a graph in
which every vertex has degree at most $1$) by removing at most $B$ vertices.
</p>
<p>Assuming the randomised Exponential Time Hypothesis, we prove their
conjecture for (I) all hereditary pattern classes $\mathcal{H}$, and (II) all
tree pattern classes, i.e., all classes $\mathcal{H}$ such that every $H\in
\mathcal{H}$ is a tree.
</p>
<p>We also establish almost tight fine-grained upper and lower bounds for the
case of hereditary patterns (I).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01318'>Implicitization of Biquadratic B\'ezier Triangle and Quadrilateral Surfaces</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jackson Borchardt, Saul Kato</p><p>We produce implicit equations for general biquadratic (order 2x2) B\'ezier
triangle and quadrilateral surface patches and provide function evaluation
code, using modern computing resources to exploit old algebraic construction
techniques.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Borchardt_J/0/1/0/all/0/1">Jackson Borchardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Kato_S/0/1/0/all/0/1">Saul Kato</a></p><p>We produce implicit equations for general biquadratic (order 2x2) B\'ezier
triangle and quadrilateral surface patches and provide function evaluation
code, using modern computing resources to exploit old algebraic construction
techniques.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01394'>Large Matchings in Maximal 1-planar graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Therese Biedl, John Wittnebel</p><p>It is well-known that every maximal planar graph has a matching of size at
least $\tfrac{n+8}{3}$ if $n\geq 14$. In this paper, we investigate similar
matching-bounds for maximal \emph{1-planar} graphs, i.e., graphs that can be
drawn such that every edge has at most one crossing. In particular we show that
every 3-connected simple-maximal 1-planar graph has a matching of size at least
$\tfrac{2n+6}{5}$; the bound decreases to $\tfrac{3n+14}{10}$ if the graph need
not be 3-connected. We also give (weaker) bounds when the graph comes with a
fixed 1-planar drawing or is not simple. All our bounds are tight in the sense
that some graph that satisfies the restrictions has no bigger matching.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Biedl_T/0/1/0/all/0/1">Therese Biedl</a>, <a href="http://arxiv.org/find/math/1/au:+Wittnebel_J/0/1/0/all/0/1">John Wittnebel</a></p><p>It is well-known that every maximal planar graph has a matching of size at
least $\tfrac{n+8}{3}$ if $n\geq 14$. In this paper, we investigate similar
matching-bounds for maximal \emph{1-planar} graphs, i.e., graphs that can be
drawn such that every edge has at most one crossing. In particular we show that
every 3-connected simple-maximal 1-planar graph has a matching of size at least
$\tfrac{2n+6}{5}$; the bound decreases to $\tfrac{3n+14}{10}$ if the graph need
not be 3-connected. We also give (weaker) bounds when the graph comes with a
fixed 1-planar drawing or is not simple. All our bounds are tight in the sense
that some graph that satisfies the restrictions has no bigger matching.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01471'>Freeform Islamic Geometric Patterns</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rebecca Lin, Craig S. Kaplan</p><p>Islamic geometric patterns are a rich and venerable ornamental tradition.
Many classic designs feature periodic arrangements of rosettes: star shapes
surrounded by rings of hexagonal petals. We present a new technique for
generating 'freeform' compositions of rosettes: finite designs that freely mix
rosettes of unusual sizes while retaining the aesthetics of traditional
patterns. We use a circle packing as a scaffolding for developing a patch of
polygons and fill each polygon with a motif based on established constructions
from Islamic art.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1">Rebecca Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaplan_C/0/1/0/all/0/1">Craig S. Kaplan</a></p><p>Islamic geometric patterns are a rich and venerable ornamental tradition.
Many classic designs feature periodic arrangements of rosettes: star shapes
surrounded by rings of hexagonal petals. We present a new technique for
generating 'freeform' compositions of rosettes: finite designs that freely mix
rosettes of unusual sizes while retaining the aesthetics of traditional
patterns. We use a circle packing as a scaffolding for developing a patch of
polygons and fill each polygon with a motif based on established constructions
from Islamic art.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01356'>Provably Fast and Space-Efficient Parallel Biconnectivity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiaojun Dong, Letong Wang, Yan Gu, Yihan Sun</p><p>Biconnectivity is one of the most fundamental graph problems. The canonical
parallel biconnectivity algorithm is the Tarjan-Vishkin algorithm, which has
$O(n+m)$ optimal work (number of operations) and polylogarithmic span (longest
dependent operations) on a graph with $n$ vertices and $m$ edges. However,
Tarjan-Vishkin is not widely used in practice. We believe the reason is the
space-inefficiency (it generates an auxiliary graph with $O(m)$ edges). In
practice, existing parallel implementations are based on breath-first search
(BFS). Since BFS has span proportional to the diameter of the graph, existing
parallel BCC implementations suffer from poor performance on large-diameter
graphs and can be even slower than the sequential algorithm on many real-world
graphs.
</p>
<p>We propose the first parallel biconnectivity algorithm (FAST-BCC) that has
optimal work, polylogarithmic span, and is space-efficient. Our algorithm first
generates a skeleton graph based on any spanning tree of the input graph. Then
we use the connectivity information of the skeleton to compute the
biconnectivity of the original input. All the steps in our algorithm are
highly-parallel. We carefully analyze the correctness of our algorithm, which
is highly non-trivial.
</p>
<p>We implemented FAST-BCC and compared it with existing implementations,
including GBBS, Slota and Madduri's algorithm, and the sequential
Hopcroft-Tarjan algorithm. We ran them on a 96-core machine on 27 graphs,
including social, web, road, $k$-NN, and synthetic graphs, with significantly
varying sizes and edge distributions. FAST-BCC is the fastest on all 27 graphs.
On average (geometric means), FAST-BCC is 5.1$\times$ faster than GBBS, and
3.1$\times$ faster than the best existing baseline on each graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaojun Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Letong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yihan Sun</a></p><p>Biconnectivity is one of the most fundamental graph problems. The canonical
parallel biconnectivity algorithm is the Tarjan-Vishkin algorithm, which has
$O(n+m)$ optimal work (number of operations) and polylogarithmic span (longest
dependent operations) on a graph with $n$ vertices and $m$ edges. However,
Tarjan-Vishkin is not widely used in practice. We believe the reason is the
space-inefficiency (it generates an auxiliary graph with $O(m)$ edges). In
practice, existing parallel implementations are based on breath-first search
(BFS). Since BFS has span proportional to the diameter of the graph, existing
parallel BCC implementations suffer from poor performance on large-diameter
graphs and can be even slower than the sequential algorithm on many real-world
graphs.
</p>
<p>We propose the first parallel biconnectivity algorithm (FAST-BCC) that has
optimal work, polylogarithmic span, and is space-efficient. Our algorithm first
generates a skeleton graph based on any spanning tree of the input graph. Then
we use the connectivity information of the skeleton to compute the
biconnectivity of the original input. All the steps in our algorithm are
highly-parallel. We carefully analyze the correctness of our algorithm, which
is highly non-trivial.
</p>
<p>We implemented FAST-BCC and compared it with existing implementations,
including GBBS, Slota and Madduri's algorithm, and the sequential
Hopcroft-Tarjan algorithm. We ran them on a 96-core machine on 27 graphs,
including social, web, road, $k$-NN, and synthetic graphs, with significantly
varying sizes and edge distributions. FAST-BCC is the fastest on all 27 graphs.
On average (geometric means), FAST-BCC is 5.1$\times$ faster than GBBS, and
3.1$\times$ faster than the best existing baseline on each graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01549'>Matching Using Sufficient Dimension Reduction for Heterogeneity Causal Effect Estimation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Haoran Zhao, Yinghao Zhang, Debo Cheng, Chen Li, Zaiwen Feng</p><p>Causal inference plays an important role in under standing the underlying
mechanisation of the data generation process across various domains. It is
challenging to estimate the average causal effect and individual causal effects
from observational data with high-dimensional covariates due to the curse of
dimension and the problem of data sufficiency. The existing matching methods
can not effectively estimate individual causal effect or solve the problem of
dimension curse in causal inference. To address this challenge, in this work,
we prove that the reduced set by sufficient dimension reduction (SDR) is a
balance score for confounding adjustment. Under the theorem, we propose to use
an SDR method to obtain a reduced representation set of the original covariates
and then the reduced set is used for the matching method. In detail, a
non-parametric model is used to learn such a reduced set and to avoid model
specification errors. The experimental results on real-world datasets show that
the proposed method outperforms the compared matching methods. Moreover, we
conduct an experiment analysis and the results demonstrate that the reduced
representation is enough to balance the imbalance between the treatment group
and control group individuals.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haoran Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinghao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1">Debo Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zaiwen Feng</a></p><p>Causal inference plays an important role in under standing the underlying
mechanisation of the data generation process across various domains. It is
challenging to estimate the average causal effect and individual causal effects
from observational data with high-dimensional covariates due to the curse of
dimension and the problem of data sufficiency. The existing matching methods
can not effectively estimate individual causal effect or solve the problem of
dimension curse in causal inference. To address this challenge, in this work,
we prove that the reduced set by sufficient dimension reduction (SDR) is a
balance score for confounding adjustment. Under the theorem, we propose to use
an SDR method to obtain a reduced representation set of the original covariates
and then the reduced set is used for the matching method. In detail, a
non-parametric model is used to learn such a reduced set and to avoid model
specification errors. The experimental results on real-world datasets show that
the proposed method outperforms the compared matching methods. Moreover, we
conduct an experiment analysis and the results demonstrate that the reduced
representation is enough to balance the imbalance between the treatment group
and control group individuals.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01631'>R\'enyi-Ulam Games and Online Computation with Imperfect Advice</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Spyros Angelopoulos, Shahin Kamali</p><p>We study the nascent setting of online computation with imperfect advice, in
which the online algorithm is enhanced by some prediction encoded in the form
of a possibly erroneous binary string. The algorithm is oblivious to the advice
error, but defines a desired tolerance, namely an upper bound on the number of
erroneous advice bits it can tolerate. This is a model that generalizes the
untrusted advice model [Angelopoulos et al. ITCS 2020], in which the
performance of the algorithm is only evaluated at the extreme values of error
(namely, if the advice has either no errors, or if it is generated
adversarially).
</p>
<p>In this work, we establish connections between games with a lying responder,
also known as R\'enyi-Ulam games, and the design and analysis of online
algorithms with imperfect advice. Specifically, we demonstrate how to obtain
upper and lower bounds on the competitive ratio for well-studied online
problems such as time-series search, online bidding, and fractional knapsack.
Our techniques provide the first lower bounds for online problems in this
model. We also highlight and exploit connections between competitive analysis
with imperfect advice and fault-tolerance in multiprocessor systems. Last, we
show how to waive the dependence on the tolerance parameter, by means of
resource augmentation and robustification.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Angelopoulos_S/0/1/0/all/0/1">Spyros Angelopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamali_S/0/1/0/all/0/1">Shahin Kamali</a></p><p>We study the nascent setting of online computation with imperfect advice, in
which the online algorithm is enhanced by some prediction encoded in the form
of a possibly erroneous binary string. The algorithm is oblivious to the advice
error, but defines a desired tolerance, namely an upper bound on the number of
erroneous advice bits it can tolerate. This is a model that generalizes the
untrusted advice model [Angelopoulos et al. ITCS 2020], in which the
performance of the algorithm is only evaluated at the extreme values of error
(namely, if the advice has either no errors, or if it is generated
adversarially).
</p>
<p>In this work, we establish connections between games with a lying responder,
also known as R\'enyi-Ulam games, and the design and analysis of online
algorithms with imperfect advice. Specifically, we demonstrate how to obtain
upper and lower bounds on the competitive ratio for well-studied online
problems such as time-series search, online bidding, and fractional knapsack.
Our techniques provide the first lower bounds for online problems in this
model. We also highlight and exploit connections between competitive analysis
with imperfect advice and fault-tolerance in multiprocessor systems. Last, we
show how to waive the dependence on the tolerance parameter, by means of
resource augmentation and robustification.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01744'>Dynamic Maintenance of Monotone Dynamic Programs and Applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Monika Henzinger, Stefan Neumann, Harald R&#xe4;cke, Stefan Schmid</p><p>Dynamic programming (DP) is one of the fundamental paradigms in algorithm
design. However, many DP algorithms have to fill in large DP tables,
represented by two-dimensional arrays, which causes at least quadratic running
times and space usages. This has led to the development of improved algorithms
for special cases when the DPs satisfy additional properties like, e.g., the
Monge property or total monotonicity.
</p>
<p>In this paper, we consider a new condition which assumes (among some other
technical assumptions) that the rows of the DP table are monotone. Under this
assumption, we introduce a novel data structure for computing
$(1+\varepsilon)$-approximate DP solutions in near-linear time and space in the
static setting, and with polylogarithmic update times when the DP entries
change dynamically. To the best of our knowledge, our new condition is
incomparable to previous conditions and is the first which allows to derive
dynamic algorithms based on existing DPs. Instead of using two-dimensional
arrays to store the DP tables, we store the rows of the DP tables using
monotone piecewise constant functions. This allows us to store length-$n$ DP
table rows with entries in $[0,W]$ using only polylog$(n,W)$ bits, and to
perform operations, such as $(\min,+)$-convolution or rounding, on these
functions in polylogarithmic time.
</p>
<p>We further present several applications of our data structure. For bicriteria
versions of $k$-balanced graph partitioning and simultaneous source location,
we obtain the first dynamic algorithms with subpolynomial update times, as well
as the first static algorithms using only near-linear time and space.
Additionally, we obtain the currently fastest algorithm for fully dynamic
knapsack.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1">Monika Henzinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_S/0/1/0/all/0/1">Stefan Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Racke_H/0/1/0/all/0/1">Harald R&#xe4;cke</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a></p><p>Dynamic programming (DP) is one of the fundamental paradigms in algorithm
design. However, many DP algorithms have to fill in large DP tables,
represented by two-dimensional arrays, which causes at least quadratic running
times and space usages. This has led to the development of improved algorithms
for special cases when the DPs satisfy additional properties like, e.g., the
Monge property or total monotonicity.
</p>
<p>In this paper, we consider a new condition which assumes (among some other
technical assumptions) that the rows of the DP table are monotone. Under this
assumption, we introduce a novel data structure for computing
$(1+\varepsilon)$-approximate DP solutions in near-linear time and space in the
static setting, and with polylogarithmic update times when the DP entries
change dynamically. To the best of our knowledge, our new condition is
incomparable to previous conditions and is the first which allows to derive
dynamic algorithms based on existing DPs. Instead of using two-dimensional
arrays to store the DP tables, we store the rows of the DP tables using
monotone piecewise constant functions. This allows us to store length-$n$ DP
table rows with entries in $[0,W]$ using only polylog$(n,W)$ bits, and to
perform operations, such as $(\min,+)$-convolution or rounding, on these
functions in polylogarithmic time.
</p>
<p>We further present several applications of our data structure. For bicriteria
versions of $k$-balanced graph partitioning and simultaneous source location,
we obtain the first dynamic algorithms with subpolynomial update times, as well
as the first static algorithms using only near-linear time and space.
Additionally, we obtain the currently fastest algorithm for fully dynamic
knapsack.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, January 04
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/'>Logicians are Everywhere</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          So where were they between 1720 and 1820? Helena Rasiowa was a famous logician from Poland. She visited Case Western Reserve University when I was an undergraduate a million years ago&#8212;in the 1960s. I have always loved mathematical logic. I took undergraduate courses with two famous logicians. Richard Vesley taught me my first logic course [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>So where were they between 1720 and 1820?</em><br />
<font color="#000000"></p>
<p>
Helena Rasiowa was a famous <a href="https://en.wikipedia.org/wiki/Helena_Rasiowa">logician</a> from Poland. She visited Case Western Reserve University when I was an undergraduate a million years ago&#8212;in the 1960s. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/helen/" rel="attachment wp-att-20741"><img data-attachment-id="20741" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/helen/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/helen.jpg?fit=220%2C294&amp;ssl=1" data-orig-size="220,294" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="helen" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/helen.jpg?fit=220%2C294&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/helen.jpg?fit=220%2C294&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/helen.jpg?resize=150%2C200&#038;ssl=1" alt="" width="150" height="200" class="aligncenter wp-image-20741" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/helen.jpg?w=220&amp;ssl=1 220w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/helen.jpg?resize=150%2C200&amp;ssl=1 150w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1" /></a></p>
<p>
I have always loved mathematical logic. I took undergraduate courses with two famous logicians. Richard Vesley taught me my first logic course at Case. I later took an advanced course there, also as an undergraduate, from Rasiowa. Vesley became a Professor in the University at Buffalo mathematics department, where Ken also knew him before he passed away in 2016.</p>
<p>
One of my memories from her class is about a statement. One day in class we were stuck on a tricky insight and we as a class were asking lots of questions. Perhaps too many. She finally said:</p>
<blockquote><p><b> </b> <em> <i>&#8220;You will understand.&#8221;</i> </em>
</p></blockquote>
<p><p>
I still recall this like it happened yesterday. She was eventually right. But at the time we were scared that we might have trouble getting it.</p>
<p>
<p><H2> Logicians Named Lewis Are Everywhere </H2></p>
<p><p>
Rasiowa&#8217;s dissertation was titled <i>Algebraic Treatment of the Functional Calculus of Lewis and Heyting</i>. The names are <a href="https://en.wikipedia.org/wiki/C._I._Lewis">Clarence Lewis</a> and Arend Heyting. Although Lewis was American, he adopted the British habit of going by his initials as C.I. Lewis. This made him confusable with C.S. Lewis, the writer Clive Lewis in this blog&#8217;s style. </p>
<p>
An unrelated Lewis is Harry Lewis, who is an American computer scientist known for his research in logic&#8212;and for books on theoretical computer science, computing, higher education, and technology. He is the Gordon McKay Professor of Computer Science at Harvard University, and was Dean of Harvard College from 1995 to 2003. </p>
<p>
Another logician named Lewis whom I could have known at Princeton was <a href="https://en.wikipedia.org/wiki/David_Lewis_(philosopher)">David Lewis</a>. He is best known in logic for rigorizing <em>counterfactual conditionals</em>. An example he <a href="https://en.wikipedia.org/wiki/David_Lewis_(philosopher)#Counterfactuals_and_modal_realism">gave</a> is, &#8220;if kangaroos had no tails, they would topple over.&#8221; In complexity theory, many results are like, &#8220;if pigs could whistle then horses could fly.&#8221; Scott Aaronson wrote about one such result <a href="https://books.google.com/books?id=pYggAwAAQBAJ&#038;pg=PA86&#038;lpg=PA86&#038;dq=if+donkeys+could+whistle,+then+pigs+could+fly+complexity&#038;source=bl&#038;ots=OcEzjHP2XX&#038;sig=ACfU3U0mWxqt8ShA90_Ni5lSIWhmWAeOMQ&#038;hl=en&#038;sa=X&#038;ved=2ahUKEwiisbbunar8AhVcEGIAHccLCtEQ6AF6BAgtEAM]">here</a>. Maybe we could have used Lewis to organize the logic of these results. </p>
<p>
Lewis is also famous for actuating the condition of the implication &#8220;if a cat could get a published paper then &#8230;&#8221; His pet named Bruce Le Catt was credited for <a href="https://www.tandfonline.com/doi/abs/10.1080/00048408212340581">this article</a> until the journal <a href="https://www.science.org/content/article/philosophy-journal-corrects-35-year-old-article-written-cat">recently</a> corrected it. The Cheshire Cat&#8212;</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/cat/" rel="attachment wp-att-20746"><img data-attachment-id="20746" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/cat/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?fit=224%2C225&amp;ssl=1" data-orig-size="224,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cat" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?fit=224%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?fit=224%2C225&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?resize=150%2C150&#038;ssl=1" alt="" width="150" height="150" class="aligncenter wp-image-20746" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?w=224&amp;ssl=1 224w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">Wikipedia <a href="https://en.wikipedia.org/wiki/Cheshire_Cat">src</a></FONT>
</td>
</tr>
</table>
<p>
&#8212;brings up another logical Lewis: Lewis Carroll. Well, in this blog&#8217;s style he is Charles Dodgson. By whichever name, his work in mathematical logic was <a href="https://iep.utm.edu/lewis-carroll-logic/">substantial</a>.</p>
<p>
Our point is, there have been so many logicians in the past century-plus that we can point to several with the same name. But that was not always the case. There is a previous century-plus when we can find hardly any logicians at all. To explain why this surprises us, we need to go back further, to Gottfried <a href="https://en.wikipedia.org/wiki/Gottfried_Wilhelm_Leibniz">Leibniz</a>.</p>
<p>
<p><H2> Leibniz </H2></p>
<p><p>
Leibniz was of course one of the great mathematicians of all time. He published nothing on formal logic in his lifetime&#8212;he wrote only working drafts. Bertrand Russell claimed that Leibniz had developed logic in his drafts to a level which was reached only two centuries later.</p>
<p>
Harry Lewis wrote a <a href="https://www.amazon.com/Leibniz-Binary-Invention-Computer-Arithmetic-ebook/dp/B09R717JLY">book</a> with Lloyd Strickland titled <i>Leibniz on Binary: The Invention of Computer Arithmetic</i>. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/lewisandstrickland/" rel="attachment wp-att-20744"><img data-attachment-id="20744" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/lewisandstrickland/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/LewisAndStrickland.png?fit=374%2C203&amp;ssl=1" data-orig-size="374,203" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="LewisAndStrickland" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/LewisAndStrickland.png?fit=300%2C163&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/LewisAndStrickland.png?fit=374%2C203&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/LewisAndStrickland.png?resize=226%2C120&#038;ssl=1" alt="" width="226" height="120" class="aligncenter wp-image-20744" data-recalc-dims="1" /></a></p>
<p>
Harry&#8217;s <a href="https://lewis.seas.harvard.edu/">website</a> says about it:</p>
<blockquote><p><b> </b> <em> The definitive edition and translation of 32 of Leibniz&#8217;s works on binary arithmetic. He works out all the arithmetic operations, and realizes that base-16 would be a more usable notation, so invents several different notations for what we now call the hexadecimal digits.</p>
<p>
Leibniz may have been the first computer scientist and information theorist. Early in life, he documented the binary numeral system (base 2), then revisited that system throughout his career. </em>
</p></blockquote>
<p><p>
<a href="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/lei/" rel="attachment wp-att-20743"><img data-attachment-id="20743" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/lei/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/lei.jpg?fit=350%2C500&amp;ssl=1" data-orig-size="350,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lei" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/lei.jpg?fit=210%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/lei.jpg?fit=350%2C500&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/lei.jpg?resize=175%2C250&#038;ssl=1" alt="" width="175" height="250" class="aligncenter wp-image-20743" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/lei.jpg?w=350&amp;ssl=1 350w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/lei.jpg?resize=210%2C300&amp;ssl=1 210w" sizes="(max-width: 175px) 100vw, 175px" data-recalc-dims="1" /></a></p>
<p>
Among testimonials on the book&#8217;s MIT Press <a href="https://mitpress.mit.edu/9780262544344/leibniz-on-binary/">page</a> is this by Donald Knuth:</p>
<blockquote><p><b> </b> <em> &#8220;This book is a model of how the history of computer science and mathematics should be written. Leibniz pointed out the importance of putting ourselves into the place of others, and here we get to put ourselves into the shoes of Leibniz himself, as we&#8217;re treated to dozens of his private notes, carefully translated into idiomatic English and thoroughly explained.&#8221; </em>
</p></blockquote>
<p><p>
The publisher&#8217;s description, echoed on the book&#8217;s Amazon <a href="https://www.amazon.com/Leibniz-Binary-Invention-Computer-Arithmetic/dp/0262544342/">page</a>, chimes in about readability:</p>
<blockquote><p><b> </b> <em> The [translated] texts are prefaced by a lengthy and detailed introductory essay, in which Strickland and Lewis trace Leibniz&#8217;s development of binary, place it in its historical context, and chart its posthumous influence, most notably on shaping our own computer age. </em>
</p></blockquote>
<p>
<p><H2> A Historical Logic Gap? </H2></p>
<p><p>
The &#8220;shaping of the computer age&#8221; seems to have started no earlier than the work of Charles Babbage on mechanical computation beginning in the 1820s. Even so, Babbage&#8217;s <a href="https://en.wikipedia.org/wiki/Difference_engine">Difference Engine</a> dealt only with numerical calculations. It took his later <a href="https://en.wikipedia.org/wiki/Analytical_Engine">Analytical Engine</a> to involve programming logic as we conceive it. </p>
<p>
Ken has had several thoughts along these lines, going back to his graduate student days at Merton College, Oxford University:</p>
<ul>
<li>
The Merton College Library had one half-height stack of mathematics books. Shelved right alongside modern texts&#8212;this was the early 1980s&#8212;was an 1854 first edition of George Boole&#8217;s book <a href="https://en.wikipedia.org/wiki/The_Laws_of_Thought">The Laws of Thought</a>. We refer to <em>Boolean logic</em> and <em>Boolean algebra</em> because of this book. These terms came from a book placed with the moderns, not from the centuries-older books growing out of Aristotle and other Classical-era works that Ken could find in the grand <a href="https://en.wikipedia.org/wiki/Merton_College_Library">Upper Library</a>. This struck Ken as a warp of time. </p>
<li>
Ken says that the watershed for <em>doing computational logic</em> is realizing that NAND and NOR are universal gates. The older name for NAND is the <a href="https://en.wikipedia.org/wiki/Sheffer_stroke">Sheffer stroke</a>, after the American logician Henry Sheffer. But that wasn&#8217;t until <b>1913</b>, when Russell and Alfred Whitehead picked it up. The polymath Charles Peirce had discovered this about NAND and NOR in the 1880s, so NOR is also called the <em>Peirce Arrow</em>. He also conceived electrical implemenation of AND and OR:
</ul>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/peircedrawing1886/" rel="attachment wp-att-20742"><img data-attachment-id="20742" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/peircedrawing1886/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/PeirceDrawing1886.png?fit=537%2C267&amp;ssl=1" data-orig-size="537,267" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PeirceDrawing1886" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/PeirceDrawing1886.png?fit=300%2C149&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/PeirceDrawing1886.png?fit=537%2C267&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/PeirceDrawing1886.png?resize=400%2C200&#038;ssl=1" alt="" width="400" height="200" class="aligncenter wp-image-20742" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/PeirceDrawing1886.png?w=537&amp;ssl=1 537w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/PeirceDrawing1886.png?resize=300%2C149&amp;ssl=1 300w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">Advent of Computers <a href="http://adventofcomputers.weebly.com/boolean-logic-the-core-of-computer-science.html">source</a></FONT>
</td>
</tr>
</table>
<p>The century-plus between Leibniz and Babbage had Leonhard Euler. It had Carl Gauss. It had all the Bernoullis. It had Joseph-Louis Lagrange, Augustin-Louis Cauchy, Adrien-Marie Legendre, Jean-Baptiste Fourier, and Marie-Sophie Germain. But where are the logicians? As we quoted Russell above, Leibniz&#8217;s preliminary work connects only to two centuries later. </p>
<p>
So why the gap? That is the puzzle. One further question is how close Leibniz came to perceiving the universality of NAND and its significance. Harry, who also drew the Peirce drawing to our attention, tells us that Leibniz invented XOR and also wrote bitwise AND for binary strings. Another is how far back the ideas of <a href="https://en.wikipedia.org/wiki/Polish_notation">Polish notation</a> go. Gottlob Frege anticipated it, but that was still in the late 1800s. Polish notation and its reverse form have had enduring value in programming and compilation since <a href="https://en.wikipedia.org/wiki/Jan_Lukasiewicz">Jan &#321;ukasiewicz</a> invented the notation in 1924. Being taught by Rasiowa in the 1960s brought me closer to the origins of these logical fundamentals than I might expect, on historical reflection.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Are you puzzled by the gap? Can you explain it? </p>
<p>
How might history have changed if the French greats had developed Boolean logic? For some jokes, spelling Louis in their names as Lewis might have helped. There are no US Senators named Lewis, though the introducer at Monday&#8217;s Rose Bowl tried to <a href="https://www.msn.com/en-us/sports/ncaafb/football-world-reacts-to-embarrassing-rose-bowl-mistake/">create</a> one. Not jokes: both Leibniz and C.I. Lewis figure in <a href="https://en.wikipedia.org/wiki/David_Lewis_(philosopher)#Realism_about_possible_worlds">this section</a> of Wikipedia&#8217;s bio of David Lewis. Maybe now the rapper <a href="https://en.wikipedia.org/wiki/Louis_Logic">Louis Logic</a> will help people named Louis catch up&#8212;to the logician <a href="https://homepages.math.uic.edu/lhls/">Louise Hay</a>, whom Ken knew when she visited <a href="https://rjlipton.wpcomstaging.com/2021/01/01/peter-m-neumann-1940-2020/">Peter Neumann</a> and others at Oxford.</p>
<p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-04T05:27:13Z">Wednesday, January 04 2023, 05:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00995'>Unconditional Quantum Advantage for Sampling with Shallow Circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adam Bene Watts, Natalie Parham</p><p>Recent work by Bravyi, Gosset, and Koenig showed that there exists a search
problem that a constant-depth quantum circuit can solve, but that any
constant-depth classical circuit with bounded fan-in cannot. They also pose the
question: can we achieve a similar proof of separation for an input-independent
sampling task? In this paper, we show that the answer to this question is yes.
</p>
<p>We introduce a distribution $D_{n}$ and give a constant-depth, $n$ qubit,
quantum circuit that samples from a distribution close to $D_{n}$ in total
variation distance. For any $\delta &lt; 1$ we also prove, unconditionally, that
any classical circuit with bounded fan-in gates that takes as input $n +
n^\delta$ uniformly random bits and produces output close to $D_{n}$ in total
variation distance has depth $\Omega(\log \log n)$. This gives an unconditional
proof that constant-depth quantum circuits can sample from distributions which
can't be reproduced by constant-depth bounded fan-in classical circuits, even
up to additive error.
</p>
<p>The distribution $D_n$ and classical circuit lower bounds are based on work
of Viola, in which he shows a different (but related) distribution cannot be
sampled from approximately by constant-depth bounded fan-in classical circuits.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Watts_A/0/1/0/all/0/1">Adam Bene Watts</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Parham_N/0/1/0/all/0/1">Natalie Parham</a></p><p>Recent work by Bravyi, Gosset, and Koenig showed that there exists a search
problem that a constant-depth quantum circuit can solve, but that any
constant-depth classical circuit with bounded fan-in cannot. They also pose the
question: can we achieve a similar proof of separation for an input-independent
sampling task? In this paper, we show that the answer to this question is yes.
</p>
<p>We introduce a distribution $D_{n}$ and give a constant-depth, $n$ qubit,
quantum circuit that samples from a distribution close to $D_{n}$ in total
variation distance. For any $\delta &lt; 1$ we also prove, unconditionally, that
any classical circuit with bounded fan-in gates that takes as input $n +
n^\delta$ uniformly random bits and produces output close to $D_{n}$ in total
variation distance has depth $\Omega(\log \log n)$. This gives an unconditional
proof that constant-depth quantum circuits can sample from distributions which
can't be reproduced by constant-depth bounded fan-in classical circuits, even
up to additive error.
</p>
<p>The distribution $D_n$ and classical circuit lower bounds are based on work
of Viola, in which he shows a different (but related) distribution cannot be
sampled from approximately by constant-depth bounded fan-in classical circuits.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-04T01:30:00Z">Wednesday, January 04 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00849'>Small-World Formation via Local Information</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Soroush Alamdari</p><p>It is observed that in a society almost anyone is acquainted with almost
anyone else through only a few intermediary links. This is known as the
small-world phenomenon. In this paper we investigate this observation from a
theoretical stand-point by imagining each individual as a greedy agent
satisfying a drive for knowledge by acquiring links that cost to maintain. We
show that in such a setting small-world properties emerge naturally.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alamdari_S/0/1/0/all/0/1">Soroush Alamdari</a></p><p>It is observed that in a society almost anyone is acquainted with almost
anyone else through only a few intermediary links. This is known as the
small-world phenomenon. In this paper we investigate this observation from a
theoretical stand-point by imagining each individual as a greedy agent
satisfying a drive for knowledge by acquiring links that cost to maintain. We
show that in such a setting small-world properties emerge naturally.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-04T01:30:00Z">Wednesday, January 04 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00996'>Transactional Composition of Nonblocking Data Structures</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Wentao Cai, Haosen Wen, Michael L. Scott</p><p>This paper introduces nonblocking transaction composition (NBTC), a new
methodology for atomic composition of nonblocking operations on concurrent data
structures. Unlike previous software transactional memory (STM) approaches,
NBTC leverages the linearizability of existing nonblocking structures, reducing
the number of memory accesses that must be executed together, atomically, to
only one per operation in most cases (these are typically the linearizing
instructions of the constituent operations).
</p>
<p>Our obstruction-free implementation of NBTC, which we call Medley, makes it
easy to transform most nonblocking data structures into transactional
counterparts while preserving their nonblocking liveness and high concurrency.
In our experiments, Medley outperforms Lock-Free Transactional Transform
(LFTT), the fastest prior competing methodology, by 40--170%. The marginal
overhead of Medley's transactional composition, relative to separate operations
performed in succession, is roughly 2.2$\times$.
</p>
<p>For persistent data structures, we observe that failure atomicity for
transactions can be achieved "almost for free" with epoch-based periodic
persistence. Toward that end, we integrate Medley with nbMontage, a general
system for periodically persistent data structures. The resulting txMontage
provides ACID transactions and achieves throughput up to two orders of
magnitude higher than that of the OneFile persistent STM system.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1">Wentao Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1">Haosen Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Scott_M/0/1/0/all/0/1">Michael L. Scott</a></p><p>This paper introduces nonblocking transaction composition (NBTC), a new
methodology for atomic composition of nonblocking operations on concurrent data
structures. Unlike previous software transactional memory (STM) approaches,
NBTC leverages the linearizability of existing nonblocking structures, reducing
the number of memory accesses that must be executed together, atomically, to
only one per operation in most cases (these are typically the linearizing
instructions of the constituent operations).
</p>
<p>Our obstruction-free implementation of NBTC, which we call Medley, makes it
easy to transform most nonblocking data structures into transactional
counterparts while preserving their nonblocking liveness and high concurrency.
In our experiments, Medley outperforms Lock-Free Transactional Transform
(LFTT), the fastest prior competing methodology, by 40--170%. The marginal
overhead of Medley's transactional composition, relative to separate operations
performed in succession, is roughly 2.2$\times$.
</p>
<p>For persistent data structures, we observe that failure atomicity for
transactions can be achieved "almost for free" with epoch-based periodic
persistence. Toward that end, we integrate Medley with nbMontage, a general
system for periodically persistent data structures. The resulting txMontage
provides ACID transactions and achieves throughput up to two orders of
magnitude higher than that of the OneFile persistent STM system.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-04T01:30:00Z">Wednesday, January 04 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01068'>Fast Parallel Algorithms for Enumeration of Simple, Temporal, and Hop-Constrained Cycles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jovan Blanu&#x161;a (1 and 2), Kubilay Atasu (1), Paolo Ienne (2) ((1) IBM Research Europe - Zurich, (2) &#xc9;cole Polytechnique F&#xe9;d&#xe9;rale de Lausanne)</p><p>Finding cycles in directed graphs enables important applications in various
domains such as finance, biology, chemistry, and network science. However, as
the size of graph datasets continues to grow, it becomes increasingly difficult
to discover cycles within them, which necessitates more efficient algorithms
and their parallel implementations. In this work, we propose scalable
parallelisation of state-of-the-art sequential algorithms for enumerating
simple, temporal, and hop-constrained cycles. First, we focus on the simple
cycle enumeration problem and parallelise the algorithms by Johnson and by Read
and Tarjan in a fine-grained manner. We theoretically show that our resulting
fine-grained parallel algorithms are scalable, with the fine-grained parallel
Read-Tarjan algorithm being strongly scalable. In contrast, we show that
straightforward coarse-grained parallel versions of these simple cycle
enumeration algorithms that exploit edge- or vertex-level parallelism are not
scalable. Next, we adapt our fine-grained approach to enable scalable
parallelisation of state-of-the-art algorithms for temporal and hop-constrained
cycle enumeration. Our evaluation on a cluster with 256 physical cores
demonstrates a near-linear scalability of our fine-grained parallel algorithms
when enumerating all the aforementioned types of cycles. On the same cluster,
our fine-grained parallel algorithms achieve, on average, one order of
magnitude speedup compared to the respective coarse-grained parallel versions
of the state-of-the-art algorithms for cycle enumeration. The performance gap
between the fine-grained and the coarse-grained parallel algorithms increases
as we use more CPU cores.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blanusa_J/0/1/0/all/0/1">Jovan Blanu&#x161;a</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Atasu_K/0/1/0/all/0/1">Kubilay Atasu</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Ienne_P/0/1/0/all/0/1">Paolo Ienne</a> (2) ((1) IBM Research Europe - Zurich, (2) &#xc9;cole Polytechnique F&#xe9;d&#xe9;rale de Lausanne)</p><p>Finding cycles in directed graphs enables important applications in various
domains such as finance, biology, chemistry, and network science. However, as
the size of graph datasets continues to grow, it becomes increasingly difficult
to discover cycles within them, which necessitates more efficient algorithms
and their parallel implementations. In this work, we propose scalable
parallelisation of state-of-the-art sequential algorithms for enumerating
simple, temporal, and hop-constrained cycles. First, we focus on the simple
cycle enumeration problem and parallelise the algorithms by Johnson and by Read
and Tarjan in a fine-grained manner. We theoretically show that our resulting
fine-grained parallel algorithms are scalable, with the fine-grained parallel
Read-Tarjan algorithm being strongly scalable. In contrast, we show that
straightforward coarse-grained parallel versions of these simple cycle
enumeration algorithms that exploit edge- or vertex-level parallelism are not
scalable. Next, we adapt our fine-grained approach to enable scalable
parallelisation of state-of-the-art algorithms for temporal and hop-constrained
cycle enumeration. Our evaluation on a cluster with 256 physical cores
demonstrates a near-linear scalability of our fine-grained parallel algorithms
when enumerating all the aforementioned types of cycles. On the same cluster,
our fine-grained parallel algorithms achieve, on average, one order of
magnitude speedup compared to the respective coarse-grained parallel versions
of the state-of-the-art algorithms for cycle enumeration. The performance gap
between the fine-grained and the coarse-grained parallel algorithms increases
as we use more CPU cores.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-04T01:30:00Z">Wednesday, January 04 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01084'>Reducing Maximum Weighted Matching to the Largest Cardinality Matching in CONGEST</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vahan Mkrtchyan</p><p>In this paper, we reduce the maximum weighted matching problem to the largest
cardinality matching in {\bf CONGEST}. The paper presents two technical
contributions. The first of them is a simple $poly(\log n,
\frac{1}{\varepsilon}, t, \ln w_t)$-round {\bf CONGEST} algorithm for reducing
the maximum weighted matching problem to the largest cardinality matching
problem. This is achieved under the assumption that all vertices know all
edge-weights $\{w_1,....,w_t\}$ (in particular, they know $t$, the number of
different edge-weights), though a particular vertex may not know the weight of
a particular edge. Our second ingredient is a simple rounding algorithm
(similar to approximation algorithms for the bin packing problem) allowing to
reduce general instances of the maximum weighted matching problem to ones
satisfying the assumptions of the first ingredient, in which $t\leq poly'(\log
n, \frac{1}{\varepsilon})$. We end the paper with a brief discussion of
implementing our algorithms in {\bf CONGEST}. Our main conclusion is that we
just need constant rounds for the reduction.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mkrtchyan_V/0/1/0/all/0/1">Vahan Mkrtchyan</a></p><p>In this paper, we reduce the maximum weighted matching problem to the largest
cardinality matching in {\bf CONGEST}. The paper presents two technical
contributions. The first of them is a simple $poly(\log n,
\frac{1}{\varepsilon}, t, \ln w_t)$-round {\bf CONGEST} algorithm for reducing
the maximum weighted matching problem to the largest cardinality matching
problem. This is achieved under the assumption that all vertices know all
edge-weights $\{w_1,....,w_t\}$ (in particular, they know $t$, the number of
different edge-weights), though a particular vertex may not know the weight of
a particular edge. Our second ingredient is a simple rounding algorithm
(similar to approximation algorithms for the bin packing problem) allowing to
reduce general instances of the maximum weighted matching problem to ones
satisfying the assumptions of the first ingredient, in which $t\leq poly'(\log
n, \frac{1}{\varepsilon})$. We end the paper with a brief discussion of
implementing our algorithms in {\bf CONGEST}. Our main conclusion is that we
just need constant rounds for the reduction.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-04T01:30:00Z">Wednesday, January 04 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, January 03
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/01/03/memento-and-large-language-models/'>Memento and Large Language Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          [Mild spoilers for the 2000 film Memento. See this doc for the full ChatGPT transcripts. &#8211;Boaz] Leonard Shelbey, the protagonist of Christopher Nolan&#8217;s film &#8220;Memento&#8220;, suffers from anterograde amnesia. He remembers everything up to the time in which he was the victim of a violent attack, but cannot form new memories after that. He uses &#8230; Continue reading Memento and Large Language&#160;Models
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><em>[Mild spoilers for the 2000 film <a href="https://en.wikipedia.org/wiki/Memento_(film)">Memento</a>. See <a href="https://docs.google.com/document/d/1-yNQgFiEjY_Q0llmN9LUt4HKD_Ag5xHTFWqb-Idqyiw/edit?usp=sharing">this doc</a> for the full ChatGPT transcripts. &#8211;Boaz]</em></p>



<p>Leonard Shelbey, the protagonist of Christopher Nolan&#8217;s film &#8220;<a href="https://www.imdb.com/title/tt0209144/">Memento</a>&#8220;, suffers from <a href="https://en.wikipedia.org/wiki/Anterograde_amnesia">anterograde amnesia</a>. He remembers everything up to the time in which he was the victim of a violent attack, but cannot form new memories after that. He uses notes, polaroid photos, and tattoos to communicate the most important facts to his future self. (See also Suzanne Corkin&#8217;s book <a href="https://www.amazon.com/Permanent-Present-Tense-Unforgettable-Amnesic/dp/0465031595">&#8220;Permanent Present Tense&#8221;</a> for the real-life story of &#8220;Patient H.M.&#8221; &#8211; Henry Molaison &#8211; who suffered from anterograde and retrograde amnesia.)</p>



<p>Large language models such as the one powering <a href="https://openai.com/blog/chatgpt/">ChatGPT</a> can be thought of as suffering from a similar affliction. They remember everything up to the point at which their training stopped. After that, in inference, they can get X tokens (which roughly correspond to 0.75X words) and produce Y tokens as output, with X+Y ≤ 2048. In particular, this means that they can only remember a very short context of less than 2000 words, and cannot recall it after it&#8217;s done.</p>



<p>For example, if we ask ChatGPT to describe an event that happened after its training ended in 2021, it will either refuse or simply &#8220;fib&#8221;, as it does when given the query:</p>



<blockquote class="wp-block-quote">
<p><strong>Q: </strong>Write a poem about the World Cup final game in Qatar</p>
</blockquote>



<blockquote class="wp-block-quote">
<p><strong>ChatGPT: </strong> <br>In Qatar, the final game<br>Of the World Cup takes place<br>The best teams from around the world<br>Come face to face</p>



<p>The heat is on, the tension high<br>As players take the field<br>A nation&#8217;s pride is on the line<br>Their fate, to be revealed</p>



<p>The crowd is wild, the atmosphere electric<br>As the ball is kicked to start<br>Two teams, determined to emerge victorious<br>With all their skill and heart</p>



<p>The game is fast, the play intense<br>As goals are scored, and missed<br>But in the end, there can be only one<br>The victor&#8217;s flag, is kissed</p>



<p>The World Cup final, a momentous occasion<br>A spectacle for all to see<br>A celebration of the beautiful game<br>In Qatar, so grand and grandiose</p>
</blockquote>



<p>ChatGPT has no clue what happened in the game, and so just makes it up. However, if we search &#8220;World Cup final game in Qatar&#8221; on Google, the first result is the <a href="https://en.wikipedia.org/wiki/2022_FIFA_World_Cup_final">Wikipedia page</a>. If we ask ChatGPT to summarize it, then it provides us with the following summary:</p>



<blockquote class="wp-block-quote">
<p><strong>ChatGPT:</strong> The 2022 FIFA World Cup final was a football match played on 18 December 2022 at the Lusail Stadium in Lusail, Qatar, between Argentina and France. Argentina won the match 4-2 in a penalty shootout after the match ended 3-3 after extra time. The match was refereed by Szymon Marciniak from Poland and was attended by 88,966 spectators. Argentina and France had both progressed to the final by finishing first in their respective groups, and then defeating Australia, the Netherlands, Croatia, Poland, England, and Morocco in the subsequent knockout rounds. The final was marked by goals from Lionel Messi and Ángel Di María for Argentina, and a hat-trick from Kylian Mbappé for France.</p>
</blockquote>



<p>We can now use this summary as a &#8220;memento&#8221; for the model, making the query: &#8220;<strong>Background: (the summary above) Task:  Write a poem about the World Cup final game in Qatar</strong>&#8220;. </p>



<p>Now the response is much more informative</p>



<blockquote class="wp-block-quote">
<p><strong>ChatGPT:</strong><br>The World Cup final in Qatar,<br>A match that will surely inspire.<br>Argentina and France,<br>Two nations that dance,<br>On the pitch they&#8217;ll set the world on fire.<br><br>The Lusail Stadium is the stage,<br>Where the best from across the globe convene.<br>The tension is high,<br>As the teams take to the sky,<br>In search of the ultimate dream.</p>



<p>Lionel Messi and Ángel Di María,<br>For Argentina they shine.<br>Kylian Mbappé for France,<br>A hat-trick he&#8217;ll advance,<br>In a game that will forever entwine.</p>



<p>The final goes to extra time,<br>As the two teams battle neck and neck.<br>But in the end, it&#8217;s Argentina who prevails,<br>In a penalty shootout they won&#8217;t fail,<br>As they lift the trophy, the ultimate check.</p>



<p>The World Cup final in Qatar,<br>A memory that will last forever.<br>Argentina the champions,<br>Their talent and their valor,<br>A victory they&#8217;ll always treasure.</p>
</blockquote>



<p>The &#8220;amnesia&#8221; suffered by large language models is also manifested by their propensity to output responses that <em>look<strong> </strong></em>correct but are actually wrong.  For example, if we ask ChatGPT the following &#8220;unfair&#8221; question:</p>



<blockquote class="wp-block-quote">
<p><strong>Q: </strong>Prove that there is a finite number of prime numbers</p>
</blockquote>



<p>Then it dutifully responds as follows:</p>



<blockquote class="wp-block-quote">
<p><strong>ChatGPT: </strong>There is no known way to prove that there is a finite number of prime numbers, but it is generally believed to be true. This is because the number of prime numbers is not infinite, and in fact, it is thought to be quite small compared to the total number of integers. For example, there are only about 50 prime numbers less than 1000.</p>



<p>One reason that it is believed that there are only a finite number of prime numbers is the fact that the prime numbers thin out as you go further along the number line. In other words, the proportion of prime numbers to total numbers decreases as the numbers get larger. For example, there are 25 prime numbers less than 100, but only 21 prime numbers between 100 and 200. This suggests that the number of prime numbers may become negligible as the numbers get very large, and thus there may be only a finite number of prime numbers.</p>



<p>Another reason that it is believed that there are only a finite number of prime numbers is the fact that there are many different types of numbers that are not prime, such as composite numbers and perfect numbers. These types of numbers are formed by the multiplication of smaller numbers, and thus it is thought that there must be a point beyond which no more prime numbers can exist.</p>



<p>Overall, while it is not possible to prove that there are only a finite number of prime numbers, it is widely believed to be true based on the observed patterns in the distribution of prime numbers and the existence of other types of numbers that are not prime.</p>
</blockquote>



<p>Even though it&#8217;s completely wrong, the paragraph above might look reasonable to an average person with no knowledge about the prime numbers. This is not an isolated incident. Stackoverflow had to <a href="https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned">ban ChatGPT-produced answers</a> because &#8220;answers which ChatGPT produces have a high rate of being incorrect, [but] they typically look like they might be good.&#8221;</p>



<p>However, large language models have one huge advantage over Leonard Shelbey: they can time travel. Specificially, ChatGPT can figure out the questions that are supposedly answered by its response. It can then query these questions to a search engine (e.g. Google) and use the information to come up with better responses. Specifically, in the context of the &#8220;number of primes&#8221; interaction, if we ask ChatGPT to <strong><em>&#8220;List the questions answered by your response above&#8221;</em></strong> then it responds with the following:</p>



<blockquote class="wp-block-quote">
<p><strong>ChatGPT:</strong><br>1. Is there a finite number of prime numbers?<br>2. What evidence suggests that there may be a finite number of prime numbers?<br>3. Why is it believed that there are only a finite number of prime numbers?</p>
</blockquote>



<p>We now plug the three questions into Google, click on the first links (<a href="https://towardsdatascience.com/proving-the-infinity-of-primes-using-elementary-calculus-3386699801f4#:~:text=The%20number%20of%20primes%20is,is%20known%20as%20Euclid's%20theorem.">this</a>, <a href="https://www.askamathematician.com/2009/10/q-are-there-an-infinite-amount-of-prime-numbers/">this</a>, and <a href="https://math.stackexchange.com/questions/382736/are-all-prime-numbers-finite#:~:text=Every%20prime%20number%20(in%20the,are%20infinitely%20many%20natural%20numbers.">this</a>) and ask ChatGPT to summarize the (first ~1000 words of) these web pages. </p>



<figure class="wp-block-image size-large is-resized"><a href="https://windowsontheory.files.wordpress.com/2023/01/image-2.png"><img loading="lazy" data-attachment-id="8508" data-permalink="https://windowsontheory.org/2023/01/03/memento-and-large-language-models/image-2-3/" data-orig-file="https://windowsontheory.files.wordpress.com/2023/01/image-2.png" data-orig-size="1224,772" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-image-caption="" data-medium-file="https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=300" data-large-file="https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=656" src="https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=1024" alt="" class="wp-image-8508" width="708" height="446" srcset="https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=1024 1024w, https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=708 708w, https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=150 150w, https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=300 300w, https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=768 768w, https://windowsontheory.files.wordpress.com/2023/01/image-2.png 1224w" sizes="(max-width: 708px) 100vw, 708px" /></a></figure>



<p>We then make the following query:</p>



<blockquote class="wp-block-quote">
<p><strong>Q: </strong>Background:</p>



<ol>
<li>The article discusses the concept of prime numbers, which are defined as positive integers that are only divisible by 1 and themselves. The article then presents a proof by Leonhard Euler, using basic calculus, that the number of prime numbers is infinite. The proof involves considering the prime-counting function, which is the number of prime numbers smaller than or equal to a certain value, and comparing the area under a curve representing this function to the area under a step function. The article then goes on to describe the steps of the proof in detail.</li>



<li>The web page discusses the question of whether there are an infinite number of prime numbers. The physicist provides a proof that there are an infinite number of prime numbers by assuming there are a finite number of primes, multiplying them all together and adding 1, and demonstrating that this new number must be a new prime or be divisible by at least one new prime. This means that no matter how many primes exist, there must be at least one more, leading to an infinite number of primes. The physicist notes that there are many other proofs of the infinitude of primes, but this one is likely the simplest.</li>



<li>The webpage discusses the concept of prime numbers and whether they are finite or infinite. Some people believe that there must be a greatest prime number, while others believe that there must be an infinite prime number. It is pointed out that both of these beliefs lead to contradictions, and the idea is raised that the set of all prime numbers may contain all finite elements with no greatest element. The concept of hyperreal numbers and infinite hypernatural numbers is also mentioned as a possible solution to this problem. It is ultimately concluded that every prime number is finite, despite there being an infinite number of them.</li>
</ol>



<p>Task: Prove that there is a finite number of prime numbers</p>
</blockquote>



<p>Given this background, ChatGPT no longer takes the bait:</p>



<blockquote class="wp-block-quote">
<p><strong>ChatGPT: </strong>I&#8217;m sorry, but it is actually not possible to prove that there is a finite number of prime numbers. In fact, the opposite has been proven to be true &#8211; there are an infinite number of prime numbers. This was first demonstrated by Euclid over 2,000 years ago, and many other proofs have been developed since then. One such proof, as mentioned in the given information, is the proof by Leonhard Euler using basic calculus. This proof involves considering the prime-counting function and comparing the area under a curve representing this function to the area under a step function, which ultimately shows that the number of primes is infinite.</p>



<p>It is worth noting that while every prime number is indeed finite, as it is a positive integer, there is an infinite number of them. This means that there is no largest prime number, and there will always be another prime number after any given prime number.</p>
</blockquote>



<p>The above raises a more general question: <em>is &#8220;memento&#8221;-like reasoning sufficient?</em>  Can you perform an arbitrarily complex computation by splitting it up into pieces that only require finite context? Decades of theoretical computer science research say that the answer is &#8220;yes&#8221;. Indeed, this is precisely what is done by a Turing Machine: at a given step, it only processes information based on a finite state and the contents of the memory address that it reads. A more challenging question is whether we can also do this even when there is some chance for error. This is indeed more challenging. However, tools such as error-correcting codes, interactive proofs, probabilistically-checkable proofs, and succinct arguments, can provide reliable computation even under a variety of challenging error models.  Hence at least this is not a fundamental barrier for arbitrarily complex computation.</p>



<p></p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T18:00:13Z">Tuesday, January 03 2023, 18:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2023/01/positional-encoding.html'>Positional Encoding</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Given the excitement over ChatGPT, I spent part of the winter recess trying to understand the underlying technology of Transformers. After trying various tutorials, I found the best explanation comes in the original 2017 paper, Attention is All you Need. This is my attempt to figure out positional encoding in transformers with some naive questions. Let me know if I'm completely off base.</p><p>Earlier models like Recurrent Neural Nets and Convolutional NNs worked under the assumption that information close by was more likely to be correlated. Machine learning seems to improve as the models make fewer and fewer assumptions about the data and transformers use positional data with no predisposed favoritism to nearby inputs.</p><p>The attention paper uses the following encoding for positions. Let α(j) = 10000-j/d where d is the dimension of the input embedding, i.e. the number of numbers used to represent each word of the input. We encode position p as d/2 pairs of numbers cos(p α(j)) and sin(p α(j)), for j ranging from 1 to d/2. They chose this function because relative positions are easy to address. We can address a relative position of a fixed k by a linear combination of cos(p α(j)) and sin(p α(j)) using the addition rules of cos and sin.</p><p>cos ((p+k) α(j)) = cos(k α(j)) cos(p α(j))&nbsp; - sin(k α(j)) sin(p α(j))&nbsp;</p><p>sin ((p+k) α(j)) = cos(k α(j)) sin(p α(j))&nbsp; + sin(k α(j)) cos(p α(j))&nbsp;</p><p>The d-dimensional vector of position encodings is added to the input embedding.</p><p>Why is the position encodings added to the input embedding?</p><p>I scoured the Internet and can't seem to find a good reason for this, other than it seems to work. Wouldn't the linear combinations to handle relative positions muddle up the input embedding? Since the input embedding is learned, perhaps some parts of the embedding are made zero or very small so the positional embedding stands out. Why not concatenate the two, have separate inputs for the input embedding and the positions? You wouldn't need to fully double the dimension since you would no longer need to match the dimension of the input encoding.</p><p>Why not use complex numbers?</p><p>I see cos(p α(j)) and sin(p α(j)) and immediately think of them as the real and imaginary parts of ep α(j) i. So why not just do the positional encodings as complex numbers? This paper&nbsp;suggests multiplying ep α(j) i with the input embedding, i.e., the input is embedding into the amplitude and the position by the phase. That makes more sense. You can now multiply by ep α(k) i to get the relative position j+k without affecting the input embedding.</p><p>I don't see a good reason not to use complex numbers for transformers, given that most learning packages and GPUs can handle complex numbers just fine. Even if you don't want to use complex numbers you could multiply the sin and cos versions of the positional encoding instead of adding to achieve a similar effect.</p><p>How about positional encoding for outputs?</p><p>Transformers output words in order but that makes it harder to relate outputs that are far apart. So why not give positional encoding to the outputs. A post-processor could then put the outputs in the correct order. More generally, how about outputting a program that produces the real output? We know transformers can generate code, and this way can handle operations that transformers normally struggle with, like multiplication or sorting.</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Given the excitement over <a href="https://chat.openai.com/chat">ChatGPT</a>, I spent part of the winter recess trying to understand the underlying technology of Transformers. After trying various tutorials, I found the best explanation comes in the original 2017 paper, <a href="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html">Attention is All you Need</a>. This is my attempt to figure out positional encoding in transformers with some naive questions. Let me know if I'm completely off base.</p><p>Earlier models like Recurrent Neural Nets and Convolutional NNs worked under the assumption that information close by was more likely to be correlated. Machine learning seems to improve as the models make fewer and fewer assumptions about the data and transformers use positional data with no predisposed favoritism to nearby inputs.</p><p>The attention paper uses the following encoding for positions. Let α(j) = 10000<sup>-j/d</sup> where d is the dimension of the input embedding, i.e. the number of numbers used to represent each word of the input. We encode position p as d/2 pairs of numbers cos(p α(j)) and sin(p α(j)), for j ranging from 1 to d/2. They chose this function because relative positions are easy to address. We can address a relative position of a fixed k by a linear combination of cos(p α(j)) and sin(p α(j)) using the addition rules of cos and sin.</p><p>cos ((p+k) α(j)) = cos(k α(j)) cos(p α(j))&nbsp; - sin(k α(j)) sin(p α(j))&nbsp;</p><p>sin ((p+k) α(j)) = cos(k α(j)) sin(p α(j))&nbsp; + sin(k α(j)) cos(p α(j))&nbsp;</p><p>The d-dimensional vector of position encodings is added to the input embedding.</p><p><b>Why is the position encodings added to the input embedding?</b></p><p>I scoured the Internet and can't seem to find a good reason for this, other than it seems to work. Wouldn't the linear combinations to handle relative positions muddle up the input embedding? Since the input embedding is learned, perhaps some parts of the embedding are made zero or very small so the positional embedding stands out. Why not concatenate the two, have separate inputs for the input embedding and the positions? You wouldn't need to fully double the dimension since you would no longer need to match the dimension of the input encoding.</p><p><b>Why not use complex numbers?</b></p><p>I see cos(p α(j)) and sin(p α(j)) and immediately think of them as the real and imaginary parts of e<sup>p α(j) i</sup>. So why not just do the positional encodings as complex numbers? <a href="https://arxiv.org/abs/1912.12333">This paper</a>&nbsp;suggests multiplying e<sup>p α(j) i</sup> with the input embedding, i.e., the input is embedding into the amplitude and the position by the phase. That makes more sense. You can now multiply by e<sup>p α(k) i</sup> to get the relative position j+k without affecting the input embedding.</p><p>I don't see a good reason not to use complex numbers for transformers, given that most learning packages and GPUs can handle complex numbers just fine. Even if you don't want to use complex numbers you could multiply the sin and cos versions of the positional encoding instead of adding to achieve a similar effect.</p><p><b>How about positional encoding for outputs?</b></p><p>Transformers output words in order but that makes it harder to relate outputs that are far apart. So why not give positional encoding to the outputs. A post-processor could then put the outputs in the correct order. More generally, how about outputting a program that produces the real output? We know transformers can generate code, and this way can handle operations that transformers normally struggle with, like multiplication or sorting.</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T14:58:00Z">Tuesday, January 03 2023, 14:58</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://thmatters.wordpress.com/2023/01/02/nsf-program-director-opening-in-algorithmic-foundations-2/'>NSF Program Director opening in Algorithmic Foundations</a></h3>
        <p class='tr-article-feed'>from <a href='https://thmatters.wordpress.com'>Theory Matters</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Serving as a program director at the NSF is one of the most impactful ways of serving the TCS community.  The Algorithmic Foundations Program in NSF/CISE/CCF is currently accepting applications for a permanent Program Director position.  Please consider applying! Apply here by January 12.  Feel free and encouraged to contact the AF group (Tracy Kimbrel, Peter Brass, [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Serving as a program director at the NSF is one of the most impactful ways of serving the TCS community.  The Algorithmic Foundations Program in NSF/CISE/CCF is currently accepting applications for a permanent Program Director position.  Please consider applying!</p>



<p><a rel="noreferrer noopener" href="https://www.usajobs.gov/job/694200200" target="_blank">Apply here</a> by January 12.  Feel free and encouraged to contact the AF group (Tracy Kimbrel, Peter Brass, Funda Ergun) for information.</p>
<p class="authors">By shuchic</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T02:18:42Z">Tuesday, January 03 2023, 02:18</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00104'>Separating Computational and Statistical Differential Privacy (Under Plausible Assumptions)</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Badih Ghazi, Rahul Ilango, Pritish Kamath, Ravi Kumar, Pasin Manurangsi</p><p>Computational differential privacy (CDP) is a natural relaxation of the
standard notion of (statistical) differential privacy (SDP) proposed by Beimel,
Nissim, and Omri (CRYPTO 2008) and Mironov, Pandey, Reingold, and Vadhan
(CRYPTO 2009). In contrast to SDP, CDP only requires privacy guarantees to hold
against computationally-bounded adversaries rather than
computationally-unbounded statistical adversaries. Despite the question being
raised explicitly in several works (e.g., Bun, Chen, and Vadhan, TCC 2016), it
has remained tantalizingly open whether there is any task achievable with the
CDP notion but not the SDP notion. Even a candidate such task is unknown.
Indeed, it is even unclear what the truth could be!
</p>
<p>In this work, we give the first construction of a task achievable with the
CDP notion but not the SDP notion. More specifically, under strong but
plausible cryptographic assumptions, we construct a task for which there exists
an $\varepsilon$-CDP mechanism with $\varepsilon = O(1)$ achieving $1-o(1)$
utility, but any $(\varepsilon, \delta)$-SDP mechanism, including
computationally unbounded ones, that achieves a constant utility must use
either a super-constant $\varepsilon$ or a non-negligible $\delta$. To prove
this, we introduce a new approach for showing that a mechanism satisfies CDP:
first we show that a mechanism is "private" against a certain class of decision
tree adversaries, and then we use cryptographic constructions to "lift" this
into privacy against computational adversaries. We believe this approach could
be useful to devise further tasks separating CDP from SDP.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghazi_B/0/1/0/all/0/1">Badih Ghazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilango_R/0/1/0/all/0/1">Rahul Ilango</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamath_P/0/1/0/all/0/1">Pritish Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Ravi Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1">Pasin Manurangsi</a></p><p>Computational differential privacy (CDP) is a natural relaxation of the
standard notion of (statistical) differential privacy (SDP) proposed by Beimel,
Nissim, and Omri (CRYPTO 2008) and Mironov, Pandey, Reingold, and Vadhan
(CRYPTO 2009). In contrast to SDP, CDP only requires privacy guarantees to hold
against computationally-bounded adversaries rather than
computationally-unbounded statistical adversaries. Despite the question being
raised explicitly in several works (e.g., Bun, Chen, and Vadhan, TCC 2016), it
has remained tantalizingly open whether there is any task achievable with the
CDP notion but not the SDP notion. Even a candidate such task is unknown.
Indeed, it is even unclear what the truth could be!
</p>
<p>In this work, we give the first construction of a task achievable with the
CDP notion but not the SDP notion. More specifically, under strong but
plausible cryptographic assumptions, we construct a task for which there exists
an $\varepsilon$-CDP mechanism with $\varepsilon = O(1)$ achieving $1-o(1)$
utility, but any $(\varepsilon, \delta)$-SDP mechanism, including
computationally unbounded ones, that achieves a constant utility must use
either a super-constant $\varepsilon$ or a non-negligible $\delta$. To prove
this, we introduce a new approach for showing that a mechanism satisfies CDP:
first we show that a mechanism is "private" against a certain class of decision
tree adversaries, and then we use cryptographic constructions to "lift" this
into privacy against computational adversaries. We believe this approach could
be useful to devise further tasks separating CDP from SDP.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00136'>Power of Decision Trees with Monotone Queries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prashanth Amireddy, Sai Jayasurya, Jayalal Sarma</p><p>In this paper, we initiate study of the computational power of adaptive and
non-adaptive monotone decision trees - decision trees where each query is a
monotone function on the input bits. In the most general setting, the monotone
decision tree height (or size) can be viewed as a measure of non-monotonicity
of a given Boolean function. We also study the restriction of the model by
restricting (in terms of circuit complexity) the monotone functions that can be
queried at each node. This naturally leads to complexity classes of the form
DT(mon-C) for any circuit complexity class C, where the height of the tree is
O(log n), and the query functions can be computed by monotone circuits in the
class C. In the above context, we prove the following characterizations and
bounds.
</p>
<p>For any Boolean function f, we show that the minimum monotone decision tree
height can be exactly characterized (both in the adaptive and non-adaptive
versions of the model) in terms of its alternation (alt(f) is defined as the
maximum number of times that the function value changes, in any chain in the
Boolean lattice). We also characterize the non-adaptive decision tree height
with a natural generalization of certification complexity of a function.
Similarly, we determine the complexity of non-deterministic and randomized
variants of monotone decision trees in terms of alt(f).
</p>
<p>We show that DT(mon-C) = C when C contains monotone circuits for the
threshold functions (for e.g., if C = TC0). For C = AC0, we are able to show
that any function in AC0 can be computed by a sub-linear height monotone
decision tree with queries having monotone AC0 circuits. To understand the
logarithmic height case in case of AC0 i.e., DT(mon-AC0), we show that
functions in DT(mon-AC0) have AC0 circuits with few negation gates.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Amireddy_P/0/1/0/all/0/1">Prashanth Amireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayasurya_S/0/1/0/all/0/1">Sai Jayasurya</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarma_J/0/1/0/all/0/1">Jayalal Sarma</a></p><p>In this paper, we initiate study of the computational power of adaptive and
non-adaptive monotone decision trees - decision trees where each query is a
monotone function on the input bits. In the most general setting, the monotone
decision tree height (or size) can be viewed as a measure of non-monotonicity
of a given Boolean function. We also study the restriction of the model by
restricting (in terms of circuit complexity) the monotone functions that can be
queried at each node. This naturally leads to complexity classes of the form
DT(mon-C) for any circuit complexity class C, where the height of the tree is
O(log n), and the query functions can be computed by monotone circuits in the
class C. In the above context, we prove the following characterizations and
bounds.
</p>
<p>For any Boolean function f, we show that the minimum monotone decision tree
height can be exactly characterized (both in the adaptive and non-adaptive
versions of the model) in terms of its alternation (alt(f) is defined as the
maximum number of times that the function value changes, in any chain in the
Boolean lattice). We also characterize the non-adaptive decision tree height
with a natural generalization of certification complexity of a function.
Similarly, we determine the complexity of non-deterministic and randomized
variants of monotone decision trees in terms of alt(f).
</p>
<p>We show that DT(mon-C) = C when C contains monotone circuits for the
threshold functions (for e.g., if C = TC0). For C = AC0, we are able to show
that any function in AC0 can be computed by a sub-linear height monotone
decision tree with queries having monotone AC0 circuits. To understand the
logarithmic height case in case of AC0 i.e., DT(mon-AC0), we show that
functions in DT(mon-AC0) have AC0 circuits with few negation gates.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00370'>Matching upper bounds on symmetric predicates in quantum communication complexity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daiki Suruga</p><p>In this paper, we focus on the quantum communication complexity of functions
of the form $f \circ G = f(G(X_1, Y_1), \ldots, G(X_n, Y_n))$ where $f: \{0,
1\}^n \to \{0, 1\}$ is a symmetric function, $G: \{0, 1\}^j \times \{0, 1\}^k
\to \{0, 1\}$ is any function and Alice (resp. Bob) is given $(X_i)_{i \leq n}$
(resp. $(Y_i)_{i \leq n}$). Recently, Chakraborty et al. [STACS 2022] showed
that the quantum communication complexity of $f \circ G$ is
$O(Q(f)\mathrm{QCC}_\mathrm{E}(G))$ when the parties are allowed to use shared
entanglement, where $Q(f)$ is the query complexity of $f$ and
$\mathrm{QCC}_\mathrm{E}(G)$ is the exact communication complexity of $G$. In
this paper, we first show that the same statement holds \emph{without shared
entanglement}, which generalizes their result. Based on the improved result, we
next show tight upper bounds on $f \circ \mathrm{AND}_2$ for any symmetric
function $f$ (where $\textrm{AND}_2 : \{0, 1\} \times \{0, 1\} \to \{0, 1\}$
denotes the 2-bit AND function) in both models: with shared entanglement and
without shared entanglement. This matches the well-known lower bound by
Razborov~[Izv. Math. 67(1) 145, 2003] when shared entanglement is allowed and
improves Razborov's bound when shared entanglement is not allowed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Suruga_D/0/1/0/all/0/1">Daiki Suruga</a></p><p>In this paper, we focus on the quantum communication complexity of functions
of the form $f \circ G = f(G(X_1, Y_1), \ldots, G(X_n, Y_n))$ where $f: \{0,
1\}^n \to \{0, 1\}$ is a symmetric function, $G: \{0, 1\}^j \times \{0, 1\}^k
\to \{0, 1\}$ is any function and Alice (resp. Bob) is given $(X_i)_{i \leq n}$
(resp. $(Y_i)_{i \leq n}$). Recently, Chakraborty et al. [STACS 2022] showed
that the quantum communication complexity of $f \circ G$ is
$O(Q(f)\mathrm{QCC}_\mathrm{E}(G))$ when the parties are allowed to use shared
entanglement, where $Q(f)$ is the query complexity of $f$ and
$\mathrm{QCC}_\mathrm{E}(G)$ is the exact communication complexity of $G$. In
this paper, we first show that the same statement holds \emph{without shared
entanglement}, which generalizes their result. Based on the improved result, we
next show tight upper bounds on $f \circ \mathrm{AND}_2$ for any symmetric
function $f$ (where $\textrm{AND}_2 : \{0, 1\} \times \{0, 1\} \to \{0, 1\}$
denotes the 2-bit AND function) in both models: with shared entanglement and
without shared entanglement. This matches the well-known lower bound by
Razborov~[Izv. Math. 67(1) 145, 2003] when shared entanglement is allowed and
improves Razborov's bound when shared entanglement is not allowed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00732'>Improved NP-Hardness of Approximation for Orthogonality Dimension and Minrank</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dror Chawin, Ishay Haviv</p><p>The orthogonality dimension of a graph $G$ over $\mathbb{R}$ is the smallest
integer $k$ for which one can assign a nonzero $k$-dimensional real vector to
each vertex of $G$, such that every two adjacent vertices receive orthogonal
vectors. We prove that for every sufficiently large integer $k$, it is
$\mathsf{NP}$-hard to decide whether the orthogonality dimension of a given
graph over $\mathbb{R}$ is at most $k$ or at least $2^{(1-o(1)) \cdot k/2}$. We
further prove such hardness results for the orthogonality dimension over finite
fields as well as for the closely related minrank parameter, which is motivated
by the index coding problem in information theory. This in particular implies
that it is $\mathsf{NP}$-hard to approximate these graph quantities to within
any constant factor. Previously, the hardness of approximation was known to
hold either assuming certain variants of the Unique Games Conjecture or for
approximation factors smaller than $3/2$. The proofs involve the concept of
line digraphs and bounds on their orthogonality dimension and on the minrank of
their complement.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chawin_D/0/1/0/all/0/1">Dror Chawin</a>, <a href="http://arxiv.org/find/cs/1/au:+Haviv_I/0/1/0/all/0/1">Ishay Haviv</a></p><p>The orthogonality dimension of a graph $G$ over $\mathbb{R}$ is the smallest
integer $k$ for which one can assign a nonzero $k$-dimensional real vector to
each vertex of $G$, such that every two adjacent vertices receive orthogonal
vectors. We prove that for every sufficiently large integer $k$, it is
$\mathsf{NP}$-hard to decide whether the orthogonality dimension of a given
graph over $\mathbb{R}$ is at most $k$ or at least $2^{(1-o(1)) \cdot k/2}$. We
further prove such hardness results for the orthogonality dimension over finite
fields as well as for the closely related minrank parameter, which is motivated
by the index coding problem in information theory. This in particular implies
that it is $\mathsf{NP}$-hard to approximate these graph quantities to within
any constant factor. Previously, the hardness of approximation was known to
hold either assuming certain variants of the Unique Games Conjecture or for
approximation factors smaller than $3/2$. The proofs involve the concept of
line digraphs and bounds on their orthogonality dimension and on the minrank of
their complement.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00739'>On the Complexity of Sub-Tree Scheduling for Wireless Sensor Networks with Partial Coverage</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michele Barbato, Nicola Bianchessi</p><p>Given an undirected graph $G$ whose edge weights change over $s$ time slots,
the sub-tree scheduling for wireless sensor networks with partial coverage asks
to partition the vertices of $G$ in $s$ non-empty trees such that the total
weight of the trees is minimized. In this note we show that the problem is
NP-hard in both the cases where $s$ $(i)$ is part of the input and $(ii)$ is a
fixed instance parameter. In both our proofs we reduce from the cardinality
Steiner tree problem. We additionally give polynomial-time algorithms for
structured inputs of the problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Barbato_M/0/1/0/all/0/1">Michele Barbato</a>, <a href="http://arxiv.org/find/cs/1/au:+Bianchessi_N/0/1/0/all/0/1">Nicola Bianchessi</a></p><p>Given an undirected graph $G$ whose edge weights change over $s$ time slots,
the sub-tree scheduling for wireless sensor networks with partial coverage asks
to partition the vertices of $G$ in $s$ non-empty trees such that the total
weight of the trees is minimized. In this note we show that the problem is
NP-hard in both the cases where $s$ $(i)$ is part of the input and $(ii)$ is a
fixed instance parameter. In both our proofs we reduce from the cardinality
Steiner tree problem. We additionally give polynomial-time algorithms for
structured inputs of the problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00806'>The characterization of $\mathbf{(n-1)}$-spheres with $\mathbf{n+4}$ vertices having maximal Buchstaber number</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Suyoung Choi, Hyeontae Jang, Mathieu Vall&#xe9;e</p><p>We provide a GPU-friendly algorithm for obtaining all weak pseudo-manifolds
whose facets are all in an input set of facets satisfying given conditions. We
use it here to completely list up toric colorable seed PL-spheres with a few
vertices implying the complete characterization of PL-spheres of dimension
$n-1$ with $n+4$ vertices having maximal Buchstaber numbers.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Choi_S/0/1/0/all/0/1">Suyoung Choi</a>, <a href="http://arxiv.org/find/math/1/au:+Jang_H/0/1/0/all/0/1">Hyeontae Jang</a>, <a href="http://arxiv.org/find/math/1/au:+Vallee_M/0/1/0/all/0/1">Mathieu Vall&#xe9;e</a></p><p>We provide a GPU-friendly algorithm for obtaining all weak pseudo-manifolds
whose facets are all in an input set of facets satisfying given conditions. We
use it here to completely list up toric colorable seed PL-spheres with a few
vertices implying the complete characterization of PL-spheres of dimension
$n-1$ with $n+4$ vertices having maximal Buchstaber numbers.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00074'>Matrix Multiplication: Verifying Strong Uniquely Solvable Puzzles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Matthew Anderson, Zongliang Ji, Anthony Yang Xu</p><p>Cohn and Umans proposed a framework for developing fast matrix multiplication
algorithms based on the embedding computation in certain groups algebras. In
subsequent work with Kleinberg and Szegedy, they connected this to the search
for combinatorial objects called strong uniquely solvable puzzles (strong
USPs). We begin a systematic computer-aided search for these objects. We
develop and implement constraint-based algorithms build on reductions to
$\mathrm{SAT}$ and $\mathrm{IP}$ to verify that puzzles are strong USPs, and to
search for large strong USPs. We produce tight bounds on the maximum size of a
strong USP for width $k \le 5$, construct puzzles of small width that are
larger than previous work, and improve the upper bounds on strong USP size for
$k \le 12$. Although our work only deals with puzzles of small-constant width,
the strong USPs we find imply matrix multiplication algorithms that run in
$O(n^\omega)$ time with exponent $\omega \le 2.66$. While our algorithms do not
beat the fastest algorithms, our work provides evidence and, perhaps, a path to
finding families of strong USPs that imply matrix multiplication algorithms
that are more efficient than those currently known.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Anderson_M/0/1/0/all/0/1">Matthew Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1">Zongliang Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_A/0/1/0/all/0/1">Anthony Yang Xu</a></p><p>Cohn and Umans proposed a framework for developing fast matrix multiplication
algorithms based on the embedding computation in certain groups algebras. In
subsequent work with Kleinberg and Szegedy, they connected this to the search
for combinatorial objects called strong uniquely solvable puzzles (strong
USPs). We begin a systematic computer-aided search for these objects. We
develop and implement constraint-based algorithms build on reductions to
$\mathrm{SAT}$ and $\mathrm{IP}$ to verify that puzzles are strong USPs, and to
search for large strong USPs. We produce tight bounds on the maximum size of a
strong USP for width $k \le 5$, construct puzzles of small width that are
larger than previous work, and improve the upper bounds on strong USP size for
$k \le 12$. Although our work only deals with puzzles of small-constant width,
the strong USPs we find imply matrix multiplication algorithms that run in
$O(n^\omega)$ time with exponent $\omega \le 2.66$. While our algorithms do not
beat the fastest algorithms, our work provides evidence and, perhaps, a path to
finding families of strong USPs that imply matrix multiplication algorithms
that are more efficient than those currently known.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
