<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-04-17T15:30:23Z">Monday, April 17 2023, 15:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, April 17
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/04/16/schoolbook-error-discovery/'>Schoolbook Error/Discovery</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Liam Squires is a fifth-grader at Virginia&#8217;s HM Pearson Elementary. He is now famous&#8212;after a story that is in print in today&#8217;s Sunday New York Times. Squires saw that the diagrams of igneous and sedimentary rocks had the wrong labels. The book was a &#8220;Level 5&#8221; tome encompassing Earth Science. The book was approved by [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
Liam Squires is a fifth-grader at Virginia&#8217;s HM Pearson Elementary. He is now famous&#8212;after a <a href="https://www.nytimes.com/2023/04/12/us/student-textbook-mistake.html?searchResultPosition=2">story</a> that is in print in today&#8217;s Sunday New York Times. Squires saw that the diagrams of igneous and sedimentary rocks had the wrong labels.</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/16/schoolbook-error-discovery/kid/" rel="attachment wp-att-21466"><img data-attachment-id="21466" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/16/schoolbook-error-discovery/kid/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kid.jpg?fit=634%2C806&amp;ssl=1" data-orig-size="634,806" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kid" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kid.jpg?fit=236%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kid.jpg?fit=600%2C763&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kid.jpg?resize=236%2C300&#038;ssl=1" alt="" width="236" height="300" class="aligncenter size-medium wp-image-21466" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kid.jpg?resize=236%2C300&amp;ssl=1 236w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kid.jpg?w=634&amp;ssl=1 634w" sizes="(max-width: 236px) 100vw, 236px" data-recalc-dims="1" /></a></p>
<p><P><br />
The book was a &#8220;Level 5&#8221; tome encompassing Earth Science. The book was approved by the school district back in 2015&#8212;but a diagram mistake had managed to creep through. Noticing the pictures of igneous and sedimentary rocks were miscaptioned, Squires told his teacher, who told the school, who then told Five Ponds Press. Who sent a wonderful personal letter back to Squires.</p>
<p>
Anthony Picciano&#8217;s blog has further <a href="https://apicciano.commons.gc.cuny.edu/2023/04/13/liam-squires-virginia-fifth-grader-is-celebrated-for-spotting-error-in-science-textbook/">details</a> of the story.</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/16/schoolbook-error-discovery/textbook/" rel="attachment wp-att-21467"><img data-attachment-id="21467" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/16/schoolbook-error-discovery/textbook/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/textbook.jpg?fit=600%2C600&amp;ssl=1" data-orig-size="600,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="textbook" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/textbook.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/textbook.jpg?fit=600%2C600&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/textbook.jpg?resize=400%2C400&#038;ssl=1" alt="" width="400" height="400" class="aligncenter wp-image-21467" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/textbook.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/textbook.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/textbook.jpg?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/textbook.jpg?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/textbook.jpg?w=600&amp;ssl=1 600w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1" /></a></p>
<p><P></p>
<p><H2> Open Problems </H2></p>
<p><p>
Let&#8217;s send Squires some &#8220;proofs&#8221; for checking? Would he catch that out of three references to the &#8220;Bell basis&#8221; in my <a href="https://mitpress.mit.edu/9780262045254/introduction-to-quantum-algorithms-via-linear-algebra/">textbook</a> with Ken, one of them is incorrect (should be &#8220;Hadamard basis&#8221;)? How about the next P=NP proof? </p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-17T02:36:23Z">Monday, April 17 2023, 02:36</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.07227'>On representations of real numbers and the computational complexity of converting between such representations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Amir M. Ben-Amram, Lars Kristiansen, Jakob Grue Simonsen</p><p>We study the computational complexity of converting one representation of
real numbers into another representation. Typical examples of representations
are Cauchy sequences, base-10 expansions, Dedekind cuts and continued
fractions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Ben_Amram_A/0/1/0/all/0/1">Amir M. Ben-Amram</a>, <a href="http://arxiv.org/find/math/1/au:+Kristiansen_L/0/1/0/all/0/1">Lars Kristiansen</a>, <a href="http://arxiv.org/find/math/1/au:+Simonsen_J/0/1/0/all/0/1">Jakob Grue Simonsen</a></p><p>We study the computational complexity of converting one representation of
real numbers into another representation. Typical examples of representations
are Cauchy sequences, base-10 expansions, Dedekind cuts and continued
fractions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-17T00:30:00Z">Monday, April 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06780'>Online Geometric Hitting Set and Set Cover Beyond Unit Balls in $\mathbb{R}^2$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Minati De, Ratnadip Mandal, Satyam Singh</p><p>We investigate the geometric hitting set problem in the online setup for the
range space $\Sigma=({\cal P},{\cal S})$, where the set $\P\subset\mathbb{R}^2$
is a collection of $n$ points and the set $\cal S$ is a family of geometric
objects in $\mathbb{R}^2$. In the online setting, the geometric objects arrive
one by one. Upon the arrival of an object, an online algorithm must maintain a
valid hitting set by making an irreversible decision, i.e., once a point is
added to the hitting set by the algorithm, it can not be deleted in the future.
The objective of the geometric hitting set problem is to find a hitting set of
the minimum cardinality. Even and Smorodinsky (Discret. Appl. Math., 2014)
considered an online model (Model-I) in which the range space $\Sigma$ is known
in advance, but the order of arrival of the input objects in $\cal S$ is
unknown. They proposed online algorithms having optimal competitive ratios of
$\Theta(\log n)$ for intervals, half-planes and unit disks in $\mathbb{R}^2$.
Whether such an algorithm exists for unit squares remained open for a long
time. This paper considers an online model (Model-II) in which the entire range
space $\Sigma$ is not known in advance. We only know the set $\cal P$ but not
the set $\cal S$ in advance. Note that any algorithm for Model-II will also
work for Model-I, but not vice-versa. In Model-II, we obtain an optimal
competitive ratio of $\Theta(\log(n))$ for unit disks and regular $k$-gon with
$k\geq 4$ in $\mathbb{R}^2$. All the above-mentioned results also hold for the
equivalent geometric set cover problem in Model-II.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+De_M/0/1/0/all/0/1">Minati De</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandal_R/0/1/0/all/0/1">Ratnadip Mandal</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Satyam Singh</a></p><p>We investigate the geometric hitting set problem in the online setup for the
range space $\Sigma=({\cal P},{\cal S})$, where the set $\P\subset\mathbb{R}^2$
is a collection of $n$ points and the set $\cal S$ is a family of geometric
objects in $\mathbb{R}^2$. In the online setting, the geometric objects arrive
one by one. Upon the arrival of an object, an online algorithm must maintain a
valid hitting set by making an irreversible decision, i.e., once a point is
added to the hitting set by the algorithm, it can not be deleted in the future.
The objective of the geometric hitting set problem is to find a hitting set of
the minimum cardinality. Even and Smorodinsky (Discret. Appl. Math., 2014)
considered an online model (Model-I) in which the range space $\Sigma$ is known
in advance, but the order of arrival of the input objects in $\cal S$ is
unknown. They proposed online algorithms having optimal competitive ratios of
$\Theta(\log n)$ for intervals, half-planes and unit disks in $\mathbb{R}^2$.
Whether such an algorithm exists for unit squares remained open for a long
time. This paper considers an online model (Model-II) in which the entire range
space $\Sigma$ is not known in advance. We only know the set $\cal P$ but not
the set $\cal S$ in advance. Note that any algorithm for Model-II will also
work for Model-I, but not vice-versa. In Model-II, we obtain an optimal
competitive ratio of $\Theta(\log(n))$ for unit disks and regular $k$-gon with
$k\geq 4$ in $\mathbb{R}^2$. All the above-mentioned results also hold for the
equivalent geometric set cover problem in Model-II.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-17T00:30:00Z">Monday, April 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06862'>The Longest Subsequence-Repeated Subsequence Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mahuel Lafond, Wenfeng Lai, Adiesha Liyanage, Binhai Zhu</p><p>Motivated by computing duplication patterns in sequences, a new fundamental
problem called the longest subsequence-repeated subsequence (LSRS) is proposed.
Given a sequence $S$ of length $n$, a letter-repeated subsequence is a
subsequence of $S$ in the form of $x_1^{d_1}x_2^{d_2}\cdots x_k^{d_k}$ with
$x_i$ a subsequence of $S$, $x_j\neq x_{j+1}$ and $d_i\geq 2$ for all $i$ in
$[k]$ and $j$ in $[k-1]$. We first present an $O(n^6)$ time algorithm to
compute the longest cubic subsequences of all the $O(n^2)$ substrings of $S$,
improving the trivial $O(n^7)$ bound. Then, an $O(n^6)$ time algorithm for
computing the longest subsequence-repeated subsequence (LSRS) of $S$ is
obtained. Finally we focus on two variants of this problem. We first consider
the constrained version when $\Sigma$ is unbounded, each letter appears in $S$
at most $d$ times and all the letters in $\Sigma$ must appear in the solution.
We show that the problem is NP-hard for $d=4$, via a reduction from a special
version of SAT (which is obtained from 3-COLORING). We then show that when each
letter appears in $S$ at most $d=3$ times, then the problem is solvable in
$O(n^5)$ time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lafond_M/0/1/0/all/0/1">Mahuel Lafond</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_W/0/1/0/all/0/1">Wenfeng Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liyanage_A/0/1/0/all/0/1">Adiesha Liyanage</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1">Binhai Zhu</a></p><p>Motivated by computing duplication patterns in sequences, a new fundamental
problem called the longest subsequence-repeated subsequence (LSRS) is proposed.
Given a sequence $S$ of length $n$, a letter-repeated subsequence is a
subsequence of $S$ in the form of $x_1^{d_1}x_2^{d_2}\cdots x_k^{d_k}$ with
$x_i$ a subsequence of $S$, $x_j\neq x_{j+1}$ and $d_i\geq 2$ for all $i$ in
$[k]$ and $j$ in $[k-1]$. We first present an $O(n^6)$ time algorithm to
compute the longest cubic subsequences of all the $O(n^2)$ substrings of $S$,
improving the trivial $O(n^7)$ bound. Then, an $O(n^6)$ time algorithm for
computing the longest subsequence-repeated subsequence (LSRS) of $S$ is
obtained. Finally we focus on two variants of this problem. We first consider
the constrained version when $\Sigma$ is unbounded, each letter appears in $S$
at most $d$ times and all the letters in $\Sigma$ must appear in the solution.
We show that the problem is NP-hard for $d=4$, via a reduction from a special
version of SAT (which is obtained from 3-COLORING). We then show that when each
letter appears in $S$ at most $d=3$ times, then the problem is solvable in
$O(n^5)$ time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-17T00:30:00Z">Monday, April 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.07107'>Near Tight Shortest Paths in the Hybrid Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Philipp Schneider</p><p>Shortest paths problems are subject to extensive studies in classic
distributed models such as the CONGEST or congested clique, which describe the
way in which nodes may communicate in order to solve such a problem. %where
nodes initially know only the distance to their neighbors in some graph and
must compute distances to any other node with as few communication rounds as
possible. This article focuses on hybrid networks, which give nodes access to
multiple, different modes of communication, in particular the HYBRID model
which combines unrestricted local communication along edges of the input graph
alongside heavily restricted global communication between arbitrary pairs of
nodes.
</p>
<p>Previous work [Augustine et al, SODA'20, Kuhn et al. PODC'20] showed that
each node learning its distance to $k$ dedicated source nodes (aka the $k$-SSP
problem) takes at least $\tilOm(\!\sqrt{k})$ rounds in the HYBRID model, even
for polynomial approximations. This lower bound was matched with algorithmic
solutions for $k \geq n^{2/3}$. However, as $k$ gets smaller, the gap between
the known upper and lower bounds diverges and even becomes exponential for the
single source shortest paths problem (SSSP). In this work we plug this gap for
the whole range of $k$ (up to terms that are polylogarithmic in $n$), by giving
algorithmic solutions for $k$-SSP in $\tilO\big(\!\sqrt k\big)$ rounds for any
$k$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Schneider_P/0/1/0/all/0/1">Philipp Schneider</a></p><p>Shortest paths problems are subject to extensive studies in classic
distributed models such as the CONGEST or congested clique, which describe the
way in which nodes may communicate in order to solve such a problem. %where
nodes initially know only the distance to their neighbors in some graph and
must compute distances to any other node with as few communication rounds as
possible. This article focuses on hybrid networks, which give nodes access to
multiple, different modes of communication, in particular the HYBRID model
which combines unrestricted local communication along edges of the input graph
alongside heavily restricted global communication between arbitrary pairs of
nodes.
</p>
<p>Previous work [Augustine et al, SODA'20, Kuhn et al. PODC'20] showed that
each node learning its distance to $k$ dedicated source nodes (aka the $k$-SSP
problem) takes at least $\tilOm(\!\sqrt{k})$ rounds in the HYBRID model, even
for polynomial approximations. This lower bound was matched with algorithmic
solutions for $k \geq n^{2/3}$. However, as $k$ gets smaller, the gap between
the known upper and lower bounds diverges and even becomes exponential for the
single source shortest paths problem (SSSP). In this work we plug this gap for
the whole range of $k$ (up to terms that are polylogarithmic in $n$), by giving
algorithmic solutions for $k$-SSP in $\tilO\big(\!\sqrt k\big)$ rounds for any
$k$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-17T00:30:00Z">Monday, April 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.07284'>Solving Unique Games over Globally Hypercontractive Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mitali Bafna, Dor Minzer</p><p>We study the complexity of affine Unique-Games (UG) over globally
hypercontractive graphs, which are graphs that are not small set expanders but
admit a useful and succinct characterization of all small sets that violate the
small-set expansion property. This class of graphs includes the Johnson and
Grassmann graphs, which have played a pivotal role in recent PCP constructions
for UG, and their generalizations via high-dimensional expanders.
</p>
<p>Our algorithm shows how to round "low-entropy" solutions to sum-of-squares
(SoS) semidefinite programs, broadly extending the algorithmic framework of
[BBKSS'21]. We give a new rounding scheme for SoS, which eliminates global
correlations in a given pseudodistribution so that it retains various good
properties even after conditioning. Getting structural control over a
pseudodistribution after conditioning is a fundamental challenge in many SoS
based algorithms. Due to these challenges, [BBKSS] were not able to establish
strong algorithms for globally hypercontractive graphs, and could only do so
for certifiable small-set expanders. Our results improve upon the results of
[BBKSS] in various aspects: we are able to deal with instances with arbitrarily
small (but constant) completeness, and most importantly, their algorithm gets a
soundness guarantee that degrades with other parameters of the graph (which in
all PCP constructions grow with the alphabet size), whereas our doesn't.
</p>
<p>Our result suggests that UG is easy on globally hypercontractive graphs, and
therefore highlights the importance of graphs that lack such a characterization
in the context of PCP reductions for UG.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bafna_M/0/1/0/all/0/1">Mitali Bafna</a>, <a href="http://arxiv.org/find/cs/1/au:+Minzer_D/0/1/0/all/0/1">Dor Minzer</a></p><p>We study the complexity of affine Unique-Games (UG) over globally
hypercontractive graphs, which are graphs that are not small set expanders but
admit a useful and succinct characterization of all small sets that violate the
small-set expansion property. This class of graphs includes the Johnson and
Grassmann graphs, which have played a pivotal role in recent PCP constructions
for UG, and their generalizations via high-dimensional expanders.
</p>
<p>Our algorithm shows how to round "low-entropy" solutions to sum-of-squares
(SoS) semidefinite programs, broadly extending the algorithmic framework of
[BBKSS'21]. We give a new rounding scheme for SoS, which eliminates global
correlations in a given pseudodistribution so that it retains various good
properties even after conditioning. Getting structural control over a
pseudodistribution after conditioning is a fundamental challenge in many SoS
based algorithms. Due to these challenges, [BBKSS] were not able to establish
strong algorithms for globally hypercontractive graphs, and could only do so
for certifiable small-set expanders. Our results improve upon the results of
[BBKSS] in various aspects: we are able to deal with instances with arbitrarily
small (but constant) completeness, and most importantly, their algorithm gets a
soundness guarantee that degrades with other parameters of the graph (which in
all PCP constructions grow with the alphabet size), whereas our doesn't.
</p>
<p>Our result suggests that UG is easy on globally hypercontractive graphs, and
therefore highlights the importance of graphs that lack such a characterization
in the context of PCP reductions for UG.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-17T00:30:00Z">Monday, April 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.07274'>Beyond Planarity: A Spring-Based Approach</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Simon van Wageningen, Tamara Mchedlidze, Alexandru Telea</p><p>Planar drawings of graphs tend to be favored over non-planar drawings.
Testing planarity and creating a planar layout of a planar graph can be done in
linear time. However, creating readable drawings of nearly planar graphs
remains a challenge. We therefore seek to answer which edges of nearly planar
graphs create clutter in their drawings generated by mainstream graph drawing
algorithms. We present a heuristic to identify problematic edges in nearly
planar graphs and adjust their weights in order to produce higher quality
layouts with spring-based drawing algorithms. Our experiments show that our
heuristic produces significantly higher quality drawings for augmented grid
graphs, augmented triangulations, and deep triangulations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wageningen_S/0/1/0/all/0/1">Simon van Wageningen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mchedlidze_T/0/1/0/all/0/1">Tamara Mchedlidze</a>, <a href="http://arxiv.org/find/cs/1/au:+Telea_A/0/1/0/all/0/1">Alexandru Telea</a></p><p>Planar drawings of graphs tend to be favored over non-planar drawings.
Testing planarity and creating a planar layout of a planar graph can be done in
linear time. However, creating readable drawings of nearly planar graphs
remains a challenge. We therefore seek to answer which edges of nearly planar
graphs create clutter in their drawings generated by mainstream graph drawing
algorithms. We present a heuristic to identify problematic edges in nearly
planar graphs and adjust their weights in order to produce higher quality
layouts with spring-based drawing algorithms. Our experiments show that our
heuristic produces significantly higher quality drawings for augmented grid
graphs, augmented triangulations, and deep triangulations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-17T00:30:00Z">Monday, April 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06733'>Near-Optimal Degree Testing for Bayes Nets</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vipul Arora, Arnab Bhattacharyya, Cl&#xe9;ment L. Canonne, Joy Qiping Yang</p><p>This paper considers the problem of testing the maximum in-degree of the
Bayes net underlying an unknown probability distribution $P$ over $\{0,1\}^n$,
given sample access to $P$. We show that the sample complexity of the problem
is $\tilde{\Theta}(2^{n/2}/\varepsilon^2)$. Our algorithm relies on a
testing-by-learning framework, previously used to obtain sample-optimal
testers; in order to apply this framework, we develop new algorithms for
``near-proper'' learning of Bayes nets, and high-probability learning under
$\chi^2$ divergence, which are of independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Arora_V/0/1/0/all/0/1">Vipul Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_A/0/1/0/all/0/1">Arnab Bhattacharyya</a>, <a href="http://arxiv.org/find/cs/1/au:+Canonne_C/0/1/0/all/0/1">Cl&#xe9;ment L. Canonne</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Joy Qiping Yang</a></p><p>This paper considers the problem of testing the maximum in-degree of the
Bayes net underlying an unknown probability distribution $P$ over $\{0,1\}^n$,
given sample access to $P$. We show that the sample complexity of the problem
is $\tilde{\Theta}(2^{n/2}/\varepsilon^2)$. Our algorithm relies on a
testing-by-learning framework, previously used to obtain sample-optimal
testers; in order to apply this framework, we develop new algorithms for
``near-proper'' learning of Bayes nets, and high-probability learning under
$\chi^2$ divergence, which are of independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-17T00:30:00Z">Monday, April 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06787'>A Polynomial Time, Pure Differentially Private Estimator for Binary Product Distributions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vikrant Singhal</p><p>We present the first $\varepsilon$-differentially private, computationally
efficient algorithm that estimates the means of product distributions over
$\{0,1\}^d$ accurately in total-variation distance, whilst attaining the
optimal sample complexity to within polylogarithmic factors. The prior work had
either solved this problem efficiently and optimally under weaker notions of
privacy, or had solved it optimally while having exponential running times.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Singhal_V/0/1/0/all/0/1">Vikrant Singhal</a></p><p>We present the first $\varepsilon$-differentially private, computationally
efficient algorithm that estimates the means of product distributions over
$\{0,1\}^d$ accurately in total-variation distance, whilst attaining the
optimal sample complexity to within polylogarithmic factors. The prior work had
either solved this problem efficiently and optimally under weaker notions of
privacy, or had solved it optimally while having exponential running times.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-17T00:30:00Z">Monday, April 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06853'>Pseudorandom Hashing for Space-bounded Computation with Applications in Streaming</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Praneeth Kacham, Rasmus Pagh, Mikkel Thorup, David P. Woodruff</p><p>We revisit Nisan's classical pseudorandom generator (PRG) for space-bounded
computation (STOC 1990) and its applications in streaming algorithms. We
describe a new generator, HashPRG, that can be thought of as a symmetric
version of Nisan's generator over larger alphabets. Our generator allows a
trade-off between seed length and the time needed to compute a given block of
the generator's output. HashPRG can be used to obtain derandomizations with
much better update time and \emph{without sacrificing space} for a large number
of data stream algorithms, such as $F_p$ estimation in the parameter regimes $p
&gt; 2$ and $0 &lt; p &lt; 2$ and CountSketch with tight estimation guarantees as
analyzed by Minton and Price (SODA 2014) which assumed access to a random
oracle. We also show a recent analysis of Private CountSketch can be
derandomized using our techniques.
</p>
<p>For a $d$-dimensional vector $x$ being updated in a turnstile stream, we show
that $\|x\|_{\infty}$ can be estimated up to an additive error of
$\varepsilon\|x\|_{2}$ using $O(\varepsilon^{-2}\log(1/\varepsilon)\log d)$
bits of space. Additionally, the update time of this algorithm is $O(\log
1/\varepsilon)$ in the Word RAM model. We show that the space complexity of
this algorithm is optimal up to constant factors. However, for vectors $x$ with
$\|x\|_{\infty} = \Theta(\|x\|_{2})$, we show that the lower bound can be
broken by giving an algorithm that uses $O(\varepsilon^{-2}\log d)$ bits of
space which approximates $\|x\|_{\infty}$ up to an additive error of
$\varepsilon\|x\|_{2}$. We use our aforementioned derandomization of the
CountSketch data structure to obtain this algorithm, and using the time-space
trade off of HashPRG, we show that the update time of this algorithm is also
$O(\log 1/\varepsilon)$ in the Word RAM model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kacham_P/0/1/0/all/0/1">Praneeth Kacham</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagh_R/0/1/0/all/0/1">Rasmus Pagh</a>, <a href="http://arxiv.org/find/cs/1/au:+Thorup_M/0/1/0/all/0/1">Mikkel Thorup</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a></p><p>We revisit Nisan's classical pseudorandom generator (PRG) for space-bounded
computation (STOC 1990) and its applications in streaming algorithms. We
describe a new generator, HashPRG, that can be thought of as a symmetric
version of Nisan's generator over larger alphabets. Our generator allows a
trade-off between seed length and the time needed to compute a given block of
the generator's output. HashPRG can be used to obtain derandomizations with
much better update time and \emph{without sacrificing space} for a large number
of data stream algorithms, such as $F_p$ estimation in the parameter regimes $p
&gt; 2$ and $0 &lt; p &lt; 2$ and CountSketch with tight estimation guarantees as
analyzed by Minton and Price (SODA 2014) which assumed access to a random
oracle. We also show a recent analysis of Private CountSketch can be
derandomized using our techniques.
</p>
<p>For a $d$-dimensional vector $x$ being updated in a turnstile stream, we show
that $\|x\|_{\infty}$ can be estimated up to an additive error of
$\varepsilon\|x\|_{2}$ using $O(\varepsilon^{-2}\log(1/\varepsilon)\log d)$
bits of space. Additionally, the update time of this algorithm is $O(\log
1/\varepsilon)$ in the Word RAM model. We show that the space complexity of
this algorithm is optimal up to constant factors. However, for vectors $x$ with
$\|x\|_{\infty} = \Theta(\|x\|_{2})$, we show that the lower bound can be
broken by giving an algorithm that uses $O(\varepsilon^{-2}\log d)$ bits of
space which approximates $\|x\|_{\infty}$ up to an additive error of
$\varepsilon\|x\|_{2}$. We use our aforementioned derandomization of the
CountSketch data structure to obtain this algorithm, and using the time-space
trade off of HashPRG, we show that the update time of this algorithm is also
$O(\log 1/\varepsilon)$ in the Word RAM model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-17T00:30:00Z">Monday, April 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.07109'>Optimal Uncoordinated Unique IDs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Peter C. Dillinger, Mart&#xed;n Farach-Colton, Guido Tagliavini, Stefan Walzer</p><p>In the Uncoordinated Unique Identifiers Problem (UUIDP) there are $n$
independent instances of an algorithm $\mathcal{A}$ that generates IDs from a
universe $\{1, \dots, m\}$, and there is an adversary that requests IDs from
these instances. The goal is to design $\mathcal{A}$ such that it minimizes the
probability that the same ID is ever generated twice across all instances, that
is, minimizes the collision probability. Crucially, no communication between
the instances of $\mathcal{A}$ is possible. Solutions to the UUIDP are often
used as mechanisms for surrogate key generation in distributed databases and
key-value stores. In spite of its practical relevance, we know of no prior
theoretical work on the UUIDP.
</p>
<p>In this paper we initiate the systematic study of the UUIDP. We analyze both
existing and novel algorithms for this problem, and evaluate their collision
probability using worst-case analysis and competitive analysis, against
oblivious and adaptive adversaries. In particular, we present an algorithm that
is optimal in the worst case against oblivious adversaries, an algorithm that
is at most a logarithmic factor away from optimal in the worst case against
adaptive adversaries, and an algorithm that is optimal in the competitive sense
against both oblivious and adaptive adversaries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dillinger_P/0/1/0/all/0/1">Peter C. Dillinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Farach_Colton_M/0/1/0/all/0/1">Mart&#xed;n Farach-Colton</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliavini_G/0/1/0/all/0/1">Guido Tagliavini</a>, <a href="http://arxiv.org/find/cs/1/au:+Walzer_S/0/1/0/all/0/1">Stefan Walzer</a></p><p>In the Uncoordinated Unique Identifiers Problem (UUIDP) there are $n$
independent instances of an algorithm $\mathcal{A}$ that generates IDs from a
universe $\{1, \dots, m\}$, and there is an adversary that requests IDs from
these instances. The goal is to design $\mathcal{A}$ such that it minimizes the
probability that the same ID is ever generated twice across all instances, that
is, minimizes the collision probability. Crucially, no communication between
the instances of $\mathcal{A}$ is possible. Solutions to the UUIDP are often
used as mechanisms for surrogate key generation in distributed databases and
key-value stores. In spite of its practical relevance, we know of no prior
theoretical work on the UUIDP.
</p>
<p>In this paper we initiate the systematic study of the UUIDP. We analyze both
existing and novel algorithms for this problem, and evaluate their collision
probability using worst-case analysis and competitive analysis, against
oblivious and adaptive adversaries. In particular, we present an algorithm that
is optimal in the worst case against oblivious adversaries, an algorithm that
is at most a logarithmic factor away from optimal in the worst case against
adaptive adversaries, and an algorithm that is optimal in the competitive sense
against both oblivious and adaptive adversaries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-17T00:30:00Z">Monday, April 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.07268'>Planar and Minor-Free Metrics Embed into Metrics of Polylogarithmic Treewidth with Expected Multiplicative Distortion Arbitrarily Close to 1</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vincent Cohen-Addad, Hung Le, Marcin Pilipczuk, Micha&#x142; Pilipczuk</p><p>We prove that there is a randomized polynomial-time algorithm that given an
edge-weighted graph $G$ excluding a fixed-minor $Q$ on $n$ vertices and an
accuracy parameter $\varepsilon&gt;0$, constructs an edge-weighted graph~$H$ and
an embedding $\eta\colon V(G)\to V(H)$ with the following properties: * For any
constant size $Q$, the treewidth of $H$ is polynomial in $\varepsilon^{-1}$,
$\log n$, and the logarithm of the stretch of the distance metric in $G$. * The
expected multiplicative distortion is $(1+\varepsilon)$: for every pair of
vertices $u,v$ of $G$, we have $\mathrm{dist}_H(\eta(u),\eta(v))\geq
\mathrm{dist}_G(u,v)$ always and
$\mathrm{Exp}[\mathrm{dist}_H(\eta(u),\eta(v))]\leq
(1+\varepsilon)\mathrm{dist}_G(u,v)$.
</p>
<p>Our embedding is the first to achieve polylogarithmic treewidth of the host
graph and comes close to the lower bound by Carroll and Goel, who showed that
any embedding of a planar graph with $\mathcal{O}(1)$ expected distortion
requires the host graph to have treewidth $\Omega(\log n)$. It also provides a
unified framework for obtaining randomized quasi-polynomial-time approximation
schemes for a variety of problems including network design, clustering or
routing problems, in minor-free metrics where the optimization goal is the sum
of selected distances. Applications include the capacitated vehicle routing
problem, and capacitated clustering problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1">Vincent Cohen-Addad</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Hung Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Marcin Pilipczuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Micha&#x142; Pilipczuk</a></p><p>We prove that there is a randomized polynomial-time algorithm that given an
edge-weighted graph $G$ excluding a fixed-minor $Q$ on $n$ vertices and an
accuracy parameter $\varepsilon&gt;0$, constructs an edge-weighted graph~$H$ and
an embedding $\eta\colon V(G)\to V(H)$ with the following properties: * For any
constant size $Q$, the treewidth of $H$ is polynomial in $\varepsilon^{-1}$,
$\log n$, and the logarithm of the stretch of the distance metric in $G$. * The
expected multiplicative distortion is $(1+\varepsilon)$: for every pair of
vertices $u,v$ of $G$, we have $\mathrm{dist}_H(\eta(u),\eta(v))\geq
\mathrm{dist}_G(u,v)$ always and
$\mathrm{Exp}[\mathrm{dist}_H(\eta(u),\eta(v))]\leq
(1+\varepsilon)\mathrm{dist}_G(u,v)$.
</p>
<p>Our embedding is the first to achieve polylogarithmic treewidth of the host
graph and comes close to the lower bound by Carroll and Goel, who showed that
any embedding of a planar graph with $\mathcal{O}(1)$ expected distortion
requires the host graph to have treewidth $\Omega(\log n)$. It also provides a
unified framework for obtaining randomized quasi-polynomial-time approximation
schemes for a variety of problems including network design, clustering or
routing problems, in minor-free metrics where the optimization goal is the sum
of selected distances. Applications include the capacitated vehicle routing
problem, and capacitated clustering problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-17T00:30:00Z">Monday, April 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, April 16
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7230'>AI safety: what should actually be done now?</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          So, I recorded a 2.5-hour-long podcast with Daniel Filan about &#8220;reform AI alignment,&#8221; and the work I’ve been doing this year at OpenAI.  The end result is &#8230; well, probably closer to my current views on this subject than anything else I&#8217;ve said or written! Listen here or read the transcript here. Here&#8217;s Daniel&#8217;s abstract: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>So, I recorded a 2.5-hour-long podcast with <a href="https://danielfilan.com/">Daniel Filan</a> about &#8220;reform AI alignment,&#8221; and the work I’ve been doing this year at OpenAI.  The end result is &#8230; well, probably closer to my current views on this subject than anything else I&#8217;ve said or written! <a href="https://podcasts.google.com/feed/aHR0cHM6Ly9heHJwb2RjYXN0LmxpYnN5bi5jb20vcnNz/episode/NTM1YTQ1MzAtMDVlNS00OTE4LThlMjgtOWRmZWUzMjM1Mjk0">Listen here</a> or <a href="https://axrp.net/episode/2023/04/11/episode-20-reform-ai-alignment-scott-aaronson.html">read the transcript here</a>.  Here&#8217;s Daniel&#8217;s abstract:</p>



<blockquote class="wp-block-quote">
<p>How should we scientifically think about the impact of AI on human civilization, and whether or not it will doom us all? In this episode, I speak with Scott Aaronson about his views on how to make progress in AI alignment, as well as his work on watermarking the output of language models, and how he moved from a background in quantum complexity theory to working on AI.</p>
</blockquote>



<p>Thanks so much to Daniel for making this podcast happen.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Maybe I should make a broader comment, though.</p>



<p>From my recent posts, and from my declining to sign the <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">six-month AI pause letter</a> (even though I sympathize with many of its goals), many people seem to have goten the impression that I’m not worried about AI, or that (ironically, given my job this year) I&#8217;m basically in the &#8220;full speed ahead&#8221; camp.</p>



<p>This is not true.  In reality, I’m <em>full</em> <em>of</em> worry.  The issue is just that, in this case, I’m also full of <em>metaworry</em>&#8212;i.e., the worry that whichever things I worry about will turn out to have been the wrong things.</p>



<p>Even if we look at the pause letter, or more generally, at the people who wish to slow down AI research, we find that they wildly disagree <em>among themselves</em> about why a slowdown is called for.  One faction says that AI needs to be paused because it will spread misinformation and entrench social biases … or (this part is said aloud surprisingly often) because progress is being led by, you know, like, <em>totally gross</em> capitalistic Silicon Valley nerdbros, and might enhance those nerds&#8217; power.</p>



<p>A second faction, one that <em>contains</em> many of the gross nerdbros, is worried about AI because it might become superintelligent, recursively improve itself, and destroy all life on earth while optimizing for some alien goal.  Hopefully both factions agree that this scenario would be bad, so that the only disagreement is about its likelihood.</p>



<p>As I&#8217;ll never tire of pointing out, the two factions seem to have been converging on the same conclusion&#8212;namely, <em>AI progress urgently needs to be slowed down</em>&#8212;even while they sharply reject each other&#8217;s rationales and indeed are barely on speaking terms with each other.</p>



<p>OK, you might object, but that&#8217;s just sociology.  Why shouldn&#8217;t a rational person worry about near-term AI risk <em>and</em> long-term AI risk?  Why shouldn&#8217;t the ethics people focused on the former and the alignment people focused on the latter strategically join forces?  Such a hybrid Frankenpause is, it seems to me, precisely what the pause letter was trying to engineer.  Alas, the result was that, while a few people closer to the AI ethics camp (like Gary Marcus and Ernest Davis) agreed to sign, many others (Emily Bender, Timnit Gebru, Arvind Narayanan&#8230;) pointedly declined, because&#8212;as they explained on social media&#8212;to do so would be to legitimate the gross nerds and their sci-fi fantasies.</p>



<p>From my perspective, the problem is this:</p>



<ol>
<li><strong>Under the ethics people&#8217;s assumptions, I don&#8217;t see that an AI pause is called for.</strong>  Or rather, while I understand the arguments, the <em>same</em> arguments would seem to have justified stopping the development of the printing press, aviation, radio, computers, the Internet, and virtually every other nascent technology, until committees of academic experts had decided that the positive social effects would outweigh the negative ones, which might&#8217;ve been never.  The trouble is, well, how do you even <em>study</em> the social effects of a new technology, before society starts using it?  Aren&#8217;t we mostly <em>happy</em> that technological pioneers went ahead with all the previously-mentioned things, and dealt with the problems later as they arose?  But preventing the widespread societal adoption of GPT-like tools seems to be what the AI ethics camp <em>really</em> wants, much more than preventing further scaling for scientific research.  I reject any anti-AI argument that could be generalized and transplanted backwards to produce an argument against moving forward with, let&#8217;s say, agriculture or metallurgy.</li>



<li><strong>Under the alignment people&#8217;s assumptions, I <em>do</em> see that an AI pause is urgently called for&#8212;but I&#8217;m not yet on board with their assumptions.</strong>  The kind of relentlessly optimizing AI that could form the intention to doom humanity, still seems very different to me from the kind of AI that’s astonished the world these past couple years, to the point that it’s not obvious how much progress in the latter should increase our terror about the former.  Even Eliezer Yudkowsky <a href="https://www.youtube.com/watch?v=AaTRHFaaPG8">agrees</a> that GPT-4 doesn&#8217;t seem too dangerous in itself.  And an AI that was only <em>slightly</em> dangerous could presumably be recognized as such before it was too late.  So everything hinges on the conjecture that, in going from GPT-n to GPT-(n+1), there might be a &#8220;sharp turn&#8221; where an existential risk to humanity very suddenly emerged, with or without the cooperation of bad humans who used GPT-(n+1) for nefarious purposes.  I still don&#8217;t know how to think about the likelihood of this risk.  The empirical case for it is likely to be inadequate, by its proponents&#8217; own admission.  I admired how my friend Sarah Constantin thought through the issues in her recent essay <a href="https://sarahconstantin.substack.com/p/why-i-am-not-an-ai-doomer">Why I Am Not An AI Doomer</a>&#8212;but on the other hand, as others have pointed out, Sarah ends up conceding a staggering fraction of the doomers&#8217; case in the course of arguing against the rest of it.  What today passes for an &#8220;anti-doomer&#8221; might&#8217;ve been called a &#8220;doomer&#8221; just a few years ago.</li>
</ol>



<p>In short, one could say, the ethics and alignment communities are <em>both</em> building up cases for pausing AI progress, working at it from opposite ends, but their efforts haven&#8217;t yet met at any single argument that I wholeheartedly endorse.</p>



<p>This might just be a question of timing.  <em>If</em> AI is going become existentially dangerous, then I definitely want global coordination well <em>before</em> that happens.  And while it seems unlikely to me that we&#8217;re anywhere near the existential danger zone yet, the pace of progress over the past few years has been so astounding, and has upended so many previous confident assumptions, that caution seems well-advised.</p>



<p>But is a pause the right action?  How should we compare the risk of acceleration now to the risk of a so-called &#8220;overhang,&#8221; where capabilities might skyrocket even faster in the future, faster than society can react or adapt, <em>because</em> of a previous pause?  Also, would a pause even force OpenAI to change its plans from what they would&#8217;ve been otherwise?  (If I knew, I&#8217;d be prohibited from telling, which makes it convenient that I don&#8217;t!)  Or would the main purpose be symbolic, just to show that the main AI labs can coordinate on <em>something</em>?</p>



<p>If so, then one striking aspect of the pause letter is that it was written without consultation with the main entities who would need to agree to any such pause (OpenAI, DeepMind, Google, &#8230;).  Another striking aspect is that it applies only to systems &#8220;more powerful than&#8221; GPT-4.  There are two problems here.  Firstly, the concept &#8220;more powerful than&#8221; isn&#8217;t well-defined: presumably it rules out more parameters and more gradient descent, but what about more reinforcement learning or tuning of hyperparameters?  Secondly, to whatever extent it makes sense, it seems specifically tailored to tie the hands of OpenAI, while giving OpenAI&#8217;s competitors a chance to catch up to OpenAI.  The fact that the most famous signatory is Elon Musk, who&#8217;s now trying to build an &#8220;anti-woke&#8221; chatbot to compete against GPT, doesn&#8217;t help.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>So, if not this pause letter, <em>what do I think ought to happen instead?</em></p>



<p>I&#8217;ve been thinking about it a lot, and the most important thing I can come up with is: clear articulation of fire alarms, red lines, whatever you want to call them, along with what our responses to those fire alarms should be.  Two of my previous fire alarms were the first use of chatbots for academic cheating, and the first depressed person who commits suicide after interacting with a chatbot.  Both of those have now happened.  Here are some others:</p>



<ul>
<li>A chatbot is used to impersonate someone for fraudulent purposes, by imitating his or her writing style.</li>



<li>A chatbot helps a hacker find security vulnerabilities in code that are then actually exploited.</li>



<li>A child dies because his or her parents follow wrong chatbot-supplied medical advice.</li>



<li>Russian or Iranian or Chinese intelligence, or some other such organization, uses a chatbot to mass-manufacture disinformation and propaganda.</li>



<li>A chatbot helps a terrorist manufacture weapons that are used in a terrorist attack.</li>
</ul>



<p>I&#8217;m extremely curious: which fire alarms are <em>you</em> most worried about?  How do you think the AI companies and governments should respond if and when they happen?</p>



<p>In my view, articulating fire alarms actually provides multiple benefits.  Not only will it give us a playbook if and when any of the bad events happen, it will also give us clear <em>targets to try to forecast</em>.  If we&#8217;ve decided that behavior X is unacceptable, and if extrapolating the performance of GPT-1 through GPT-n on various metrics leads to the prediction that GPT-(n+1) will be capable of X, then we suddenly have a clear, legible case for delaying the release of GPT-(n+1).</p>



<p>Or&#8212;and this is yet a third benefit&#8212;we have something clear on which to <em>test</em> GPT-(n+1), in &#8220;sandboxes,&#8221; before releasing it.  I think the kinds of <a href="https://www.lesswrong.com/posts/4Gt42jX7RiaNaxCwP/more-information-about-the-dangerous-capability-evaluations">safety evals</a> that ARC (the Alignment Research Center) did on GPT-4 before it was released&#8212;for example, testing its ability to deceive Mechanical Turkers&#8212;were an extremely important prototype, something that we&#8217;ll need a lot more of before the release of future language models.   But all of society should have a say on what, specifically, <em>are</em> the dangerous behaviors that these evals are checking for.</p>



<p>So let&#8217;s get started on that!  Readers: which unaligned behaviors would you like GPT-5 to be tested for prior to its release?  Bonus points for plausibility and non-obviousness.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-16T22:18:25Z">Sunday, April 16 2023, 22:18</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/04/16/fractal-arbelos.html'>A fractal arbelos</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          If you nest a triangle in a hexagon in a dodecagon, etc., doubling the number of sides each time, you get a triangulation. This sequence of nested polygons was already known to Archimedes, who took it all the way up to 96 sides in order to calculate an accurate approximation of \(\pi\).
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>If you nest a triangle in a hexagon in a dodecagon, etc., doubling the number of sides each time, you get a triangulation. This sequence of nested polygons was already known to Archimedes, who took it all the way up to 96 sides in order to calculate an accurate <a href="https://en.wikipedia.org/wiki/Approximations_of_%CF%80">approximation of \(\pi\)</a>.</p>

<p style="text-align:center"><img src="/blog/assets/2023/archimedes.svg" alt="Triangle in a hexagon in a dodecagon in a circle" style="width:100%;max-width:540px" /></p>

<p>Replacing each triangle by an <a href="https://en.wikipedia.org/wiki/Arbelos">arbelos</a>, the shape between one outer semicircle and two inner ones, and keeping the same pattern, with each triangle connected to one bigger one and two smaller ones, we get a nice tessellation of a semicircle, which can be extended outward in the same way to tile a halfplane. Alternatively, you can think of these as forming a triangulation of the <a href="https://en.wikipedia.org/wiki/Hyperbolic_geometry">hyperbolic plane</a> by <a href="https://en.wikipedia.org/wiki/Ideal_triangle">ideal triangles</a>. Under this reinterpretation, the distinction between bigger and smaller goes away; all the triangles are the same size.</p>

<p style="text-align:center"><img src="/blog/assets/2023/fractal-arbelos.svg" alt="A fractal arbelos" /></p>

<p>It looks like a <a href="https://en.wikipedia.org/wiki/Uniform_tilings_in_hyperbolic_plane">uniform tessellation of the hyperbolic plane</a>, but it’s not: it has at most a one-dimensional group of symmetries, not the full two-dimensional group that a uniform tiling would have. There is a uniform tessellation generated by reflections across the sides of an ideal triangle, but it’s not this one:</p>

<p style="text-align:center"><img src="/blog/assets/2023/uniform-ideal.svg" alt="Uniform tessellation by reflected ideal triangles" title="PD image by Saric from Wikimedia commons, File:Ideal-triangle hyperbolic tiling.svg" style="width:100%;max-width:540px" /></p>

<p>They have the same combinatorial structure (their dual graphs form the same infinite 3-regular tree), but their geometry is different. You can tell they’re not the same because in the uniform tessellation, each triangle is adjacent to its reflection across each of its sides. In the fractal arbelos, if you reflected any triangle across its top side, the other two sides would reflect into vertical rays, but we don’t see any vertical rays. Instead, the fractal arbelos is what you get when you contract the vertical sides of the <a href="https://en.wikipedia.org/wiki/Binary_tiling">aperiodic binary tiling of the hyperbolic plane</a> (below) into points at infinity, leaving the other sides straight (in the hyperbolic plane).</p>

<p style="text-align:center"><img src="/blog/assets/2018/binary-tiling.svg" alt="The binary tiling" /></p>

<p>Now let’s take it down to only some fixed level, rather than recursing infinitely all the way down, and number the vertices in binary.</p>

<p style="text-align:center"><img src="/blog/assets/2023/numbered-arbelos.svg" alt="Fewer levels of the fractal arbelos, with its vertices numbered in binary" /></p>

<p>We can read off a lot of information from these numbers:</p>

<ul>
  <li>
    <p>Each numbered point, with number \(x\), is connected by arcs to other numbers \(x\pm 2^i\), where \(2^i\) is less than or equal to the smallest power of two used in the binary representation of \(x\) (its rightmost one-bit). In the special case \(x=0\), any power of two is allowed.</p>
  </li>
  <li>
    <p>Each numbered point, with nonzero number \(x\), is the middle point of exactly one arbelos-shaped tile. If \(p\) is the largest power of two in the binary representation of \(x\), then the two smaller tiles under this one are numbered \(x\pm p/2\). The larger tile above it is either \(x+p\) or \(x-p\), depending on whether the next bit in the binary representation of \(x\) is a \(0\) or a \(1\), respectively.</p>
  </li>
</ul>

<p>The same numbering system can be extended to all tiles in the halfplane, using <a href="https://en.wikipedia.org/wiki/Dyadic_rational">dyadic rationals</a> in place of integers. The one-dimensional symmetry group is then apparent from the numbers: it’s just multiplication or division by finite powers of two.</p>

<p>If the existence of a special point \(0\), with no arbelos above it, is a concern, then you can replace \(0\) by any <a href="https://en.wikipedia.org/wiki/P-adic_number">2-adic integer</a> whose left-infinite binary representation has infinitely many zeros and infinitely many ones, and number from there in the same way. You can either choose a number with a periodic binary representation (in which case you still get a one-dimensional symmetry group) or an aperiodic representation (producing a tiling with no symmetries at all).</p>

<p>(<a href="https://mathstodon.xyz/@11011110/110211494756432130">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-16T18:04:00Z">Sunday, April 16 2023, 18:04</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/047'>TR23-047 |  Ruling Out Short Proofs of Unprovable Sentences is Hard | 

	Hunter Monroe</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          If no optimal propositional proof system exists, we (and independently Pudlák) prove that ruling out length $t$ proofs of any unprovable sentence is hard. This mapping from unprovable to hard-to-prove sentences powerfully translates facts about noncomputability into complexity theory. For instance, because proving string $x$ is Kolmogorov random ($x{\in}R$) is typically impossible, it is typically hard to prove &quot;no length $t$ proof shows $x{\in}R$&quot;, or tautologies encoding this. Therefore, a proof system with one family of hard tautologies has these densely in an enumeration of families. The assumption also implies that a natural language is $\textbf{NP}$-intermediate: with $R$ redefined to have a sparse complement, the complement of the language $\{\langle x,1^t\rangle|$ no length $t$ proof exists of  $x{\in}R\}$ is also sparse. 

Efficiently ruling out length $t$ proofs of $x{\in}R$ might violate the constraint on using the fact of $x{\in}R$&#39;s unprovability. We conjecture: any computable predicate on $R$ that might be used in if-then statements (or case-based proofs) does no better than branching at random, because $R$ appears random by any effective test. This constraint could also inhibit the usefulness in circuits and propositional proofs of NOT gates and cancellation---needed to encode if-then statements. If $R$ defeats if-then logic, exhaustive search is necessary.
        
        </div>

        <div class='tr-article-summary'>
        
          
          If no optimal propositional proof system exists, we (and independently Pudlák) prove that ruling out length $t$ proofs of any unprovable sentence is hard. This mapping from unprovable to hard-to-prove sentences powerfully translates facts about noncomputability into complexity theory. For instance, because proving string $x$ is Kolmogorov random ($x{\in}R$) is typically impossible, it is typically hard to prove &quot;no length $t$ proof shows $x{\in}R$&quot;, or tautologies encoding this. Therefore, a proof system with one family of hard tautologies has these densely in an enumeration of families. The assumption also implies that a natural language is $\textbf{NP}$-intermediate: with $R$ redefined to have a sparse complement, the complement of the language $\{\langle x,1^t\rangle|$ no length $t$ proof exists of  $x{\in}R\}$ is also sparse. 

Efficiently ruling out length $t$ proofs of $x{\in}R$ might violate the constraint on using the fact of $x{\in}R$&#39;s unprovability. We conjecture: any computable predicate on $R$ that might be used in if-then statements (or case-based proofs) does no better than branching at random, because $R$ appears random by any effective test. This constraint could also inhibit the usefulness in circuits and propositional proofs of NOT gates and cancellation---needed to encode if-then statements. If $R$ defeats if-then logic, exhaustive search is necessary.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-16T12:20:26Z">Sunday, April 16 2023, 12:20</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/046'>TR23-046 |  NP-Hardness of Approximating Meta-Complexity: A Cryptographic Approach | 

	Hanlin Ren, 

	Rahul Ilango, 

	Yizhi Huang</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          It is a long-standing open problem whether the Minimum Circuit Size Problem ($\mathrm{MCSP}$) and related meta-complexity problems are NP-complete. Even for the rare cases where the NP-hardness of meta-complexity problems are known, we only know very weak hardness of approximation.

In this work, we prove NP-hardness of approximating meta-complexity with nearly-optimal approximation gaps. Our key idea is to use *cryptographic constructions* in our reductions, where the security of the cryptographic construction implies the correctness of the reduction. We present both conditional and unconditional hardness of approximation results as follows.

$\bullet$ Assuming subexponentially-secure witness encryption exists, we prove essentially optimal NP-hardness of approximating conditional time-bounded Kolmogorov complexity ($\mathrm{K}^t(x \mid y)$) in the regime where $t \gg |y|$. Previously, the best hardness of approximation known was a $|x|^{1/ \mathrm{poly}(\log \log |x|)}$ factor and only in the sublinear regime ($t \ll |y|$).
$\bullet$ Unconditionally, we show near-optimal NP-hardness of approximation for the Minimum Oracle Circuit Size Problem (MOCSP), where Yes instances have circuit complexity at most $2^{\varepsilon n}$, and No instances are essentially as hard as random truth tables. Our reduction builds on a witness encryption construction proposed by Garg, Gentry, Sahai, and Waters (STOC&#39;13). Previously, it was unknown whether it is NP-hard to distinguish between oracle circuit complexity $s$ versus $10s\log N$.
$\bullet$ Finally, we define a &quot;multi-valued&quot; version of $\mathrm{MCSP}$, called $\mathrm{mvMCSP}$, and show that w.p. $1$ over a random oracle $O$, $\mathrm{mvMCSP}^O$ is NP-hard to approximate under quasi-polynomial-time reductions with $O$ oracle access. Intriguingly, this result follows almost directly from the security of Micali&#39;s CS proofs (Micali, SICOMP&#39;00).

In conclusion, we give three results convincingly demonstrating the power of cryptographic techniques in proving NP-hardness of approximating meta-complexity.
        
        </div>

        <div class='tr-article-summary'>
        
          
          It is a long-standing open problem whether the Minimum Circuit Size Problem ($\mathrm{MCSP}$) and related meta-complexity problems are NP-complete. Even for the rare cases where the NP-hardness of meta-complexity problems are known, we only know very weak hardness of approximation.

In this work, we prove NP-hardness of approximating meta-complexity with nearly-optimal approximation gaps. Our key idea is to use *cryptographic constructions* in our reductions, where the security of the cryptographic construction implies the correctness of the reduction. We present both conditional and unconditional hardness of approximation results as follows.

$\bullet$ Assuming subexponentially-secure witness encryption exists, we prove essentially optimal NP-hardness of approximating conditional time-bounded Kolmogorov complexity ($\mathrm{K}^t(x \mid y)$) in the regime where $t \gg |y|$. Previously, the best hardness of approximation known was a $|x|^{1/ \mathrm{poly}(\log \log |x|)}$ factor and only in the sublinear regime ($t \ll |y|$).
$\bullet$ Unconditionally, we show near-optimal NP-hardness of approximation for the Minimum Oracle Circuit Size Problem (MOCSP), where Yes instances have circuit complexity at most $2^{\varepsilon n}$, and No instances are essentially as hard as random truth tables. Our reduction builds on a witness encryption construction proposed by Garg, Gentry, Sahai, and Waters (STOC&#39;13). Previously, it was unknown whether it is NP-hard to distinguish between oracle circuit complexity $s$ versus $10s\log N$.
$\bullet$ Finally, we define a &quot;multi-valued&quot; version of $\mathrm{MCSP}$, called $\mathrm{mvMCSP}$, and show that w.p. $1$ over a random oracle $O$, $\mathrm{mvMCSP}^O$ is NP-hard to approximate under quasi-polynomial-time reductions with $O$ oracle access. Intriguingly, this result follows almost directly from the security of Micali&#39;s CS proofs (Micali, SICOMP&#39;00).

In conclusion, we give three results convincingly demonstrating the power of cryptographic techniques in proving NP-hardness of approximating meta-complexity.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-16T06:00:20Z">Sunday, April 16 2023, 06:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, April 15
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/04/15/linkage.html'>Linkage</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Two recent posts by Dave Richeson on connections between stamp folding and the design of circular labyrinths and their combinatorial enumeration as meanders (\(\mathbb{M}\)). See also Wikipedia on map folding and meanders.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <ul>
  <li>
    <p>Two recent posts by Dave Richeson on <a href="https://mathstodon.xyz/@divbyzero/110074607064920932">connections between stamp folding and the design of circular labyrinths</a> and <a href="https://mathstodon.xyz/@divbyzero/110107529366706667">their combinatorial enumeration as meanders</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110130128539526442">\(\mathbb{M}\)</a>).</span> 
See also Wikipedia on <a href="https://en.wikipedia.org/wiki/Map_folding">map folding</a> and <a href="https://en.wikipedia.org/wiki/Meander_(mathematics)">meanders</a>.</p>
  </li>
  <li>
    <p>Here’s a long-standing mistake in Wikipedia’s algorithms coverage <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110131646871368785">\(\mathbb{M}\)</a>).</span> From August 2013 until recently <a href="https://en.wikipedia.org/wiki/Quickselect">the quickselect article</a> stated “quickselect has almost certain \(O(n)\) time complexity” or “a random pivot, which yields almost certain linear time”, or some other form of this statement. This turns out to be false. There is no constant \(C\) such that the probability of performing fewer than \(Cn\) comparisons goes to one in the limit as \(n\) goes to infinity. Instead, if you are using quickselect to find the minimum element (say), you will perform more than \(Cn\) comparisons in the case that the first \(2C\) pivots all land in the top half of the inputs, in decreasing order. This happens with constant probability, exponentially small in \(C\log C\) but independent of \(n\). Luc Devroye in two papers showed upper bounds on the probability of many comparisons, exponential and then (as above) superexponential in \(C\): see “<a href="http://luc.devroye.org/devroye-selection1984.pdf">Exponential bounds for the running time of a selection algorithm</a>” (1984), and “<a href="http://luc.devroye.org/wcfind.pdf">On the probabilistic worst-case time of ‘Find’</a>” (2001). So the probability of linearity is indeed very close to one, but it is not almost certain.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@tao/110068572186339264">Thread by Terry Tao with images of historical manuscripts at the Institut de France</a>, including Poincaré’s anticipation of special relativity, Pascal’s triangle (in a book by Pascal), Galois’s last letter, a Gutenberg bible, and some historical portraits.</p>
  </li>
  <li>
    <p>Did you know that the first publication to connect carbon dioxide levels to global warming, by 19th century amateur scientist <a href="https://en.wikipedia.org/wiki/Eunice_Newton_Foote">Eunice Newton Foote</a>, went long forgotten until uncovered by feminist historians in the 1970s <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110144606239976056">\(\mathbb{M}\)</a>).</span> Via <a href="https://wikimediafoundation.org/news/2023/03/14/susunw-is-on-a-mission-to-write-women-into-history-with-wikipedia/">a profile of Wikipedia volunteer SusunW</a> who significantly expanded Foote’s article last year, bringing it to Featured Article status.</p>
  </li>
  <li>
    <p><a href="https:doi.org/10.1080/17513472.2023.2191572">Knitted origami</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@villares@ciberlandia.pt/110123876929220736">\(\mathbb{M}\)</a>),</span> techniques for embedding sharp creases as features in knitted fabric.</p>
  </li>
  <li>
    <p>Two more recent Wikipedia Good Articles <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110155594315017176">\(\mathbb{M}\)</a>):</span></p>

    <ul>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Unit_fraction">Unit fraction</a> – you know, like 1/2, 1/3, 1/27, etc.</p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Beckman%E2%80%93Quarles_theorem">Beckman–Quarles theorem</a>, according to which the only mappings from the Euclidean plane to itself that preserve unit distances are the obvious ones: translations, rotations, mirror reflections, and glide reflections. In contrast, mappings into higher dimensions can be much messier; for instance, there is a unit-distance-preserving map from the plane to a set of only seven distinct points in six dimensions.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="https://www.julianstanczak.com/work.php">Selected paintings by Julian Stanczek</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@joshmillard@mastodon.social/110113097820423511">\(\mathbb{M}\)</a>),</span> very geometric in their use of color, form, and line.</p>
  </li>
  <li>
    <p><a href="https://reason.com/tag/large-libel-models/">Large libel models</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110166208017935593">\(\mathbb{M}\)</a>,</span> <a href="https://www.metafilter.com/198888/ChatGPT-cooks-up-fake-sexual-harassment-scandal-and-names-real-professor">via</a>). Far more than you probably wanted to know about: when ChatGPT makes up fake scandals about real people, who is responsible for the resulting libel? Also via Wikipedia, where there have been multiple incidents of editors adding falsified LLM-written content to Wikipedia, and discussions about how to keep this junk out. But attempts to ban LLM content have been somewhat stymied by too many under-informed editors who think “isn’t it neat that computers can write Wikipedia articles” or “won’t someone think of the people who can’t write themselves but can get computers to write for them”.</p>
  </li>
  <li>
    <p><a href="https://im.icerm.brown.edu/portfolio/nonabelian-set/">Nonabelian Set</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110172037195803108">\(\mathbb{M}\)</a>),</span> a variation of the Set card game (in which one seeks triples of cards that form lines in a finite geometry) where the cards represent permutation group elements and the goal is to find sequences of tiles that compose to the identity. One of many neat mathematical projects and visualizations from a 2019 program, “<a href="https://im.icerm.brown.edu/">Illustrating Mathematics</a>”, at the Brown University Institute for Computational and Experimental Research in Mathematics.</p>
  </li>
  <li>
    <p><a href="https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/aperiodic-tilings/">Simon Tatham writes about two algorithms for randomly generating aperiodic tilings</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@fanf@mendeddrum.org/110175215669526845">\(\mathbb{M}\)</a>),</span> including the new hat tiling, which we might expect to see soon as one of the fields for the Loopy puzzle in Tatham’s puzzle collection.</p>
  </li>
  <li>
    <p><a href="https://ericneyman.wordpress.com/2020/11/29/an-elegant-proof-of-laplaces-rule-of-succession/">Laplace’s Rule of Succession</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@ccanonne/110183704348315532">\(\mathbb{M}\)</a>).</span> An intuitive explanation for why, after seeing \(k\) heads out of \(n\) flips of a coin with unknown bias, your estimate for the bias should be \((k+1)/(n+2)\).</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/how-randomness-improves-algorithms-20230403/"><em>Quanta</em> on why randomness is useful in algorithm design</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@QuantaMagazine@mstdn.social/110135300361305997">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://igorpak.wordpress.com/2023/04/12/the-journal-hall-of-shame/">Igor Pak names and shames high-level journals claiming to cover all of mathematics, but actually excluding all of combinatorics</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110195556643419780">\(\mathbb{M}\)</a>).</span> The follow-up discussion also concerns similar prejudices against category theory, and how a hypothetical book on categorical combinatorics would be treated.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Kaktovik_numerals">Kaktovik numerals</a>, an intuitive system of base-20 digits invented by <a href="https://en.wikipedia.org/wiki/I%C3%B1upiat">Iñupiat</a> schoolchildren, <a href="https://www.scientificamerican.com/article/a-number-system-invented-by-inuit-schoolchildren-will-make-its-silicon-valley-debut/">are getting added to Unicode</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@tokensane@mastodon.me.uk/110190269945900718">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p>Amusing to see <a href="https://cameroncounts.wordpress.com/2023/04/15/bases-2/">an application of Mornington Crescent in group theory</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110204407564525420">\(\mathbb{M}\)</a>).</span> Peter Cameron looks at bases, sequences of the elements permuted by a permutation group whose permuted values are sufficient to identify which group element permuted them. For bases that are minimal under taking prefixes, the possible base lengths form a contiguous interval of integers.</p>
  </li>
</ul><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-15T14:40:00Z">Saturday, April 15 2023, 14:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/04/14/tcs-talk-wednesday-april-19-michal-feldman-tel-aviv-university/'>TCS+ talk: Wednesday, April 19 — Michal Feldman, Tel Aviv University</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, April 19th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Michal Feldman from Tel Aviv University will speak about &#8220;Algorithmic Contract Design&#8221; (abstract below). You can reserve a spot as an individual or a group to join us [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The next TCS+ talk will take place this coming Wednesday, April 19th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Michal Feldman</strong> from Tel Aviv University will speak about &#8220;<em>Algorithmic Contract Design</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: Contract design captures situations where a principal delegates the execution of a costly task to an agent. To complete the task, the agent chooses an action from a set of costly actions. The principal can only observe the outcome, which is stochastically determined by the chosen action. The principal incentivizes the desired action through a contract, that specifies payments based on the observed outcome. In this talk, I will survey two papers on *combinatorial* contracts, which highlight different sources of complexity that arise in contract design. The first (FOCS’21) is where the agent can choose any subset of a given set of actions; the second (STOC’23) is where the principal motivates a team of agents. We provide (approximation) algorithms and hardness results for the optimal contract problem in these scenarios.</p>
<p>Based on joint work with Tomer Ezra, Paul Duetting and Thomas Kesselheim.</p></blockquote>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-15T00:18:14Z">Saturday, April 15 2023, 00:18</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, April 14
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/04/14/mathematics-of-the-impossible-chapter-8-three-impossibility-results-for-3sat/'>Mathematics of the impossible, Chapter 8, Three impossibility results for 3Sat</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We should turn back to a traditional separation technique – diagonalization.[21] In this chapter we put together many of the techniques we have seen to obtain several impossibility results for 3Sat. The template of all these results (and others, like those mentioned in section&#160;º5.1) is similar. All these results prove time bounds of the form [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <div class="quote">
<div class="flushright">
<p style="text-align:justify">  <em>We should turn back to a traditional separation technique – diagonalization.</em><span class="cite">[<a href="journals/jcss/Fortnow00">21</a>]</span></p>
</div>
</div>
<p style="text-align:justify">In this chapter we put together many of the techniques we have seen to obtain several impossibility results for 3Sat. The template of all these results (and others, like those mentioned in section&nbsp;º<a href="#x1-580005.1">5.1<!--tex4ht:ref: sec:Nondeterministic-computation --></a>) is similar. All these results prove time bounds of the form <img src="https://s0.wp.com/latex.php?latex=t%5Cge+n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cge+n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cge+n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;ge n^{1+&#92;epsilon }" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%5Cin+%280%2C1%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+%5Cin+%280%2C1%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+%5Cin+%280%2C1%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon &#92;in (0,1)" class="latex" />. One can optimize the methods to push <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon " class="latex" /> close to <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" />, but even establishing <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon =1" class="latex" /> seems out of reach, and there are known barriers for current techniques <span class="cite">[<a href="journals/cc/BussW15">16</a>]</span>.</p>
<h3 class="sectionHead"><span class="titlemark">8.1   </span> <a id="x1-970008.1"></a>Impossibility I</h3>
<p style="text-align:justify">We begin with the following remarkable result.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-97001r1"></a> <b>Theorem</b> 8.1.  </span><span class="cite">[<a href="journals/jcss/Fortnow00">21</a>]</span> Either <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;not &#92;in &#92;text {L}" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;not &#92;in &#92;text {Time}(n^{1+&#92;epsilon })" class="latex" /> for some constant <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon " class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Note that we don’t know if <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {L}" class="latex" /> or if <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BTime%7D%28n%5Clog+%5E%7B10%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BTime%7D%28n%5Clog+%5E%7B10%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BTime%7D%28n%5Clog+%5E%7B10%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {Time}(n&#92;log ^{10}n)" class="latex" />. In particular, Theorem <a href="#x1-97001r1">8.1<!--tex4ht:ref: thm:fortnow --></a> implies that any algorithm for 3Sat either must use super-logarithmic space or time <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B1%2Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B1%2Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{1+c}" class="latex" />.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>We assume that what we want to prove is not true and derive the following striking contradiction with the hierarchy Theorem <a href="#x1-41003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29+%26+%5Csubseteq+%5Ctext+%7BL%7D%5C%5C+%26+%5Csubseteq+%5Cbigcup+_%7Bd%7D%5CSigma+_%7Bd%7D%5Ctext+%7BTime%7D%28n%29%5C%5C+%26+%5Csubseteq+%5Ctext+%7BTime%7D%28n%5E%7B1.9%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29+%26+%5Csubseteq+%5Ctext+%7BL%7D%5C%5C+%26+%5Csubseteq+%5Cbigcup+_%7Bd%7D%5CSigma+_%7Bd%7D%5Ctext+%7BTime%7D%28n%29%5C%5C+%26+%5Csubseteq+%5Ctext+%7BTime%7D%28n%5E%7B1.9%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29+%26+%5Csubseteq+%5Ctext+%7BL%7D%5C%5C+%26+%5Csubseteq+%5Cbigcup+_%7Bd%7D%5CSigma+_%7Bd%7D%5Ctext+%7BTime%7D%28n%29%5C%5C+%26+%5Csubseteq+%5Ctext+%7BTime%7D%28n%5E%7B1.9%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;text {Time}(n^{2}) &amp; &#92;subseteq &#92;text {L}&#92;&#92; &amp; &#92;subseteq &#92;bigcup _{d}&#92;Sigma _{d}&#92;text {Time}(n)&#92;&#92; &amp; &#92;subseteq &#92;text {Time}(n^{1.9}). &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   The first inclusion holds by the assumption that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {L}" class="latex" /> and the fact that any function in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(n^{2})" class="latex" /> can be reduced to 3Sat in log-space, by Theorem <a href="#x1-57001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> and the discussion after that.</p>
<p style="text-align:justify">   The second inclusion is Theorem <a href="#x1-91003r11">7.11<!--tex4ht:ref: thm:L-in-linear-hiearchy --></a>.</p>
<p style="text-align:justify">   For the third inclusion, the assumption that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {Time}(n^{1+&#92;epsilon })" class="latex" /> for every <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon " class="latex" /> implies that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%28dn%29%5Csubseteq+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%28dn%29%5Csubseteq+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%28dn%29%5Csubseteq+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NTime}(dn)&#92;subseteq &#92;text {Time}(n^{1+&#92;epsilon })" class="latex" /> for every <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon " class="latex" />, by the quasi-linear-time completeness of 3Sat, Theorem <a href="#x1-63006r4">5.4<!--tex4ht:ref: thm:redux-NTime-3Sat --></a>. Now apply Exercise <a href="#x1-73002r2">6.2<!--tex4ht:ref: xca:LIN-NTIME=00003DTIME-implies-LIN-H=00003DTIME --></a>. <b>QED</b></p>
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">8.2   </span> <a id="x1-980008.2"></a>Impossibility II</h3>
<p style="text-align:justify">We now state and prove a closely related result for TiSp. We seek to rule out algorithms for 3Sat that simultaneously use little space and time, whereas in Theorem <a href="#x1-97001r1">8.1<!--tex4ht:ref: thm:fortnow --></a> we even ruled out the possibility that there are two distinct algorithms, one optimizing space and the other time. The main gain is that we will be able to handle much larger space: power rather than log.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-98001r2"></a> <b>Theorem</b> 8.2.  </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BTiSp%7D%28n%5E%7B1%2Bc_%7B%5Cepsilon+%7D%7D%2Cn%5E%7B1-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BTiSp%7D%28n%5E%7B1%2Bc_%7B%5Cepsilon+%7D%7D%2Cn%5E%7B1-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BTiSp%7D%28n%5E%7B1%2Bc_%7B%5Cepsilon+%7D%7D%2Cn%5E%7B1-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;not &#92;in &#92;text {TiSp}(n^{1+c_{&#92;epsilon }},n^{1-&#92;epsilon })" class="latex" />, for any <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon &gt;0" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The important aspect of Theorem <a href="#x1-97001r1">8.1<!--tex4ht:ref: thm:fortnow --></a> is that it applies to the RAM model; stronger results can be shown for space-bounded TMs.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-98002r1"></a> <b>Exercise</b> 8.1.  </span>Prove that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BPalindromes%7D%5Cnot+%5Cin+%5Ctext+%7BTM-TiSp%7D%28n%5E%7B1%2Bc_%7B%5Cepsilon+%7D%7D%2Cn%5E%7B1-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BPalindromes%7D%5Cnot+%5Cin+%5Ctext+%7BTM-TiSp%7D%28n%5E%7B1%2Bc_%7B%5Cepsilon+%7D%7D%2Cn%5E%7B1-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BPalindromes%7D%5Cnot+%5Cin+%5Ctext+%7BTM-TiSp%7D%28n%5E%7B1%2Bc_%7B%5Cepsilon+%7D%7D%2Cn%5E%7B1-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Palindromes}&#92;not &#92;in &#92;text {TM-TiSp}(n^{1+c_{&#92;epsilon }},n^{1-&#92;epsilon })" class="latex" />, for any <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon &gt;0" class="latex" />. (TM-TiSp<img src="https://s0.wp.com/latex.php?latex=%28t%2Cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28t%2Cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28t%2Cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(t,s)" class="latex" /> is defined as Space<img src="https://s0.wp.com/latex.php?latex=%28s%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28s%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28s%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(s)" class="latex" />, cf.&nbsp;Definition <a href="#x1-80001r1">7.1<!--tex4ht:ref: def:Space --></a>, but moreover the machine runs in at most <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> steps.) Hint: This problem has a simple solution. Give a suitable simulation of TM-Tisp by 1TM, then apply Theorem <a href="#x1-39001r1">3.1<!--tex4ht:ref: thm:TM-pal-requires-quadratic --></a>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>We assume that what we want to prove is not true and derive the following contradiction with the hierarchy Theorem <a href="#x1-41003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%7D%29+%26+%5Csubseteq+%5Ctext+%7B%5Ctext+%7BTiSp%7D%28c%5Censuremath+%7Bn%5E%7B%281%2B%5Cepsilon+%29%281%2Bc_%7B%5Cepsilon+%7D%29%7D%7D%2Cc%5Censuremath+%7Bn%5E%7B%281%2B%5Cepsilon+%29%281-%5Cepsilon+%29%7D%7D%29%7D%5C%5C+%26+%5Csubseteq+%5Ctext+%7B%5Ctext+%7BTiSp%7D%28%5Censuremath+%7Bn%5E%7B1%2Bc_%7B%5Cepsilon+%7D%7D%7D%2Cc%5Censuremath+%7Bn%5E%7B1-%5Cepsilon+%5E%7B2%7D%7D%7D%29%7D%5C%5C+%26+%5Csubseteq+%5CSigma+_%7Bc_%7B%5Cepsilon+%7D%7D%5Ctext+%7BTime%7D%28n%29%5C%5C+%26+%5Csubseteq+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%2F2%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%7D%29+%26+%5Csubseteq+%5Ctext+%7B%5Ctext+%7BTiSp%7D%28c%5Censuremath+%7Bn%5E%7B%281%2B%5Cepsilon+%29%281%2Bc_%7B%5Cepsilon+%7D%29%7D%7D%2Cc%5Censuremath+%7Bn%5E%7B%281%2B%5Cepsilon+%29%281-%5Cepsilon+%29%7D%7D%29%7D%5C%5C+%26+%5Csubseteq+%5Ctext+%7B%5Ctext+%7BTiSp%7D%28%5Censuremath+%7Bn%5E%7B1%2Bc_%7B%5Cepsilon+%7D%7D%7D%2Cc%5Censuremath+%7Bn%5E%7B1-%5Cepsilon+%5E%7B2%7D%7D%7D%29%7D%5C%5C+%26+%5Csubseteq+%5CSigma+_%7Bc_%7B%5Cepsilon+%7D%7D%5Ctext+%7BTime%7D%28n%29%5C%5C+%26+%5Csubseteq+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%2F2%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%7D%29+%26+%5Csubseteq+%5Ctext+%7B%5Ctext+%7BTiSp%7D%28c%5Censuremath+%7Bn%5E%7B%281%2B%5Cepsilon+%29%281%2Bc_%7B%5Cepsilon+%7D%29%7D%7D%2Cc%5Censuremath+%7Bn%5E%7B%281%2B%5Cepsilon+%29%281-%5Cepsilon+%29%7D%7D%29%7D%5C%5C+%26+%5Csubseteq+%5Ctext+%7B%5Ctext+%7BTiSp%7D%28%5Censuremath+%7Bn%5E%7B1%2Bc_%7B%5Cepsilon+%7D%7D%7D%2Cc%5Censuremath+%7Bn%5E%7B1-%5Cepsilon+%5E%7B2%7D%7D%7D%29%7D%5C%5C+%26+%5Csubseteq+%5CSigma+_%7Bc_%7B%5Cepsilon+%7D%7D%5Ctext+%7BTime%7D%28n%29%5C%5C+%26+%5Csubseteq+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon+%2F2%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;text {Time}(n^{1+&#92;epsilon }) &amp; &#92;subseteq &#92;text {&#92;text {TiSp}(c&#92;ensuremath {n^{(1+&#92;epsilon )(1+c_{&#92;epsilon })}},c&#92;ensuremath {n^{(1+&#92;epsilon )(1-&#92;epsilon )}})}&#92;&#92; &amp; &#92;subseteq &#92;text {&#92;text {TiSp}(&#92;ensuremath {n^{1+c_{&#92;epsilon }}},c&#92;ensuremath {n^{1-&#92;epsilon ^{2}}})}&#92;&#92; &amp; &#92;subseteq &#92;Sigma _{c_{&#92;epsilon }}&#92;text {Time}(n)&#92;&#92; &amp; &#92;subseteq &#92;text {Time}(n^{1+&#92;epsilon /2}). &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   The first inclusion holds by the assumption, padding, and the fact that 3Sat is complete under reductions s.t.&nbsp;each bit is computable in time (and hence space) <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{o(1)}" class="latex" />, a fact we do not prove here. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-98003r2"></a> <b>Exercise</b> 8.2.  </span>Finish the proof by justifying the remaining inclusions.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">8.3   </span> <a id="x1-990008.3"></a>Impossibility III</h3>
<p style="text-align:justify">So far our impossibility results required bounds on space. We now state and prove a result that applies to time. Of course, as discussed in Chapter <a href="#x1-380003">3<!--tex4ht:ref: chap:The-grand-challenge --></a>, we don’t know how to prove that, say, 3Sat cannot be computed in linear time on a 2TM. For single-tape machines, we can prove quadratic bounds, for palindromes (Theorem <a href="#x1-39001r1">3.1<!--tex4ht:ref: thm:TM-pal-requires-quadratic --></a>) and 3Sat (Problem <a href="#x1-56002r2">4.2<!--tex4ht:ref: prob:3Sat-not-in-TM-Time1.99 --></a>). Next we consider an interesting model which is between 1TM and 2TM and is a good indication of the state of our knowledge.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-99001r1"></a> <b>Definition</b> 8.1.  </span>A <img src="https://s0.wp.com/latex.php?latex=1.5%5Ctext+%7BTM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1.5%5Ctext+%7BTM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1.5%5Ctext+%7BTM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1.5&#92;text {TM}" class="latex" /> is like a 2TM except that the input tape is read-only.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-99002r3"></a> <b>Theorem</b> 8.3.  </span><span class="cite">[<a href="#XMaS87">43</a>,&nbsp;<a href="journals/tcs/MelkebeekR05">70</a>]</span> 3Sat requires time <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B1%2Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B1%2Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{1+c}" class="latex" /> on a 1.5TM.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-99003r3"></a> <b>Exercise</b> 8.3.  </span>Prove Theorem <a href="#x1-99002r3">8.3<!--tex4ht:ref: thm:3Sat-requires-time-1.5TM --></a> following this guideline:</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-99005x1">Let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be a 1.5 TM running in tine <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />. Divide the read-write tape of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> into consecutive blocks of <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b" class="latex" /> cells, shifted by an offset <img src="https://s0.wp.com/latex.php?latex=i+%5Cleq+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i+%5Cleq+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i+%5Cleq+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i &#92;leq b" class="latex" />.  Prove that for every input there is an offset s.t. the sum of the lengths of all the crossing sequences between adjacent blocks is small.</li>
<li class="enumerate" id="x1-99007x2">Prove that <img src="https://s0.wp.com/latex.php?latex=1.5%5Ctext+%7BTM-Time%7D%28n%5E%7B1.1%7D%29%5Csubseteq+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%5E%7B1-c%7D%7D%5Ctext+%7BTiSp%7D%28n%5E%7Bc%7D%2Cn%5E%7B1-c%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1.5%5Ctext+%7BTM-Time%7D%28n%5E%7B1.1%7D%29%5Csubseteq+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%5E%7B1-c%7D%7D%5Ctext+%7BTiSp%7D%28n%5E%7Bc%7D%2Cn%5E%7B1-c%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1.5%5Ctext+%7BTM-Time%7D%28n%5E%7B1.1%7D%29%5Csubseteq+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%5E%7B1-c%7D%7D%5Ctext+%7BTiSp%7D%28n%5E%7Bc%7D%2Cn%5E%7B1-c%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1.5&#92;text {TM-Time}(n^{1.1})&#92;subseteq &#92;exists y&#92;in &#92;{0,1&#92;} ^{n^{1-c}}&#92;text {TiSp}(n^{c},n^{1-c})" class="latex" />. (The right-hand side is the class of functions <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} " class="latex" /> for which there is a RAM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />       that on input <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|=n" class="latex" />, runs in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{c}" class="latex" /> and uses memory cells <img src="https://s0.wp.com/latex.php?latex=0..n%5E%7B1-c%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0..n%5E%7B1-c%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0..n%5E%7B1-c%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0..n^{1-c}" class="latex" /> and s.t.&nbsp;<img src="https://s0.wp.com/latex.php?latex=f%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%5E%7B1-c%7D%7DM%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%5E%7B1-c%7D%7DM%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%5E%7B1-c%7D%7DM%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)=1&#92;Leftrightarrow &#92;exists y&#92;in &#92;{0,1&#92;} ^{n^{1-c}}M(x,y)=1" class="latex" />.)</li>
<li class="enumerate" id="x1-99009x3">Conclude the proof.</li>
</ol>
</div>
<p style="text-align:justify">
<h3 class="likesectionHead"><a id="x1-1000008.3"></a>Notes</h3>
<p style="text-align:justify">For a survey (not up to date) of this type of impossibility results see <span class="cite">[<a href="#XMelkebeek06">69</a>]</span>.</p>
<div class="thebibliography">
<p class="bibitem"><span class="biblabel">   [1]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/focs/AbboudBW15"></a>Amir Abboud, Arturs Backurs, and Virginia&nbsp;Vassilevska Williams. Tight hardness      results for LCS and other sequence similarity measures.  In Venkatesan Guruswami,      editor, IEEE 56th Annual Symposium on Foundations of Computer Science, FOCS      2015, Berkeley, CA, USA, 17-20 October, 2015, pages 59–78. IEEE Computer Society,      2015.</p>
<p class="bibitem"><span class="biblabel">   [2]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAdleman78"></a>Leonard  Adleman.   Two  theorems  on  random  polynomial  time.   In  19th IEEE      Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 75–83. 1978.</p>
<p class="bibitem"><span class="biblabel">   [3]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAjt83"></a>Mikl≤s Ajtai.  <img src="https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Sigma &#92;sp {1}&#92;sb {1}" class="latex" />-formulae on finite structures.  Annals of Pure and Applied Logic,      24(1):1–48, 1983.</p>
<p class="bibitem"><span class="biblabel">   [4]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAjtai05"></a>Mikl≤s Ajtai. A non-linear time lower bound for boolean branching programs. Theory      of Computing, 1(1):149–176, 2005.</p>
<p class="bibitem"><span class="biblabel">   [5]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAll89"></a>Eric  Allender.   A  note  on  the  power  of  threshold  circuits.   In  30th Symposium      on Foundations of Computer Science, pages 580–584, Research Triangle Park, North      Carolina, 30 October–1 November 1989. IEEE.</p>
<p class="bibitem"><span class="biblabel">   [6]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAllender01"></a>Eric Allender. The division breakthroughs. Bulletin of the EATCS, 74:61–77, 2001.</p>
<p class="bibitem"><span class="biblabel">   [7]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAllenderK10"></a>Eric  Allender  and  Michal  Koucký.     Amplifying  lower  bounds  by  means  of      self-reducibility. J.&nbsp;of the ACM, 57(3), 2010.</p>
<p class="bibitem"><span class="biblabel">   [8]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAGHP92"></a>Noga Alon, Oded Goldreich, Johan Hσstad, and RenΘ Peralta. Simple constructions      of  almost  <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-wise  independent  random  variables.   Random  Structures  &amp;  Algorithms,      3(3):289–304, 1992.</p>
<p class="bibitem"><span class="biblabel">   [9]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/AngluinV79"></a>Dana Angluin<br />
and Leslie&nbsp;G. Valiant. Fast probabilistic algorithms for hamiltonian      circuits and matchings. J. Comput. Syst. Sci., 18(2):155–193, 1979.</p>
<p class="bibitem"><span class="biblabel">  [10]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAroraLuMoSuSz98"></a>Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy.      Proof  verification  and  the  hardness  of  approximation  problems.    J.&nbsp;of  the  ACM,      45(3):501–555, May 1998.</p>
<p class="bibitem"><span class="biblabel">  [11]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/BackursI18"></a>Arturs Backurs and Piotr Indyk.  Edit distance cannot be computed in strongly      subquadratic time (unless SETH is false). SIAM J. Comput., 47(3):1087–1097, 2018.</p>
<p class="bibitem"><span class="biblabel">  [12]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBatcher68"></a>Kenneth&nbsp;E. Batcher.  Sorting networks and their applications.  In AFIPS Spring      Joint Computing Conference, volume&nbsp;32, pages 307–314, 1968.</p>
<p class="bibitem"><span class="biblabel">  [13]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBeameCH86"></a>Paul  Beame,  Stephen&nbsp;A.  Cook,  and  H.&nbsp;James  Hoover.   Log  depth  circuits  for      division and related problems. SIAM J. Comput., 15(4):994–1003, 1986.</p>
<p class="bibitem"><span class="biblabel">  [14]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBSSV03"></a>Paul Beame, Michael Saks, Xiaodong Sun, and Erik Vee.   Time-space trade-off      lower  bounds  for  randomized  computation  of  decision  problems.   J.&nbsp;of  the  ACM,      50(2):154–195, 2003.</p>
<p class="bibitem"><span class="biblabel">  [15]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBen-OrC92"></a>Michael Ben-Or and Richard Cleve. Computing algebraic formulas using a constant      number of registers. SIAM J.&nbsp;on Computing, 21(1):54–58, 1992.</p>
<p class="bibitem"><span class="biblabel">  [16]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/cc/BussW15"></a>Samuel&nbsp;R.  Buss  and  Ryan  Williams.   Limits  on  alternation  trading  proofs  for      time-space lower bounds. Comput. Complex., 24(3):533–600, 2015.</p>
<p class="bibitem"><span class="biblabel">  [17]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/stoc/ChenT19"></a>Lijie Chen and Roei Tell. Bootstrapping results for threshold circuits &#8220;just beyond&#8221;      known lower bounds.  In Moses Charikar and Edith Cohen, editors, Proceedings of the      51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, Phoenix,      AZ, USA, June 23-26, 2019, pages 34–41. ACM, 2019.</p>
<p class="bibitem"><span class="biblabel">  [18]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCleve91"></a>Richard  Cleve.    Towards  optimal  simulations  of  formulas  by  bounded-width                                                                                                                                                                                          programs. Computational Complexity, 1:91–105, 1991.</p>
<p class="bibitem"><span class="biblabel">  [19]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCook73"></a>Stephen&nbsp;A. Cook. A hierarchy for nondeterministic time complexity. J.&nbsp;of Computer      and System Sciences, 7(4):343–353, 1973.</p>
<p class="bibitem"><span class="biblabel">  [20]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Csanky76"></a>L.&nbsp;Csanky.     Fast  parallel  matrix  inversion  algorithms.     SIAM  J.  Comput.,      5(4):618–623, 1976.</p>
<p class="bibitem"><span class="biblabel">  [21]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/Fortnow00"></a>Lance  Fortnow.   Time-space  tradeoffs  for  satisfiability.   J.  Comput.  Syst.  Sci.,      60(2):337–353, 2000.</p>
<p class="bibitem"><span class="biblabel">  [22]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jct/FraenkelL81"></a>Aviezri&nbsp;S. Fraenkel and David Lichtenstein. Computing a perfect strategy for n x n      chess requires time exponential in n. J. Comb. Theory, Ser. A, 31(2):199–214, 1981.</p>
<p class="bibitem"><span class="biblabel">  [23]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XFredmanS89"></a>Michael&nbsp;L. Fredman and Michael&nbsp;E. Saks.  The cell probe complexity of dynamic      data structures. In ACM Symp.&nbsp;on the Theory of Computing (STOC), pages 345–354,      1989.</p>
<p class="bibitem"><span class="biblabel">  [24]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGajentaanO95"></a>Anka Gajentaan and Mark&nbsp;H. Overmars. On a class of <img src="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="{O}(n^2)" class="latex" /> problems in computational      geometry. Comput. Geom., 5:165–185, 1995.</p>
<p class="bibitem"><span class="biblabel">  [25]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGareyJ79"></a>M.&nbsp;R. Garey and David&nbsp;S. Johnson. Computers and Intractability: A Guide to the      Theory of NP-Completeness. W. H. Freeman, 1979.</p>
<p class="bibitem"><span class="biblabel">  [26]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR1549939"></a>K.&nbsp;G÷del.   ▄ber  formal  unentscheidbare  sΣtze  der  Principia  Mathematica  und      verwandter systeme I. Monatsh. Math. Phys., 38, 1931.</p>
<p class="bibitem"><span class="biblabel">  [27]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGoldreich08Complexity"></a>Oded Goldreich. Computational Complexity: A Conceptual Perspective. Cambridge      University Press, 2008.</p>
<p class="bibitem"><span class="biblabel">  [28]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGreenlawHR-Limits"></a>Raymond  Greenlaw,  H.&nbsp;James  Hoover,  and  Walter  Ruzzo.   Limits  to  Parallel      Computation: P-Completeness Theory. 02 2001.</p>
<p class="bibitem"><span class="biblabel">  [29]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="X10.4007/annals.2021.193.2.4"></a>David Harvey and Joris van&nbsp;der Hoeven. Integer multiplication in time <img src="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(n&#92;mathrm {log}&#92;, n)" class="latex" />. Annals of      Mathematics, 193(2):563 – 617, 2021.</p>
<p class="bibitem"><span class="biblabel">  [30]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F.&nbsp;C. Hennie.  One-tape, off-line turing machine computations.  Information and      Control, 8(6):553–578, 1965.</p>
<p class="bibitem"><span class="biblabel">  [31]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XHennieS66"></a>Fred  Hennie  and  Richard  Stearns.    Two-tape  simulation  of  multitape  turing      machines. J.&nbsp;of the ACM, 13:533–546, October 1966.</p>
<p class="bibitem"><span class="biblabel">  [32]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jacm/HopcroftPV77"></a>John&nbsp;E. Hopcroft, Wolfgang&nbsp;J. Paul, and Leslie&nbsp;G. Valiant. On time versus space.      J. ACM, 24(2):332–337, 1977.</p>
<p class="bibitem"><span class="biblabel">  [33]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIP99"></a>Russell Impagliazzo and Ramamohan Paturi.   The complexity of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-sat.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 237–, 1999.</p>
<p class="bibitem"><span class="biblabel">  [34]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImpagliazzoPS97"></a>Russell Impagliazzo, Ramamohan Paturi, and Michael&nbsp;E. Saks. Size-depth tradeoffs      for threshold circuits. SIAM J. Comput., 26(3):693–707, 1997.</p>
<p class="bibitem"><span class="biblabel">  [35]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIPZ01"></a>Russell Impagliazzo, Ramamohan Paturi, and Francis Zane.  Which problems have      strongly exponential complexity? J. Computer &amp; Systems Sciences, 63(4):512–530, Dec      2001.</p>
<p class="bibitem"><span class="biblabel">  [36]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImW97"></a>Russell  Impagliazzo  and  Avi  Wigderson.    <img src="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathit {P} = &#92;mathit {BPP}" class="latex" />  if  <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E" class="latex" />  requires  exponential  circuits:      Derandomizing the XOR lemma.  In 29th ACM Symp.&nbsp;on the Theory of Computing      (STOC), pages 220–229. ACM, 1997.</p>
<p class="bibitem"><span class="biblabel">  [37]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKarpLi82"></a>Richard&nbsp;M.  Karp  and  Richard&nbsp;J.  Lipton.    Turing  machines  that  take  advice.      L’Enseignement MathΘmatique. Revue Internationale. IIe SΘrie, 28(3-4):191–209, 1982.</p>
<p class="bibitem"><span class="biblabel">  [38]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi.  On the structure of one-tape nondeterministic turing machine      time hierarchy. Theor. Comput. Sci., 40:175–193, 1985.</p>
<p class="bibitem"><span class="biblabel">  [39]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/LarsenWY20"></a>Kasper&nbsp;Green Larsen, Omri Weinstein, and Huacheng Yu. Crossing the logarithmic      barrier for dynamic boolean data structure lower bounds.  SIAM J. Comput., 49(5),      2020.</p>
<p class="bibitem"><span class="biblabel">  [40]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLevin73"></a>Leonid&nbsp;A.  Levin.    Universal  sequential  search  problems.    Problemy  Peredachi      Informatsii, 9(3):115–116, 1973.</p>
<p class="bibitem"><span class="biblabel">  [41]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLundFoKaNi92"></a>Carsten Lund, Lance Fortnow, Howard Karloff, and Noam Nisan. Algebraic methods      for interactive proof systems. J.&nbsp;of the ACM, 39(4):859–868, October 1992.</p>
<p class="bibitem"><span class="biblabel">  [42]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLupanov58"></a>O.&nbsp;B. Lupanov. A method of circuit synthesis. Izv. VUZ Radiofiz., 1:120–140, 1958.</p>
<p class="bibitem"><span class="biblabel">  [43]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMaS87"></a>Wolfgang Maass and Amir Schorr. Speed-up of Turing machines with one work tape      and a two-way input tape. SIAM J.&nbsp;on Computing, 16(1):195–202, 1987.</p>
<p class="bibitem"><span class="biblabel">  [44]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBarrington89"></a>David&nbsp;A.  Mix  Barrington.   Bounded-width  polynomial-size  branching  programs      recognize  exactly  those  languages  in  NC<img src="https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^1" class="latex" />.    J.&nbsp;of  Computer  and  System  Sciences,      38(1):150–164, 1989.</p>
<p class="bibitem"><span class="biblabel">  [45]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNaN93"></a>Joseph Naor and Moni Naor.  Small-bias probability spaces: efficient constructions      and applications. SIAM J.&nbsp;on Computing, 22(4):838–856, 1993.</p>
<p class="bibitem"><span class="biblabel">  [46]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNechiporuk66"></a>E.&nbsp;I. Nechiporuk. A boolean function. Soviet Mathematics-Doklady, 169(4):765–766,      1966.</p>
<p class="bibitem"><span class="biblabel">  [47]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNep70"></a>Valery&nbsp;A. Nepomnjaščiĭ. Rudimentary predicates and Turing calculations. Soviet      Mathematics-Doklady, 11(6):1462–1465, 1970.</p>
<p class="bibitem"><span class="biblabel">  [48]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaNEU-ram2sat-neu-author"></a>NEU. From RAM to SAT. Available at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2012.</p>
<p class="bibitem"><span class="biblabel">                                                                                                                                                                                      [49]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/PapadimitriouY91"></a>Christos&nbsp;H. Papadimitriou and Mihalis Yannakakis. Optimization, approximation,      and complexity classes. J. Comput. Syst. Sci., 43(3):425–440, 1991.</p>
<p class="bibitem"><span class="biblabel">  [50]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPPST83"></a>Wolfgang&nbsp;J. Paul, Nicholas Pippenger, Endre SzemerΘdi, and William&nbsp;T. Trotter.      On determinism versus non-determinism and related problems (preliminary version). In      IEEE Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 429–438, 1983.</p>
<p class="bibitem"><span class="biblabel">  [51]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPippengerF79"></a>Nicholas Pippenger and Michael&nbsp;J. Fischer. Relations among complexity measures.      J.&nbsp;of the ACM, 26(2):361–381, 1979.</p>
<p class="bibitem"><span class="biblabel">  [52]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XRaz87"></a>Alexander Razborov. Lower bounds on the dimension of schemes of bounded depth      in a complete basis containing the logical addition function.  Akademiya Nauk SSSR.      Matematicheskie Zametki, 41(4):598–607, 1987.  English translation in Mathematical      Notes of the Academy of Sci. of the USSR, 41(4):333-338, 1987.</p>
<p class="bibitem"><span class="biblabel">  [53]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XReingold08"></a>Omer Reingold. Undirected connectivity in log-space. J.&nbsp;of the ACM, 55(4), 2008.</p>
<p class="bibitem"><span class="biblabel">  [54]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Robson84"></a>J.&nbsp;M.  Robson.    N  by  N  checkers  is  exptime  complete.    SIAM  J.  Comput.,      13(2):252–267, 1984.</p>
<p class="bibitem"><span class="biblabel">  [55]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/coco/Santhanam01"></a>Rahul Santhanam.   On separators, segregators and time versus space.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 286–294, 2001.</p>
<p class="bibitem"><span class="biblabel">  [56]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSAVITCH1970177"></a>Walter&nbsp;J. Savitch.  Relationships between nondeterministic and deterministic tape      complexities. Journal of Computer and System Sciences, 4(2):177–192, 1970.</p>
<p class="bibitem"><span class="biblabel">  [57]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Schonhage80"></a>Arnold Sch÷nhage. Storage modification machines. SIAM J. Comput., 9(3):490–508,      1980.</p>
<p class="bibitem"><span class="biblabel">  [58]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XShamir92"></a>Adi Shamir. IP = PSPACE. J.&nbsp;of the ACM, 39(4):869–877, October 1992.</p>
<p class="bibitem"><span class="biblabel">  [59]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR29860"></a>Claude&nbsp;E. Shannon. The synthesis of two-terminal switching circuits. Bell System                                                                                                                                                                                          Tech. J., 28:59–98, 1949.</p>
<p class="bibitem"><span class="biblabel">  [60]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSho90"></a>Victor Shoup. New algorithms for finding irreducible polynomials over finite fields.      Mathematics of Computation, 54(189):435–447, 1990.</p>
<p class="bibitem"><span class="biblabel">  [61]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSiegel04"></a>Alan Siegel. On universal classes of extremely random constant-time hash functions.      SIAM J.&nbsp;on Computing, 33(3):505–543, 2004.</p>
<p class="bibitem"><span class="biblabel">  [62]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSip83b"></a>Michael Sipser. A complexity theoretic approach to randomness. In ACM Symp.&nbsp;on      the Theory of Computing (STOC), pages 330–335, 1983.</p>
<p class="bibitem"><span class="biblabel">  [63]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSmo87"></a>Roman Smolensky.  Algebraic methods in the theory of lower bounds for Boolean      circuit complexity.  In 19th ACM Symp.&nbsp;on the Theory of Computing (STOC), pages      77–82. ACM, 1987.</p>
<p class="bibitem"><span class="biblabel">  [64]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert&nbsp;R. Meyer.  Cosmological lower bound on the circuit      complexity of a small problem in logic. J. ACM, 49(6):753–784, 2002.</p>
<p class="bibitem"><span class="biblabel">  [65]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XToda91"></a>Seinosuke Toda.   PP is as hard as the polynomial-time hierarchy.   SIAM J.&nbsp;on      Computing, 20(5):865–877, 1991.</p>
<p class="bibitem"><span class="biblabel">  [66]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/x/Turing37"></a>Alan&nbsp;M.   Turing.      On   computable   numbers,   with   an   application   to   the      entscheidungsproblem. Proc. London Math. Soc., s2-42(1):230–265, 1937.</p>
<p class="bibitem"><span class="biblabel">  [67]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XVal77"></a>Leslie&nbsp;G.  Valiant.   Graph-theoretic  arguments  in  low-level  complexity.   In  6th      Symposium on Mathematical Foundations of Computer Science, volume&nbsp;53 of Lecture      Notes in Computer Science, pages 162–176. Springer, 1977.</p>
<p class="bibitem"><span class="biblabel">  [68]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/ValiantV86"></a>Leslie&nbsp;G. Valiant and Vijay&nbsp;V. Vazirani. NP is as easy as detecting unique solutions.      Theor. Comput. Sci., 47(3):85–93, 1986.</p>
<p class="bibitem"><span class="biblabel">  [69]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMelkebeek06"></a>Dieter  van  Melkebeek.   A  survey  of  lower  bounds  for  satisfiability  and  related                                                                                                                                                                                          problems. Foundations and Trends in Theoretical Computer Science, 2(3):197–303, 2006.</p>
<p class="bibitem"><span class="biblabel">  [70]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/MelkebeekR05"></a>Dieter van Melkebeek and Ran Raz.  A time lower bound for satisfiability.  Theor.      Comput. Sci., 348(2-3):311–320, 2005.</p>
<p class="bibitem"><span class="biblabel">  [71]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/Vinodchandran05"></a>N.&nbsp;V. Vinodchandran.  A note on the circuit complexity of PP.  Theor. Comput.      Sci., 347(1-2):415–418, 2005.</p>
<p class="bibitem"><span class="biblabel">  [72]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaBPvsE"></a>Emanuele Viola.  On approximate majority and probabilistic time.  Computational      Complexity, 18(3):337–375, 2009.</p>
<p class="bibitem"><span class="biblabel">  [73]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-FTTCS09"></a>Emanuele Viola. On the power of small-depth computation. Foundations and Trends      in Theoretical Computer Science, 5(1):1–72, 2009.</p>
<p class="bibitem"><span class="biblabel">  [74]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViola-xxx"></a>Emanuele Viola.  Reducing 3XOR to listing triangles, an exposition.  Available at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2011.</p>
<p class="bibitem"><span class="biblabel">  [75]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-datastructurelb-implies-cclb"></a>Emanuele Viola.  Lower bounds for data structures with space close to maximum      imply  circuit  lower  bounds.    Theory  of  Computing,  15:1–9,  2019.    Available  at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>.</p>
<p class="bibitem"><span class="biblabel">  [76]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-tm"></a>Emanuele  Viola.   Pseudorandom  bits  and  lower  bounds  for  randomized  turing      machines. Theory of Computing, 18(10):1–12, 2022.</p>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T14:41:26Z">Friday, April 14 2023, 14:41</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/04/14/junior-professor-chaire-de-professeur-junior-at-university-lyon-1-apply-by-may-12-2023/'>junior professor (chaire de professeur junior) at University Lyon 1 (apply by May 12, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Tenure track position with a low teaching load and an attractive financial package. Teaching at University Lyon 1 and research in theoretical computer science at the LIP laboratory, located at Ecole Normale Supérieure de Lyon. Teaching in English is possible. Contact person for research: Nicolas Trotignon. For teaching: Saida Bouakaz. Website: www.univ-lyon1.fr/universite/travailler-a-lyon-1/recrutement-chaires-de-professeurs-junior-2022#.ZDkD7exBz9G Email: nicolas.trotignon@ens-lyon.fr
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Tenure track position with a low teaching load and an attractive financial package. Teaching at University Lyon 1 and research in theoretical computer science at the LIP laboratory, located at Ecole Normale Supérieure de Lyon. Teaching in English is possible. Contact person for research: Nicolas Trotignon. For teaching: Saida Bouakaz.</p>
<p>Website: <a href="https://www.univ-lyon1.fr/universite/travailler-a-lyon-1/recrutement-chaires-de-professeurs-junior-2022#.ZDkD7exBz9G">https://www.univ-lyon1.fr/universite/travailler-a-lyon-1/recrutement-chaires-de-professeurs-junior-2022#.ZDkD7exBz9G</a><br />
Email: nicolas.trotignon@ens-lyon.fr</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T07:51:11Z">Friday, April 14 2023, 07:51</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06523'>The 2-Attractor Problem is NP-Complete</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Janosch Fuchs, Philip Whittington</p><p>A $k$-attractor is a combinatorial object unifying dictionary-based
compression. It allows to compare the repetitiveness measures of different
dictionary compressors such as Lempel-Ziv 77, the Burrows-Wheeler transform,
straight line programs and macro schemes. For a string $ T \in \Sigma^n$, the
$k$-attractor is defined as a set of positions $\Gamma \subseteq [1,n]$, such
that every distinct substring of length at most $k$ is covered by at least one
of the selected positions. Thus, if a substring occurs multiple times in $T$,
one position suffices to cover it. A 1-attractor is easily computed in linear
time, while Kempa and Prezza [STOC 2018] have shown that for $k \geq 3$, it is
NP-complete to compute the smallest $k$-attractor by a reduction from $k$-set
cover.
</p>
<p>The main result of this paper answers the open question for the complexity of
the 2-attractor problem, showing that the problem remains NP-complete. Kempa
and Prezza's proof for $k \geq 3$ also reduces the 2-attractor problem to the
2-set cover problem, which is equivalent to edge cover, but that does not fully
capture the complexity of the 2-attractor problem. For this reason, we extend
edge cover by a color function on the edges, yielding the colorful edge cover
problem. Any edge cover must then satisfy the additional constraint that each
color is represented. This extension raises the complexity such that colorful
edge cover becomes NP-complete while also more precisely modeling the
2-attractor problem. We obtain a reduction showing $k$-attractor to be
NP-complete for any $k \geq 2$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fuchs_J/0/1/0/all/0/1">Janosch Fuchs</a>, <a href="http://arxiv.org/find/cs/1/au:+Whittington_P/0/1/0/all/0/1">Philip Whittington</a></p><p>A $k$-attractor is a combinatorial object unifying dictionary-based
compression. It allows to compare the repetitiveness measures of different
dictionary compressors such as Lempel-Ziv 77, the Burrows-Wheeler transform,
straight line programs and macro schemes. For a string $ T \in \Sigma^n$, the
$k$-attractor is defined as a set of positions $\Gamma \subseteq [1,n]$, such
that every distinct substring of length at most $k$ is covered by at least one
of the selected positions. Thus, if a substring occurs multiple times in $T$,
one position suffices to cover it. A 1-attractor is easily computed in linear
time, while Kempa and Prezza [STOC 2018] have shown that for $k \geq 3$, it is
NP-complete to compute the smallest $k$-attractor by a reduction from $k$-set
cover.
</p>
<p>The main result of this paper answers the open question for the complexity of
the 2-attractor problem, showing that the problem remains NP-complete. Kempa
and Prezza's proof for $k \geq 3$ also reduces the 2-attractor problem to the
2-set cover problem, which is equivalent to edge cover, but that does not fully
capture the complexity of the 2-attractor problem. For this reason, we extend
edge cover by a color function on the edges, yielding the colorful edge cover
problem. Any edge cover must then satisfy the additional constraint that each
color is represented. This extension raises the complexity such that colorful
edge cover becomes NP-complete while also more precisely modeling the
2-attractor problem. We obtain a reduction showing $k$-attractor to be
NP-complete for any $k \geq 2$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06713'>Influences of Fourier Completely Bounded Polynomials and Classical Simulation of Quantum Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Francisco Escudero Guti&#xe9;rrez</p><p>We give a new presentation of the main result of Arunachalam, Bri\"et and
Palazuelos (SICOMP'19) and show that quantum query algorithms are characterized
by a new class of polynomials which we call Fourier completely bounded
polynomials. We conjecture that all such polynomials have an influential
variable. This conjecture is weaker than the famous Aaronson-Ambainis (AA)
conjecture (Theory of Computing'14), but has the same implications for
classical simulation of quantum query algorithms.
</p>
<p>We prove a new case of the AA conjecture by showing that it holds for
homogeneous Fourier completely bounded polynomials. This implies that if the
output of $d$-query quantum algorithm is a homogeneous polynomial $p$ of degree
$2d$, then it has a variable with influence at least $Var[p]^2$.
</p>
<p>In addition, we give an alternative proof of the results of Bansal, Sinha and
de Wolf (CCC'22 and QIP'23) showing that block-multilinear completely bounded
polynomials have influential variables. Our proof is simpler, obtains better
constants and does not use randomness.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Gutierrez_F/0/1/0/all/0/1">Francisco Escudero Guti&#xe9;rrez</a></p><p>We give a new presentation of the main result of Arunachalam, Bri\"et and
Palazuelos (SICOMP'19) and show that quantum query algorithms are characterized
by a new class of polynomials which we call Fourier completely bounded
polynomials. We conjecture that all such polynomials have an influential
variable. This conjecture is weaker than the famous Aaronson-Ambainis (AA)
conjecture (Theory of Computing'14), but has the same implications for
classical simulation of quantum query algorithms.
</p>
<p>We prove a new case of the AA conjecture by showing that it holds for
homogeneous Fourier completely bounded polynomials. This implies that if the
output of $d$-query quantum algorithm is a homogeneous polynomial $p$ of degree
$2d$, then it has a variable with influence at least $Var[p]^2$.
</p>
<p>In addition, we give an alternative proof of the results of Bansal, Sinha and
de Wolf (CCC'22 and QIP'23) showing that block-multilinear completely bounded
polynomials have influential variables. Our proof is simpler, obtains better
constants and does not use randomness.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06704'>How Will It Drape Like? Capturing Fabric Mechanics from Depth Images</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Carlos Rodriguez-Pardo, Melania Prieto-Martin, Dan Casas, Elena Garces</p><p>We propose a method to estimate the mechanical parameters of fabrics using a
casual capture setup with a depth camera. Our approach enables to create
mechanically-correct digital representations of real-world textile materials,
which is a fundamental step for many interactive design and engineering
applications. As opposed to existing capture methods, which typically require
expensive setups, video sequences, or manual intervention, our solution can
capture at scale, is agnostic to the optical appearance of the textile, and
facilitates fabric arrangement by non-expert operators. To this end, we propose
a sim-to-real strategy to train a learning-based framework that can take as
input one or multiple images and outputs a full set of mechanical parameters.
Thanks to carefully designed data augmentation and transfer learning protocols,
our solution generalizes to real images despite being trained only on synthetic
data, hence successfully closing the sim-to-real loop.Key in our work is to
demonstrate that evaluating the regression accuracy based on the similarity at
parameter space leads to an inaccurate distances that do not match the human
perception. To overcome this, we propose a novel metric for fabric drape
similarity that operates on the image domain instead on the parameter space,
allowing us to evaluate our estimation within the context of a similarity rank.
We show that out metric correlates with human judgments about the perception of
drape similarity, and that our model predictions produce perceptually accurate
results compared to the ground truth parameters.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Pardo_C/0/1/0/all/0/1">Carlos Rodriguez-Pardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Prieto_Martin_M/0/1/0/all/0/1">Melania Prieto-Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Casas_D/0/1/0/all/0/1">Dan Casas</a>, <a href="http://arxiv.org/find/cs/1/au:+Garces_E/0/1/0/all/0/1">Elena Garces</a></p><p>We propose a method to estimate the mechanical parameters of fabrics using a
casual capture setup with a depth camera. Our approach enables to create
mechanically-correct digital representations of real-world textile materials,
which is a fundamental step for many interactive design and engineering
applications. As opposed to existing capture methods, which typically require
expensive setups, video sequences, or manual intervention, our solution can
capture at scale, is agnostic to the optical appearance of the textile, and
facilitates fabric arrangement by non-expert operators. To this end, we propose
a sim-to-real strategy to train a learning-based framework that can take as
input one or multiple images and outputs a full set of mechanical parameters.
Thanks to carefully designed data augmentation and transfer learning protocols,
our solution generalizes to real images despite being trained only on synthetic
data, hence successfully closing the sim-to-real loop.Key in our work is to
demonstrate that evaluating the regression accuracy based on the similarity at
parameter space leads to an inaccurate distances that do not match the human
perception. To overcome this, we propose a novel metric for fabric drape
similarity that operates on the image domain instead on the parameter space,
allowing us to evaluate our estimation within the context of a similarity rank.
We show that out metric correlates with human judgments about the perception of
drape similarity, and that our model predictions produce perceptually accurate
results compared to the ground truth parameters.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06715'>Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jonathan Crabb&#xe9;, Mihaela van der Schaar</p><p>Interpretability methods are valuable only if their explanations faithfully
describe the explained model. In this work, we consider neural networks whose
predictions are invariant under a specific symmetry group. This includes
popular architectures, ranging from convolutional to graph neural networks. Any
explanation that faithfully explains this type of model needs to be in
agreement with this invariance property. We formalize this intuition through
the notion of explanation invariance and equivariance by leveraging the
formalism from geometric deep learning. Through this rigorous formalism, we
derive (1) two metrics to measure the robustness of any interpretability method
with respect to the model symmetry group; (2) theoretical robustness guarantees
for some popular interpretability methods and (3) a systematic approach to
increase the invariance of any interpretability method with respect to a
symmetry group. By empirically measuring our metrics for explanations of models
associated with various modalities and symmetry groups, we derive a set of 5
guidelines to allow users and developers of interpretability methods to produce
robust explanations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Crabbe_J/0/1/0/all/0/1">Jonathan Crabb&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1">Mihaela van der Schaar</a></p><p>Interpretability methods are valuable only if their explanations faithfully
describe the explained model. In this work, we consider neural networks whose
predictions are invariant under a specific symmetry group. This includes
popular architectures, ranging from convolutional to graph neural networks. Any
explanation that faithfully explains this type of model needs to be in
agreement with this invariance property. We formalize this intuition through
the notion of explanation invariance and equivariance by leveraging the
formalism from geometric deep learning. Through this rigorous formalism, we
derive (1) two metrics to measure the robustness of any interpretability method
with respect to the model symmetry group; (2) theoretical robustness guarantees
for some popular interpretability methods and (3) a systematic approach to
increase the invariance of any interpretability method with respect to a
symmetry group. By empirically measuring our metrics for explanations of models
associated with various modalities and symmetry groups, we derive a set of 5
guidelines to allow users and developers of interpretability methods to produce
robust explanations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06170'>Locality via Global Ties: Stability of the 2-Core Against Misspecification</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Christian Borgs, Geng Zhao</p><p>For many random graph models, the analysis of a related birth process
suggests local sampling algorithms for the size of, e.g., the giant connected
component, the $k$-core, the size and probability of an epidemic outbreak, etc.
In this paper, we study the question of when these algorithms are robust
against misspecification of the graph model, for the special case of the
2-core. We show that, for locally converging graphs with bounded average
degrees, under a weak notion of expansion, a local sampling algorithm provides
robust estimates for the size of both the 2-core and its largest component. Our
weak notion of expansion generalizes the classical definition of expansion,
while holding for many well-studied random graph models.
</p>
<p>Our method involves a two-step sprinkling argument. In the first step, we use
sprinkling to establish the existence of a non-empty $2$-core inside the giant,
while in the second, we use this non-empty $2$-core as seed for a second
sprinkling argument to establish that the giant contains a linear sized
$2$-core. The second step is based on a novel coloring scheme for the vertices
in the tree-part. Our algorithmic results follow from the structural properties
for the $2$-core established in the course of our sprinkling arguments.
</p>
<p>The run-time of our local algorithm is constant independent of the graph
size, with the value of the constant depending on the desired asymptotic
accuracy $\epsilon$. But given the existential nature of local limits, our
arguments do not give any bound on the functional dependence of this constant
on $\epsilon$, nor do they give a bound on how large the graph has to be for
the asymptotic additive error bound $\epsilon$ to hold.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Borgs_C/0/1/0/all/0/1">Christian Borgs</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Geng Zhao</a></p><p>For many random graph models, the analysis of a related birth process
suggests local sampling algorithms for the size of, e.g., the giant connected
component, the $k$-core, the size and probability of an epidemic outbreak, etc.
In this paper, we study the question of when these algorithms are robust
against misspecification of the graph model, for the special case of the
2-core. We show that, for locally converging graphs with bounded average
degrees, under a weak notion of expansion, a local sampling algorithm provides
robust estimates for the size of both the 2-core and its largest component. Our
weak notion of expansion generalizes the classical definition of expansion,
while holding for many well-studied random graph models.
</p>
<p>Our method involves a two-step sprinkling argument. In the first step, we use
sprinkling to establish the existence of a non-empty $2$-core inside the giant,
while in the second, we use this non-empty $2$-core as seed for a second
sprinkling argument to establish that the giant contains a linear sized
$2$-core. The second step is based on a novel coloring scheme for the vertices
in the tree-part. Our algorithmic results follow from the structural properties
for the $2$-core established in the course of our sprinkling arguments.
</p>
<p>The run-time of our local algorithm is constant independent of the graph
size, with the value of the constant depending on the desired asymptotic
accuracy $\epsilon$. But given the existential nature of local limits, our
arguments do not give any bound on the functional dependence of this constant
on $\epsilon$, nor do they give a bound on how large the graph has to be for
the asymptotic additive error bound $\epsilon$ to hold.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06317'>Universally Optimal Deterministic Broadcasting in the HYBRID Distributed Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yi-Jun Chang, Oren Hecht, Dean Leitersdorf</p><p>In theoretical computer science, it is a common practice to show existential
lower bounds for problems, meaning there is a family of pathological inputs on
which no algorithm can do better. However, most inputs of interest can be
solved much more efficiently, giving rise to the notion of universally optimal
algorithms, which run as fast as possible on every input. Questions on the
existence of universally optimal algorithms were first raised by Garay, Kutten,
and Peleg in FOCS '93. This research direction reemerged recently through a
series of works, including the influential work of Haeupler, Wajc, and Zuzic in
STOC '21, which resolves some of these decades-old questions in the supported
CONGEST model.
</p>
<p>We work in the HYBRID distributed model, which analyzes networks combining
both global and local communication. Much attention has recently been devoted
to solving distance related problems, such as All-Pairs Shortest Paths (APSP)
in HYBRID, culminating in a $\tilde \Theta(n^{1/2})$ round algorithm for exact
APSP. However, by definition, every problem in HYBRID is solvable in $D$
(diameter) rounds, showing that it is far from universally optimal.
</p>
<p>We show the first universally optimal algorithms in HYBRID, by presenting a
fundamental tool that solves any broadcasting problem in a universally optimal
number of rounds, deterministically. Specifically, we consider the problem in a
graph $G$ where a set of $k$ messages $M$ distributed arbitrarily across $G$,
requires every node to learn all of $M$. We show a universal lower bound and a
matching, deterministic upper bound, for any graph $G$, any value $k$, and any
distribution of $M$ across $G$.
</p>
<p>This broadcasting tool opens a new exciting direction of research into
showing universally optimal algorithms in HYBRID. As an example, we use it to
obtain algorithms for approximate and exact APSP in general and sparse graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yi-Jun Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hecht_O/0/1/0/all/0/1">Oren Hecht</a>, <a href="http://arxiv.org/find/cs/1/au:+Leitersdorf_D/0/1/0/all/0/1">Dean Leitersdorf</a></p><p>In theoretical computer science, it is a common practice to show existential
lower bounds for problems, meaning there is a family of pathological inputs on
which no algorithm can do better. However, most inputs of interest can be
solved much more efficiently, giving rise to the notion of universally optimal
algorithms, which run as fast as possible on every input. Questions on the
existence of universally optimal algorithms were first raised by Garay, Kutten,
and Peleg in FOCS '93. This research direction reemerged recently through a
series of works, including the influential work of Haeupler, Wajc, and Zuzic in
STOC '21, which resolves some of these decades-old questions in the supported
CONGEST model.
</p>
<p>We work in the HYBRID distributed model, which analyzes networks combining
both global and local communication. Much attention has recently been devoted
to solving distance related problems, such as All-Pairs Shortest Paths (APSP)
in HYBRID, culminating in a $\tilde \Theta(n^{1/2})$ round algorithm for exact
APSP. However, by definition, every problem in HYBRID is solvable in $D$
(diameter) rounds, showing that it is far from universally optimal.
</p>
<p>We show the first universally optimal algorithms in HYBRID, by presenting a
fundamental tool that solves any broadcasting problem in a universally optimal
number of rounds, deterministically. Specifically, we consider the problem in a
graph $G$ where a set of $k$ messages $M$ distributed arbitrarily across $G$,
requires every node to learn all of $M$. We show a universal lower bound and a
matching, deterministic upper bound, for any graph $G$, any value $k$, and any
distribution of $M$ across $G$.
</p>
<p>This broadcasting tool opens a new exciting direction of research into
showing universally optimal algorithms in HYBRID. As an example, we use it to
obtain algorithms for approximate and exact APSP in general and sparse graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06543'>Load Balanced Demand Distribution under Overload Penalties</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sarnath Ramnath, Venkata M. V. Gunturi, Subi Dangol, Abhishek Mishra, Pradeep Kumar</p><p>Input to the Load Balanced Demand Distribution (LBDD) consists of the
following: (a) a set of public service centers (e.g., schools); (b) a set of
demand (people) units and; (c) a cost matrix containing the cost of assignment
for all demand unit-service center pairs. In addition, each service center is
also associated with a notion of capacity and a penalty which is incurred if it
gets overloaded. Given the input, the LBDD problem determines a mapping from
the set of demand units to the set of service centers. The objective is to
determine a mapping that minimizes the sum of the following two terms: (i) the
total assignment cost between demand units and their allotted service centers
and, (ii) total of penalties incurred. The problem of LBDD finds its
application in the domain of urban planning. An instance of the LBDD problem
can be reduced to an instance of the min-cost bi-partite matching problem.
However, this approach cannot scale up to the real world large problem
instances. The current state of the art related to LBDD makes simplifying
assumptions such as infinite capacity or total capacity being equal to the
total demand. This paper proposes a novel allotment subspace re-adjustment
based approach (ASRAL) for the LBDD problem. We analyze ASRAL theoretically and
present its asymptotic time complexity. We also evaluate ASRAL experimentally
on large problem instances and compare with alternative approaches. Our results
indicate that ASRAL is able to scale-up while maintaining significantly better
solution quality over the alternative approaches. In addition, we also extend
ASRAL to para-ASRAL which uses the GPU and CPU cores to speed-up the execution
while maintaining the same solution quality as ASRAL.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ramnath_S/0/1/0/all/0/1">Sarnath Ramnath</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunturi_V/0/1/0/all/0/1">Venkata M. V. Gunturi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dangol_S/0/1/0/all/0/1">Subi Dangol</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1">Abhishek Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1">Pradeep Kumar</a></p><p>Input to the Load Balanced Demand Distribution (LBDD) consists of the
following: (a) a set of public service centers (e.g., schools); (b) a set of
demand (people) units and; (c) a cost matrix containing the cost of assignment
for all demand unit-service center pairs. In addition, each service center is
also associated with a notion of capacity and a penalty which is incurred if it
gets overloaded. Given the input, the LBDD problem determines a mapping from
the set of demand units to the set of service centers. The objective is to
determine a mapping that minimizes the sum of the following two terms: (i) the
total assignment cost between demand units and their allotted service centers
and, (ii) total of penalties incurred. The problem of LBDD finds its
application in the domain of urban planning. An instance of the LBDD problem
can be reduced to an instance of the min-cost bi-partite matching problem.
However, this approach cannot scale up to the real world large problem
instances. The current state of the art related to LBDD makes simplifying
assumptions such as infinite capacity or total capacity being equal to the
total demand. This paper proposes a novel allotment subspace re-adjustment
based approach (ASRAL) for the LBDD problem. We analyze ASRAL theoretically and
present its asymptotic time complexity. We also evaluate ASRAL experimentally
on large problem instances and compare with alternative approaches. Our results
indicate that ASRAL is able to scale-up while maintaining significantly better
solution quality over the alternative approaches. In addition, we also extend
ASRAL to para-ASRAL which uses the GPU and CPU cores to speed-up the execution
while maintaining the same solution quality as ASRAL.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06552'>Beyond the Quadratic Time Barrier for Network Unreliability</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ruoxu Cen, William He, Jason Li, Debmalya Panigrahi</p><p>Karger (STOC 1995) gave the first FPTAS for the network (un)reliability
problem, setting in motion research over the next three decades that obtained
increasingly faster running times, eventually leading to a
$\tilde{O}(n^2)$-time algorithm (Karger, STOC 2020). This represented a natural
culmination of this line of work because the algorithmic techniques used can
enumerate $\Theta(n^2)$ (near)-minimum cuts. In this paper, we go beyond this
quadratic barrier and obtain a faster algorithm for the network unreliability
problem. Our algorithm runs in $m^{1+o(1)} + \tilde{O}(n^{1.5})$ time.
</p>
<p>Our main contribution is a new estimator for network unreliability in very
reliable graphs. These graphs are usually the bottleneck for network
unreliability since the disconnection event is elusive. Our estimator is
obtained by defining an appropriate importance sampling subroutine on a dual
spanning tree packing of the graph. To complement this estimator for very
reliable graphs, we use recursive contraction for moderately reliable graphs.
We show that an interleaving of sparsification and contraction can be used to
obtain a better parametrization of the recursive contraction algorithm that
yields a faster running time matching the one obtained for the very reliable
case.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cen_R/0/1/0/all/0/1">Ruoxu Cen</a>, <a href="http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1">William He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jason Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Panigrahi_D/0/1/0/all/0/1">Debmalya Panigrahi</a></p><p>Karger (STOC 1995) gave the first FPTAS for the network (un)reliability
problem, setting in motion research over the next three decades that obtained
increasingly faster running times, eventually leading to a
$\tilde{O}(n^2)$-time algorithm (Karger, STOC 2020). This represented a natural
culmination of this line of work because the algorithmic techniques used can
enumerate $\Theta(n^2)$ (near)-minimum cuts. In this paper, we go beyond this
quadratic barrier and obtain a faster algorithm for the network unreliability
problem. Our algorithm runs in $m^{1+o(1)} + \tilde{O}(n^{1.5})$ time.
</p>
<p>Our main contribution is a new estimator for network unreliability in very
reliable graphs. These graphs are usually the bottleneck for network
unreliability since the disconnection event is elusive. Our estimator is
obtained by defining an appropriate importance sampling subroutine on a dual
spanning tree packing of the graph. To complement this estimator for very
reliable graphs, we use recursive contraction for moderately reliable graphs.
We show that an interleaving of sparsification and contraction can be used to
obtain a better parametrization of the recursive contraction algorithm that
yields a faster running time matching the one obtained for the very reliable
case.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06565'>List Update with Delays or Time Windows</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yossi Azar, Shahar Lewkowicz, Danny Vainstein</p><p>We consider the problem of List Update, one of the most fundamental problems
in online algorithms. We are given a list of elements and requests for these
elements that arrive over time. Our goal is to serve these requests, at a cost
equivalent to their position in the list, with the option of moving them
towards the head of the list. Sleator and Tarjan introduced the famous "Move to
Front" algorithm (wherein any requested element is immediately moved to the
head of the list) and showed that it is 2-competitive. While this bound is
excellent, the absolute cost of the algorithm's solution may be very large
(e.g., requesting the last half elements of the list would result in a solution
cost that is quadratic in the length of the list). Thus, we consider the more
general problem wherein every request arrives with a deadline and must be
served, not immediately, but rather before the deadline. We further allow the
algorithm to serve multiple requests simultaneously. We denote this problem as
List Update with Time Windows. While this generalization benefits from lower
solution costs, it requires new types of algorithms. In particular, for the
simple example of requesting the last half elements of the list with
overlapping time windows, Move-to-Front fails. We show an O(1) competitive
algorithm. The algorithm is natural but the analysis is a bit complicated and a
novel potential function is required. Thereafter we consider the more general
problem of List Update with Delays in which the deadlines are replaced with
arbitrary delay functions. This problem includes as a special case the prize
collecting version in which a request might not be served (up to some deadline)
and instead suffers an arbitrary given penalty. Here we also establish an O(1)
competitive algorithm for general delays. The algorithm for the delay version
is more complex and its analysis is significantly more involved.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Azar_Y/0/1/0/all/0/1">Yossi Azar</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewkowicz_S/0/1/0/all/0/1">Shahar Lewkowicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Vainstein_D/0/1/0/all/0/1">Danny Vainstein</a></p><p>We consider the problem of List Update, one of the most fundamental problems
in online algorithms. We are given a list of elements and requests for these
elements that arrive over time. Our goal is to serve these requests, at a cost
equivalent to their position in the list, with the option of moving them
towards the head of the list. Sleator and Tarjan introduced the famous "Move to
Front" algorithm (wherein any requested element is immediately moved to the
head of the list) and showed that it is 2-competitive. While this bound is
excellent, the absolute cost of the algorithm's solution may be very large
(e.g., requesting the last half elements of the list would result in a solution
cost that is quadratic in the length of the list). Thus, we consider the more
general problem wherein every request arrives with a deadline and must be
served, not immediately, but rather before the deadline. We further allow the
algorithm to serve multiple requests simultaneously. We denote this problem as
List Update with Time Windows. While this generalization benefits from lower
solution costs, it requires new types of algorithms. In particular, for the
simple example of requesting the last half elements of the list with
overlapping time windows, Move-to-Front fails. We show an O(1) competitive
algorithm. The algorithm is natural but the analysis is a bit complicated and a
novel potential function is required. Thereafter we consider the more general
problem of List Update with Delays in which the deadlines are replaced with
arbitrary delay functions. This problem includes as a special case the prize
collecting version in which a request might not be served (up to some deadline)
and instead suffers an arbitrary given penalty. Here we also establish an O(1)
competitive algorithm for general delays. The algorithm for the delay version
is more complex and its analysis is significantly more involved.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06594'>Solving Tensor Low Cycle Rank Approximation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yichuan Deng, Yeqi Gao, Zhao Song</p><p>Large language models have become ubiquitous in modern life, finding
applications in various domains such as natural language processing, language
translation, and speech recognition. Recently, a breakthrough work [Zhao,
Panigrahi, Ge, and Arora Arxiv 2023] explains the attention model from
probabilistic context-free grammar (PCFG). One of the central computation task
for computing probability in PCFG is formulating a particular tensor low rank
approximation problem, we can call it tensor cycle rank. Given an $n \times n
\times n$ third order tensor $A$, we say that $A$ has cycle rank-$k$ if there
exists three $n \times k^2$ size matrices $U , V$, and $W$ such that for each
entry in each \begin{align*} A_{a,b,c} = \sum_{i=1}^k \sum_{j=1}^k \sum_{l=1}^k
U_{a,i+k(j-1)} \otimes V_{b, j + k(l-1)} \otimes W_{c, l + k(i-1) }
\end{align*} for all $a \in [n], b \in [n], c \in [n]$. For the tensor
classical rank, tucker rank and train rank, it has been well studied in [Song,
Woodruff, Zhong SODA 2019]. In this paper, we generalize the previous
``rotation and sketch'' technique in page 186 of [Song, Woodruff, Zhong SODA
2019] and show an input sparsity time algorithm for cycle rank.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yichuan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yeqi Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a></p><p>Large language models have become ubiquitous in modern life, finding
applications in various domains such as natural language processing, language
translation, and speech recognition. Recently, a breakthrough work [Zhao,
Panigrahi, Ge, and Arora Arxiv 2023] explains the attention model from
probabilistic context-free grammar (PCFG). One of the central computation task
for computing probability in PCFG is formulating a particular tensor low rank
approximation problem, we can call it tensor cycle rank. Given an $n \times n
\times n$ third order tensor $A$, we say that $A$ has cycle rank-$k$ if there
exists three $n \times k^2$ size matrices $U , V$, and $W$ such that for each
entry in each \begin{align*} A_{a,b,c} = \sum_{i=1}^k \sum_{j=1}^k \sum_{l=1}^k
U_{a,i+k(j-1)} \otimes V_{b, j + k(l-1)} \otimes W_{c, l + k(i-1) }
\end{align*} for all $a \in [n], b \in [n], c \in [n]$. For the tensor
classical rank, tucker rank and train rank, it has been well studied in [Song,
Woodruff, Zhong SODA 2019]. In this paper, we generalize the previous
``rotation and sketch'' technique in page 186 of [Song, Woodruff, Zhong SODA
2019] and show an input sparsity time algorithm for cycle rank.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06596'>Beyond Submodularity: A Unified Framework of Randomized Set Selection with Group Fairness Constraints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shaojie Tang, Jing Yuan</p><p>Machine learning algorithms play an important role in a variety of important
decision-making processes, including targeted advertisement displays, home loan
approvals, and criminal behavior predictions. Given the far-reaching impact of
these algorithms, it is crucial that they operate fairly, free from bias or
prejudice towards certain groups in the population. Ensuring impartiality in
these algorithms is essential for promoting equality and avoiding
discrimination. To this end we introduce a unified framework for randomized
subset selection that incorporates group fairness constraints. Our problem
involves a global utility function and a set of group utility functions for
each group, here a group refers to a group of individuals (e.g., people)
sharing the same attributes (e.g., gender). Our aim is to generate a
distribution across feasible subsets, specifying the selection probability of
each feasible set, to maximize the global utility function while meeting a
predetermined quota for each group utility function in expectation. Note that
there may not necessarily be any direct connections between the global utility
function and each group utility function. We demonstrate that this framework
unifies and generalizes many significant applications in machine learning and
operations research. Our algorithmic results either improves the best known
result or provide the first approximation algorithms for new applications.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Shaojie Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Jing Yuan</a></p><p>Machine learning algorithms play an important role in a variety of important
decision-making processes, including targeted advertisement displays, home loan
approvals, and criminal behavior predictions. Given the far-reaching impact of
these algorithms, it is crucial that they operate fairly, free from bias or
prejudice towards certain groups in the population. Ensuring impartiality in
these algorithms is essential for promoting equality and avoiding
discrimination. To this end we introduce a unified framework for randomized
subset selection that incorporates group fairness constraints. Our problem
involves a global utility function and a set of group utility functions for
each group, here a group refers to a group of individuals (e.g., people)
sharing the same attributes (e.g., gender). Our aim is to generate a
distribution across feasible subsets, specifying the selection probability of
each feasible set, to maximize the global utility function while meeting a
predetermined quota for each group utility function in expectation. Note that
there may not necessarily be any direct connections between the global utility
function and each group utility function. We demonstrate that this framework
unifies and generalizes many significant applications in machine learning and
operations research. Our algorithmic results either improves the best known
result or provide the first approximation algorithms for new applications.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06656'>Improved Approximations for Relative Survivable Network Design</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Dinitz, Ama Koranteng, Guy Kortsarz, Zeev Nutov</p><p>One of the most important and well-studied settings for network design is
edge-connectivity requirements. This encompasses uniform demands such as the
Minimum $k$-Edge-Connected Spanning Subgraph problem as well as nonuniform
demands such as the Survivable Network Design problem (SND). In a recent paper
by [Dinitz, Koranteng, Kortsarz APPROX '22] , the authors observed that a
weakness of these formulations is that it does not enable one to consider
fault-tolerance in graphs that have just one small cut. To remedy this, they
introduced new variants of these problems under the notion "relative"
fault-tolerance. Informally, this requires not that two nodes are connected if
there are a bounded number of faults (as in the classical setting), but that
two nodes are connected if there are a bounded number of faults and the two
nodes are connected in the underlying graph post-faults. The problem is already
highly non-trivial even for the case of a single demand.
</p>
<p>Due to difficulties introduced by this new notion of fault-tolerance, the
results in [Dinitz, Koranteng, Kortsarz APPROX '22] are quite limited. For the
Relative Survivable Network Design problem (RSND), when the demands are not
uniform they give a nontrivial result only when there is a single demand with a
connectivity requirement of $3$: a non-optimal $27/4$-approximation. We
strengthen this result in two significant ways: We give a $2$-approximation for
RSND where all requirements are at most $3$, and a $2^{O(k^2)}$-approximation
for RSND with a single demand of arbitrary value $k$. To achieve these results,
we first use the "cactus representation'' of minimum cuts to give a lossless
reduction to normal SND. Second, we extend the techniques of [Dinitz,
Koranteng, Kortsarz APPROX '22] to prove a generalized and more complex version
of their structure theorem, which we then use to design a recursive
approximation algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dinitz_M/0/1/0/all/0/1">Michael Dinitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Koranteng_A/0/1/0/all/0/1">Ama Koranteng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kortsarz_G/0/1/0/all/0/1">Guy Kortsarz</a>, <a href="http://arxiv.org/find/cs/1/au:+Nutov_Z/0/1/0/all/0/1">Zeev Nutov</a></p><p>One of the most important and well-studied settings for network design is
edge-connectivity requirements. This encompasses uniform demands such as the
Minimum $k$-Edge-Connected Spanning Subgraph problem as well as nonuniform
demands such as the Survivable Network Design problem (SND). In a recent paper
by [Dinitz, Koranteng, Kortsarz APPROX '22] , the authors observed that a
weakness of these formulations is that it does not enable one to consider
fault-tolerance in graphs that have just one small cut. To remedy this, they
introduced new variants of these problems under the notion "relative"
fault-tolerance. Informally, this requires not that two nodes are connected if
there are a bounded number of faults (as in the classical setting), but that
two nodes are connected if there are a bounded number of faults and the two
nodes are connected in the underlying graph post-faults. The problem is already
highly non-trivial even for the case of a single demand.
</p>
<p>Due to difficulties introduced by this new notion of fault-tolerance, the
results in [Dinitz, Koranteng, Kortsarz APPROX '22] are quite limited. For the
Relative Survivable Network Design problem (RSND), when the demands are not
uniform they give a nontrivial result only when there is a single demand with a
connectivity requirement of $3$: a non-optimal $27/4$-approximation. We
strengthen this result in two significant ways: We give a $2$-approximation for
RSND where all requirements are at most $3$, and a $2^{O(k^2)}$-approximation
for RSND with a single demand of arbitrary value $k$. To achieve these results,
we first use the "cactus representation'' of minimum cuts to give a lossless
reduction to normal SND. Second, we extend the techniques of [Dinitz,
Koranteng, Kortsarz APPROX '22] to prove a generalized and more complex version
of their structure theorem, which we then use to design a recursive
approximation algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.06664'>On streaming approximation algorithms for constraint satisfaction problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Noah G. Singer</p><p>In this thesis, we explore streaming algorithms for approximating constraint
satisfaction problems (CSPs). The setup is roughly the following: A computer
has limited memory space, sees a long "stream" of local constraints on a set of
variables, and tries to estimate how many of the constraints may be
simultaneously satisfied. The past ten years have seen a number of works in
this area, and this thesis includes both expository material and novel
contributions. Throughout, we emphasize connections to the broader theories of
CSPs, approximability, and streaming models, and highlight interesting open
problems.
</p>
<p>The first part of our thesis is expository: We present aspects of previous
works that completely characterize the approximability of specific CSPs like
Max-Cut and Max-Dicut with $\sqrt{n}$-space streaming algorithm (on
$n$-variable instances), while characterizing the approximability of all CSPs
in $\sqrt n$ space in the special case of "composable" (i.e., sketching)
algorithms, and of a particular subclass of CSPs with linear-space streaming
algorithms.
</p>
<p>In the second part of the thesis, we present two of our own joint works. We
begin with a work with Madhu Sudan and Santhoshini Velusamy in which we prove
linear-space streaming approximation-resistance for all ordering CSPs (OCSPs),
which are "CSP-like" problems maximizing over sets of permutations. Next, we
present joint work with Joanna Boyland, Michael Hwang, Tarun Prasad, and
Santhoshini Velusamy in which we investigate the $\sqrt n$-space streaming
approximability of symmetric Boolean CSPs with negations. We give explicit
$\sqrt n$-space sketching approximability ratios for several families of CSPs,
including Max-$k$AND; develop simpler optimal sketching approximation
algorithms for threshold predicates; and show that previous lower bounds fail
to characterize the $\sqrt n$-space streaming approximability of Max-$3$AND.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Singer_N/0/1/0/all/0/1">Noah G. Singer</a></p><p>In this thesis, we explore streaming algorithms for approximating constraint
satisfaction problems (CSPs). The setup is roughly the following: A computer
has limited memory space, sees a long "stream" of local constraints on a set of
variables, and tries to estimate how many of the constraints may be
simultaneously satisfied. The past ten years have seen a number of works in
this area, and this thesis includes both expository material and novel
contributions. Throughout, we emphasize connections to the broader theories of
CSPs, approximability, and streaming models, and highlight interesting open
problems.
</p>
<p>The first part of our thesis is expository: We present aspects of previous
works that completely characterize the approximability of specific CSPs like
Max-Cut and Max-Dicut with $\sqrt{n}$-space streaming algorithm (on
$n$-variable instances), while characterizing the approximability of all CSPs
in $\sqrt n$ space in the special case of "composable" (i.e., sketching)
algorithms, and of a particular subclass of CSPs with linear-space streaming
algorithms.
</p>
<p>In the second part of the thesis, we present two of our own joint works. We
begin with a work with Madhu Sudan and Santhoshini Velusamy in which we prove
linear-space streaming approximation-resistance for all ordering CSPs (OCSPs),
which are "CSP-like" problems maximizing over sets of permutations. Next, we
present joint work with Joanna Boyland, Michael Hwang, Tarun Prasad, and
Santhoshini Velusamy in which we investigate the $\sqrt n$-space streaming
approximability of symmetric Boolean CSPs with negations. We give explicit
$\sqrt n$-space sketching approximability ratios for several families of CSPs,
including Max-$k$AND; develop simpler optimal sketching approximation
algorithms for threshold predicates; and show that previous lower bounds fail
to characterize the $\sqrt n$-space streaming approximability of Max-$3$AND.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-14T00:30:00Z">Friday, April 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, April 13
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/04/my-week-at-simons.html'>My Week at Simons</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>This week finds me at the Simons Institute for Theoretical Computer Science in Berkeley California. Simons started about the same time I joined the administrative ranks and never had the opportunity to spend a full semester there. I can manage a shorter trip and purposely chose a week with no workshops and great visitors including Sam Buss, Russell Impagliazzo, Valentine Kabanets, Toni Pitassi, Ryan Williams, former student Rahul Santhanam and former postdocs Pavan Aduri and Vinod Variyam and many others including the next generations of complexity theory leaders. Simons is having programs on Meta-Complexity and an "extended reunion" for Satisfiability. Apparently I used to work on Meta-Complexity before it was a thing.</p><p>Computational complexity traditionally has tried to get ahead of new technologies, and modelled randomized, parallel, quantum computation and cryptography in the infancy of their development allowing complexity to help guide our understanding and development of these areas. In the last twenty years or so, complexity has migrated more towards mathematics, and has mostly missed technological changes like cloud computing, hierarchical memory models, edge and mobile computing for example.&nbsp;</p><p>But the recent advances in optimization and machine learning cannot be ignored. There has certainly been plenty of discussion of ChatGPT and Russell gave an informal lecture yesterday trying to model large-language models at some level. I've been having some discussions about how complexity can answer questions like what it means for a model to be explainable.&nbsp;</p><p>Complexity theory also out to reckon that practically we seem to be getting the best of P = NP while avoiding losing cryptography simultaneously in Heuristica and Cryptomania among Russell's five worlds. Russell claims we're not in Heuristica, at least not now, since we can still generate hard to solve problems. But if our models aren't modeling the world we live in, perhaps it's time to rethink the models.&nbsp;</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>This week finds me at the <a href="https://simons.berkeley.edu/">Simons Institute for Theoretical Computer Science</a> in Berkeley California. Simons started about the same time I joined the administrative ranks and never had the opportunity to spend a full semester there. I can manage a shorter trip and purposely chose a week with no workshops and great visitors including Sam Buss, Russell Impagliazzo, Valentine Kabanets, Toni Pitassi, Ryan Williams, former student Rahul Santhanam and former postdocs Pavan Aduri and Vinod Variyam and <a href="https://simons.berkeley.edu/people/visitors">many others</a> including the next generations of complexity theory leaders. Simons is having programs on <a href="https://simons.berkeley.edu/programs/Meta-Complexity2023">Meta-Complexity</a> and an "extended reunion" for <a href="https://simons.berkeley.edu/programs/extended-reunion-satisfiability">Satisfiability</a>. Apparently I used to work on Meta-Complexity before it was a thing.</p><p>Computational complexity traditionally has tried to get ahead of new technologies, and modelled randomized, parallel, quantum computation and cryptography in the infancy of their development allowing complexity to help guide our understanding and development of these areas. In the last twenty years or so, complexity has migrated more towards mathematics, and has mostly missed technological changes like cloud computing, hierarchical memory models, edge and mobile computing for example.&nbsp;</p><p>But the recent advances in optimization and machine learning cannot be ignored. There has certainly been plenty of discussion of ChatGPT and Russell gave an informal lecture yesterday trying to model large-language models at some level. I've been having some discussions about how complexity can answer questions like what it means for a model to be explainable.&nbsp;</p><p>Complexity theory also out to reckon that practically we seem to be getting the best of P = NP while avoiding losing cryptography <a href="https://blog.computationalcomplexity.org/2020/12/optiland.html">simultaneously</a> in Heuristica and Cryptomania among Russell's <a href="https://blog.computationalcomplexity.org/2004/06/impagliazzos-five-worlds.html">five worlds</a>. Russell claims we're not in Heuristica, at least not now, since we can still generate hard to solve problems. But if our models aren't modeling the world we live in, perhaps it's time to rethink the models.&nbsp;</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T17:07:00Z">Thursday, April 13 2023, 17:07</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/045'>TR23-045 |  Tight Correlation Bounds for Circuits Between AC0 and TC0 | 

	Vinayak Kumar</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We initiate the study of generalized $AC^0$ circuits comprised of arbitrary unbounded fan-in gates which only need to be constant over inputs of Hamming weight $\ge k$ (up to negations of the input bits), which we denote $GC^0(k)$. The gate set of this class includes biased LTFs like the $k$-$OR$ (outputs $1$ iff $\ge k$ bits are $1$) and $k$-$AND$ (outputs $0$ iff $\ge k$ bits are $0$), and thus can be seen as an interpolation between $AC^0$ and $TC^0$. 

We establish a tight multi-switching lemma for $GC(k)$ circuits, which bounds the probability that several depth-2 $GC^0(k)$ circuits do not simultaneously simplify under a random restriction. We also establish a new depth reduction lemma such that coupled with our multi-switching lemma, we can show many results obtained from the multi-switching lemma for depth-$d$ size-$s$ $AC^0$ circuits lifts to depth-$d$ size-$s^{.99}$ $GC^0(.01\log s)$ circuits with no loss in parameters (other than hidden constants). 

Our result has the following applications:

-Size-$2^{\Omega(n^{1/d})}$ depth-$d$ $GC^0(\Omega(n^{1/d}))$ circuits do not correlate with parity (extending a result of Håstad (SICOMP, 2014)).

-Size-$n^{\Omega(\log n)}$ $GC^0(\Omega(\log^2 n))$ circuits with $n^{.249}$ arbitrary threshold gates or $n^{.499}$ arbitrary symmetric gates exhibit exponentially small correlation against an explicit function (extending a result of Tan and Servedio (RANDOM, 2019)).

-There is a seed length $O((\log m)^{d-1}\log(m/\varepsilon)\log\log(m))$ pseudorandom generator against size-$m$ depth-$d$ $GC^0(\log m)$ circuits, matching the $AC^0$ lower bound of Håstad up to a $\log\log m$ factor (extending a result of Lyu (CCC, 2022)).

-Size-$m$ $GC^0(\log m)$ circuits have exponentially small Fourier tails (extending a result of Tal (CCC, 2017)).
        
        </div>

        <div class='tr-article-summary'>
        
          
          We initiate the study of generalized $AC^0$ circuits comprised of arbitrary unbounded fan-in gates which only need to be constant over inputs of Hamming weight $\ge k$ (up to negations of the input bits), which we denote $GC^0(k)$. The gate set of this class includes biased LTFs like the $k$-$OR$ (outputs $1$ iff $\ge k$ bits are $1$) and $k$-$AND$ (outputs $0$ iff $\ge k$ bits are $0$), and thus can be seen as an interpolation between $AC^0$ and $TC^0$. 

We establish a tight multi-switching lemma for $GC(k)$ circuits, which bounds the probability that several depth-2 $GC^0(k)$ circuits do not simultaneously simplify under a random restriction. We also establish a new depth reduction lemma such that coupled with our multi-switching lemma, we can show many results obtained from the multi-switching lemma for depth-$d$ size-$s$ $AC^0$ circuits lifts to depth-$d$ size-$s^{.99}$ $GC^0(.01\log s)$ circuits with no loss in parameters (other than hidden constants). 

Our result has the following applications:

-Size-$2^{\Omega(n^{1/d})}$ depth-$d$ $GC^0(\Omega(n^{1/d}))$ circuits do not correlate with parity (extending a result of Håstad (SICOMP, 2014)).

-Size-$n^{\Omega(\log n)}$ $GC^0(\Omega(\log^2 n))$ circuits with $n^{.249}$ arbitrary threshold gates or $n^{.499}$ arbitrary symmetric gates exhibit exponentially small correlation against an explicit function (extending a result of Tan and Servedio (RANDOM, 2019)).

-There is a seed length $O((\log m)^{d-1}\log(m/\varepsilon)\log\log(m))$ pseudorandom generator against size-$m$ depth-$d$ $GC^0(\log m)$ circuits, matching the $AC^0$ lower bound of Håstad up to a $\log\log m$ factor (extending a result of Lyu (CCC, 2022)).

-Size-$m$ $GC^0(\log m)$ circuits have exponentially small Fourier tails (extending a result of Tal (CCC, 2017)).
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T11:23:19Z">Thursday, April 13 2023, 11:23</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/'>ACM Prize to Yael Kalai</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Plus evocations of the roles of complexity and verification in crypto and human relations Yael Kalai has just been named the winner of the 2022 ACM Prize. She works at Microsoft Research. Today we congratulate her, say a little about her work, and riff on some related and &#8220;unrelated&#8221; matters. The prize cites Kalai for [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>Plus evocations of the roles of complexity and verification in crypto and human relations</em><br />
<font color="#000000"></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/kalai_6965246/" rel="attachment wp-att-21430"><img data-attachment-id="21430" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/kalai_6965246/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kalai_6965246.jpeg?fit=485%2C550&amp;ssl=1" data-orig-size="485,550" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kalai_6965246" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kalai_6965246.jpeg?fit=265%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kalai_6965246.jpeg?fit=485%2C550&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kalai_6965246.jpeg?resize=124%2C138&#038;ssl=1" alt="" width="124" height="138" class="alignright wp-image-21430" data-recalc-dims="1" /></a></p>
<p>
Yael Kalai has just been named the winner of the <a href="https://awards.acm.org/about/2022-acm-prize">2022 ACM Prize</a>. She works at Microsoft Research. </p>
<p>
Today we congratulate her, say a little about her work, and riff on some related and &#8220;unrelated&#8221; matters.<br />
<span id="more-21427"></span></p>
<p>
The prize cites Kalai for her work on cryptography. Her work is immediately practical. It provides both ways to speed up interactive protocols and to verify the results. Two ways of speeding up the kind of protocols we engage in daily are:</p>
<ol>
<li>
Reduce the number of rounds of interaction needed. </p>
<li>
Shift the computational burden from the weaker party (exemplified by your credit card chip) to the stronger party&#8212;without allowing the latter more ways to be malicious.
</ol>
<p>
One also needs to devise and provide an efficient certificate that the security needs have been met.</p>
<p>
<p><H2> Her Work </H2></p>
<p><p>
Kalai&#8217;s work on objective 1 starts with a <a href="https://en.wikipedia.org/wiki/Fiat-Shamir_heuristic">paradigm</a> originally expounded by Amos Fiat and Adi Shamir in the 1980s:</p>
<blockquote><p><b> </b> <em> An interactive round in which Arthur challenges Merlin with a string he chose <b>randomly</b> from public coins can be replaced by nonteractive requests to a random oracle. The oracle in turn can be simulated via a cryptographically strong hash function. </em>
</p></blockquote>
<p><p>
The second clause is the delicate one. How can we know, in a particular application, that a particular hash function does not have correlations that could be exploited by malicious choices of plaintext or seed strings? She and Shafi Goldwasser, her PhD advisor, <a href="https://eprint.iacr.org/2003/034.pdf">showed</a> cases where a 3-round protocol secure in the random oracle model becomes insecure under cases of this transformation. </p>
<p>
However, in a series of papers culminating in a <a href="https://dl.acm.org/doi/10.1145/3313276.3316380">Part I</a> and a <a href="https://eprint.iacr.org/2018/1248.pdf">Part II</a>, she and coauthors designed cases that work under progressively more reasonable hardness assumptions. (Note: the date on the &#8220;Part II&#8221; paper is three days earlier than that on the &#8220;Part I&#8221;&#8211;a good solution to a problem we noted at the end of <a href="https://rjlipton.wpcomstaging.com/2013/03/13/no-go-theorems/">this post</a>.)</p>
<p>
Objective 2 not only runs the risk of leakage in shifting the party who executes the computation, it involves issues of trust. How does the one who delegated the task know the result is correct, without having done the computation? This leads to issues of proving computations correct that we have mentioned, but with a twist: both the computation and the proof needs to be real-time efficient to generate. Her many papers on this (ACM features <a href="https://dl.acm.org/doi/10.1145/2699436">these</a> <a href="https://dl.acm.org/doi/pdf/10.1145/3456867">two</a>) are well represented in a <a href="https://gilkalai.files.wordpress.com/2018/01/cacm-delegation.pdf">survey</a> she presented at the 2018 International Congress of Mathematicians. Its abstract proclaims:</p>
<blockquote><p><b> </b> <em> Efficient verification of computation, also known as delegation of computation, is one of the most fundamental notions in computer science, and in particular it lies at the heart of the P vs. NP question. </em>
</p></blockquote>
<p>
<p><H2> P = NP: An Omen? </H2></p>
<p><p>
Her survey was unveiled &#8220;exclusively for our readers&#8221; in a January 6, 2018 <a href="https://gilkalai.wordpress.com/2018/01/06/yael-tauman-kalais-icm2018-paper-my-paper-and-cryptography/">post</a> by Gil Kalai, along with two photos of adoring father(-in-law)/grandparent type. We hasten to add that all this is not just about how &#8220;P=NP?&#8221; captures the question of whether it is as easy to <em>generate</em> a proof as to <em>verify</em> it. Much of Yael Kalai&#8217;s work depends on hardness assumptions that vanish if in fact P equals NP (with relevant efficiency).</p>
<p>
Thinking of Gil Kalai makes us leap to two other topics that are variously related and &#8220;unrelated.&#8221; Gil recently <a href="https://gilkalai.wordpress.com/2023/03/27/critical-times-in-israel-last-nights-demonstrations/">featured</a> the following photo from street protests in Israel on his blog:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/pnp-3/" rel="attachment wp-att-21433"><img data-attachment-id="21433" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/pnp-3/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?fit=1080%2C816&amp;ssl=1" data-orig-size="1080,816" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pnp" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?fit=300%2C227&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?fit=600%2C454&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=550%2C415&#038;ssl=1" alt="" width="550" height="415" class="aligncenter wp-image-21433" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=1024%2C774&amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=300%2C227&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=768%2C580&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?w=1080&amp;ssl=1 1080w" sizes="(max-width: 550px) 100vw, 550px" data-recalc-dims="1" /></a></p>
<p><P><br />
The photo was also <a href="https://scottaaronson.blog/?p=7170">picked up</a> and commented on by Scott Aaronson on his blog. Gil added:</p>
<blockquote><p><b> </b> <em> Whether the picture is genuine or not, it shows the anarchist nature of at least some of the protestors. (We know for sure that some computer scientists were there.) I am not sure if a proof of this bold claim was also provided. </em>
</p></blockquote>
<p><p>
Lightheartedness aside, we wonder if this is an omen of growing public awareness of the connection of our field&#8217;s signature question not only to the security workings of governments, but to the walks of life represented by Yael Kalai&#8217;s applications. </p>
<p>
<p><H2> Educating GPT </H2></p>
<p><p>
Your humble bloggers face a kind of verification problem with nearly every post: how to pin down and attest basic facts. Here we remembered <a href="https://rjlipton.wpcomstaging.com/2014/12/13/chats/">writing</a> in 2014&#8212;correctly&#8212;that &#8220;Yael Kalai [is] not related to our friend Gil Kalai.&#8221; But learning that Yael Tauman married Adam Kalai (<a href="https://en.wikipedia.org/wiki/Yael_Tauman_Kalai">which</a> is <a href="https://www.facebook.com/adam.t.kalai/">attested</a> in <a href="https://kids.kiddle.co/Yael_Tauman_Kalai">many</a> <a href="https://www.microsoft.com/en-us/research/blog/new-england-researcher-finds-bliss/">places</a>) added another thing to check. The passage of time&#8212;and Gil&#8217;s photos&#8212;revived doubt. </p>
<p>
Heretofore we&#8217;ve refined the art of crafting Google queries to filter out professional information and bring what we want to the top page of hits. But in theory, such quests are better posed directly to the likes of ChatGPT. So I (Ken) did so, first to the free GPT-3.5:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt3-5kalais-2/" rel="attachment wp-att-21441"><img data-attachment-id="21441" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt3-5kalais-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?fit=590%2C458&amp;ssl=1" data-orig-size="590,458" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1681333545&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GPT3.5Kalais" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?fit=300%2C233&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?fit=590%2C458&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?resize=590%2C458&#038;ssl=1" alt="" width="590" height="458" class="aligncenter size-full wp-image-21441" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?w=590&amp;ssl=1 590w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?resize=300%2C233&amp;ssl=1 300w" sizes="(max-width: 590px) 100vw, 590px" data-recalc-dims="1" /></a></p>
<p><P><br />
Wait a second&#8212;has ChatGPT not been briefed on the injunction against incestuous marriage? Or have too many Roman and Greek emperors dominated its data? When Moses flung down and broke the stone tablets in exasperation, was it over chatbots? I tried the pay-grade version and got a different&#8212;but not better&#8212;answer:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisa-2/" rel="attachment wp-att-21442"><img data-attachment-id="21442" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisa-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?fit=540%2C350&amp;ssl=1" data-orig-size="540,350" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1681334250&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GPT4KalaisA" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?fit=300%2C194&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?fit=540%2C350&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?resize=540%2C350&#038;ssl=1" alt="" width="540" height="350" class="aligncenter size-full wp-image-21442" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?w=540&amp;ssl=1 540w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?resize=300%2C194&amp;ssl=1 300w" sizes="(max-width: 540px) 100vw, 540px" data-recalc-dims="1" /></a></p>
<p><P><br />
Nor did GPT-4 correct my typo of an extra &#8216;n.&#8217; Happily, Gil&#8217;s mention of the <a href="https://en.wikipedia.org/wiki/Ehud_Kalai">fourth Kalai</a>&#8212;and confirmation <a href="https://blog.computationalcomplexity.org/2008/07/games-and-computer-science.html">gratia</a> Lance Fortnow that I found via Google&#8212;enabled me to confront GPT-4 with a pertinent question. This produced an all-too-human reaction:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisb-2/" rel="attachment wp-att-21443"><img data-attachment-id="21443" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisb-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?fit=536%2C313&amp;ssl=1" data-orig-size="536,313" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1681334908&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GPT4KalaisB" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?fit=300%2C175&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?fit=536%2C313&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?resize=536%2C313&#038;ssl=1" alt="" width="536" height="313" class="aligncenter size-full wp-image-21443" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?w=536&amp;ssl=1 536w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?resize=300%2C175&amp;ssl=1 300w" sizes="(max-width: 536px) 100vw, 536px" data-recalc-dims="1" /></a></p>
<p><P><br />
&#8220;Confusion,&#8221; indeed? At the right are little hands to upvote or downvote responses. I upvoted the true one and gave the reason as, &#8220;it is true.&#8221; <em>Then</em> I down-voted the false one and clicked a reason button saying, &#8220;This isn&#8217;t true.&#8221; To my consternation a new box appeared:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisc-2/" rel="attachment wp-att-21444"><img data-attachment-id="21444" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisc-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?fit=642%2C384&amp;ssl=1" data-orig-size="642,384" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1681335110&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GPT4KalaisC" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?fit=300%2C179&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?fit=600%2C359&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?resize=540%2C323&#038;ssl=1" alt="" width="540" height="323" class="aligncenter wp-image-21444" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?w=642&amp;ssl=1 642w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?resize=300%2C179&amp;ssl=1 300w" sizes="(max-width: 540px) 100vw, 540px" data-recalc-dims="1" /></a></p>
<p><P><br />
In words that won the 2016 Literature Nobel, <a href="https://en.wikipedia.org/wiki/No_Direction_Home">no direction home</a>. It seems our task of educating GPT will pale that in the wonderful play and movie <a href="https://en.wikipedia.org/wiki/Educating_Rita_(film)">Educating Rita</a>.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Should we have been more worried if P=PSPACE was sprayed in the street? Or if a proof was referenced somehow?  As for GPT, it calls to our minds some other <a href="https://www.azlyrics.com/lyrics/simongarfunkel/thesoundofsilence.html">words</a> that have not yet won a Literature Nobel.  </p>
<p><P><br />
[some word tweaks]</p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T02:26:38Z">Thursday, April 13 2023, 02:26</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05598'>Optimal Testing of Generalized Reed-Muller Codes in Fewer Queries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dor Minzer, Kai Zheng</p><p>A local tester for an error correcting code $C\subseteq \Sigma^{n}$ is a
tester that makes $Q$ oracle queries to a given word $w\in \Sigma^n$ and
decides to accept or reject the word $w$. An optimal local tester is a local
tester that has the additional properties of completeness and optimal
soundness. By completeness, we mean that the tester must accept with
probability $1$ if $w\in C$. By optimal soundness, we mean that if the tester
accepts with probability at least $1-\epsilon$ (where $\epsilon$ is small),
then it must be the case that $w$ is $O(\epsilon/Q)$-close to some codeword
$c\in C$ in Hamming distance.
</p>
<p>We show that Generalized Reed-Muller codes admit optimal testers with $Q =
(3q)^{\lceil{ \frac{d+1}{q-1}\rceil}+O(1)}$ queries. Here, for a prime power $q
= p^{k}$, the Generalized Reed-Muller code, RM[n,q,d], consists of the
evaluations of all $n$-variate degree $d$ polynomials over $\mathbb{F}_q$.
Previously, no tester achieving this query complexity was known, and the best
known testers due to Haramaty, Shpilka and Sudan(which is optimal) and due to
Ron-Zewi and Sudan(which was not known to be optimal) both required
$q^{\lceil{\frac{d+1}{q-q/p} \rceil}}$ queries. Our tester achieves query
complexity which is polynomially better than by a power of $p/(p-1)$, which is
nearly the best query complexity possible for generalized Reed-Muller codes.
</p>
<p>The tester we analyze is due to Ron-Zewi and Sudan, and we show that their
basic tester is in fact optimal. Our methods are more general and also allow us
to prove that a wide class of testers, which follow the form of the Ron-Zewi
and Sudan tester, are optimal. This result applies to testers for all
affine-invariant codes (which are not necessarily generalized Reed-Muller
codes).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Minzer_D/0/1/0/all/0/1">Dor Minzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1">Kai Zheng</a></p><p>A local tester for an error correcting code $C\subseteq \Sigma^{n}$ is a
tester that makes $Q$ oracle queries to a given word $w\in \Sigma^n$ and
decides to accept or reject the word $w$. An optimal local tester is a local
tester that has the additional properties of completeness and optimal
soundness. By completeness, we mean that the tester must accept with
probability $1$ if $w\in C$. By optimal soundness, we mean that if the tester
accepts with probability at least $1-\epsilon$ (where $\epsilon$ is small),
then it must be the case that $w$ is $O(\epsilon/Q)$-close to some codeword
$c\in C$ in Hamming distance.
</p>
<p>We show that Generalized Reed-Muller codes admit optimal testers with $Q =
(3q)^{\lceil{ \frac{d+1}{q-1}\rceil}+O(1)}$ queries. Here, for a prime power $q
= p^{k}$, the Generalized Reed-Muller code, RM[n,q,d], consists of the
evaluations of all $n$-variate degree $d$ polynomials over $\mathbb{F}_q$.
Previously, no tester achieving this query complexity was known, and the best
known testers due to Haramaty, Shpilka and Sudan(which is optimal) and due to
Ron-Zewi and Sudan(which was not known to be optimal) both required
$q^{\lceil{\frac{d+1}{q-q/p} \rceil}}$ queries. Our tester achieves query
complexity which is polynomially better than by a power of $p/(p-1)$, which is
nearly the best query complexity possible for generalized Reed-Muller codes.
</p>
<p>The tester we analyze is due to Ron-Zewi and Sudan, and we show that their
basic tester is in fact optimal. Our methods are more general and also allow us
to prove that a wide class of testers, which follow the form of the Ron-Zewi
and Sudan tester, are optimal. This result applies to testers for all
affine-invariant codes (which are not necessarily generalized Reed-Muller
codes).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T00:30:00Z">Thursday, April 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05697'>Foundations for an Abstract Proof Theory in the Context of Horn Rules</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tim S. Lyon, Piotr Ostropolski-Nalewaja</p><p>We introduce a novel, logic-independent framework for the study of
sequent-style proof systems, which covers a number of proof-theoretic
formalisms and concrete proof systems that appear in the literature. In
particular, we introduce a generalized form of sequents, dubbed 'g-sequents,'
which are taken to be binary graphs of typical, Gentzen-style sequents. We then
define a variety of 'inference rule types' as sets of operations that act over
such objects, and define 'abstract (sequent) calculi' as pairs consisting of a
set of g-sequents together with a finite set of operations. Our approach
permits an analysis of how certain inference rule types interact in a general
setting, demonstrating under what conditions rules of a specific type can be
permuted with or simulated by others, and being applicable to any sequent-style
proof system that fits within our framework. We then leverage our permutation
and simulation results to establish generic calculus and proof transformation
algorithms, which show that every abstract calculus can be effectively
transformed into a lattice of polynomially equivalent abstract calculi. We
determine the complexity of computing this lattice and compute the relative
sizes of proofs and sequents within distinct calculi of a lattice. We recognize
that top elements in lattices correspond to nested sequent systems, while
bottom elements correspond to labeled sequent systems, and observe that top and
bottom elements coincide with many known (cut-free) nested and labeled sequent
systems for logics characterized by Horn properties.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lyon_T/0/1/0/all/0/1">Tim S. Lyon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ostropolski_Nalewaja_P/0/1/0/all/0/1">Piotr Ostropolski-Nalewaja</a></p><p>We introduce a novel, logic-independent framework for the study of
sequent-style proof systems, which covers a number of proof-theoretic
formalisms and concrete proof systems that appear in the literature. In
particular, we introduce a generalized form of sequents, dubbed 'g-sequents,'
which are taken to be binary graphs of typical, Gentzen-style sequents. We then
define a variety of 'inference rule types' as sets of operations that act over
such objects, and define 'abstract (sequent) calculi' as pairs consisting of a
set of g-sequents together with a finite set of operations. Our approach
permits an analysis of how certain inference rule types interact in a general
setting, demonstrating under what conditions rules of a specific type can be
permuted with or simulated by others, and being applicable to any sequent-style
proof system that fits within our framework. We then leverage our permutation
and simulation results to establish generic calculus and proof transformation
algorithms, which show that every abstract calculus can be effectively
transformed into a lattice of polynomially equivalent abstract calculi. We
determine the complexity of computing this lattice and compute the relative
sizes of proofs and sequents within distinct calculi of a lattice. We recognize
that top elements in lattices correspond to nested sequent systems, while
bottom elements correspond to labeled sequent systems, and observe that top and
bottom elements coincide with many known (cut-free) nested and labeled sequent
systems for logics characterized by Horn properties.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T00:30:00Z">Thursday, April 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05831'>When Should You Wait Before Updating? Toward a Robustness Refinement</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Swan Dubois, Laurent Feuilloley, Franck Petit, Mika&#xeb;l Rabie</p><p>Consider a dynamic network and a given distributed problem. At any point in
time, there might exist several solutions that are equally good with respect to
the problem specification, but that are different from an algorithmic
perspective, because some could be easier to update than others when the
network changes. In other words, one would prefer to have a solution that is
more robust to topological changes in the network; and in this direction the
best scenario would be that the solution remains correct despite the dynamic of
the network.
</p>
<p>In~\cite{CasteigtsDPR20}, the authors introduced a very strong robustness
criterion: they required that for any removal of edges that maintain the
network connected, the solution remains valid. They focus on the maximal
independent set problem, and their approach consists in characterizing the
graphs in which there exists a robust solution (the existential problem), or
even stronger, where any solution is robust (the universal problem). As the
robustness criteria is very demanding, few graphs have a robust solution, and
even fewer are such that all of their solutions are robust. In this paper, we
ask the following question: \textit{Can we have robustness for a larger class
of networks, if we bound the number $k$ of edge removals allowed}? (See the
full paper for the full abstract.)
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dubois_S/0/1/0/all/0/1">Swan Dubois</a>, <a href="http://arxiv.org/find/cs/1/au:+Feuilloley_L/0/1/0/all/0/1">Laurent Feuilloley</a>, <a href="http://arxiv.org/find/cs/1/au:+Petit_F/0/1/0/all/0/1">Franck Petit</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabie_M/0/1/0/all/0/1">Mika&#xeb;l Rabie</a></p><p>Consider a dynamic network and a given distributed problem. At any point in
time, there might exist several solutions that are equally good with respect to
the problem specification, but that are different from an algorithmic
perspective, because some could be easier to update than others when the
network changes. In other words, one would prefer to have a solution that is
more robust to topological changes in the network; and in this direction the
best scenario would be that the solution remains correct despite the dynamic of
the network.
</p>
<p>In~\cite{CasteigtsDPR20}, the authors introduced a very strong robustness
criterion: they required that for any removal of edges that maintain the
network connected, the solution remains valid. They focus on the maximal
independent set problem, and their approach consists in characterizing the
graphs in which there exists a robust solution (the existential problem), or
even stronger, where any solution is robust (the universal problem). As the
robustness criteria is very demanding, few graphs have a robust solution, and
even fewer are such that all of their solutions are robust. In this paper, we
ask the following question: \textit{Can we have robustness for a larger class
of networks, if we bound the number $k$ of edge removals allowed}? (See the
full paper for the full abstract.)
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T00:30:00Z">Thursday, April 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05859'>A Hall-type theorem with algorithmic consequences in planar graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hossein Jowhari</p><p>Given a graph $G=(V,E)$, for a vertex set $S\subseteq V$, let $N(S)$ denote
the set of vertices in $V$ that have a neighbor in $S$. In this paper, we prove
the following Hall-type statement. Let $k \ge 2$ be an integer. Let $X$ be a
vertex set in the undirected graph $G$ such that for each subset $S$ of $X$ it
holds $|N(S)|\ge \frac1k {|S|}$. Then $G$ has a matching of size at least
$\frac{|X|}{k+1}$. Using this statement, we derive tight bounds for the
estimators of the matching size in planar graphs. These estimators are used in
designing sublinear space algorithms for approximating the maching size in the
data stream model of computation. In particular, we show the number of locally
superior vertices, introduced in \cite{Jowhari23}, is a $3$ factor
approximation of the matching size in planar graphs. The previous analysis
proved a $3.5$ approximation factor. In another consequence, we show a simple
setting of an estimator by Esfandiari \etal \cite{EHLMO15} achieves $3$ factor
approximation of the matching size in planar graphs. Namely, let $s$ be the
number of edges with both endpoints having degree at most $2$ and let $h$ be
the number of vertices with degree at least $3$. We show when the graph is
planar, the size of matching is at least $\frac{s+h}3$. This result generalizes
a known fact that every planar graph on $n$ vertices with minimum degree $3$
has a matching of size at least $\frac{n}3$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jowhari_H/0/1/0/all/0/1">Hossein Jowhari</a></p><p>Given a graph $G=(V,E)$, for a vertex set $S\subseteq V$, let $N(S)$ denote
the set of vertices in $V$ that have a neighbor in $S$. In this paper, we prove
the following Hall-type statement. Let $k \ge 2$ be an integer. Let $X$ be a
vertex set in the undirected graph $G$ such that for each subset $S$ of $X$ it
holds $|N(S)|\ge \frac1k {|S|}$. Then $G$ has a matching of size at least
$\frac{|X|}{k+1}$. Using this statement, we derive tight bounds for the
estimators of the matching size in planar graphs. These estimators are used in
designing sublinear space algorithms for approximating the maching size in the
data stream model of computation. In particular, we show the number of locally
superior vertices, introduced in \cite{Jowhari23}, is a $3$ factor
approximation of the matching size in planar graphs. The previous analysis
proved a $3.5$ approximation factor. In another consequence, we show a simple
setting of an estimator by Esfandiari \etal \cite{EHLMO15} achieves $3$ factor
approximation of the matching size in planar graphs. Namely, let $s$ be the
number of edges with both endpoints having degree at most $2$ and let $h$ be
the number of vertices with degree at least $3$. We show when the graph is
planar, the size of matching is at least $\frac{s+h}3$. This result generalizes
a known fact that every planar graph on $n$ vertices with minimum degree $3$
has a matching of size at least $\frac{n}3$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T00:30:00Z">Thursday, April 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05883'>On Parallel k-Center Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sam Coy, Artur Czumaj, Gopinath Mishra</p><p>We consider the classic $k$-center problem in a parallel setting, on the
low-local-space Massively Parallel Computation (MPC) model, with local space
per machine of $\mathcal{O}(n^{\delta})$, where $\delta \in (0,1)$ is an
arbitrary constant. As a central clustering problem, the $k$-center problem has
been studied extensively. Still, until very recently, all parallel MPC
algorithms have been requiring $\Omega(k)$ or even $\Omega(k n^{\delta})$ local
space per machine. While this setting covers the case of small values of $k$,
for a large number of clusters these algorithms require large local memory,
making them poorly scalable. The case of large $k$, $k \ge \Omega(n^{\delta})$,
has been considered recently for the low-local-space MPC model by Bateni et al.
(2021), who gave an $\mathcal{O}(\log \log n)$-round MPC algorithm that
produces $k(1+o(1))$ centers whose cost has multiplicative approximation of
$\mathcal{O}(\log\log\log n)$. In this paper we extend the algorithm of Bateni
et al. and design a low-local-space MPC algorithm that in $\mathcal{O}(\log\log
n)$ rounds returns a clustering with $k(1+o(1))$ clusters that is an
$\mathcal{O}(\log^*n)$-approximation for $k$-center.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Coy_S/0/1/0/all/0/1">Sam Coy</a>, <a href="http://arxiv.org/find/cs/1/au:+Czumaj_A/0/1/0/all/0/1">Artur Czumaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_G/0/1/0/all/0/1">Gopinath Mishra</a></p><p>We consider the classic $k$-center problem in a parallel setting, on the
low-local-space Massively Parallel Computation (MPC) model, with local space
per machine of $\mathcal{O}(n^{\delta})$, where $\delta \in (0,1)$ is an
arbitrary constant. As a central clustering problem, the $k$-center problem has
been studied extensively. Still, until very recently, all parallel MPC
algorithms have been requiring $\Omega(k)$ or even $\Omega(k n^{\delta})$ local
space per machine. While this setting covers the case of small values of $k$,
for a large number of clusters these algorithms require large local memory,
making them poorly scalable. The case of large $k$, $k \ge \Omega(n^{\delta})$,
has been considered recently for the low-local-space MPC model by Bateni et al.
(2021), who gave an $\mathcal{O}(\log \log n)$-round MPC algorithm that
produces $k(1+o(1))$ centers whose cost has multiplicative approximation of
$\mathcal{O}(\log\log\log n)$. In this paper we extend the algorithm of Bateni
et al. and design a low-local-space MPC algorithm that in $\mathcal{O}(\log\log
n)$ rounds returns a clustering with $k(1+o(1))$ clusters that is an
$\mathcal{O}(\log^*n)$-approximation for $k$-center.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T00:30:00Z">Thursday, April 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05890'>Node-Differentially Private Estimation of the Number of Connected Components</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Iden Kalemaj, Sofya Raskhodnikova, Adam Smith, Charalampos E. Tsourakakis</p><p>We design the first node-differentially private algorithm for approximating
the number of connected components in a graph. Given a database representing an
$n$-vertex graph $G$ and a privacy parameter $\varepsilon$, our algorithm runs
in polynomial time and, with probability $1-o(1)$, has additive error
$\widetilde{O}(\frac{\Delta^*\ln\ln n}{\varepsilon}),$ where $\Delta^*$ is the
smallest possible maximum degree of a spanning forest of $G.$
Node-differentially private algorithms are known only for a small number of
database analysis tasks. A major obstacle for designing such an algorithm for
the number of connected components is that this graph statistic is not robust
to adding one node with arbitrary connections (a change that node-differential
privacy is designed to hide): {\em every} graph is a neighbor of a connected
graph.
</p>
<p>We overcome this by designing a family of efficiently computable Lipschitz
extensions of the number of connected components or, equivalently, the size of
a spanning forest. The construction of the extensions, which is at the core of
our algorithm, is based on the forest polytope of $G.$ We prove several
combinatorial facts about spanning forests, in particular, that a graph with no
induced $\Delta$-stars has a spanning forest of degree at most $\Delta$. With
this fact, we show that our Lipschitz extensions for the number of connected
components equal the true value of the function for the largest possible
monotone families of graphs. More generally, on all monotone sets of graphs,
the $\ell_\infty$ error of our Lipschitz extensions is nearly optimal.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kalemaj_I/0/1/0/all/0/1">Iden Kalemaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Raskhodnikova_S/0/1/0/all/0/1">Sofya Raskhodnikova</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_A/0/1/0/all/0/1">Adam Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsourakakis_C/0/1/0/all/0/1">Charalampos E. Tsourakakis</a></p><p>We design the first node-differentially private algorithm for approximating
the number of connected components in a graph. Given a database representing an
$n$-vertex graph $G$ and a privacy parameter $\varepsilon$, our algorithm runs
in polynomial time and, with probability $1-o(1)$, has additive error
$\widetilde{O}(\frac{\Delta^*\ln\ln n}{\varepsilon}),$ where $\Delta^*$ is the
smallest possible maximum degree of a spanning forest of $G.$
Node-differentially private algorithms are known only for a small number of
database analysis tasks. A major obstacle for designing such an algorithm for
the number of connected components is that this graph statistic is not robust
to adding one node with arbitrary connections (a change that node-differential
privacy is designed to hide): {\em every} graph is a neighbor of a connected
graph.
</p>
<p>We overcome this by designing a family of efficiently computable Lipschitz
extensions of the number of connected components or, equivalently, the size of
a spanning forest. The construction of the extensions, which is at the core of
our algorithm, is based on the forest polytope of $G.$ We prove several
combinatorial facts about spanning forests, in particular, that a graph with no
induced $\Delta$-stars has a spanning forest of degree at most $\Delta$. With
this fact, we show that our Lipschitz extensions for the number of connected
components equal the true value of the function for the largest possible
monotone families of graphs. More generally, on all monotone sets of graphs,
the $\ell_\infty$ error of our Lipschitz extensions is nearly optimal.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T00:30:00Z">Thursday, April 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, April 12
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/04/12/tcs-for-all-originally-tcs-women-spotlight-workshop-at-stoc-2023-rising-star-nominations/'>Guest Post: TCS for All (originally TCS Women) spotlight workshop at STOC 2023: Rising Star nominations</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          TCS for All (originally TCS Women) invites nominations for speakers in Rising Star talks at the TCS for All Spotlight Workshop at STOC 2023. To be eligible, your nominee has to be a senior PhD student with expected graduation no later than August 2024, or a postdoc in theoretical computer science (all topics represented at [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>TCS for All (originally TCS Women) invites nominations for speakers in Rising Star talks at the <a href="https://sigact.org/tcsforall/">TCS for All Spotlight Workshop</a> at <a href="http://acm-stoc.org/stoc2023/">STOC 2023</a>. To be eligible, your nominee has to be a senior PhD student with expected graduation no later than August 2024, or a postdoc in theoretical computer science (all topics represented at STOC are welcome), an underrepresented minority, and not a speaker at a previous TCS Women Spotlight Workshop. Preference will be given to speakers who are currently on the job market for postdoctoral/faculty positions, or who expect to be on the job market in Fall 2023.</p>



<p>You can make your nomination by <a href="https://forms.gle/jCMXsTmZ4DZ8r5xJA">filling this form</a> by <strong>May 7th</strong>. TCS for All Spotlight Workshop will be held on Thursday, June 22nd, 2023 (2-4pm), in Orlando, Florida, USA, as part of the 54th Symposium on Theory of Computing (STOC) and TheoryFest! We are happy to announce that our annual inspirational talk will be given by Professor Dana Randall!</p>



<p>For more information, check out the website: <a href="https://sigact.org/tcsforall/">https://sigact.org/tcsforall/</a></p>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T22:08:35Z">Wednesday, April 12 2023, 22:08</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/'>Thoughts on AI safety</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Last week, I gave a lecture on AI safety as part of my deep learning foundations course. In this post, I’ll try to write down a few of my thoughts on this topic. (The lecture was three hours, and this blog post will not cover all of what we discussed or all the points that &#8230; Continue reading Thoughts on AI safety
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Last week, I gave a lecture on AI safety as part of my <a href="https://boazbk.github.io/mltheoryseminar/">deep learning foundations course</a>. In this post, I’ll try to write down a few of my thoughts on this topic. (The lecture was three hours, and this blog post will not cover all of what we discussed or all the points that appeared in the pre-readings and the papers linked below.)  </p>



<p>The general goal of safety in artificial intelligence is to protect individual humans or society at large from harm. The field of AI safety is broad and considers risks including:</p>



<ol>
<li>Harm to users of an AI system or harm to third parties due to the system not functioning as intended. One example includes drivers or pedestrians harmed by the failures of self-driving cars. For instance, there were several fatal accidents involving Tesla&#8217;s autopilot. Interestingly, just last week, Elon Musk tweeted the following: <img width="355" height="320" src="https://lh6.googleusercontent.com/i9Z8g5ZkhsRZgxZgRMNf09mSgrrRY2zTK0ZukDVs3kooksLLCwroUgdZr6OSGBNb0DbtAFK3FBYW_DIVpOPuCSu4ImmboKNTZH6fq9hWlZiDkLWkxIVEJeMFEcx9UBOHgVlRPce772sv9AZo-E6MPVo"></li>



<li>Another example is harm from automated decisions that may be unfair. The paper of<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4238015"> Wang </a>et al. discusses the risks of “predictive optimization.” One well-known example is the COMPAS risk-assessment system for bail decisions (see <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Pro-Publica’s investigation</a>, as well as the broader discussion by <a href="https://arxiv.org/abs/1610.02413">Hardt, Price, and Srebro</a>)</li>



<li>Algorithmic decisions could cause “feedback loops”, where several algorithms interact with each other in unexpected and ever-escalating ways. Algorithmic trading was blamed for the <a href="https://en.wikipedia.org/wiki/2010_flash_crash">2010 “Flash Crash”</a>; another example is how a single not-very-rare book came to be priced <a href="https://www.wired.com/2011/04/amazon-flies-24-million/">at $24M on Amazon</a>.</li>



<li>There are many societal risks in AI. These include <a href="https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/?sh=7306d7e4782b">job loss</a>, <a href="https://www.nytimes.com/2019/11/19/technology/artificial-intelligence-bias.html">amplifying biases</a>, <a href="https://en.wikipedia.org/wiki/The_Age_of_Surveillance_Capitalism">concentrating power</a>, <a href="https://www.newyorker.com/culture/infinite-scroll/is-ai-art-stealing-from-artists">appropriating content</a>, and <a href="https://www.noemamag.com/the-exploited-labor-behind-artificial-intelligence/">exploiting data workers</a>.</li>



<li>Yet another issue was pointed out to me by Yejin Choi &#8211; “AI literacy.” As AI’s capabilities are rapidly advancing, it will take some time for people to get used to them, and during this time, we may misinterpret them. This is manifested in people seeing such systems as <a href="https://www.scientificamerican.com/article/google-engineer-claims-ai-chatbot-is-sentient-why-that-matters/">sentient</a> (something that already happened with the 1966 chatbot <a href="https://en.wikipedia.org/wiki/ELIZA_effect">ELIZA</a>). Another example is “deepfakes”: inauthentic images or videos that could mislead people that are not yet aware of AI’s capabilities (again, an issue with a <a href="https://en.wikipedia.org/wiki/Cottingley_Fairies">long history</a>).<br><br><img width="504" height="325" src="https://lh4.googleusercontent.com/DTisxiomU8oCYSmmjTUULGCvq8Cwy6Xxlq872pWXHU-gaC6SDgESdwRVdu_cyIGmHBgpleY2ozToXU-8MYADtUG8sPpfaKlbb_1HAlfvEnBG_nC1d3_oLZoNqC5hBw8VfK8aPNrDIZpM_812ia-hpco">    </li>



<li>AI could be misused by bad actors for hacking, spreading dis-information, help in designing weapons, and more.</li>



<li>Finally, several people are concerned about artificial intelligence systems acting themselves as “malicious agents”, which could behave in adversarial ways, harming humanity and in extreme cases leading to an existential risk of “loss of control” of humanity over its future or extinction.</li>
</ol>



<p>Different subfields of “AI safety” deal with different aspects of these risks. AI “<strong>assurance</strong>,<em>” </em>or quality control, is about ensuring that systems have clear specifications and satisfy these specifications. An example of work along these lines is <a href="https://arxiv.org/abs/1708.06374">Shalev-Shwartz et al</a>, who gave a framework for formally specifying safety assurances for self-driving cars.. AI <em><strong>ethics</strong></em> deals with the individual and social implications of deploying AI systems, asking the question of how AI systems could be deployed responsibly and even<em> </em>whether such a system should be deployed at all. <em><strong>Security</strong></em> deals with malicious actors, that could both be the users of AI, suppliers of data (e.g., data poisoning and prompt injection attacks), or control other aspects of the environment. Finally, researchers in <em>“<strong>alignment</strong>”</em> or <em>“<strong>existential risk</strong>”</em> are concerned with the case in which the AI itself is the adversary. These subfields are not disjoint and share overlapping concerns.</p>



<p>Another way to classify risks is to consider the extent to which they are reduced or magnified by the normal processes of the free market and improved technology. </p>



<figure class="wp-block-image size-large is-resized"><a href="https://windowsontheory.files.wordpress.com/2023/04/image-2.png"><img loading="lazy" data-attachment-id="8602" data-permalink="https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/image-2-4/" data-orig-file="https://windowsontheory.files.wordpress.com/2023/04/image-2.png" data-orig-size="1224,692" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-image-caption="" data-medium-file="https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=300" data-large-file="https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=656" src="https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=1024" alt="" class="wp-image-8602" width="680" height="385" srcset="https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=1024 1024w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=680 680w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=150 150w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=300 300w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=768 768w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png 1224w" sizes="(max-width: 680px) 100vw, 680px" /></a></figure>



<p>In some cases, the interests of safety go hand in hand with the economic incentives for the entity controlling the model, while in others they could be unrelated or even directly opposed to these incentives. Similarly, in some cases, improving capabilities (e.g., by increasing the size of models and data) would reduce risks, while in others, this might not help or even harm.</p>



<h2 class="wp-block-heading">Impact of AI on humanity &#8211; the baseline expectation</h2>



<p>Artificial intelligence is a very general technology, and as such, we might expect its impact on humanity to be qualitatively similar to that of past technological revolutions. If we look at the past, we can draw two lessons:</p>



<ol>
<li>Technological revolutions have both positive and negative impacts, but in the long run and summing over populations, the positives outweigh the negatives. For example, measures such as life expectancy and GDP per capita have gone up over history.</li>
</ol>



<figure class="wp-block-image"><img src="https://lh4.googleusercontent.com/Z8ccZBQmNvYP8ylKcAFuAox35d7rmpx16r1zpqAAyA6yG9X0xAVcNJFICaG5gbIKqH_2Af2EacONKXOnfQQRzMBGUA9FS0KTOD2Jw7ovvp2DXeRpofulsOKB1-2lYU0KjTAPIUNhrlcPGFEfK6WR8hw" alt="" /></figure>



<ol start="2">
<li>There is no reason to assume that the benefits of technology will be distributed equally. <a href="https://www.cbpp.org/research/poverty-and-inequality/a-guide-to-statistics-on-historical-trends-in-income-inequality">Inequality</a> can go either <a href="https://www.imf.org/external/pubs/ft/fandd/2011/09/picture.htm">up or down</a>, dependent on government policies rather than technological improvements. </li>
</ol>



<p>In my lecture, I discussed the issue of fairness. I discussed both the COMPAS system as well as the paper of <a href="https://arxiv.org/abs/1610.02413">Hardt et al</a>, visualized in the <a href="https://research.google.com/bigpicture/attacking-discrimination-in-ml/">following page</a>, demonstrating how different notions of fairness can be at odds with maximizing profits and even at odds with one another.  In this blog post, I focus on the settings where <strong>capabilities</strong> and <strong>safety </strong>may be at odds.</p>



<h2 class="wp-block-heading">Capabilities</h2>



<p>As is well known, the capabilities of artificial intelligence systems have been growing in recent years, see, for example this paper of <a href="https://arxiv.org/abs/2206.07682">Wei et al</a>. </p>



<figure class="wp-block-image is-resized"><img src="https://lh4.googleusercontent.com/M18nhEY3ApIXjrril-PxYPFrgx4mxgIxzIXYvXWaAXfgwguAO9r0igfIoYplJ59b1oV5_dTwe-QmETaHCN4_fZPmA4TTTOaxdiUD_YdEITKID8nVoctBU3Hg707JRKZ2ntqFUxOH6qmSPgCNbkH2HGs" alt="" width="543" height="367" /></figure>



<p>Graphs like these show capabilities emerging suddenly with model scale. However, we should note that these graphs are plotted with the X axis on the <strong>log scale.</strong> If we plot it on linear scale, it would be much less abrupt.&nbsp;</p>



<figure class="wp-block-image is-resized"><img src="https://lh5.googleusercontent.com/UbtJ1n09TuRPznworgdaznIIkGdceuK_ZUrVwpYqsGmjUUktxCfdHBAdtKTf-KG9-TZTf709ZS9gNDtnUr2BoCQeYq_KzsnQS3-NCOZEtkbYrqJCqzEXHfTfWlC2FnofBHIgfP5VsSkSu05jaYGkjug" alt="" width="635" height="376" /></figure>



<p>Another way to plot increasing capabilities is to look at improvements in ELO scores of Chess engines.&nbsp;</p>



<figure class="wp-block-image is-resized"><img src="https://lh3.googleusercontent.com/9MNusf0mSr5PExwfDqGULmPYEwuL7QU79m0fTBmzEI1iCXcVsYabauEiAjLSEq_owZUK1UqlImqwWIwuLTBP74fOXAldhbW988uARoG8N08mmsfawt4Q-PV2T3a8Hq4TgaKk5GCo_s6okNB2U7NyP0Y" alt="" width="691" height="369" /></figure>



<p>Once again, we see improvement with time. (Due to Moore’s law, we can also treat the X axis as a log scale here. BTW credit for this figure is due to GPT4; I didn’t verify the numbers though I probably should have.)</p>



<p>Given the above, we might expect future capabilities to increase roughly as follows: (this is a cartoon, so the slope or the labels on either axis should not be taken too seriously)<img src="https://lh3.googleusercontent.com/7t_z2fR0rHtTnjq7XVBa2kyQsPiIM3zFvXPo_GrXciBjNay046-9-WcVaSA9itWAbxD2o50K9VP6Q6UJHmw8_NA3jeSc2ngCOBsrBrJXjmBheqxe9kNESt-8UVgToR770JPTSSJKfoekfW7Z1IG9Ks4" width="474" height="349"></p>



<p>However, Moore’s law (assuming <a href="https://www.semianalysis.com/p/a-century-of-moores-law">it keeps holding</a>) can reduce costs as a function of time. Also, the graph may well behave differently for different skills. Finally, if we manage to use AI to reduce the costs of building future AI (i.e. “self improvement” or “singularity”), then the costs could be radically reduced.</p>



<h2 class="wp-block-heading">Capabilities vs. Safety Round 1: Risk of misuse</h2>



<p>One aspect in which increased capabilities seem to be at odds with safety is the potential for <em>misuse</em> of AI. The more powerful an AI system is, the more harm one can do with it. However, this logic assumes that only the attacker can access the system. In many cases, increased capabilities of AI benefits both the “attacker” and “defender”, and it is unclear which one would be helped more. </p>



<p>For example, AI systems could find software vulnerabilities and help hackers, but software companies could also use them to secure their systems. AI could be used to spread disinformation on social media and by social media companies to detect such disinformation. A related setting is the use of AI for persuasion. However, it is still an open question whether the current “limiting factor” in persuasion, whether it’s advertising or scams, is a lack of know-how or workforce on the part of the persuaders. Rather, it may be that different people have varying susceptibility to persuasion; thus, even very skilled persuaders will be limited in the number of people they can persuade and the things they can persuade them to do. Also, AI could be used to combat illicit persuasion by detecting scams, just as it is currently used in spam detection.</p>



<p>An example closest to my expertise is student cheating. AI may help professors detect cheating more than it helps potential cheaters. In past semesters, if I wanted to detect whether two students copied from one another, I needed to &#8220;run&#8221; an N² time algorithm (manually comparing all pairs of submissions).  Now I could ask ChatGPT to compare all pairs and summarize any suspicious similarities. If I am worried about students using ChatGPT itself to cheat, I can ask it to throw its own solution into the pool of comparands (and maybe some solutions from past semesters or Course Hero as well). </p>



<p>There are other misuse scenarios in which the balance does favor the attacker. For example, an attacker might be able to use a system to learn how to make a bomb or get detailed information about a physical target for an attack. However, society has been through inflection points such as this in the past, when the amount of information available to ordinary citizens radically increased. It is unclear to me that the increase in access to harmful information due to AI would be larger than the increase between the pre- and post-Internet eras. </p>



<h2 class="wp-block-heading">Capabilities vs. Safety Round 2: Unaligned powerful AI systems<br></h2>



<p>The other setting in which increased capabilities could lead to higher risk is when we are concerned with the AI systems themselves behaving in “agentic” or malicious ways. We do not have to get into the question of whether such systems could be “sentient” or “concious” but rather ask whether it might be possible that the systems’ actions would be so complex and unpredictable that they could be modeled as adversarial. </p>



<p>There is a long history of worrying about such risks. Alan Turing famously said in 1951 that <em>“it seems probable that once the machine thinking method had started, it would not take long to outstrip our feeble powers. They would be able to converse with each other to sharpen their wits. At some stage therefore, we should have to expect the machines to take control.”</em></p>



<figure class="wp-block-image size-large is-resized"><a href="https://windowsontheory.files.wordpress.com/2023/04/image-1.png"><img loading="lazy" data-attachment-id="8598" data-permalink="https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/image-1-4/" data-orig-file="https://windowsontheory.files.wordpress.com/2023/04/image-1.png" data-orig-size="1224,464" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-image-caption="" data-medium-file="https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=300" data-large-file="https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=656" src="https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=1024" alt="" class="wp-image-8598" width="656" height="248" srcset="https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=1024 1024w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=654 654w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=150 150w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=300 300w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=768 768w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png 1224w" sizes="(max-width: 656px) 100vw, 656px" /></a></figure>



<p>There are two metaphors for a “super human AI”. One is the model of an AI as a<strong> “genie”:</strong> an entity that is single-mindedly focused on optimizing some objective (a.k.a granting a wish). However, like the genies in many stories, it may interpret the wish in a way that is literally true but completely misaligned with the intentions and interests of the human who made it. A less fanciful way to phrase this is that we expect that <em>any</em> objective, when pursued relentlessly, will eventually be misaligned with the general well-being of society. In his <a href="https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html">blog</a>, Jascha Sohl-Dickstein called this principle the “strong version of Goodhat’s law” and illustrated it as follows:</p>



<figure class="wp-block-image is-resized"><img src="https://lh5.googleusercontent.com/BdPFfV53mLAN3gY6IkBCImnNXHbZW_P4LO97CMg_NGBXPp-03s21GWo0isaDZMaWaP4b-16997bp6fmG2Yb8KAYBHoSACfl_m9XwRTYXmQnUIPv8OL2zJBxnx749bnhvJLlJeBdLaOt5VXWjfNbN75A" alt="" width="545" height="279" /></figure>



<p>Specifically, the concern is that to satisfy any objective, it seems useful to <a href="https://arxiv.org/abs/1912.01683">seek power</a>, and it is possible systems might use deception as well. <a href="https://arxiv.org/abs/2209.00626">Ngo et al </a>raised the concern that such systems would develop “situational awareness” and behave differently when trained and deployed.</p>



<p>The other metaphor for a “super-human AI” is the one of the “alien”: it is highly intelligent, but like us, it is not focused on a single goal; rather, its intelligence (to use another term from Sohl-Dickstein) is a “hot mess”. Being like us is not necessarily a good thing. For example, the interaction between early modern humans and the Neanderthals did not go well for the latter. (Though <a href="https://www.nature.com/articles/s41598-021-84410-7">we</a> <a href="https://www.discovermagazine.com/planet-earth/neanderthal-brains-bigger-not-necessarily-better">don’t</a> <a href="https://www.nature.com/articles/s41559-021-01391-6">know</a> whether or not Homo Sapiens had cognitive advantages over Neanderthals, and if so, whether those played a key role in the Neanderthal’s extinction. Also, as our society has grown more sophisticated, we are trying to do more to <a href="https://www.iucn.org/">conserve</a> rather than extinguish other species.)</p>



<p>The “AI as a genie” metaphor arises from the fact that AI systems are often the result of some optimization procedure. In particular, in <em>reinforcement learning (RL)</em>, the system is trained to maximize some <em>reward</em>. While RL wasn’t used in earlier large language models (LLMs), it has <a href="https://arxiv.org/abs/2203.02155">recently been used</a> in models such as GPT3.5, training a “reward model” from human feedback that is later used in an RL procedure to generate a sequence of tokens that maximizes the reward (this is known as RL from human feedback or RLHF). Ngo et al claimed that the use of RLHF could lead models to “reward hacking” in which the model pursues goals that, like in the “strong version of Goodhart’s law” would be ultimately detrimental to humanity.</p>



<p>To me, this particular concern hinges on the question of whether RLHF amounts to most of the “magic” in modern LLMs or whether (to use a phrase favored by <a href="https://medium.com/syncedreview/yann-lecun-cake-analogy-2-0-a361da560dae">Yann LeCun</a>) it is merely the “cherry on top”. </p>



<figure class="wp-block-image"><img src="https://lh3.googleusercontent.com/tmylI-HGa_ec4wXtiYfu9t2hgBAq3UcnwyUtOqydL-nl0tL1ZD3eo6BwOHt4K5EaFaR998IuMbxu7k5N9k3FukbmCznqRmKqu0n8vMVmwqgy81mQgrn1aXSmTvzukQ0YLw-3b1s4KHaihOrIHdGBsAs" alt="" /></figure>



<p>If we believe that “magic” corresponds to computational or data resources, then RLHF is merely the &#8220;cherry on top&#8221;. While OpenAI did not reveal details, <a href="https://arxiv.org/abs/2204.05862">Anthropic</a> trained a similar model and used about 10¹¹ tokens in pre-training, while only about 10⁵ human annotations for RLHF.  So if the computational scale is the same as “magic,” then intelligence is formed at pre-training and only shaped by RLHF. Is scale the same as magic? I would argue that this is what <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">the bitter lesson</a> tells us.</p>



<p>Even so, should we still be worried about the “alien” model? The question is, again, who is the alien? Do we think of the AI system as the combination of the pre-trained model and whatever “fine tuning” or “reinforcement learning” adapter is on top of it? Or is the heart of the system the pre-trained model itself? </p>



<p>If we consider the pre-trained model as the heart of the system, then I argue that modeling it as an individual entity or agent is misguided.&nbsp; In fact:</p>



<blockquote class="wp-block-quote">
<p><em>A pre-trained language model is not an imitation of any human, it is an imitation of all of humanity.</em></p>
</blockquote>



<p>A pre-trained generative text model is not designed to model any particular entity. Rather, it is designed to generate all text that it has been trained on and, along the way, develop the skills to perform deductions, combinations, and style transfers on this text. To use such a model as an assistant, we need to <em>condition</em> it by providing a <a href="https://www.reddit.com/r/copypasta/comments/111mlh7/entire_microsoft_bing_ai_prompt_leaked/">prompt</a>, much like we can condition an image generative model to generate images inside one particular building. If we think of a pre-trained model as an “intelligence engine” that is later used with “adapters” (that could include learned models, hard-coded programs, as well as humans), then our assumptions on the risk scenarios change. Rather than a monolithic “AI system” that could act in adversarial ways, we might have a variety of agents/modules built on top of the “intelligence engine”. Some of these agents, whether human or artificial, may well be adversarial. However, all of those would have access to the same “engine,” and so the rising tide of AI will lift all (good and bad) boats. </p>



<figure class="wp-block-image"><img src="https://lh6.googleusercontent.com/dUGyRSPiw0M1Gnb4UYsMOMff-n536k3BJ7VfBUQvf3dgIIeRd7Ns5CTzdtIK9JPbYfP4Xsdir73jIFIc-q-X3ttfb-K8vAu78eW2GckWfsBzf5dmaDVXaCai-So9fC5n8GBxNr2rA9eHyFA9Ezl_T4g" alt="" /></figure>



<p>Generally, I think that the view of “intelligence” as some inherent skill belonging to a monolithic entity or agent is quite anthropocentric. In fact, it’s not even true for humans. While the human brains have not grown for more than hundred thousand years,  human society has collectively become more intelligent over the last millennia and centuries, and all of us can access this collective intelligence. Indeed, with modern deep learning, we can take any advanced AI system and <em>fine-tune</em> it to achieve a particular task of interest. Hence<strong> intelligence is not so much a skill of an individual as a capability of the system as a whole.</strong></p>



<h2 class="wp-block-heading">Verification</h2>



<p>Regardless of whether you are concerned about AI taking over humanity or simply about the wisdom of deploying highly complex systems that we don’t fully understand, <em>verification</em> can be a crucial element for ensuring safety. One of the general principles we see time and again in theoretical computer science is that</p>



<blockquote class="wp-block-quote">
<p><em>Verification is easier than creation.</em></p>
</blockquote>



<p>(In other words, it’s easier to be the critic than the “<a href="https://www.theodorerooseveltcenter.org/Learn-About-TR/TR-Encyclopedia/Culture-and-Society/Man-in-the-Arena.aspx">man in the arena</a>” &#8211; and that’s a good thing!)</p>



<p>This is the content of the P vs NP conjecture and also underlies the theory of <a href="http://people.csail.mit.edu/madhu/papers/2009/pcpcacm.pdf">probabilistically  checkable proofs. (PCPs)</a> These are now used in cryptography to delegate computation by a weak verifier to a powerful server (see this <a href="https://cap.csail.mit.edu/engage/spotlights/yael-kalai">interview</a> with Yael Kalai, and her <a href="https://gilkalai.files.wordpress.com/2018/01/cacm-delegation.pdf">survey</a>) which is a problem not unlike the task of verifying a powerful AI by a weaker entity.</p>



<p>I recently saw a talk by Zico Kolter in which he put forward the following equation as to when generative models have positive utility:</p>



<figure class="wp-block-image"><img src="https://lh3.googleusercontent.com/aQtCbNVlUK1AM_V2PvU1iSNwwRH_Zhg3bH_XcU7_jwYMi6yJDRAP7kHVbLuUwkDPi_H9kYcHJeImzlMow-oVtjhaQwOJJuk89Yf6nOtBrxdzBq6AGd_EYvKUM4R0ES6s8rA0Q9nihvnqomayae2COt4" alt="" /></figure>



<p>That is, as long as the time for us to verify a solution is smaller than the time to generate it ourselves multiplied by the probability that the model’s output is correct, then we can efficiently use a model by always verifying its output, spending the effort to generate a solution ourself if verification fails. Our expected time would be smaller than the time spent generating solutions from scratch, even if the model is far from always correct.</p>



<p>The principle that verification can be done even with powerful provers is one we see in human enterprises as well. <a href="https://en.wikipedia.org/wiki/Terence_Tao">Terence Tao</a> might be (by some measures) the world’s top mathematician. But he still submits his papers to peer review, and they can (and are) checked by mere “mortals”. Indeed I would argue that this ability to <strong>communicate</strong>, <strong>verify</strong>, and <strong>teach</strong> is <em>the reason</em> that human society has managed to “stand on the shoulders of giants” and achieve such growth in productivity despite working with the same human brains our ancestors used to run from animals. Theories like relativity may have taken a huge effort to <em>discover</em>, but once discovered, could be communicated, verified, and are now taught to first-year undergraduates.</p>



<p>Interestingly, it seems that the professions that are <a href="https://academic.oup.com/qje/article-abstract/132/4/1877/3859758?redirectedFrom=fulltext&amp;login=false">more subject to verification</a> are not the ones that require the most information-processing skills but rather “alignment”: more “wisdom” than “smartness”. Perhaps those professions <a href="https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/">would not be the professions most amenable for AIs</a>.</p>



<figure class="wp-block-image"><img src="https://lh3.googleusercontent.com/zt9TK0wqTCqgyCcwOelndi2KWvqbc7EEkTMfkw09CFOyT0Sj5QuafmRF9ro-VaMpR_n6JD-1txqau3c4bc1QWbPaE5G-942lomjrSk3qGS2XVIkcYppZ5t1OPxKVkEYbZpPOttrCQEdv4-yBCeqn-Rg" alt="" /></figure>



<p>Practical verification of ML systems is still an ongoing effort. There are methods for <a href="https://www.deepmind.com/publications/red-teaming-language-models-with-language-models">red teaming</a>, <a href="https://arxiv.org/abs/2206.05802">self-critiquing</a>,  <a href="https://arxiv.org/abs/2205.11822">probing for consistency</a>, or <a href="https://arxiv.org/abs/2112.02969">testing generated code</a> that can reduce errors. However, we do not yet have robust verification schemes in the sense that we can reliably drive the error probability to zero by spending more effort at inference (let alone drive it <em>exponentially fast</em> to zero, as we can often do in theoretical CS- something that may be crucial for ensuring robustness against adversarial inputs).</p>



<figure class="wp-block-image"><img src="https://lh5.googleusercontent.com/ylrE7vqPWD3urdsy34vHOGxzEleKZr9906UMKksSNDeIkeg1y9p_4Pqwi2dikT__blW7cYjOxAfraLhsavMWPwSYMLbIBuGPdM27_TbEFPtNXaFDt2rlHxj6dq1AoKwNWPFe4VOgjxgQlGk4ppF2_-U" alt="" /></figure>



<p>One potential advantage of AI models is that they can themselves write symbolic proofs that may later be verifiable with formal theorem provers. For example, <a href="https://arxiv.org/abs/2205.12615">Wu et al</a> used LLMs to formalize mathematical competition problems in the systems Isabelle/HOL. Overall, there seems to be a huge potential in combining the rich literature on proof systems with the power of modern language models.</p>



<p>To sum up, artificial Intelligence has made great strides in performance over the last decade and will be widely deployed across many fields in the near future. As the use of AI systems increases, so will the importance of ensuring reliability, fairness, trustworthiness, and security.</p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T15:25:45Z">Wednesday, April 12 2023, 15:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04837'>Geometry of Rounding: Near Optimal Bounds and a New Neighborhood Sperner's Lemma</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jason Vander Woude, Peter Dixon, A. Pavan, Jamie Radcliffe, N. V. Vinodchandran</p><p>A partition $\mathcal{P}$ of $\mathbb{R}^d$ is called a
$(k,\varepsilon)$-secluded partition if, for every $\vec{p} \in \mathbb{R}^d$,
the ball $\overline{B}_{\infty}(\varepsilon, \vec{p})$ intersects at most $k$
members of $\mathcal{P}$. A goal in designing such secluded partitions is to
minimize $k$ while making $\varepsilon$ as large as possible. This partition
problem has connections to a diverse range of topics, including deterministic
rounding schemes, pseudodeterminism, replicability, as well as Sperner/KKM-type
results.
</p>
<p>In this work, we establish near-optimal relationships between $k$ and
$\varepsilon$. We show that, for any bounded measure partitions and for any
$d\geq 1$, it must be that $k\geq(1+2\varepsilon)^d$. Thus, when $k=k(d)$ is
restricted to ${\rm poly}(d)$, it follows that $\varepsilon=\varepsilon(d)\in
O\left(\frac{\ln d}{d}\right)$. This bound is tight up to log factors, as it is
known that there exist secluded partitions with $k(d)=d+1$ and
$\varepsilon(d)=\frac{1}{2d}$. We also provide new constructions of secluded
partitions that work for a broad spectrum of $k(d)$ and $\varepsilon(d)$
parameters. Specifically, we prove that, for any
$f:\mathbb{N}\rightarrow\mathbb{N}$, there is a secluded partition with
$k(d)=(f(d)+1)^{\lceil\frac{d}{f(d)}\rceil}$ and
$\varepsilon(d)=\frac{1}{2f(d)}$. These new partitions are optimal up to
$O(\log d)$ factors for various choices of $k(d)$ and $\varepsilon(d)$. Based
on the lower bound result, we establish a new neighborhood version of Sperner's
lemma over hypercubes, which is of independent interest. In addition, we prove
a no-free-lunch theorem about the limitations of rounding schemes in the
context of pseudodeterministic/replicable algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Woude_J/0/1/0/all/0/1">Jason Vander Woude</a>, <a href="http://arxiv.org/find/cs/1/au:+Dixon_P/0/1/0/all/0/1">Peter Dixon</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavan_A/0/1/0/all/0/1">A. Pavan</a>, <a href="http://arxiv.org/find/cs/1/au:+Radcliffe_J/0/1/0/all/0/1">Jamie Radcliffe</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinodchandran_N/0/1/0/all/0/1">N. V. Vinodchandran</a></p><p>A partition $\mathcal{P}$ of $\mathbb{R}^d$ is called a
$(k,\varepsilon)$-secluded partition if, for every $\vec{p} \in \mathbb{R}^d$,
the ball $\overline{B}_{\infty}(\varepsilon, \vec{p})$ intersects at most $k$
members of $\mathcal{P}$. A goal in designing such secluded partitions is to
minimize $k$ while making $\varepsilon$ as large as possible. This partition
problem has connections to a diverse range of topics, including deterministic
rounding schemes, pseudodeterminism, replicability, as well as Sperner/KKM-type
results.
</p>
<p>In this work, we establish near-optimal relationships between $k$ and
$\varepsilon$. We show that, for any bounded measure partitions and for any
$d\geq 1$, it must be that $k\geq(1+2\varepsilon)^d$. Thus, when $k=k(d)$ is
restricted to ${\rm poly}(d)$, it follows that $\varepsilon=\varepsilon(d)\in
O\left(\frac{\ln d}{d}\right)$. This bound is tight up to log factors, as it is
known that there exist secluded partitions with $k(d)=d+1$ and
$\varepsilon(d)=\frac{1}{2d}$. We also provide new constructions of secluded
partitions that work for a broad spectrum of $k(d)$ and $\varepsilon(d)$
parameters. Specifically, we prove that, for any
$f:\mathbb{N}\rightarrow\mathbb{N}$, there is a secluded partition with
$k(d)=(f(d)+1)^{\lceil\frac{d}{f(d)}\rceil}$ and
$\varepsilon(d)=\frac{1}{2f(d)}$. These new partitions are optimal up to
$O(\log d)$ factors for various choices of $k(d)$ and $\varepsilon(d)$. Based
on the lower bound result, we establish a new neighborhood version of Sperner's
lemma over hypercubes, which is of independent interest. In addition, we prove
a no-free-lunch theorem about the limitations of rounding schemes in the
context of pseudodeterministic/replicable algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04970'>GRIL: A $2$-parameter Persistence Based Vectorization for Machine Learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Cheng Xin, Soham Mukherjee, Shreyas N. Samaga, Tamal K. Dey</p><p>$1$-parameter persistent homology, a cornerstone in Topological Data Analysis
(TDA), studies the evolution of topological features such as connected
components and cycles hidden in data. It has been applied to enhance the
representation power of deep learning models, such as Graph Neural Networks
(GNNs). To enrich the representations of topological features, here we propose
to study $2$-parameter persistence modules induced by bi-filtration functions.
In order to incorporate these representations into machine learning models, we
introduce a novel vector representation called Generalized Rank Invariant
Landscape \textsc{Gril} for $2$-parameter persistence modules. We show that
this vector representation is $1$-Lipschitz stable and differentiable with
respect to underlying filtration functions and can be easily integrated into
machine learning models to augment encoding topological features. We present an
algorithm to compute the vector representation efficiently. We also test our
methods on synthetic and benchmark graph datasets, and compare the results with
previous vector representations of $1$-parameter and $2$-parameter persistence
modules.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Xin_C/0/1/0/all/0/1">Cheng Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1">Soham Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Samaga_S/0/1/0/all/0/1">Shreyas N. Samaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_T/0/1/0/all/0/1">Tamal K. Dey</a></p><p>$1$-parameter persistent homology, a cornerstone in Topological Data Analysis
(TDA), studies the evolution of topological features such as connected
components and cycles hidden in data. It has been applied to enhance the
representation power of deep learning models, such as Graph Neural Networks
(GNNs). To enrich the representations of topological features, here we propose
to study $2$-parameter persistence modules induced by bi-filtration functions.
In order to incorporate these representations into machine learning models, we
introduce a novel vector representation called Generalized Rank Invariant
Landscape \textsc{Gril} for $2$-parameter persistence modules. We show that
this vector representation is $1$-Lipschitz stable and differentiable with
respect to underlying filtration functions and can be easily integrated into
machine learning models to augment encoding topological features. We present an
algorithm to compute the vector representation efficiently. We also test our
methods on synthetic and benchmark graph datasets, and compare the results with
previous vector representations of $1$-parameter and $2$-parameter persistence
modules.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04852'>The Kraft--Barmpalias--Lewis-Pye lemma revisited</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Shen</p><p>This note provides a simplified exposition of the proof of hierarchical Kraft
lemma proven by Barmpalias and Lewis-Pye and its consequences for the oracle
use in the Ku\v{c}era--G\'acs theorem (saying that every sequence is Turing
reducible to a random one).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Shen_A/0/1/0/all/0/1">Alexander Shen</a></p><p>This note provides a simplified exposition of the proof of hierarchical Kraft
lemma proven by Barmpalias and Lewis-Pye and its consequences for the oracle
use in the Ku\v{c}era--G\'acs theorem (saying that every sequence is Turing
reducible to a random one).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04932'>Robust Dequantization of the Quantum Singular value Transformation and Quantum Machine Learning Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fran&#xe7;ois Le Gall</p><p>Several quantum algorithms for linear algebra problems, and in particular
quantum machine learning problems, have been "dequantized" in the past few
years. These dequantization results typically hold when classical algorithms
can access the data via length-squared sampling. In this work we investigate
how robust these dequantization results are. We introduce the notion of
approximate length-squared sampling, where classical algorithms are only able
to sample from a distribution close to the ideal distribution in total
variation distance. While quantum algorithms are natively robust against small
perturbations, current techniques in dequantization are not. Our main technical
contribution is showing how many techniques from randomized linear algebra can
be adapted to work under this weaker assumption as well. We then use these
techniques to show that the recent low-rank dequantization framework by Chia,
Gily\'en, Li, Lin, Tang and Wang (JACM 2022) and the dequantization framework
for sparse matrices by Gharibian and Le Gall (STOC 2022), which are both based
on the Quantum Singular Value Transformation, can be generalized to the case of
approximate length-squared sampling access to the input. We also apply these
results to obtain a robust dequantization of many quantum machine learning
algorithms, including quantum algorithms for recommendation systems, supervised
clustering and low-rank matrix inversion.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Gall_F/0/1/0/all/0/1">Fran&#xe7;ois Le Gall</a></p><p>Several quantum algorithms for linear algebra problems, and in particular
quantum machine learning problems, have been "dequantized" in the past few
years. These dequantization results typically hold when classical algorithms
can access the data via length-squared sampling. In this work we investigate
how robust these dequantization results are. We introduce the notion of
approximate length-squared sampling, where classical algorithms are only able
to sample from a distribution close to the ideal distribution in total
variation distance. While quantum algorithms are natively robust against small
perturbations, current techniques in dequantization are not. Our main technical
contribution is showing how many techniques from randomized linear algebra can
be adapted to work under this weaker assumption as well. We then use these
techniques to show that the recent low-rank dequantization framework by Chia,
Gily\'en, Li, Lin, Tang and Wang (JACM 2022) and the dequantization framework
for sparse matrices by Gharibian and Le Gall (STOC 2022), which are both based
on the Quantum Singular Value Transformation, can be generalized to the case of
approximate length-squared sampling access to the input. We also apply these
results to obtain a robust dequantization of many quantum machine learning
algorithms, including quantum algorithms for recommendation systems, supervised
clustering and low-rank matrix inversion.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04954'>An Associativity Threshold Phenomenon in Set-Associative Caches</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael A. Bender, Rathish Das, Mart&#xed;n Farach-Colton, Guido Tagliavini</p><p>In an $\alpha$-way set-associative cache, the cache is partitioned into
disjoint sets of size $\alpha$, and each item can only be cached in one set,
typically selected via a hash function. Set-associative caches are widely used
and have many benefits, e.g., in terms of latency or concurrency, over fully
associative caches, but they often incur more cache misses. As the set size
$\alpha$ decreases, the benefits increase, but the paging costs worsen.
</p>
<p>In this paper we characterize the performance of an $\alpha$-way
set-associative LRU cache of total size $k$, as a function of $\alpha =
\alpha(k)$. We prove the following, assuming that sets are selected using a
fully random hash function:
</p>
<p>- For $\alpha = \omega(\log k)$, the paging cost of an $\alpha$-way
set-associative LRU cache is within additive $O(1)$ of that a fully-associative
LRU cache of size $(1-o(1))k$, with probability $1 - 1/\operatorname{poly}(k)$,
for all request sequences of length $\operatorname{poly}(k)$.
</p>
<p>- For $\alpha = o(\log k)$, and for all $c = O(1)$ and $r = O(1)$, the paging
cost of an $\alpha$-way set-associative LRU cache is not within a factor $c$ of
that a fully-associative LRU cache of size $k/r$, for some request sequence of
length $O(k^{1.01})$.
</p>
<p>- For $\alpha = \omega(\log k)$, if the hash function can be occasionally
changed, the paging cost of an $\alpha$-way set-associative LRU cache is within
a factor $1 + o(1)$ of that a fully-associative LRU cache of size $(1-o(1))k$,
with probability $1 - 1/\operatorname{poly}(k)$, for request sequences of
arbitrary (e.g., super-polynomial) length.
</p>
<p>Some of our results generalize to other paging algorithms besides LRU, such
as least-frequently used (LFU).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bender_M/0/1/0/all/0/1">Michael A. Bender</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1">Rathish Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Farach_Colton_M/0/1/0/all/0/1">Mart&#xed;n Farach-Colton</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliavini_G/0/1/0/all/0/1">Guido Tagliavini</a></p><p>In an $\alpha$-way set-associative cache, the cache is partitioned into
disjoint sets of size $\alpha$, and each item can only be cached in one set,
typically selected via a hash function. Set-associative caches are widely used
and have many benefits, e.g., in terms of latency or concurrency, over fully
associative caches, but they often incur more cache misses. As the set size
$\alpha$ decreases, the benefits increase, but the paging costs worsen.
</p>
<p>In this paper we characterize the performance of an $\alpha$-way
set-associative LRU cache of total size $k$, as a function of $\alpha =
\alpha(k)$. We prove the following, assuming that sets are selected using a
fully random hash function:
</p>
<p>- For $\alpha = \omega(\log k)$, the paging cost of an $\alpha$-way
set-associative LRU cache is within additive $O(1)$ of that a fully-associative
LRU cache of size $(1-o(1))k$, with probability $1 - 1/\operatorname{poly}(k)$,
for all request sequences of length $\operatorname{poly}(k)$.
</p>
<p>- For $\alpha = o(\log k)$, and for all $c = O(1)$ and $r = O(1)$, the paging
cost of an $\alpha$-way set-associative LRU cache is not within a factor $c$ of
that a fully-associative LRU cache of size $k/r$, for some request sequence of
length $O(k^{1.01})$.
</p>
<p>- For $\alpha = \omega(\log k)$, if the hash function can be occasionally
changed, the paging cost of an $\alpha$-way set-associative LRU cache is within
a factor $1 + o(1)$ of that a fully-associative LRU cache of size $(1-o(1))k$,
with probability $1 - 1/\operatorname{poly}(k)$, for request sequences of
arbitrary (e.g., super-polynomial) length.
</p>
<p>Some of our results generalize to other paging algorithms besides LRU, such
as least-frequently used (LFU).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05270'>Longest Common Subsequence with Gap Constraints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Duncan Adamson, Maria Kosche, Tore Ko&#xdf;, Florin Manea, Stefan Siemer</p><p>We consider the longest common subsequence problem in the context of
subsequences with gap constraints. In particular, following Day et al. 2022, we
consider the setting when the distance (i. e., the gap) between two consecutive
symbols of the subsequence has to be between a lower and an upper bound (which
may depend on the position of those symbols in the subsequence or on the
symbols bordering the gap) as well as the case where the entire subsequence is
found in a bounded range (defined by a single upper bound), considered by
Kosche et al. 2022. In all these cases, we present effcient algorithms for
determining the length of the longest common constrained subsequence between
two given strings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Adamson_D/0/1/0/all/0/1">Duncan Adamson</a>, <a href="http://arxiv.org/find/cs/1/au:+Kosche_M/0/1/0/all/0/1">Maria Kosche</a>, <a href="http://arxiv.org/find/cs/1/au:+Koss_T/0/1/0/all/0/1">Tore Ko&#xdf;</a>, <a href="http://arxiv.org/find/cs/1/au:+Manea_F/0/1/0/all/0/1">Florin Manea</a>, <a href="http://arxiv.org/find/cs/1/au:+Siemer_S/0/1/0/all/0/1">Stefan Siemer</a></p><p>We consider the longest common subsequence problem in the context of
subsequences with gap constraints. In particular, following Day et al. 2022, we
consider the setting when the distance (i. e., the gap) between two consecutive
symbols of the subsequence has to be between a lower and an upper bound (which
may depend on the position of those symbols in the subsequence or on the
symbols bordering the gap) as well as the case where the entire subsequence is
found in a bounded range (defined by a single upper bound), considered by
Kosche et al. 2022. In all these cases, we present effcient algorithms for
determining the length of the longest common constrained subsequence between
two given strings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
