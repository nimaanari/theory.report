<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>
  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel='stylesheet' type='text/css' href='css/font-awesome.css'>
  <link rel='stylesheet' type='text/css' href='css/blank.css'>
</head>
<body>
  <div id='navwrap'>
    <div id='nav'>
      <p>
        Last Update
      </p>
      <p class='small'>
        
          <time class='timeago' datetime="2022-09-22T22:41:07Z">Thursday, September 22 2022, 22:41</time>
        
      </p>

      <p>Feeds</p>
      <ul class='subscriptions small' >
      
        <li>
          <a href='http://arxiv.org/rss/cs.CC'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.CG'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.DS'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
          
        </li>
      
        <li>
          <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
          
        </li>
      
        <li>
          <a href='https://adamsheffer.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
          
        </li>
      
        <li>
          <a href='https://adamdsmith.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
          
        </li>
      
        <li>
          <a href='https://polylogblog.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
          
        </li>
      
        <li>
          <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
          
        </li>
      
        <li>
          <a href='http://www.argmin.net/feed.xml'><img src='i/feed.png'></a>
          <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
          
        </li>
      
        <li>
          <a href='http://bit-player.org/feed/atom/'><img src='i/feed.png'></a>
          <a href='http://bit-player.org'>bit-player</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-jobs.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-jobs.org'>CCI: jobs</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-events.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-events.org'>CS Theory Events</a>
          
        </li>
      
        <li>
          <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='https://11011110.github.io/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='https://11011110.github.io/blog/'>David Eppstein</a>
          
        </li>
      
        <li>
          <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='i/feed.png'></a>
          <a href='https://daveagp.wordpress.com'>David Pritchard</a>
          
        </li>
      
        <li>
          <a href='https://decentdescent.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://decentdescent.org/'>Decent Descent</a>
          
        </li>
      
        <li>
          <a href='https://decentralizedthoughts.github.io/feed'><img src='i/feed.png'></a>
          <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
          
        </li>
      
        <li>
          <a href='https://differentialprivacy.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
          
        </li>
      
        <li>
          <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='i/feed.png'></a>
          <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
          
        </li>
      
        <li>
          <a href='https://emanueleviola.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
          
        </li>
      
        <li>
          <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='i/feed.png'></a>
          <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
          
        </li>
      
        <li>
          <a href='https://dstheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
          
        </li>
      
        <li>
          <a href='https://francisbach.com/feed/'><img src='i/feed.png'></a>
          <a href='https://francisbach.com'>Francis Bach</a>
          
        </li>
      
        <li>
          <a href='https://gilkalai.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
          
        </li>
      
        <li>
          <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
          
        </li>
      
        <li>
          <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='i/feed.png'></a>
          <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
          
        </li>
      
        <li>
          <a href='https://gradientscience.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://gradientscience.org/'>Gradient Science</a>
          
        </li>
      
        <li>
          <a href='http://grigory.us/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
          
        </li>
      
        <li>
          <a href='https://tcsmath.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
          
        </li>
      
        <li>
          <a href='https://kamathematics.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
          
        </li>
      
        <li>
          <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
          
        </li>
      
        <li>
          <a href='https://lucatrevisan.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
          
        </li>
      
        <li>
          <a href='https://mittheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
          
        </li>
      
        <li>
          <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
          
        </li>
      
        <li>
          <a href='http://blog.mrtz.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
          
        </li>
      
        <li>
          <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
          
        </li>
      
        <li>
          <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
          
        </li>
      
        <li>
          <a href='http://www.solipsistslog.com/feed/'><img src='i/feed.png'></a>
          <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
          
        </li>
      
        <li>
          <a href='http://www.offconvex.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://offconvex.github.io/'>Off the Convex Path</a>
          
        </li>
      
        <li>
          <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
          
        </li>
      
        <li>
          <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
          
        </li>
      
        <li>
          <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='i/feed.png'></a>
          <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
          
        </li>
      
        <li>
          <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
          
        </li>
      
        <li>
          <a href='https://scottaaronson.blog/?feed=atom'><img src='i/feed.png'></a>
          <a href='https://scottaaronson.blog'>Scott Aaronson</a>
          
        </li>
      
        <li>
          <a href='https://blog.simons.berkeley.edu/feed/'><img src='i/feed.png'></a>
          <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
          
        </li>
      
        <li>
          <a href='https://tcsplus.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
          
        </li>
      
        <li>
          <a href='https://toc4fairness.org/feed/'><img src='i/feed.png'></a>
          <a href='https://toc4fairness.org'>TOC for Fairness</a>
          
        </li>
      
        <li>
          <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='i/feed.png'></a>
          <a href='http://blog.geomblog.org/'>The Geomblog</a>
          
        </li>
      
        <li>
          <a href='https://www.let-all.com/blog/feed/'><img src='i/feed.png'></a>
          <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
          
        </li>
      
        <li>
          <a href='https://theorydish.blog/feed/'><img src='i/feed.png'></a>
          <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
          
        </li>
      
        <li>
          <a href='https://thmatters.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://thmatters.wordpress.com'>Theory Matters</a>
          
        </li>
      
        <li>
          <a href='https://mycqstate.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
          
        </li>
      
        <li>
          <a href='https://agtb.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
          
        </li>
      
        <li>
          <a href='https://windowsontheory.org/feed/'><img src='i/feed.png'></a>
          <a href='https://windowsontheory.org'>Windows on Theory</a>
          
        </li>
      
      </ul>

      <p class='small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
      <p class='small'>Subscribe to the <a href="atom.xml">Atom feed</a> or <a href="rss20.xml">RSS feed</a> to stay up to date.</p>
      <p class='small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
      <p class='small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
      <p class='small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
    </div>
  </div>

  <div id='opts'>
    <div style='width: 100%; text-align: right;'>
    <img src='i/view-headlines.png' id='show-headlines' title='Show Headlines Only' width='24' height='24'>
    <img src='i/view-snippets.png' id='show-snippets' title='Show Snippets' width='24' height='24'>
    <img src='i/view-standard.png' id='show-fulltext' title='Show Full Text' width='24' height='24'>
    </div>
  </div>

  <h1>
    Theory of Computing Report
  </h1>

  <div id="articles">
    
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Thursday, September 22
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/09/22/faculty-at-claremont-mckenna-college-apply-by-november-15-2022/'>Faculty at Claremont McKenna College (apply by November 15, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The Department of Mathematical Sciences at Claremont McKenna College invites applications for a tenure-track position, at the assistant professor level, in Probability, Statistics, and Statistical Computing. Website: www.mathjobs.org/jobs/list/20279 Email: sarah.cannon@cmc.edu; Ckao@claremontmckenna.edu
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The Department of Mathematical Sciences at Claremont McKenna College invites applications for a tenure-track position, at the assistant professor level, in Probability, Statistics, and Statistical Computing.</p>
<p>Website: <a href="https://www.mathjobs.org/jobs/list/20279">https://www.mathjobs.org/jobs/list/20279</a><br />
Email: sarah.cannon@cmc.edu; Ckao@claremontmckenna.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T17:40:49Z">Thursday, September 22 2022, 17:40</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/09/22/tenure-track-assistant-professor-at-cunys-baruch-college-apply-by-november-7-2022/'>Tenure track assistant professor at CUNY’s Baruch College (apply by November 7, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Baruch College, part of CUNY, lies at the heart of Manhattan. It is regularly ranked as the country&#8217;s top college for social mobility. Since Baruch College was traditionally CUNY&#8217;s business school, it did not include Computer Science. Our computer science major will start in August 2023. We are hiring professors that will help shape and [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Baruch College, part of CUNY, lies at the heart of Manhattan. It is regularly ranked as the country&#8217;s top college for social mobility. Since Baruch College was traditionally CUNY&#8217;s business school, it did not include Computer Science. Our computer science major will start in August 2023. We are hiring professors that will help shape and grow computer science at Baruch.</p>
<p>Website: <a href="https://geometrynyc.wixsite.com/csjobs">https://geometrynyc.wixsite.com/csjobs</a><br />
Email: warren.gordon@baruch.cuny.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T17:00:15Z">Thursday, September 22 2022, 17:00</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/'>Cheating at Chess—Not Again</a></h3>
          <p class='item-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Play the opening like a book, the middle game like a magician, and the end game like a machine &#8212; Rudolf Spielmann Kenneth Regan is my dear friend and co-writer of this blog. He obtained his doctorate&#8212;technically D.Phil not PhD&#8212;in 1986 for a thesis titled On the Separation of Complexity Classes from the University of [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><font color="#0044cc"><br />
<em>Play the opening like a book, the middle game like a magician, and the end game like a machine &#8212; Rudolf Spielmann</em><br />
<font color="#000000"></p>
<p><a href="https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/kenglenveagh/" rel="attachment wp-att-20422"><img data-attachment-id="20422" data-permalink="https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/kenglenveagh/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenGlenveagh.jpeg?fit=185%2C272&amp;ssl=1" data-orig-size="185,272" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="KenGlenveagh" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenGlenveagh.jpeg?fit=185%2C272&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenGlenveagh.jpeg?fit=185%2C272&amp;ssl=1" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenGlenveagh.jpeg?resize=123%2C181&#038;ssl=1" alt="" width="123" height="181" class="alignright wp-image-20422" data-recalc-dims="1" /></a></p>
<p>
Kenneth Regan is my dear friend and co-writer of this blog. He obtained his doctorate&#8212;technically D.Phil not PhD&#8212;in 1986 for a thesis titled <em>On the Separation of Complexity Classes</em> from the University of Oxford under Dominic Welsh. He has, however, been enmeshed this month in a story quite separate from complexity classes.</p>
<p>
It was Ken&#8217;s birthday just last week and we wish him many more.</p>
<p>
<p><H2> Cheating at Chess </H2></p>
<p><p>
Ken was the 1977 US Junior co-champion and once held the record of youngest USCF Master since Bobby Fischer. He holds the title of International Master with a rating of 2372. Ken is perhaps the strongest chess player ever with a doctorate in complexity theory.</p>
<p>
He is certainly the world best at <i>both</i> complexity theory and cheating at chess. Ken is one of the leading experts in detecting cheating in games played in real tournaments. </p>
<p>
He has, however, been occupied by a major story that erupted after the world champion, Magnus Carlsen, lost to the American teenager and bottom-rated participant Hans Niemann in the third round of the Sinquefield Cup in St. Louis. The next day, Labor Day, Carlsen abruptly withdrew from the tournament with no explanation beyond a cryptic <a href="https://twitter.com/MagnusCarlsen/status/1566848734616555523">tweet</a>. This was widely regarded as an insinuation of some kind of cheating.  Ken was involved daily monitoring the event and was cited in a subsequent <a href="https://grandchesstour.org/blog/2022-sinquefield-cup-chief-arbiter's-statement">press release</a> as having found nothing amiss. </p>
<p>
Nevertheless&#8212;really <i>everthemore</i>&#8212;this has sparked renewed discussion of cheating at chess and measures to protect tournaments at all levels. Let&#8217;s go into that.</p>
<p>
<p><H2> Detecting Cheating </H2></p>
<p><p>
How does one cheat at chess? Imagine Bob is playing a game in a live chess tournament. Bob is a strong player but is not nearly as strong as his opponent Ted. How does Bob cheat?</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/two-2/" rel="attachment wp-att-20423"><img data-attachment-id="20423" data-permalink="https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/two-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/two.jpeg?fit=273%2C184&amp;ssl=1" data-orig-size="273,184" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="two" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/two.jpeg?fit=273%2C184&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/two.jpeg?fit=273%2C184&amp;ssl=1" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/two.jpeg?resize=273%2C184&#038;ssl=1" alt="" width="273" height="184" class="aligncenter size-full wp-image-20423" data-recalc-dims="1" /></a></p>
<p>
The basic idea is quite simple: Bob uses a computer program <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" /> to make moves for him. He types Ted&#8217;s moves into <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" /> and then makes its moves. The reason this is so powerful is that the ranking of the computer program <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" /> is likely much higher than Ted&#8217;s. It could be ranked at 3000 or even higher. This means that Bob is likely to not lose to Ted but perhaps even beat him. </p>
<p>
The challenge for Bob to cheat in this manner is that he must ask the program <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" /> for its moves without being detected. Bob is not allowed to have a digital device like a phone or a laptop to ask the program <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" /> for its next move. This is the challenge that Bob, the cheater, is faced with. He must enter Ted&#8217;s last move and then follow <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" />&#8216;s move without it being noticed that he invoked the program <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" />. This is the challenge that the cheater must solve.</p>
<p>
The cheater may be able to send the moves to the program <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" /> in various ways. In some cases Bob has been found to use some hidden device to get this information to <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" />. He also may use clever ways to get the moves from <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" />. </p>
<p>
<p><H2> Why Is Detection Hard? </H2></p>
<p><p>
Ken is one of the world&#8217;s foremost experts on using predictive analytics to help detect computer-assisted cheating in chess tournaments. Why is this hard? There are several reasons that this is difficult: But the central point is expressed by Alexander <a href="https://en.wikipedia.org/wiki/Alexander_Grischuk">Grischuk</a> who notes that &#8220;only a very stupid Bob who stubbornly plays the computer&#8217;s first line&#8221; is likely to get detected.</p>
<p>
Let&#8217;s examine what Grischuk means. Bob as above is trying to use <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" />&#8216;s moves to defeat Ted. Grischuk&#8217;s point is that Bob is stupid if he blindly uses the first move that the program <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" /> suggests. Programs often suggest more than one move that is safe to play. This makes detection much harder. </p>
<p>
An even more powerful point is that what if Bob consults more than one program. Perhaps Bob checks the top moves from several programs <img src="https://s0.wp.com/latex.php?latex=%7BP_1%2C+P_2%2C+%5Cdots%2C+P_6%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P_1, P_2, &#92;dots, P_6}" class="latex" />. This could make the detection of his cheating even more difficult. </p>
<p>
Bob could use similar ideas to make the detection that he is consulting a program even more complicated. This is why Ken&#8217;s checking to see if cheating occurred is so difficult. He tries to stay ahead on the detection end. For instance, his model is not predicated on identifying which program was used, and the provisionally-deployed ideas explored with his students <a href="https://rjlipton.wpcomstaging.com/2019/11/29/predicating-predictivity/">here</a> quantify departure from human predictivity apart from any programs.</p>
<p>
Consult <a href="https://katv.com/news/nation-world/chess-grandmaster-accused-of-using-sex-toy-to-cheat-win-against-worlds-top-player-hans-niemann-magnus-carlsen-anal-beads-cheating-ai-artificial-intellegence">this</a> for a recent claim that Niemann used <a href="https://www.cosmopolitan.com/sex-love/a12274254/anal-beads-how-to/">anal beads</a> to signal moves. Even Elon Musk <a href="https://futurism.com/the-byte/elon-musk-sex-toy-chess">raised</a> this possibility. Just an extreme example of why detecting cheating is tough.</p>
<p>
<p><H2> Losing in Translation </H2></p>
<p><p>
The chess story took another twist when Carlsen and Niemann faced each other on Monday in the Julius Baer Generations Cup, an online tournament sponsored by Carlsen&#8217;s own organization. Carlsen played one move and then resigned the game&#8212;again giving no comment. Much effort has been expended in trying to translate exactly what Carlsen meant by losing in this manner.</p>
<p>
Two years ago, a <a href="https://www.theguardian.com/sport/2020/oct/16/chesss-cheating-crisis-paranoia-has-become-the-culture">story</a> in the <em>Guardian</em> newspaper subtitled &#8220;paranoia has become the culture&#8221; featured Ken and efforts to avert cheating in tournaments that were moved online on account of the pandemic. Its quoting Ken included an example of translation from English to <em>English</em>:</p>
<blockquote><p><b> </b> <em> &#8220;The pandemic has brought me as much work in a single day as I have had in a year previously,&#8221; said Prof Kenneth Regan, an international chess master and computer scientist whose model is relied on by the sport&#8217;s governing body, <a href="https://www.fide.com">FIDE</a>, to detect suspicious patterns of play. &#8220;It has ruined my sabbatical.&#8221; </em>
</p></blockquote>
<p><p>
What Ken actually said was, &#8220;It ate my sabbatical.&#8221; </p>
<p>
Now Ken was mentioned in the <em>Guardian</em> <a href="https://www.theguardian.com/sport/2022/sep/20/carlsen-v-niemann-the-cheating-row-that-is-rocking-chess-explained">yesterday</a> and again <a href="https://www.theguardian.com/sport/2022/sep/21/magnus-carlsen-v-hans-niemann-world-champion-resigns-after-one-move-chess-julius-baer-generation-cup">today</a>. Today&#8217;s mention linked a longer <a href="https://en.chessbase.com/post/is-hans-niemann-cheating-world-renowned-expert-ken-regan-analyzes">article</a> on the ChessBase site explaining his methods and conclusions to date. Ken may have more to say after the developments&#8212;and ongoing media contacts&#8212;settle down. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/kenoffice/" rel="attachment wp-att-20424"><img data-attachment-id="20424" data-permalink="https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/kenoffice/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenOffice.jpeg?fit=264%2C191&amp;ssl=1" data-orig-size="264,191" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="KenOffice" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenOffice.jpeg?fit=264%2C191&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenOffice.jpeg?fit=264%2C191&amp;ssl=1" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenOffice.jpeg?resize=264%2C191&#038;ssl=1" alt="" width="264" height="191" class="aligncenter size-full wp-image-20424" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
How will chess come out of the current controversies? I hope Ken had a happy birthday in the meantime.</p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T03:59:28Z">Thursday, September 22 2022, 03:59</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10311'>Capturing Bisimulation-Invariant Exponential-Time Complexity Classes</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Florian Bruse (University of Kassel, Kassel, Germany), David Kronenberger (University of Kassel, Kassel, Germany), Martin Lange (University of Kassel, Kassel, Germany)</p><p>Otto's Theorem characterises the bisimulation-invariant PTIME queries over
graphs as exactly those that can be formulated in the polyadic mu-calculus,
hinging on the Immerman-Vardi Theorem which characterises PTIME (over ordered
structures) by First-Order Logic with least fixpoints. This connection has been
extended to characterise bisimulation-invariant EXPTIME by an extension of the
polyadic mu-calculus with functions on predicates, making use of Immerman's
characterisation of EXPTIME by Second-Order Logic with least fixpoints. In this
paper we show that the bisimulation-invariant versions of all classes in the
exponential time hierarchy have logical counterparts which arise as extensions
of the polyadic mu-calculus by higher-order functions. This makes use of the
characterisation of k-EXPTIME by Higher-Order Logic (of order k+1) with least
fixpoints, due to Freire and Martins.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bruse_F/0/1/0/all/0/1">Florian Bruse</a> (University of Kassel, Kassel, Germany), <a href="http://arxiv.org/find/cs/1/au:+Kronenberger_D/0/1/0/all/0/1">David Kronenberger</a> (University of Kassel, Kassel, Germany), <a href="http://arxiv.org/find/cs/1/au:+Lange_M/0/1/0/all/0/1">Martin Lange</a> (University of Kassel, Kassel, Germany)</p><p>Otto's Theorem characterises the bisimulation-invariant PTIME queries over
graphs as exactly those that can be formulated in the polyadic mu-calculus,
hinging on the Immerman-Vardi Theorem which characterises PTIME (over ordered
structures) by First-Order Logic with least fixpoints. This connection has been
extended to characterise bisimulation-invariant EXPTIME by an extension of the
polyadic mu-calculus with functions on predicates, making use of Immerman's
characterisation of EXPTIME by Second-Order Logic with least fixpoints. In this
paper we show that the bisimulation-invariant versions of all classes in the
exponential time hierarchy have logical counterparts which arise as extensions
of the polyadic mu-calculus by higher-order functions. This makes use of the
characterisation of k-EXPTIME by Higher-Order Logic (of order k+1) with least
fixpoints, due to Freire and Martins.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10312'>Schema-Based Automata Determinization</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Joachim Niehren (Inria, Universit&#xe9; de Lille, France), Momar Sakho (Inria, Universit&#xe9; de Lille, France), Antonio Al Serhali (Inria, Universit&#xe9; de Lille, France)</p><p>We propose an algorithm for schema-based determinization of finite automata
on words and of step-wise hedge automata on nested words. The idea is to
integrate schema-based cleaning directly into automata determinization. We
prove the correctness of our new algorithm and show that it is alway smore
efficient than standard determinization followed by schema-based cleaning. Our
implementation permits to obtain a small deterministic automaton for an example
of an XPath query, where standard determinization yields a huge stepwise hedge
automaton for which schema-based cleaning runs out of memory.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Niehren_J/0/1/0/all/0/1">Joachim Niehren</a> (Inria, Universit&#xe9; de Lille, France), <a href="http://arxiv.org/find/cs/1/au:+Sakho_M/0/1/0/all/0/1">Momar Sakho</a> (Inria, Universit&#xe9; de Lille, France), <a href="http://arxiv.org/find/cs/1/au:+Serhali_A/0/1/0/all/0/1">Antonio Al Serhali</a> (Inria, Universit&#xe9; de Lille, France)</p><p>We propose an algorithm for schema-based determinization of finite automata
on words and of step-wise hedge automata on nested words. The idea is to
integrate schema-based cleaning directly into automata determinization. We
prove the correctness of our new algorithm and show that it is alway smore
efficient than standard determinization followed by schema-based cleaning. Our
implementation permits to obtain a small deterministic automaton for an example
of an XPath query, where standard determinization yields a huge stepwise hedge
automaton for which schema-based cleaning runs out of memory.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10398'>BQP is not in NP</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Jonah Librande</p><p>Quantum computers are widely believed have an advantage over classical
computers, and some have even published some empirical evidence that this is
the case. However, these publications do not include a rigorous proof of this
advantage, which would have to minimally state that the class of problems
decidable by a quantum computer in polynomial time, BQP, contains problems that
are not in the class of problems decidable by a classical computer with similar
time bounds, P. Here, I provide the proof of a stronger result that implies
this result: BQP contains problems that lie beyond the much larger classical
computing class NP. This proves that quantum computation is able to efficiently
solve problems which are far beyond the capabilities of classical computers.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Librande_J/0/1/0/all/0/1">Jonah Librande</a></p><p>Quantum computers are widely believed have an advantage over classical
computers, and some have even published some empirical evidence that this is
the case. However, these publications do not include a rigorous proof of this
advantage, which would have to minimally state that the class of problems
decidable by a quantum computer in polynomial time, BQP, contains problems that
are not in the class of problems decidable by a classical computer with similar
time bounds, P. Here, I provide the proof of a stronger result that implies
this result: BQP contains problems that lie beyond the much larger classical
computing class NP. This proves that quantum computation is able to efficiently
solve problems which are far beyond the capabilities of classical computers.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10509'>Downward Self-Reducibility in TFNP</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Prahladh Harsha, Daniel Mitropolsky, Alon Rosen</p><p>A problem is \emph{downward self-reducible} if it can be solved efficiently
given an oracle that returns solutions for strictly smaller instances. In the
decisional landscape, downward self-reducibility is well studied and it is
known that all downward self-reducible problems are in \textsc{PSPACE}. In this
paper, we initiate the study of downward self-reducible search problems which
are guaranteed to have a solution -- that is, the downward self-reducible
problems in \textsc{TFNP}. We show that most natural $\PLS$-complete problems
are downward self-reducible and any downward self-reducible problem in
\textsc{TFNP} is contained in \textsc{PLS}. Furthermore, if the downward
self-reducible problem is in \textsc{UTFNP} (i.e. it has a unique solution),
then it is actually contained in \textsc{CLS}. This implies that if integer
factoring is \emph{downward self-reducible} then it is in fact in \textsc{CLS},
suggesting that no efficient factoring algorithm exists using the factorization
of smaller numbers.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Harsha_P/0/1/0/all/0/1">Prahladh Harsha</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitropolsky_D/0/1/0/all/0/1">Daniel Mitropolsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosen_A/0/1/0/all/0/1">Alon Rosen</a></p><p>A problem is \emph{downward self-reducible} if it can be solved efficiently
given an oracle that returns solutions for strictly smaller instances. In the
decisional landscape, downward self-reducibility is well studied and it is
known that all downward self-reducible problems are in \textsc{PSPACE}. In this
paper, we initiate the study of downward self-reducible search problems which
are guaranteed to have a solution -- that is, the downward self-reducible
problems in \textsc{TFNP}. We show that most natural $\PLS$-complete problems
are downward self-reducible and any downward self-reducible problem in
\textsc{TFNP} is contained in \textsc{PLS}. Furthermore, if the downward
self-reducible problem is in \textsc{UTFNP} (i.e. it has a unique solution),
then it is actually contained in \textsc{CLS}. This implies that if integer
factoring is \emph{downward self-reducible} then it is in fact in \textsc{CLS},
suggesting that no efficient factoring algorithm exists using the factorization
of smaller numbers.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10291'>The Dispersive Art Gallery Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Christian Rieck, Christian Scheffer</p><p>We introduce a new variant of the art gallery problem that comes from safety
issues. In this variant we are not interested in guard sets of smallest
cardinality, but in guard sets with largest possible distances between these
guards. To the best of our knowledge, this variant has not been considered
before.We call it the Dispersive Art Gallery Problem. In particular, in the
dispersive art gallery problem we are given a polygon $\mathcal{P}$ and a real
number $\ell$, and want to decide whether $\mathcal{P}$ has a guard set such
that every pair of guards in this set is at least a distance of $\ell$ apart.
</p>
<p>In this paper, we study the vertex guard variant of this problem for the
class of polyominoes. We consider rectangular visibility and distances as
geodesics in the $L_1$-metric. Our results are as follows. We give a (simple)
thin polyomino such that every guard set has minimum pairwise distances of at
most $3$. On the positive side, we describe an algorithm that computes guard
sets for simple polyominoes that match this upper bound, i.e., the algorithm
constructs worst-case optimal solutions. We also study the computational
complexity of computing guard sets that maximize the smallest distance between
all pairs of guards within the guard sets. We prove that deciding whether there
exists a guard set realizing a minimum pairwise distance for all pairs of
guards of at least $5$ in a given polyomino is NP-complete.
</p>
<p>We were also able to find an optimal dynamic programming approach that
computes a guard set that maximizes the minimum pairwise distance between
guards in tree-shaped polyominoes, i.e., computes optimal solutions. Because
the shapes constructed in the NP-hardness reduction are thin as well (but have
holes), this result completes the case for thin polyominoes.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rieck_C/0/1/0/all/0/1">Christian Rieck</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheffer_C/0/1/0/all/0/1">Christian Scheffer</a></p><p>We introduce a new variant of the art gallery problem that comes from safety
issues. In this variant we are not interested in guard sets of smallest
cardinality, but in guard sets with largest possible distances between these
guards. To the best of our knowledge, this variant has not been considered
before.We call it the Dispersive Art Gallery Problem. In particular, in the
dispersive art gallery problem we are given a polygon $\mathcal{P}$ and a real
number $\ell$, and want to decide whether $\mathcal{P}$ has a guard set such
that every pair of guards in this set is at least a distance of $\ell$ apart.
</p>
<p>In this paper, we study the vertex guard variant of this problem for the
class of polyominoes. We consider rectangular visibility and distances as
geodesics in the $L_1$-metric. Our results are as follows. We give a (simple)
thin polyomino such that every guard set has minimum pairwise distances of at
most $3$. On the positive side, we describe an algorithm that computes guard
sets for simple polyominoes that match this upper bound, i.e., the algorithm
constructs worst-case optimal solutions. We also study the computational
complexity of computing guard sets that maximize the smallest distance between
all pairs of guards within the guard sets. We prove that deciding whether there
exists a guard set realizing a minimum pairwise distance for all pairs of
guards of at least $5$ in a given polyomino is NP-complete.
</p>
<p>We were also able to find an optimal dynamic programming approach that
computes a guard set that maximizes the minimum pairwise distance between
guards in tree-shaped polyominoes, i.e., computes optimal solutions. Because
the shapes constructed in the NP-hardness reduction are thin as well (but have
holes), this result completes the case for thin polyominoes.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10400'>Efficient inspection of underground galleries using k robots with limited energy</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Sergey Bereg, L. Evaristo Caraballo, Jos&#xe9; Miguel D&#xed;az-B&#xe1;&#xf1;ez</p><p>We study the problem of optimally inspecting an underground (underwater)
gallery with k agents. We consider a gallery with a single opening and with a
tree topology rooted at the opening. Due to the small diameter of the pipes
(caves), the agents are small robots with limited autonomy and there is a
supply station at the gallery's opening. Therefore, they are initially placed
at the root and periodically need to return to the supply station. Our goal is
to design off-line strategies to efficiently cover the tree with $k$ small
robots. We consider two objective functions: the covering time (maximum
collective time) and the covering distance (total traveled distance). The
maximum collective time is the maximum time spent by a robot needs to finish
its assigned task (assuming that all the robots start at the same time); the
total traveled distance is the sum of the lengths of all the covering walks.
Since the problems are intractable for big trees, we propose approximation
algorithms. Both efficiency and accuracy of the suboptimal solutions are
empirically showed for random trees through intensive numerical experiments.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bereg_S/0/1/0/all/0/1">Sergey Bereg</a>, <a href="http://arxiv.org/find/cs/1/au:+Caraballo_L/0/1/0/all/0/1">L. Evaristo Caraballo</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1">Jos&#xe9; Miguel D&#xed;az-B&#xe1;&#xf1;ez</a></p><p>We study the problem of optimally inspecting an underground (underwater)
gallery with k agents. We consider a gallery with a single opening and with a
tree topology rooted at the opening. Due to the small diameter of the pipes
(caves), the agents are small robots with limited autonomy and there is a
supply station at the gallery's opening. Therefore, they are initially placed
at the root and periodically need to return to the supply station. Our goal is
to design off-line strategies to efficiently cover the tree with $k$ small
robots. We consider two objective functions: the covering time (maximum
collective time) and the covering distance (total traveled distance). The
maximum collective time is the maximum time spent by a robot needs to finish
its assigned task (assuming that all the robots start at the same time); the
total traveled distance is the sum of the lengths of all the covering walks.
Since the problems are intractable for big trees, we propose approximation
algorithms. Both efficiency and accuracy of the suboptimal solutions are
empirically showed for random trees through intensive numerical experiments.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10324'>Characterizing the Decidability of Finite State Automata Team Games with Communication</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Michael Coulombe (Massachusetts Institute of Technology), Jayson Lynch (Cheriton School of Computer Science, University of Waterloo)</p><p>In this paper we define a new model of limited communication for multiplayer
team games of imperfect information. We prove that the Team DFA Game and Team
Formula Game, which have bounded state, remain undecidable when players have a
rate of communication which is less than the rate at which they make moves in
the game. We also show that meeting this communication threshold causes these
games to be decidable.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Coulombe_M/0/1/0/all/0/1">Michael Coulombe</a> (Massachusetts Institute of Technology), <a href="http://arxiv.org/find/cs/1/au:+Lynch_J/0/1/0/all/0/1">Jayson Lynch</a> (Cheriton School of Computer Science, University of Waterloo)</p><p>In this paper we define a new model of limited communication for multiplayer
team games of imperfect information. We prove that the Team DFA Game and Team
Formula Game, which have bounded state, remain undecidable when players have a
rate of communication which is less than the rate at which they make moves in
the game. We also show that meeting this communication threshold causes these
games to be decidable.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.09903'>Parametric Synthesis of Computational Circuits for Complex Quantum Algorithms</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Cesar Borisovich Pronin, Andrey Vladimirovich Ostroukh</p><p>At the moment, quantum circuits are created mainly by manually placing logic
elements on lines that symbolize quantum bits. The purpose of creating Quantum
Circuit Synthesizer "Naginata" was due to the fact that even with a slight
increase in the number of operations in a quantum algorithm, leads to the
significant increase in size of the corresponding quantum circuit. This causes
serious difficulties both in creating and debugging these quantum circuits. The
purpose of our quantum synthesizer is enabling users an opportunity to
implement quantum algorithms using higher-level commands. This is achieved by
creating generic blocks for frequently used operations such as: the adder,
multiplier, digital comparator (comparison operator), etc. Thus, the user could
implement a quantum algorithm by using these generic blocks, and the quantum
synthesizer would create a suitable circuit for this algorithm, in a format
that is supported by the chosen quantum computation environment. This approach
greatly simplifies the processes of development and debugging a quantum
algorithm. The proposed approach for implementing quantum algorithms has a
potential application in the field of machine learning, in this regard, we
provided an example of creating a circuit for training a simple neural network.
Neural networks have a significant impact on the technological development of
the transport and road complex, and there is a potential for improving the
reliability and efficiency of their learning process by utilizing quantum
computation, through the introduction of quantum computing.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Pronin_C/0/1/0/all/0/1">Cesar Borisovich Pronin</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ostroukh_A/0/1/0/all/0/1">Andrey Vladimirovich Ostroukh</a></p><p>At the moment, quantum circuits are created mainly by manually placing logic
elements on lines that symbolize quantum bits. The purpose of creating Quantum
Circuit Synthesizer "Naginata" was due to the fact that even with a slight
increase in the number of operations in a quantum algorithm, leads to the
significant increase in size of the corresponding quantum circuit. This causes
serious difficulties both in creating and debugging these quantum circuits. The
purpose of our quantum synthesizer is enabling users an opportunity to
implement quantum algorithms using higher-level commands. This is achieved by
creating generic blocks for frequently used operations such as: the adder,
multiplier, digital comparator (comparison operator), etc. Thus, the user could
implement a quantum algorithm by using these generic blocks, and the quantum
synthesizer would create a suitable circuit for this algorithm, in a format
that is supported by the chosen quantum computation environment. This approach
greatly simplifies the processes of development and debugging a quantum
algorithm. The proposed approach for implementing quantum algorithms has a
potential application in the field of machine learning, in this regard, we
provided an example of creating a circuit for training a simple neural network.
Neural networks have a significant impact on the technological development of
the transport and road complex, and there is a potential for improving the
reliability and efficiency of their learning process by utilizing quantum
computation, through the introduction of quantum computing.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10241'>Exact and Sampling Methods for Mining Higher-Order Motifs in Large Hypergraphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Quintino Francesco Lotito, Federico Musciotto, Federico Battiston, Alberto Montresor</p><p>Network motifs are patterns of interactions occurring among a small set of
nodes in a graph. They highlight fundamental aspects of the interplay between
the topology and the dynamics of complex networks and have a wide range of
real-world applications. Motif analysis has been extended to a variety of
network models that allow for a richer description of the interactions of a
system, including weighted, temporal, multilayer, and, more recently,
higher-order networks. Generalizing network motifs to capture patterns of group
interactions is not only interesting from the fundamental perspective of
understanding complex systems, but also proposes unprecedented computational
challenges. In this work, we focus on the problem of counting occurrences of
sub-hypergraph patterns in very large higher-order networks. We show that, by
directly exploiting higher-order structures, we speed up the counting process
compared to applying traditional data mining techniques for network motifs.
Moreover, by including hyperedge sampling techniques, computational complexity
is further reduced at the cost of small errors in the estimation of motif
frequency. We evaluate our algorithms on several real-world datasets describing
face-to-face interactions, co-authorship and human communication. We show that
our approximated algorithm not only allows to speed up the performance, but
also to extract larger higher-order motifs beyond the computational limits of
an exact approach.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lotito_Q/0/1/0/all/0/1">Quintino Francesco Lotito</a>, <a href="http://arxiv.org/find/cs/1/au:+Musciotto_F/0/1/0/all/0/1">Federico Musciotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Battiston_F/0/1/0/all/0/1">Federico Battiston</a>, <a href="http://arxiv.org/find/cs/1/au:+Montresor_A/0/1/0/all/0/1">Alberto Montresor</a></p><p>Network motifs are patterns of interactions occurring among a small set of
nodes in a graph. They highlight fundamental aspects of the interplay between
the topology and the dynamics of complex networks and have a wide range of
real-world applications. Motif analysis has been extended to a variety of
network models that allow for a richer description of the interactions of a
system, including weighted, temporal, multilayer, and, more recently,
higher-order networks. Generalizing network motifs to capture patterns of group
interactions is not only interesting from the fundamental perspective of
understanding complex systems, but also proposes unprecedented computational
challenges. In this work, we focus on the problem of counting occurrences of
sub-hypergraph patterns in very large higher-order networks. We show that, by
directly exploiting higher-order structures, we speed up the counting process
compared to applying traditional data mining techniques for network motifs.
Moreover, by including hyperedge sampling techniques, computational complexity
is further reduced at the cost of small errors in the estimation of motif
frequency. We evaluate our algorithms on several real-world datasets describing
face-to-face interactions, co-authorship and human communication. We show that
our approximated algorithm not only allows to speed up the performance, but
also to extract larger higher-order motifs beyond the computational limits of
an exact approach.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10262'>On Reachable Assignments under Dichotomous Preferences</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Takehiro Ito, Naonori Kakimura, Naoyuki Kamiyama, Yusuke Kobayashi, Yuta Nozaki, Yoshio Okamoto, Kenta Ozeki</p><p>We consider the problem of determining whether a target item assignment can
be reached from an initial item assignment by a sequence of pairwise exchanges
of items between agents. In particular, we consider the situation where each
agent has a dichotomous preference over the items, that is, each agent
evaluates each item as acceptable or unacceptable. Furthermore, we assume that
communication between agents is limited, and the relationship is represented by
an undirected graph. Then, a pair of agents can exchange their items only if
they are connected by an edge and the involved items are acceptable. We prove
that this problem is PSPACE-complete even when the communication graph is
complete (that is, every pair of agents can exchange their items), and this
problem can be solved in polynomial time if an input graph is a tree.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ito_T/0/1/0/all/0/1">Takehiro Ito</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakimura_N/0/1/0/all/0/1">Naonori Kakimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamiyama_N/0/1/0/all/0/1">Naoyuki Kamiyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1">Yusuke Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nozaki_Y/0/1/0/all/0/1">Yuta Nozaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Okamoto_Y/0/1/0/all/0/1">Yoshio Okamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozeki_K/0/1/0/all/0/1">Kenta Ozeki</a></p><p>We consider the problem of determining whether a target item assignment can
be reached from an initial item assignment by a sequence of pairwise exchanges
of items between agents. In particular, we consider the situation where each
agent has a dichotomous preference over the items, that is, each agent
evaluates each item as acceptable or unacceptable. Furthermore, we assume that
communication between agents is limited, and the relationship is represented by
an undirected graph. Then, a pair of agents can exchange their items only if
they are connected by an edge and the involved items are acceptable. We prove
that this problem is PSPACE-complete even when the communication graph is
complete (that is, every pair of agents can exchange their items), and this
problem can be solved in polynomial time if an input graph is a tree.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10265'>Improved Approximation for Two-Edge-Connectivity</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mohit Garg, Fabrizio Grandoni, Afrouz Jabal Ameli</p><p>The basic goal of survivable network design is to construct low-cost networks
which preserve a sufficient level of connectivity despite the failure or
removal of a few nodes or edges. One of the most basic problems in this area is
the $2$-Edge-Connected Spanning Subgraph problem (2-ECSS): given an undirected
graph $G$, find a $2$-edge-connected spanning subgraph $H$ of $G$ with the
minimum number of edges (in particular, $H$ remains connected after the removal
of one arbitrary edge).
</p>
<p>2-ECSS is NP-hard and the best-known (polynomial-time) approximation factor
for this problem is $4/3$. Interestingly, this factor was achieved with
drastically different techniques by [Hunkenschr{\"o}der, Vempala and Vetta
'00,'19] and [Seb{\"o} and Vygen, '14]. In this paper we present an improved
$\frac{118}{89}+\epsilon&lt;1.326$ approximation for 2-ECSS.
</p>
<p>The key ingredient in our approach (which might also be helpful in future
work) is a reduction to a special type of structured graphs: our reduction
preserves approximation factors up to $6/5$. While reducing to
2-vertex-connected graphs is trivial (and heavily used in prior work), our
structured graphs are "almost" 3-vertex-connected: more precisely, given any
2-vertex-cut $\{u,v\}$ of a structured graph $G=(V,E)$, $G[V\setminus \{u,v\}]$
has exactly 2 connected components, one of which contains exactly one node of
degree $2$ in $G$.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Garg_M/0/1/0/all/0/1">Mohit Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Grandoni_F/0/1/0/all/0/1">Fabrizio Grandoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Ameli_A/0/1/0/all/0/1">Afrouz Jabal Ameli</a></p><p>The basic goal of survivable network design is to construct low-cost networks
which preserve a sufficient level of connectivity despite the failure or
removal of a few nodes or edges. One of the most basic problems in this area is
the $2$-Edge-Connected Spanning Subgraph problem (2-ECSS): given an undirected
graph $G$, find a $2$-edge-connected spanning subgraph $H$ of $G$ with the
minimum number of edges (in particular, $H$ remains connected after the removal
of one arbitrary edge).
</p>
<p>2-ECSS is NP-hard and the best-known (polynomial-time) approximation factor
for this problem is $4/3$. Interestingly, this factor was achieved with
drastically different techniques by [Hunkenschr{\"o}der, Vempala and Vetta
'00,'19] and [Seb{\"o} and Vygen, '14]. In this paper we present an improved
$\frac{118}{89}+\epsilon&lt;1.326$ approximation for 2-ECSS.
</p>
<p>The key ingredient in our approach (which might also be helpful in future
work) is a reduction to a special type of structured graphs: our reduction
preserves approximation factors up to $6/5$. While reducing to
2-vertex-connected graphs is trivial (and heavily used in prior work), our
structured graphs are "almost" 3-vertex-connected: more precisely, given any
2-vertex-cut $\{u,v\}$ of a structured graph $G=(V,E)$, $G[V\setminus \{u,v\}]$
has exactly 2 connected components, one of which contains exactly one node of
degree $2$ in $G$.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10323'>Avoid One's Doom: Finding Cliff-Edge Configurations in Petri Nets</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Giann Karlo Aguirre-Sambon&#xed; (INRIA and LMF, CNRS and ENS Paris-Saclay, Universit&#xe9; Paris-Saclay), Stefan Haar (INRIA and LMF, CNRS and ENS Paris-Saclay, Universit&#xe9; Paris-Saclay), Lo&#xef;c Paulev&#xe9; (Univ. Bordeaux, Bordeaux INP, CNRS, LaBRI, UMR5800), Stefan Schwoon (INRIA and LMF, CNRS and ENS Paris-Saclay, Universit&#xe9; Paris-Saclay), Nick W&#xfc;rdemann (Department of Computing Science, University of Oldenburg)</p><p>A crucial question in analyzing a concurrent system is to determine its
long-run behaviour, and in particular, whether there are irreversible choices
in its evolution, leading into parts of the reachability space from which there
is no return to other parts. Casting this problem in the unifying framework of
safe Petri nets, our previous work has provided techniques for identifying
attractors, i.e. terminal strongly connected components of the reachability
space, whose attraction basins we wish to determine. Here, we provide a
solution for the case of safe Petri nets. Our algorithm uses net unfoldings and
provides a map of all of the system's configurations (concurrent executions)
that act as cliff-edges, i.e. any maximal extension for those configurations
lies in some basin that is considered fatal. The computation turns out to
require only a relatively small prefix of the unfolding, just twice the depth
of Esparza's complete prefix.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aguirre_Samboni_G/0/1/0/all/0/1">Giann Karlo Aguirre-Sambon&#xed;</a> (INRIA and LMF, CNRS and ENS Paris-Saclay, Universit&#xe9; Paris-Saclay), <a href="http://arxiv.org/find/cs/1/au:+Haar_S/0/1/0/all/0/1">Stefan Haar</a> (INRIA and LMF, CNRS and ENS Paris-Saclay, Universit&#xe9; Paris-Saclay), <a href="http://arxiv.org/find/cs/1/au:+Pauleve_L/0/1/0/all/0/1">Lo&#xef;c Paulev&#xe9;</a> (Univ. Bordeaux, Bordeaux INP, CNRS, LaBRI, UMR5800), <a href="http://arxiv.org/find/cs/1/au:+Schwoon_S/0/1/0/all/0/1">Stefan Schwoon</a> (INRIA and LMF, CNRS and ENS Paris-Saclay, Universit&#xe9; Paris-Saclay), <a href="http://arxiv.org/find/cs/1/au:+Wurdemann_N/0/1/0/all/0/1">Nick W&#xfc;rdemann</a> (Department of Computing Science, University of Oldenburg)</p><p>A crucial question in analyzing a concurrent system is to determine its
long-run behaviour, and in particular, whether there are irreversible choices
in its evolution, leading into parts of the reachability space from which there
is no return to other parts. Casting this problem in the unifying framework of
safe Petri nets, our previous work has provided techniques for identifying
attractors, i.e. terminal strongly connected components of the reachability
space, whose attraction basins we wish to determine. Here, we provide a
solution for the case of safe Petri nets. Our algorithm uses net unfoldings and
provides a map of all of the system's configurations (concurrent executions)
that act as cliff-edges, i.e. any maximal extension for those configurations
lies in some basin that is considered fatal. The computation turns out to
require only a relatively small prefix of the unfolding, just twice the depth
of Esparza's complete prefix.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10453'>Quasipolynomial-time algorithms for repulsive Gibbs point processes</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Matthew Jenssen, Marcus Michelen, Mohan Ravichandran</p><p>We demonstrate a quasipolynomial-time deterministic approximation algorithm
for the partition function of a Gibbs point process interacting via a repulsive
potential. This result holds for all activities $\lambda$ for which the
partition function satisfies a zero-free assumption in a neighborhood of the
interval $[0,\lambda]$. As a corollary, we obtain a quasipolynomial-time
deterministic approximation algorithm for all $\lambda &lt; e/\Delta_\phi$, where
$\Delta_\phi$ is the potential-weighted connective constant of the potential
$\phi$. Our algorithm approximates coefficients of the cluster expansion of the
partition function and uses the interpolation method of Barvinok to extend this
approximation throughout the zero-free region.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jenssen_M/0/1/0/all/0/1">Matthew Jenssen</a>, <a href="http://arxiv.org/find/cs/1/au:+Michelen_M/0/1/0/all/0/1">Marcus Michelen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravichandran_M/0/1/0/all/0/1">Mohan Ravichandran</a></p><p>We demonstrate a quasipolynomial-time deterministic approximation algorithm
for the partition function of a Gibbs point process interacting via a repulsive
potential. This result holds for all activities $\lambda$ for which the
partition function satisfies a zero-free assumption in a neighborhood of the
interval $[0,\lambda]$. As a corollary, we obtain a quasipolynomial-time
deterministic approximation algorithm for all $\lambda &lt; e/\Delta_\phi$, where
$\Delta_\phi$ is the potential-weighted connective constant of the potential
$\phi$. Our algorithm approximates coefficients of the cluster expansion of the
partition function and uses the interpolation method of Barvinok to extend this
approximation throughout the zero-free region.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10539'>Chaining, Group Leverage Score Overestimates, and Fast Spectral Hypergraph Sparsification</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Arun Jambulapati, Yang P. Liu, Aaron Sidford</p><p>We present an algorithm that given any $n$-vertex, $m$-edge, rank $r$
hypergraph constructs a spectral sparsifier with $O(n \varepsilon^{-2} \log n
\log r)$ hyperedges in nearly-linear $\widetilde{O}(mr)$ time. This improves in
both size and efficiency over a line of work (Bansal-Svensson-Trevisan 2019,
Kapralov-Krauthgamer-Tardos-Yoshida 2021) for which the previous best size was
$O(\min\{n \varepsilon^{-4} \log^3 n,nr^3 \varepsilon^{-2} \log n\})$ and
runtime was $\widetilde{O}(mr + n^{O(1)})$.
</p>
<p>Independent Result: In an independent work, Lee (Lee 2022) also shows how to
compute a spectral hypergraph sparsifier with $O(n \varepsilon^{-2} \log n \log
r)$ hyperedges.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jambulapati_A/0/1/0/all/0/1">Arun Jambulapati</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang P. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidford_A/0/1/0/all/0/1">Aaron Sidford</a></p><p>We present an algorithm that given any $n$-vertex, $m$-edge, rank $r$
hypergraph constructs a spectral sparsifier with $O(n \varepsilon^{-2} \log n
\log r)$ hyperedges in nearly-linear $\widetilde{O}(mr)$ time. This improves in
both size and efficiency over a line of work (Bansal-Svensson-Trevisan 2019,
Kapralov-Krauthgamer-Tardos-Yoshida 2021) for which the previous best size was
$O(\min\{n \varepsilon^{-4} \log^3 n,nr^3 \varepsilon^{-2} \log n\})$ and
runtime was $\widetilde{O}(mr + n^{O(1)})$.
</p>
<p>Independent Result: In an independent work, Lee (Lee 2022) also shows how to
compute a spectral hypergraph sparsifier with $O(n \varepsilon^{-2} \log n \log
r)$ hyperedges.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-22T00:30:00Z">Thursday, September 22 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Wednesday, September 21
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://blog.computationalcomplexity.org/2022/09/posted-updated-version-of-computers-and.html'>POSTED UPDATED VERSION OF   Computers and Intractability: A guide to Algorithmic Lower Bounds posted (New title)</a></h3>
          <p class='item-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>We have posted a revised version of&nbsp;</p><p><br></p><p>Computational Intractability: A Guide to Algorithmic Lower Bounds</p><p>by Demaine-Gasarch-Hajiaghayi</p><p>The book is&nbsp;here.</p><p>(For the original post about it, edited it to use the new title (see below), see&nbsp;HERE.)&nbsp;</p><p><br></p><p>We&nbsp; changed the title&nbsp;(the title above is the new one)&nbsp;</p><p>since the earlier title looked too much</p><p>like the title of Garey's and Johnson's classic. While that was intentional we&nbsp;</p><p>later felt that it was too close&nbsp;to their title and might cause confusion.&nbsp;</p><p>Of course changing the title might also cause confusion; however,&nbsp;</p><p>this post (and we will email various people as well) will stem that confusion.&nbsp;</p><p><br></p><p>We welcome corrections, suggestions and comments on the book. Email us at&nbsp;hardness-book@mit.edu</p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>We have posted a revised version of&nbsp;</p><p><br /></p><p><i>Computational Intractability: A Guide to Algorithmic Lower Bounds</i></p><p>by Demaine-Gasarch-Hajiaghayi</p><p>The book is&nbsp;<a href="https://hardness.mit.edu/">here</a>.</p><p>(For the original post about it, edited it to use the new title (see below), see&nbsp;<a href="https://blog.computationalcomplexity.org/2022/08/computers-and-intractability-guide-to.html">HERE</a>.)&nbsp;</p><p><br /></p><p>We&nbsp; <i>changed the title</i>&nbsp;(the title above is the new one)&nbsp;</p><p>since the earlier title looked <i>too much</i></p><p>like the title of Garey's and Johnson's classic. While that was intentional we&nbsp;</p><p>later felt that it was <i>too close</i>&nbsp;to their title and might cause confusion.&nbsp;</p><p>Of course changing the title might <i>also</i> cause confusion; however,&nbsp;</p><p>this post (and we will email various people as well) will stem that confusion.&nbsp;</p><p><br /></p><p>We welcome corrections, suggestions and comments on the book. Email us at&nbsp;<a href="mailto:hardness-book@mit.edu">hardness-book@mit.edu</a></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T20:48:00Z">Wednesday, September 21 2022, 20:48</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://11011110.github.io/blog/2022/09/21/counting-paths-convex.html'>Counting paths in convex polygons</a></h3>
          <p class='item-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Let’s count non-crossing paths through the all points of a convex polygon. There is a very simple formula for this, \(n2^{n-3}\) undirected paths through an \(n\)-gon, but why? Here’s a simple coloring-based argument that immediately gives this formula.
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Let’s count non-crossing paths through the all points of a convex polygon.
There is a very simple formula for this, \(n2^{n-3}\) undirected paths through an \(n\)-gon, but why? Here’s a simple coloring-based argument that immediately gives this formula.</p>

<p>Choose a coloring for the points of the polygon, red and blue, and choose a starting point for the path. Build a path, starting from this point, by the following rule: if you are at a red point, go to the next available point clockwise, and if you are at a blue point, go to the next available point counterclockwise.</p>

<p style="text-align:center"><img src="/blog/assets/2022/colored-ham.svg" alt="Generating a non-crossing path through all points of a convex polygon, by using a 2-coloring of the points to determing the direction of each step" /></p>

<p>There are \(n2^n\) choices of starting point and coloring, but each path is counted eight times, because the colors of the last two points on the path don’t make a difference to  where it goes, and because each path is also traced in the opposite direction using the other end as its starting point. Dividing \(n2^n\) by eight gives the formula.</p>

<p>This same idea also works to count non-crossing paths that are allowed to skip some of the points of the polygon. Now, color each point red, blue, or yellow. Use the same rule for building a path, but ignore the yellow points: start on a red or blue point, and when searching for an available point only go to another red or blue point.</p>

<p style="text-align:center"><img src="/blog/assets/2022/colored-path.svg" alt="Generating a non-crossing path through some points of a convex polygon, by using a 3-coloring of the points to determing the direction of each step" /></p>

<p>There are \(3^n\) choices of coloring. They have different numbers of choices of starting point, but by cyclically permuting the colors you can group them into \(3^{n-1}\) triples of colorings that together have exactly \(2n\) available (non-yellow) starting points. Each path is counted eight times just like before, so this argument would seem to give the formula \(2n\cdot 3^{n-1} / 8\) for the number of paths. But it’s not quite right. For one thing, it’s not even an integer.</p>

<p>The problem is, what happens when you color all but one of the points yellow, and that one remaining point red or blue? You get a sequence of one point only: does that count as a path? If we count these as length-zero paths (as I would prefer), then they are undercounted, because they do not have two ends, and they only have one point whose coloring (red or blue) is irrelevant, rather than the usual two points. When we divide by eight we make their contribution too small. If we don’t count them (as <a href="http://oeis.org/A261064">OEIS tells me</a> was the definition used in a 2020 Bulgarian mathematics contest) then they are overcounted, because they contribute to the formula and shouldn’t.</p>

<p>Adjusting for these one-point paths gives two alternative formulas:</p>

\[\frac{n}{4}(3^{n-1}+3)\]

<p>if we are counting one-point zero-length paths, or</p>

\[\frac{n}{4}(3^{n-1}-1),\]

<p>the formula from OEIS, if we are not counting them.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/109039377346914779">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T17:32:00Z">Wednesday, September 21 2022, 17:32</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/09/21/postdoc-at-tu-eindhoven-university-of-amsterdam-leiden-university-cwi-apply-by-october-31-2022/'>postdoc at TU Eindhoven, University of Amsterdam, Leiden University, CWI  (apply by October 31, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The NETWORKS project is a collaboration of world-leading researchers from four institutions in The Netherlands: TU Eindhoven, University of Amsterdam, Leiden University and CWI. Research in NETWORKS focuses on stochastics and algorithmics for network problems. Would you like to become a postdoc in the NETWORKS project? Then we invite you to apply for one of [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The NETWORKS project is a collaboration of world-leading researchers from four institutions in The Netherlands: TU Eindhoven, University of Amsterdam, Leiden University and CWI. Research in NETWORKS focuses on stochastics and algorithmics for network problems. Would you like to become a postdoc in the NETWORKS project? Then we invite you to apply for one of these positions.</p>
<p>Website: <a href="https://www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND-">https://www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND-</a><br />
Email: info@thenetworkcenter.nl</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T15:20:55Z">Wednesday, September 21 2022, 15:20</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://tcsplus.wordpress.com/2022/09/21/tcs-talk-wednesday-september-28-joakim-blikstad-kth-stockholm/'>TCS+ talk: Wednesday, September 28 — Joakim Blikstad, KTH Stockholm</a></h3>
          <p class='item-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, September 28th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Joakim Blikstad from KTH Stockholm will speak about &#8220;Nearly Optimal Communication and Query Complexity of Bipartite Matching&#8221; (abstract below). You can reserve a spot as an individual or [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p></p>


<p>The next TCS+ talk will take place this coming Wednesday, September 28th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Joakim Blikstad</strong> from KTH Stockholm will speak about &#8220;<em>Nearly Optimal Communication and Query Complexity of Bipartite Matching</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote">
<p>Abstract: With a simple application of the cutting planes method, we settle the complexities of the bipartite maximum matching problem (BMM) up to poly-logarithmic factors in five models of computation: the two-party communication, AND query, OR query, XOR query, and quantum edge query models. Our results answer open problems that have been raised repeatedly since at least three decades ago [Hajnal, Maass, and Turan STOC&#8217;88; Ivanyos, Klauck, Lee, Santha, and de Wolf FSTTCS&#8217;12; Dobzinski, Nisan, and Oren STOC&#8217;14; Nisan SODA&#8217;21] and tighten the lower bounds shown by Beniamini and Nisan [STOC&#8217;21] and Zhang [ICALP&#8217;04]. Our communication protocols also work for some generalizations of BMM, such as maximum-cost bipartite b-matching and transshipment, using only Õ(|V|) bits of communications.</p>
<p>To appear in FOCS&#8217;22. Joint work with Jan van den Brand, Yuval Efron, Danupon Nanongkai, and Sagnik Mukhopadhyay. preprint: <a href="https://arxiv.org/abs/2208.02526">https://arxiv.org/abs/2208.02526</a></p>
</blockquote><p class="authors">By plustcs</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T13:25:44Z">Wednesday, September 21 2022, 13:25</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/09/21/teaching-professor-at-uc-san-diego-apply-by-october-15-2022/'>Teaching professor at UC San Diego (apply by October 15, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          UC San Diego Computer Science department seeks applications for an Assistant Teaching Professor. Teaching Professors are full members of the academic senate and are eligible for Security of Employment, analogous to tenure. Teaching Professors have an increased emphasis on teaching, while maintaining an active program of research, in their research area and/or education. Website: apol-recruit.ucsd.edu/JPF03253 [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>UC San Diego Computer Science department seeks applications for an Assistant Teaching Professor. Teaching Professors are full members of the academic senate and are eligible for Security of Employment, analogous to tenure. Teaching Professors have an increased emphasis on teaching, while maintaining an active program of research, in their research area and/or education.</p>
<p>Website: <a href="https://apol-recruit.ucsd.edu/JPF03253">https://apol-recruit.ucsd.edu/JPF03253</a><br />
Email: shachar.lovett@gmail.com</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T06:20:52Z">Wednesday, September 21 2022, 06:20</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.09527'>Intrinsic Simulations and Universality in Automata Networks</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mart&#xed;n R&#xed;os-Wilson, Guillaume Theyssier (I2M)</p><p>An automata network (AN) is a finite graph where each node holds a state from
a finite alphabet and is equipped with a local map defining the evolution of
the state of the node depending on its neighbors. They are studied both from
the dynamical and the computational complexity point of view. Inspired from
well-established notions in the context of cellular automata, we develop a
theory of intrinsic simulations and universality for families of automata
networks. We establish many consequences of intrinsic universality in terms of
complexity of orbits (periods of attractors, transients, etc) as well as
hardness of the standard well-studied decision problems for automata networks
(short/long term prediction, reachability, etc). In the way, we prove
orthogonality results for these problems: the hardness of a single one does not
imply hardness of the others, while intrinsic universality implies hardness of
all of them. As a complement, we develop a proof technique to establish
intrinsic simulation and universality results which is suitable to deal with
families of symmetric networks were connections are non-oriented. It is based
on an operation of glueing of networks, which allows to produce complex orbits
in large networks from compatible pseudo-orbits in small networks. As an
illustration, we give a short proof that the family of networks were each node
obeys the rule of the 'game of life' cellular automaton is strongly universal.
This formalism and proof technique is also applied in a companion paper devoted
to studying the effect of update schedules on intrinsic universality for
concrete symmetric families of automata networks.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rios_Wilson_M/0/1/0/all/0/1">Mart&#xed;n R&#xed;os-Wilson</a>, <a href="http://arxiv.org/find/cs/1/au:+Theyssier_G/0/1/0/all/0/1">Guillaume Theyssier</a> (I2M)</p><p>An automata network (AN) is a finite graph where each node holds a state from
a finite alphabet and is equipped with a local map defining the evolution of
the state of the node depending on its neighbors. They are studied both from
the dynamical and the computational complexity point of view. Inspired from
well-established notions in the context of cellular automata, we develop a
theory of intrinsic simulations and universality for families of automata
networks. We establish many consequences of intrinsic universality in terms of
complexity of orbits (periods of attractors, transients, etc) as well as
hardness of the standard well-studied decision problems for automata networks
(short/long term prediction, reachability, etc). In the way, we prove
orthogonality results for these problems: the hardness of a single one does not
imply hardness of the others, while intrinsic universality implies hardness of
all of them. As a complement, we develop a proof technique to establish
intrinsic simulation and universality results which is suitable to deal with
families of symmetric networks were connections are non-oriented. It is based
on an operation of glueing of networks, which allows to produce complex orbits
in large networks from compatible pseudo-orbits in small networks. As an
illustration, we give a short proof that the family of networks were each node
obeys the rule of the 'game of life' cellular automaton is strongly universal.
This formalism and proof technique is also applied in a companion paper devoted
to studying the effect of update schedules on intrinsic universality for
concrete symmetric families of automata networks.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T00:30:00Z">Wednesday, September 21 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.09788'>VEST is W[2]-hard</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Michael Skotnica</p><p>In this short note, we show that the problem of VEST is $W[2]$-hard for
parameter $k$. This strengthens a result of Matou\v{s}ek, who showed
$W[1]$-hardness of that problem. The consequence of this result is that
computing the $k$-th homotopy group of a $d$-dimensional space for $d &gt; 3$ is
$W[2]$-hard for parameter $k$.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Skotnica_M/0/1/0/all/0/1">Michael Skotnica</a></p><p>In this short note, we show that the problem of VEST is $W[2]$-hard for
parameter $k$. This strengthens a result of Matou\v{s}ek, who showed
$W[1]$-hardness of that problem. The consequence of this result is that
computing the $k$-th homotopy group of a $d$-dimensional space for $d &gt; 3$ is
$W[2]$-hard for parameter $k$.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T00:30:00Z">Wednesday, September 21 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.09800'>A tight bound for the number of edges of matchstick graphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: J&#xe9;r&#xe9;my Lavoll&#xe9;e, Konrad Swanepoel</p><p>A matchstick graph is a plane graph with edges drawn as unit-distance line
segments. Harborth introduced these graphs in 1986 and conjectured that the
maximum number of edges for a matchstick graph on $n$ vertices is $\lfloor
3n-\sqrt{12n-3} \rfloor$. In this paper we prove this conjecture for all $n\geq
1$. The main geometric ingredient of the proof is an isoperimetric inequality
related to Lhuilier's inequality.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Lavollee_J/0/1/0/all/0/1">J&#xe9;r&#xe9;my Lavoll&#xe9;e</a>, <a href="http://arxiv.org/find/math/1/au:+Swanepoel_K/0/1/0/all/0/1">Konrad Swanepoel</a></p><p>A matchstick graph is a plane graph with edges drawn as unit-distance line
segments. Harborth introduced these graphs in 1986 and conjectured that the
maximum number of edges for a matchstick graph on $n$ vertices is $\lfloor
3n-\sqrt{12n-3} \rfloor$. In this paper we prove this conjecture for all $n\geq
1$. The main geometric ingredient of the proof is an isoperimetric inequality
related to Lhuilier's inequality.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T00:30:00Z">Wednesday, September 21 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.09313'>Natural Wave Numbers, Natural Wave Co-numbers, and the Computation of the Primes</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Terence R. Smith</p><p>The paper exploits an isomorphism between the natural numbers N and a space U
of periodic sequences of the roots of unity in constructing a recursive
procedure for representing and computing the prime numbers. The nth wave number
${\bf u}_n$ is the countable sequence of the nth roots of unity having
frequencies k/n for all integer phases k. The space U is closed under a
commutative and associative binary operation ${\bf u}_m \odot{\bf u}_n={\bf
u}_{mn}$, termed the circular product, and is isomorphic with N under their
respective product operators. Functions are defined on U that partition wave
numbers into two complementary sequences, of which the co-number $ {\overset
{\bf \ast }{ \bf u}}_n$ is a function of a wave number in which zeros replace
its positive roots of unity. The recursive procedure $ {\overset {\bf \ast }{
\bf U}}_{N+1}= {\overset {\bf \ast }{ \bf U}}_{N}\odot{\overset {\bf \ast }{\bf
u}}_{{N+1}}$ represents prime numbers explicitly in terms of preceding prime
numbers, starting with $p_1=2$, and is shown never to terminate. If ${p}_1, ...
, { p}_{N+1}$ are the first $N+1$ prime phases, then the phases in the range
$p_{N+1} \leq k &lt; p^2_{N+1}$ that are associated with the non-zero terms of $
{\overset {\bf \ast }{\bf U}}_{N}$ are, together with $ p_1, ...,p_N$, all of
the prime phases less than $p^2_{N+1}$. When applied with all of the primes
identified at the previous step, the recursive procedure identifies
approximately $7^{2(N-1)}/(2(N-1)ln7)$ primes at each iteration for $ N&gt;1$.
When the phases of wave numbers are represented in modular arithmetic, the
prime phases are representable in terms of sums of reciprocals of the initial
set of prime phases and have a relation with the zeta-function.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Smith_T/0/1/0/all/0/1">Terence R. Smith</a></p><p>The paper exploits an isomorphism between the natural numbers N and a space U
of periodic sequences of the roots of unity in constructing a recursive
procedure for representing and computing the prime numbers. The nth wave number
${\bf u}_n$ is the countable sequence of the nth roots of unity having
frequencies k/n for all integer phases k. The space U is closed under a
commutative and associative binary operation ${\bf u}_m \odot{\bf u}_n={\bf
u}_{mn}$, termed the circular product, and is isomorphic with N under their
respective product operators. Functions are defined on U that partition wave
numbers into two complementary sequences, of which the co-number $ {\overset
{\bf \ast }{ \bf u}}_n$ is a function of a wave number in which zeros replace
its positive roots of unity. The recursive procedure $ {\overset {\bf \ast }{
\bf U}}_{N+1}= {\overset {\bf \ast }{ \bf U}}_{N}\odot{\overset {\bf \ast }{\bf
u}}_{{N+1}}$ represents prime numbers explicitly in terms of preceding prime
numbers, starting with $p_1=2$, and is shown never to terminate. If ${p}_1, ...
, { p}_{N+1}$ are the first $N+1$ prime phases, then the phases in the range
$p_{N+1} \leq k &lt; p^2_{N+1}$ that are associated with the non-zero terms of $
{\overset {\bf \ast }{\bf U}}_{N}$ are, together with $ p_1, ...,p_N$, all of
the prime phases less than $p^2_{N+1}$. When applied with all of the primes
identified at the previous step, the recursive procedure identifies
approximately $7^{2(N-1)}/(2(N-1)ln7)$ primes at each iteration for $ N&gt;1$.
When the phases of wave numbers are represented in modular arithmetic, the
prime phases are representable in terms of sums of reciprocals of the initial
set of prime phases and have a relation with the zeta-function.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T00:30:00Z">Wednesday, September 21 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.09509'>Data structures for topologically sound higher-dimensional diagram rewriting</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Amar Hadzihasanovic, Diana Kessler</p><p>We present a computational implementation of diagrammatic sets, a model of
higher-dimensional diagram rewriting that is "topologically sound": diagrams
admit a functorial interpretation as homotopies in cell complexes. This has
potential applications both in the formalisation of higher algebra and category
theory and in computational algebraic topology. We describe data structures for
well-formed shapes of diagrams of arbitrary dimensions and provide a solution
to their isomorphism problem in time $O(n^3 \log n)$. On top of this, we define
a type theory for rewriting in diagrammatic sets and provide a semantic
characterisation of its syntactic category. All data structures and algorithms
are implemented in the Python library rewalt, which also supports various
visualisations of diagrams.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Hadzihasanovic_A/0/1/0/all/0/1">Amar Hadzihasanovic</a>, <a href="http://arxiv.org/find/math/1/au:+Kessler_D/0/1/0/all/0/1">Diana Kessler</a></p><p>We present a computational implementation of diagrammatic sets, a model of
higher-dimensional diagram rewriting that is "topologically sound": diagrams
admit a functorial interpretation as homotopies in cell complexes. This has
potential applications both in the formalisation of higher algebra and category
theory and in computational algebraic topology. We describe data structures for
well-formed shapes of diagrams of arbitrary dimensions and provide a solution
to their isomorphism problem in time $O(n^3 \log n)$. On top of this, we define
a type theory for rewriting in diagrammatic sets and provide a semantic
characterisation of its syntactic category. All data structures and algorithms
are implemented in the Python library rewalt, which also supports various
visualisations of diagrams.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T00:30:00Z">Wednesday, September 21 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.09661'>Exact Matching and the Top-k Perfect Matching Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Nicolas El Maalouly, Lasse Wulf</p><p>The aim of this note is to provide a reduction of the Exact Matching problem
to the Top-$k$ Perfect Matching Problem. Together with earlier work by El
Maalouly, this shows that the two problems are polynomial-time equivalent.
</p>
<p>The Exact Matching Problem is a well-known 40 years old problem for which a
randomized, but no deterministic poly-time algorithm has been discovered. The
Top-$k$ Perfect Matching Problem is the problem of finding a perfect matching
which maximizes the total weight of the $k$ heaviest edges contained in it.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Maalouly_N/0/1/0/all/0/1">Nicolas El Maalouly</a>, <a href="http://arxiv.org/find/cs/1/au:+Wulf_L/0/1/0/all/0/1">Lasse Wulf</a></p><p>The aim of this note is to provide a reduction of the Exact Matching problem
to the Top-$k$ Perfect Matching Problem. Together with earlier work by El
Maalouly, this shows that the two problems are polynomial-time equivalent.
</p>
<p>The Exact Matching Problem is a well-known 40 years old problem for which a
randomized, but no deterministic poly-time algorithm has been discovered. The
Top-$k$ Perfect Matching Problem is the problem of finding a perfect matching
which maximizes the total weight of the $k$ heaviest edges contained in it.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T00:30:00Z">Wednesday, September 21 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.09668'>Maximizing a Submodular Function with Bounded Curvature under an Unknown Knapsack Constraint</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Max Klimm, Martin Knaack</p><p>This paper studies the problem of maximizing a monotone submodular function
under an unknown knapsack constraint. A solution to this problem is a policy
that decides which item to pack next based on the past packing history. The
robustness factor of a policy is the worst case ratio of the solution obtained
by following the policy and an optimal solution that knows the knapsack
capacity. We develop an algorithm with a robustness factor that is decreasing
in the curvature $B$ of the submodular function. For the extreme cases $c=0$
corresponding to a modular objective, it matches a previously known and best
possible robustness factor of $1/2$. For the other extreme case of $c=1$ it
yields a robustness factor of $\approx 0.35$ improving over the best previously
known robustness factor of $\approx 0.06$.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Klimm_M/0/1/0/all/0/1">Max Klimm</a>, <a href="http://arxiv.org/find/cs/1/au:+Knaack_M/0/1/0/all/0/1">Martin Knaack</a></p><p>This paper studies the problem of maximizing a monotone submodular function
under an unknown knapsack constraint. A solution to this problem is a policy
that decides which item to pack next based on the past packing history. The
robustness factor of a policy is the worst case ratio of the solution obtained
by following the policy and an optimal solution that knows the knapsack
capacity. We develop an algorithm with a robustness factor that is decreasing
in the curvature $B$ of the submodular function. For the extreme cases $c=0$
corresponding to a modular objective, it matches a previously known and best
possible robustness factor of $1/2$. For the other extreme case of $c=1$ it
yields a robustness factor of $\approx 0.35$ improving over the best previously
known robustness factor of $\approx 0.06$.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T00:30:00Z">Wednesday, September 21 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.09711'>Development of a Parallel BAT and Its Applications in Binary-state Network Reliability Problems</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Wei-Chang Yeh</p><p>Various networks are broadly and deeply applied in real-life applications.
Reliability is the most important index for measuring the performance of all
network types. Among the various algorithms, only implicit enumeration
algorithms, such as depth-first-search, breadth-search-first, universal
generating function methodology, binary-decision diagram, and
binary-addition-tree algorithm (BAT), can be used to calculate the exact
network reliability. However, implicit enumeration algorithms can only be used
to solve small-scale network reliability problems. The BAT was recently
proposed as a simple, fast, easy-to-code, and flexible make-to-fit
exact-solution algorithm. Based on the experimental results, the BAT and its
variants outperformed other implicit enumeration algorithms. Hence, to overcome
the above-mentioned obstacle as a result of the size problem, a new parallel
BAT (PBAT) was proposed to improve the BAT based on compute multithread
architecture to calculate the binary-state network reliability problem, which
is fundamental for all types of network reliability problems. From the analysis
of the time complexity and experiments conducted on 20 benchmarks of
binary-state network reliability problems, PBAT was able to efficiently solve
medium-scale network reliability problems.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yeh_W/0/1/0/all/0/1">Wei-Chang Yeh</a></p><p>Various networks are broadly and deeply applied in real-life applications.
Reliability is the most important index for measuring the performance of all
network types. Among the various algorithms, only implicit enumeration
algorithms, such as depth-first-search, breadth-search-first, universal
generating function methodology, binary-decision diagram, and
binary-addition-tree algorithm (BAT), can be used to calculate the exact
network reliability. However, implicit enumeration algorithms can only be used
to solve small-scale network reliability problems. The BAT was recently
proposed as a simple, fast, easy-to-code, and flexible make-to-fit
exact-solution algorithm. Based on the experimental results, the BAT and its
variants outperformed other implicit enumeration algorithms. Hence, to overcome
the above-mentioned obstacle as a result of the size problem, a new parallel
BAT (PBAT) was proposed to improve the BAT based on compute multithread
architecture to calculate the binary-state network reliability problem, which
is fundamental for all types of network reliability problems. From the analysis
of the time complexity and experiments conducted on 20 benchmarks of
binary-state network reliability problems, PBAT was able to efficiently solve
medium-scale network reliability problems.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T00:30:00Z">Wednesday, September 21 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.09888'>Modeling the Small-World Phenomenon with Road Networks</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Michael T. Goodrich, Evrim Ozel</p><p>Dating back to two famous experiments by the social-psychologist, Stanley
Milgram, in the 1960s, the small-world phenomenon is the idea that all people
are connected through a short chain of acquaintances that can be used to route
messages. Many subsequent papers have attempted to model this phenomenon, with
most concentrating on the "short chain" of acquaintances rather than their
ability to efficiently route messages. In this paper, we study the small-world
navigability of the U.S. road network, with the goal of providing a model that
explains how messages in the original small-world experiments could be routed
along short paths using U.S. roads. To this end, we introduce the Neighborhood
Preferential Attachment model, which combines elements from Kleinberg's model
and the Barab\'asi-Albert model, such that long-range links are chosen
according to both the degrees and (road-network) distances of vertices in the
network. We empirically evaluate all three models by running a decentralized
routing algorithm, where each vertex only has knowledge of its own neighbors,
and find that our model outperforms both of these models in terms of the
average hop length. Moreover, our experiments indicate that similar to the
Barab\'asi-Albert model, networks generated by our model are scale-free, which
could be a more realistic representation of acquaintanceship links in the
original small-world experiment.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goodrich_M/0/1/0/all/0/1">Michael T. Goodrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozel_E/0/1/0/all/0/1">Evrim Ozel</a></p><p>Dating back to two famous experiments by the social-psychologist, Stanley
Milgram, in the 1960s, the small-world phenomenon is the idea that all people
are connected through a short chain of acquaintances that can be used to route
messages. Many subsequent papers have attempted to model this phenomenon, with
most concentrating on the "short chain" of acquaintances rather than their
ability to efficiently route messages. In this paper, we study the small-world
navigability of the U.S. road network, with the goal of providing a model that
explains how messages in the original small-world experiments could be routed
along short paths using U.S. roads. To this end, we introduce the Neighborhood
Preferential Attachment model, which combines elements from Kleinberg's model
and the Barab\'asi-Albert model, such that long-range links are chosen
according to both the degrees and (road-network) distances of vertices in the
network. We empirically evaluate all three models by running a decentralized
routing algorithm, where each vertex only has knowledge of its own neighbors,
and find that our model outperforms both of these models in terms of the
average hop length. Moreover, our experiments indicate that similar to the
Barab\'asi-Albert model, networks generated by our model are scale-free, which
could be a more realistic representation of acquaintanceship links in the
original small-world experiment.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T00:30:00Z">Wednesday, September 21 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.09896'>On the Correlation Gap of Matroids</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Edin Husi&#x107;, Zhuan Khye Koh, Georg Loho, L&#xe1;szl&#xf3; A. V&#xe9;gh</p><p>A set function can be extended to the unit cube in various ways; the
correlation gap measures the ratio between two natural extensions. This
quantity has been identified as the performance guarantee in a range of
approximation algorithms and mechanism design settings. It is known that the
correlation gap of a monotone submodular function is $1-1/e$, and this is tight
even for simple matroid rank functions.
</p>
<p>We initiate a fine-grained study of correlation gaps of matroid rank
functions. In particular, we present improved lower bounds on the correlation
gap as parametrized by the rank and the girth of the matroid. We also show that
the worst correlation gap of a weighted matroid rank function is achieved under
uniform weights. Such improved lower bounds have direct applications for
submodular maximization under matroid constraints, mechanism design, and
contention resolution schemes. Previous work relied on implicit correlation gap
bounds for problems such as list decoding and approval voting.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Husic_E/0/1/0/all/0/1">Edin Husi&#x107;</a>, <a href="http://arxiv.org/find/math/1/au:+Koh_Z/0/1/0/all/0/1">Zhuan Khye Koh</a>, <a href="http://arxiv.org/find/math/1/au:+Loho_G/0/1/0/all/0/1">Georg Loho</a>, <a href="http://arxiv.org/find/math/1/au:+Vegh_L/0/1/0/all/0/1">L&#xe1;szl&#xf3; A. V&#xe9;gh</a></p><p>A set function can be extended to the unit cube in various ways; the
correlation gap measures the ratio between two natural extensions. This
quantity has been identified as the performance guarantee in a range of
approximation algorithms and mechanism design settings. It is known that the
correlation gap of a monotone submodular function is $1-1/e$, and this is tight
even for simple matroid rank functions.
</p>
<p>We initiate a fine-grained study of correlation gaps of matroid rank
functions. In particular, we present improved lower bounds on the correlation
gap as parametrized by the rank and the girth of the matroid. We also show that
the worst correlation gap of a weighted matroid rank function is achieved under
uniform weights. Such improved lower bounds have direct applications for
submodular maximization under matroid constraints, mechanism design, and
contention resolution schemes. Previous work relied on implicit correlation gap
bounds for problems such as list decoding and approval voting.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-21T00:30:00Z">Wednesday, September 21 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Tuesday, September 20
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://eccc.weizmann.ac.il/report/2022/133'>TR22-133 |  Downward Self-Reducibility in TFNP | 

	Prahladh Harsha, 

	Daniel Mitropolsky, 

	Alon Rosen</a></h3>
          <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          A problem is downward self-reducible if it can be solved efficiently given an oracle that returns
solutions for strictly smaller instances. In the decisional landscape, downward self-reducibility is
well studied and it is known that all downward self-reducible problems are in PSPACE. In this
paper, we initiate the study of downward self-reducible search problems which are guaranteed to
have a solution — that is, the downward self-reducible problems in TFNP. We show that most
natural PLS-complete problems are downward self-reducible and any downward self-reducible
problem in TFNP is contained in PLS. Furthermore, if the downward self-reducible problem
is in UTFNP (i.e. it has a unique solution), then it is actually contained in CLS. This implies
that if integer factoring is downward self-reducible then it is in fact in CLS, suggesting that no
efficient factoring algorithm exists using the factorization of smaller numbers.
        
        </div>

        <div class='item-content item-summary'>
        
          
          A problem is downward self-reducible if it can be solved efficiently given an oracle that returns
solutions for strictly smaller instances. In the decisional landscape, downward self-reducibility is
well studied and it is known that all downward self-reducible problems are in PSPACE. In this
paper, we initiate the study of downward self-reducible search problems which are guaranteed to
have a solution — that is, the downward self-reducible problems in TFNP. We show that most
natural PLS-complete problems are downward self-reducible and any downward self-reducible
problem in TFNP is contained in PLS. Furthermore, if the downward self-reducible problem
is in UTFNP (i.e. it has a unique solution), then it is actually contained in CLS. This implies
that if integer factoring is downward self-reducible then it is in fact in CLS, suggesting that no
efficient factoring algorithm exists using the factorization of smaller numbers.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-20T18:28:17Z">Tuesday, September 20 2022, 18:28</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.08219'>Better Hardness Results for the Minimum Spanning Tree Congestion Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Huong Luu, Marek Chrobak</p><p>In the spanning tree congestion problem, given a connected graph $G$, the
objective is to compute a spanning tree $T$ in $G$ for which the maximum edge
congestion is minimized, where the congestion of an edge $e$ of $T$ is the
number of vertex pairs adjacent in $G$ for which the path connecting them in
$T$ traverses $e$. The problem is known to be NP-hard, but its approximability
is still poorly understood, and it is not even known whether the optimum can be
efficiently approximated with ratio $o(n)$. In the decision version of this
problem, denoted STC-$K$, we need to determine if $G$ has a spanning tree with
congestion at most $K$. It is known that STC-$K$ is NP-complete for $K\ge 8$,
and this implies a lower bound of $1.125$ on the approximation ratio of
minimizing congestion. On the other hand, $3$-STC can be solved in polynomial
time, with the complexity status of this problem for $K\in \{4,5,6,7\}$
remaining an open problem. We substantially improve the earlier hardness result
by proving that STC-$K$ is NP-complete for $K\ge 5$. This leaves only the case
$K=4$ open, and improves the lower bound on the approximation ratio to $1.2$.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Luu_H/0/1/0/all/0/1">Huong Luu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chrobak_M/0/1/0/all/0/1">Marek Chrobak</a></p><p>In the spanning tree congestion problem, given a connected graph $G$, the
objective is to compute a spanning tree $T$ in $G$ for which the maximum edge
congestion is minimized, where the congestion of an edge $e$ of $T$ is the
number of vertex pairs adjacent in $G$ for which the path connecting them in
$T$ traverses $e$. The problem is known to be NP-hard, but its approximability
is still poorly understood, and it is not even known whether the optimum can be
efficiently approximated with ratio $o(n)$. In the decision version of this
problem, denoted STC-$K$, we need to determine if $G$ has a spanning tree with
congestion at most $K$. It is known that STC-$K$ is NP-complete for $K\ge 8$,
and this implies a lower bound of $1.125$ on the approximation ratio of
minimizing congestion. On the other hand, $3$-STC can be solved in polynomial
time, with the complexity status of this problem for $K\in \{4,5,6,7\}$
remaining an open problem. We substantially improve the earlier hardness result
by proving that STC-$K$ is NP-complete for $K\ge 5$. This leaves only the case
$K=4$ open, and improves the lower bound on the approximation ratio to $1.2$.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-20T00:30:00Z">Tuesday, September 20 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.08688'>On Relaxed Locally Decodable Codes for Hamming and Insertion-Deletion Errors</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Alex Block, Jeremiah Blocki, Kuan Cheng, Elena Grigorescu, Xin Li, Yu Zheng, Minshen Zhu</p><p>Locally Decodable Codes (LDCs) are error-correcting codes
$C:\Sigma^n\rightarrow \Sigma^m$ with super-fast decoding algorithms. They are
important mathematical objects in many areas of theoretical computer science,
yet the best constructions so far have codeword length $m$ that is
super-polynomial in $n$, for codes with constant query complexity and constant
alphabet size. In a very surprising result, Ben-Sasson et al. showed how to
construct a relaxed version of LDCs (RLDCs) with constant query complexity and
almost linear codeword length over the binary alphabet, and used them to obtain
significantly-improved constructions of Probabilistically Checkable Proofs. In
this work, we study RLDCs in the standard Hamming-error setting, and introduce
their variants in the insertion and deletion (Insdel) error setting. Insdel
LDCs were first studied by Ostrovsky and Paskin-Cherniavsky, and are further
motivated by recent advances in DNA random access bio-technologies, in which
the goal is to retrieve individual files from a DNA storage database. Our first
result is an exponential lower bound on the length of Hamming RLDCs making 2
queries, over the binary alphabet. This answers a question explicitly raised by
Gur and Lachish. Our result exhibits a "phase-transition"-type behavior on the
codeword length for constant-query Hamming RLDCs. We further define two
variants of RLDCs in the Insdel-error setting, a weak and a strong version. On
the one hand, we construct weak Insdel RLDCs with with parameters matching
those of the Hamming variants. On the other hand, we prove exponential lower
bounds for strong Insdel RLDCs. These results demonstrate that, while these
variants are equivalent in the Hamming setting, they are significantly
different in the insdel setting. Our results also prove a strict separation
between Hamming RLDCs and Insdel RLDCs.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Block_A/0/1/0/all/0/1">Alex Block</a>, <a href="http://arxiv.org/find/cs/1/au:+Blocki_J/0/1/0/all/0/1">Jeremiah Blocki</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1">Kuan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Grigorescu_E/0/1/0/all/0/1">Elena Grigorescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Minshen Zhu</a></p><p>Locally Decodable Codes (LDCs) are error-correcting codes
$C:\Sigma^n\rightarrow \Sigma^m$ with super-fast decoding algorithms. They are
important mathematical objects in many areas of theoretical computer science,
yet the best constructions so far have codeword length $m$ that is
super-polynomial in $n$, for codes with constant query complexity and constant
alphabet size. In a very surprising result, Ben-Sasson et al. showed how to
construct a relaxed version of LDCs (RLDCs) with constant query complexity and
almost linear codeword length over the binary alphabet, and used them to obtain
significantly-improved constructions of Probabilistically Checkable Proofs. In
this work, we study RLDCs in the standard Hamming-error setting, and introduce
their variants in the insertion and deletion (Insdel) error setting. Insdel
LDCs were first studied by Ostrovsky and Paskin-Cherniavsky, and are further
motivated by recent advances in DNA random access bio-technologies, in which
the goal is to retrieve individual files from a DNA storage database. Our first
result is an exponential lower bound on the length of Hamming RLDCs making 2
queries, over the binary alphabet. This answers a question explicitly raised by
Gur and Lachish. Our result exhibits a "phase-transition"-type behavior on the
codeword length for constant-query Hamming RLDCs. We further define two
variants of RLDCs in the Insdel-error setting, a weak and a strong version. On
the one hand, we construct weak Insdel RLDCs with with parameters matching
those of the Hamming variants. On the other hand, we prove exponential lower
bounds for strong Insdel RLDCs. These results demonstrate that, while these
variants are equivalent in the Hamming setting, they are significantly
different in the insdel setting. Our results also prove a strict separation
between Hamming RLDCs and Insdel RLDCs.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-20T00:30:00Z">Tuesday, September 20 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.08114'>Asymptotically Optimal Bounds for Estimating H-Index in Sublinear Time with Applications to Subgraph Counting</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Sepehr Assadi, Hoai-An Nguyen</p><p>The $h$-index is a metric used to measure the impact of a user in a
publication setting, such as a member of a social network with many highly
liked posts or a researcher in an academic domain with many highly cited
publications. Specifically, the $h$-index of a user is the largest integer $h$
such that at least $h$ publications of the user have at least $h$ units of
positive feedback.
</p>
<p>We design an algorithm that, given query access to the $n$ publications of a
user and each publication's corresponding positive feedback number, outputs a
$(1\pm \varepsilon)$-approximation of the $h$-index of this user with
probability at least $1-\delta$ in time \[
</p>
<p>O(\frac{n \cdot \ln{(1/\delta)}}{\varepsilon^2 \cdot h}),
</p>
<p>\] where $h$ is the actual $h$-index which is unknown to the algorithm
a-priori. We then design a novel lower bound technique that allows us to prove
that this bound is in fact asymptotically optimal for this problem in all
parameters $n,h,\varepsilon,$ and $\delta$.
</p>
<p>Our work is one of the first in sublinear time algorithms that addresses
obtaining asymptotically optimal bounds, especially in terms of the error and
confidence parameters. As such, we focus on designing novel techniques for this
task. In particular, our lower bound technique seems quite general -- to
showcase this, we also use our approach to prove an asymptotically optimal
lower bound for the problem of estimating the number of triangles in a graph in
sublinear time, which now is also optimal in the error and confidence
parameters. This result improves upon prior lower bounds of Eden, Levi, Ron,
and Seshadhri (FOCS'15) for this problem, as well as multiple follow-ups that
extended this lower bound to other subgraph counting problems.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Assadi_S/0/1/0/all/0/1">Sepehr Assadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Hoai-An Nguyen</a></p><p>The $h$-index is a metric used to measure the impact of a user in a
publication setting, such as a member of a social network with many highly
liked posts or a researcher in an academic domain with many highly cited
publications. Specifically, the $h$-index of a user is the largest integer $h$
such that at least $h$ publications of the user have at least $h$ units of
positive feedback.
</p>
<p>We design an algorithm that, given query access to the $n$ publications of a
user and each publication's corresponding positive feedback number, outputs a
$(1\pm \varepsilon)$-approximation of the $h$-index of this user with
probability at least $1-\delta$ in time \[
</p>
<p>O(\frac{n \cdot \ln{(1/\delta)}}{\varepsilon^2 \cdot h}),
</p>
<p>\] where $h$ is the actual $h$-index which is unknown to the algorithm
a-priori. We then design a novel lower bound technique that allows us to prove
that this bound is in fact asymptotically optimal for this problem in all
parameters $n,h,\varepsilon,$ and $\delta$.
</p>
<p>Our work is one of the first in sublinear time algorithms that addresses
obtaining asymptotically optimal bounds, especially in terms of the error and
confidence parameters. As such, we focus on designing novel techniques for this
task. In particular, our lower bound technique seems quite general -- to
showcase this, we also use our approach to prove an asymptotically optimal
lower bound for the problem of estimating the number of triangles in a graph in
sublinear time, which now is also optimal in the error and confidence
parameters. This result improves upon prior lower bounds of Eden, Levi, Ron,
and Seshadhri (FOCS'15) for this problem, as well as multiple follow-ups that
extended this lower bound to other subgraph counting problems.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-20T00:30:00Z">Tuesday, September 20 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.08166'>The trace reconstruction problem for spider graphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Alec Sun, William Yue</p><p>We study the trace reconstruction problem for spider graphs. Let $n$ be the
number of nodes of a spider and $d$ be the length of each leg, and suppose that
we are given independent traces of the spider from a deletion channel in which
each non-root node is deleted with probability $q$. This is a natural
generalization of the string trace reconstruction problem in theoretical
computer science, which corresponds to the special case where the spider has
one leg. In the regime where $d\ge \log_{1/q}(n)$, the problem can be reduced
to the vanilla string trace reconstruction problem. We thus study the more
interesting regime $d\le \log_{1/q}(n)$, in which entire legs of the spider are
deleted with non-negligible probability. We describe an algorithm that
reconstructs spiders with high probability using
$\exp\left(\mathcal{O}\left(\frac{(nq^d)^{1/3}}{d^{1/3}}(\log
n)^{2/3}\right)\right)$ traces. Our algorithm works for all deletion
probabilities $q\in(0,1)$.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sun_A/0/1/0/all/0/1">Alec Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_W/0/1/0/all/0/1">William Yue</a></p><p>We study the trace reconstruction problem for spider graphs. Let $n$ be the
number of nodes of a spider and $d$ be the length of each leg, and suppose that
we are given independent traces of the spider from a deletion channel in which
each non-root node is deleted with probability $q$. This is a natural
generalization of the string trace reconstruction problem in theoretical
computer science, which corresponds to the special case where the spider has
one leg. In the regime where $d\ge \log_{1/q}(n)$, the problem can be reduced
to the vanilla string trace reconstruction problem. We thus study the more
interesting regime $d\le \log_{1/q}(n)$, in which entire legs of the spider are
deleted with non-negligible probability. We describe an algorithm that
reconstructs spiders with high probability using
$\exp\left(\mathcal{O}\left(\frac{(nq^d)^{1/3}}{d^{1/3}}(\log
n)^{2/3}\right)\right)$ traces. Our algorithm works for all deletion
probabilities $q\in(0,1)$.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-20T00:30:00Z">Tuesday, September 20 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.08281'>Improved Generalization Bound and Learning of Sparsity Patterns for Data-Driven Low-Rank Approximation</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Shinsaku Sakaue, Taihei Oki</p><p>Learning sketching matrices for fast and accurate low-rank approximation
(LRA) has gained increasing attention. Recently, Bartlett, Indyk, and Wagner
(COLT 2022) presented a generalization bound for the learning-based LRA.
Specifically, for rank-$k$ approximation using an $m \times n$ learned
sketching matrix with $s$ non-zeros in each column, they proved an
$\tilde{\mathrm{O}}(nsm)$ bound on the \emph{fat shattering dimension}
($\tilde{\mathrm{O}}$ hides logarithmic factors). We build on their work and
make two contributions.
</p>
<p>1. We present a better $\tilde{\mathrm{O}}(nsk)$ bound ($k \le m$). En route
to obtaining the bound, we give a low-complexity \emph{Goldberg--Jerrum
algorithm} for computing pseudo-inverse matrices, which would be of independent
interest.
</p>
<p>2. We alleviate an assumption of the previous study that the sparsity pattern
of sketching matrices is fixed. We prove that learning positions of non-zeros
increases the fat shattering dimension only by ${\mathrm{O}}(ns\log n)$. Also,
experiments confirm the practical benefit of learning sparsity patterns.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sakaue_S/0/1/0/all/0/1">Shinsaku Sakaue</a>, <a href="http://arxiv.org/find/cs/1/au:+Oki_T/0/1/0/all/0/1">Taihei Oki</a></p><p>Learning sketching matrices for fast and accurate low-rank approximation
(LRA) has gained increasing attention. Recently, Bartlett, Indyk, and Wagner
(COLT 2022) presented a generalization bound for the learning-based LRA.
Specifically, for rank-$k$ approximation using an $m \times n$ learned
sketching matrix with $s$ non-zeros in each column, they proved an
$\tilde{\mathrm{O}}(nsm)$ bound on the \emph{fat shattering dimension}
($\tilde{\mathrm{O}}$ hides logarithmic factors). We build on their work and
make two contributions.
</p>
<p>1. We present a better $\tilde{\mathrm{O}}(nsk)$ bound ($k \le m$). En route
to obtaining the bound, we give a low-complexity \emph{Goldberg--Jerrum
algorithm} for computing pseudo-inverse matrices, which would be of independent
interest.
</p>
<p>2. We alleviate an assumption of the previous study that the sparsity pattern
of sketching matrices is fixed. We prove that learning positions of non-zeros
increases the fat shattering dimension only by ${\mathrm{O}}(ns\log n)$. Also,
experiments confirm the practical benefit of learning sparsity patterns.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-20T00:30:00Z">Tuesday, September 20 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.08427'>A Nearly Tight Lower Bound for the $d$-Dimensional Cow-Path Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Nikhil Bansal, John Kuszmaul, William Kuszmaul</p><p>In the $d$-dimensional cow-path problem, a cow living in $\mathbb{R}^d$ must
locate a $(d - 1)$-dimensional hyperplane $H$ whose location is unknown. The
only way that the cow can find $H$ is to roam $\mathbb{R}^d$ until it
intersects $\mathcal{H}$. If the cow travels a total distance $s$ to locate a
hyperplane $H$ whose distance from the origin was $r \ge 1$, then the cow is
said to achieve competitive ratio $s / r$.
</p>
<p>It is a classic result that, in $\mathbb{R}^2$, the optimal (deterministic)
competitive ratio is $9$. In $\mathbb{R}^3$, the optimal competitive ratio is
known to be at most $\approx 13.811$. But in higher dimensions, the asymptotic
relationship between $d$ and the optimal competitive ratio remains an open
question. The best upper and lower bounds, due to Antoniadis et al., are
$O(d^{3/2})$ and $\Omega(d)$, leaving a gap of roughly $\sqrt{d}$. In this
note, we achieve a stronger lower bound of $\tilde{\Omega}(d^{3/2})$.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bansal_N/0/1/0/all/0/1">Nikhil Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuszmaul_J/0/1/0/all/0/1">John Kuszmaul</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuszmaul_W/0/1/0/all/0/1">William Kuszmaul</a></p><p>In the $d$-dimensional cow-path problem, a cow living in $\mathbb{R}^d$ must
locate a $(d - 1)$-dimensional hyperplane $H$ whose location is unknown. The
only way that the cow can find $H$ is to roam $\mathbb{R}^d$ until it
intersects $\mathcal{H}$. If the cow travels a total distance $s$ to locate a
hyperplane $H$ whose distance from the origin was $r \ge 1$, then the cow is
said to achieve competitive ratio $s / r$.
</p>
<p>It is a classic result that, in $\mathbb{R}^2$, the optimal (deterministic)
competitive ratio is $9$. In $\mathbb{R}^3$, the optimal competitive ratio is
known to be at most $\approx 13.811$. But in higher dimensions, the asymptotic
relationship between $d$ and the optimal competitive ratio remains an open
question. The best upper and lower bounds, due to Antoniadis et al., are
$O(d^{3/2})$ and $\Omega(d)$, leaving a gap of roughly $\sqrt{d}$. In this
note, we achieve a stronger lower bound of $\tilde{\Omega}(d^{3/2})$.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-20T00:30:00Z">Tuesday, September 20 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.08600'>GenPIP: In-Memory Acceleration of Genome Analysis via Tight Integration of Basecalling and Read Mapping</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Haiyu Mao, Mohammed Alser, Mohammad Sadrosadati, Can Firtina, Akanksha Baranwal, Damla Senol Cali, Aditya Manglik, Nour Almadhoun Alserr, Onur Mutlu</p><p>Nanopore sequencing is a widely-used high-throughput genome sequencing
technology that can sequence long fragments of a genome into raw electrical
signals at low cost. Nanopore sequencing requires two computationally-costly
processing steps for accurate downstream genome analysis. The first step,
basecalling, translates the raw electrical signals into nucleotide bases (i.e.,
A, C, G, T). The second step, read mapping, finds the correct location of a
read in a reference genome. In existing genome analysis pipelines, basecalling
and read mapping are executed separately. We observe in this work that such
separate execution of the two most time-consuming steps inherently leads to (1)
significant data movement and (2) redundant computations on the data, slowing
down the genome analysis pipeline. This paper proposes GenPIP, an in-memory
genome analysis accelerator that tightly integrates basecalling and read
mapping. GenPIP improves the performance of the genome analysis pipeline with
two key mechanisms: (1) in-memory fine-grained collaborative execution of the
major genome analysis steps in parallel; (2) a new technique for
early-rejection of low-quality and unmapped reads to timely stop the execution
of genome analysis for such reads, reducing inefficient computation. Our
experiments show that, for the execution of the genome analysis pipeline,
GenPIP provides 41.6X (8.4X) speedup and 32.8X (20.8X) energy savings with
negligible accuracy loss compared to the state-of-the-art software genome
analysis tools executed on a state-of-the-art CPU (GPU). Compared to a design
that combines state-of-the-art in-memory basecalling and read mapping
accelerators, GenPIP provides 1.39X speedup and 1.37X energy savings.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1">Haiyu Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Alser_M/0/1/0/all/0/1">Mohammed Alser</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadrosadati_M/0/1/0/all/0/1">Mohammad Sadrosadati</a>, <a href="http://arxiv.org/find/cs/1/au:+Firtina_C/0/1/0/all/0/1">Can Firtina</a>, <a href="http://arxiv.org/find/cs/1/au:+Baranwal_A/0/1/0/all/0/1">Akanksha Baranwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Cali_D/0/1/0/all/0/1">Damla Senol Cali</a>, <a href="http://arxiv.org/find/cs/1/au:+Manglik_A/0/1/0/all/0/1">Aditya Manglik</a>, <a href="http://arxiv.org/find/cs/1/au:+Alserr_N/0/1/0/all/0/1">Nour Almadhoun Alserr</a>, <a href="http://arxiv.org/find/cs/1/au:+Mutlu_O/0/1/0/all/0/1">Onur Mutlu</a></p><p>Nanopore sequencing is a widely-used high-throughput genome sequencing
technology that can sequence long fragments of a genome into raw electrical
signals at low cost. Nanopore sequencing requires two computationally-costly
processing steps for accurate downstream genome analysis. The first step,
basecalling, translates the raw electrical signals into nucleotide bases (i.e.,
A, C, G, T). The second step, read mapping, finds the correct location of a
read in a reference genome. In existing genome analysis pipelines, basecalling
and read mapping are executed separately. We observe in this work that such
separate execution of the two most time-consuming steps inherently leads to (1)
significant data movement and (2) redundant computations on the data, slowing
down the genome analysis pipeline. This paper proposes GenPIP, an in-memory
genome analysis accelerator that tightly integrates basecalling and read
mapping. GenPIP improves the performance of the genome analysis pipeline with
two key mechanisms: (1) in-memory fine-grained collaborative execution of the
major genome analysis steps in parallel; (2) a new technique for
early-rejection of low-quality and unmapped reads to timely stop the execution
of genome analysis for such reads, reducing inefficient computation. Our
experiments show that, for the execution of the genome analysis pipeline,
GenPIP provides 41.6X (8.4X) speedup and 32.8X (20.8X) energy savings with
negligible accuracy loss compared to the state-of-the-art software genome
analysis tools executed on a state-of-the-art CPU (GPU). Compared to a design
that combines state-of-the-art in-memory basecalling and read mapping
accelerators, GenPIP provides 1.39X speedup and 1.37X energy savings.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-20T00:30:00Z">Tuesday, September 20 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Monday, September 19
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://blog.computationalcomplexity.org/2022/09/there-are-two-different-definitions-of.html'>There are two different definitions of Integer Programming. Why?</a></h3>
          <p class='item-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Alice and Bob have the following conversation.</p><p>===============================</p><p>ALICE: In your book you define INT PROG as, given a matrix A and vectors b,c,</p><p>find the integer vector x such that Ax\le b and c DOT x is maximized.</p><p>This is not correct! You also need x\ge 0.</p><p><br></p><p>BOB: Really? I always heard it without that extra constraint, though I am</p><p>sure they are equivalent and both NP-complete (Alice nods).</p><p>Where did you see it defined with that extra constraint?</p><p><br></p><p>ALICE:</p><p>Wikipedia entry in IP<br></p><p>Chapter of a book at an MIT website<br></p><p>Something on Science Direct<br></p><p>A course at Duke<br></p><p>An article by Papadimitriou&nbsp;<br></p><p>An article on arxiv<br></p><p>The book&nbsp;Graphs, Networks and Algorithms by Dieter Jungnickel</p><p>Bob, do you have examples where they do not use that extra constraint.&nbsp;</p><p>BOB:&nbsp;</p><p>Math Works<br></p><p>Lecture notes from UIUC<br></p><p>Lecture notes from Lehigh Univ.<br></p><p>The book Parameterized Complexity Theory&nbsp;by Flum and Grohe</p><p>The book Computers and Intractability : A Guide to the Theory of NP-Completeness by Garey and Johnson</p><p>ALICE: Both of our lists are impressive. So now what?&nbsp;</p><p>--------------------------------------------------------------------</p><p>(This is Bill again.)</p><p>What indeed!</p><p>1) Why are there two definitions of Int Prog?</p><p>2) When is it good to use which one?&nbsp;</p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Alice and Bob have the following conversation.</p><p>===============================</p><p>ALICE: In your book you define INT PROG as, given a matrix A and vectors b,c,</p><p>find the integer vector x such that Ax\le b and c DOT x is maximized.</p><p>This is not correct! You also need x\ge 0.</p><p><br /></p><p>BOB: Really? I always heard it without that extra constraint, though I am</p><p>sure they are equivalent and both NP-complete (Alice nods).</p><p>Where did you see it defined with that extra constraint?</p><p><br /></p><p>ALICE:</p><p><a href="https://en.wikipedia.org/wiki/Integer_programming">Wikipedia entry in IP</a><br /></p><p><a href="https://web.mit.edu/15.053/www/AMP-Chapter-09.pdf">Chapter of a book at an MIT website</a><br /></p><p><a href="https://www.sciencedirect.com/topics/mathematics/integer-programming-problem">Something on Science Direct</a><br /></p><p><a href="https://courses.cs.duke.edu/fall12/compsci590.1/introduction.pdf">A course at Duke</a><br /></p><p><a href="https://lara.epfl.ch/w/_media/papadimitriou81complexityintegerprogramming.pdf">An article by Papadimitriou</a>&nbsp;<br /></p><p><a href="https://arxiv.org/pdf/2012.00079.pdf">An article on arxiv</a><br /></p><p>The book&nbsp;<i>Graphs, Networks and Algorithms</i> by Dieter Jungnickel</p><p>Bob, do you have examples where they do not use that extra constraint.&nbsp;</p><p>BOB:&nbsp;</p><p><a href="https://www.mathworks.com/discovery/integer-programming.html">Math Works</a><br /></p><p><a href="https://faculty.math.illinois.edu/~mlavrov/docs/482-fall-2019/lecture33.pdf">Lecture notes from UIUC</a><br /></p><p><a href="https://coral.ise.lehigh.edu/~ted/files/ie418/lectures/Lecture1.pdf">Lecture notes from Lehigh Univ.</a><br /></p><p>The book <i>Parameterized Complexity Theory</i>&nbsp;by Flum and Grohe</p><p>The book <i>Computers and Intractability : A Guide to the Theory of NP-Completeness</i> by Garey and Johnson</p><p>ALICE: Both of our lists are impressive. So now what?&nbsp;</p><p>--------------------------------------------------------------------</p><p>(This is Bill again.)</p><p>What indeed!</p><p>1) Why are there two definitions of Int Prog?</p><p>2) When is it good to use which one?&nbsp;</p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-19T19:02:00Z">Monday, September 19 2022, 19:02</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://processalgebra.blogspot.com/2022/09/dean-of-school-of-technology-at.html'>Dean of the School of Technology at Reykjavik University: Call for applications</a></h3>
          <p class='item-feed'>from <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Reykjavik University is looking for a new dean of the School of Technology, which comprises the Department of Applied Engineering, the Department of Computer Science, and the Department of Engineering.&nbsp;</p><p>If you have a strong academic career, a vision of how our school can improve its standing and impact, and would enjoy living in Iceland, I encourage you to consider this opportunity!  See the ad at the link below for more information:&nbsp;</p><p>jobs.50skills.com/ru/en/15613&nbsp;</p><p>Spread the news through your network and encourage excellent candidates to apply.</p><p>By Luca Aceto</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Reykjavik University is looking for a new dean of the School of Technology, which comprises the Department of Applied Engineering, the Department of Computer Science, and the Department of Engineering.&nbsp;</p><p>If you have a strong academic career, a vision of how our school can improve its standing and impact, and would enjoy living in Iceland, I encourage you to consider this opportunity!  See the ad at the link below for more information:&nbsp;</p><p><a href="https://jobs.50skills.com/ru/en/15613">https://jobs.50skills.com/ru/en/15613</a>&nbsp;</p><p>Spread the news through your network and encourage excellent candidates to apply.</p><p class="authors">By Luca Aceto</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-19T16:58:00Z">Monday, September 19 2022, 16:58</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.07625'>Extremal combinatorics, iterated pigeonhole arguments, and generalizations of PPP</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Amol Pasarkar, Mihalis Yannakakis, Christos Papadimitriou</p><p>We study the complexity of computational problems arising from existence
theorems in extremal combinatorics. For some of these problems, a solution is
guaranteed to exist based on an iterated application of the Pigeonhole
Principle. This results in the definition of a new complexity class within
TFNP, which we call PLC (for "polynomial long choice"). PLC includes all of
PPP, as well as numerous previously unclassified total problems, including
search problems related to Ramsey's theorem, the Sunflower theorem, the
Erd\H{o}s-Ko-Rado lemma, and K\"onig's lemma. Whether the first two of these
four problems are PLC-complete is an important open question which we pursue;
in contrast, we show that the latter two are PPP-complete. Finally, we reframe
PPP as an optimization problem, and define a hierarchy of such problems related
to Tur\'an's theorem.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pasarkar_A/0/1/0/all/0/1">Amol Pasarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Yannakakis_M/0/1/0/all/0/1">Mihalis Yannakakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Papadimitriou_C/0/1/0/all/0/1">Christos Papadimitriou</a></p><p>We study the complexity of computational problems arising from existence
theorems in extremal combinatorics. For some of these problems, a solution is
guaranteed to exist based on an iterated application of the Pigeonhole
Principle. This results in the definition of a new complexity class within
TFNP, which we call PLC (for "polynomial long choice"). PLC includes all of
PPP, as well as numerous previously unclassified total problems, including
search problems related to Ramsey's theorem, the Sunflower theorem, the
Erd\H{o}s-Ko-Rado lemma, and K\"onig's lemma. Whether the first two of these
four problems are PLC-complete is an important open question which we pursue;
in contrast, we show that the latter two are PPP-complete. Finally, we reframe
PPP as an optimization problem, and define a hierarchy of such problems related
to Tur\'an's theorem.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-19T00:30:00Z">Monday, September 19 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.08009'>Approximate traces on groups and the quantum complexity class $\operatorname{MIP}^{co,s}$</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Isaac Goldbring, Bradd Hart</p><p>An open question in quantum complexity theory is whether or not the class
$\operatorname{MIP}^{co}$, consisting of languages that can be efficiently
verified using interacting provers sharing quantum resources according to the
quantum commuting model, coincides with the class $coRE$ of languages with
recursively enumerable complement. We introduce the notion of a qc-modulus,
which encodes approximations to quantum commuting correlations, and show that
the existence of a computable qc-modulus gives a negative answer to a natural
variant of the aforementioned question.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goldbring_I/0/1/0/all/0/1">Isaac Goldbring</a>, <a href="http://arxiv.org/find/cs/1/au:+Hart_B/0/1/0/all/0/1">Bradd Hart</a></p><p>An open question in quantum complexity theory is whether or not the class
$\operatorname{MIP}^{co}$, consisting of languages that can be efficiently
verified using interacting provers sharing quantum resources according to the
quantum commuting model, coincides with the class $coRE$ of languages with
recursively enumerable complement. We introduce the notion of a qc-modulus,
which encodes approximations to quantum commuting correlations, and show that
the existence of a computable qc-modulus gives a negative answer to a natural
variant of the aforementioned question.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-19T00:30:00Z">Monday, September 19 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.08042'>Decision Tree Complexity versus Block Sensitivity and Degree</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Rahul Chugh, Supartha Podder, Swagato Sanyal</p><p>Relations between the decision tree complexity and various other complexity
measures of Boolean functions is a thriving topic of research in computational
complexity. It is known that decision tree complexity is bounded above by the
cube of block sensitivity, and the cube of polynomial degree. However, the
widest separation between decision tree complexity and each of block
sensitivity and degree that is witnessed by known Boolean functions is
quadratic. In this work, we investigate the tightness of the existing cubic
upper bounds.
</p>
<p>We improve the cubic upper bounds for many interesting classes of Boolean
functions. We show that for graph properties and for functions with a constant
number of alternations, both of the cubic upper bounds can be improved to
quadratic. We define a class of Boolean functions, which we call the zebra
functions, that comprises Boolean functions where each monotone path from 0^n
to 1^n has an equal number of alternations. This class contains the symmetric
and monotone functions as its subclasses. We show that for any zebra function,
decision tree complexity is at most the square of block sensitivity, and
certificate complexity is at most the square of degree.
</p>
<p>Finally, we show using a lifting theorem of communication complexity by
G{\"{o}}{\"{o}}s, Pitassi and Watson that the task of proving an improved upper
bound on the decision tree complexity for all functions is in a sense
equivalent to the potentially easier task of proving a similar upper bound on
communication complexity for each bi-partition of the input variables, for all
functions. In particular, this implies that to bound the decision tree
complexity it suffices to bound smaller measures like parity decision tree
complexity, subcube decision tree complexity and decision tree rank, that are
defined in terms of models that can be efficiently simulated by communication
protocols.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chugh_R/0/1/0/all/0/1">Rahul Chugh</a>, <a href="http://arxiv.org/find/cs/1/au:+Podder_S/0/1/0/all/0/1">Supartha Podder</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanyal_S/0/1/0/all/0/1">Swagato Sanyal</a></p><p>Relations between the decision tree complexity and various other complexity
measures of Boolean functions is a thriving topic of research in computational
complexity. It is known that decision tree complexity is bounded above by the
cube of block sensitivity, and the cube of polynomial degree. However, the
widest separation between decision tree complexity and each of block
sensitivity and degree that is witnessed by known Boolean functions is
quadratic. In this work, we investigate the tightness of the existing cubic
upper bounds.
</p>
<p>We improve the cubic upper bounds for many interesting classes of Boolean
functions. We show that for graph properties and for functions with a constant
number of alternations, both of the cubic upper bounds can be improved to
quadratic. We define a class of Boolean functions, which we call the zebra
functions, that comprises Boolean functions where each monotone path from 0^n
to 1^n has an equal number of alternations. This class contains the symmetric
and monotone functions as its subclasses. We show that for any zebra function,
decision tree complexity is at most the square of block sensitivity, and
certificate complexity is at most the square of degree.
</p>
<p>Finally, we show using a lifting theorem of communication complexity by
G{\"{o}}{\"{o}}s, Pitassi and Watson that the task of proving an improved upper
bound on the decision tree complexity for all functions is in a sense
equivalent to the potentially easier task of proving a similar upper bound on
communication complexity for each bi-partition of the input variables, for all
functions. In particular, this implies that to bound the decision tree
complexity it suffices to bound smaller measures like parity decision tree
complexity, subcube decision tree complexity and decision tree rank, that are
defined in terms of models that can be efficiently simulated by communication
protocols.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-19T00:30:00Z">Monday, September 19 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.07557'>On Optimal Coverage of a Tree with Multiple Robots</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: I. Aldana-Galv&#xe1;n, J.C. Catana-Salazar, J.M. D&#xed;az-B&#xe1;&#xf1;ez, F. Duque, R. Fabila-Monroy, M.A. Heredia, A. Ram&#xed;rez-Vigueras, J. Urrutia</p><p>We study the algorithmic problem of optimally covering a tree with $k$ mobile
robots. The tree is known to all robots, and our goal is to assign a walk to
each robot in such a way that the union of these walks covers the whole tree.
We assume that the edges have the same length, and that traveling along an edge
takes a unit of time. Two objective functions are considered: the cover time
and the cover length. The cover time is the maximum time a robot needs to
finish its assigned walk and the cover length is the sum of the lengths of all
the walks. We also consider a variant in which the robots must rendezvous
periodically at the same vertex in at most a certain number of moves. We show
that the problem is different for the two cost functions. For the cover time
minimization problem, we prove that the problem is NP-hard when $k$ is part of
the input, regardless of whether periodic rendezvous are required or not. For
the cover length minimization problem, we show that it can be solved in
polynomial time when periodic rendezvous are not required, and it is NP-hard
otherwise.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aldana_Galvan_I/0/1/0/all/0/1">I. Aldana-Galv&#xe1;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Catana_Salazar_J/0/1/0/all/0/1">J.C. Catana-Salazar</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1">J.M. D&#xed;az-B&#xe1;&#xf1;ez</a>, <a href="http://arxiv.org/find/cs/1/au:+Duque_F/0/1/0/all/0/1">F. Duque</a>, <a href="http://arxiv.org/find/cs/1/au:+Fabila_Monroy_R/0/1/0/all/0/1">R. Fabila-Monroy</a>, <a href="http://arxiv.org/find/cs/1/au:+Heredia_M/0/1/0/all/0/1">M.A. Heredia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramirez_Vigueras_A/0/1/0/all/0/1">A. Ram&#xed;rez-Vigueras</a>, <a href="http://arxiv.org/find/cs/1/au:+Urrutia_J/0/1/0/all/0/1">J. Urrutia</a></p><p>We study the algorithmic problem of optimally covering a tree with $k$ mobile
robots. The tree is known to all robots, and our goal is to assign a walk to
each robot in such a way that the union of these walks covers the whole tree.
We assume that the edges have the same length, and that traveling along an edge
takes a unit of time. Two objective functions are considered: the cover time
and the cover length. The cover time is the maximum time a robot needs to
finish its assigned walk and the cover length is the sum of the lengths of all
the walks. We also consider a variant in which the robots must rendezvous
periodically at the same vertex in at most a certain number of moves. We show
that the problem is different for the two cost functions. For the cover time
minimization problem, we prove that the problem is NP-hard when $k$ is part of
the input, regardless of whether periodic rendezvous are required or not. For
the cover length minimization problem, we show that it can be solved in
polynomial time when periodic rendezvous are not required, and it is NP-hard
otherwise.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-19T00:30:00Z">Monday, September 19 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.07772'>$b$-Coloring Parameterized by Pathwidth is XNLP-complete</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Lars Jaffke, Paloma T. Lima, Roohani Sharma</p><p>We show that the $b$-Coloring problem is complete for the class XNLP when
parameterized by the pathwidth of the input graph. Besides determining the
precise parameterized complexity of this problem, this implies that b-Coloring
parameterized by pathwidth is $W[t]$-hard for all $t$, and resolves the
parameterized complexity of $b$-Coloring parameterized by treewidth.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jaffke_L/0/1/0/all/0/1">Lars Jaffke</a>, <a href="http://arxiv.org/find/cs/1/au:+Lima_P/0/1/0/all/0/1">Paloma T. Lima</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Roohani Sharma</a></p><p>We show that the $b$-Coloring problem is complete for the class XNLP when
parameterized by the pathwidth of the input graph. Besides determining the
precise parameterized complexity of this problem, this implies that b-Coloring
parameterized by pathwidth is $W[t]$-hard for all $t$, and resolves the
parameterized complexity of $b$-Coloring parameterized by treewidth.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-19T00:30:00Z">Monday, September 19 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.07580'>Exploring the Tradeoff between Competitive Ratio and Variance in Online-Matching Markets</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Pan Xu</p><p>In this paper, we propose an online-matching-based model to study the
assignment problems arising in a wide range of online-matching markets,
including online recommendations, ride-hailing platforms, and crowdsourcing
markets. It features that each assignment can request a random set of resources
and yield a random utility, and the two (cost and utility) can be arbitrarily
correlated with each other. We present two linear-programming-based
parameterized policies to study the tradeoff between the \emph{competitive
ratio} (CR) on the total utilities and the \emph{variance} on the total number
of matches (unweighted version). The first one (SAMP) is to sample an edge
according to the distribution extracted from the clairvoyant optimal, while the
second (ATT) features a time-adaptive attenuation framework that leads to an
improvement over the state-of-the-art competitive-ratio result. We also
consider the problem under a large-budget assumption and show that SAMP
achieves asymptotically optimal performance in terms of competitive ratio.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Pan Xu</a></p><p>In this paper, we propose an online-matching-based model to study the
assignment problems arising in a wide range of online-matching markets,
including online recommendations, ride-hailing platforms, and crowdsourcing
markets. It features that each assignment can request a random set of resources
and yield a random utility, and the two (cost and utility) can be arbitrarily
correlated with each other. We present two linear-programming-based
parameterized policies to study the tradeoff between the \emph{competitive
ratio} (CR) on the total utilities and the \emph{variance} on the total number
of matches (unweighted version). The first one (SAMP) is to sample an edge
according to the distribution extracted from the clairvoyant optimal, while the
second (ATT) features a time-adaptive attenuation framework that leads to an
improvement over the state-of-the-art competitive-ratio result. We also
consider the problem under a large-budget assumption and show that SAMP
achieves asymptotically optimal performance in terms of competitive ratio.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-19T00:30:00Z">Monday, September 19 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.07729'>On Weighted Graph Sparsification by Linear Sketching</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Yu Chen, Sanjeev Khanna, Huan Li</p><p>A seminal work of [Ahn-Guha-McGregor, PODS'12] showed that one can compute a
cut sparsifier of an unweighted undirected graph by taking a near-linear number
of linear measurements on the graph. Subsequent works also studied computing
other graph sparsifiers using linear sketching, and obtained near-linear upper
bounds for spectral sparsifiers [Kapralov-Lee-Musco-Musco-Sidford, FOCS'14] and
first non-trivial upper bounds for spanners [Filtser-Kapralov-Nouri, SODA'21].
All these linear sketching algorithms, however, only work on unweighted graphs.
</p>
<p>In this paper, we initiate the study of weighted graph sparsification by
linear sketching by investigating a natural class of linear sketches that we
call incidence sketches, in which each measurement is a linear combination of
the weights of edges incident on a single vertex. Our results are:
</p>
<p>1. Weighted cut sparsification: We give an algorithm that computes a $(1 +
\epsilon)$-cut sparsifier using $\tilde{O}(n \epsilon^{-3})$ linear
measurements, which is nearly optimal.
</p>
<p>2. Weighted spectral sparsification: We give an algorithm that computes a $(1
+ \epsilon)$-spectral sparsifier using $\tilde{O}(n^{6/5} \epsilon^{-4})$
linear measurements. Complementing our algorithm, we then prove a superlinear
lower bound of $\Omega(n^{21/20-o(1)})$ measurements for computing some
$O(1)$-spectral sparsifier using incidence sketches.
</p>
<p>3. Weighted spanner computation: We focus on graphs whose largest/smallest
edge weights differ by an $O(1)$ factor, and prove that, for incidence
sketches, the upper bounds obtained by~[Filtser-Kapralov-Nouri, SODA'21] are
optimal up to an $n^{o(1)}$ factor.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Khanna_S/0/1/0/all/0/1">Sanjeev Khanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Huan Li</a></p><p>A seminal work of [Ahn-Guha-McGregor, PODS'12] showed that one can compute a
cut sparsifier of an unweighted undirected graph by taking a near-linear number
of linear measurements on the graph. Subsequent works also studied computing
other graph sparsifiers using linear sketching, and obtained near-linear upper
bounds for spectral sparsifiers [Kapralov-Lee-Musco-Musco-Sidford, FOCS'14] and
first non-trivial upper bounds for spanners [Filtser-Kapralov-Nouri, SODA'21].
All these linear sketching algorithms, however, only work on unweighted graphs.
</p>
<p>In this paper, we initiate the study of weighted graph sparsification by
linear sketching by investigating a natural class of linear sketches that we
call incidence sketches, in which each measurement is a linear combination of
the weights of edges incident on a single vertex. Our results are:
</p>
<p>1. Weighted cut sparsification: We give an algorithm that computes a $(1 +
\epsilon)$-cut sparsifier using $\tilde{O}(n \epsilon^{-3})$ linear
measurements, which is nearly optimal.
</p>
<p>2. Weighted spectral sparsification: We give an algorithm that computes a $(1
+ \epsilon)$-spectral sparsifier using $\tilde{O}(n^{6/5} \epsilon^{-4})$
linear measurements. Complementing our algorithm, we then prove a superlinear
lower bound of $\Omega(n^{21/20-o(1)})$ measurements for computing some
$O(1)$-spectral sparsifier using incidence sketches.
</p>
<p>3. Weighted spanner computation: We focus on graphs whose largest/smallest
edge weights differ by an $O(1)$ factor, and prove that, for incidence
sketches, the upper bounds obtained by~[Filtser-Kapralov-Nouri, SODA'21] are
optimal up to an $n^{o(1)}$ factor.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-19T00:30:00Z">Monday, September 19 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.07860'>A $(1.5+\epsilon)$-Approximation Algorithm for Weighted Connectivity Augmentation</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Vera Traub, Rico Zenklusen</p><p>Connectivity augmentation problems are among the most elementary questions in
Network Design. Many of these problems admit natural $2$-approximation
algorithms, often through various classic techniques, whereas it remains open
whether approximation factors below $2$ can be achieved. One of the most basic
examples thereof is the Weighted Connectivity Augmentation Problem (WCAP). In
WCAP, one is given an undirected graph together with a set of additional
weighted candidate edges, and the task is to find a cheapest set of candidate
edges whose addition to the graph increases its edge-connectivity. We present a
$(1.5+\varepsilon)$-approximation algorithm for WCAP, showing for the first
time that factors below $2$ are achievable.
</p>
<p>On a high level, we design a well-chosen local search algorithm, inspired by
recent advances for Weighted Tree Augmentation. To measure progress, we
consider a directed weakening of WCAP and show that it has highly structured
planar solutions. Interpreting a solution of the original problem as one of
this directed weakening allows us to describe local exchange steps in a clean
and algorithmically amenable way. Leveraging these insights, we show that we
can efficiently search for good exchange steps within a component class for
link sets that is closely related to bounded treewidth subgraphs of circle
graphs. Moreover, we prove that an optimum solution can be decomposed into
smaller components, at least one of which leads to a good local search step as
long as we did not yet achieve the claimed approximation guarantee.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Traub_V/0/1/0/all/0/1">Vera Traub</a>, <a href="http://arxiv.org/find/cs/1/au:+Zenklusen_R/0/1/0/all/0/1">Rico Zenklusen</a></p><p>Connectivity augmentation problems are among the most elementary questions in
Network Design. Many of these problems admit natural $2$-approximation
algorithms, often through various classic techniques, whereas it remains open
whether approximation factors below $2$ can be achieved. One of the most basic
examples thereof is the Weighted Connectivity Augmentation Problem (WCAP). In
WCAP, one is given an undirected graph together with a set of additional
weighted candidate edges, and the task is to find a cheapest set of candidate
edges whose addition to the graph increases its edge-connectivity. We present a
$(1.5+\varepsilon)$-approximation algorithm for WCAP, showing for the first
time that factors below $2$ are achievable.
</p>
<p>On a high level, we design a well-chosen local search algorithm, inspired by
recent advances for Weighted Tree Augmentation. To measure progress, we
consider a directed weakening of WCAP and show that it has highly structured
planar solutions. Interpreting a solution of the original problem as one of
this directed weakening allows us to describe local exchange steps in a clean
and algorithmically amenable way. Leveraging these insights, we show that we
can efficiently search for good exchange steps within a component class for
link sets that is closely related to bounded treewidth subgraphs of circle
graphs. Moreover, we prove that an optimum solution can be decomposed into
smaller components, at least one of which leads to a good local search step as
long as we did not yet achieve the claimed approximation guarantee.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-19T00:30:00Z">Monday, September 19 2022, 00:30</time>
        </div>
      </div>
    </article>
  
  </div>

  <script src='js/jquery-2.0.3.min.js'></script>
  <script src="js/jquery.timeago.js" type="text/javascript"></script>
  <script>
    jQuery(document).ready(function() {
      jQuery("time.timeago").timeago();
    });
  </script>
  <script src='js/blank.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
