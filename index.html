<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-02-13T12:53:29Z">Monday, February 13 2023, 12:53</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, February 13
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/13/postdoc-at-institute-of-mathematics-czech-academy-of-sciences-apply-by-march-31-2023/'>postdoc at Institute of Mathematics, Czech Academy of Sciences (apply by March 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Institute of Mathematics of the Czech Academy of Sciences is seeking a researcher for the project “Logic and unsatisfiability”. Applications are invited from candidates who have completed their PhD within the last 5 years (or will have completed it before the time of hiring), and who have a strong background in proof complexity or [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Institute of Mathematics of the Czech Academy of Sciences is seeking a researcher for the project “Logic and unsatisfiability”. Applications are invited from candidates who have completed their PhD within the last 5 years (or will have completed it before the time of hiring), and who have a strong background in proof complexity or bounded arithmetic.</p>
<p>Website: <a href="http://www.math.cas.cz/recrutements/postes.php">http://www.math.cas.cz/recrutements/postes.php</a><br />
Email: thapen@math.cas.cz</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T10:19:11Z">Monday, February 13 2023, 10:19</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05426'>Lower bounds for Choiceless Polynomial Time via Symmetric XOR-circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Benedikt Pago</p><p>Choiceless Polynomial Time (CPT) is one of the few remaining candidate logics
for capturing PTIME. In this paper, we make progress towards separating CPT
from polynomial time by firstly establishing a connection between the
expressive power of CPT and the existence of certain symmetric circuit
families, and secondly, proving lower bounds against these circuits. We focus
on the isomorphism problem of unordered Cai-F\"urer-Immerman-graphs (the
CFI-query) as a potential candidate for separating CPT from P. Results by
Dawar, Richerby and Rossman, and subsequently by Pakusa, Schalth\"ofer and
Selman show that the CFI-query is CPT-definable on linearly ordered and
preordered base graphs with small colour classes. We define a class of
CPT-algorithms, that we call "CFI-symmetric algorithms", which generalises all
the known ones, and show that such algorithms can only define the CFI-query on
a given class of base graphs if there exists a family of symmetric XOR-circuits
with certain properties. These properties include that the circuits have the
same symmetries as the base graphs, are of polynomial size, and satisfy certain
fan-in restrictions. Then we prove that such circuits with slightly
strengthened requirements (i.e. stronger symmetry and fan-in and fan-out
restrictions) do not exist for the n-dimensional hypercubes as base graphs.
This almost separates the CFI-symmetric algorithms from polynomial time - up to
the gap that remains between the circuits whose existence we can currently
disprove and the circuits whose existence is necessary for the definability of
the CFI-query by a CFI-symmetric algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pago_B/0/1/0/all/0/1">Benedikt Pago</a></p><p>Choiceless Polynomial Time (CPT) is one of the few remaining candidate logics
for capturing PTIME. In this paper, we make progress towards separating CPT
from polynomial time by firstly establishing a connection between the
expressive power of CPT and the existence of certain symmetric circuit
families, and secondly, proving lower bounds against these circuits. We focus
on the isomorphism problem of unordered Cai-F\"urer-Immerman-graphs (the
CFI-query) as a potential candidate for separating CPT from P. Results by
Dawar, Richerby and Rossman, and subsequently by Pakusa, Schalth\"ofer and
Selman show that the CFI-query is CPT-definable on linearly ordered and
preordered base graphs with small colour classes. We define a class of
CPT-algorithms, that we call "CFI-symmetric algorithms", which generalises all
the known ones, and show that such algorithms can only define the CFI-query on
a given class of base graphs if there exists a family of symmetric XOR-circuits
with certain properties. These properties include that the circuits have the
same symmetries as the base graphs, are of polynomial size, and satisfy certain
fan-in restrictions. Then we prove that such circuits with slightly
strengthened requirements (i.e. stronger symmetry and fan-in and fan-out
restrictions) do not exist for the n-dimensional hypercubes as base graphs.
This almost separates the CFI-symmetric algorithms from polynomial time - up to
the gap that remains between the circuits whose existence we can currently
disprove and the circuits whose existence is necessary for the definability of
the CFI-query by a CFI-symmetric algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T01:30:00Z">Monday, February 13 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04908'>Certified simultaneous isotopic approximation of pairs of curves via subdivision</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Burr, Michael Byrd</p><p>We present a certified algorithm based on subdivision for computing an
isotopic approximation to a pair of curves in the plane. Our algorithm is based
on the certified curve approximation algorithm of Plantinga and Vegter. The
main challenge in this computation is to correctly and efficiently compute the
intersections of the curves. To address this issue, we introduce a new, but
simple test that guarantees the global correctness of our output.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Burr_M/0/1/0/all/0/1">Michael Burr</a>, <a href="http://arxiv.org/find/cs/1/au:+Byrd_M/0/1/0/all/0/1">Michael Byrd</a></p><p>We present a certified algorithm based on subdivision for computing an
isotopic approximation to a pair of curves in the plane. Our algorithm is based
on the certified curve approximation algorithm of Plantinga and Vegter. The
main challenge in this computation is to correctly and efficiently compute the
intersections of the curves. To address this issue, we introduce a new, but
simple test that guarantees the global correctness of our output.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T01:30:00Z">Monday, February 13 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04963'>Quadratic Memory is Necessary for Optimal Query Complexity in Convex Optimization: Center-of-Mass is Pareto-Optimal</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mo&#xef;se Blanchard, Junhui Zhang, Patrick Jaillet</p><p>We give query complexity lower bounds for convex optimization and the related
feasibility problem. We show that quadratic memory is necessary to achieve the
optimal oracle complexity for first-order convex optimization. In particular,
this shows that center-of-mass cutting-planes algorithms in dimension $d$ which
use $\tilde O(d^2)$ memory and $\tilde O(d)$ queries are Pareto-optimal for
both convex optimization and the feasibility problem, up to logarithmic
factors. Precisely, we prove that to minimize $1$-Lipschitz convex functions
over the unit ball to $1/d^4$ accuracy, any deterministic first-order
algorithms using at most $d^{2-\delta}$ bits of memory must make
$\tilde\Omega(d^{1+\delta/3})$ queries, for any $\delta\in[0,1]$. For the
feasibility problem, in which an algorithm only has access to a separation
oracle, we show a stronger trade-off: for at most $d^{2-\delta}$ memory, the
number of queries required is $\tilde\Omega(d^{1+\delta})$. This resolves a
COLT 2019 open problem of Woodworth and Srebro.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blanchard_M/0/1/0/all/0/1">Mo&#xef;se Blanchard</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junhui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaillet_P/0/1/0/all/0/1">Patrick Jaillet</a></p><p>We give query complexity lower bounds for convex optimization and the related
feasibility problem. We show that quadratic memory is necessary to achieve the
optimal oracle complexity for first-order convex optimization. In particular,
this shows that center-of-mass cutting-planes algorithms in dimension $d$ which
use $\tilde O(d^2)$ memory and $\tilde O(d)$ queries are Pareto-optimal for
both convex optimization and the feasibility problem, up to logarithmic
factors. Precisely, we prove that to minimize $1$-Lipschitz convex functions
over the unit ball to $1/d^4$ accuracy, any deterministic first-order
algorithms using at most $d^{2-\delta}$ bits of memory must make
$\tilde\Omega(d^{1+\delta/3})$ queries, for any $\delta\in[0,1]$. For the
feasibility problem, in which an algorithm only has access to a separation
oracle, we show a stronger trade-off: for at most $d^{2-\delta}$ memory, the
number of queries required is $\tilde\Omega(d^{1+\delta})$. This resolves a
COLT 2019 open problem of Woodworth and Srebro.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T01:30:00Z">Monday, February 13 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05030'>Dynamic $(1+\epsilon)$-Approximate Matching Size in Truly Sublinear Update Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sayan Bhattacharya, Peter Kiss, Thatchaphol Saranurak</p><p>We show a fully dynamic algorithm for maintaining $(1+\epsilon)$-approximate
\emph{size} of maximum matching of the graph with $n$ vertices and $m$ edges
using $m^{0.5-\Omega_{\epsilon}(1)}$ update time. This is the first polynomial
improvement over the long-standing $O(n)$ update time, which can be trivially
obtained by periodic recomputation. Thus, we resolve the value version of a
major open question of the dynamic graph algorithms literature (see, e.g.,
[Gupta and Peng FOCS'13], [Bernstein and Stein SODA'16],[Behnezhad and Khanna
SODA'22]).
</p>
<p>Our key technical component is the first sublinear algorithm for $(1,\epsilon
n)$-approximate maximum matching with sublinear running time on dense graphs.
All previous algorithms suffered a multiplicative approximation factor of at
least $1.499$ or assumed that the graph has a very small maximum degree.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1">Sayan Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiss_P/0/1/0/all/0/1">Peter Kiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Saranurak_T/0/1/0/all/0/1">Thatchaphol Saranurak</a></p><p>We show a fully dynamic algorithm for maintaining $(1+\epsilon)$-approximate
\emph{size} of maximum matching of the graph with $n$ vertices and $m$ edges
using $m^{0.5-\Omega_{\epsilon}(1)}$ update time. This is the first polynomial
improvement over the long-standing $O(n)$ update time, which can be trivially
obtained by periodic recomputation. Thus, we resolve the value version of a
major open question of the dynamic graph algorithms literature (see, e.g.,
[Gupta and Peng FOCS'13], [Bernstein and Stein SODA'16],[Behnezhad and Khanna
SODA'22]).
</p>
<p>Our key technical component is the first sublinear algorithm for $(1,\epsilon
n)$-approximate maximum matching with sublinear running time on dense graphs.
All previous algorithms suffered a multiplicative approximation factor of at
least $1.499$ or assumed that the graph has a very small maximum degree.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T01:30:00Z">Monday, February 13 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05245'>Count-min sketch with variable number of hash functions: an experimental study</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: &#xc9;ric Fusy, Gregory Kucherov</p><p>Conservative Count-Min, an improved version of Count-Min sketch [Cormode,
Muthukrishnan 2005], is an online-maintained hashing-based data structure
summarizing element frequency information without storing elements themselves.
Although several works attempted to analyze the error that can be made by
Count-Min, the behavior of this data structure remains poorly understood. In
[Fusy, Kucherov 2022], we demonstrated that under the uniform distribution of
input elements, the error of conservative Count-Min follows two distinct
regimes depending on its load factor.
</p>
<p>In this work, we provide a series of experimental results providing new
insights into the behavior of conservative Count-Min. Our contributions can be
seen as twofold. On one hand, we provide a detailed experimental analysis of
the behavior of Count-Min sketch in different regimes and under several
representative probability distributions of input elements. On the other hand,
we demonstrate improvements that can be made by assigning a variable number of
hash functions to different elements. This includes, in particular, reduced
space of the data structure while still supporting a small error.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fusy_E/0/1/0/all/0/1">&#xc9;ric Fusy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kucherov_G/0/1/0/all/0/1">Gregory Kucherov</a></p><p>Conservative Count-Min, an improved version of Count-Min sketch [Cormode,
Muthukrishnan 2005], is an online-maintained hashing-based data structure
summarizing element frequency information without storing elements themselves.
Although several works attempted to analyze the error that can be made by
Count-Min, the behavior of this data structure remains poorly understood. In
[Fusy, Kucherov 2022], we demonstrated that under the uniform distribution of
input elements, the error of conservative Count-Min follows two distinct
regimes depending on its load factor.
</p>
<p>In this work, we provide a series of experimental results providing new
insights into the behavior of conservative Count-Min. Our contributions can be
seen as twofold. On one hand, we provide a detailed experimental analysis of
the behavior of Count-Min sketch in different regimes and under several
representative probability distributions of input elements. On the other hand,
we demonstrate improvements that can be made by assigning a variable number of
hash functions to different elements. This includes, in particular, reduced
space of the data structure while still supporting a small error.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T01:30:00Z">Monday, February 13 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05366'>Online Algorithms with Randomly Infused Advice</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuval Emek, Yuval Gil, Maciej Pacut, Stefan Schmid</p><p>We introduce a novel method for the rigorous quantitative evaluation of
online algorithms that relaxes the "radical worst-case" perspective of classic
competitive analysis. In contrast to prior work, our method, referred to as
randomly infused advice (RIA), does not make any probabilistic assumptions
about the input sequence and does not rely on the development of designated
online algorithms. Rather, it can be applied to existing online randomized
algorithms, introducing a means to evaluate their performance in scenarios that
lie outside the radical worst-case regime. More concretely, an online algorithm
ALG with RIA benefits from pieces of advice generated by an omniscient but not
entirely reliable oracle. The crux of the new method is that the advice is
provided to ALG by writing it into the buffer B from which ALG normally reads
its random bits, hence allowing us to augment it through a very simple and
non-intrusive interface. The (un)reliability of the oracle is captured via a
parameter 0 {\le} {\alpha} {\le} 1 that determines the probability (per round)
that the advice is successfully infused by the oracle; if the advice is not
infused, which occurs with probability 1 - {\alpha}, then the buffer B contains
fresh random bits (as in the classic online setting).
</p>
<p>The applicability of the new RIA method is demonstrated by applying it to
three extensively studied online problems: paging, uniform metrical task
systems, and online set cover. For these problems, we establish new upper
bounds on the competitive ratio of classic online algorithms that improve as
the infusion parameter {\alpha} increases. These are complemented with (often
tight) lower bounds on the competitive ratio of online algorithms with RIA for
the three problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Emek_Y/0/1/0/all/0/1">Yuval Emek</a>, <a href="http://arxiv.org/find/cs/1/au:+Gil_Y/0/1/0/all/0/1">Yuval Gil</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacut_M/0/1/0/all/0/1">Maciej Pacut</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a></p><p>We introduce a novel method for the rigorous quantitative evaluation of
online algorithms that relaxes the "radical worst-case" perspective of classic
competitive analysis. In contrast to prior work, our method, referred to as
randomly infused advice (RIA), does not make any probabilistic assumptions
about the input sequence and does not rely on the development of designated
online algorithms. Rather, it can be applied to existing online randomized
algorithms, introducing a means to evaluate their performance in scenarios that
lie outside the radical worst-case regime. More concretely, an online algorithm
ALG with RIA benefits from pieces of advice generated by an omniscient but not
entirely reliable oracle. The crux of the new method is that the advice is
provided to ALG by writing it into the buffer B from which ALG normally reads
its random bits, hence allowing us to augment it through a very simple and
non-intrusive interface. The (un)reliability of the oracle is captured via a
parameter 0 {\le} {\alpha} {\le} 1 that determines the probability (per round)
that the advice is successfully infused by the oracle; if the advice is not
infused, which occurs with probability 1 - {\alpha}, then the buffer B contains
fresh random bits (as in the classic online setting).
</p>
<p>The applicability of the new RIA method is demonstrated by applying it to
three extensively studied online problems: paging, uniform metrical task
systems, and online set cover. For these problems, we establish new upper
bounds on the competitive ratio of classic online algorithms that improve as
the infusion parameter {\alpha} increases. These are complemented with (often
tight) lower bounds on the competitive ratio of online algorithms with RIA for
the three problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T01:30:00Z">Monday, February 13 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, February 12
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/when-is-paper-easily-available.html'>When is a paper `Easily Available' ?</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>I was looking at the paper&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PSPACE-Completeness of reversible deterministic systems</p><p>by Erik Demaine, Robert Hearn,&nbsp; Dylan Hendrickson, and Jayson Lynch (see&nbsp;here) and came across the following fascinating result which I paraphrase:</p><p>The problem of, given balls on a pool table (though it can be one you devise which is not the standard one) and each balls initial position and velocity, and a particular ball and place, it is PSPACE complete to determine if that ball ever gets to that place.&nbsp;</p><p>Demaine et al. stated that this was proven by&nbsp;Edward Fredkin and Tommaso Toffoli in 1982 (see&nbsp;here&nbsp;for a link to the 1982 paper, not behind a paywall). Demaine et al. gave an easier proof with some nice properties. (Just in case the link goes away I downloaded the paper to my files and you can find it&nbsp;here.)&nbsp;</p><p>I needed the bib reference for the FT-1982 paper and rather than copy it from Demaine et al. I wanted to cut-and-paste, so I looked for it in DBLP. I didn't find the 1982 paper but I did find a book from 2002 that reprinted it. The book, Collision-based computing, has a website&nbsp;here. The book itself is behind a paywall.</p><p>On the website is the following curious statement:</p><p>[This book] Gives a state-of-the-art overview of an emerging topic, on which there is little published literature at the moment. [The book] Includes 2 classic paper, both of which are widely referred to but are NOT EASILY AVAILABLE (E. Fredkin and T. Toffoli: Conservative Logic, and N . Margolous Physics-Like Models of Computation).&nbsp;</p><p>The caps are mine.</p><p>Not easily available? I found a link in less than a minute, and I used it above when I pointed to the paper.&nbsp;</p><p>But the book IS behind a paywall.&nbsp;</p><p>Perhaps Springer does not know that the article is easily available. That would be odd since the place I found the article is also a Springer website.&nbsp;</p><p>The notion of EASILY AVAILABLE is very odd. While not quite related, it reminds me of when MIT Press had to pay a few thousand dollars for permission (that might not be the legal term) to reprint Turing's 1936 paper where he defined Turing Machines (he didn't call them that), which is&nbsp;on line here&nbsp;(and other places), for Harry Lewis's book Ideas that created the future.&nbsp;</p><p><br></p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I was looking at the paper&nbsp;</p><p><i>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PSPACE-Completeness of reversible deterministic systems</i></p><p>by Erik Demaine, Robert Hearn,&nbsp; Dylan Hendrickson, and Jayson Lynch (see&nbsp;<a href="https://arxiv.org/abs/2207.07229">here</a>) and came across the following fascinating result which I paraphrase:</p><p><i>The problem of, given balls on a pool table (though it can be one you devise which is not the standard one) and each balls initial position and velocity, and a particular ball and place, it is PSPACE complete to determine if that ball ever gets to that place.&nbsp;</i></p><p>Demaine et al. stated that this was proven by&nbsp;Edward Fredkin and Tommaso Toffoli in 1982 (see&nbsp;<a href="https://link.springer.com/article/10.1007/BF01857727">here</a>&nbsp;for a link to the 1982 paper, not behind a paywall). Demaine et al. gave an easier proof with some nice properties. (Just in case the link goes away I downloaded the paper to my files and you can find it&nbsp;<a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/clogic.pdf">here</a>.)&nbsp;</p><p>I needed the bib reference for the FT-1982 paper and rather than copy it from Demaine et al. I wanted to cut-and-paste, so I looked for it in DBLP. I didn't find the 1982 paper but I did find a book from 2002 that reprinted it. The book, <i>Collision-based computing,</i> has a website&nbsp;<a href="https://link.springer.com/book/10.1007/978-1-4471-0129-1">here</a>. The book itself is behind a paywall.</p><p>On the website is the following curious statement:</p><p><i>[This book] Gives a state-of-the-art overview of an emerging topic, on which there is little published literature at the moment. [The book] Includes 2 classic paper, both of which are widely referred to but are NOT EASILY AVAILABLE (E. Fredkin and T. Toffoli: Conservative Logic, and N . Margolous Physics-Like Models of Computation).&nbsp;</i></p><p>The caps are mine.</p><p>Not easily available? I found a link in less than a minute, and I used it above when I pointed to the paper.&nbsp;</p><p>But the book IS behind a paywall.&nbsp;</p><p>Perhaps Springer does not know that the article is easily available. That would be odd since the place I found the article is also a Springer website.&nbsp;</p><p>The notion of EASILY AVAILABLE is very odd. While not quite related, it reminds me of when MIT Press had to pay a few thousand dollars for permission (that might not be the legal term) to reprint Turing's 1936 paper where he defined Turing Machines (he didn't call them that), which is&nbsp;<a href="https://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf">on line here</a>&nbsp;(and other places), for Harry Lewis's book <i>Ideas that created the</i> <i>future.&nbsp;</i></p><p><br /></p><p><i><br /></i></p><p><i><br /></i></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-12T21:22:00Z">Sunday, February 12 2023, 21:22</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, February 11
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/'>Are We Nuts?</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Gil Kalai is one of the top researchers in the world in the area of combinatorics. His blog is one of the best in the universe. He also has some of the top results of anyone. One measure of excellence is how important not your results are, but how important your conjectures are. He with [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Gil Kalai is one of the top researchers in the world in the area of combinatorics. His <a href="https://gilkalai.wordpress.com">blog</a> is one of the best in the universe.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/gk-2/" rel="attachment wp-att-21072"><img data-attachment-id="21072" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/gk-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/gk.jpeg?fit=278%2C181&amp;ssl=1" data-orig-size="278,181" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="gk" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/gk.jpeg?fit=278%2C181&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/gk.jpeg?fit=278%2C181&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/gk.jpeg?resize=278%2C181&#038;ssl=1" alt="" width="278" height="181" class="aligncenter size-full wp-image-21072" data-recalc-dims="1" /></a></p>
<p>He also has some of the top results of anyone. One measure of excellence is how important not your results are, but how important your conjectures are. He with Jeff Kahn created in 2006 the expectation threshold <a href="https://arxiv.org/abs/math/0603218">conjecture</a> which was just solved by Jinyoung Park and Huy Tuan Pham&#8212; <a href="https://arxiv.org/abs/2203.17207">here</a>.</p>
<p>The fact that open problems are perhaps more important than results will be reflected in the next FOCS 2023. There will be a whole <a href="https://windowsontheory.org/2023/01/16/new-in-focs-2023-a-conjectures-track/">track</a> on open problems. See Amit Sahai, Shubhangi Saraf, and Thomas Vidick who have put together an FAQ about this: This year, FOCS 2023 will include something new: a Conjectures Track, separate from the Main Track. Submissions to the Main Track will be evaluated along similar lines as STOC/FOCS papers typically are, aiming to accept papers that obtain the very best results across all fields of theoretical computer science. Submissions to the new Conjectures Track will be evaluated completely separately from submissions to the Main Track. There is no a priori acceptance quota for either track, or desired number of accepted papers: it will all depend on the quality of submissions only.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/am-2/" rel="attachment wp-att-21082"><img data-attachment-id="21082" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/am-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/am.jpeg?fit=171%2C295&amp;ssl=1" data-orig-size="171,295" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="am" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/am.jpeg?fit=171%2C295&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/am.jpeg?fit=171%2C295&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/am.jpeg?resize=171%2C295&#038;ssl=1" alt="" width="171" height="295" class="aligncenter size-full wp-image-21082" data-recalc-dims="1" /></a></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/ss-2/" rel="attachment wp-att-21077"><img data-attachment-id="21077" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/ss-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?fit=225%2C225&amp;ssl=1" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ss" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?fit=225%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?fit=225%2C225&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?resize=225%2C225&#038;ssl=1" alt="" width="225" height="225" class="aligncenter size-full wp-image-21077" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?w=225&amp;ssl=1 225w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1" /></a></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/tv-2/" rel="attachment wp-att-21079"><img data-attachment-id="21079" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/tv-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/tv.jpeg?fit=198%2C255&amp;ssl=1" data-orig-size="198,255" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tv" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/tv.jpeg?fit=198%2C255&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/tv.jpeg?fit=198%2C255&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/tv.jpeg?resize=198%2C255&#038;ssl=1" alt="" width="198" height="255" class="aligncenter size-full wp-image-21079" data-recalc-dims="1" /></a></p>
<p><strong>Against Quantum Computers</strong></p>
<p>Gil Kalai has argued against quantum computation being a faster type of computation. See his paper <a href="https://gilkalai.wordpress.com">here</a> for one example. Or see <a href="https://gilkalai.wordpress.com/2020/12/29/the-argument-against-quantum-computers-a-very-short-introduction/">anti 1</a> and <a href="https://arxiv.org/abs/1908.02499">anti 2</a>.</p>
<p><strong>The New Yorker Magazine</strong></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/cover-3/" rel="attachment wp-att-21074"><img data-attachment-id="21074" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/cover-3/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpeg?fit=258%2C352&amp;ssl=1" data-orig-size="258,352" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cover" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpeg?fit=220%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpeg?fit=258%2C352&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpeg?resize=258%2C352&#038;ssl=1" alt="" width="258" height="352" class="aligncenter size-full wp-image-21074" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpeg?w=258&amp;ssl=1 258w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpeg?resize=220%2C300&amp;ssl=1 220w" sizes="(max-width: 258px) 100vw, 258px" data-recalc-dims="1" /></a></p>
<p>Last month the New Yorker had two articles about math. That&#8217;s two more than usual.</p>
<p>The main article was on quantum algorithms by Stephen Witt. He is a reporter and has a degree in 2001 from the University of Chicago in mathematics.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/sw/" rel="attachment wp-att-21073"><img data-attachment-id="21073" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/sw/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?fit=225%2C225&amp;ssl=1" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sw" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?fit=225%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?fit=225%2C225&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?resize=225%2C225&#038;ssl=1" alt="" width="225" height="225" class="aligncenter size-full wp-image-21073" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?w=225&amp;ssl=1 225w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1" /></a></p>
<p>His article features Peter Shor a leader in quantum algorithms&#8212;no relationship to Santa&#8212;but long time friend.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/peter-2/" rel="attachment wp-att-21076"><img data-attachment-id="21076" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/peter-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?fit=224%2C224&amp;ssl=1" data-orig-size="224,224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="peter" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?fit=224%2C224&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?fit=224%2C224&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?resize=224%2C224&#038;ssl=1" alt="" width="224" height="224" class="aligncenter size-full wp-image-21076" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?w=224&amp;ssl=1 224w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 224px) 100vw, 224px" data-recalc-dims="1" /></a></p>
<p>Witt&#8217;s article features other friends of ours such as Scott Aaronson&#8212;the owner of the wonderful <a href="https://scottaaronson.blog">blog</a>&#8212;Shtetl-Optimized. Scott&#8217;s post starts: I, Scott confess: this was the first time I felt visceral anger, rather than mere bemusement, over this wormhole affair. Before, I had implicitly assumed: no one was actually hoodwinked by this. No one really, literally believed that this little 9-qubit simulation opened up a wormhole, or helped prove the holographic nature of the real universe, or anything like that. I was wrong.</p>
<p><strong>Quantum Is Weird</strong></p>
<p>Read the New Yorker article, which is a nice popular writeup by Witt. Quantum is tricky, but his article is pretty straightforward.</p>
<p>Witt&#8217;s main focus is on the potential to build quantum computers that can solve real problems. The goal is of course to make quantum computers that can handle more and more qubits. Witt says this will make: Quantum physics win the Nobel prizes; Quantum chemistry will write the checks. Tens of billions of dollars are being invested in searching for ways to make such quantum computers. The <a href="https://thequantuminsider.com">investments</a> are by existing huge companies as well as new startups.</p>
<p><strong>Quantum Is Powerful?</strong></p>
<p>Witt assumes the usual view that classic computers are weaker than quantum computers. This is likely to be the case; it is the main viewpoint, but it is open. It could be that quantum computers could indeed be efficiently simulated by classic computers. That is still an open problem. See list of blogs on quantum for the main view.</p>
<p>We cannot prove that PSPACE is more powerful than P=POLYTIME. This is believed by most, but it is open. It could be the case that they are equal. If that is true, then Shor&#8217;s factoring algorithm is in P and other shocks happen. But it could be true.</p>
<p>Take a look at the recent <em>A Closer Look at Some Recent Proof Compression-Related Claims</em> <a href="https://arxiv.org/pdf/2212.12150.pdf}{https://arxiv.org/pdf/2212.12150.pdf">paper</a> by Michael Chavrimootoo, Ethan Ferland, Erin Gibson, Ashley Wilson. They show that a claimed proof that resolves a related open problem fails. But it could be possible via some other argument. It is interesting that people believe they have an approach to such results&#8212;even if their arguments are wrong.</p>
<p><strong>Open Problems</strong></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/just2/" rel="attachment wp-att-21075"><img data-attachment-id="21075" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/just2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?fit=225%2C225&amp;ssl=1" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="just2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?fit=225%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?fit=225%2C225&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?resize=225%2C225&#038;ssl=1" alt="" width="225" height="225" class="aligncenter size-full wp-image-21075" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?w=225&amp;ssl=1 225w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1" /></a></p>
<p>Are we nuts to point out that quantum computers could be no more powerful than classic computers? Are the billions of dollars being spent on quantum computers foolish? What do you think? Should some resources be spent on advances in classic algorithms?</p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-11T13:25:38Z">Saturday, February 11 2023, 13:25</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, February 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04322'>Quantum free games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anand Natarajan, Tina Zhang</p><p>The complexity of free games with two or more classical players was
essentially settled by Aaronson, Impagliazzo, and Moshkovitz (CCC'14). There
are two complexity classes that can be considered quantum analogues of
classical free games: (1) AM*, the multiprover interactive proof class
corresponding to free games with entangled players, and, somewhat less
obviously, (2) BellQMA(2), the class of quantum Merlin-Arthur proof systems
with two unentangled Merlins, whose proof states are separately measured by
Arthur. In this work, we make significant progress towards a tight
characterization of both of these classes. 1. We show a BellQMA(2) protocol for
3SAT on $n$ variables, where the total amount of communication is
$\tilde{O}(\sqrt{n})$. This answers an open question of Chen and Drucker (2010)
and also shows, conditional on ETH, that the algorithm of Brand\~{a}o,
Christandl and Yard (STOC'11) is tight up to logarithmic factors. 2. We show
that $\mathsf{AM}^*[n_{\text{provers}} = 2, q = O(1), a =\mathrm{poly}\log(n)]
= \mathsf{RE}$, i.e. that free entangled games with constant-sized questions
are as powerful as general entangled games. Our result is a significant
improvement over the headline result of Ji et al. (2020), whose MIP* protocol
for the halting problem has $\mathrm{poly}(n)$-sized questions and answers. 3.
We obtain a zero-gap AM* protocol for a $\Pi_2$ complete language with
constant-size questions and almost logarithmically large answers, improving on
the headline result of Mousavi, Nezhadi and Yuen (STOC'22). 4. Using a
connection to the nonuniform complexity of the halting problem we show that any
MIP* protocol for RE requires $\Omega(\log n)$ bits of communication. It
follows that our results in item 3 are optimal up to an $O(\log^* n)$ factor,
and that the gapless compression theorems of MNY'22 are asymptotically optimal.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Natarajan_A/0/1/0/all/0/1">Anand Natarajan</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhang_T/0/1/0/all/0/1">Tina Zhang</a></p><p>The complexity of free games with two or more classical players was
essentially settled by Aaronson, Impagliazzo, and Moshkovitz (CCC'14). There
are two complexity classes that can be considered quantum analogues of
classical free games: (1) AM*, the multiprover interactive proof class
corresponding to free games with entangled players, and, somewhat less
obviously, (2) BellQMA(2), the class of quantum Merlin-Arthur proof systems
with two unentangled Merlins, whose proof states are separately measured by
Arthur. In this work, we make significant progress towards a tight
characterization of both of these classes. 1. We show a BellQMA(2) protocol for
3SAT on $n$ variables, where the total amount of communication is
$\tilde{O}(\sqrt{n})$. This answers an open question of Chen and Drucker (2010)
and also shows, conditional on ETH, that the algorithm of Brand\~{a}o,
Christandl and Yard (STOC'11) is tight up to logarithmic factors. 2. We show
that $\mathsf{AM}^*[n_{\text{provers}} = 2, q = O(1), a =\mathrm{poly}\log(n)]
= \mathsf{RE}$, i.e. that free entangled games with constant-sized questions
are as powerful as general entangled games. Our result is a significant
improvement over the headline result of Ji et al. (2020), whose MIP* protocol
for the halting problem has $\mathrm{poly}(n)$-sized questions and answers. 3.
We obtain a zero-gap AM* protocol for a $\Pi_2$ complete language with
constant-size questions and almost logarithmically large answers, improving on
the headline result of Mousavi, Nezhadi and Yuen (STOC'22). 4. Using a
connection to the nonuniform complexity of the halting problem we show that any
MIP* protocol for RE requires $\Omega(\log n)$ bits of communication. It
follows that our results in item 3 are optimal up to an $O(\log^* n)$ factor,
and that the gapless compression theorems of MNY'22 are asymptotically optimal.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04482'>Secret Sharing on Superconcentrator</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuan Li</p><p>Using information inequalities, we prove any unrestricted arithmetic circuits
computing the shares of any $(t, n)$-threshold secret sharing scheme must
satisfy some superconcentrator-like connection properties. In the reverse
direction, we prove, when the underlying field is large enough, any graph
satisfying these connection properties can be turned into a linear arithmetic
circuit computing the shares of a $(t, n)$-threshold secret sharing scheme.
Specifically, $n$ shares can be computed by a linear arithmetic circuits with
$O(n)$ wires in depth $O(\alpha(t, n))$, where $\alpha(t, n)$ is the
two-parameter version of the inverse Ackermann function. For example, when $n
\ge t^{2.5}$, depth $2$ would be enough; when $n \ge t \log^{2.5} t$, depth 3
would be enough.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuan Li</a></p><p>Using information inequalities, we prove any unrestricted arithmetic circuits
computing the shares of any $(t, n)$-threshold secret sharing scheme must
satisfy some superconcentrator-like connection properties. In the reverse
direction, we prove, when the underlying field is large enough, any graph
satisfying these connection properties can be turned into a linear arithmetic
circuit computing the shares of a $(t, n)$-threshold secret sharing scheme.
Specifically, $n$ shares can be computed by a linear arithmetic circuits with
$O(n)$ wires in depth $O(\alpha(t, n))$, where $\alpha(t, n)$ is the
two-parameter version of the inverse Ackermann function. For example, when $n
\ge t^{2.5}$, depth $2$ would be enough; when $n \ge t \log^{2.5} t$, depth 3
would be enough.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04522'>Hardness of monadic second-order formulae over succinct graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guilhem Gamard (LORIA), Pierre Guillon (I2M), K&#xe9;vin Perrot (LIS), Guillaume Theyssier (I2M)</p><p>Our main result is a succinct counterpoint to Courcelle's meta-theorem as
follows: every arborescent monadic second-order (MSO) property is either
NP-hard or coNP-hard over graphs given by succinct representations. Succint
representations are Boolean circuits computing the adjacency relation.
Arborescent properties are those which have infinitely many models and
countermodels with bounded treewidth. We actually prove this result in the
terminology of automata network, which is a generalization of finite cellular
automata over arbitrary graphs. This model arose from the biological
modelization of neural networks and gene regulation networks. Our result states
that every arborescent MSO property on the transition graph of automata
networks is either NP-hard or coNP-hard. Moreover, we explore what happens when
the arborescence condition is dropped and show that, under a reasonable
complexity assumption, the previous dichotomy fails, even for questions
expressible in first-order logic.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gamard_G/0/1/0/all/0/1">Guilhem Gamard</a> (LORIA), <a href="http://arxiv.org/find/cs/1/au:+Guillon_P/0/1/0/all/0/1">Pierre Guillon</a> (I2M), <a href="http://arxiv.org/find/cs/1/au:+Perrot_K/0/1/0/all/0/1">K&#xe9;vin Perrot</a> (LIS), <a href="http://arxiv.org/find/cs/1/au:+Theyssier_G/0/1/0/all/0/1">Guillaume Theyssier</a> (I2M)</p><p>Our main result is a succinct counterpoint to Courcelle's meta-theorem as
follows: every arborescent monadic second-order (MSO) property is either
NP-hard or coNP-hard over graphs given by succinct representations. Succint
representations are Boolean circuits computing the adjacency relation.
Arborescent properties are those which have infinitely many models and
countermodels with bounded treewidth. We actually prove this result in the
terminology of automata network, which is a generalization of finite cellular
automata over arbitrary graphs. This model arose from the biological
modelization of neural networks and gene regulation networks. Our result states
that every arborescent MSO property on the transition graph of automata
networks is either NP-hard or coNP-hard. Moreover, we explore what happens when
the arborescence condition is dropped and show that, under a reasonable
complexity assumption, the previous dichotomy fails, even for questions
expressible in first-order logic.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04731'>Find a witness or shatter: the landscape of computable PAC learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Valentino Delle Rose, Alexander Kozachinskiy, Cristobal Rojas, Tomasz Steifer</p><p>This paper contributes to the study of CPAC learnability -- a computable
version of PAC learning -- by solving three open questions from recent papers.
Firstly, we prove that every improperly CPAC learnable class is contained in a
class which is properly CPAC learnable with polynomial sample complexity. This
confirms a conjecture by Agarwal et al (COLT 2021). Secondly, we show that
there exists a decidable class of hypothesis which is properly CPAC learnable,
but only with uncomputably fast growing sample complexity. This solves a
question from Sterkenburg (COLT 2022). Finally, we construct a decidable class
of finite Littlestone dimension which is not improperly CPAC learnable,
strengthening a recent result of Sterkenburg (2022) and answering a question
posed by Hasrati and Ben-David (ALT 2023). Together with previous work, our
results provide a complete landscape for the learnability problem in the CPAC
setting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rose_V/0/1/0/all/0/1">Valentino Delle Rose</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozachinskiy_A/0/1/0/all/0/1">Alexander Kozachinskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Rojas_C/0/1/0/all/0/1">Cristobal Rojas</a>, <a href="http://arxiv.org/find/cs/1/au:+Steifer_T/0/1/0/all/0/1">Tomasz Steifer</a></p><p>This paper contributes to the study of CPAC learnability -- a computable
version of PAC learning -- by solving three open questions from recent papers.
Firstly, we prove that every improperly CPAC learnable class is contained in a
class which is properly CPAC learnable with polynomial sample complexity. This
confirms a conjecture by Agarwal et al (COLT 2021). Secondly, we show that
there exists a decidable class of hypothesis which is properly CPAC learnable,
but only with uncomputably fast growing sample complexity. This solves a
question from Sterkenburg (COLT 2022). Finally, we construct a decidable class
of finite Littlestone dimension which is not improperly CPAC learnable,
strengthening a recent result of Sterkenburg (2022) and answering a question
posed by Hasrati and Ben-David (ALT 2023). Together with previous work, our
results provide a complete landscape for the learnability problem in the CPAC
setting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04749'>Quantum Advantage from One-Way Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tomoyuki Morimae, Takashi Yamakawa</p><p>We demonstrate quantum advantage with several basic assumptions, specifically
based on only the existence of OWFs. We introduce inefficient-verifier proofs
of quantumness (IV-PoQ), and construct it from classical bit commitments.
IV-PoQ is an interactive protocol between a verifier and a quantum prover
consisting of two phases. In the first phase, the verifier is probabilistic
polynomial-time, and it interacts with the prover. In the second phase, the
verifier becomes inefficient, and makes its decision based on the transcript of
the first phase. If the prover is honest, the inefficient verifier accepts with
high probability, but any classical malicious prover only has a small
probability of being accepted by the inefficient verifier. Our construction
demonstrates the following results: (1)If one-way functions exist, then IV-PoQ
exist. (2)If distributional collision-resistant hash functions exist (which
exist if hard-on-average problems in $\mathbf{SZK}$ exist), then constant-round
IV-PoQ exist. We also demonstrate quantum advantage based on worst-case-hard
assumptions. We define auxiliary-input IV-PoQ (AI-IV-PoQ) that only require
that for any malicious prover, there exist infinitely many auxiliary inputs
under which the prover cannot cheat. We construct AI-IV-PoQ from an
auxiliary-input version of commitments in a similar way, showing that (1)If
auxiliary-input one-way functions exist (which exist if
$\mathbf{CZK}\not\subseteq\mathbf{BPP}$), then AI-IV-PoQ exist. (2)If
auxiliary-input collision-resistant hash functions exist (which is equivalent
to $\mathbf{PWPP}\nsubseteq \mathbf{FBPP}$) or $\mathbf{SZK}\nsubseteq
\mathbf{BPP}$, then constant-round AI-IV-PoQ exist.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Morimae_T/0/1/0/all/0/1">Tomoyuki Morimae</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yamakawa_T/0/1/0/all/0/1">Takashi Yamakawa</a></p><p>We demonstrate quantum advantage with several basic assumptions, specifically
based on only the existence of OWFs. We introduce inefficient-verifier proofs
of quantumness (IV-PoQ), and construct it from classical bit commitments.
IV-PoQ is an interactive protocol between a verifier and a quantum prover
consisting of two phases. In the first phase, the verifier is probabilistic
polynomial-time, and it interacts with the prover. In the second phase, the
verifier becomes inefficient, and makes its decision based on the transcript of
the first phase. If the prover is honest, the inefficient verifier accepts with
high probability, but any classical malicious prover only has a small
probability of being accepted by the inefficient verifier. Our construction
demonstrates the following results: (1)If one-way functions exist, then IV-PoQ
exist. (2)If distributional collision-resistant hash functions exist (which
exist if hard-on-average problems in $\mathbf{SZK}$ exist), then constant-round
IV-PoQ exist. We also demonstrate quantum advantage based on worst-case-hard
assumptions. We define auxiliary-input IV-PoQ (AI-IV-PoQ) that only require
that for any malicious prover, there exist infinitely many auxiliary inputs
under which the prover cannot cheat. We construct AI-IV-PoQ from an
auxiliary-input version of commitments in a similar way, showing that (1)If
auxiliary-input one-way functions exist (which exist if
$\mathbf{CZK}\not\subseteq\mathbf{BPP}$), then AI-IV-PoQ exist. (2)If
auxiliary-input collision-resistant hash functions exist (which is equivalent
to $\mathbf{PWPP}\nsubseteq \mathbf{FBPP}$) or $\mathbf{SZK}\nsubseteq
\mathbf{BPP}$, then constant-round AI-IV-PoQ exist.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04462'>Nonlinear Random Matrices and Applications to the Sum of Squares Hierarchy</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Goutham Rajendran</p><p>We develop new tools in the theory of nonlinear random matrices and apply
them to study the performance of the Sum of Squares (SoS) hierarchy on
average-case problems.
</p>
<p>The SoS hierarchy is a powerful optimization technique that has achieved
tremendous success for various problems in combinatorial optimization, robust
statistics and machine learning. It's a family of convex relaxations that lets
us smoothly trade off running time for approximation guarantees. In recent
works, it's been shown to be extremely useful for recovering structure in high
dimensional noisy data. It also remains our best approach towards refuting the
notorious Unique Games Conjecture.
</p>
<p>In this work, we analyze the performance of the SoS hierarchy on fundamental
problems stemming from statistics, theoretical computer science and statistical
physics. In particular, we show subexponential-time SoS lower bounds for the
problems of the Sherrington-Kirkpatrick Hamiltonian, Planted Slightly Denser
Subgraph, Tensor Principal Components Analysis and Sparse Principal Components
Analysis. These SoS lower bounds involve analyzing large random matrices,
wherein lie our main contributions. These results offer strong evidence for the
truth of and insight into the low-degree likelihood ratio hypothesis, an
important conjecture that predicts the power of bounded-time algorithms for
hypothesis testing.
</p>
<p>We also develop general-purpose tools for analyzing the behavior of random
matrices which are functions of independent random variables. Towards this, we
build on and generalize the matrix variant of the Efron-Stein inequalities. In
particular, our general theorem on matrix concentration recovers various
results that have appeared in the literature. We expect these random matrix
theory ideas to have other significant applications.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rajendran_G/0/1/0/all/0/1">Goutham Rajendran</a></p><p>We develop new tools in the theory of nonlinear random matrices and apply
them to study the performance of the Sum of Squares (SoS) hierarchy on
average-case problems.
</p>
<p>The SoS hierarchy is a powerful optimization technique that has achieved
tremendous success for various problems in combinatorial optimization, robust
statistics and machine learning. It's a family of convex relaxations that lets
us smoothly trade off running time for approximation guarantees. In recent
works, it's been shown to be extremely useful for recovering structure in high
dimensional noisy data. It also remains our best approach towards refuting the
notorious Unique Games Conjecture.
</p>
<p>In this work, we analyze the performance of the SoS hierarchy on fundamental
problems stemming from statistics, theoretical computer science and statistical
physics. In particular, we show subexponential-time SoS lower bounds for the
problems of the Sherrington-Kirkpatrick Hamiltonian, Planted Slightly Denser
Subgraph, Tensor Principal Components Analysis and Sparse Principal Components
Analysis. These SoS lower bounds involve analyzing large random matrices,
wherein lie our main contributions. These results offer strong evidence for the
truth of and insight into the low-degree likelihood ratio hypothesis, an
important conjecture that predicts the power of bounded-time algorithms for
hypothesis testing.
</p>
<p>We also develop general-purpose tools for analyzing the behavior of random
matrices which are functions of independent random variables. Towards this, we
build on and generalize the matrix variant of the Efron-Stein inequalities. In
particular, our general theorem on matrix concentration recovers various
results that have appeared in the literature. We expect these random matrix
theory ideas to have other significant applications.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04378'>Fast Parallel Degree+1 List Coloring</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sam Coy, Artur Czumaj, Peter Davies, Gopinath Mishra</p><p>Graph coloring problems are arguably among the most fundamental graph
problems in parallel and distributed computing with numerous applications. In
particular, in recent years the classical ($\Delta+1$)-coloring problem became
a benchmark problem to study the impact of local computation for parallel and
distributed algorithms. In this work, we study the parallel complexity of a
generalization of the ($\Delta+1$)-coloring problem: the problem of
(degree+1)-list coloring (${\mathsf{D1LC}}$), where each node has an input
palette of acceptable colors, of size one more than its degree, and the
objective is to find a proper coloring using these palettes.
</p>
<p>In a recent work, Halld\'orsson et al. (STOC'22) presented a randomized
$O(\log^3\log n)$-rounds distributed algorithm for ${\mathsf{D1LC}}$ in the
${\mathsf{LOCAL}}$ model, matching for the first time the state-of-the art
complexity for $(\Delta+1)$-coloring due to Chang et al. (SICOMP'20).
</p>
<p>In this paper, we obtain a similar connection for $\mathsf{D1LC}$ in the
Massively Parallel Computation (${\mathsf{MPC}}$) model with sublinear local
space: we present a randomized $O(\log\log\log n)$-round ${\mathsf{MPC}}$
algorithm for ${\mathsf{D1LC}}$, matching the state-of-the art ${\mathsf{MPC}}$
algorithm for the $(\Delta+1)$-coloring problem. We also show that our
algorithm can be efficiently derandomized.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Coy_S/0/1/0/all/0/1">Sam Coy</a>, <a href="http://arxiv.org/find/cs/1/au:+Czumaj_A/0/1/0/all/0/1">Artur Czumaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Davies_P/0/1/0/all/0/1">Peter Davies</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_G/0/1/0/all/0/1">Gopinath Mishra</a></p><p>Graph coloring problems are arguably among the most fundamental graph
problems in parallel and distributed computing with numerous applications. In
particular, in recent years the classical ($\Delta+1$)-coloring problem became
a benchmark problem to study the impact of local computation for parallel and
distributed algorithms. In this work, we study the parallel complexity of a
generalization of the ($\Delta+1$)-coloring problem: the problem of
(degree+1)-list coloring (${\mathsf{D1LC}}$), where each node has an input
palette of acceptable colors, of size one more than its degree, and the
objective is to find a proper coloring using these palettes.
</p>
<p>In a recent work, Halld\'orsson et al. (STOC'22) presented a randomized
$O(\log^3\log n)$-rounds distributed algorithm for ${\mathsf{D1LC}}$ in the
${\mathsf{LOCAL}}$ model, matching for the first time the state-of-the art
complexity for $(\Delta+1)$-coloring due to Chang et al. (SICOMP'20).
</p>
<p>In this paper, we obtain a similar connection for $\mathsf{D1LC}$ in the
Massively Parallel Computation (${\mathsf{MPC}}$) model with sublinear local
space: we present a randomized $O(\log\log\log n)$-round ${\mathsf{MPC}}$
algorithm for ${\mathsf{D1LC}}$, matching the state-of-the art ${\mathsf{MPC}}$
algorithm for the $(\Delta+1)$-coloring problem. We also show that our
algorithm can be efficiently derandomized.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04384'>SF-SGL: Solver-Free Spectral Graph Learning from Linear Measurements</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ying Zhang, Zhiqiang Zhao, Zhuo Feng</p><p>This work introduces a highly-scalable spectral graph densification framework
(SGL) for learning resistor networks with linear measurements, such as node
voltages and currents. We show that the proposed graph learning approach is
equivalent to solving the classical graphical Lasso problems with
Laplacian-like precision matrices. We prove that given $O(\log N)$ pairs of
voltage and current measurements, it is possible to recover sparse $N$-node
resistor networks that can well preserve the effective resistance distances on
the original graph. In addition, the learned graphs also preserve the
structural (spectral) properties of the original graph, which can potentially
be leveraged in many circuit design and optimization tasks.
</p>
<p>To achieve more scalable performance, we also introduce a solver-free method
(SF-SGL) that exploits multilevel spectral approximation of the graphs and
allows for a scalable and flexible decomposition of the entire graph spectrum
(to be learned) into multiple different eigenvalue clusters (frequency bands).
Such a solver-free approach allows us to more efficiently identify the most
spectrally-critical edges for reducing various ranges of spectral embedding
distortions. Through extensive experiments for a variety of real-world test
cases, we show that the proposed approach is highly scalable for learning
sparse resistor networks without sacrificing solution quality. We also
introduce a data-driven EDA algorithm for vectorless power/thermal integrity
verifications to allow estimating worst-case voltage/temperature (gradient)
distributions across the entire chip by leveraging a few voltage/temperature
measurements.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Ying Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhiqiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhuo Feng</a></p><p>This work introduces a highly-scalable spectral graph densification framework
(SGL) for learning resistor networks with linear measurements, such as node
voltages and currents. We show that the proposed graph learning approach is
equivalent to solving the classical graphical Lasso problems with
Laplacian-like precision matrices. We prove that given $O(\log N)$ pairs of
voltage and current measurements, it is possible to recover sparse $N$-node
resistor networks that can well preserve the effective resistance distances on
the original graph. In addition, the learned graphs also preserve the
structural (spectral) properties of the original graph, which can potentially
be leveraged in many circuit design and optimization tasks.
</p>
<p>To achieve more scalable performance, we also introduce a solver-free method
(SF-SGL) that exploits multilevel spectral approximation of the graphs and
allows for a scalable and flexible decomposition of the entire graph spectrum
(to be learned) into multiple different eigenvalue clusters (frequency bands).
Such a solver-free approach allows us to more efficiently identify the most
spectrally-critical edges for reducing various ranges of spectral embedding
distortions. Through extensive experiments for a variety of real-world test
cases, we show that the proposed approach is highly scalable for learning
sparse resistor networks without sacrificing solution quality. We also
introduce a data-driven EDA algorithm for vectorless power/thermal integrity
verifications to allow estimating worst-case voltage/temperature (gradient)
distributions across the entire chip by leveraging a few voltage/temperature
measurements.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04475'>Locally consistent decomposition of strings with applications to edit distance sketching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sudatta Bhattacharya, Michal Kouck&#xfd;</p><p>In this paper we provide a new locally consistent decomposition of strings.
Each string $x$ is decomposed into blocks that can be described by grammars of
size $\widetilde{O}(k)$ (using some amount of randomness). If we take two
strings $x$ and $y$ of edit distance at most $k$ then their block decomposition
uses the same number of grammars and the $i$-th grammar of $x$ is the same as
the $i$-th grammar of $y$ except for at most $k$ indexes $i$. The edit distance
of $x$ and $y$ equals to the sum of edit distances of pairs of blocks where $x$
and $y$ differ. Our decomposition can be used to design a sketch of size
$\widetilde{O}(k^2)$ for edit distance, and also a rolling sketch for edit
distance of size $\widetilde{O}(k^2)$. The rolling sketch allows to update the
sketched string by appending a symbol or removing a symbol from the beginning
of the string.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1">Sudatta Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Koucky_M/0/1/0/all/0/1">Michal Kouck&#xfd;</a></p><p>In this paper we provide a new locally consistent decomposition of strings.
Each string $x$ is decomposed into blocks that can be described by grammars of
size $\widetilde{O}(k)$ (using some amount of randomness). If we take two
strings $x$ and $y$ of edit distance at most $k$ then their block decomposition
uses the same number of grammars and the $i$-th grammar of $x$ is the same as
the $i$-th grammar of $y$ except for at most $k$ indexes $i$. The edit distance
of $x$ and $y$ equals to the sum of edit distances of pairs of blocks where $x$
and $y$ differ. Our decomposition can be used to design a sketch of size
$\widetilde{O}(k^2)$ for edit distance, and also a rolling sketch for edit
distance of size $\widetilde{O}(k^2)$. The rolling sketch allows to update the
sketched string by appending a symbol or removing a symbol from the beginning
of the string.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04496'>Dual Algorithmic Reasoning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Danilo Numeroso, Davide Bacciu, Petar Veli&#x10d;kovi&#x107;</p><p>Neural Algorithmic Reasoning is an emerging area of machine learning which
seeks to infuse algorithmic computation in neural networks, typically by
training neural models to approximate steps of classical algorithms. In this
context, much of the current work has focused on learning reachability and
shortest path graph algorithms, showing that joint learning on similar
algorithms is beneficial for generalisation. However, when targeting more
complex problems, such similar algorithms become more difficult to find. Here,
we propose to learn algorithms by exploiting duality of the underlying
algorithmic problem. Many algorithms solve optimisation problems. We
demonstrate that simultaneously learning the dual definition of these
optimisation problems in algorithmic learning allows for better learning and
qualitatively better solutions. Specifically, we exploit the max-flow min-cut
theorem to simultaneously learn these two algorithms over synthetically
generated graphs, demonstrating the effectiveness of the proposed approach. We
then validate the real-world utility of our dual algorithmic reasoner by
deploying it on a challenging brain vessel classification task, which likely
depends on the vessels' flow properties. We demonstrate a clear performance
gain when using our model within such a context, and empirically show that
learning the max-flow and min-cut algorithms together is critical for achieving
such a result.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Numeroso_D/0/1/0/all/0/1">Danilo Numeroso</a>, <a href="http://arxiv.org/find/cs/1/au:+Bacciu_D/0/1/0/all/0/1">Davide Bacciu</a>, <a href="http://arxiv.org/find/cs/1/au:+Velickovic_P/0/1/0/all/0/1">Petar Veli&#x10d;kovi&#x107;</a></p><p>Neural Algorithmic Reasoning is an emerging area of machine learning which
seeks to infuse algorithmic computation in neural networks, typically by
training neural models to approximate steps of classical algorithms. In this
context, much of the current work has focused on learning reachability and
shortest path graph algorithms, showing that joint learning on similar
algorithms is beneficial for generalisation. However, when targeting more
complex problems, such similar algorithms become more difficult to find. Here,
we propose to learn algorithms by exploiting duality of the underlying
algorithmic problem. Many algorithms solve optimisation problems. We
demonstrate that simultaneously learning the dual definition of these
optimisation problems in algorithmic learning allows for better learning and
qualitatively better solutions. Specifically, we exploit the max-flow min-cut
theorem to simultaneously learn these two algorithms over synthetically
generated graphs, demonstrating the effectiveness of the proposed approach. We
then validate the real-world utility of our dual algorithmic reasoner by
deploying it on a challenging brain vessel classification task, which likely
depends on the vessels' flow properties. We demonstrate a clear performance
gain when using our model within such a context, and empirically show that
learning the max-flow and min-cut algorithms together is critical for achieving
such a result.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04581'>A Reduction from Chores Allocation to Job Scheduling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xin Huang, Erel Segal-Halevi</p><p>We consider allocating indivisible chores among agents with different cost
functions, such that all agents receive a cost of at most a constant factor
times their maximin share. The state-of-the-art was presented in In EC 2021 by
Huang and Lu. They presented a non-polynomial-time algorithm, called HFFD, that
attains an 11/9 approximation, and a polynomial-time algorithm that attains a
5/4 approximation.
</p>
<p>In this paper, we show that HFFD can be reduced to an algorithm called
MultiFit, developed by Coffman, Garey and Johnson in 1978 for makespan
minimization in job scheduling. Using this reduction, we prove that the
approximation ratio of HFFD is in fact equal to that of MultiFit, which is
known to be 13/11 in general, 20/17 for n at most 7, and 15/13 for n=3.
</p>
<p>Moreover, we develop an algorithm for (13/11+epsilon)-maximin-share
allocation for any epsilon&gt;0, with run-time polynomial in the problem size and
1/epsilon. For n=3, we can improve the algorithm to find a 15/13-maximin-share
allocation with run-time polynomial in the problem size. Thus, we have
practical algorithms that attain the best known approximation to maximin-share
chore allocation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Segal_Halevi_E/0/1/0/all/0/1">Erel Segal-Halevi</a></p><p>We consider allocating indivisible chores among agents with different cost
functions, such that all agents receive a cost of at most a constant factor
times their maximin share. The state-of-the-art was presented in In EC 2021 by
Huang and Lu. They presented a non-polynomial-time algorithm, called HFFD, that
attains an 11/9 approximation, and a polynomial-time algorithm that attains a
5/4 approximation.
</p>
<p>In this paper, we show that HFFD can be reduced to an algorithm called
MultiFit, developed by Coffman, Garey and Johnson in 1978 for makespan
minimization in job scheduling. Using this reduction, we prove that the
approximation ratio of HFFD is in fact equal to that of MultiFit, which is
known to be 13/11 in general, 20/17 for n at most 7, and 15/13 for n=3.
</p>
<p>Moreover, we develop an algorithm for (13/11+epsilon)-maximin-share
allocation for any epsilon&gt;0, with run-time polynomial in the problem size and
1/epsilon. For n=3, we can improve the algorithm to find a 15/13-maximin-share
allocation with run-time polynomial in the problem size. Thus, we have
practical algorithms that attain the best known approximation to maximin-share
chore allocation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04624'>A new width parameter of graphs based on edge cuts: $\alpha$-edge-crossing width</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yeonsu Chang, O-joung Kwon, Myounghwan Lee</p><p>We introduce graph width parameters, called $\alpha$-edge-crossing width and
edge-crossing width. These are defined in terms of the number of edges crossing
a bag of a tree-cut decomposition. They are motivated by edge-cut width,
recently introduced by Brand et al. (WG 2022). We show that edge-crossing width
is equivalent to the known parameter tree-partition-width. On the other hand,
$\alpha$-edge-crossing width is a new parameter; tree-cut width and
$\alpha$-edge-crossing width are incomparable, and they both lie between
tree-partition-width and edge-cut width.
</p>
<p>We provide an algorithm that, for a given $n$-vertex graph $G$ and integers
$k$ and $\alpha$, in time $2^{O((\alpha+k)\log (\alpha+k))}n^2$ either outputs
a tree-cut decomposition certifying that the $\alpha$-edge-crossing width of
$G$ is at most $2\alpha^2+5k$ or confirms that the $\alpha$-edge-crossing width
of $G$ is more than $k$. As applications, for every fixed $\alpha$, we obtain
FPT algorithms for the List Coloring and Precoloring Extension problems
parameterized by $\alpha$-edge-crossing width. They were known to be W[1]-hard
parameterized by tree-partition-width, and FPT parameterized by edge-cut width,
and we close the complexity gap between these two parameters.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yeonsu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_O/0/1/0/all/0/1">O-joung Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1">Myounghwan Lee</a></p><p>We introduce graph width parameters, called $\alpha$-edge-crossing width and
edge-crossing width. These are defined in terms of the number of edges crossing
a bag of a tree-cut decomposition. They are motivated by edge-cut width,
recently introduced by Brand et al. (WG 2022). We show that edge-crossing width
is equivalent to the known parameter tree-partition-width. On the other hand,
$\alpha$-edge-crossing width is a new parameter; tree-cut width and
$\alpha$-edge-crossing width are incomparable, and they both lie between
tree-partition-width and edge-cut width.
</p>
<p>We provide an algorithm that, for a given $n$-vertex graph $G$ and integers
$k$ and $\alpha$, in time $2^{O((\alpha+k)\log (\alpha+k))}n^2$ either outputs
a tree-cut decomposition certifying that the $\alpha$-edge-crossing width of
$G$ is at most $2\alpha^2+5k$ or confirms that the $\alpha$-edge-crossing width
of $G$ is more than $k$. As applications, for every fixed $\alpha$, we obtain
FPT algorithms for the List Coloring and Precoloring Extension problems
parameterized by $\alpha$-edge-crossing width. They were known to be W[1]-hard
parameterized by tree-partition-width, and FPT parameterized by edge-cut width,
and we close the complexity gap between these two parameters.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04747'>An $O(\log k)$-Approximation for Directed Steiner Tree in Planar Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zachary Friggstad, Ramin Mousavi</p><p>We present an $O(\log k)$-approximation for both the edge-weighted and
node-weighted versions of \DST in planar graphs where $k$ is the number of
terminals. We extend our approach to \MDST (in general graphs \MDST and \DST
are easily seen to be equivalent but in planar graphs this is not the case
necessarily) in which we get a $O(R+\log k)$-approximation for planar graphs
for where $R$ is the number of roots.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Friggstad_Z/0/1/0/all/0/1">Zachary Friggstad</a>, <a href="http://arxiv.org/find/cs/1/au:+Mousavi_R/0/1/0/all/0/1">Ramin Mousavi</a></p><p>We present an $O(\log k)$-approximation for both the edge-weighted and
node-weighted versions of \DST in planar graphs where $k$ is the number of
terminals. We extend our approach to \MDST (in general graphs \MDST and \DST
are easily seen to be equivalent but in planar graphs this is not the case
necessarily) in which we get a $O(R+\log k)$-approximation for planar graphs
for where $R$ is the number of roots.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04783'>$t$-sails and sparse hereditary classes of unbounded tree-width</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Cocks</p><p>It has long been known that the following basic objects are obstructions to
bounded tree-width: for arbitrarily large $t$, $(1)$ a subdivision of the
complete graph $K_t$, $(2)$ a subdivision of the complete bipartite graph
$K_{t,t}$, $(3)$ a subdivision of the $(t \times t)$-wall and $(4)$ a line
graph of a subdivision of the $(t \times t)$-wall. We are now able to add a
further \emph{boundary object} to this list, a subdivision of a
\emph{$t$-sail}. We identify new hereditary graph classes of unbounded
tree-width that do not contain any of the four basic obstructions but instead
contain arbitrarily large $t$-sails or subdivisions of a $t$-sail. We also show
that these sparse graph classes do not contain a minimal class of unbounded
tree-width.
</p>
<p>These results have been obtained by studying \emph{path-star} graph classes,
a type of sparse hereditary graph class formed by combining a path (or union of
paths) with a forest of stars, characterised by an infinite word over a
possibly infinite alphabet.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Cocks_D/0/1/0/all/0/1">Daniel Cocks</a></p><p>It has long been known that the following basic objects are obstructions to
bounded tree-width: for arbitrarily large $t$, $(1)$ a subdivision of the
complete graph $K_t$, $(2)$ a subdivision of the complete bipartite graph
$K_{t,t}$, $(3)$ a subdivision of the $(t \times t)$-wall and $(4)$ a line
graph of a subdivision of the $(t \times t)$-wall. We are now able to add a
further \emph{boundary object} to this list, a subdivision of a
\emph{$t$-sail}. We identify new hereditary graph classes of unbounded
tree-width that do not contain any of the four basic obstructions but instead
contain arbitrarily large $t$-sails or subdivisions of a $t$-sail. We also show
that these sparse graph classes do not contain a minimal class of unbounded
tree-width.
</p>
<p>These results have been obtained by studying \emph{path-star} graph classes,
a type of sparse hereditary graph class formed by combining a path (or union of
paths) with a forest of stars, characterised by an infinite word over a
possibly infinite alphabet.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, February 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/why-cant-little-chatty-do-math.html'>Why Can't Little Chatty Do Math?</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Despite OpenAI's claim that ChatGPT has improved mathematical capabilities, we don't get far multiplying large numbers.<br>♦<br>Typical for ChatGPT, the answer passes the smell test. It has the right number of digits and has correct first and last couple of digits. But the real answer is&nbsp;646382140418841070,&nbsp; quite different from the number given.<br>As far as I know, multiplication isn't known to be in&nbsp;TC0, the complexity class that roughly corresponds to neural nets. [Note Added: Multiplication is in TC0. See comments.] Also functions learned by deep learning can often be inverted by deep learning. So if AI can learn how to multiply, it might also learn how to factor.&nbsp;<br>But what about addition? Addition is known to be in TC0 and ChatGPT performs better.<br>♦<br>The correct answer is&nbsp;1612502411, only one digit off but still wrong. The TC0 algorithm needs to do some tricks for carry lookahead that is probably hard to learn. Addition is easier if you work from right to left, but ChatGPT has trouble reversing numbers. There's a limit to its self-attention.<br>♦<br><br>ChatGPT can't multiply but it does know how to write a program to multiply.<br>♦<br>It still claims the result will be the same as before. Running the program gives the correct answer&nbsp;646382140418841070.&nbsp;<br>ChatGPT is run on a general purpose computer, so one could hope a later version that could determine when its given a math question, write a program and run it. That's probably too dangerous--we would want to avoid a code injection vulnerability. But still it could use an API to WolframAlpha or some other math engine. Or a chess engine to play chess. Etc.&nbsp;<p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <div>Despite OpenAI's claim that ChatGPT has improved mathematical capabilities, we don't get far multiplying large numbers.</div><div><br /></div><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnHsNFxbQ6oNEW1qIr0bFD8Jw_ESAXGWVGYfpsQyeZVoVnhlOgUHS5lozsRweLvsHAe3MFc5GU4tWvOyU7IbcykpHEVL2fo5Pm7kMkz-WIb5khJqZhVyXv9mI9bvRhlI9n6Jl0T29uzy8nVlcCtrEki46W0We3IxOBaXYZZHB36dMopnKWPA/s887/mult.jpg" style="margin-left: 1em; margin-right: 1em;"><img alt="L:What is 866739766 * 745762645?  C:647733560997969470" border="0" data-original-height="191" data-original-width="887" height="86" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnHsNFxbQ6oNEW1qIr0bFD8Jw_ESAXGWVGYfpsQyeZVoVnhlOgUHS5lozsRweLvsHAe3MFc5GU4tWvOyU7IbcykpHEVL2fo5Pm7kMkz-WIb5khJqZhVyXv9mI9bvRhlI9n6Jl0T29uzy8nVlcCtrEki46W0We3IxOBaXYZZHB36dMopnKWPA/w400-h86/mult.jpg" width="400" /></a></div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">Typical for ChatGPT, the answer passes the smell test. It has the right number of digits and has correct first and last couple of digits. But the real answer is&nbsp;646382140418841070,&nbsp; quite different from the number given.</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">As far as I know, multiplication isn't known to be in&nbsp;<a href="https://complexityzoo.net/Complexity_Zoo:T#tc0">TC<sup>0</sup></a>, the complexity class that roughly corresponds to neural nets. [Note Added: Multiplication is in TC<sup>0</sup>. See <a href="https://blog.computationalcomplexity.org/2023/02/why-cant-little-chatty-do-math.html?showComment=1675963811947#c5283298584977635369">comments</a>.] Also functions learned by deep learning can often be inverted by deep learning. So if AI can learn how to multiply, it might also learn how to factor.&nbsp;</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">But what about addition? Addition is known to be in TC<sup>0</sup> and ChatGPT performs better.</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVo4fuwVf4sege-8Wm41_dOSQZvTeHhUB7Wn5oe3_OQZna0J-y2EmiBka5yq8ftdHPrG4Lth6SJyEcerSExsJpQm6DbsiKN9Hf49Fkcgf3XReVRCzYylbGfGJqzHmsCj8BF46UCv4DLWcIFfSnFrG41RoTtUCMb6YwaaP2V7nAC6LntsM26A/s897/add.jpg" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="193" data-original-width="897" height="86" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVo4fuwVf4sege-8Wm41_dOSQZvTeHhUB7Wn5oe3_OQZna0J-y2EmiBka5yq8ftdHPrG4Lth6SJyEcerSExsJpQm6DbsiKN9Hf49Fkcgf3XReVRCzYylbGfGJqzHmsCj8BF46UCv4DLWcIFfSnFrG41RoTtUCMb6YwaaP2V7nAC6LntsM26A/w400-h86/add.jpg" width="400" /></a></div><br /><div class="separator" style="clear: both; text-align: left;">The correct answer is&nbsp;1612502411, only one digit off but still wrong. The TC<sup>0</sup> algorithm needs to do some tricks for carry lookahead that is probably hard to learn. Addition is easier if you work from right to left, but ChatGPT has trouble reversing numbers. There's a limit to its self-attention.</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiVaCr_CJXUTeQUVDWj38LkVnI37p0u5P8_ABoOqBG5T4ymxwEUxlzc60UU9-YSCXSccpH1ICpDlJJ8KGuK8h7Olf4JmYdwsW2nd3kdEhmnm4mQe0HikFlmkiZt1v6Zj3jddoVV-waokMYLixiFYQAR4pV58e9s6ULshXUql32JuR5nIzd7Lg/s892/backwards.jpg" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="201" data-original-width="892" height="90" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiVaCr_CJXUTeQUVDWj38LkVnI37p0u5P8_ABoOqBG5T4ymxwEUxlzc60UU9-YSCXSccpH1ICpDlJJ8KGuK8h7Olf4JmYdwsW2nd3kdEhmnm4mQe0HikFlmkiZt1v6Zj3jddoVV-waokMYLixiFYQAR4pV58e9s6ULshXUql32JuR5nIzd7Lg/w400-h90/backwards.jpg" width="400" /></a></div><br /><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">ChatGPT can't multiply but it does know how to write a program to multiply.</div><br /><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjAtKeY7oA8q4mgvad016knm2noD1Nd7-Pk2wSicc_6fs-4nAF0f2LWInnmeV0sBnHB7sw92eeFbEfsXDCD1kNoebURfH4zziLhSbVVv-GKL0g_EwnE8A2PH8Qr5J12uC1xkYk16I6HwMdmmodECNEijrrSV5FeArwyLA1qKZ-3QdCC8lxOiQ/s907/python.jpg" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="528" data-original-width="907" height="233" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjAtKeY7oA8q4mgvad016knm2noD1Nd7-Pk2wSicc_6fs-4nAF0f2LWInnmeV0sBnHB7sw92eeFbEfsXDCD1kNoebURfH4zziLhSbVVv-GKL0g_EwnE8A2PH8Qr5J12uC1xkYk16I6HwMdmmodECNEijrrSV5FeArwyLA1qKZ-3QdCC8lxOiQ/w400-h233/python.jpg" width="400" /></a></div><br /><div>It still claims the result will be the same as before. Running the program gives the correct answer&nbsp;646382140418841070.&nbsp;</div><div><br /></div><div>ChatGPT is run on a general purpose computer, so one could hope a later version that could determine when its given a math question, write a program and run it. That's probably too dangerous--we would want to avoid a code injection vulnerability. But still it could use an API to WolframAlpha or some other math engine. Or a chess engine to play chess. Etc.&nbsp;</div><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T14:59:00Z">Thursday, February 09 2023, 14:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/02/09/mathematics-of-the-impossible-computational-complexity-chapter-4-reductions/'>Mathematics of the impossible: Computational Complexity, chapter 4, reductions</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          All posts in this series. A PDF version of this post will be published with a delay, but if you’d like to have it soon let me know. Contents 4 Reductions 4.1 Types of reductions 4.2 Reductions 4.2.1 Multiplication 4.2.2 3Sum 4.3 Reductions from 3Sat 4.4 Power hardness from SETH 4.5 Search problems 4.5.1 Fastest [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <hr />
<p><!--?xml version="1.0" encoding="iso-8859-1" ?--> <!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd--> <!-- html,xhtml,-css,NoFonts --></p>
<div class="maketitle">
<div class="date"><a href="https://emanueleviola.wordpress.com/tag/moti/">All posts in this series.</a><br />
A PDF version of this post will be published with a delay, but if you’d like to have it soon let me know.</div>
</div>
<h2 class="likechapterHead"><a id="x1-1000"></a>Contents</h2>
<div class="tableofcontents"><span class="chapterToc">4 <a id="QQ2-1-48" href="#x1-450004">Reductions</a></span><br />
<span class="sectionToc">4.1 <a id="QQ2-1-49" href="#x1-460004.1">Types of reductions</a></span><br />
<span class="sectionToc">4.2 <a id="QQ2-1-50" href="#x1-470004.2">Reductions</a></span><br />
<span class="subsectionToc">4.2.1 <a id="QQ2-1-51" href="#x1-480004.2.1">Multiplication</a></span><br />
<span class="subsectionToc">4.2.2 <a id="QQ2-1-52" href="#x1-490004.2.2">3Sum</a></span><br />
<span class="sectionToc">4.3 <a id="QQ2-1-53" href="#x1-500004.3">Reductions from 3Sat </a></span><br />
<span class="sectionToc">4.4 <a id="QQ2-1-54" href="#x1-510004.4">Power hardness from SETH</a></span><br />
<span class="sectionToc">4.5 <a id="QQ2-1-55" href="#x1-520004.5">Search problems</a></span><br />
<span class="subsectionToc">4.5.1 <a id="QQ2-1-56" href="#x1-530004.5.1">Fastest algorithm for Search-3Sat</a></span><br />
<span class="sectionToc">4.6 <a id="QQ2-1-57" href="#x1-540004.6">Gap-SAT: The PCP theorem </a></span><br />
<span class="sectionToc">4.7 <a id="QQ2-1-58" href="#x1-550004.7">Problems</a></span></div>
<div id="verbatim-1" class="verbatim"></div>
<p style="text-align: justify">
<h2 class="chapterHead"><span class="titlemark">Chapter&nbsp;4</span><br />
<a id="x1-450004"></a>Reductions</h2>
<div class="flushright">
<p style="text-align: justify"><img src="hamiltonian.png" alt="PIC" width="371" height="321"/></p>
</div>
<div class="flushright">
<p style="text-align: justify"><a href="https://xkcd.com/230/" rel="nofollow">https://xkcd.com/230/</a></p>
</div>
<p style="text-align: justify">One can relate the complexity of functions via <em>reductions</em>. This concept is so ingrained in common reasoning that giving it a name may feel, at times, strange. For in some sense pretty much everything proceeds by reductions. In any algorithms textbook, the majority of algorithms can be cast as reductions to algorithms presented earlier in the book, and so on. And it is worthwhile to emphasize now that, as we shall see below, reductions, even in the context of computing, have been used for millennia. For about a century reductions have been used in the context of undecidability in a modern way, starting with the incompleteness theorem in logic <span class="cite">[<a href="#XMR1549939">8</a>]</span>, whose proof reduces questions in logic to questions in arithmetic.</p>
<p style="text-align: justify">Perhaps one reason for the more recent interest in complexity reductions is that we can use them to relate problems that are tantalizingly close to problems that today we solve routinely on somewhat large scale inputs with computers, and that therefore appear to be just out of reach. By contrast, reductions in the context of undecidability tend to apply to problems that are completely out of reach, and in this sense remote from our immediate worries.</p>
<h3 class="sectionHead"><span class="titlemark">4.1 </span> <a id="x1-460004.1"></a>Types of reductions</h3>
<p style="text-align: justify">Informally, a reduction from a function <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> to a function <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> is a way to compute <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> given that we can compute <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" />. One can define reductions in different ways, depending on the overhead required to compute <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> given that we can compute <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" />. The most general type of reduction is simply an <em>implication</em>.</p>
<div style="text-align: center">
<p style="text-align: justify">
<div class="minipage">
<p style="text-align: justify"><b>General form of reduction from <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" />:</b></p>
<p style="text-align: justify">&nbsp;&nbsp;<b>If</b> <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> can be computed with resources <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> <b>then </b><img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> can be computed with resources <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" />.</p>
</div>
</div>
<p style="text-align: justify">A common setting is when <img src="https://s0.wp.com/latex.php?latex=X%3DY&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%3DY&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%3DY&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X=Y" class="latex" />. In this case the reduction allows us to stay within the same complexity class.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-46001r1"></a> <b>Definition</b> 4.1. </span>We say that <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> (or under <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> reductions) if</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+g%5Cin+X%5CRightarrow+f%5Cin+X.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+g%5Cin+X%5CRightarrow+f%5Cin+X.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+g%5Cin+X%5CRightarrow+f%5Cin+X.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} g&#92;in X&#92;Rightarrow f&#92;in X. &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">
</div>
<p style="text-align: justify">A further special and noteworthy case is when <img src="https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X=&#92;text {P}" class="latex" />, or <img src="https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X=&#92;text {BPP}" class="latex" />; in these cases the reduction can be interpreted as saying that if <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> is easy to compute than <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is too.But in general <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> may not be equal to <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" />. We will see examples of such implications for various <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" />.</p>
<p style="text-align: justify">It is sometimes useful to be more specific about how the implication is proved. For example, this is useful when inferring various properties of <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> from properties of <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" />, something which can be obscured by a stark implication. The following definition gives a specific way in which the implication can be proved.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-46002r2"></a> <b>Definition</b> 4.2. </span>We say that <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> <em>map reduces </em>to <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> (or via a map in <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" />) if there is <img src="https://s0.wp.com/latex.php?latex=M%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M&#92;in X" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3Dg%28M%28x%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3Dg%28M%28x%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3Dg%28M%28x%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)=g(M(x))" class="latex" /> for every <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-46003r1"></a> <b>Exercise</b> 4.1. </span>Suppose that <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> map reduces to <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" />.</p>
<p style="text-align: justify">(1) Suppose <img src="https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X=&#92;text {P}" class="latex" />. Show <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BX%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BX%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BX%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {X}" class="latex" />.</p>
<p style="text-align: justify">(2) Suppose <img src="https://s0.wp.com/latex.php?latex=X%3D%5Cbigcup+_%7Bd%7D%5Ctext+%7BTime%7D%28d%5Ccdot+n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%3D%5Cbigcup+_%7Bd%7D%5Ctext+%7BTime%7D%28d%5Ccdot+n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%3D%5Cbigcup+_%7Bd%7D%5Ctext+%7BTime%7D%28d%5Ccdot+n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X=&#92;bigcup _{d}&#92;text {Time}(d&#92;cdot n^{2})" class="latex" />. Can you still show that <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BX%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BX%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BX%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {X}" class="latex" />?</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Many reductions we shall see are not mapping reductions. In fact, our first example is not a mapping reduction.</p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">4.2 </span> <a id="x1-470004.2"></a>Reductions</h3>
<p style="text-align: justify">
<h4 class="subsectionHead"><span class="titlemark">4.2.1 </span> <a id="x1-480004.2.1"></a>Multiplication</h4>
<p style="text-align: justify">Summing two <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />-bit integers is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BCktGates%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BCktGates%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BCktGates%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {CktGates}(cn)" class="latex" /> (Exercise <a href="#x1-25005r8">2.8<!--tex4ht:ref: xca:sum-ckt --></a>). But the smallest circuit known for multiplication has <img src="https://s0.wp.com/latex.php?latex=%5Cge+cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge cn&#92;log n" class="latex" /> gates <span class="cite">[<a href="#X10.4007/annals.2021.193.2.4">10</a>]</span>. (The same situation holds for MTMs; over RAMs and related models multiplication can be done in time <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" /> <span class="cite">[<a href="journals/siamcomp/Schonhage80">21</a>]</span>.) It is a long-standing question whether we can multiply two <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />-bit integers with a linear-size circuit.</p>
<p style="text-align: justify">What about squaring integers? Is that harder or easier than multiplication? Obviously, if we can multiply two numbers we can also square a number: simply multiply it by itself. This is a trivial example of a reduction. What about the other way around? We can use a reduction established millennia ago by the Babylonians. They employed the equation</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5Ccdot+b%3D%5Cfrac+%7B%28a%2Bb%29%5E%7B2%7D-%28a-b%29%5E%7B2%7D%7D%7B4%7D%7E%7E%7E%7E%284.1%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5Ccdot+b%3D%5Cfrac+%7B%28a%2Bb%29%5E%7B2%7D-%28a-b%29%5E%7B2%7D%7D%7B4%7D%7E%7E%7E%7E%284.1%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5Ccdot+b%3D%5Cfrac+%7B%28a%2Bb%29%5E%7B2%7D-%28a-b%29%5E%7B2%7D%7D%7B4%7D%7E%7E%7E%7E%284.1%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} a&#92;cdot b=&#92;frac {(a+b)^{2}-(a-b)^{2}}{4}~~~~(4.1) &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">to reduce multiplication to squaring, plus some easy operations like addition and division by four. In our terminology we have the following.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-48001r3"></a> <b>Definition</b> 4.3. </span>Multiplication is the problem of computing the product of two <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />-bit integers. Squaring is the problem of computing the square of an <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />-bit integer.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-48002r1"></a> <b>Theorem</b> 4.1. </span>If Squaring has linear-size circuits then Multiplication has linear-size circuits.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>.&nbsp;</span>Suppose <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> computes Squaring. Then we can multiply using equation&nbsp;(??). Specifically, given <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b" class="latex" /> we use Exercise <a href="#x1-25005r8">2.8<!--tex4ht:ref: xca:sum-ckt --></a> to compute <img src="https://s0.wp.com/latex.php?latex=a%2Bb&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%2Bb&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%2Bb&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a+b" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=a-b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a-b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a-b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a-b" class="latex" />. (We haven’t seen subtraction or negative integers, but it’s similar to addition.) Then we run <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> on both of them. Finally, we again use Exercise <a href="#x1-25005r8">2.8<!--tex4ht:ref: xca:sum-ckt --></a> for computing their difference. It remains to divide by four. In binary, this is accomplished by ignoring the last two bits – which costs nothing on a circuit. <b>QED</b></p>
</div>
<p style="text-align: justify">
<h4 class="subsectionHead"><span class="titlemark">4.2.2 </span> <a id="x1-490004.2.2"></a>3Sum</h4>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49001r4"></a> <b>Definition</b> 4.4. </span> The <img src="https://s0.wp.com/latex.php?latex=3%5Ctext+%7BSum%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3%5Ctext+%7BSum%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3%5Ctext+%7BSum%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3&#92;text {Sum}" class="latex" /> problem: Given a list of integers, are there three integers that sum to <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" />?</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">It is easy to solve 3Sum in time <img src="https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn^{2}&#92;log n" class="latex" /> on a RAM. (We can first sort the integers then for each pair <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(a,b)" class="latex" /> we can do a binary search to check if <img src="https://s0.wp.com/latex.php?latex=-%28a%2Bb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=-%28a%2Bb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=-%28a%2Bb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="-(a+b)" class="latex" /> is also present.) The time can be improved <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}/&#92;log ^{c}n" class="latex" />.</p>
<p style="text-align: justify">3Sum is believed to require quadratic time.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49002r5"></a> <b>Definition</b> 4.5. </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSubquadraticTime%7D%3A%3D%5Cbigcup+_%7B%5Cepsilon+%3E0%7D%5Ctext+%7BTime%7D%28n%5E%7B2-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSubquadraticTime%7D%3A%3D%5Cbigcup+_%7B%5Cepsilon+%3E0%7D%5Ctext+%7BTime%7D%28n%5E%7B2-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BSubquadraticTime%7D%3A%3D%5Cbigcup+_%7B%5Cepsilon+%3E0%7D%5Ctext+%7BTime%7D%28n%5E%7B2-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {SubquadraticTime}:=&#92;bigcup _{&#92;epsilon &gt;0}&#92;text {Time}(n^{2-&#92;epsilon })" class="latex" />.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49003r1"></a> <b>Conjecture</b> 4.1. </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cnot+%5Cin+%5Ctext+%7BSubquadraticTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cnot+%5Cin+%5Ctext+%7BSubquadraticTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cnot+%5Cin+%5Ctext+%7BSubquadraticTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sum}&#92;not &#92;in &#92;text {SubquadraticTime}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">One can reduce 3Sum to a number of other interesting problem to infer that, under Conjecture <a href="#x1-49003r1">4.1<!--tex4ht:ref: conj:3sum --></a>, those problems require quadratic time too.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49004r6"></a> <b>Definition</b> 4.6. </span>The Collinearity problem: Given a list of points in the plane, are there three points on a line?</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49005r2"></a> <b>Theorem</b> 4.2. </span><span class="cite">[<a href="#XGajentaanO95">6</a>]</span> <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BCollinearity%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BCollinearity%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BCollinearity%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Collinearity}&#92;in &#92;text {SubquadraticTime&#92;ensuremath {&#92;Rightarrow &#92;text {3Sum}&#92;in &#92;text {SubquadraticTime}} (i.e., }" class="latex" />Conjecture <a href="#x1-49003r1">4.1<!--tex4ht:ref: conj:3sum --></a> is false).</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>.&nbsp;</span>We map instance <img src="https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Ca_%7B2%7D%2C%5Cldots+%2Ca_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Ca_%7B2%7D%2C%5Cldots+%2Ca_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Ca_%7B2%7D%2C%5Cldots+%2Ca_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a_{1},a_{2},&#92;ldots ,a_{n}" class="latex" /> of 3Sum to the points</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28a_%7B1%7D%2Ca_%7B1%7D%5E%7B3%7D%29%2C%28a_%7B2%7D%2Ca_%7B2%7D%5E%7B3%7D%29%2C%5Cldots+%2C%28a_%7Bn%7D%2Ca_%7Bn%7D%5E%7B3%7D%29%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28a_%7B1%7D%2Ca_%7B1%7D%5E%7B3%7D%29%2C%28a_%7B2%7D%2Ca_%7B2%7D%5E%7B3%7D%29%2C%5Cldots+%2C%28a_%7Bn%7D%2Ca_%7Bn%7D%5E%7B3%7D%29%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28a_%7B1%7D%2Ca_%7B1%7D%5E%7B3%7D%29%2C%28a_%7B2%7D%2Ca_%7B2%7D%5E%7B3%7D%29%2C%5Cldots+%2C%28a_%7Bn%7D%2Ca_%7Bn%7D%5E%7B3%7D%29%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} (a_{1},a_{1}^{3}),(a_{2},a_{2}^{3}),&#92;ldots ,(a_{n},a_{n}^{3}), &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">and solve Collinearity on those points.</p>
<p style="text-align: justify">To verify correctness, notice that points <img src="https://s0.wp.com/latex.php?latex=%28x%2Cx%5E%7B3%7D%29%2C%28y%2Cy%5E%7B3%7D%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cx%5E%7B3%7D%29%2C%28y%2Cy%5E%7B3%7D%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cx%5E%7B3%7D%29%2C%28y%2Cy%5E%7B3%7D%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,x^{3}),(y,y^{3})," class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%28z%2Cz%5E%7B3%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28z%2Cz%5E%7B3%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28z%2Cz%5E%7B3%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(z,z^{3})" class="latex" /> are on a line iff</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac+%7By%5E%7B3%7D-x%5E%7B3%7D%7D%7By-x%7D%3D%5Cfrac+%7Bz%5E%7B3%7D-x%5E%7B3%7D%7D%7Bz-x%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac+%7By%5E%7B3%7D-x%5E%7B3%7D%7D%7By-x%7D%3D%5Cfrac+%7Bz%5E%7B3%7D-x%5E%7B3%7D%7D%7Bz-x%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac+%7By%5E%7B3%7D-x%5E%7B3%7D%7D%7By-x%7D%3D%5Cfrac+%7Bz%5E%7B3%7D-x%5E%7B3%7D%7D%7Bz-x%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;frac {y^{3}-x^{3}}{y-x}=&#92;frac {z^{3}-x^{3}}{z-x}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">Because <img src="https://s0.wp.com/latex.php?latex=y%5E%7B3%7D-x%5E%7B3%7D%3D%28y-x%29%28y%5E%7B2%7D%2Byx%2Bx%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y%5E%7B3%7D-x%5E%7B3%7D%3D%28y-x%29%28y%5E%7B2%7D%2Byx%2Bx%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y%5E%7B3%7D-x%5E%7B3%7D%3D%28y-x%29%28y%5E%7B2%7D%2Byx%2Bx%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y^{3}-x^{3}=(y-x)(y^{2}+yx+x^{2})" class="latex" />, this condition is equivalent to</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%2Byx%2Bx%5E%7B2%7D%3Dz%5E%7B2%7D%2Bzx%2Bx%5E%7B2%7D%5CLeftrightarrow+%28x%2B%28y%2Bz%29%29%28y-z%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%2Byx%2Bx%5E%7B2%7D%3Dz%5E%7B2%7D%2Bzx%2Bx%5E%7B2%7D%5CLeftrightarrow+%28x%2B%28y%2Bz%29%29%28y-z%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%2Byx%2Bx%5E%7B2%7D%3Dz%5E%7B2%7D%2Bzx%2Bx%5E%7B2%7D%5CLeftrightarrow+%28x%2B%28y%2Bz%29%29%28y-z%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} y^{2}+yx+x^{2}=z^{2}+zx+x^{2}&#92;Leftrightarrow (x+(y+z))(y-z). &#92;end{aligned}" class="latex" /></div>
<p>Assuming <img src="https://s0.wp.com/latex.php?latex=y%5Cne+z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y%5Cne+z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y%5Cne+z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y&#92;ne z" class="latex" />, i.e., that the 3Sum instance consists of distinct numbers, this is equivalent to <img src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x+y+z=0" class="latex" />, as desired. (The case where there can be duplicates is left as an exercise.)</p>
<p style="text-align: justify">Note that the Collinearity instance has length linear in the 3Sum instance, and the result follows. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49006r2"></a> <b>Exercise</b> 4.2. </span>The Tripartite-3Sum problem: Given lists <img src="https://s0.wp.com/latex.php?latex=A_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A_{1}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=A_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A_{2}" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=A_%7B3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A_%7B3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A_%7B3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A_{3}" class="latex" /> of numbers, are there <img src="https://s0.wp.com/latex.php?latex=a_%7Bi%7D%5Cin+A_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a_%7Bi%7D%5Cin+A_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a_%7Bi%7D%5Cin+A_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a_{i}&#92;in A_{i}" class="latex" /> s.t.&nbsp;<img src="https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Ba_%7B2%7D%2Ba_%7B3%7D%3D0%3F&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Ba_%7B2%7D%2Ba_%7B3%7D%3D0%3F&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Ba_%7B2%7D%2Ba_%7B3%7D%3D0%3F&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a_{1}+a_{2}+a_{3}=0?" class="latex" /></p>
<p style="text-align: justify">Prove that Tripartite-3Sum is in subquadratic time iff 3Sum is.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">We now give a reduction in the other direction: We reduce a problem to 3Sum.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49007r7"></a> <b>Definition</b> 4.7. </span>The 3Cycle-Detection problem: Given the adjacency list of a directed graph, is there a cycle of length 3?</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">This problem can be solved in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%5Comega+%2F%28%5Comega+%2B1%29%2Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%5Comega+%2F%28%5Comega+%2B1%29%2Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%5Comega+%2F%28%5Comega+%2B1%29%2Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2&#92;omega /(&#92;omega +1)+o(1)}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%5Comega+%3C2.373&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Comega+%3C2.373&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Comega+%3C2.373&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;omega &lt;2.373" class="latex" /> is the exponent of matrix multiplication. If <img src="https://s0.wp.com/latex.php?latex=%5Comega+%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Comega+%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Comega+%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;omega =2" class="latex" /> then the bound is <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1.3%5Cbar+%7B3%7D%2Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B1.3%5Cbar+%7B3%7D%2Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B1.3%5Cbar+%7B3%7D%2Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{1.3&#92;bar {3}+o(1)}" class="latex" />. It is not known if any subquadratic algorithm for 3Sum would improve these bounds. However, we can show that an improvement follows if <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sum}&#92;in &#92;text {Time}(n^{1+&#92;epsilon})" class="latex" /> for a small enough <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49008r3"></a> <b>Theorem</b> 4.3. </span><span class="cite">[<a href="#XViola-xxx">26</a>]</span> <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BTime%7D%28t%28n%29%29%5CRightarrow+%5Ctext+%7B3Cycle-Detection%7D%5Cin+%5Ctext+%7BBPTime%7D%28ct%28n%29%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BTime%7D%28t%28n%29%29%5CRightarrow+%5Ctext+%7B3Cycle-Detection%7D%5Cin+%5Ctext+%7BBPTime%7D%28ct%28n%29%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BTime%7D%28t%28n%29%29%5CRightarrow+%5Ctext+%7B3Cycle-Detection%7D%5Cin+%5Ctext+%7BBPTime%7D%28ct%28n%29%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sum}&#92;in &#92;text {Time}(t(n))&#92;Rightarrow &#92;text {3Cycle-Detection}&#92;in &#92;text {BPTime}(ct(n))," class="latex" /> for any <img src="https://s0.wp.com/latex.php?latex=t%28n%29%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)&#92;ge n" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">The reduction can be derandomized (that is, one can replace <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPTime}" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}" class="latex" /> in the conclusion) but the randomized case contains the main ideas.</p>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>.&nbsp;</span>We assign random numbers <img src="https://s0.wp.com/latex.php?latex=r_%7Bx%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bx%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bx%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{x}" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=4%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=4%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=4%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="4&#92;log n" class="latex" /> bits to each node <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> in the graph. The 3Sum instance consists of the integers <img src="https://s0.wp.com/latex.php?latex=r_%7Bx%7D-r_%7By%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bx%7D-r_%7By%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bx%7D-r_%7By%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{x}-r_{y}" class="latex" /> for every edge <img src="https://s0.wp.com/latex.php?latex=x%5Cto+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cto+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cto+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;to y" class="latex" /> in the graph.</p>
<p style="text-align: justify">To verify correctness, suppose that there is a cycle</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5Cto+y%5Cto+z%5Cto+x+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5Cto+y%5Cto+z%5Cto+x+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5Cto+y%5Cto+z%5Cto+x+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} x&#92;to y&#92;to z&#92;to x &#92;end{aligned}" class="latex" /></div>
<p>in the graph. Then we have <img src="https://s0.wp.com/latex.php?latex=r_%7Bx%7D-r_%7By%7D%2Br_%7By%7D-r_%7Bz%7D%2Br_%7Bz%7D-r_%7Bx%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bx%7D-r_%7By%7D%2Br_%7By%7D-r_%7Bz%7D%2Br_%7Bz%7D-r_%7Bx%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bx%7D-r_%7By%7D%2Br_%7By%7D-r_%7Bz%7D%2Br_%7Bz%7D-r_%7Bx%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{x}-r_{y}+r_{y}-r_{z}+r_{z}-r_{x}=0" class="latex" />, for any random choices.</p>
<p style="text-align: justify">Conversely, suppose there is no cycle, and consider any three numbers <img src="https://s0.wp.com/latex.php?latex=r_%7Bx1%7D-r_%7By1%7D%2Cr_%7Bx2%7D-r_%7By2%7D%2Cr_%7Bx3%7D-r_%7By3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bx1%7D-r_%7By1%7D%2Cr_%7Bx2%7D-r_%7By2%7D%2Cr_%7Bx3%7D-r_%7By3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bx1%7D-r_%7By1%7D%2Cr_%7Bx2%7D-r_%7By2%7D%2Cr_%7Bx3%7D-r_%7By3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{x1}-r_{y1},r_{x2}-r_{y2},r_{x3}-r_{y3}" class="latex" /> from the reduction and its corresponding edges. Some node <img src="https://s0.wp.com/latex.php?latex=xi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=xi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=xi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="xi" class="latex" /> has unequal in-degree and out-degree in those edges. This means that when summing the three numbers, the random variable <img src="https://s0.wp.com/latex.php?latex=r_%7Bxi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bxi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bxi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{xi}" class="latex" /> will not cancel out. When selecting uniform values for that variable, the probability of getting <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> is at most <img src="https://s0.wp.com/latex.php?latex=1%2Fn%5E%7B4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%2Fn%5E%7B4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%2Fn%5E%7B4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1/n^{4}" class="latex" />.</p>
<p style="text-align: justify">By a union bound, the probability there there are three numbers that sum to zero is <img src="https://s0.wp.com/latex.php?latex=%5Cle+n%5E%7B3%7D%2Fn%5E%7B4%7D%3C1%2F3.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n%5E%7B3%7D%2Fn%5E%7B4%7D%3C1%2F3.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n%5E%7B3%7D%2Fn%5E%7B4%7D%3C1%2F3.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n^{3}/n^{4}&lt;1/3." class="latex" /> <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49009r3"></a> <b>Exercise</b> 4.3. </span>Prove an analogous result for undirected graphs. Note TBD: This exercise should be more interesting for 4-cycles, because you can’t just duplicate edges, I think.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Many other clusters of problems exist, for example based on matrix multiplication or all-pairs shortest path.</p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">4.3 </span> <a id="x1-500004.3"></a>Reductions from 3Sat</h3>
<p style="text-align: justify">In this section we begin to explore an important cluster of problems not known to be in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPP}" class="latex" />. What’s special about these problems is that in Chapter ?? we will show that we can reduce <em>arbitrary computation</em> to them, while this is unknown for the problems in the previous section.</p>
<p style="text-align: justify">Perhaps the most basic problem in the cluster is the following.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50001r8"></a> <b>Definition</b> 4.8. </span>The 3Sat problem: Given a 3CNF <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" />, is there an assignment <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> s.t.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cphi+%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi (x)=1" class="latex" />?</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50002r2"></a> <b>Conjecture</b> 4.2. </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%5Censuremath+%7B%5Cnot+%7D%5Censuremath+%7B%5Censuremath+%7B%5Cin+%5Ctext+%7BP%7D%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%5Censuremath+%7B%5Cnot+%7D%5Censuremath+%7B%5Censuremath+%7B%5Cin+%5Ctext+%7BP%7D%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%5Censuremath+%7B%5Cnot+%7D%5Censuremath+%7B%5Censuremath+%7B%5Cin+%5Ctext+%7BP%7D%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat&#92;ensuremath {&#92;not }&#92;ensuremath {&#92;ensuremath {&#92;in &#92;text {P}}}.}" class="latex" /></p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Stronger conjectures have been made.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50003r3"></a> <b>Conjecture</b> 4.3. </span><span class="cite">[<a href="#XIP99">13</a>]</span> [Exponential time hypothesis (ETH)] There is <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon&gt;0" class="latex" /> such that there is no algorithm that on input a <img src="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3" class="latex" />CNF <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v" class="latex" /> variables and <img src="https://s0.wp.com/latex.php?latex=cv%5E%7B3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cv%5E%7B3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cv%5E%7B3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cv^{3}" class="latex" /> clauses decides if <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> is satisfiable in time <img src="https://s0.wp.com/latex.php?latex=2%5E%7B%28%5Cepsilon+%2Bo%281%29%29v%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7B%28%5Cepsilon+%2Bo%281%29%29v%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7B%28%5Cepsilon+%2Bo%281%29%29v%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{(&#92;epsilon +o(1))v}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50004r4"></a> <b>Conjecture</b> 4.4. </span><span class="cite">[<a href="#XIPZ01">14</a>]</span> [Strong exponential-time hypothesis (SETH)] For every <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon &gt;0" class="latex" /> there is <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" /> such that there is no algorithm that on input a <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />CNF <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v" class="latex" /> variables and <img src="https://s0.wp.com/latex.php?latex=cv%5E%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cv%5E%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cv%5E%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cv^{k}" class="latex" /> clauses decides if <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> is satisfiable in time <img src="https://s0.wp.com/latex.php?latex=2%5E%7B%281-%5Cepsilon+%2Bo%281%29%29v%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7B%281-%5Cepsilon+%2Bo%281%29%29v%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7B%281-%5Cepsilon+%2Bo%281%29%29v%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{(1-&#92;epsilon +o(1))v}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">It is known that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSETH%7D%5CRightarrow+%5Ctext+%7BETH%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSETH%7D%5CRightarrow+%5Ctext+%7BETH%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BSETH%7D%5CRightarrow+%5Ctext+%7BETH%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {SETH}&#92;Rightarrow &#92;text {ETH}," class="latex" /> but the proof is not immediate.</p>
<p style="text-align: justify">We now give reductions from 3Sat to several other problems. The reductions are in fact mapping reductions. Moreover, the reduction map can be extremely restricted, see Problem <a href="#x1-55004r4">4.4<!--tex4ht:ref: prob:reducing-the-complexity-of-reductions --></a>. In this sense, therefore, this reduction can be viewed as a direct translation of the problem, and maybe we shouldn’t really be thinking of the problems as different, even if they at first sight refer to different types of objects (formulas, graphs, numbers, etc.).</p>
<p style="text-align: justify"><b>Watch videos 29, 30, 31, and 32 </b>covering reductions: 3SAT to CLIQUE, CLIQUE to VERTEX-COVER, 3SAT to SUBSET-SUM, 3SAT to 3COLOR <b>from <a href="https://www.ccs.neu.edu/home/viola/classes/algm-generic.html" rel="nofollow">https://www.ccs.neu.edu/home/viola/classes/algm-generic.html</a></b></p>
<p style="text-align: justify">Note: The videos use the terminology “polynomial time” instead of “power time” here.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50005r4"></a> <b>Exercise</b> 4.4. </span>The problem System is defined as follows. A <em>linear inequality</em> is an inequality involving sums of variables and constants, such as <img src="https://s0.wp.com/latex.php?latex=x%2By%5Cge+z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%2By%5Cge+z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%2By%5Cge+z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x+y&#92;ge z" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=x%5Cle+-17&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cle+-17&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cle+-17&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;le -17" class="latex" />, and so on. A system of linear inequalities has an <em>integer</em> solution if it is possible to substitute integer values for the variables so that every inequality in the system becomes true. The language System consists of systems of linear inequalities that have an integer solution. For example,</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2By%5Cge+z%2Cx%5Cle+5%2Cy%5Cle+1%2Cz%5Cge+5%29%5Cin+%5Cmbox+%7BSystem+%7D%5C%5C+%28x%2By%5Cge+2z%2Cx%5Cle+5%2Cy%5Cle+1%2Cz%5Cge+5%29%5Cnot+%5Cin+%5Cmbox+%7BSystem+%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2By%5Cge+z%2Cx%5Cle+5%2Cy%5Cle+1%2Cz%5Cge+5%29%5Cin+%5Cmbox+%7BSystem+%7D%5C%5C+%28x%2By%5Cge+2z%2Cx%5Cle+5%2Cy%5Cle+1%2Cz%5Cge+5%29%5Cnot+%5Cin+%5Cmbox+%7BSystem+%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2By%5Cge+z%2Cx%5Cle+5%2Cy%5Cle+1%2Cz%5Cge+5%29%5Cin+%5Cmbox+%7BSystem+%7D%5C%5C+%28x%2By%5Cge+2z%2Cx%5Cle+5%2Cy%5Cle+1%2Cz%5Cge+5%29%5Cnot+%5Cin+%5Cmbox+%7BSystem+%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} (x+y&#92;ge z,x&#92;le 5,y&#92;le 1,z&#92;ge 5)&#92;in &#92;mbox {System }&#92;&#92; (x+y&#92;ge 2z,x&#92;le 5,y&#92;le 1,z&#92;ge 5)&#92;not &#92;in &#92;mbox {System } &#92;end{aligned}" class="latex" /></div>
<p>Reduce 3Sat to System in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50006r5"></a> <b>Exercise</b> 4.5. </span>For an integer <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-Color is the problem of deciding if the nodes of a given undirected graph <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> can be colored using <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" /> colors in such a way that no two adjacent vertices have the same color.</p>
<p style="text-align: justify">Reduce 3-Color to 4-Color P.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Reductions in the opposite directions are possible, and so in fact the problems in this section are <em>power-time equivalent</em> in the sense that any of the problems is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> iff all the others are. We will see a generic reduction in the next chapter. For now, we illustrate this equivalence in a particular case.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50007r6"></a> <b>Exercise</b> 4.6. </span>Reduce 3Color to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />, following these steps:</p>
<p style="text-align: justify">1. Given a graph <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" />, introduce variables <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%2Cc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7Bi%2Cc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bi%2Cc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{i,c}" class="latex" /> representing that node <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> has color <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c" class="latex" /> ranges in the set of colors <img src="https://s0.wp.com/latex.php?latex=C%3D%5C%7Bg%2Cr%2Cb%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3D%5C%7Bg%2Cr%2Cb%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3D%5C%7Bg%2Cr%2Cb%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C=&#92;{g,r,b&#92;}" class="latex" />. Describe a set of clauses that is satisfiable if and only if for every <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> there is exactly one <img src="https://s0.wp.com/latex.php?latex=c%5Cin+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Cin+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Cin+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;in C" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%2Cc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7Bi%2Cc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bi%2Cc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{i,c}" class="latex" /> is true.</p>
<p style="text-align: justify">2. Introduce clauses representing that adjacent nodes do not have the same color.</p>
<p style="text-align: justify">3. Briefly conclude the proof.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Thus, we are identifying a cluster of problems which are all power-time equivalent. This cluster is so prominent that problems in it have been compiled into books <span class="cite">[<a href="#XGareyJ79">7</a>]</span>. More recently, it was shown that it contains (generalized versions of) several games including: Tetris, Lemmings, Sudoku, etc. For a list see e.g.&nbsp;the wikipedia page <a href="https://en.wikipedia.org/wiki/List_of_NP-complete_problems" rel="nofollow">https://en.wikipedia.org/wiki/List_of_NP-complete_problems</a></p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">4.4 </span> <a id="x1-510004.4"></a>Power hardness from SETH</h3>
<p style="text-align: justify">In this section we show that a conjecture similar to Conjecture <a href="#x1-49003r1">4.1<!--tex4ht:ref: conj:3sum --></a> can be proved assuming SETH. This is an interesting example of how we can connect different parameter regimes, since SETH is stated in terms of exponential running times. In general, “scaling” parameters is a powerful technique in the complexity toolkit.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-51001r9"></a> <b>Definition</b> 4.9. </span>The Or-Vector problem: Given two sets <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> of strings of the same length, determine if there is <img src="https://s0.wp.com/latex.php?latex=a%5Cin+A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%5Cin+A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%5Cin+A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a&#92;in A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=b%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b&#92;in B" class="latex" /> such that the bit-wise Or <img src="https://s0.wp.com/latex.php?latex=a%5Cvee+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%5Cvee+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%5Cvee+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a&#92;vee b" class="latex" /> equals the all-one vector.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">The Or-Vector problem is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(n^{2})" class="latex" />. We can show that a substantial improvement would disprove SETH.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-51002r4"></a> <b>Theorem</b> 4.4. </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BOr-Vector%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%5CRightarrow+%5Ctext+%7BSETH+is+false.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BOr-Vector%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%5CRightarrow+%5Ctext+%7BSETH+is+false.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BOr-Vector%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%5CRightarrow+%5Ctext+%7BSETH+is+false.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Or-Vector}&#92;in &#92;text {SubquadraticTime}&#92;Rightarrow &#92;text {SETH is false.}" class="latex" /></p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>.&nbsp;</span>Divide the variables in two blocks of <img src="https://s0.wp.com/latex.php?latex=v%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v/2" class="latex" /> each. For each assignment to the variables in the first block construct the vector in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{d}" class="latex" /> where bit <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> iff clause <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> is satisfied by the variables in the first block. Call <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> the resulting set of vectors. Let <img src="https://s0.wp.com/latex.php?latex=N%3A%3D2%5E%7Bv%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N%3A%3D2%5E%7Bv%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N%3A%3D2%5E%7Bv%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N:=2^{v/2}" class="latex" /> and note <img src="https://s0.wp.com/latex.php?latex=%7CA%7C%3DN&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CA%7C%3DN&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CA%7C%3DN&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|A|=N" class="latex" />. Do the same for the other block and call the resulting set <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" />.</p>
<p style="text-align: justify">Note that <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> is satisfiable iff <img src="https://s0.wp.com/latex.php?latex=%5Cexists+a%5Cin+A%2Cb%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+a%5Cin+A%2Cb%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+a%5Cin+A%2Cb%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists a&#92;in A,b&#92;in B" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=a%5Cvee+b%3D1%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%5Cvee+b%3D1%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%5Cvee+b%3D1%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a&#92;vee b=1^{d}" class="latex" />.</p>
<p style="text-align: justify">Constructing these sets takes time <img src="https://s0.wp.com/latex.php?latex=Nd%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Nd%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Nd%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Nd^{c}" class="latex" />. If <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BOr-Vector%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B2-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BOr-Vector%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B2-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BOr-Vector%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B2-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Or-Vector}&#92;in &#92;text {Time}(n^{2-&#92;epsilon })" class="latex" /> for some <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon &gt;0" class="latex" />, we can take <img src="https://s0.wp.com/latex.php?latex=k%3Dc_%7B%5Cepsilon%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k%3Dc_%7B%5Cepsilon%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k%3Dc_%7B%5Cepsilon%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k=c_{&#92;epsilon}" class="latex" /> and rule out SETH. <b>QED</b></p>
</div>
<p style="text-align: justify">Tight hardness results based on SETH have been established for several well-studied problems, including longest-common subsequence <span class="cite">[<a href="conf/focs/AbboudBW15">1</a>]</span> and edit distance <span class="cite">[<a href="journals/siamcomp/BackursI18">5</a>]</span>.</p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">4.5 </span> <a id="x1-520004.5"></a>Search problems</h3>
<p style="text-align: justify">Most of the problems in the previous sections ask about the <em>existence</em> of solutions. For example 3Sat asks about the existence of a satisfying assignment. It is natural to ask about computing such a solution, if it exists. Such non-boolean problems are known as <em>search problems</em>.</p>
<p style="text-align: justify">Next we show that in some cases we can reduce a search problem to the corresponding boolean problem.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-52001r10"></a> <b>Definition</b> 4.10. </span>Search-3Sat is the problem: Given a satisfiable 3CNF formula, output a satisfying assignment.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-52002r5"></a> <b>Theorem</b> 4.5. </span> Search-3Sat reduces to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />. That is: <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {P}&#92;Rightarrow &#92;text {Search-3Sat}&#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>.&nbsp;</span>We construct a satisfying assignment one variable at the time. Given a satisfiable 3CNF, set the first variable to <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> and check if it is still satisfiable with the assumed algorithm for 3Sat. If it is, go to the next variable. If it is not, set the first variable to <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> and go to the next variable. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-52003r7"></a> <b>Exercise</b> 4.7. </span>Show <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BClique%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-Clique%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BClique%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-Clique%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BClique%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-Clique%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Clique}&#92;in &#92;text {P}&#92;Rightarrow &#92;text {Search-Clique}&#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<h4 class="subsectionHead"><span class="titlemark">4.5.1 </span> <a id="x1-530004.5.1"></a>Fastest algorithm for Search-3Sat</h4>
<p style="text-align: justify">A curious fact about many search problems is that we know of an algorithm which is, in an asymptotic sense to be discussed now, essentially the fastest possible algorithm. This algorithm proceeds by simulating every possible program. When a program stops and outputs the answer, we can <em>check it</em> efficiently. Naturally, we can’t just take any program and simulate it until it ends, since it may never end. So we will clock programs, and stop them if they take too long. There is a particular simulation schedule which leads to efficient running times.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-53001r6"></a> <b>Theorem</b> 4.6. </span> <span class="cite">[<a href="#XLevin73">17</a>]</span> There is a RAM <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> such that on input any satisfiable formula <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />:</p>
<p style="text-align: justify">(1) <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> outputs a satisfying assignment, and</p>
<p style="text-align: justify">(2) If there is a RAM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> that on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> outputs a satisfying assignment for <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> steps then <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> stops in <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%2B%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%2B%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%2B%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}t+|x|^{c}" class="latex" /> steps.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">We are taking advantage of the RAM model. On other models it is not known if the dependence on <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> can be linear.</p>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>.&nbsp;</span>For <img src="https://s0.wp.com/latex.php?latex=i%3D1%2C2%2C%5Cldots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%3D1%2C2%2C%5Cldots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%3D1%2C2%2C%5Cldots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i=1,2,&#92;ldots " class="latex" /> the RAM <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> simulates RAM <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{i}" class="latex" /> steps. <a href="#x1-26006r2">2.2<!--tex4ht:ref: lem-univ-ram --></a> guarantees that for each <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> the simulation takes time <img src="https://s0.wp.com/latex.php?latex=c2%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c2%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c2%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c2^{i}" class="latex" />. If RAM <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> stops and outputs <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> checks in time <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|^{c}" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> is a satisfying assignment. If it is, then <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> outputs <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> and stops. Otherwise it continues.</p>
<p style="text-align: justify">Now let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be as in (2). As before, we work with an enumeration of programs where each program appears infinitely often. Hence we can assume that <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> has a description of length <img src="https://s0.wp.com/latex.php?latex=%5Cell+%3A%3Dc_%7BM%7D%2B%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cell+%3A%3Dc_%7BM%7D%2B%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cell+%3A%3Dc_%7BM%7D%2B%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ell :=c_{M}+&#92;log t" class="latex" />. Thus the simulation will terminate when <img src="https://s0.wp.com/latex.php?latex=i%3D%5Cell+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%3D%5Cell+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%3D%5Cell+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i=&#92;ell " class="latex" />.</p>
<p style="text-align: justify">The time spent by <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> for a fixed <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cle+c%5Ccdot+2%5E%7Bi%7D%2B%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c%5Ccdot+2%5E%7Bi%7D%2B%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c%5Ccdot+2%5E%7Bi%7D%2B%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c&#92;cdot 2^{i}+|x|^{c}" class="latex" />. Hence he total running time of <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> is</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+c%5Csum+_%7Bj%3D1%7D%5E%7B%5Cell+%7D%5Cleft+%28c2%5E%7Bj%7D%2B%7Cx%7C%5E%7Bc%7D%5Cright+%29%5Cle+c_%7BM%7D2%5E%7B%5Cell+%7D%2Bc_%7BM%7D%7Cx%7C%5E%7Bc%7D%5Cle+c_%7BM%7D%28t%2B%7Cx%7C%5E%7Bc%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+c%5Csum+_%7Bj%3D1%7D%5E%7B%5Cell+%7D%5Cleft+%28c2%5E%7Bj%7D%2B%7Cx%7C%5E%7Bc%7D%5Cright+%29%5Cle+c_%7BM%7D2%5E%7B%5Cell+%7D%2Bc_%7BM%7D%7Cx%7C%5E%7Bc%7D%5Cle+c_%7BM%7D%28t%2B%7Cx%7C%5E%7Bc%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+c%5Csum+_%7Bj%3D1%7D%5E%7B%5Cell+%7D%5Cleft+%28c2%5E%7Bj%7D%2B%7Cx%7C%5E%7Bc%7D%5Cright+%29%5Cle+c_%7BM%7D2%5E%7B%5Cell+%7D%2Bc_%7BM%7D%7Cx%7C%5E%7Bc%7D%5Cle+c_%7BM%7D%28t%2B%7Cx%7C%5E%7Bc%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;le c&#92;sum _{j=1}^{&#92;ell }&#92;left (c2^{j}+|x|^{c}&#92;right )&#92;le c_{M}2^{&#92;ell }+c_{M}|x|^{c}&#92;le c_{M}(t+|x|^{c}). &#92;end{aligned}" class="latex" /></div>
<p><b>QED</b></p>
</div>
<p style="text-align: justify">This result nicely illustrates how “constant factors” can lead to impractical results because, of course, the problem is that the constant in front of <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is enormous. Specifically, it is exponential in the size of the program, see Problem <a href="#x1-55005r5">4.5<!--tex4ht:ref: prob:universal-search-program-enumeration-bottleneck --></a>.</p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">4.6 </span> <a id="x1-540004.6"></a>Gap-SAT: The PCP theorem</h3>
<table class="quotation" cellspacing="15" cellpadding="0" border="0">
<tbody>
<tr>
<td>
<div class="quotation">
<p style="text-align: justify">“Furthermore, most problem reductions do not create or preserve such gaps. There would appear to be a last resort, namely to <em>create </em>such a gap in the generic reduction [C]. Unfortunately, this also seems doubtful. The intuitive reason is that computation is an inherently unstable, non-robust mathematical object, in the sense that it can be turned from non-accepting by changes that would be insignificant in any reasonable metric – say, by flipping a single state to accepting.” <span class="cite">[<a href="journals/jcss/PapadimitriouY91">19</a>]</span></p>
</div>
</td>
</tr>
</tbody>
</table>
<p>One of the most exciting, consequential, and technical developments in complexity theory of the last few decades has been the development of reductions that create <em>gaps.</em></p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-54001r11"></a> <b>Definition</b> 4.11. </span><img src="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma " class="latex" />-Gap-3Sat is the 3Sat problem restricted to input formulas <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> that are either satisfiable or such that any assignment satisfies at most a <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma " class="latex" /> fraction of clauses.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Note that 3Sat is equivalent to <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma " class="latex" />-Gap-3Sat for <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3D1-1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+%3D1-1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+%3D1-1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma =1-1/n" class="latex" />, since a formula of size <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> has at most <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> clauses. At first sight it is unclear how to connect the problems when <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma " class="latex" /> is much smaller. But in fact it is possible to obtain a constant <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma " class="latex" />. This result is known as the PCP theorem, where PCP stands for probabilistically-checkable-proofs. The connection to proofs will be discussed in Chapter ??.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-54002r7"></a> <b>Theorem</b> 4.7. </span><span class="cite">[<a href="#XAroraLuMoSuSz98">4</a>]</span> [PCP] There is <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3C1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+%3C1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+%3C1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma &lt;1" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+%5Ctext+%7B-Gap-3Sat%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+%5Ctext+%7B-Gap-3Sat%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+%5Ctext+%7B-Gap-3Sat%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma &#92;text {-Gap-3Sat}&#92;in &#92;text {P}&#92;Rightarrow &#92;text {3Sat}&#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Similar results can be established for other problems such as 3Color, but the reductions in the previous section don’t preserve gaps and can’t be immediately applied.</p>
<p style="text-align: justify">A major application of the PCP theorem is in <em>inapproximability</em> results. A typical optimization problem is Max-3Sat.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-54003r12"></a> <b>Definition</b> 4.12. </span>The Max-3Sat problem: given a 3CNF formula, find a satisfying assignment that satisfies the maximum number of clauses.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Solving 3Sat reduces to Max-3Sat (in Chapter ?? we will give a reverse reduction as well). But we can ask for <em><img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" />-approximating</em> Max-3Sat, that is, computing an assignment that satisfies a number of clauses that is at least a <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" /> fraction of the maximum possible clauses that can be satisfied.</p>
<p style="text-align: justify">The PCP Theorem <a href="#x1-54002r7">4.7<!--tex4ht:ref: thm:-=00005BPCP=00005D --></a> implies that 3Sat reduces to <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+-&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+-&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+-&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta -" class="latex" />approximating Max-3Sat, for some constant <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3C1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+%3C1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+%3C1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta &lt;1" class="latex" />.</p>
<p style="text-align: justify">It has been a major line of research to obtain tight approximation factors <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" /> for a variety of problems. For example, 3Sat reduces to <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" />-approximating Max-3Sat for any <img src="https://s0.wp.com/latex.php?latex=%5Cb+%3E7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cb+%3E7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cb+%3E7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;b &gt;7/8" class="latex" />. This constant is tight because a random uniform assignment to the variables satisfies each clause with probability <img src="https://s0.wp.com/latex.php?latex=7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="7/8" class="latex" /> and hence expects to satisfy a <img src="https://s0.wp.com/latex.php?latex=7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="7/8" class="latex" /> fraction of the clauses.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-54004r8"></a> <b>Exercise</b> 4.8. </span>Turn this latter observation in an efficient randomized algorithm with an approximation factor <img src="https://s0.wp.com/latex.php?latex=7%2F8-o%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=7%2F8-o%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=7%2F8-o%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="7/8-o(1)" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">4.7 </span> <a id="x1-550004.7"></a>Problems</h3>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-55001r1"></a> <b>Problem</b> 4.1. </span>Reduce 3Sat to the PIT problem (Definition <a href="#x1-32001r8">2.8<!--tex4ht:ref: def:arithmetic-circuit-PIT --></a>) over the field with two elements.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-55002r2"></a> <b>Problem</b> 4.2. </span>Prove that 3Sat is not <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5E%7B1.99%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5E%7B1.99%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5E%7B1.99%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(n^{1.99})" class="latex" />. (Hint: Consider the <em>Padded-Palindromes </em>problem which is like palindromes except the input is divided in blocks of <img src="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log n" class="latex" /> bits, and only the first bit of each block may be non-zero. (1) Prove a time lower bound for Padded-Palindromes by explaining what modifications are needed to the proof of Theorem <a href="#x1-38001r1">3.1<!--tex4ht:ref: thm:TM-pal-requires-quadratic --></a>. (2) Give a suitable reduction from Padded-Palindromes to 3Sat.)</p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-55003r3"></a> <b>Problem</b> 4.3. </span>Show that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Color%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-3Color%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Color%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-3Color%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Color%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-3Color%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Color}&#92;in &#92;text {P}&#92;Rightarrow &#92;text {Search-3Color}&#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-55004r4"></a> <b>Problem</b> 4.4. </span>Give an encoding of 3Sat so that the reduction to 3Color in section&nbsp;º<a href="#x1-500004.3">4.3<!--tex4ht:ref: sec:Reductions-from-3Sat --></a> can be computed, for any input length, by a <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" />-local map (in particular, a circuit of constant depth).</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-55005r5"></a> <b>Problem</b> 4.5. </span>Suppose there exists <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a" class="latex" /> such that Theorem <a href="#x1-53001r6">4.6<!--tex4ht:ref: thm:univeral-search --></a> holds with the running time of <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> replaced with <img src="https://s0.wp.com/latex.php?latex=%28%7CM%7C%5Ccdot+t%5Ccdot+%7Cx%7C%29%5E%7Ba%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%7CM%7C%5Ccdot+t%5Ccdot+%7Cx%7C%29%5E%7Ba%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%7CM%7C%5Ccdot+t%5Ccdot+%7Cx%7C%29%5E%7Ba%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(|M|&#92;cdot t&#92;cdot |x|)^{a}" class="latex" />. (That is, the dependence on the program description improved to polynomial, and we allow even weaker dependence on <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />.) Prove that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<h3 class="likesectionHead"><a id="x1-560004.7"></a>References</h3>
<p style="text-align: justify">
<div class="thebibliography">
<p class="bibitem"><span class="biblabel"> [1]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/focs/AbboudBW15"></a>Amir Abboud, Arturs Backurs, and Virginia&nbsp;Vassilevska Williams. Tight hardness results for LCS and other sequence similarity measures. In Venkatesan Guruswami, editor, IEEE 56th Annual Symposium on Foundations of Computer Science, FOCS 2015, Berkeley, CA, USA, 17-20 October, 2015, pages 59–78. IEEE Computer Society, 2015.</p>
<p class="bibitem"><span class="biblabel"> [2]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAdleman78"></a>Leonard Adleman. Two theorems on random polynomial time. In 19th IEEE Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 75–83. 1978.</p>
<p class="bibitem"><span class="biblabel"> [3]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/AngluinV79"></a>Dana Angluin and Leslie&nbsp;G. Valiant. Fast probabilistic algorithms for hamiltonian circuits and matchings. J. Comput. Syst. Sci., 18(2):155–193, 1979.</p>
<p class="bibitem"><span class="biblabel"> [4]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAroraLuMoSuSz98"></a>Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy. Proof verification and the hardness of approximation problems. J.&nbsp;of the ACM, 45(3):501–555, May 1998.</p>
<p class="bibitem"><span class="biblabel"> [5]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/BackursI18"></a>Arturs Backurs and Piotr Indyk. Edit distance cannot be computed in strongly subquadratic time (unless SETH is false). SIAM J. Comput., 47(3):1087–1097, 2018.</p>
<p class="bibitem"><span class="biblabel"> [6]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGajentaanO95"></a>Anka Gajentaan and Mark&nbsp;H. Overmars. On a class of <img src="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="{O}(n^2)" class="latex" /> problems in computational geometry. Comput. Geom., 5:165–185, 1995.</p>
<p class="bibitem"><span class="biblabel"> [7]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGareyJ79"></a>M.&nbsp;R. Garey and David&nbsp;S. Johnson. Computers and Intractability: A Guide to the Theory of NP-Completeness. W. H. Freeman, 1979.</p>
<p class="bibitem"><span class="biblabel"> [8]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR1549939"></a>K.&nbsp;G÷del. ▄ber formal unentscheidbare sΣtze der Principia Mathematica und verwandter systeme I. Monatsh. Math. Phys., 38, 1931.</p>
<p class="bibitem"><span class="biblabel"> [9]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGoldreich08Complexity"></a>Oded Goldreich. Computational Complexity: A Conceptual Perspective. Cambridge University Press, 2008.</p>
<p class="bibitem"><span class="biblabel"> [10]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="X10.4007/annals.2021.193.2.4"></a>David Harvey and Joris van&nbsp;der Hoeven. Integer multiplication in time <img src="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(n&#92;mathrm {log}&#92;, n)" class="latex" />. Annals of Mathematics, 193(2):563 – 617, 2021.</p>
<p class="bibitem"><span class="biblabel"> [11]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F.&nbsp;C. Hennie. One-tape, off-line turing machine computations. Information and Control, 8(6):553–578, 1965.</p>
<p class="bibitem"><span class="biblabel"> [12]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XHennieS66"></a>Fred Hennie and Richard Stearns. Two-tape simulation of multitape turing machines. J.&nbsp;of the ACM, 13:533–546, October 1966.</p>
<p class="bibitem"><span class="biblabel"> [13]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIP99"></a>Russell Impagliazzo and Ramamohan Paturi. The complexity of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-sat. In IEEE Conf.&nbsp;on Computational Complexity (CCC), pages 237–, 1999.</p>
<p class="bibitem"><span class="biblabel"> [14]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIPZ01"></a>Russell Impagliazzo, Ramamohan Paturi, and Francis Zane. Which problems have strongly exponential complexity? J. Computer &amp; Systems Sciences, 63(4):512–530, Dec 2001.</p>
<p class="bibitem"><span class="biblabel"> [15]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImW97"></a>Russell Impagliazzo and Avi Wigderson. <img src="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathit {P} = &#92;mathit {BPP}" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E" class="latex" /> requires exponential circuits: Derandomizing the XOR lemma. In 29th ACM Symp.&nbsp;on the Theory of Computing (STOC), pages 220–229. ACM, 1997.</p>
<p class="bibitem"><span class="biblabel"> [16]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi. On the structure of one-tape nondeterministic turing machine time hierarchy. Theor. Comput. Sci., 40:175–193, 1985.</p>
<p class="bibitem"><span class="biblabel"> [17]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLevin73"></a>Leonid&nbsp;A. Levin. Universal sequential search problems. Problemy Peredachi Informatsii, 9(3):115–116, 1973.</p>
<p class="bibitem"><span class="biblabel"> [18]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLupanov58"></a>O.&nbsp;B. Lupanov. A method of circuit synthesis. Izv. VUZ Radiofiz., 1:120–140, 1958.</p>
<p class="bibitem"><span class="biblabel"> [19]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/PapadimitriouY91"></a>Christos&nbsp;H. Papadimitriou and Mihalis Yannakakis. Optimization, approximation, and complexity classes. J. Comput. Syst. Sci., 43(3):425–440, 1991.</p>
<p class="bibitem"><span class="biblabel"> [20]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPippengerF79"></a>Nicholas Pippenger and Michael&nbsp;J. Fischer. Relations among complexity measures. J.&nbsp;of the ACM, 26(2):361–381, 1979.</p>
<p class="bibitem"><span class="biblabel"> [21]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Schonhage80"></a>Arnold Sch÷nhage. Storage modification machines. SIAM J. Comput., 9(3):490–508, 1980.</p>
<p class="bibitem"><span class="biblabel"> [22]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR29860"></a>Claude&nbsp;E. Shannon. The synthesis of two-terminal switching circuits. Bell System Tech. J., 28:59–98, 1949.</p>
<p class="bibitem"><span class="biblabel"> [23]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSho90"></a>Victor Shoup. New algorithms for finding irreducible polynomials over finite fields. Mathematics of Computation, 54(189):435–447, 1990.</p>
<p class="bibitem"><span class="biblabel"> [24]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert&nbsp;R. Meyer. Cosmological lower bound on the circuit complexity of a small problem in logic. J. ACM, 49(6):753–784, 2002.</p>
<p class="bibitem"><span class="biblabel"> [25]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/x/Turing37"></a>Alan&nbsp;M. Turing. On computable numbers, with an application to the entscheidungsproblem. Proc. London Math. Soc., s2-42(1):230–265, 1937.</p>
<p class="bibitem"><span class="biblabel"> [26]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViola-xxx"></a>Emanuele Viola. Reducing 3XOR to listing triangles, an exposition. Available at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2011.</p>
<p class="bibitem"><span class="biblabel"> [27]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-tm"></a>Emanuele Viola. Pseudorandom bits and lower bounds for randomized turing machines. Theory of Computing, 18(10):1–12, 2022.</p>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T14:06:22Z">Thursday, February 09 2023, 14:06</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04108'>Triplet Loss-less Center Loss Sampling Strategies in Facial Expression Recognition Scenarios</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hossein Rajoli, Fatemeh Lotfi, Adham Atyabi, Fatemeh Afghah</p><p>Facial expressions convey massive information and play a crucial role in
emotional expression. Deep neural network (DNN) accompanied by deep metric
learning (DML) techniques boost the discriminative ability of the model in
facial expression recognition (FER) applications. DNN, equipped with only
classification loss functions such as Cross-Entropy cannot compact intra-class
feature variation or separate inter-class feature distance as well as when it
gets fortified by a DML supporting loss item. The triplet center loss (TCL)
function is applied on all dimensions of the sample's embedding in the
embedding space. In our work, we developed three strategies: fully-synthesized,
semi-synthesized, and prediction-based negative sample selection strategies. To
achieve better results, we introduce a selective attention module that provides
a combination of pixel-wise and element-wise attention coefficients using
high-semantic deep features of input samples. We evaluated the proposed method
on the RAF-DB, a highly imbalanced dataset. The experimental results reveal
significant improvements in comparison to the baseline for all three negative
sample selection strategies.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rajoli_H/0/1/0/all/0/1">Hossein Rajoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Lotfi_F/0/1/0/all/0/1">Fatemeh Lotfi</a>, <a href="http://arxiv.org/find/cs/1/au:+Atyabi_A/0/1/0/all/0/1">Adham Atyabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Afghah_F/0/1/0/all/0/1">Fatemeh Afghah</a></p><p>Facial expressions convey massive information and play a crucial role in
emotional expression. Deep neural network (DNN) accompanied by deep metric
learning (DML) techniques boost the discriminative ability of the model in
facial expression recognition (FER) applications. DNN, equipped with only
classification loss functions such as Cross-Entropy cannot compact intra-class
feature variation or separate inter-class feature distance as well as when it
gets fortified by a DML supporting loss item. The triplet center loss (TCL)
function is applied on all dimensions of the sample's embedding in the
embedding space. In our work, we developed three strategies: fully-synthesized,
semi-synthesized, and prediction-based negative sample selection strategies. To
achieve better results, we introduce a selective attention module that provides
a combination of pixel-wise and element-wise attention coefficients using
high-semantic deep features of input samples. We evaluated the proposed method
on the RAF-DB, a highly imbalanced dataset. The experimental results reveal
significant improvements in comparison to the baseline for all three negative
sample selection strategies.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04162'>Optimal Sufficient Requirements on the Embedded Ising Problem in Polynomial Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Elisabeth Lobe, Volker Kaibel</p><p>One of the central applications for quantum annealers is to find the
solutions of Ising problems. Suitable Ising problems, however, need to be
formulated such that they, on the one hand, respect the specific restrictions
of the hardware and, on the other hand, represent the original problems which
shall actually be solved. We evaluate sufficient requirements on such an
embedded Ising problem analytically and transform them into a linear
optimization problem. With an objective function aiming to minimize the maximal
absolute problem parameter, the precision issues of the annealers are
addressed. Due to the redundancy of several constraints, we can show that the
formally exponentially large optimization problem can be reduced and finally
solved in polynomial time for the standard embedding setting where the embedded
vertices induce trees. This allows to formulate provably equivalent embedded
Ising problems in a practical setup.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Lobe_E/0/1/0/all/0/1">Elisabeth Lobe</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kaibel_V/0/1/0/all/0/1">Volker Kaibel</a></p><p>One of the central applications for quantum annealers is to find the
solutions of Ising problems. Suitable Ising problems, however, need to be
formulated such that they, on the one hand, respect the specific restrictions
of the hardware and, on the other hand, represent the original problems which
shall actually be solved. We evaluate sufficient requirements on such an
embedded Ising problem analytically and transform them into a linear
optimization problem. With an objective function aiming to minimize the maximal
absolute problem parameter, the precision issues of the annealers are
addressed. Due to the redundancy of several constraints, we can show that the
formally exponentially large optimization problem can be reduced and finally
solved in polynomial time for the standard embedding setting where the embedded
vertices induce trees. This allows to formulate provably equivalent embedded
Ising problems in a practical setup.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04218'>On the Computational Complexity of Ethics: Moral Tractability for Minds and Machines</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jakob Stenseke</p><p>Why should moral philosophers, moral psychologists, and machine ethicists
care about computational complexity? Debates on whether artificial intelligence
(AI) can or should be used to solve problems in ethical domains have mainly
been driven by what AI can or cannot do in terms of human capacities. In this
paper, we tackle the problem from the other end by exploring what kind of moral
machines are possible based on what computational systems can or cannot do. To
do so, we analyze normative ethics through the lens of computational
complexity. First, we introduce computational complexity for the uninitiated
reader and discuss how the complexity of ethical problems can be framed within
Marr's three levels of analysis. We then study a range of ethical problems
based on consequentialism, deontology, and virtue ethics, with the aim of
elucidating the complexity associated with the problems themselves (e.g., due
to combinatorics, uncertainty, strategic dynamics), the computational methods
employed (e.g., probability, logic, learning), and the available resources
(e.g., time, knowledge, learning). The results indicate that most problems the
normative frameworks pose lead to tractability issues in every category
analyzed. Our investigation also provides several insights about the
computational nature of normative ethics, including the differences between
rule- and outcome-based moral strategies, and the implementation-variance with
regard to moral resources. We then discuss the consequences complexity results
have for the prospect of moral machines in virtue of the trade-off between
optimality and efficiency. Finally, we elucidate how computational complexity
can be used to inform both philosophical and cognitive-psychological research
on human morality by advancing the Moral Tractability Thesis (MTT).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Stenseke_J/0/1/0/all/0/1">Jakob Stenseke</a></p><p>Why should moral philosophers, moral psychologists, and machine ethicists
care about computational complexity? Debates on whether artificial intelligence
(AI) can or should be used to solve problems in ethical domains have mainly
been driven by what AI can or cannot do in terms of human capacities. In this
paper, we tackle the problem from the other end by exploring what kind of moral
machines are possible based on what computational systems can or cannot do. To
do so, we analyze normative ethics through the lens of computational
complexity. First, we introduce computational complexity for the uninitiated
reader and discuss how the complexity of ethical problems can be framed within
Marr's three levels of analysis. We then study a range of ethical problems
based on consequentialism, deontology, and virtue ethics, with the aim of
elucidating the complexity associated with the problems themselves (e.g., due
to combinatorics, uncertainty, strategic dynamics), the computational methods
employed (e.g., probability, logic, learning), and the available resources
(e.g., time, knowledge, learning). The results indicate that most problems the
normative frameworks pose lead to tractability issues in every category
analyzed. Our investigation also provides several insights about the
computational nature of normative ethics, including the differences between
rule- and outcome-based moral strategies, and the implementation-variance with
regard to moral resources. We then discuss the consequences complexity results
have for the prospect of moral machines in virtue of the trade-off between
optimality and efficiency. Finally, we elucidate how computational complexity
can be used to inform both philosophical and cognitive-psychological research
on human morality by advancing the Moral Tractability Thesis (MTT).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03771'>A generalization of the persistent Laplacian to simplicial maps</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aziz Burak G&#xfc;len, Facundo M&#xe9;moli, Zhengchao Wan, Yusu Wang</p><p>The graph Laplacian is a fundamental object in the analysis of and
optimization on graphs. This operator can be extended to a simplicial complex
$K$ and therefore offers a way to perform ``signal processing" on
$p$-(co)chains of $K$. Recently, the concept of persistent Laplacian was
proposed and studied for a pair of simplicial complexes $K\hookrightarrow L$
connected by an inclusion relation, further broadening the use of Laplace-based
operators.
</p>
<p>In this paper, we expand the scope of the persistent Laplacian by
generalizing it to a pair of simplicial complexes connected by a simplicial map
$f: K \to L$. Such simplicial map setting arises frequently, e.g., when
relating a coarsened simplicial representation with an original representation,
or the case when the two simplicial complexes are spanned by different point
sets i.e. cases in which it does not hold that $K\subset L$. However, the
simplicial map setting is more challenging than the inclusion setting since the
underlying algebraic structure is more complicated.
</p>
<p>We present a natural generalization of the persistent Laplacian to the
simplicial setting. To shed insight on the structure behind it, as well as to
develop an algorithm to compute it, we exploit the relationship between the
persistent Laplacian and the Schur complement of a matrix. A critical step is
to view the Schur complement as a functorial way of restricting a self-adjoint
PSD operator to a given subspace. As a consequence, we prove that persistent
Betti numbers of a simplicial map can be recovered by persistent Laplacians. We
then propose an algorithm for finding the matrix representations of persistent
Laplacians which in turn yields a new algorithm for computing persistent Betti
numbers of a simplicial map. Finally, we study the persistent Laplacian on
simplicial towers under simplicial maps and establish monotonicity results for
their eigenvalues.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gulen_A/0/1/0/all/0/1">Aziz Burak G&#xfc;len</a>, <a href="http://arxiv.org/find/math/1/au:+Memoli_F/0/1/0/all/0/1">Facundo M&#xe9;moli</a>, <a href="http://arxiv.org/find/math/1/au:+Wan_Z/0/1/0/all/0/1">Zhengchao Wan</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_Y/0/1/0/all/0/1">Yusu Wang</a></p><p>The graph Laplacian is a fundamental object in the analysis of and
optimization on graphs. This operator can be extended to a simplicial complex
$K$ and therefore offers a way to perform ``signal processing" on
$p$-(co)chains of $K$. Recently, the concept of persistent Laplacian was
proposed and studied for a pair of simplicial complexes $K\hookrightarrow L$
connected by an inclusion relation, further broadening the use of Laplace-based
operators.
</p>
<p>In this paper, we expand the scope of the persistent Laplacian by
generalizing it to a pair of simplicial complexes connected by a simplicial map
$f: K \to L$. Such simplicial map setting arises frequently, e.g., when
relating a coarsened simplicial representation with an original representation,
or the case when the two simplicial complexes are spanned by different point
sets i.e. cases in which it does not hold that $K\subset L$. However, the
simplicial map setting is more challenging than the inclusion setting since the
underlying algebraic structure is more complicated.
</p>
<p>We present a natural generalization of the persistent Laplacian to the
simplicial setting. To shed insight on the structure behind it, as well as to
develop an algorithm to compute it, we exploit the relationship between the
persistent Laplacian and the Schur complement of a matrix. A critical step is
to view the Schur complement as a functorial way of restricting a self-adjoint
PSD operator to a given subspace. As a consequence, we prove that persistent
Betti numbers of a simplicial map can be recovered by persistent Laplacians. We
then propose an algorithm for finding the matrix representations of persistent
Laplacians which in turn yields a new algorithm for computing persistent Betti
numbers of a simplicial map. Finally, we study the persistent Laplacian on
simplicial towers under simplicial maps and establish monotonicity results for
their eigenvalues.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03690'>Storing a Trie with Compact and Predictable Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuxuan Dong</p><p>This paper proposed a storing approach for trie structures, called Coordinate
Hash Trie. For a trie with $n$ nodes and an alphabet with size $m$, the
execution time of finding, inserting and deleting a child node, is $O(1)$ for
the average case, $O(m)$ for the worst case. The space used by this approach is
$O(n)$, unrelated to $m$. The constant of space consumption is predictable,
with no need for reallocation or resizing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yuxuan Dong</a></p><p>This paper proposed a storing approach for trie structures, called Coordinate
Hash Trie. For a trie with $n$ nodes and an alphabet with size $m$, the
execution time of finding, inserting and deleting a child node, is $O(1)$ for
the average case, $O(m)$ for the worst case. The space used by this approach is
$O(n)$, unrelated to $m$. The constant of space consumption is predictable,
with no need for reallocation or resizing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03781'>Cardinality-Constrained Continuous Knapsack Problem with Concave Piecewise-Linear Utilities</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Miao Bai, Carlos Cardonha</p><p>We study an extension of the cardinality-constrained knapsack problem where
each item has a concave piecewise-linear utility structure. Our main
contributions are approximation algorithms for the problem and the
investigation of an online version in the random order model. For the offline
problem, we present a fully polynomial-time approximation scheme and show that
it can be cast as the maximization of a submodular function with cardinality
constraints; the latter result allows us to derive a greedy $(1 -
\frac{1}{e})$-approximation algorithm. For the online problem in the random
order model, we present a 6.027-competitive algorithm. Finally, we investigate
the empirical performance of the greedy and online algorithms in numerical
experiments.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bai_M/0/1/0/all/0/1">Miao Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cardonha_C/0/1/0/all/0/1">Carlos Cardonha</a></p><p>We study an extension of the cardinality-constrained knapsack problem where
each item has a concave piecewise-linear utility structure. Our main
contributions are approximation algorithms for the problem and the
investigation of an online version in the random order model. For the offline
problem, we present a fully polynomial-time approximation scheme and show that
it can be cast as the maximization of a submodular function with cardinality
constraints; the latter result allows us to derive a greedy $(1 -
\frac{1}{e})$-approximation algorithm. For the online problem in the random
order model, we present a 6.027-competitive algorithm. Finally, we investigate
the empirical performance of the greedy and online algorithms in numerical
experiments.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03797'>Men Can't Always be Transformed into Mice: Decision Algorithms and Complexity for Sorting by Symmetric Reversals</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xin Tong, Yixiao Yu, Ziyi Fang, Haitao Jiang, Lusheng Wang, Binhai Zhu, Daming Zhu</p><p>Sorting a permutation by reversals is a famous problem in genome
rearrangements. Since 1997, quite some biological evidence were found that in
many genomes the reversed regions are usually flanked by a pair of inverted
repeats. This type of reversals are called symmetric reversals, which,
unfortunately, were largely ignored until recently. In this paper, we
investigate the problem of sorting by symmetric reversals, which requires a
series of symmetric reversals to transform one chromosome $A$ into the another
chromosome $B$. The decision problem of sorting by symmetric reversals is
referred to as {\em SSR} (when the input chromosomes $A$ and $B$ are given, we
use {\em SSR(A,B)}) and the corresponding optimization version (i.e., when the
answer for {\em SSR(A,B)} is yes, using the minimum number of symmetric
reversals to convert $A$ to $B$), is referred to as {\em SMSR(A,B)}. The main
results of this paper are summarized as follows, where the input is a pair of
chromosomes $A$ and $B$ with $n$ repeats. (1) We present an $O(n^2)$ time
algorithm to solve the decision problem {\em SSR(A,B)}, i.e., determine whether
a chromosome $A$ can be transformed into $B$ by a series of symmetric
reversals. (2) We design an $O(n^2)$ time algorithm for a special 2-balanced
case of {\em SMSR(A,B)}, where chromosomes $A$ and $B$ both have duplication
number 2 and every repeat appears twice in different orientations in $A$ and
$B$. (3) We show that SMSR is NP-hard even if the duplication number of the
input chromosomes are at most 2, hence showing that the above positive
optimization result is the best possible. As a by-product, we show that the
\emph{minimum Steiner tree} problem on \emph{circle graphs} is NP-hard,
settling the complexity status of a 38-year old open problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1">Xin Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yixiao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Ziyi Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Haitao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lusheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1">Binhai Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1">Daming Zhu</a></p><p>Sorting a permutation by reversals is a famous problem in genome
rearrangements. Since 1997, quite some biological evidence were found that in
many genomes the reversed regions are usually flanked by a pair of inverted
repeats. This type of reversals are called symmetric reversals, which,
unfortunately, were largely ignored until recently. In this paper, we
investigate the problem of sorting by symmetric reversals, which requires a
series of symmetric reversals to transform one chromosome $A$ into the another
chromosome $B$. The decision problem of sorting by symmetric reversals is
referred to as {\em SSR} (when the input chromosomes $A$ and $B$ are given, we
use {\em SSR(A,B)}) and the corresponding optimization version (i.e., when the
answer for {\em SSR(A,B)} is yes, using the minimum number of symmetric
reversals to convert $A$ to $B$), is referred to as {\em SMSR(A,B)}. The main
results of this paper are summarized as follows, where the input is a pair of
chromosomes $A$ and $B$ with $n$ repeats. (1) We present an $O(n^2)$ time
algorithm to solve the decision problem {\em SSR(A,B)}, i.e., determine whether
a chromosome $A$ can be transformed into $B$ by a series of symmetric
reversals. (2) We design an $O(n^2)$ time algorithm for a special 2-balanced
case of {\em SMSR(A,B)}, where chromosomes $A$ and $B$ both have duplication
number 2 and every repeat appears twice in different orientations in $A$ and
$B$. (3) We show that SMSR is NP-hard even if the duplication number of the
input chromosomes are at most 2, hence showing that the above positive
optimization result is the best possible. As a by-product, we show that the
\emph{minimum Steiner tree} problem on \emph{circle graphs} is NP-hard,
settling the complexity status of a 38-year old open problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03886'>Approximately Optimal Core Shapes for Tensor Decompositions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mehrdad Ghadiri, Matthew Fahrbach, Gang Fu, Vahab Mirrokni</p><p>This work studies the combinatorial optimization problem of finding an
optimal core tensor shape, also called multilinear rank, for a size-constrained
Tucker decomposition. We give an algorithm with provable approximation
guarantees for its reconstruction error via connections to higher-order
singular values. Specifically, we introduce a novel Tucker packing problem,
which we prove is NP-hard, and give a polynomial-time approximation scheme
based on a reduction to the 2-dimensional knapsack problem with a matroid
constraint. We also generalize our techniques to tree tensor network
decompositions. We implement our algorithm using an integer programming solver,
and show that its solution quality is competitive with (and sometimes better
than) the greedy algorithm that uses the true Tucker decomposition loss at each
step, while also running up to 1000x faster.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghadiri_M/0/1/0/all/0/1">Mehrdad Ghadiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Fahrbach_M/0/1/0/all/0/1">Matthew Fahrbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_G/0/1/0/all/0/1">Gang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a></p><p>This work studies the combinatorial optimization problem of finding an
optimal core tensor shape, also called multilinear rank, for a size-constrained
Tucker decomposition. We give an algorithm with provable approximation
guarantees for its reconstruction error via connections to higher-order
singular values. Specifically, we introduce a novel Tucker packing problem,
which we prove is NP-hard, and give a polynomial-time approximation scheme
based on a reduction to the 2-dimensional knapsack problem with a matroid
constraint. We also generalize our techniques to tree tensor network
decompositions. We implement our algorithm using an integer programming solver,
and show that its solution quality is competitive with (and sometimes better
than) the greedy algorithm that uses the true Tucker decomposition loss at each
step, while also running up to 1000x faster.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03994'>Fully-Dynamic Approximate Decision Trees With Worst-Case Update Time Guarantees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marco Bressan, Mauro Sozio</p><p>We give the first algorithm that maintains an approximate decision tree over
an arbitrary sequence of insertions and deletions of labeled examples, with
strong guarantees on the worst-case running time per update request. For
instance, we show how to maintain a decision tree where every vertex has Gini
gain within an additive $\alpha$ of the optimum by performing
$O\Big(\frac{d\,(\log n)^4}{\alpha^3}\Big)$ elementary operations per update,
where $d$ is the number of features and $n$ the maximum size of the active set
(the net result of the update requests). We give similar bounds for the
information gain and the variance gain. In fact, all these bounds are
corollaries of a more general result, stated in terms of decision rules --
functions that, given a set $S$ of labeled examples, decide whether to split
$S$ or predict a label. Decision rules give a unified view of greedy decision
tree algorithms regardless of the example and label domains, and lead to a
general notion of $\epsilon$-approximate decision trees that, for natural
decision rules such as those used by ID3 or C4.5, implies the gain
approximation guarantees above. The heart of our work provides a deterministic
algorithm that, given any decision rule and any $\epsilon &gt; 0$, maintains an
$\epsilon$-approximate tree using $O\!\left(\frac{d\, f(n)}{n}
\operatorname{poly}\frac{h}{\epsilon}\right)$ operations per update, where
$f(n)$ is the complexity of evaluating the rule over a set of $n$ examples and
$h$ is the maximum height of the maintained tree.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bressan_M/0/1/0/all/0/1">Marco Bressan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sozio_M/0/1/0/all/0/1">Mauro Sozio</a></p><p>We give the first algorithm that maintains an approximate decision tree over
an arbitrary sequence of insertions and deletions of labeled examples, with
strong guarantees on the worst-case running time per update request. For
instance, we show how to maintain a decision tree where every vertex has Gini
gain within an additive $\alpha$ of the optimum by performing
$O\Big(\frac{d\,(\log n)^4}{\alpha^3}\Big)$ elementary operations per update,
where $d$ is the number of features and $n$ the maximum size of the active set
(the net result of the update requests). We give similar bounds for the
information gain and the variance gain. In fact, all these bounds are
corollaries of a more general result, stated in terms of decision rules --
functions that, given a set $S$ of labeled examples, decide whether to split
$S$ or predict a label. Decision rules give a unified view of greedy decision
tree algorithms regardless of the example and label domains, and lead to a
general notion of $\epsilon$-approximate decision trees that, for natural
decision rules such as those used by ID3 or C4.5, implies the gain
approximation guarantees above. The heart of our work provides a deterministic
algorithm that, given any decision rule and any $\epsilon &gt; 0$, maintains an
$\epsilon$-approximate tree using $O\!\left(\frac{d\, f(n)}{n}
\operatorname{poly}\frac{h}{\epsilon}\right)$ operations per update, where
$f(n)$ is the complexity of evaluating the rule over a set of $n$ examples and
$h$ is the maximum height of the maintained tree.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04033'>Adaptive Massively Parallel Connectivity in Optimal Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jakub &#x141;&#x105;cki, Rustam Latypov, Yannic Maus, Jara Uitto</p><p>We study the problem of finding connected components in the Adaptive
Massively Parallel Computation (AMPC) model. We show that when we require the
total space to be linear in the size of the input graph the problem can be
solved in $O(\log^* n)$ rounds in forests (with high probability) and
$2^{O(\log^* n)}$ expected rounds in general graphs. This improves upon an
existing $O(\log \log_{m/n} n)$ round algorithm.
</p>
<p>For the case when the desired number of rounds is constant we show that both
problems can be solved using $\Theta(m + n \log^{(k)} n)$ total space in
expectation (in each round), where $k$ is an arbitrarily large constant and
$\log^{(k)}$ is the $k$-th iterate of the $\log_2$ function. This improves upon
existing algorithms requiring $\Omega(m + n \log n)$ total space.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lacki_J/0/1/0/all/0/1">Jakub &#x141;&#x105;cki</a>, <a href="http://arxiv.org/find/cs/1/au:+Latypov_R/0/1/0/all/0/1">Rustam Latypov</a>, <a href="http://arxiv.org/find/cs/1/au:+Maus_Y/0/1/0/all/0/1">Yannic Maus</a>, <a href="http://arxiv.org/find/cs/1/au:+Uitto_J/0/1/0/all/0/1">Jara Uitto</a></p><p>We study the problem of finding connected components in the Adaptive
Massively Parallel Computation (AMPC) model. We show that when we require the
total space to be linear in the size of the input graph the problem can be
solved in $O(\log^* n)$ rounds in forests (with high probability) and
$2^{O(\log^* n)}$ expected rounds in general graphs. This improves upon an
existing $O(\log \log_{m/n} n)$ round algorithm.
</p>
<p>For the case when the desired number of rounds is constant we show that both
problems can be solved using $\Theta(m + n \log^{(k)} n)$ total space in
expectation (in each round), where $k$ is an arbitrarily large constant and
$\log^{(k)}$ is the $k$-th iterate of the $\log_2$ function. This improves upon
existing algorithms requiring $\Omega(m + n \log n)$ total space.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04229'>Weighted Edit Distance Computation: Strings, Trees and Dyck</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Debarati Das, Jacob Gilbert, MohammadTaghi Hajiaghayi, Tomasz Kociumaka, Barna Saha</p><p>Given two strings of length $n$ over alphabet $\Sigma$, and an upper bound
$k$ on their edit distance, the algorithm of Myers (Algorithmica'86) and Landau
and Vishkin (JCSS'88) computes the unweighted string edit distance in
$\mathcal{O}(n+k^2)$ time. Till date, it remains the fastest algorithm for
exact edit distance computation, and it is optimal under the Strong Exponential
Hypothesis (STOC'15). Over the years, this result has inspired many
developments, including fast approximation algorithms for string edit distance
as well as similar $\tilde{\mathcal{O}}(n+$poly$(k))$-time algorithms for
generalizations to tree and Dyck edit distances. Surprisingly, all these
results hold only for unweighted instances.
</p>
<p>While unweighted edit distance is theoretically fundamental, almost all
real-world applications require weighted edit distance, where different weights
are assigned to different edit operations and may vary with the characters
being edited. Given a weight function $w: \Sigma \cup \{\varepsilon \}\times
\Sigma \cup \{\varepsilon \} \rightarrow \mathbb{R}_{\ge 0}$ (such that
$w(a,a)=0$ and $w(a,b)\ge 1$ for all $a,b\in \Sigma \cup \{\varepsilon\}$ with
$a\ne b$), the goal is to find an alignment that minimizes the total weight of
edits. Except for the vanilla $\mathcal{O}(n^2)$-time dynamic-programming
algorithm and its almost trivial $\mathcal{O}(nk)$-time implementation, none of
the aforementioned developments on the unweighted edit distance apply to the
weighted variant. In this paper, we propose the first
$\mathcal{O}(n+$poly$(k))$-time algorithm that computes weighted string edit
distance exactly, thus bridging a fundamental gap between our understanding of
unweighted and weighted edit distance. We then generalize this result to
weighted tree and Dyck edit distances, which lead to a deterministic algorithm
that improves upon the previous work for unweighted tree edit distance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1">Debarati Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Gilbert_J/0/1/0/all/0/1">Jacob Gilbert</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajiaghayi_M/0/1/0/all/0/1">MohammadTaghi Hajiaghayi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kociumaka_T/0/1/0/all/0/1">Tomasz Kociumaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_B/0/1/0/all/0/1">Barna Saha</a></p><p>Given two strings of length $n$ over alphabet $\Sigma$, and an upper bound
$k$ on their edit distance, the algorithm of Myers (Algorithmica'86) and Landau
and Vishkin (JCSS'88) computes the unweighted string edit distance in
$\mathcal{O}(n+k^2)$ time. Till date, it remains the fastest algorithm for
exact edit distance computation, and it is optimal under the Strong Exponential
Hypothesis (STOC'15). Over the years, this result has inspired many
developments, including fast approximation algorithms for string edit distance
as well as similar $\tilde{\mathcal{O}}(n+$poly$(k))$-time algorithms for
generalizations to tree and Dyck edit distances. Surprisingly, all these
results hold only for unweighted instances.
</p>
<p>While unweighted edit distance is theoretically fundamental, almost all
real-world applications require weighted edit distance, where different weights
are assigned to different edit operations and may vary with the characters
being edited. Given a weight function $w: \Sigma \cup \{\varepsilon \}\times
\Sigma \cup \{\varepsilon \} \rightarrow \mathbb{R}_{\ge 0}$ (such that
$w(a,a)=0$ and $w(a,b)\ge 1$ for all $a,b\in \Sigma \cup \{\varepsilon\}$ with
$a\ne b$), the goal is to find an alignment that minimizes the total weight of
edits. Except for the vanilla $\mathcal{O}(n^2)$-time dynamic-programming
algorithm and its almost trivial $\mathcal{O}(nk)$-time implementation, none of
the aforementioned developments on the unweighted edit distance apply to the
weighted variant. In this paper, we propose the first
$\mathcal{O}(n+$poly$(k))$-time algorithm that computes weighted string edit
distance exactly, thus bridging a fundamental gap between our understanding of
unweighted and weighted edit distance. We then generalize this result to
weighted tree and Dyck edit distances, which lead to a deterministic algorithm
that improves upon the previous work for unweighted tree edit distance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, February 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://ptreview.sublinear.info/2023/02/news-for-january-2023/'>News for January 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Welcome to the first batch of 2023. Looks like it&#8217;s going to be a good year, with 5 property testing or related papers (that I could find) already: An efficient asymmetric removal lemma and its limitations, by Lior Gishboliner, Asaf Shapira, and Yuval Wigderson (arXiv). One of the jewels of graph property testing is the [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Welcome to the first batch of 2023. Looks like it&#8217;s going to be a good year, with 5 property testing or related papers (that I could find) already: </p>



<p><strong>An efficient asymmetric removal lemma and its limitations</strong>, by Lior Gishboliner, Asaf Shapira, and Yuval Wigderson (<a href="https://arxiv.org/abs/2301.07693">arXiv</a>). One of the jewels of graph property testing is the triangle removel lemma (and its many generalizations and variants), which relates the number of triangles in a dense graph to its distance from being triangle-free: namely, any graph \(\varepsilon\)-far from being triangle-free must have \(\delta(\varepsilon)n^3\) triangles, where the density \(\delta(\varepsilon)\) only depends on the distance (and not the size of the graph!). This immediately leads to constant-query testers (and even &#8220;proximity-oblivious&#8221; testers) for triangle-freness (and, more generally, pattern-freeness). Unfortunately, the dependence on \(\varepsilon\) is quite bad, essentially a tower-type function (and it is known no polynomial bound is possible). This work attempts to bypass this impossibility result by proving an asymmetric removal lemma, or the form &#8220;any graph \(\varepsilon\)-far from being triangle-free must have \(\mathrm{poly}(\varepsilon)n^5\) 5-cycles&#8221; (and generalizations beyond triangles). This seems like a very interesting direction, with potential applications to property testing, and (who knows!) efficient testers for many properties hithertho only known to be (practically) testable for constant \(\varepsilon\).</p>



<p>Related (more removal lemmata!), a different work on this topic:</p>



<p><strong>The Minimum Degree Removal Lemma Thresholds</strong>, by Lior Gishboliner, Zhihan Jin, and Benny Sudakov (<a href="https://arxiv.org/abs/2301.13789">arXiv</a>). As mentioned above, removal lemmata relate the distance \(\varepsilon\) from being \(H\)-free (for a given subgraph \(H\)) to the density \(\delta(\varepsilon)\) of occurrences of \(H\) in the graph. Sadly, it is known that this density will be superpolynomial (in the distance) unless \(H\) is bipartite… which, while technically still yielding testing algorithms (query complexity independent of the size of the graph!), yields very inefficient testers (very bad dependence on \(\varepsilon\)!). This paper studies one direction to bypass this sad state of affairs: under which additional assumption on the underlying graph (specifically, bounds on its minimum degree) can we obtain a polynomial bound on \(\delta(\varepsilon)\)? And a linear bound? The authors give a tight degree condition for \(\delta(\varepsilon)\) to be polynomial when \(H\) is an odd cycle, and their results for the linear-dependence case establishes a separation between the two. Put differently: obtaining polynomial-query testers via removal lemmas is possible for a strictly larger class of graphs than linear-query ones!</p>



<p>And now, for something completely different: testing binary matrices!</p>



<p><strong>A Note on Property Testing of the Binary Rank</strong>, by Nader H. Bshouty (<a href="https://arxiv.org/abs/2301.04406">arXiv</a>). The binary rank of a matrix \(M\in\{0,1\}^{n\times m}\) is the smallest \(d\) such that there exist \(A\in\{0,1\}^{n\times d}\) and \(B\in\{0,1\}^{d\times m}\) with \(M=AB\); this can also be seen as the minimal number of bipartite cliques needed to partition the edges of a bipartite graph represented by \(M\). One can also define the relaxed notion of \(s\)-binary rank, if one enforces that each edge of the bipartite graph is covered by at most \(s\) bipartite cliques. The property testing question is then to decide, given inputs \(s,d,\varepsilon\), if \(M\) has \(s\)-binary rank at most \(d\), or is \(\varepsilon\)-far from it. The main result of this note is to give one-sided testers (one adaptive, and one non-adaptive) for \(s\)-binary rank with query complexity \(\tilde{O}(2^d)\) (for constant \(s\)), improving on the previous algorithms by a factor \(2^d\).</p>



<p>Into the quantum realm!</p>



<p><strong>Testing quantum satisfiability,</strong> by Ashley Montanaro, Changpeng Shao, and Dominic Verdon (<a href="https://arxiv.org/abs/2301.10699">arXiv</a>). Classically, one can study the property version of \(k\)-SAT, which asks to decide whether a given instance is satisfiable or far from being so. And people (namely, Alon and Shapira, in 2003) did! Quantumly, one can define an analogue of \(k\)-SAT, &#8220;quantum \(k\)-SAT&#8221;: and people (namely, Bravyi, in 2011) did! But what about property testing of quantum \(k\)-SAT? Well, now, people (namely, the authors of this paper) just did! Showing (Corollary 1.10) that one can efficiently distinguish between (1) the quantum \(k\)-SAT is satisfiable, and (2) it is far from satisfiable by a product state. This, effectively, extends the result of Alon–Shapira&#8217;03 to the quantum realm.</p>



<p>And to conclude, a foray into reinforcement learning via distribution testing…</p>



<p><strong>Lower Bounds for Learning in Revealing POMDPs</strong>, by Fan Chen, Huan Wang, Caiming Xiong, Song Mei, and Yu Bai (<a href="https://arxiv.org/abs/2302.01333">arXiv</a>). Alright, I&#8217;m even more out of my depth than usual here, so I&#8217;ll just copy (part of) the abstract, for fear I don&#8217;t do justice to the authors&#8217; work: &#8220;This paper studies the fundamental limits of reinforcement learning (RL) in the challenging <em>partially observable</em> setting. While it is well-established that learning in Partially Observable Markov Decision Processes (POMDPs) requires exponentially many samples in the worst case, a surge of recent work shows that polynomial sample complexities are achievable under the <em>revealing condition</em> &#8212; A natural condition that requires the observables to reveal some information about the unobserved latent states. However, the fundamental limits for learning in revealing POMDPs are much less understood, with existing lower bounds being rather preliminary and having substantial gaps from the current best upper bounds. We establish strong PAC and regret lower bounds for learning in revealing POMDPs. […] <strong>Technically, our hard instance construction adapts techniques in distribution testing, which is new to the RL literature and may be of independent interest.</strong>&#8221; (Emphasis mine)</p>



<p></p>
<p class="authors">By Clement Canonne</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T06:04:08Z">Wednesday, February 08 2023, 06:04</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03569'>Label propagation on binomial random graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marcos Kiwi, Lyuben Lichev, Dieter Mitsche, Pawe&#x142; Pra&#x142;at</p><p>We study a variant of the widely popular, fast and often used ``family'' of
community detection procedures referred to as label propagation algorithms.
Initially, given a network, each vertex starts with a random label in the
interval $[0,1]$. Then, in each round of the algorithm, every vertex switches
its label to the majority label in its neighborhood (including its own label).
At the first round, ties are broken towards smaller labels, while at each of
the next rounds, ties are broken uniformly at random.
</p>
<p>We investigate the performance of this algorithm on the binomial random graph
$\mathcal G(n,p)$. We show that for $np \ge n^{5/8+\varepsilon}$, the algorithm
terminates with a single label a.a.s. (which was previously known only for
$np\ge n^{3/4+\varepsilon}$). Moreover, we show that if $np\gg n^{2/3}$, a.a.s.
this label is the smallest one, whereas if $n^{5/8+\varepsilon}\le np\ll
n^{2/3}$, the surviving label is a.a.s. not the smallest one.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Kiwi_M/0/1/0/all/0/1">Marcos Kiwi</a>, <a href="http://arxiv.org/find/math/1/au:+Lichev_L/0/1/0/all/0/1">Lyuben Lichev</a>, <a href="http://arxiv.org/find/math/1/au:+Mitsche_D/0/1/0/all/0/1">Dieter Mitsche</a>, <a href="http://arxiv.org/find/math/1/au:+Pralat_P/0/1/0/all/0/1">Pawe&#x142; Pra&#x142;at</a></p><p>We study a variant of the widely popular, fast and often used ``family'' of
community detection procedures referred to as label propagation algorithms.
Initially, given a network, each vertex starts with a random label in the
interval $[0,1]$. Then, in each round of the algorithm, every vertex switches
its label to the majority label in its neighborhood (including its own label).
At the first round, ties are broken towards smaller labels, while at each of
the next rounds, ties are broken uniformly at random.
</p>
<p>We investigate the performance of this algorithm on the binomial random graph
$\mathcal G(n,p)$. We show that for $np \ge n^{5/8+\varepsilon}$, the algorithm
terminates with a single label a.a.s. (which was previously known only for
$np\ge n^{3/4+\varepsilon}$). Moreover, we show that if $np\gg n^{2/3}$, a.a.s.
this label is the smallest one, whereas if $n^{5/8+\varepsilon}\le np\ll
n^{2/3}$, the surviving label is a.a.s. not the smallest one.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03451'>The Solidarity Cover Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eran Rosenbluth</p><p>Various real-world problems consist of partitioning a set of locations into
disjoint subsets, each subset spread in a way that it covers the whole set with
a certain radius. Given a finite set S, a metric d, and a radius r, define a
subset (of S) S' to be an r-cover if and only if forall s in S there exists s'
in S' such that d(s,s') is less or equal to r. We examine the problem of
determining whether there exist m disjoint r-covers, naming it the Solidarity
Cover Problem (SCP). We consider as well the related optimization problems of
maximizing the number of r-covers, referred to as the partition size, and
minimizing the radius. We analyze the relation between the SCP and a graph
problem known as the Domatic Number Problem (DNP), both hard problems in the
general case. We show that the SCP is hard already in the Euclidean 2D setting,
implying hardness of the DNP already in the unit-disc-graph setting. As far as
we know, the latter is a result yet to be shown. We use the tight approximation
bound of (1-o(1))/ln(n) for the DNP's general case, shown by U.Feige,
M.Halld'orsson, G.Kortsarz, and A.Srinivasan (SIAM Journal on computing, 2002),
to deduce the same bound for partition-size approximation of the SCP in the
Euclidean space setting. We show an upper bound of 3 and lower bounds of 2 and
sqrt(2) for approximating the minimal radius in different settings of the SCP.
Lastly, in the Euclidean 2D setting we provide a general
bicriteria-approximation scheme which allows a range of possibilities for
trading the optimality of the radius in return for better approximation of the
partition size and vice versa. We demonstrate a usage of the scheme which
achieves an approximation of (1/16,2) for the partition size and radius
respectively.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rosenbluth_E/0/1/0/all/0/1">Eran Rosenbluth</a></p><p>Various real-world problems consist of partitioning a set of locations into
disjoint subsets, each subset spread in a way that it covers the whole set with
a certain radius. Given a finite set S, a metric d, and a radius r, define a
subset (of S) S' to be an r-cover if and only if forall s in S there exists s'
in S' such that d(s,s') is less or equal to r. We examine the problem of
determining whether there exist m disjoint r-covers, naming it the Solidarity
Cover Problem (SCP). We consider as well the related optimization problems of
maximizing the number of r-covers, referred to as the partition size, and
minimizing the radius. We analyze the relation between the SCP and a graph
problem known as the Domatic Number Problem (DNP), both hard problems in the
general case. We show that the SCP is hard already in the Euclidean 2D setting,
implying hardness of the DNP already in the unit-disc-graph setting. As far as
we know, the latter is a result yet to be shown. We use the tight approximation
bound of (1-o(1))/ln(n) for the DNP's general case, shown by U.Feige,
M.Halld'orsson, G.Kortsarz, and A.Srinivasan (SIAM Journal on computing, 2002),
to deduce the same bound for partition-size approximation of the SCP in the
Euclidean space setting. We show an upper bound of 3 and lower bounds of 2 and
sqrt(2) for approximating the minimal radius in different settings of the SCP.
Lastly, in the Euclidean 2D setting we provide a general
bicriteria-approximation scheme which allows a range of possibilities for
trading the optimality of the radius in return for better approximation of the
partition size and vice versa. We demonstrate a usage of the scheme which
achieves an approximation of (1/16,2) for the partition size and radius
respectively.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03456'>On the complexity of the approximate hypergraph homomorphism problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lorenzo Ciardo, Marcin Kozik, Andrei Krokhin, Tamio-Vesa Nakajima, Stanislav &#x17d;ivn&#xfd;</p><p>Understanding the computational complexity of fragments of the Constraint
Satisfaction Problem (CSP) has been instrumental in the formulation of
Feder-Vardi's Dichotomy Conjecture and its positive resolution by Bulatov and
Zhuk. An approximation version of the CSP - known as the promise CSP - has
recently gained prominence as an exciting generalisation of the CSP that
captures many fundamental computational problems. In this work, we establish a
computational complexity dichotomy for a natural fragment of the promise CSP
consisting of homomorphism problems involving a class of 3-uniform hypergraphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ciardo_L/0/1/0/all/0/1">Lorenzo Ciardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozik_M/0/1/0/all/0/1">Marcin Kozik</a>, <a href="http://arxiv.org/find/cs/1/au:+Krokhin_A/0/1/0/all/0/1">Andrei Krokhin</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakajima_T/0/1/0/all/0/1">Tamio-Vesa Nakajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Zivny_S/0/1/0/all/0/1">Stanislav &#x17d;ivn&#xfd;</a></p><p>Understanding the computational complexity of fragments of the Constraint
Satisfaction Problem (CSP) has been instrumental in the formulation of
Feder-Vardi's Dichotomy Conjecture and its positive resolution by Bulatov and
Zhuk. An approximation version of the CSP - known as the promise CSP - has
recently gained prominence as an exciting generalisation of the CSP that
captures many fundamental computational problems. In this work, we establish a
computational complexity dichotomy for a natural fragment of the promise CSP
consisting of homomorphism problems involving a class of 3-uniform hypergraphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03071'>Optimally Interpolating between Ex-Ante Fairness and Welfare</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mikael H&#xf8;gsgaard, Panagiotis Karras, Wenyue Ma, Nidhi Rathi, Chris Schwiegelshohn</p><p>For the fundamental problem of allocating a set of resources among
individuals with varied preferences, the quality of an allocation relates to
the degree of fairness and the collective welfare achieved. Unfortunately, in
many resource-allocation settings, it is computationally hard to maximize
welfare while achieving fairness goals.
</p>
<p>In this work, we consider ex-ante notions of fairness; popular examples
include the \emph{randomized round-robin algorithm} and \emph{sortition
mechanism}. We propose a general framework to systematically study the
\emph{interpolation} between fairness and welfare goals in a multi-criteria
setting. We develop two efficient algorithms ($\varepsilon-Mix$ and
$Simple-Mix$) that achieve different trade-off guarantees with respect to
fairness and welfare. $\varepsilon-Mix$ achieves an optimal multi-criteria
approximation with respect to fairness and welfare, while $Simple-Mix$ achieves
optimality up to a constant factor with zero computational overhead beyond the
underlying \emph{welfare-maximizing mechanism} and the \emph{ex-ante fair
mechanism}. Our framework makes no assumptions on either of the two underlying
mechanisms, other than that the fair mechanism produces a distribution over the
set of all allocations. Indeed, if these mechanisms are themselves
approximation algorithms, our framework will retain the approximation factor,
guaranteeing sensitivity to the quality of the underlying mechanisms, while
being \emph{oblivious} to them. We also give an extensive experimental analysis
for the aforementioned ex-ante fair mechanisms on real data sets, confirming
our theoretical analysis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hogsgaard_M/0/1/0/all/0/1">Mikael H&#xf8;gsgaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Karras_P/0/1/0/all/0/1">Panagiotis Karras</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Wenyue Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Rathi_N/0/1/0/all/0/1">Nidhi Rathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwiegelshohn_C/0/1/0/all/0/1">Chris Schwiegelshohn</a></p><p>For the fundamental problem of allocating a set of resources among
individuals with varied preferences, the quality of an allocation relates to
the degree of fairness and the collective welfare achieved. Unfortunately, in
many resource-allocation settings, it is computationally hard to maximize
welfare while achieving fairness goals.
</p>
<p>In this work, we consider ex-ante notions of fairness; popular examples
include the \emph{randomized round-robin algorithm} and \emph{sortition
mechanism}. We propose a general framework to systematically study the
\emph{interpolation} between fairness and welfare goals in a multi-criteria
setting. We develop two efficient algorithms ($\varepsilon-Mix$ and
$Simple-Mix$) that achieve different trade-off guarantees with respect to
fairness and welfare. $\varepsilon-Mix$ achieves an optimal multi-criteria
approximation with respect to fairness and welfare, while $Simple-Mix$ achieves
optimality up to a constant factor with zero computational overhead beyond the
underlying \emph{welfare-maximizing mechanism} and the \emph{ex-ante fair
mechanism}. Our framework makes no assumptions on either of the two underlying
mechanisms, other than that the fair mechanism produces a distribution over the
set of all allocations. Indeed, if these mechanisms are themselves
approximation algorithms, our framework will retain the approximation factor,
guaranteeing sensitivity to the quality of the underlying mechanisms, while
being \emph{oblivious} to them. We also give an extensive experimental analysis
for the aforementioned ex-ante fair mechanisms on real data sets, confirming
our theoretical analysis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03143'>Sparsification of Monotone $k$-Submodular Functions of Low Curvature</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jannik Kudla, Stanislav &#x17d;ivn&#xfd;</p><p>Pioneered by Benczur and Karger for cuts in graphs [STOC'96], sparsification
is a fundamental topic with wide-ranging applications that has been studied,
e.g., for graphs and hypergraphs, in a combinatorial and a spectral setting,
and with additive and multiplicate error bounds. Rafiey and Yoshida recently
considered sparsification of decomposable submodular functions [AAAI'22]. We
extend their work by presenting an efficient algorithm for a sparsifier for
monotone $k$-submodular functions of low curvature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kudla_J/0/1/0/all/0/1">Jannik Kudla</a>, <a href="http://arxiv.org/find/cs/1/au:+Zivny_S/0/1/0/all/0/1">Stanislav &#x17d;ivn&#xfd;</a></p><p>Pioneered by Benczur and Karger for cuts in graphs [STOC'96], sparsification
is a fundamental topic with wide-ranging applications that has been studied,
e.g., for graphs and hypergraphs, in a combinatorial and a spectral setting,
and with additive and multiplicate error bounds. Rafiey and Yoshida recently
considered sparsification of decomposable submodular functions [AAAI'22]. We
extend their work by presenting an efficient algorithm for a sparsifier for
monotone $k$-submodular functions of low curvature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03239'>Calibrated Recommendations for Users with Decaying Attention</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jon Kleinberg, Emily Ryu, &#xc9;va Tardos</p><p>Recommendation systems capable of providing diverse sets of results are a
focus of increasing importance, with motivations ranging from fairness to
novelty and other aspects of optimizing user experience. One form of diversity
of recent interest is calibration, the notion that personalized recommendations
should reflect the full distribution of a user's interests, rather than a
single predominant category -- for instance, a user who mainly reads
entertainment news but also wants to keep up with news on the environment and
the economy would prefer to see a mixture of these genres, not solely
entertainment news. Existing work has formulated calibration as a subset
selection problem; this line of work observes that the formulation requires the
unrealistic assumption that all recommended items receive equal consideration
from the user, but leaves as an open question the more realistic setting in
which user attention decays as they move down the list of results.
</p>
<p>In this paper, we consider calibration with decaying user attention under two
different models. In both models, there is a set of underlying genres that
items can belong to. In the first setting, where items are represented by
fine-grained mixtures of genre percentages, we provide a
$(1-1/e)$-approximation algorithm by extending techniques for constrained
submodular optimization. In the second setting, where items are coarsely binned
into a single genre each, we surpass the $(1-1/e)$ barrier imposed by
submodular maximization and give a $2/3$-approximate greedy algorithm. Our work
thus addresses the problem of capturing ordering effects due to decaying
attention, allowing for the extension of near-optimal calibration from
recommendation sets to recommendation lists.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1">Jon Kleinberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryu_E/0/1/0/all/0/1">Emily Ryu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tardos_E/0/1/0/all/0/1">&#xc9;va Tardos</a></p><p>Recommendation systems capable of providing diverse sets of results are a
focus of increasing importance, with motivations ranging from fairness to
novelty and other aspects of optimizing user experience. One form of diversity
of recent interest is calibration, the notion that personalized recommendations
should reflect the full distribution of a user's interests, rather than a
single predominant category -- for instance, a user who mainly reads
entertainment news but also wants to keep up with news on the environment and
the economy would prefer to see a mixture of these genres, not solely
entertainment news. Existing work has formulated calibration as a subset
selection problem; this line of work observes that the formulation requires the
unrealistic assumption that all recommended items receive equal consideration
from the user, but leaves as an open question the more realistic setting in
which user attention decays as they move down the list of results.
</p>
<p>In this paper, we consider calibration with decaying user attention under two
different models. In both models, there is a set of underlying genres that
items can belong to. In the first setting, where items are represented by
fine-grained mixtures of genre percentages, we provide a
$(1-1/e)$-approximation algorithm by extending techniques for constrained
submodular optimization. In the second setting, where items are coarsely binned
into a single genre each, we surpass the $(1-1/e)$ barrier imposed by
submodular maximization and give a $2/3$-approximate greedy algorithm. Our work
thus addresses the problem of capturing ordering effects due to decaying
attention, allowing for the extension of near-optimal calibration from
recommendation sets to recommendation lists.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03245'>Two Parallel PageRank Algorithms via Improving Forward Push</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Qi Zhang, Rongxia Tang, Zhengan Yao, Jun Liang</p><p>Initially used to rank web pages, PageRank has now been applied in many
fields. With the growing scale of graph, accelerating PageRank computing is
urged and designing parallel algorithm is a feasible solution. In this paper,
two parallel PageRank algorithms IFP1 and IFP2 are proposed via improving the
state-of-the-art Personalized PageRank algorithm, i.e., Forward Push.
Theoretical analysis indicates that, IFP1 can take advantage of the DAG
structure of the graph, where the dangling vertices improves the convergence
rate and the unreferenced vertices decreases the computation amount. As an
improvement of IFP1, IFP2 pushes mass to the dangling vertices only once but
rather many times, and thus decreases the computation amount further.
Experiments on six data sets illustrate that both IFP1 and IFP2 outperform
Power method, where IFP2 with 38 parallelism can be at most 50 times as fast as
the Power method.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1">Rongxia Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1">Zhengan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jun Liang</a></p><p>Initially used to rank web pages, PageRank has now been applied in many
fields. With the growing scale of graph, accelerating PageRank computing is
urged and designing parallel algorithm is a feasible solution. In this paper,
two parallel PageRank algorithms IFP1 and IFP2 are proposed via improving the
state-of-the-art Personalized PageRank algorithm, i.e., Forward Push.
Theoretical analysis indicates that, IFP1 can take advantage of the DAG
structure of the graph, where the dangling vertices improves the convergence
rate and the unreferenced vertices decreases the computation amount. As an
improvement of IFP1, IFP2 pushes mass to the dangling vertices only once but
rather many times, and thus decreases the computation amount further.
Experiments on six data sets illustrate that both IFP1 and IFP2 outperform
Power method, where IFP2 with 38 parallelism can be at most 50 times as fast as
the Power method.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03317'>Engineering Shared-Memory Parallel Shuffling to Generate Random Permutations In-Place</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Manuel Penschuck</p><p>Shuffling is the process of rearranging a sequence of elements into a random
order such that any permutation occurs with equal probability. It is an
important building block in a plethora of techniques used in virtually all
scientific areas. Consequently considerable work has been devoted to the design
and implementation of shuffling algorithms.
</p>
<p>We engineer, -- to the best of our knowledge -- for the first time, a
practically fast, parallel shuffling algorithm with $\Oh{\sqrt{n}\log n}$
parallel depth that requires only poly-logarithmic auxiliary memory. Our
reference implementations in Rust are freely available, easy to include in
other projects, and can process large data sets approaching the size of the
system's memory. In an empirical evaluation, we compare our implementations
with a number of existing solutions on various computer architectures. Our
algorithms consistently achieve the highest through-put on all machines.
Further, we demonstrate that the runtime of our parallel algorithm is
comparable to the time that other algorithms may take to acquire the memory
from the operating system to copy the input.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Penschuck_M/0/1/0/all/0/1">Manuel Penschuck</a></p><p>Shuffling is the process of rearranging a sequence of elements into a random
order such that any permutation occurs with equal probability. It is an
important building block in a plethora of techniques used in virtually all
scientific areas. Consequently considerable work has been devoted to the design
and implementation of shuffling algorithms.
</p>
<p>We engineer, -- to the best of our knowledge -- for the first time, a
practically fast, parallel shuffling algorithm with $\Oh{\sqrt{n}\log n}$
parallel depth that requires only poly-logarithmic auxiliary memory. Our
reference implementations in Rust are freely available, easy to include in
other projects, and can process large data sets approaching the size of the
system's memory. In an empirical evaluation, we compare our implementations
with a number of existing solutions on various computer architectures. Our
algorithms consistently achieve the highest through-put on all machines.
Further, we demonstrate that the runtime of our parallel algorithm is
comparable to the time that other algorithms may take to acquire the memory
from the operating system to copy the input.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03527'>First-Order Model Checking on Structurally Sparse Graph Classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jan Dreier, Nikolas M&#xe4;hlmann, Sebastian Siebertz</p><p>A class of graphs is structurally nowhere dense if it can be constructed from
a nowhere dense class by a first-order transduction. Structurally nowhere dense
classes vastly generalize nowhere dense classes and constitute important
examples of monadically stable classes. We show that the first-order model
checking problem is fixed-parameter tractable on every structurally nowhere
dense class of graphs.
</p>
<p>Our result builds on a recently developed game-theoretic characterization of
monadically stable graph classes. As a second key ingredient of independent
interest, we provide a polynomial-time algorithm for approximating weak
neighborhood covers (on general graphs). We combine the two tools into a
recursive locality-based model checking algorithm. This algorithm is efficient
on every monadically stable graph class admitting flip-closed sparse weak
neighborhood covers, where flip-closure is a mild additional assumption.
Thereby, establishing efficient first-order model checking on monadically
stable classes is reduced to proving the existence of flip-closed sparse weak
neighborhood covers on these classes - a purely combinatorial problem. We
complete the picture by proving the existence of the desired covers for
structurally nowhere dense classes: we show that every structurally nowhere
dense class can be sparsified by contracting local sets of vertices, enabling
us to lift the existence of covers from sparse classes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dreier_J/0/1/0/all/0/1">Jan Dreier</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahlmann_N/0/1/0/all/0/1">Nikolas M&#xe4;hlmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Siebertz_S/0/1/0/all/0/1">Sebastian Siebertz</a></p><p>A class of graphs is structurally nowhere dense if it can be constructed from
a nowhere dense class by a first-order transduction. Structurally nowhere dense
classes vastly generalize nowhere dense classes and constitute important
examples of monadically stable classes. We show that the first-order model
checking problem is fixed-parameter tractable on every structurally nowhere
dense class of graphs.
</p>
<p>Our result builds on a recently developed game-theoretic characterization of
monadically stable graph classes. As a second key ingredient of independent
interest, we provide a polynomial-time algorithm for approximating weak
neighborhood covers (on general graphs). We combine the two tools into a
recursive locality-based model checking algorithm. This algorithm is efficient
on every monadically stable graph class admitting flip-closed sparse weak
neighborhood covers, where flip-closure is a mild additional assumption.
Thereby, establishing efficient first-order model checking on monadically
stable classes is reduced to proving the existence of flip-closed sparse weak
neighborhood covers on these classes - a purely combinatorial problem. We
complete the picture by proving the existence of the desired covers for
structurally nowhere dense classes: we show that every structurally nowhere
dense class can be sparsified by contracting local sets of vertices, enabling
us to lift the existence of covers from sparse classes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03627'>Tight algorithms for connectivity problems parameterized by clique-width</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Falko Hegerfeld, Stefan Kratsch</p><p>The complexity of problems involving global constraints is usually much more
difficult to understand than the complexity of problems only involving local
constraints. A natural form of global constraints are connectivity constraints.
We study connectivity problems from a fine-grained parameterized perspective.
In a breakthrough, Cygan et al. (TALG 2022) first obtained algorithms with
single-exponential running time c^{tw} n^O(1) for connectivity problems
parameterized by treewidth by introducing the cut-and-count-technique.
Furthermore, the obtained bases c were shown to be optimal under the Strong
Exponential-Time Hypothesis (SETH).
</p>
<p>However, since only sparse graphs may admit small treewidth, we lack
knowledge of the fine-grained complexity of connectivity problems with respect
to dense structure. The most popular graph parameter to measure dense structure
is arguably clique-width, which intuitively measures how easily a graph can be
constructed by repeatedly adding bicliques. Bergougnoux and Kant\'e (TCS 2019)
have shown, using the rank-based approach, that also parameterized by
clique-width many connectivity problems admit single-exponential algorithms.
Unfortunately, the obtained running times are far from optimal under SETH.
</p>
<p>We show how to obtain optimal running times parameterized by clique-width for
two benchmark connectivity problems, namely Connected Vertex Cover and
Connected Dominating Set. These are the first tight results for connectivity
problems with respect to clique-width and these results are obtained by
developing new algorithms based on the cut-and-count-technique and novel lower
bound constructions. Precisely, we show that there exist one-sided error
Monte-Carlo algorithms that given a k-clique-expression solve Connected Vertex
Cover in time 6^k n^O(1), and Connected Dominating Set in time 5^k n^O(1). Both
results are shown to be tight under SETH.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hegerfeld_F/0/1/0/all/0/1">Falko Hegerfeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Kratsch_S/0/1/0/all/0/1">Stefan Kratsch</a></p><p>The complexity of problems involving global constraints is usually much more
difficult to understand than the complexity of problems only involving local
constraints. A natural form of global constraints are connectivity constraints.
We study connectivity problems from a fine-grained parameterized perspective.
In a breakthrough, Cygan et al. (TALG 2022) first obtained algorithms with
single-exponential running time c^{tw} n^O(1) for connectivity problems
parameterized by treewidth by introducing the cut-and-count-technique.
Furthermore, the obtained bases c were shown to be optimal under the Strong
Exponential-Time Hypothesis (SETH).
</p>
<p>However, since only sparse graphs may admit small treewidth, we lack
knowledge of the fine-grained complexity of connectivity problems with respect
to dense structure. The most popular graph parameter to measure dense structure
is arguably clique-width, which intuitively measures how easily a graph can be
constructed by repeatedly adding bicliques. Bergougnoux and Kant\'e (TCS 2019)
have shown, using the rank-based approach, that also parameterized by
clique-width many connectivity problems admit single-exponential algorithms.
Unfortunately, the obtained running times are far from optimal under SETH.
</p>
<p>We show how to obtain optimal running times parameterized by clique-width for
two benchmark connectivity problems, namely Connected Vertex Cover and
Connected Dominating Set. These are the first tight results for connectivity
problems with respect to clique-width and these results are obtained by
developing new algorithms based on the cut-and-count-technique and novel lower
bound constructions. Precisely, we show that there exist one-sided error
Monte-Carlo algorithms that given a k-clique-expression solve Connected Vertex
Cover in time 6^k n^O(1), and Connected Dominating Set in time 5^k n^O(1). Both
results are shown to be tight under SETH.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03658'>Planted Bipartite Graph Detection</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Asaf Rotenberg, Wasim Huleihel, Ofer Shayevitz</p><p>We consider the task of detecting a hidden bipartite subgraph in a given
random graph. Specifically, under the null hypothesis, the graph is a
realization of an Erd\H{o}s-R\'{e}nyi random graph over $n$ vertices with edge
density $q$. Under the alternative, there exists a planted $k_{\mathsf{R}}
\times k_{\mathsf{L}}$ bipartite subgraph with edge density $p&gt;q$. We derive
asymptotically tight upper and lower bounds for this detection problem in both
the dense regime, where $q,p = \Theta\left(1\right)$, and the sparse regime
where $q,p = \Theta\left(n^{-\alpha}\right), \alpha \in \left(0,2\right]$.
Moreover, we consider a variant of the above problem, where one can only
observe a relatively small part of the graph, by using at most $\mathsf{Q}$
edge queries. For this problem, we derive upper and lower bounds in both the
dense and sparse regimes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rotenberg_A/0/1/0/all/0/1">Asaf Rotenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Huleihel_W/0/1/0/all/0/1">Wasim Huleihel</a>, <a href="http://arxiv.org/find/cs/1/au:+Shayevitz_O/0/1/0/all/0/1">Ofer Shayevitz</a></p><p>We consider the task of detecting a hidden bipartite subgraph in a given
random graph. Specifically, under the null hypothesis, the graph is a
realization of an Erd\H{o}s-R\'{e}nyi random graph over $n$ vertices with edge
density $q$. Under the alternative, there exists a planted $k_{\mathsf{R}}
\times k_{\mathsf{L}}$ bipartite subgraph with edge density $p&gt;q$. We derive
asymptotically tight upper and lower bounds for this detection problem in both
the dense regime, where $q,p = \Theta\left(1\right)$, and the sparse regime
where $q,p = \Theta\left(n^{-\alpha}\right), \alpha \in \left(0,2\right]$.
Moreover, we consider a variant of the above problem, where one can only
observe a relatively small part of the graph, by using at most $\mathsf{Q}$
edge queries. For this problem, we derive upper and lower bounds in both the
dense and sparse regimes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, February 07
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/07/postdoc-at-department-of-computer-science-stony-brook-university-apply-by-april-8-2023/'>Postdoc at Department of Computer Science, Stony Brook University (apply by April 8, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The department of Computer Science at Stony Brook University is looking to hire a postdoc in quantum information science, including but not limited to complexity theory, property testing, algorithms, sensing, and program analysis, with an expected start date in May 2023 and a duration of 1+1 years. The postdocs will work closely with Prof Nengkun [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The department of Computer Science at Stony Brook University is looking to hire a postdoc in quantum information science, including but not limited to complexity theory, property testing, algorithms, sensing, and program analysis, with an expected start date in May 2023 and a duration of 1+1 years. The postdocs will work closely with Prof Nengkun Yu and Prof Supartha Podder.</p>
<p>Website: <a href="https://stonybrooku.taleo.net/careersection/2/jobdetail.ftl?job=2204491&amp;tz=GMT-05%3A00&amp;tzname=America%2FNew_York">https://stonybrooku.taleo.net/careersection/2/jobdetail.ftl?job=2204491&amp;tz=GMT-05%3A00&amp;tzname=America%2FNew_York</a><br />
Email: nengkun.yu@cs.stonybrook.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-07T17:30:54Z">Tuesday, February 07 2023, 17:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/02/07/focs-2022-program/'>FOCS 2022 Program</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Alvy Ray Smith designed the distinctive cover art that was a notable feature of FOCS proceedings until FOCS ended the production of printed proceedings in 2010. FOCS was founded in 1960 as the Symposium on Switching Circuit Theory and Logical Design. The 1960 conference did not have a separate published proceedings but most of the [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Alvy Ray Smith designed the distinctive cover art that was a notable feature of FOCS proceedings until FOCS ended the production of printed proceedings in 2010. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/07/focs-2022-program/ars/" rel="attachment wp-att-21047"><img data-attachment-id="21047" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/07/focs-2022-program/ars/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?fit=225%2C225&amp;ssl=1" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ars" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?fit=225%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?fit=225%2C225&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?resize=225%2C225&#038;ssl=1" alt="" width="225" height="225" class="aligncenter size-full wp-image-21047" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?w=225&amp;ssl=1 225w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1" /></a></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/07/focs-2022-program/cover-2/" rel="attachment wp-att-21048"><img data-attachment-id="21048" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/07/focs-2022-program/cover-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpg?fit=378%2C450&amp;ssl=1" data-orig-size="378,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="cover" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpg?fit=252%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpg?fit=378%2C450&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpg?resize=378%2C450&#038;ssl=1" alt="" width="378" height="450" class="aligncenter size-full wp-image-21048" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpg?w=378&amp;ssl=1 378w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpg?resize=252%2C300&amp;ssl=1 252w" sizes="(max-width: 378px) 100vw, 378px" data-recalc-dims="1" /></a></p>
<p>FOCS was founded in 1960 as the Symposium on Switching Circuit Theory and Logical Design. The 1960 conference did not have a separate published proceedings but most of the papers were published in the second half of the proceedings of the 1961 conference. For the 7th instantiation of the conference in 1966, the name was changed to the Symposium on Switching and Automata Theory (SWAT). The greatly increased breadth of the conference led to a name change to its present one in 1975. </p>
<p><strong>FOCS 2022</strong></p>
<p>Yes the FOCS 2023 is about to be out. But I was looking at the &#8220;old&#8221; ones and thought this might be useful. So here are the papers with pointers to online versions. We will do the same for the 2023 version.</p>
<p><a href="https://arxiv.org/pdf/2202.04551.pdf">Shortest Paths without a Map, but with an Entropic Regularizer.</a><br />
Sebastien Bubeck (Microsoft Research), Christian Coester (University of Sheffield), Yuval Rabani (Hebrew University).</p>
<p><a href="https://arxiv.org/abs/2203.02763">Online List Labeling: Breaking the <span class="math inline">log<sup>2</sup><em>n</em></span> Barrier.</a><br />
Michael A. Bender (Stony Brook University), Alex Conway (VMWare Research), Martin Farach-Colton (Rutgers University), Hanna Komlos (Rutgers University), William Kuszmaul (MIT), Nicole Wein (DIMACS).</p>
<p><a href="https://arxiv.org/abs/2205.07175">Simple Hard Instances for Low-Depth Algebraic Proofs.</a><br />
Nashlen Govindasamy (Imperial College London), Tuomas Hakoniemi (Imperial College London), Iddo Tzameret (Imperial College London).</p>
<p><a href="https://arxiv.org/abs/1904.05390">Constant Approximation of Min-Distances in Near-Linear Time.</a><br />
Shiri Chechik (Tel Aviv University), Tianyi Zhang (Tel Aviv University).</p>
<p><a href="https://arxiv.org/abs/2207.01761">First Price Auction is <span class="math inline">1 − 1/<em>e</em><sup>2</sup></span> Efficient.</a><br />
Yaonan Jin (Columbia University), Pinyan Lu (Shanghai University of Finance and Economics).</p>
<p><a href="https://arxiv.org/abs/2112.05106">Estimating the Longest Increasing Subsequence in Nearly Optimal Time.</a><br />
Alexandr Andoni (Columbia University), Negev Shekel Nosatzki (Columbia University), Sandip Sinha (Columbia University), Clifford Stein (Columbia University).</p>
<p><a href="https://arxiv.org/abs/2204.01425">Order Selection Prophet Inequality: From Threshold Optimization to Arrival Time Design.</a><br />
Bo Peng (ITCS, Shanghai University of Finance and Economics), Zhihao Gavin Tang (ITCS, Shanghai University of Finance and Economics).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996652">Using invariant theory to fool polynomials.</a><br />
Harm Derksen (Northeastern University), Emanuele Viola (Northeastern University).</p>
<p><a href="https://arxiv.org/pdf/2111.13198.pdf">The Implicit Graph Conjecture is False.</a><br />
Hamed Hatami (McGill University), Pooya Hatami (Ohio State University).</p>
<p><a href="https://arxiv.org/abs/2201.05674">Cut Query Algorithms with Star Contraction.</a><br />
Yuval Efron (Columbia University), Danupon Nanongkai (University of Copenhagen &amp; KTH), Sagnik Mukhopadhyay (University of Sheffield), Simon Apers (CNRS IRIF), Troy Lee (University of Technology Sydney), Pawel Gawrychowski (University of Wroc?aw).</p>
<p><a href="https://arxiv.org/abs/2202.08688">Improved Optimal Testing Results from Global Hypercontractivity.</a><br />
Tali Kaufman (Bar Ilan University), Dor Minzer (MIT).</p>
<p><a href="https://arxiv.org/abs/2209.06038">A Hash Table Without Hash Functions, and How to Get the Most out of Your Random Bits.</a><br />
William Henry Kuszmaul (Massachusetts Institute of Technology (MIT)).</p>
<p><a href="https://arxiv.org/abs/2205.06558">Balanced Allocations: The Heavily Loaded Case with Deletions.</a><br />
Nikhil Bansal (University of Michigan), William Kuszmaul (MIT).</p>
<p><a href="https://arxiv.org/abs/2203.01550">A Characterization of Multiclass Learnability.</a><br />
Nataly Brukhim (Princeton University), Daniel Carmon (Technion), Irit Dinur (Weizmann), Shay Moran (Technion and Google), Amir Yehudayoff (Technion-IIT).</p>
<p><a href="https://arxiv.org/abs/2209.07016">Algorithms and Lower Bounds for Replacement Paths under Multiple Edge Failures.</a><br />
Virginia Vassilevska Williams (Massachusetts Institute of Technology), Eyob Woldeghebriel (Massachusetts Institute of Technology), Yinzhan Xu (Massachusetts Institute of Technology).</p>
<p><a href="https://arxiv.org/abs/2208.10959">Derandomizing Directed Random Walks in Almost-Linear Time.</a><br />
Rasmus Kyng (ETH Zurich, Department of Computer Science), Simon Meierhans (ETH Zurich, Department of Computer Science), Maximilian Probst Gutenberg (ETH Zurich, Department of Computer Science).</p>
<p><a href="https://arxiv.org/abs/2203.07346">Sparse random hypergraphs: Non-backtracking spectra and community detection.</a><br />
Ludovic Stephan (Ecole Polytechnique Federale de Lausanne), Yizhe Zhu (University of California, Irvine).</p>
<p><a href="https://arxiv.org/abs/2207.04923">Killing a Vortex.</a><br />
Dimitrios Thilikos (LIRMM, Univ Montpellier, CNRS, Montpellier, France), Sebastian Wiederrecht (LIRMM, Univ Montpellier, CNRS, Montpellier, France).</p>
<p><a href="https://arxiv.org/abs/2203.15627">Low Treewidth Embeddings of Planar and Minor-Free Metrics.</a><br />
Hung Le (University of Massachusetts), Arnold Filtser (Bar-Ilan University).</p>
<p><a href="https://arxiv.org/abs/2203.06168">Cheeger Inequalities for Vertex Expansion and Reweighted Eigenvalues.</a><br />
Tsz Chiu Kwok (Shanghai University of Finance and Economics), Lap Chi Lau (University of Waterloo), Kam Chuen Tung (University of Waterloo).</p>
<p><a href="https://arxiv.org/abs/2204.01923">Algorithms for the ferromagnetic Potts model on expanders.</a><br />
Charlie Carlson (University of Colorado, Boulder), Ewan Davies (University of Colorado, Boulder), Nicolas Fraiman (University of North Carolina at Chapel Hill), Alexandra Kolla (University of Colorado, Boulder and University of California Santa Cruz), Aditya Potukuchi (University of Illinois at Chicago), Corrine Yap (Rutgers University).</p>
<p><a href="https://arxiv.org/abs/2208.02526">Nearly Optimal Communication and Query Complexity of Bipartite Matching.</a><br />
Joakim Blikstad (KTH Royal Institute of Technology), Jan van den Brand (Simons Institute and UC Berkeley), Yuval Efron (Columbia University USA), Sagnik Mukhopadhyay (University of Sheffield UK), Danupon Nanongkai (University of Copenhagen &amp; KTH).</p>
<p><a href="https://arxiv.org/abs/2204.02550">Continuous LWE is as Hard as LWE &amp; Applications to Learning Gaussian Mixtures.</a><br />
Aparna Gupte (MIT CSAIL), Neekon Vafa (MIT CSAIL), Vinod Vaikuntanathan (MIT CSAIL).</p>
<p><a href="https://arxiv.org/abs/2204.02063">Verifiable Quantum Advantage without Structure.</a><br />
Takashi Yamakawa (NTT Social Informatics Laboratories), Mark Zhandry (Princeton University and NTT Research).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996896">Separated borders: Exponential-gap fanin-hierarchy theorem for approximative depth-3 circuits.</a><br />
Pranjal Dutta (Chennai Mathematical Institute), Nitin Saxena (Department of Computer Science &amp; Engg., Indian Institute of Technology Kanpur).</p>
<p><a href="https://arxiv.org/abs/2208.13920">Fitting Metrics and Ultrametrics with Minimum Disagreements.</a><br />
Vincent Cohen-Addad (Google), Chenglin Fan (Sorbonne Universite, Paris, France), Euiwoong Lee (University of Michigan), Arnaud de Mesmay (CNRS, LIGM, Universite Gustave Eiffel).</p>
<p><a href="https://arxiv.org/abs/2203.15667">Algorithms and Barriers in the Symmetric Binary Perceptron Model.</a><br />
David Gamarnik (MIT), Eren Can Kizildag (MIT), Will Perkins (University of Illinois at Chicago), Changji Xu (Harvard).</p>
<p><a href="https://arxiv.org/abs/2211.10887">Differential Privacy from Locally Adjustable Graph Algorithms: k-Core Decomposition, Low Outdegree Ordering, and Densest Subgraphs.</a><br />
Laxman Dhulipala (Google Research), Quanquan C. Liu (Northwestern University), Sofya Raskhodnikova (Boston University), Jessica Shi (Massahusetts Institute of Technology), Julian Shun (Massahusetts Institute of Technology), Shangdi Yu (Massachusetts Institute of Technology).</p>
<p><a href="https://www.math.ucla.edu/~pak/papers/SharpP11.pdf">What is in <span class="math inline">#<em>P</em></span> and what is not?.</a><br />
Christian Ikenmeyer (University of Liverpool), Igor Pak (University of California, Los Angeles).</p>
<p><a href="https://arxiv.org/abs/2203.05093">Sampling from the Sherrington-Kirkpatrick Gibbs measure via algorithmic stochastic localization.</a><br />
Ahmed El Alaoui (Cornell University), Andrea Montanari (Stanford University), Mark Sellke (Stanford University).</p>
<p><a href="https://arxiv.org/abs/2206.00213">The Quantum and Classical Streaming Complexity of Quantum and Classical Max-Cut.</a><br />
John Kallaugher (Sandia National Laboratories), Ojas Parekh (Sandia National Laboratories).</p>
<p><a href="https://arxiv.org/abs/2204.01665">Linear Hashing with <span class="math inline">ℓ<sub>∞</sub></span> guarantees and two-sided Kakeya bounds.</a><br />
Manik Dhar (Princeton University), Zeev Dvir (Princeton University).</p>
<p><a href="https://arxiv.org/abs/2204.03790">High-Dimensional Geometric Streaming in Polynomial Space.</a><br />
David P. Woodruff (Carnegie Mellon University), Taisuke Yasuda (Carnegie Mellon University).</p>
<p><a href="https://arxiv.org/abs/2111.04888">Active Linear Regression for <span class="math inline">ℓ<sub><em>p</em></sub></span> Norms and Beyond.</a><br />
Cameron Musco (University of Massachusetts Amherst), Christopher Musco (New York University), David P. Woodruff (Carnegie Mellon University), Taisuke Yasuda (Carnegie Mellon University).</p>
<p><a href="https://arxiv.org/abs/2110.07847">Tight Lipschitz Hardness for Optimizing Mean Field Spin Glasses.</a><br />
Brice Huang (Massachusetts Institute of Technology), Mark Sellke (Stanford University).</p>
<p><a href="https://arxiv.org/abs/2207.10889">Correlation Clustering with Sherali-Adams.</a><br />
Vincent Cohen-Addad (Google Research), Euiwoong Lee (University of Michigan), Alantha Newman (Laboratoire G-SCOP (CNRS, Grenoble-INP)).</p>
<p><a href="https://arxiv.org/abs/2101.08208">Solving SDP Faster: A Robust IPM Framework and Efficient Implementation.</a><br />
Baihe Huang (Peking University), Shunhua Jiang (Columbia University), Zhao Song (Adobe Research), Runzhou Tao (Columbia University), Ruizhe Zhang (The University of Texas at Austin).</p>
<p><a href="https://arxiv.org/abs/2204.06974">Planting Undetectable Backdoors in Machine Learning Models.</a><br />
Shafi Goldwasser (UC Berkeley), Michael P. Kim (UC Berkeley), Vinod Vaikuntanathan (MIT), Or Zamir (IAS).</p>
<p><a href="https://arxiv.org/abs/2209.05839">Bounded depth proof for Tseitin formulas on the grid; revisited.</a><br />
Johan Hastad (KTH Royal Institute of Technology), Kilian Risse (KTH Royal Institute of Technology).</p>
<p><a href="https://arxiv.org/abs/2210.01104">Local Computation of Maximal Independent Set.</a><br />
Mohsen Ghaffari (MIT).</p>
<p><a href="https://arxiv.org/abs/2204.13648">Survivable Network Design Revisited: Group-Connectivity.</a><br />
Qingyun Chen (University of California, Merced), Bundit Laekhanukit (Shanghai University of Finance and Economics), Chao Liao (Huawei TCS Lab), Yuhao Zhang (Shanghai Jiao Tong University).</p>
<p><a href="https://arxiv.org/abs/2209.01873">Induced Cycles and Paths Are Harder Than You Think.</a><br />
Mina Dalirrooyfard (Massachusetts Institute of Technology), Virginia Vassilevska Williams (Massachusetts Institute of Technology).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996753">Binary Codes with Resilience Beyond 1/4 via Interaction.</a><br />
Klim Efremenko (Ben-Gurion University), Gillat Kol (Princeton University), Raghuvansh Saxena (Microsoft Research), Zhijun Zhang (Princeton University).</p>
<p><a href="https://arxiv.org/abs/2203.03456">Negative-Weight Single-Source Shortest Paths in Near-Linear Time.</a><br />
Aaron Bernstein (Rutgers University), Danupon Nanongkai (University of Copenhagen), Christian Wulff-Nilsen (University of Copenhagen).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996716">Error Correcting Codes that Achieve BSC Capacity Against Channels that are Poly-Size Circuits.</a><br />
Ronen Shaltiel (University of Haifa), Jad Silbak (Tel Aviv University).</p>
<p><a href="https://arxiv.org/abs/2208.00122">Polynomial-Time Power-Sum Decomposition of Polynomials.</a><br />
Mitali Bafna (Harvard University), Jun-Ting Hsieh (Carnegie Mellon University), Pravesh Kothari (CMU), Jeff Xu (Carnegie Mellon University).</p>
<p><a href="https://eccc.weizmann.ac.il/report/2022/045/">Relaxed Locally Decodable and Correctable Codes: Beyond Tensoring.</a><br />
Gil Cohen (Tel Aviv University), Tal Yankovitz (Tel Aviv University).</p>
<p><a href="https://arxiv.org/abs/2207.04342">Improved Lower Bounds for Submodular Function Minimization.</a><br />
Deeparnab Chakrabarty (Dartmouth College), Andrei Graur (Stanford University), Haotian Jiang (University of Washington), Aaron Sidford (Stanford University).</p>
<p><a href="https://eccc.weizmann.ac.il/report/2022/048/">On the Range Avoidance Problem for Circuits.</a><br />
Hanlin Ren (University of Oxford), Rahul Santhanam (University of Oxford), Zhikun Wang (Xi’an Jiaotong University).</p>
<p><a href="https://arxiv.org/abs/2205.03930">Near-Optimal Deterministic Vertex-Failure Connectivity Oracles.</a><br />
Yaowei Long (University of Michigan), Thatchaphol Saranurak (University of Michigan).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996620">Solving the Hamilton Cycle problem fast on average.</a><br />
Michael Anastos (Institute of Science and Technology Austria).</p>
<p><a href="https://arxiv.org/abs/2204.11894">Properly learning monotone functions via local correction.</a><br />
Jane Lange (MIT), Ronitt Rubinfeld (MIT), Arsen Vasilyan (MIT).</p>
<p><a href="https://arxiv.org/abs/2109.11725">Punctured Low-Bias Codes Behave Like Random Linear Codes.</a><br />
Venkatesan Guruswami (UC Berkeley), Jonathan Mosheiff (Ben-Gurion University).</p>
<p><a href="https://arxiv.org/abs/2209.07024">Almost Ramanujan Expanders from Arbitrary Expanders via Operator Amplification.</a><br />
Fernando Granha Jeronimo (Institute of Advanced Study), Tushant Mittal (University of Chicago), Sourya Roy (University of California, Riverside), Avi Wigderson (Institute for Advanced Study).</p>
<p><a href="https://arxiv.org/abs/2204.01520">Sampling Lovasz Local Lemma For General Constraint Satisfaction Solutions In Near-Linear Time.</a><br />
Kun He (Chinese Academy of Sciences), Chunyang Wang (Nanjing University), Yitong Yin (Nanjing University).</p>
<p><a href="https://arxiv.org/abs/2204.03782">Testing Positive Semidefiniteness Using Linear Measurements.</a><br />
Deanna Needell (University of California Los Angeles), William Swartworth (University of California Los Angeles), David P Woodruff (CMU).</p>
<p><a href="https://eccc.weizmann.ac.il/report/2022/108/">Hardness Self-Amplification from Feasible Hard-Core Sets.</a><br />
Shuichi Hirahara (National Institute of Informatics), Nobutaka Shimizu (Tokyo Institute of Technology).</p>
<p><a href="https://arxiv.org/abs/2209.07524"><span class="math inline"><em>O</em>(<em>n</em>+<em>p</em><em>o</em><em>l</em><em>y</em>(<em>k</em>))</span>-time Algorithm for Distance k Tree Edit Distance.</a><br />
Debarati Das (Penn State University), Jacob Gilbert (University of Maryland), MohammadTaghi Hajiaghayi (University of Maryland), Tomasz Kociumaka (UC Berkeley), Barna Saha (University of California San Diego), Hamed Saleh (University of Maryland).</p>
<p><a href="https://arxiv.org/abs/2204.03076">Approximation Algorithms and Hardness for n-Pairs Shortest Paths and All-Nodes Shortest Cycles.</a><br />
Mina Dalirooyfard (MIT), Ce Jin (MIT), Virginia Vassilevska Williams (MIT), Nicole Wein (DIMACS).</p>
<p><a href="https://arxiv.org/abs/2010.01513">Radical Sylvester-Gallai Theorem for Cubics.</a><br />
Rafael Oliveira (University of Waterloo), Akash Kumar Sengupta (Columbia University).</p>
<p><a href="https://arxiv.org/abs/2204.11469">Explicit Lower Bounds Against <span class="math inline"><em>Ω</em>(<em>n</em>)</span>-Rounds of Sum-of-Squares.</a><br />
Max Hopkins (UCSD), Ting-Chun Lin (UCSD, Hong Hai Research Institute).</p>
<p><a href="https://arxiv.org/abs/2110.10091">Factorial Lower Bounds for (Almost) Random Order Streams.</a><br />
Ashish Chiplunkar (IIT Delhi), John Kallaugher (Sandia National Labs), Michael Kapralov (EPFL), Eric Price (The University of Texas at Austin).</p>
<p><a href="https://arxiv.org/abs/2207.03427">Binary Iterative Hard Thresholding Converges with Optimal Number of Measurements for 1-Bit Compressed Sensing.</a><br />
Namiko Matsumoto (UC San Diego), Arya Mazumdar (UC San Diego).</p>
<p><a href="https://arxiv.org/abs/2203.07771">Optimal mixing for two-state anti-ferromagnetic spin systems.</a><br />
Xiaoyu Chen (Nanjing University), Weiming Feng (University of Edinburgh), Yitong Yin (Nanjing University), Xinyuan Zhang (Nanjing University).</p>
<p><a href="https://arxiv.org/abs/2207.04318">Determinant Maximization via Matroid Intersection Algorithms.</a><br />
Adam Brown (Georgia Insittute of Technology), Aditi Laddha (Georgia Insittute of Technology), Madhusudhan Pittu (Carnegie Mellon University), Mohit Singh (Georgia Insittute of Technology), Prasad Tetali (Carnegie Mellon University).</p>
<p><a href="https://arxiv.org/abs/2111.04958">Breaking the Cubic Barrier for All-Pairs Max-Flow: Gomory-Hu Tree in Nearly Quadratic Time.</a><br />
Amir Abboud (Weizmann Institute of Science), Robert Krauthgamer (Weizmann Institute of Science), Jason Li (UC Berkeley), Debmalya Panigrahi (Duke University), Thatchaphol Saranurak (University of Michigan), Ohad Trabelsi (University of Michigan).</p>
<p><a href="https://arxiv.org/abs/2203.04989">Generalised entropy accumulation.</a><br />
Tony Metger (ETH Zurich), Omar Fawzi (ENS Lyon), David Sutter (IBM Quantum, IBM Research Zurich), Renato Renner (ETH Zurich).</p>
<p><a href="https://arxiv.org/abs/2203.04163">Localization schemes: A framework for proving mixing bounds for Markov chains.</a><br />
Yuansi Chen (Duke University), Ronen Eldan (Microsoft Research).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996905">A tight (non-combinatorial) conditional lower bound for Klee’s Measure Problem in 3D.</a><br />
Marvin Kunnemann (TU Kaiserslautern).</p>
<p><a href="https://arxiv.org/abs/2111.03361">Fast Deterministic Fully Dynamic Distance Approximation.</a><br />
Jan van den Brand (Simons Institute and UC Berkeley), Sebastian Forster (University of Salzburg), Yasamin Nazari (University of Salzburg).</p>
<p><a href="https://arxiv.org/abs/2209.07729">On Weighted Graph Sparsification by Linear Sketching.</a><br />
Yu Chen (University of Pennsylvania), Sanjeev Khanna (University of Pennsylvania), Huan Li (University of Pennsylvania).</p>
<p><a href="https://arxiv.org/abs/2204.03087">Faster Pattern Matching under Edit Distance.</a><br />
Panagiotis Charalampopoulos (Reichman University, Herzliya, Israel and Birkbeck, University of London), Tomasz Kociumaka (UC Berkeley and Max Planck Institute for Informatics, SIC, Germany), Philip Wellnitz (Max Planck Institute for Informatics, SIC, Germany).</p>
<p><a href="https://eccc.weizmann.ac.il/report/2022/119/">NP-Hardness of Learning Programs and Partial MCSP.</a><br />
Shuichi Hirahara (National Institute of Informatics).</p>
<p><a href="https://arxiv.org/abs/2208.00795">An Approximate Generalization of the Okamura-Seymour Theorem.</a><br />
Nikhil Kumar (Hasso Plattner Institute Potsdam).</p>
<p><a href="https://arxiv.org/abs/2111.12706">Gap Edit Distance via Non-Adaptive Queries: Simple and Optimal.</a><br />
Elazar Goldenberg (The Academic College of Tel Aviv-Yafo), Tomasz Kociumaka (UC Berkeley), Robert Krauthgamer (Weizmann Institute of Science), Barna Saha (University of California San Diego).</p>
<p><a href="https://arxiv.org/abs/2208.01078">On Matrix Multiplication and Polynomial Identity Testing.</a><br />
Robert Andrews (University of Illinois Urbana-Champaign).</p>
<p><a href="https://arxiv.org/abs/2204.02095">Streaming Facility Location in High Dimension via Geometric Hashing.</a><br />
Artur Czumaj (University of Warwick), Shaofeng Jiang (Peking University), Robert Krauthgamer (Weizmann Institute of Science), Pavel Vesel? (Charles University), Mingwei Yang (Peking University).</p>
<p><a href="https://arxiv.org/abs/2204.10830">Memory Bounds for Continual Learning.</a><br />
Binghui Peng (Columbia), Christos Papadimitriou (Columbia University), Xi Chen (Columbia University).</p>
<p><a href="https://arxiv.org/abs/2204.08254">Deterministic Low-Diameter Decompositions for Weighted Graphs and Distributed and Parallel Applications.</a><br />
Michael Elkin (Ben-Gurion University of the Negev), Bernhard Haeupler (ETHZ &amp; Carnegie Mellon University), Vaclav Rozho? (ETH Zurich), Christoph Grunau (ETH Zurich).</p>
<p><a href="https://arxiv.org/abs/2211.06920">Having Hope in Hops: New Spanners, Preservers and Lower Bounds for Hopsets.</a><br />
Shimon Kogan (Weizmann Institute), Merav Parter (Weizmann Institute).</p>
<p><a href="https://arxiv.org/abs/2208.11152">Strong XOR Lemma for Communication with Bounded Rounds.</a><br />
Huacheng Yu (Princeton University).</p>
<p><a href="https://arxiv.org/abs/2202.13641">Quantum Tanner codes.</a><br />
Anthony Leverrier (Inria), Gilles Zemor (University of Bordeaux).</p>
<p><a href="https://arxiv.org/abs/2108.04842">Optimal learning of quantum Hamiltonians from high-temperature Gibbs states.</a><br />
Jeongwan Haah (Microsoft Research), Robin Kothari (Microsoft), Ewin Tang (University of Washington).</p>
<p><a href="https://arxiv.org/abs/2204.09951">Motif Cut Sparsifiers.</a><br />
Michael Kapralov (EPFL), Mikhail Makarov (EPFL), Sandeep Silwal (MIT), Christian Sohler (University of Cologne), Jakab Tardos (EPFL).</p>
<p><a href="https://arxiv.org/abs/2203.00671">Maximum Flow and Minimum-Cost Flow in Almost-Linear Time.</a><br />
Li Chen (Georgia Tech), Rasmus Kyng (ETH Zurich), Yang P. Liu (Stanford University), Richard Peng (University of Waterloo), Maximilian Probst Gutenberg (ETH Zurich), Sushant Sachdeva (University of Toronto).</p>
<p><a href="https://arxiv.org/abs/2207.11903">Minimax Rates for Robust Community Detection.</a><br />
Allen Liu (MIT), Ankur Moitra (Math &amp; CSAIL, MIT).</p>
<p><a href="https://eprint.iacr.org/2021/1543.pdf">Post-Quantum Zero Knowledge, Revisited (or: How to Do Quantum Rewinding Undetectably).</a><br />
Alex Lombardi (MIT), Fermi Ma (Simons Institute and UC Berkeley), Nicholas Spooner (University of Warwick).</p>
<p><a href="https://arxiv.org/abs/2206.08810">Interior point methods are not worse than Simplex.</a><br />
Xavier Allamigeon (INRIA &amp; Ecole Polytechnique), Daniel Dadush (CWI Amsterdam), Georg Loho (University of Twente), Bento Natura (London School of Economics and Political Science), Laszlo A. Vegh (London School of Economics and Political Science).</p>
<p><a href="https://arxiv.org/abs/2105.10043">A (Slightly) Improved Bound on the Integrality Gap of the Subtour LP for TSP.</a><br />
Anna Karlin (University of Washington), Nathan Klein (University of Washington), Shayan Oveis Gharan (University of Washington).</p>
<p><a href="https://arxiv.org/abs/2204.07155">Tight Bounds for Quantum State Certification with Incoherent Measurements.</a><br />
Sitan Chen (UC Berkeley), Brice Huang (MIT), Jerry Li (Microsoft Research), Allen Liu (MIT).</p>
<p><a href="https://arxiv.org/abs/2205.00342">Fast Multivariate Multipoint Evaluation Over All Finite Fields.</a><br />
Vishwas Bhargava (Rutgers University), Sumanta Ghosh (Caltech), Zeyu Guo (UT Austin), Mrinal Kumar (IIT Bombay), Chris Umans (Caltech).</p>
<p><a href="https://eprint.iacr.org/2022/1236">Rate-1 Non-Interactive Arguments for Batch-NP and Applications.</a><br />
Lalita Devadas (MIT CSAIL), Rishab Goyal (MIT CSAIL), Yael Tauman Kalai (MIT and Microsoft Research), Vinod Vaikuntanathan (MIT CSAIL).</p>
<p><a href="https://arxiv.org/abs/2205.02168">Separations in Proof Complexity and TFNP.</a><br />
Mika Goos (EPFL), Alexandros Hollender (University of Oxford), Siddhartha Jain (EPFL), Gilbert Maystre (EPFL), William Pires (McGill), Robert Robere (McGill), Ran Tao (McGill).</p>
<p><a href="https://arxiv.org/abs/2208.12896">Randomised Composition and Small-Bias Minimax.</a><br />
Shalev Ben-David (University of Waterloo), Eric Blais (University of Waterloo), Mika Goos (EPFL), Gilbert Maystre (EPFL).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996646">Incrementally Verifiable Computation via Rate-1 Batch Arguments.</a><br />
Omer Paneth (Tel Aviv University), Rafael Pass (Cornell Tech and Tel Aviv University).</p>
<p><a href="https://eccc.weizmann.ac.il/report/2022/097/">Unstructured Hardness to Average-Case Randomness.</a><br />
Lijie Chen (MIT), Ron Rothblum (Technion), Roei Tell (IAS + DIMACS).</p>
<p><a href="https://arxiv.org/abs/2207.11832">New Additive Spanner Lower Bounds by an Unlayered Obstacle Product.</a><br />
Greg Bodwin (University of Michigan), Gary Hoppenworth (University of Michigan).</p>
<p><a href="https://arxiv.org/abs/2209.01901">The Power of Uniform Sampling for Coresets.</a><br />
Vladimir Braverman (Johns Hopkins University), Vincent Cohen-Addad (Google Research, Switzerland), Shaofeng Jiang (Peking University), Robert Krauthgamer (Weizmann Institute of Science), Chris Schwiegelshohn (Aarhus University), Mads Bech Toftrup (Aarhus University), Xuan Wu (Johns Hopkins University).</p>
<p><a href="https://www.cs.purdue.edu/homes/hmaji/papers/BKMN22.pdf">Geometry of Secure Two-party Computation.</a><br />
Saugata Basu (Purdue University), Hamidreza Amini Khorasgani (Purdue University), Hemanta K. Maji (Purdue University), Hai H. Nguyen (Purdue University).</p>
<p><a href="https://arxiv.org/abs/2204.02128">Computing in Anonymous Dynamic Networks Is Linear.</a><br />
Giuseppe Antonio Di Luna (Sapienza University of Rome), Giovanni Viglietta (Japan Advanced Institute of Science and Technology (JAIST)).</p>
<p><a href="https://arxiv.org/abs/2202.13997">Classical Verification of Quantum Computations in Linear Time.</a><br />
Jiayu Zhang (California Institute of Technology).</p>
<p><a href="https://arxiv.org/abs/2209.15149">Pure-Circuit: Strong Inapproximability for PPAD.</a><br />
Argyrios Deligkas (Royal Holloway, University of London), John Fearnley (University of Liverpool), Alexandros Hollender (University of Oxford), Themistoklis Melissourgos (University of Essex).</p>
<p><a href="https://arxiv.org/abs/2204.10306">Performance and limitations of the QAOA at constant levels on large sparse hypergraphs and spin glass models.</a><br />
Joao Basso (Google), David Gamarnik (MIT), Song Mei (University of California, Berkeley), Leo Zhou (California Institute of Technology).</p>
<p><a href="https://arxiv.org/abs/2209.09049">Rounds vs Communication Tradeoffs for Maximal Independent Sets.</a><br />
Sepehr Assadi (Rutgers University), Gillat Kol (Princeton University), Zhijun Zhang (Princeton University).</p>
<p><a href="https://arxiv.org/abs/2205.03710">Almost 3-Approximate Correlation Clustering in Constant Rounds.</a><br />
Soheil Behnezhad (Stanford University), Moses Charikar (Stanford University), Weiyun Ma (Stanford University), Li-Yang Tan (Stanford University).</p>
<p><a href="https://arxiv.org/abs/2111.03142">Inapproximability of Positive Semidefinite Permanents and Quantum State Tomography.</a><br />
Alexander Meiburg (UCSB).</p>
<p><a href="https://arxiv.org/abs/2203.17207">A Proof of the Kahn-Kalai Conjecture.</a><br />
Huy Tuan Pham (Stanford University), Jinyoung Park (Stanford University).</p>
<p><a href="https://arxiv.org/abs/2210.13739">Deterministic Small Vertex Connectivity in Almost Linear Time.</a><br />
Thatchaphol Saranurak (University of Michigan), Sorrachai Yingchareonthawornchai (Aalto University).</p>
<p><a href="https://arxiv.org/abs/2204.02570">Optimal Sublinear Sampling of Spanning Trees and Determinantal Point Processes via Average-Case Entropic Independence.</a><br />
Nima Anari (Stanford University), Yang P. Liu (Stanford University), Thuy-Duong Vuong (Stanford University).</p>
<p><a href="https://eprint.iacr.org/2022/1430">Indistinguishability Obfuscation via Mathematical Proofs of Equivalence.</a><br />
Abhishek Jain (Johns Hopkins University), Zhengzhong Jin (Johns Hopkins University).</p>
<p><strong>Open Problems</strong></p>
<p>Is this of any value? Should we do it for FOCS 2023?</p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-07T13:44:21Z">Tuesday, February 07 2023, 13:44</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
