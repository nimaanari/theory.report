<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-06-18T09:30:29Z">Sunday, June 18 2023, 09:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://export.arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://export.arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://export.arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, June 18
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://ptreview.sublinear.info/2023/06/news-for-may-2023/'>News for May 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Apologies, dear readers for the delay in getting out this month&#8217;s post. This month we had three papers &#8212; all on testing properties of graphs! One of the featured papers this month revisits the problem of testing the properties of directed graphs and comes back with a happy progress report. Alright, let&#8217;s dig in. A [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Apologies, dear readers for the delay in getting out this month&#8217;s post. This month we had three papers &#8212; all on testing properties of graphs! One of the featured papers this month revisits the problem of testing the properties of directed graphs and comes back with a happy progress report. Alright, let&#8217;s dig in.</p>



<p></p>



<p><strong>A Distributed Conductance Tester Without Global Information Collection</strong> by Tugkan Batu, Chhaya Trehan (<a href="https://arxiv.org/abs/2305.14178">arXiv</a>) One of the classic questions in property testing considers the task of testing expansion. Here, you are interested in knowing whether the input graph has conductance at least \(\alpha\) or it is far from having conductance at most \(\alpha^2\). On a parallel track, we recall that thanks to the classic work of Parnas and Ron, we know there are connections between distributed algorithms and graph property testing. Meditating on these connections led to the emergence of distributed graph property testing as an active area of research. The featured paper considers the task of testing expansion in the distributed framework. The algorithms presented give a distributed implementation of multiple random walks from all vertices, and controls the congestion of the implementation. In particular, this leads to a \(O(\log n/\alpha^2)\) round expansion-tester. In a first attempt at such an implementation, you might note that you need to track how well short random walks mix when started from a bunch of randomly chosen vertices. This seems to require maintaining some global state/global aggregate information. One of the important features of their algorithm (as mentioned in the title) does away with the need to maintain such global states. As a closing remark, I note the algorithm presented in this paper does not require the graph to be bounded degree.</p>



<p></p>



<p><strong>Testing versus estimation of graph properties, revisited</strong> by Lior Gishboliner, Nick Kushnir, Asaf Shapira (<a href="https://arxiv.org/abs/2305.05487">arXiv</a>) This paper considers the task of additively estimating the distance to a property \(\mathcal{P}\) of a dense graph. Let me set up some context to view the results in the featured paper by summarizing what was known before. One of the early important results in this area is the original result of Fischer and Newman which shows that any testable graph property admits a \(\pm \varepsilon\) distance approximation algorithm, which follows from the regularity lemma. However, the query complexity of the resulting algorithm is a Tower-style bound. Later, Hoppen et al., building upon tools from the classic work of Conlon and Fox, demonstrated that this bound of \(twr(poly(1/\varepsilon))\) also holds for testable hereditary properties. Fiat and Ron introduced a decomposition machinery that allowed them to decompose a &#8220;complex&#8221; property into a collection of simpler properties. They used this decomposition to estimate distances to a vast collection of graph properties. They also asked if it was possible to find a transformation using which one can bypass the blowup in query complexity incurred by Fischer and Newman for some rich class of graph properties. The featured paper proves that for a hereditary graph property, you can in fact get algorithms where the query complexity for distance estimation only grows as \(\exp(1/\varepsilon)\). Additionally, for every testable graph property, you can get distance estimators for that property whose query complexity only grows doubly exponentially in \(1/\varepsilon\) (as opposed to the tower bound earlier).  </p>



<p></p>



<p><strong>An Optimal Separation between Two Property Testing Models for Bounded Degree Directed Graphs</strong> by Pan Peng, Yuyang Wang (<a href="https://arxiv.org/abs/2305.13089">arXiv</a>) Unlike undirected graphs, directed graph properties have not received as much attention in the property testing community. In a classic work, Bender and Ron considered two natural models for studying property testing on directed graphs. The first model is one where you can only follow the &#8220;out&#8221; edges or the so-called <em>unidirectional model</em>. In the other model, you are allowed to follow both the &#8220;out&#8221; edges and the &#8220;in&#8221; edges incident on the vertex which is also called the <em>bidirectional model</em>. The featured paper considers directed graphs where the in-degree and the out-degrees are both bounded in both of the models mentioned above. The graph is presented to you in the adjacency list format (tailored for the model you consider). The paper shows that even for the fundamental task of subgraph-freeness, the directed world has some interesting behavior with respect to the two models above. Let me showcase one of the catchy results from the paper which illustrates this separation nicely. Take a connected directed graph \(H\) with \(k\) source components. The paper shows that for sufficiently small \(\varepsilon\), testing whether a directed graph \(G\) is \(H\)-free or \(\varepsilon\)-far from being \(H\)-free requires \(\Omega(n^{1-1/k})\) unidirectional queries. On the other hand, in the bidirectional model, this can be done with a mere \(O_{\varepsilon, d, k}(1)\) number of queries.</p>
<p class="authors">By Akash</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-18T07:14:46Z">Sunday, June 18 2023, 07:14</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/090'>TR23-090 |  HDX Condensers | 

	Itay Cohen, 

	Roy Roth, 

	Amnon Ta-Shma</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          More than twenty years ago, Capalbo, Reingold, Vadhan and Wigderson gave the first (and up to date only) explicit construction of a bipartite expander with almost full combinatorial expansion. The construction incorporates zig-zag ideas together with extractor technology, and is rather complicated. We give an alternative construction that builds upon recent constructions of hyper-regular, high-dimensional expanders. The new construction is, in our opinion, simple and elegant.
Beyond demonstrating a new, surprising, and intriguing, application of high-dimensional expanders, the construction employs totally new ideas which we hope may lead to progress on the still remaining open problems in the area.
        
        </div>

        <div class='tr-article-summary'>
        
          
          More than twenty years ago, Capalbo, Reingold, Vadhan and Wigderson gave the first (and up to date only) explicit construction of a bipartite expander with almost full combinatorial expansion. The construction incorporates zig-zag ideas together with extractor technology, and is rather complicated. We give an alternative construction that builds upon recent constructions of hyper-regular, high-dimensional expanders. The new construction is, in our opinion, simple and elegant.
Beyond demonstrating a new, surprising, and intriguing, application of high-dimensional expanders, the construction employs totally new ideas which we hope may lead to progress on the still remaining open problems in the area.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-18T05:48:51Z">Sunday, June 18 2023, 05:48</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, June 17
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/06/17/guest-post-stocial-activities-graduating-bits-and-junior-senior-lunch-at-stoc-2023/'>Guest post: STOCial activities, Graduating Bits, and Junior/Senior Lunch at STOC 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          If you are attending STOC&#8217;23 as part of the TheoryFest next week, don&#8217;t forget to have a look at the STOCial Program! In particular, and to get to the point of this announcement: if you are graduating or will be on the job market soon, consider participating to the Graduating Bits Session on Wednesday: 1-2 [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>If you are attending <a href="http://acm-stoc.org/stoc2023/">STOC&#8217;23</a> as part of the TheoryFest next week, don&#8217;t forget to have a look at the <a href="https://sites.google.com/view/stocial2023/home">STOCial Program</a>! </p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://tcsplus.files.wordpress.com/2023/06/it-is-fun-its-enjoyable.gif"><img data-attachment-id="699" data-permalink="https://tcsplus.wordpress.com/2023/06/17/guest-post-stocial-activities-graduating-bits-and-junior-senior-lunch-at-stoc-2023/it-is-fun-its-enjoyable/" data-orig-file="https://tcsplus.files.wordpress.com/2023/06/it-is-fun-its-enjoyable.gif" data-orig-size="498,289" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="it-is-fun-its-enjoyable" data-image-description="" data-image-caption="" data-medium-file="https://tcsplus.files.wordpress.com/2023/06/it-is-fun-its-enjoyable.gif?w=300" data-large-file="https://tcsplus.files.wordpress.com/2023/06/it-is-fun-its-enjoyable.gif?w=498" src="https://tcsplus.files.wordpress.com/2023/06/it-is-fun-its-enjoyable.gif?w=498" alt="GIF of a man with a beret saying &quot;It is fun!&quot;" class="wp-image-699" /></a></figure></div>


<p></p>



<p>In particular, and to get to the point of this announcement: if you are graduating or will be on the job market soon, consider participating to the <em>Graduating Bits Session</em> on Wednesday: 1-2 slides, 2 minutes, entirely yours to present and pitch your research to the STOC attendees! To register, <a href="https://docs.google.com/forms/d/e/1FAIpQLScgDDosoozV6rJ7kemMolHQJGgt3vO7ihjfpKhaeVMc_7IDVw/viewform">fill this form</a> before Tuesday evening <em>(up to 25 slots, first-come-first-served)</em>.</p>



<p>Following the by-now-well-established tradition, there will also be a &#8220;senior/junior lunch&#8221; on Thursday, during the 12:30-2pm time slot: <a href="https://docs.google.com/spreadsheets/d/1nmPaZdjC0y0FbJgwXDAzaHSp6FjOtSoRM_SCjqbA9rE/edit">put your name here</a> as a &#8220;senior&#8221; (broadly construed) or a &#8220;junior&#8221; academic, for informal discussions, academic advice, and general questions over lunch. </p>



<p>See you next week at the TheoryFest!</p>



<p><em>Clément, on behalf of the STOCial Committee (Barna Saha, Clément Canonne, Elena Grigorescu, and Raghu Meka)</em></p>



<p></p>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-17T12:34:16Z">Saturday, June 17 2023, 12:34</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, June 15
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/06/15/linkage.html'>Linkage</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Marmor Soorten, or The Book of Marble (\(\mathbb{M}\)), an Enlightenment-era full-color catalog of types of marble, to be reprinted by Taschen.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <ul>
  <li>
    <p><a href="https://www.thisiscolossal.com/2023/04/book-of-marble/"><em>Marmor Soorten</em>, or <em>The Book of Marble</em></a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@colossal@mastodon.art/110349972015054620">\(\mathbb{M}\)</a>),</span> an Enlightenment-era full-color catalog of types of marble, to be reprinted by Taschen.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/how-math-has-changed-the-shape-of-gerrymandering-20230601/">How Math Has Changed the Shape of Gerrymandering</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@JeanneClelland/110475855814528525">\(\mathbb{M}\)</a>),</span> <em>Quanta</em> on the ReCom method for generating random ensembles of redistricting plans with the probability of a plan proportional to its number of spanning forests, via Markov Chain Monte Carlo, and using them as a basis of comparison to test the fairness of real redistricting plans. Moon Duchin recently spoke on the same thing at SoCG.</p>
  </li>
  <li>
    <p><a href="https://www.erdosproblems.com/">Erdős problems</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@sioum/110469648800130541">\(\mathbb{M}\)</a>),</span> collected and tracked by Thomas Bloom.</p>
  </li>
  <li>
    <p><a href="https://meta.stackexchange.com/questions/389811/moderation-strike-stack-overflow-inc-cannot-consistently-ignore-mistreat-an">Moderation Strike on Stack Overflow</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@highergeometer/110489672001944513">\(\mathbb{M}\)</a>)</span> triggered by a combination of corporate insistance on allowing AI content and lying to users about what they are requiring of their moderators. This affects both <a href="https://mathoverflow.net/">MathOverflow</a> and the <a href="https://cstheory.stackexchange.com/">TCS Stack Exchange</a>, although MathOverflow at least is merely operated by StackExchange, not actually owned by it.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2002.09534">Hyperbolic Minesweeper is in \(\mathsf{P}\)</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110499653895105776">\(\mathbb{M}\)</a>),</span> paper from FUN 2021 by Eryk Kopczyński. As the paper shows, finite subsets of hyperbolic tilings form graphs with only logarithmic treewidth. As a consequence, problems that can be solved by dynamic programming on these graphs, such as testing the safety of moves in hyperbolic minesweeper, take polynomial time.</p>
  </li>
  <li>
    <p><a href="https://www.cambridge.org/files/9216/8487/6990/matching_book_pw.pdf"><em>Online and Matching-Based Market Design</em></a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@fortnow@fediscience.org/110498942774330068">\(\mathbb{M}\)</a>),</span> new book edited by Federico Echenique, Nicole Immorlica, and Vijay Vazirani. The editors gave up any royalties to make it free online, but in a gratuitously annoying format where the online copy is password-locked with a publicly-announced password. The password is OMBMD_CUP. I put it into the filename of my downloaded copy so I wouldn’t lose one without the other.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2306.04007">Sam Mattheus and Jacques Verstraete determine the asymptotics of the Ramsey numbers \(r(4,n)\) to within a polylog</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@anuragbishnoi/110508895802423231">\(\mathbb{M}\)</a>).</span> See also <a href="https://anuragbishnoi.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/">Anurag Bishnoi’s blog post on the proof</a>.</p>
  </li>
  <li>
    <p><a href="https://www.techcityng.com/wikipedia-says-it-will-not-comply-with-uk-bill-on-age-checks/">“Wikipedia has announced that it will not comply with the age verification requirements of the UK’s Online Safety Bill”</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110518781331781604">\(\mathbb{M}\)</a>,</span> <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2023-06-05/In_the_media">via</a>). For more about the bill, see <a href="https://en.wikipedia.org/wiki/Online_Safety_Bill">Wikipedia’s article on it</a> — the issues are whether Wikipedia’s articles on sexual topics could be classified as pornography, which would trigger mandatory age verification according to the bill, and incompatibility of both age restriction and reader identification with the goals and purposes of Wikipedia.</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/news/faculty-issues/diversity-equity/2023/06/09/mathfest-florida-some-lgbtq-mathematicians-arent"><em>Inside Higher Education</em> on MAA’s insistence on holding MathFest in Florida this August</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110524346620592147">\(\mathbb{M}\)</a>,</span> <a href="https://web.archive.org/web/20230609042324/https://www.insidehighered.com/news/faculty-issues/diversity-equity/2023/06/09/mathfest-florida-some-lgbtq-mathematicians-arent">archive</a>), in-person only, over the objections of LGBTQ+ mathematicians targeted by recently passed state anti-gay laws that prohibit people from using gender-appropriate bathrooms, forbid the mention of homosexuality, sexism, or racism in schools, and have been used to shut down parades and concerts for including people being trans in public. See also <a href="http://digitaleditions.walsworthprintgroup.com/publication/?i=793202&amp;article_id=4588328">“Mathfest in Tampa: A Discussion”, <em>MAA Focus</em></a>. These sorts of events take years in advance to set up, and would incur a huge financial penalty to cancel at this late date, but the MAA already started having recriminations in 2021.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@tonwood/110524333213370377">Anton Sherwood asks for monohedral tilings of the sphere with no symmetries</a>. It’s possible, but whether it can be done with arbitrarily large numbers of tiles is unclear.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Cantor%27s_isomorphism_theorem">Newly promoted Wikipedia Good Article: Cantor’s isomorphism theorem</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110533545897925388">\(\mathbb{M}\)</a>).</span> This is the one saying that when an infinite linear ordering looks like the ordering on the rational numbers, it is the same ordering. “Looks like” means:</p>

    <ul>
      <li>
        <p>It has countably many elements</p>
      </li>
      <li>
        <p>It has no minimum and no maximum</p>
      </li>
      <li>
        <p>It has another element between any two of its elements</p>
      </li>
    </ul>

    <p>So the rationals, the dyadic rationals, the algebraic numbers, their intersections with the open unit interval, etc. all have the same ordering.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@logicalelegance@mastodon.online/110503412274553258">Origami snail shells and companion octopodes</a>.</p>
  </li>
  <li>
    <p><a href="https://www.wired.com/story/dont-want-students-to-rely-on-chatgpt-have-them-use-it/">According to <em>Wired</em>, giving students assignments using ChatGPT can help them become more confident in their own abilities to do better than it</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@TammyKolda/110497708715756714">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2301.10191">New simple streaming algorithm for estimating the number of distinct elements in a stream</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@fortnow@fediscience.org/110537617395576272">\(\mathbb{M}\)</a>),</span> “Distinct Elements in Streams: An Algorithm for the (Text) Book”, by Sourav Chakraborty, N. V. Vinodchandran, and Kuldeep S. Meel, updated from their ESA 2022 paper. <a href="https://en.wikipedia.org/wiki/HyperLogLog">HyperLogLog</a> can do the same thing but the new one is maybe more suitable for teaching, and doesn’t depend on hashing. See also writeups by <a href="https://cs.stanford.edu/~knuth/papers/cvm-note.pdf">Knuth</a> and <a href="https://justinjaffray.com/a-charming-algorithm-for-count-distinct/">Justin Jaffray</a>.</p>
  </li>
</ul><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-15T23:00:00Z">Thursday, June 15 2023, 23:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/06/randomized-acceptances.html'>Randomized Acceptances</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>NeurIPS recently released their 2021 consistency report, a sequel to the 2014 experiment. While the conference has grown dramatically, the results remain "consistent", about 23% disagreement from two separated program committee groups. As before I don't find this too surprising--different committee members have different tastes.</p><p>Roughly conference submissions fall into three categories</p><p></p><ol><li>Clearly strong papers</li><li>Clear rejects</li><li>A bunch that could go either way.</li></ol>A typical program committee quickly sorts out the first two groups and then painfully spends considerable time arguing over the others.<p></p><p>What if instead we took a different approach. Accept all the strong papers and reject the weak ones. Choose the rest randomly, either with a uniform or weighted distribution based on the ranking. Maybe reduce the probability of those who submit multiple papers.</p><p>Choosing randomly reduces biases and can increase diversity, if there is diversity in submissions. Knowing there is randomness in the process allows those with rejected papers to blame the randomness and those whose papers gets in claim they were in the first group. Randomness encourages more submissions and is fair over time.</p><p>Note we're just acknowledging the randomness in the process instead of pretending there is a perfect linear order to the papers that only a lengthy program committee discussion can suss out.</p><p>We should do the same for grant proposals--all worthy proposals should get a chance to be funded.</p><p>I doubt any of this will ever happen. People would rather trust human decisions with all their inconsistencies over pure randomness.&nbsp;</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>NeurIPS recently released their <a href="https://arxiv.org/abs/2306.03262">2021 consistency report</a>, a sequel to the <a href="https://inverseprobability.com/2014/12/16/the-nips-experiment">2014 experiment</a>. While the conference has grown dramatically, the results remain "consistent", about 23% disagreement from two separated program committee groups. As <a href="https://blog.computationalcomplexity.org/2014/12/the-nips-experiment.html">before</a> I don't find this too surprising--different committee members have different tastes.</p><p>Roughly conference submissions fall into three categories</p><p></p><ol style="text-align: left;"><li>Clearly strong papers</li><li>Clear rejects</li><li>A bunch that could go either way.</li></ol>A typical program committee quickly sorts out the first two groups and then painfully spends considerable time arguing over the others.<p></p><p>What if instead we took a different approach. Accept all the strong papers and reject the weak ones. Choose the rest randomly, either with a uniform or weighted distribution based on the ranking. Maybe reduce the probability of those who submit multiple papers.</p><p>Choosing randomly reduces biases and can increase diversity, if there is diversity in submissions. Knowing there is randomness in the process allows those with rejected papers to blame the randomness and those whose papers gets in claim they were in the first group. Randomness encourages more submissions and is fair over time.</p><p>Note we're just acknowledging the randomness in the process instead of pretending there is a perfect linear order to the papers that only a lengthy program committee discussion can suss out.</p><p>We should do the same for grant proposals--all worthy proposals should get a chance to be funded.</p><p>I doubt any of this will ever happen. People would rather trust human decisions with all their inconsistencies over pure randomness.&nbsp;</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-15T21:04:00Z">Thursday, June 15 2023, 21:04</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/089'>TR23-089 |  New Explicit Constant-Degree Lossless Expanders | 

	Louis Golowich</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We present a new explicit construction of onesided bipartite lossless expanders of constant degree, with arbitrary constant ratio between the sizes of the two vertex sets. Our construction is simpler to state and analyze than the prior construction of Capalbo, Reingold, Vadhan, and Wigderson (2002).

  We construct our lossless expanders by imposing the structure of a constant-sized lossless expander &quot;gadget&quot; within the neighborhoods of a large bipartite spectral expander; similar constructions were previously used to obtain the weaker notion of unique-neighbor expansion. Our analysis simply consists of elementary counting arguments and an application of the expander mixing lemma.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We present a new explicit construction of onesided bipartite lossless expanders of constant degree, with arbitrary constant ratio between the sizes of the two vertex sets. Our construction is simpler to state and analyze than the prior construction of Capalbo, Reingold, Vadhan, and Wigderson (2002).

  We construct our lossless expanders by imposing the structure of a constant-sized lossless expander &quot;gadget&quot; within the neighborhoods of a large bipartite spectral expander; similar constructions were previously used to obtain the weaker notion of unique-neighbor expansion. Our analysis simply consists of elementary counting arguments and an application of the expander mixing lemma.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-15T06:20:23Z">Thursday, June 15 2023, 06:20</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, June 14
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/'>A Little Noise Makes Quantum Factoring Fail</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Jin-Yi Cai is one of the top theory experts in the world. Both Ken and I have had the pleasure to work with him and interact with him over the years. We have discussed some of his previous work here and here. Today we will talk about his new work on quantum computing. Quantum Factoring [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
Jin-Yi Cai is one of the top theory experts in the world. Both Ken and I have had the pleasure to work with him and interact with him over the years. We have discussed some of his previous work <a href="https://rjlipton.wpcomstaging.com/2022/02/23/simons-awards-for-2022/">here</a> and <a href="https://rjlipton.wpcomstaging.com/2017/11/20/a-magic-madison-visit/">here</a>.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/jcai/" rel="attachment wp-att-21763"><img data-attachment-id="21763" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/jcai/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jcai.jpeg?fit=150%2C190&amp;ssl=1" data-orig-size="150,190" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="jcai" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jcai.jpeg?fit=150%2C190&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jcai.jpeg?fit=150%2C190&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jcai.jpeg?resize=150%2C190&#038;ssl=1" alt="" width="150" height="190" class="aligncenter size-full wp-image-21763" data-recalc-dims="1" /></a></p>
<p><P><br />
Today we will talk about his new work on quantum computing.</p>
<p>
<p><H2> Quantum Factoring </H2></p>
<p><p>
Peter Shor invented <a href="https://en.wikipedia.org/wiki/Shor&#37;27s_algorithm">the</a> quantum algorithm for finding the prime factors of an integer in 1994.</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/pshor/" rel="attachment wp-att-21764"><img data-attachment-id="21764" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/pshor/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?fit=241%2C241&amp;ssl=1" data-orig-size="241,241" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pshor" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?fit=241%2C241&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?fit=241%2C241&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?resize=150%2C150&#038;ssl=1" alt="" width="150" height="150" class="aligncenter wp-image-21764" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?w=241&amp;ssl=1 241w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1" /></a></p>
<p><P><br />
This is one of the great algorithms of all time. It shows at least in theory that quantum algorithms can be much more efficient than classical algorithms. The algorithm shows that the integer factorization problem can be efficiently solved on an idealized quantum computer and is consequently in the complexity class <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{BQP}}" class="latex" />. This is almost exponentially faster than the most efficient known classical factoring algorithm.</p>
<p>
<p><H2> Quantum Factoring Possible? </H2></p>
<p>Is it practically feasible to use Shor&#8217;s factoring method to break RSA? This leads to a major question: </p>
<blockquote><p>
<em>Can cryptography survive quantum methods?</em>
</p></blockquote>
<p>
A <a href="https://eprint.iacr.org/2017/351.pdf">paper</a> by Daniel Bernstein, Nadia Heninger, Paul Lou, and Luke Valenta titled &#8220;Post-Quantum RSA&#8221; is a key one. They consider further systems including elliptic curve cryptography (ECC) and say:</p>
<blockquote><p><b> </b> <em> The conventional wisdom among researchers in post-quantum cryptography is that quantum computers will kill RSA and ECC but will not kill hash-based cryptography, code-based cryptography, lattice-based cryptography, or multivariate- quadratic-equations cryptography.<br />
&#8230;<br />
Shor&#8217;s algorithm easily breaks RSA as used on the Internet today. The question is whether RSA parameters can be adjusted so that all known quantum attack algorithms are infeasible while encryption and decryption remain feasible. </em>
</p></blockquote>
<p><p>
See also <a href="https://math.mit.edu/~apost/courses/18.204-2016/18.204_Jeremy_Wohlwend_final_paper.pdf">this</a>. A 2019 <a href="https://arxiv.org/abs/1905.09749">paper</a> by Craig Gidney and Martin Eker&aring; argues that implementations of Shor on 2,048-bit integers <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N}" class="latex" /> is within reach of current technology using noisy qubits&#8212;needing only some millions of them. However, this presumes an error-free implementation of the Quantum Fourier Transform (QFT). They say:</p>
<blockquote><p><b> </b> <em> Note furthermore that when we analyze the success probabilities of Shor’s algorithms, and the various derivatives, we assume the use of an ideal QFT even though the implemented QFT is technically an approximation. </em>
</p></blockquote>
<p>
<p><H2> Quantum Factoring Impossible? </H2></p>
<p>Now enter Jin-Yi. He has a new <a href="https://pages.cs.wisc.edu/~jyc/Shor-Algorithm-with-Noise.pdf">paper</a> that says:</p>
<blockquote><p><b> </b> <em> We consider Shor&#8217;s quantum factoring algorithm in the setting of noisy quantum gates. Under a generic model of random noise for rotation gates, we prove that the algorithm does not factor integers of the form <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bpq%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{pq}" class="latex" /> when the noise exceeds a vanishingly small level in terms of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /> (the number of bits of the integer to be factored), where <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{q}" class="latex" /> are chosen from a set of primes of positive density. </em>
</p></blockquote>
<p><p>
Jin-Yi essentially is saying that quantum algorithms fail to break RSA in the presence of noisy gates. He argues that they will <b>not</b> be able to work when quantum gates are not perfect. </p>
<p>
<i>This seems to contradict the previous section.</i> Can it be that quantum algorithms break RSA in theory, but are not practically realizable? See these <a href="https://usa.kaspersky.com/blog/quantum-computers-and-rsa-2023/27605/">three</a> <a href="https://www.lawfareblog.com/retrospective-post-quantum-policy-problem">recent</a> <a href="https://www.forbes.com/sites/forbestechcouncil/2022/08/08/rsas-quantum-proof-successor-may-not-be-safe-for-long/?sh=55c0555475ff">discussions</a>.</p>
<p>
To our knowledge, this is the first hard-and-fast negative result about Shor&#8217;s algorithm. Let&#8217;s take a closer look.</p>
<p>
<p><H2> Angles on Shor&#8217;s Algorithm </H2></p>
<p><p>
Given <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+pq%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N = pq}" class="latex" /> to factor, Shor&#8217;s algorithm starts by choosing <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{a}" class="latex" /> relatively prime to <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N}" class="latex" />. The algorithm extends the domain of the function <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29+%3D+a%5Ex+%5Cpmod%7BN%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{f(x) = a^x &#92;pmod{N}}" class="latex" /> to all <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx+%3C+M%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x &lt; M}" class="latex" /> where <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BM+%3D+2%5Em%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{M = 2^m}" class="latex" />, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+2n%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{m = 2n}" class="latex" />, and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{2^n}" class="latex" /> is the next power of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{2}" class="latex" /> after <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N}" class="latex" />, so that <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BM+%5Capprox+N%5E2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{M &#92;approx N^2}" class="latex" />. The quantum engine of Shor&#8217;s algorithm has just two main components:</p>
<ol>
<li>
A routine that computes the quantum state </p>
<p align=center><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CPhi+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7BM%7D%7D%5Csum_x+%7Cx%5Crangle%7Cf%28x%29%5Crangle.+&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle  &#92;Phi = &#92;frac{1}{&#92;sqrt{M}}&#92;sum_x |x&#92;rangle|f(x)&#92;rangle. " class="latex" /></p>
<p>Put another way without the Dirac angle-bracket notation, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;Phi}" class="latex" /> is a state of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bm%2Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{m+n}" class="latex" /> qubits that has equal nonzero amplitude only on those components <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bxy%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{xy}" class="latex" /> where <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By+%3D+f%28x%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y = f(x)}" class="latex" />. </p>
<li>
The QFT (or its inverse) on <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{m}" class="latex" /> qubits.
</ol>
<p>
Quantum gates of the form <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BR_k+%3D+%5Cbegin%7Bbmatrix%7D+1+%26+0+%5C%5C+0+%26+%5Comega_k+%5Cend%7Bbmatrix%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{R_k = &#92;begin{bmatrix} 1 &amp; 0 &#92;&#92; 0 &amp; &#92;omega_k &#92;end{bmatrix}}" class="latex" /> where <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Comega_k+%3D+%5Cexp%28%5Cfrac%7B2%5Cpi+i%7D%7B2%5Ek%7D%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;omega_k = &#92;exp(&#92;frac{2&#92;pi i}{2^k})}" class="latex" />, when <em>controlled</em> from another qubit, are used in the &#8220;textbook&#8221; way to compute the QFT. The diagram with <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bm%3D4%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{m=4}" class="latex" /> suffices for the general pattern:</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/qft4a/" rel="attachment wp-att-21765"><img data-attachment-id="21765" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/qft4a/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/QFT4A.jpg?fit=666%2C178&amp;ssl=1" data-orig-size="666,178" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1686570454&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="QFT4A" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/QFT4A.jpg?fit=300%2C80&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/QFT4A.jpg?fit=600%2C160&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/QFT4A.jpg?resize=555%2C150&#038;ssl=1" alt="" width="555" height="150" class="aligncenter wp-image-21765" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2"><a href="http://math.utoledo.edu/~codenth/Spring_15/4350/HW/fourier.pdf">source</a></FONT>
</td>
</tr>
</table>
<p>
For all but a few small values of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" />, the rotation angle in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BR_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{R_k}" class="latex" /> is tinier than theoretical minimum units of space, let alone the smallest precision of angular or spatial resolution we have achieved in experiments such as LIGO. Call a circuit family using <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BR_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{R_k}" class="latex" /> for unbounded <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> &#8220;idealistic.&#8221; </p>
<p>
Donald Coppersmith <a href="https://arxiv.org/abs/quant-ph/0201067">showed</a> that Shor&#8217;s algorithm still works if <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BR_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{R_k}" class="latex" /> is replaced by the identity operator for <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk+%3E+b%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k &gt; b}" class="latex" />, where the threshold <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{b}" class="latex" /> equals <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bc%5Clog_2+n%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{c&#92;log_2 n}" class="latex" /> for a constant <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{c}" class="latex" /> slightly above <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{1}" class="latex" />. The resulting circuits are still &#8220;idealistic&#8221; but at least not exponentially so. Coppersmith&#8217;s analysis is referenced in Shor&#8217;s original <a href="https://arxiv.org/abs/quant-ph/9508027">paper</a> but not expounded further there.</p>
<p>
Jin-Yi shows that Shor&#8217;s and Coppersmith&#8217;s circuits cannot tolerate a natural kind of noise that operates close to Coppersmith&#8217;s level of scaling. It stands concretely against any asymptotic claims of power via Shor&#8217;s algorithm that involve idealistic circuits. At the end we will discuss its implications also for circuits that implement Shor&#8217;s algorithm without using <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BR_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{R_k}" class="latex" /> gates.</p>
<p>
<p><H2> The Noise </H2></p>
<p><p>
Call <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BC%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{C}" class="latex" /> a <em>Shor circuit</em> if it uses controlled <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BR_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{R_k}" class="latex" /> gates to compute the QFT (or its inverse) and can be sampled by a classical procedure <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+A%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{{&#92;cal A}}" class="latex" /> to infer the period <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;rho}" class="latex" /> of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29+%3D+a%5Ex+%5Cpmod%7BN%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{f(x) = a^x &#92;pmod{N}}" class="latex" /> in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7BO%281%29%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n^{O(1)}}" class="latex" /> expected time. </p>
<p>
Jin-Yi&#8217;s noise operation has parameters <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;epsilon}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bb%27%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{b&#039;}" class="latex" /> and maps a Shor circuit <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BC%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{C}" class="latex" /> to a distribution of circuits <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BC%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;tilde{C}}" class="latex" /> defined as follows: For each controlled <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BR_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{R_k}" class="latex" /> gate in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BC%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{C}" class="latex" /> with <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+b%27%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k &#92;geq b&#039;}" class="latex" /> (alternatively, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+b%27%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k = b&#039;}" class="latex" />), replace it by </p>
<p align=center><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctilde%7BR_k%7D+%3D+%5Cbegin%7Bbmatrix%7D+1+%26+0+%5C%5C+0+%26+%5Ctilde%7B%5Comega%7D+%5Cend%7Bbmatrix%7D%5Cquad%5Ctext%7Bwhere%7D%5Cquad+%5Ctilde%7B%5Comega%7D+%3D+%5Cexp%5Cleft%28%5Cfrac%7B2%5Cpi+i%281+%2B+r%5Cepsilon%29%7D%7B2%5Ek%7D%5Cright%29+&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle  &#92;tilde{R_k} = &#92;begin{bmatrix} 1 &amp; 0 &#92;&#92; 0 &amp; &#92;tilde{&#92;omega} &#92;end{bmatrix}&#92;quad&#92;text{where}&#92;quad &#92;tilde{&#92;omega} = &#92;exp&#92;left(&#92;frac{2&#92;pi i(1 + r&#92;epsilon)}{2^k}&#92;right) " class="latex" /></p>
<p>with the same control qubit and with an independent draw of Gaussian noise <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Br+%5Csim+%7B%5Ccal+N%7D%280%2C1%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{r &#92;sim {&#92;cal N}(0,1)}" class="latex" />. The echo of Coppersmith&#8217;s &#8220;<img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{b}" class="latex" />&#8221; is on purpose, because he establishes the following fact, which we first state loosely:</p>
<blockquote><p><b> </b> <em> Provided <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bb%27+%2B+%5Clog_2%281%2F%5Cepsilon%29+%5Csim+%5Cfrac%7B1%7D%7B3%7D%28%5Clog_2+n%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{b&#039; + &#92;log_2(1/&#92;epsilon) &#92;sim &#92;frac{1}{3}(&#92;log_2 n)}" class="latex" />, the circuits <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BC%7D%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;tilde{C}}" class="latex" /> lose the Shor property, meaning that <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+A%7D%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{{&#92;cal A}}" class="latex" /> sampling <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BC%7D%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;tilde{C}}" class="latex" /> cannot find <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;rho}" class="latex" />. </em>
</p></blockquote>
<p><p>
This says that the noise range brushes against the Coppersmith upper bound for the precision needed to implement Shor&#8217;s algorithm. Since <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> is exponentiated, one can say that noise on the order of the cube of the precision needed for Shor&#8217;s algorithm is enough to destroy it. </p>
<p>
The estimates in the paper allow replacing <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B3%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;frac{1}{3}}" class="latex" /> by <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%2B%5Cdelta%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;frac{1}{2+&#92;delta}}" class="latex" /> with greater attention to additive constants, so lower noise approaching the square root of the Coppersmith precision suffices to destroy the Shor property. This may be improvable to almost linear. Exactly what does the noise attack? That&#8217;s next.</p>
<p>
<p><H2> Long Periods </H2></p>
<p><p>
The noise most strongly affects cases <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+pq%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N = pq}" class="latex" /> where <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp-1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p-1}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bq-1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{q-1}" class="latex" /> have a large prime factor. The most extreme such case is <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bp+-+1%7D%7B2%7D+%3D+p%27%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;frac{p - 1}{2} = p&#039;}" class="latex" /> being prime. Then <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp%27%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p&#039;}" class="latex" /> is called a <a href="https://en.wikipedia.org/wiki/Safe_and_Sophie_Germain_primes">Sophie Germain prime</a>. Ironically, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+2p%27%2B1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p = 2p&#039;+1}" class="latex" /> is called a &#8220;safe prime&#8221; but those are the most unsafe under Jin-Yi&#8217;s noise.</p>
<p>
It remains unknown whether infinitely many Sophie Germain primes exist, despite the quest <a href="https://en.wikipedia.org/wiki/Proof_(play)">winning</a> a Tony Award and Pulitzer Prize. But a less-heralded property suffices. &Eacute;tienne Fouvry <a href="https://eudml.org/doc/143202">proved</a> in 1985 that the set of primes <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p}" class="latex" /> for which <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp+-+1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p - 1}" class="latex" /> has a factor <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp%27+%3E+p%5E%7B2%2F3%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p&#039; &gt; p^{2/3}}" class="latex" /> is not only infinite, but has positive density in the set of primes. It follows that cases <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+pq%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N = pq}" class="latex" /> where both <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{q}" class="latex" /> have this &#8220;Fouvry property&#8221; have positive density among products of two primes. There can be only one prime factor <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp%27+%3E+p%5E%7B2%2F3%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p&#039; &gt; p^{2/3}}" class="latex" />, likewise <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bq%27+%3E+q%5E%7B2%2F3%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{q&#039; &gt; q^{2/3}}" class="latex" />. </p>
<p>
The upshot for such <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{q}" class="latex" /> is that most <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{a}" class="latex" /> have exponentially long periods <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;rho}" class="latex" /> modulo <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N}" class="latex" />. The geometric sums that concentrate amplitudes on multiples of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;rho}" class="latex" /> in the ideal situation, when the circuit is sampled via quantum measurement, have norm-squared proportional to <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;rho}" class="latex" />. In the noisy situation, such length maximizes the perturbative effect of the noise so as to level out the amplitude. This destroys the ability to infer <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;rho}" class="latex" />.</p>
<p>
We cut a few corners in the statements of Jin-Yi&#8217;s theorems, but they are reasonably close and the paper has full details. They hold also under the <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+b%27%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k = b&#039;}" class="latex" /> variant and with-or-without removing controlled <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BR_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{R_k}" class="latex" /> gates for <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk+%3E+b%27%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k &gt; b&#039;}" class="latex" />.</p>
<blockquote><p><b>Theorem 1</b> <em><a name="Fouvry"></a> Asymptotically as <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n &#92;rightarrow &#92;infty}" class="latex" />, if <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+pq%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N = pq}" class="latex" /> is an <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />-bit product of two Fouvry primes, and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bb%27+%2B+%5Clog%281%2F%5Cepsilon%29+%3C+%5Cfrac%7B1%7D%7B3%7D%5Clog_2+n+-+%5CTheta%281%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{b&#039; + &#92;log(1/&#92;epsilon) &lt; &#92;frac{1}{3}&#92;log_2 n - &#92;Theta(1)}" class="latex" />, then the probability that <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+A%7D%28%5Ctilde%7BC%7D%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{{&#92;cal A}(&#92;tilde{C})}" class="latex" /> infers <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;rho}" class="latex" /> is exponentially small. </em>
</p></blockquote>
<p>
<blockquote><p><b>Theorem 2</b> <em><a name="random"></a> Asymptotically as <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n &#92;rightarrow &#92;infty}" class="latex" />, for all but a vanishing fraction of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />-bit primes and with <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bb%27+%2B+%5Clog%281%2F%5Cepsilon%29+%3C+%5Cfrac%7B1%7D%7B3%7D%5Clog_2+n+-+%5CTheta%281%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{b&#039; + &#92;log(1/&#92;epsilon) &lt; &#92;frac{1}{3}&#92;log_2 n - &#92;Theta(1)}" class="latex" />, the probability over <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{a}" class="latex" /> and noisy <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BC%7D%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;tilde{C}}" class="latex" /> that <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+A%7D%28%5Ctilde%7BC%7D%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{{&#92;cal A}(&#92;tilde{C})}" class="latex" /> infers <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;rho}" class="latex" /> is exponentially small. </em>
</p></blockquote>
<p><p>
Theorem <a href="#random">2</a>, whose proof is in the paper&#8217;s appendix, says that Shor&#8217;s algorithm fails to survive the noise in all but a vanishing fraction of instances. It applies also under certain restrictions of the primes, such as <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{q}" class="latex" /> both being congruent to 3 modulo 4. Theorem <a href="#Fouvry">1</a> gives a substantial explicit set of cases <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+pq%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N = pq}" class="latex" /> on which the algorithm fails.</p>
<p>
<p><H2> How General Is This? </H2></p>
<p><p>
The theorems are carefully stated in terms of the period-inferencing component of Shor&#8217;s algorithm. And they are asymptotic. They do not rule out:</p>
<ul>
<li>
possible quantum improvements on input sizes in the finite range of conceivable practical crypto; </p>
<li>
quantum circuits <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BD%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{D}" class="latex" /> that might factor by other means; nor </p>
<li>
that error correction might restore the Shor property.
</ul>
<p>
In particular, they do not define a general-purpose noise model that could apply to any quantum circuit <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BD%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{D}" class="latex" />. </p>
<p>
Now we discuss two means to implement Shor&#8217;s algorithm without using gates beyond <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BR_3%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{R_3}" class="latex" />:</p>
<ol>
<li>
The Hadamard gate <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BH%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{H}" class="latex" />, the controlled-not gate CNOT, and the gate <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+R_3%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{T = R_3}" class="latex" /> form a <em>complete set</em> that (by the Solovay-Kitaev <a href="https://en.wikipedia.org/wiki/Solovay-Kitaev_theorem">theorem</a>) can feasibly approximate the state produced by any feasible quantum circuit plus QFT. Then the minimum angle of any individual operation is <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F8%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi/8}" class="latex" />. </p>
<li>
The Hadamard and <a href="https://en.wikipedia.org/wiki/Toffoli_gate">Toffoli</a> gates form a universal set in the weaker sense of encoding real and imaginary parts of quantum amplitudes separately. This suffices to compute the factoring function via polynomial-size circuits using only real entries.
</ol>
<p>
Idea 1 may only mask the issue, insofar as the resulting circuits must still approximate angles down to Coppersmith&#8217;s unboundedly small magnitude <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B-b%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{2^{-b}}" class="latex" />. Both <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BH%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{H}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BT%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{T}" class="latex" /> are rotations of the <a href="https://en.wikipedia.org/wiki/Bloch_sphere">Bloch sphere</a> of periods 2 and 8, respectively. As such, each may be exactly physically realizable, along with their controlled versions and CNOT in higher-dimensional Bloch spheres. </p>
<p>
However, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BH%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{H}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BT%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{T}" class="latex" /> together generate an infinite subgroup of SU(2). The group has members that rotate through arbitrarily small angles. Jin-Yi says in his speculative concluding section:</p>
<blockquote><p><b> </b> <em> It is true that using a fixed finite set of rotations of reasonable angles such as <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F8%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi/8}" class="latex" /> along various axes <b>can</b> compose to rotations of arbitrarily small angles. But my view is just that these compositional rules as specified by the group SU(2) must not be exact for physical reality. </em>
</p></blockquote>
<p><p>
Most in particular, let <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BA+%3D+HT%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{A = HT}" class="latex" />. If <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{A}" class="latex" /> can be exactly realized, then any power <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BAA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{AA}" class="latex" />, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BAAA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{AAA}" class="latex" />, &#8230; should be. But the angle of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{A}" class="latex" /> is not a rational multiple of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" />, so the powers alone form an infinite state space and include arbitrarily tiny rotations. Please see Jin-Yi&#8217;s <a href="https://pages.cs.wisc.edu/~jyc/Shor-Algorithm-with-Noise.pdf">paper</a> for other context and justifications on these points, plus related <a href="https://spectrum.ieee.org/the-case-against-quantum-computing">contentions</a> <a href="https://arxiv.org/ftp/arxiv/papers/1401/1401.3629.pdf">by</a> Mikhail Dyakonov.</p>
<p>
The circuits in idea 2 cannot approximate any (feasible) quantum state metrically, but they can emulate Shor&#8217;s algorithm using only <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B0%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{0}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;pi}" class="latex" /> as &#8220;angles.&#8221; They may, however, still involve quantum states with filigrees beyond physically realizable precision. In the coda to our own textbook, we speculate this already for the deterministic &#8220;functional superposition&#8221; component of Shor&#8217;s algorithm.</p>
<p>
All this and more was discussed already twenty-plus years ago in the &#8220;<a href="http://www.scottaaronson.com/papers/mlinsiam.pdf">Sure/Shor</a> <a href="https://www.scottaaronson.com/democritus/lec14.html">separator</a>&#8221; <a href="https://scottaaronson.blog/?p=124">debate</a>. The difference now is having Jin-Yi&#8217;s new work as a linchpin for the skeptical side. Non-robustness to noise in the &#8220;Coppersmith range&#8221; may be a wider phenomenon than his current results show.</p>
<p>
In his last paragraph, Jin-Yi argues that quantum computing makes a fundamental departure from Alan Turing&#8217;s condition that primitive steps are finite and fixed independent of the data size <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />. He mentions the free use of SU(2) but his point may apply as well to the step of placing a Toffoli gate anywhere in an <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />-qubit quantum circuit. This point is separate from issues of noise models, about which we have heard much from Gil Kalai including <a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/">recently</a>.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
The issue is simple: Can quantum algorithms be made to work in the presence of gates that are making errors at Jin-Yi&#8217;s scaling? The obvious interesting open question is: As in classical computation, can we build circuits that can handle errors? See <a href="https://e3s-center.berkeley.edu/wp-content/uploads/2017/07/PEB2012_12_TSzkopek_Webfinal.pdf">this</a> and <a href="https://cosmosmagazine.com/technology/error-free-quantum-computer/">this</a> on error-free computation. </p>
<p>
This seems to be a wonderful question. Will the new results reshape debates on quantum computing and the polynomial Church-Turing thesis, or are they subsumed in <a href="https://windowsontheory.org/2017/10/30/the-different-forms-of-quantum-computing-skepticism/">matters</a> <a href="https://cacm.acm.org/magazines/2019/5/236426-quantum-hype-and-quantum-skepticism/fulltext?mobile=false">already</a> <a href="https://unfashionable.blog/p/quantum">recently</a> <a href="https://www.technologyreview.com/2022/03/28/1048355/quantum-computing-has-a-hype-problem/">much</a> <a href="https://www.hpcwire.com/2023/05/02/microsoft-eth-take-aim-at-quantum-computings-hype-and-promise/">discussed</a>?</p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-14T04:16:28Z">Wednesday, June 14 2023, 04:16</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.07583'>Invertible Bloom Lookup Tables with Less Memory and Less Randomness</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nils Fleischhacker, Kasper Green Larsen, Maciej Obremski, Mark Simkin</p><p>In this work we study Invertible Bloom Lookup Tables (IBLTs) with small
failure probabilities. IBLTs are highly versatile data structures that have
found applications in set reconciliation protocols, error-correcting codes, and
even the design of advanced cryptographic primitives. For storing $n$ elements
and ensuring correctness with probability at least $1 - \delta$, existing IBLT
constructions require $\Omega(n(\frac{\log(1/\delta)}{\log(n)}+1))$ space and
they crucially rely on fully random hash functions.
</p>
<p>We present new constructions of IBLTs that are simultaneously more space
efficient and require less randomness. For storing $n$ elements with a failure
probability of at most $\delta$, our data structure only requires
$\mathcal{O}(n + \log(1/\delta)\log\log(1/\delta))$ space and
$\mathcal{O}(\log(\log(n)/\delta))$-wise independent hash functions.
</p>
<p>As a key technical ingredient we show that hashing $n$ keys with any $k$-wise
independent hash function $h:U \to [Cn]$ for some sufficiently large constant
$C$ guarantees with probability $1 - 2^{-\Omega(k)}$ that at least $n/2$ keys
will have a unique hash value. Proving this is highly non-trivial as $k$
approaches $n$. We believe that the techniques used to prove this statement may
be of independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fleischhacker_N/0/1/0/all/0/1">Nils Fleischhacker</a>, <a href="http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1">Kasper Green Larsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Obremski_M/0/1/0/all/0/1">Maciej Obremski</a>, <a href="http://arxiv.org/find/cs/1/au:+Simkin_M/0/1/0/all/0/1">Mark Simkin</a></p><p>In this work we study Invertible Bloom Lookup Tables (IBLTs) with small
failure probabilities. IBLTs are highly versatile data structures that have
found applications in set reconciliation protocols, error-correcting codes, and
even the design of advanced cryptographic primitives. For storing $n$ elements
and ensuring correctness with probability at least $1 - \delta$, existing IBLT
constructions require $\Omega(n(\frac{\log(1/\delta)}{\log(n)}+1))$ space and
they crucially rely on fully random hash functions.
</p>
<p>We present new constructions of IBLTs that are simultaneously more space
efficient and require less randomness. For storing $n$ elements with a failure
probability of at most $\delta$, our data structure only requires
$\mathcal{O}(n + \log(1/\delta)\log\log(1/\delta))$ space and
$\mathcal{O}(\log(\log(n)/\delta))$-wise independent hash functions.
</p>
<p>As a key technical ingredient we show that hashing $n$ keys with any $k$-wise
independent hash function $h:U \to [Cn]$ for some sufficiently large constant
$C$ guarantees with probability $1 - 2^{-\Omega(k)}$ that at least $n/2$ keys
will have a unique hash value. Proving this is highly non-trivial as $k$
approaches $n$. We believe that the techniques used to prove this statement may
be of independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-14T00:30:00Z">Wednesday, June 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.07674'>Differentially Private One Permutation Hashing and Bin-wise Consistent Weighted Sampling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiaoyun Li, Ping Li</p><p>Minwise hashing (MinHash) is a standard algorithm widely used in the
industry, for large-scale search and learning applications with the binary
(0/1) Jaccard similarity. One common use of MinHash is for processing massive
n-gram text representations so that practitioners do not have to materialize
the original data (which would be prohibitive). Another popular use of MinHash
is for building hash tables to enable sub-linear time approximate near neighbor
(ANN) search. MinHash has also been used as a tool for building large-scale
machine learning systems. The standard implementation of MinHash requires
applying $K$ random permutations. In comparison, the method of one permutation
hashing (OPH), is an efficient alternative of MinHash which splits the data
vectors into $K$ bins and generates hash values within each bin. OPH is
substantially more efficient and also more convenient to use.
</p>
<p>In this paper, we combine the differential privacy (DP) with OPH (as well as
MinHash), to propose the DP-OPH framework with three variants: DP-OPH-fix,
DP-OPH-re and DP-OPH-rand, depending on which densification strategy is adopted
to deal with empty bins in OPH. A detailed roadmap to the algorithm design is
presented along with the privacy analysis. An analytical comparison of our
proposed DP-OPH methods with the DP minwise hashing (DP-MH) is provided to
justify the advantage of DP-OPH. Experiments on similarity search confirm the
merits of DP-OPH, and guide the choice of the proper variant in different
practical scenarios. Our technique is also extended to bin-wise consistent
weighted sampling (BCWS) to develop a new DP algorithm called DP-BCWS for
non-binary data. Experiments on classification tasks demonstrate that DP-BCWS
is able to achieve excellent utility at around $\epsilon = 5\sim 10$, where
$\epsilon$ is the standard parameter in the language of $(\epsilon,
\delta)$-DP.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1">Xiaoyun Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1">Ping Li</a></p><p>Minwise hashing (MinHash) is a standard algorithm widely used in the
industry, for large-scale search and learning applications with the binary
(0/1) Jaccard similarity. One common use of MinHash is for processing massive
n-gram text representations so that practitioners do not have to materialize
the original data (which would be prohibitive). Another popular use of MinHash
is for building hash tables to enable sub-linear time approximate near neighbor
(ANN) search. MinHash has also been used as a tool for building large-scale
machine learning systems. The standard implementation of MinHash requires
applying $K$ random permutations. In comparison, the method of one permutation
hashing (OPH), is an efficient alternative of MinHash which splits the data
vectors into $K$ bins and generates hash values within each bin. OPH is
substantially more efficient and also more convenient to use.
</p>
<p>In this paper, we combine the differential privacy (DP) with OPH (as well as
MinHash), to propose the DP-OPH framework with three variants: DP-OPH-fix,
DP-OPH-re and DP-OPH-rand, depending on which densification strategy is adopted
to deal with empty bins in OPH. A detailed roadmap to the algorithm design is
presented along with the privacy analysis. An analytical comparison of our
proposed DP-OPH methods with the DP minwise hashing (DP-MH) is provided to
justify the advantage of DP-OPH. Experiments on similarity search confirm the
merits of DP-OPH, and guide the choice of the proper variant in different
practical scenarios. Our technique is also extended to bin-wise consistent
weighted sampling (BCWS) to develop a new DP algorithm called DP-BCWS for
non-binary data. Experiments on classification tasks demonstrate that DP-BCWS
is able to achieve excellent utility at around $\epsilon = 5\sim 10$, where
$\epsilon$ is the standard parameter in the language of $(\epsilon,
\delta)$-DP.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-14T00:30:00Z">Wednesday, June 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.07872'>Expanding the Scope of DAWN: A Novel Version for Weighted Shortest Path Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yelai Feng</p><p>The shortest path problem is a typical problem in graph theory with wide
potential applications. The state-of-the-art single-source shortest paths
algorithm on the weight graph is the $\Delta$-stepping algorithm, which can
efficiently process weighted graphs in parallel. DAWN is an algorithm that
addresses the shortest path problem on unweighted graphs, and we propose a
weighted version that can handle graphs with weights edges, while maintaining
the high scalability and parallelism features as DAWN. The novel version
requires $O(\mu m)$ and $O(\mu \cdot E_{wcc})$ times on the connected and
unconnected graphs for SSSP problems, respectively. $E_{wcc}$ denote the number
of edges included in the largest weakly connected component, and $\mu$ is a
constant denoting the average number of path transformations in the tasks. We
tested the weighted version on the real graphs from Stanford Network Analysis
Platform and SuiteSparse Matrix Collection, which outperformed the solution of
$\Delta$-stepping algorithm from Gunrock, achieving a speedup of
43.163$\times$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yelai Feng</a></p><p>The shortest path problem is a typical problem in graph theory with wide
potential applications. The state-of-the-art single-source shortest paths
algorithm on the weight graph is the $\Delta$-stepping algorithm, which can
efficiently process weighted graphs in parallel. DAWN is an algorithm that
addresses the shortest path problem on unweighted graphs, and we propose a
weighted version that can handle graphs with weights edges, while maintaining
the high scalability and parallelism features as DAWN. The novel version
requires $O(\mu m)$ and $O(\mu \cdot E_{wcc})$ times on the connected and
unconnected graphs for SSSP problems, respectively. $E_{wcc}$ denote the number
of edges included in the largest weakly connected component, and $\mu$ is a
constant denoting the average number of path transformations in the tasks. We
tested the weighted version on the real graphs from Stanford Network Analysis
Platform and SuiteSparse Matrix Collection, which outperformed the solution of
$\Delta$-stepping algorithm from Gunrock, achieving a speedup of
43.163$\times$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-14T00:30:00Z">Wednesday, June 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.07884'>Continual Release of Differentially Private Synthetic Data</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mark Bun, Marco Gaboardi, Marcel Neunhoeffer, Wanrong Zhang</p><p>Motivated by privacy concerns in long-term longitudinal studies in medical
and social science research, we study the problem of continually releasing
differentially private synthetic data. We introduce a model where, in every
time step, each individual reports a new data element, and the goal of the
synthesizer is to incrementally update a synthetic dataset to capture a rich
class of statistical properties. We give continual synthetic data generation
algorithms that preserve two basic types of queries: fixed time window queries
and cumulative time queries. We show nearly tight upper bounds on the error
rates of these algorithms and demonstrate their empirical performance on
realistically sized datasets from the U.S. Census Bureau's Survey of Income and
Program Participation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bun_M/0/1/0/all/0/1">Mark Bun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaboardi_M/0/1/0/all/0/1">Marco Gaboardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Neunhoeffer_M/0/1/0/all/0/1">Marcel Neunhoeffer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wanrong Zhang</a></p><p>Motivated by privacy concerns in long-term longitudinal studies in medical
and social science research, we study the problem of continually releasing
differentially private synthetic data. We introduce a model where, in every
time step, each individual reports a new data element, and the goal of the
synthesizer is to incrementally update a synthetic dataset to capture a rich
class of statistical properties. We give continual synthetic data generation
algorithms that preserve two basic types of queries: fixed time window queries
and cumulative time queries. We show nearly tight upper bounds on the error
rates of these algorithms and demonstrate their empirical performance on
realistically sized datasets from the U.S. Census Bureau's Survey of Income and
Program Participation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-14T00:30:00Z">Wednesday, June 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.07891'>Online Matching in Geometric Random Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Flore Sentenac, Nathan Noiry, Matthieu Lerasle, Laurent M&#xe9;nard, Vianney Perchet</p><p>In online advertisement, ad campaigns are sequentially displayed to users.
Both users and campaigns have inherent features, and the former is eligible to
the latter if they are ``similar enough''. We model these interactions as a
bipartite geometric random graph: the features of the $2N$ vertices ($N$ users
and $N$ campaigns) are drawn independently in a metric space and an edge is
present between a campaign and a user node if the distance between their
features is smaller than $c/N$, where $c&gt;0$ is the parameter of the model. Our
contributions are two-fold. In the one-dimensional case, with uniform
distribution over the segment $[0,1]$, we derive the size of the optimal
offline matching in these bipartite random geometric graphs, and we build an
algorithm achieving it (as a benchmark), and analyze precisely its performance.
We then turn to the online setting where one side of the graph is known at the
beginning while the other part is revealed sequentially. We study the number of
matches of the online algorithm closest, which matches any incoming point to
its closest available neighbor. We show that its performances can be compared
to its fluid limit, completely described as the solution of an explicit PDE.
From the latter, we can compute the competitive ratio of closest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sentenac_F/0/1/0/all/0/1">Flore Sentenac</a>, <a href="http://arxiv.org/find/cs/1/au:+Noiry_N/0/1/0/all/0/1">Nathan Noiry</a>, <a href="http://arxiv.org/find/cs/1/au:+Lerasle_M/0/1/0/all/0/1">Matthieu Lerasle</a>, <a href="http://arxiv.org/find/cs/1/au:+Menard_L/0/1/0/all/0/1">Laurent M&#xe9;nard</a>, <a href="http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1">Vianney Perchet</a></p><p>In online advertisement, ad campaigns are sequentially displayed to users.
Both users and campaigns have inherent features, and the former is eligible to
the latter if they are ``similar enough''. We model these interactions as a
bipartite geometric random graph: the features of the $2N$ vertices ($N$ users
and $N$ campaigns) are drawn independently in a metric space and an edge is
present between a campaign and a user node if the distance between their
features is smaller than $c/N$, where $c&gt;0$ is the parameter of the model. Our
contributions are two-fold. In the one-dimensional case, with uniform
distribution over the segment $[0,1]$, we derive the size of the optimal
offline matching in these bipartite random geometric graphs, and we build an
algorithm achieving it (as a benchmark), and analyze precisely its performance.
We then turn to the online setting where one side of the graph is known at the
beginning while the other part is revealed sequentially. We study the number of
matches of the online algorithm closest, which matches any incoming point to
its closest available neighbor. We show that its performances can be compared
to its fluid limit, completely described as the solution of an explicit PDE.
From the latter, we can compute the competitive ratio of closest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-14T00:30:00Z">Wednesday, June 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.07892'>Robustly Learning a Single Neuron via Sharpness</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Puqian Wang, Nikos Zarifis, Ilias Diakonikolas, Jelena Diakonikolas</p><p>We study the problem of learning a single neuron with respect to the
$L_2^2$-loss in the presence of adversarial label noise. We give an efficient
algorithm that, for a broad family of activations including ReLUs, approximates
the optimal $L_2^2$-error within a constant factor. Our algorithm applies under
much milder distributional assumptions compared to prior work. The key
ingredient enabling our results is a novel connection to local error bounds
from optimization theory.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Puqian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zarifis_N/0/1/0/all/0/1">Nikos Zarifis</a>, <a href="http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1">Ilias Diakonikolas</a>, <a href="http://arxiv.org/find/cs/1/au:+Diakonikolas_J/0/1/0/all/0/1">Jelena Diakonikolas</a></p><p>We study the problem of learning a single neuron with respect to the
$L_2^2$-loss in the presence of adversarial label noise. We give an efficient
algorithm that, for a broad family of activations including ReLUs, approximates
the optimal $L_2^2$-error within a constant factor. Our algorithm applies under
much milder distributional assumptions compared to prior work. The key
ingredient enabling our results is a novel connection to local error bounds
from optimization theory.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-14T00:30:00Z">Wednesday, June 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.07930'>Reducing Exposure to Harmful Content via Graph Rewiring</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Corinna Coupette, Stefan Neumann, Aristides Gionis</p><p>Most media content consumed today is provided by digital platforms that
aggregate input from diverse sources, where access to information is mediated
by recommendation algorithms. One principal challenge in this context is
dealing with content that is considered harmful. Striking a balance between
competing stakeholder interests, rather than block harmful content altogether,
one approach is to minimize the exposure to such content that is induced
specifically by algorithmic recommendations. Hence, modeling media items and
recommendations as a directed graph, we study the problem of reducing the
exposure to harmful content via edge rewiring. We formalize this problem using
absorbing random walks, and prove that it is NP-hard and NP-hard to approximate
to within an additive error, while under realistic assumptions, the greedy
method yields a (1-1/e)-approximation. Thus, we introduce Gamine, a fast greedy
algorithm that can reduce the exposure to harmful content with or without
quality constraints on recommendations. By performing just 100 rewirings on
YouTube graphs with several hundred thousand edges, Gamine reduces the initial
exposure by 50%, while ensuring that its recommendations are at most 5% less
relevant than the original recommendations. Through extensive experiments on
synthetic data and real-world data from video recommendation and news feed
applications, we confirm the effectiveness, robustness, and efficiency of
Gamine in practice.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Coupette_C/0/1/0/all/0/1">Corinna Coupette</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_S/0/1/0/all/0/1">Stefan Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Gionis_A/0/1/0/all/0/1">Aristides Gionis</a></p><p>Most media content consumed today is provided by digital platforms that
aggregate input from diverse sources, where access to information is mediated
by recommendation algorithms. One principal challenge in this context is
dealing with content that is considered harmful. Striking a balance between
competing stakeholder interests, rather than block harmful content altogether,
one approach is to minimize the exposure to such content that is induced
specifically by algorithmic recommendations. Hence, modeling media items and
recommendations as a directed graph, we study the problem of reducing the
exposure to harmful content via edge rewiring. We formalize this problem using
absorbing random walks, and prove that it is NP-hard and NP-hard to approximate
to within an additive error, while under realistic assumptions, the greedy
method yields a (1-1/e)-approximation. Thus, we introduce Gamine, a fast greedy
algorithm that can reduce the exposure to harmful content with or without
quality constraints on recommendations. By performing just 100 rewirings on
YouTube graphs with several hundred thousand edges, Gamine reduces the initial
exposure by 50%, while ensuring that its recommendations are at most 5% less
relevant than the original recommendations. Through extensive experiments on
synthetic data and real-world data from video recommendation and news feed
applications, we confirm the effectiveness, robustness, and efficiency of
Gamine in practice.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-14T00:30:00Z">Wednesday, June 14 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, June 12
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/06/12/phd-student-at-ruhr-university-of-bochum-apply-by-july-10-2023/'>PhD Student at Ruhr University of Bochum (apply by July 10, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We are inviting applications for a fully-funded PhD position at the Cluster of Excellence CASA. As the successful candidate, you will join the project &#8220;Robust Certification of Quantum Devices&#8221; and conduct fundamental research in the areas of: &#8211; Nonlocal games and self-testing. &#8211; Quantum information and cryptography. &#8211; Group and representation theory. Language: English. Salary: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We are inviting applications for a fully-funded PhD position at the Cluster of Excellence CASA. As the successful candidate, you will join the project &#8220;Robust Certification of Quantum Devices&#8221; and conduct fundamental research in the areas of:</p>
<p>&#8211; Nonlocal games and self-testing.<br />
&#8211; Quantum information and cryptography.<br />
&#8211; Group and representation theory.</p>
<p>Language: English. Salary: E-13, 100%.</p>
<p>Website: <a href="https://qi.ruhr-uni-bochum.de/hiring_casa">https://qi.ruhr-uni-bochum.de/hiring_casa</a><br />
Email: qi@rub.de</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T10:46:22Z">Monday, June 12 2023, 10:46</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/06/12/postdocs-at-ruhr-university-bochum-apply-by-july-10-2023/'>Postdocs at Ruhr University Bochum (apply by July 10, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We are inviting applications for postdoc positions as part of the ERC project Symmetry and Optimization at the Frontiers of Computation (SYMOPTIC). Website: qi.rub.de/hiring_erc_pd Email: qi@rub.de
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We are inviting applications for postdoc positions as part of the ERC project Symmetry and Optimization at the Frontiers of Computation (SYMOPTIC).</p>
<p>Website: <a href="https://qi.rub.de/hiring_erc_pd">https://qi.rub.de/hiring_erc_pd</a><br />
Email: qi@rub.de</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T08:56:40Z">Monday, June 12 2023, 08:56</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/06/12/phd-at-ruhr-university-bochum-apply-by-october-7-2023/'>PhD at Ruhr University Bochum (apply by October 7, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We are inviting applications for fully-funded PhD positions as part of the ERC project Symmetry and Optimization at the Frontiers of Computation (SYMOPTIC). Website: qi.rub.de/hiring_erc Email: qi@rub.de
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We are inviting applications for fully-funded PhD positions as part of the ERC project Symmetry and Optimization at the Frontiers of Computation (SYMOPTIC).</p>
<p>Website: <a href="https://qi.rub.de/hiring_erc">https://qi.rub.de/hiring_erc</a><br />
Email: qi@rub.de</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T08:52:55Z">Monday, June 12 2023, 08:52</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05818'>Complexity of Reachability Problems in Neural Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adrian Wurm</p><p>In this paper we investigate formal verification problems for Neural Network
computations. Various reachability problems will be in the focus, such as:
Given symbolic specifications of allowed inputs and outputs in form of Linear
Programming instances, one question is whether valid inputs exist such that the
given network computes a valid output? Does this property hold for all valid
inputs? The former question's complexity has been investigated recently by
S\"alzer and Lange for nets using the Rectified Linear Unit and the identity
function as their activation functions. We complement their achievements by
showing that the problem is NP-complete for piecewise linear functions with
rational coefficients that are not linear, NP-hard for almost all suitable
activation functions including non-linear ones that are continuous on an
interval, complete for the Existential Theory of the Reals $\exists \mathbb R$
for every non-linear polynomial and $\exists \mathbb R$-hard for the
exponential function and various sigmoidal functions. For the completeness
results, linking the verification tasks with the theory of Constraint
Satisfaction Problems turns out helpful.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wurm_A/0/1/0/all/0/1">Adrian Wurm</a></p><p>In this paper we investigate formal verification problems for Neural Network
computations. Various reachability problems will be in the focus, such as:
Given symbolic specifications of allowed inputs and outputs in form of Linear
Programming instances, one question is whether valid inputs exist such that the
given network computes a valid output? Does this property hold for all valid
inputs? The former question's complexity has been investigated recently by
S\"alzer and Lange for nets using the Rectified Linear Unit and the identity
function as their activation functions. We complement their achievements by
showing that the problem is NP-complete for piecewise linear functions with
rational coefficients that are not linear, NP-hard for almost all suitable
activation functions including non-linear ones that are continuous on an
interval, complete for the Existential Theory of the Reals $\exists \mathbb R$
for every non-linear polynomial and $\exists \mathbb R$-hard for the
exponential function and various sigmoidal functions. For the completeness
results, linking the verification tasks with the theory of Constraint
Satisfaction Problems turns out helpful.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05962'>A dichotomy theorem for $\Gamma$-switchable $H$-colouring on $m$-edge coloured graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Richard Brewster, Arnott Kinder, Gary MacGillivray</p><p>Let $G$ be a graph in which each edge is assigned one of the colours $1, 2,
\ldots, m$, and let $\Gamma$ be a subgroup of $S_m$. The operation of switching
at a vertex $x$ of $G$ with respect to an element $\pi$ of $\Gamma$ permutes
the colours of the edges incident with $x$ according to $\pi$. We investigate
the complexity of whether there exists a sequence of switches that transforms a
given $m$-edge coloured graph $G$ so that it has a colour-preserving
homomorphism to a fixed $m$-edge coloured graph $H$ and give a dichotomy
theorem in the case that $\Gamma$ acts transitively.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Brewster_R/0/1/0/all/0/1">Richard Brewster</a>, <a href="http://arxiv.org/find/math/1/au:+Kinder_A/0/1/0/all/0/1">Arnott Kinder</a>, <a href="http://arxiv.org/find/math/1/au:+MacGillivray_G/0/1/0/all/0/1">Gary MacGillivray</a></p><p>Let $G$ be a graph in which each edge is assigned one of the colours $1, 2,
\ldots, m$, and let $\Gamma$ be a subgroup of $S_m$. The operation of switching
at a vertex $x$ of $G$ with respect to an element $\pi$ of $\Gamma$ permutes
the colours of the edges incident with $x$ according to $\pi$. We investigate
the complexity of whether there exists a sequence of switches that transforms a
given $m$-edge coloured graph $G$ so that it has a colour-preserving
homomorphism to a fixed $m$-edge coloured graph $H$ and give a dichotomy
theorem in the case that $\Gamma$ acts transitively.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05977'>Towards Universally Optimal Shortest Paths Algorithms in the Hybrid Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Philipp Schneider</p><p>A drawback of the classic approach for complexity analysis of distributed
graph problems is that it mostly informs about the complexity of notorious
classes of ``worst case'' graphs. Algorithms that are used to prove a tight
(existential) bound are essentially optimized to perform well on such worst
case graphs. However, such graphs are often either unlikely or actively avoided
in practice, where benign graph instances usually admit much faster solutions.
</p>
<p>To circumnavigate these drawbacks, the concept of universal complexity
analysis in the distributed setting was suggested by [Kutten and Peleg,
PODC'95] and actively pursued by [Haeupler et al., STOC'21]. Here, the aim is
to gauge the complexity of a distributed graph problem depending on the given
graph instance. The challenge is to identify and understand the graph property
that allows to accurately quantify the complexity of a distributed problem on a
given graph.
</p>
<p>In the present work, we consider distributed shortest paths problems in the
HYBRID model of distributed computing, where nodes have simultaneous access to
two different modes of communication: one is restricted by locality and the
other is restricted by congestion. We identify the graph parameter of
neighborhood quality and show that it accurately describes a universal bound
for the complexity of certain class of shortest paths problems in the HYBRID
model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Schneider_P/0/1/0/all/0/1">Philipp Schneider</a></p><p>A drawback of the classic approach for complexity analysis of distributed
graph problems is that it mostly informs about the complexity of notorious
classes of ``worst case'' graphs. Algorithms that are used to prove a tight
(existential) bound are essentially optimized to perform well on such worst
case graphs. However, such graphs are often either unlikely or actively avoided
in practice, where benign graph instances usually admit much faster solutions.
</p>
<p>To circumnavigate these drawbacks, the concept of universal complexity
analysis in the distributed setting was suggested by [Kutten and Peleg,
PODC'95] and actively pursued by [Haeupler et al., STOC'21]. Here, the aim is
to gauge the complexity of a distributed graph problem depending on the given
graph instance. The challenge is to identify and understand the graph property
that allows to accurately quantify the complexity of a distributed problem on a
given graph.
</p>
<p>In the present work, we consider distributed shortest paths problems in the
HYBRID model of distributed computing, where nodes have simultaneous access to
two different modes of communication: one is restricted by locality and the
other is restricted by congestion. We identify the graph parameter of
neighborhood quality and show that it accurately describes a universal bound
for the complexity of certain class of shortest paths problems in the HYBRID
model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05475'>Robust Topological Orderings for Directed Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: James Smith</p><p>We modify the Pearce-Kelly algorithm that maintains a topological ordering
for a directed acyclic graph in order to allow cycles to be tolerated. Cycles
make topological orderings moot, of course, however tolerating them is useful
in practice. A user may mistakenly introduce a cyclic dependency in their
project,, for example, and then subsequently fix their mistake. In these cases
it is better to maintain the relevant data structures so that if and when the
directed graph becomes acyclic again, a topological ordering can be instantly
recovered. It turns out that adding this functionality costs us little, only
small modifications and some attention to detail are needed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1">James Smith</a></p><p>We modify the Pearce-Kelly algorithm that maintains a topological ordering
for a directed acyclic graph in order to allow cycles to be tolerated. Cycles
make topological orderings moot, of course, however tolerating them is useful
in practice. A user may mistakenly introduce a cyclic dependency in their
project,, for example, and then subsequently fix their mistake. In these cases
it is better to maintain the relevant data structures so that if and when the
directed graph becomes acyclic again, a topological ordering can be instantly
recovered. It turns out that adding this functionality costs us little, only
small modifications and some attention to detail are needed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05588'>An Improved Algorithm for Finding Maximum Outerplanar Subgraphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gruia Calinescu, Hemanshu Kaul, Bahareh Kudarzi</p><p>We study the NP-complete Maximum Outerplanar Subgraph problem. The previous
best known approximation ratio for this problem is 2/3. We propose a new
approximation algorithm which improves the ratio to 7/10.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Calinescu_G/0/1/0/all/0/1">Gruia Calinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaul_H/0/1/0/all/0/1">Hemanshu Kaul</a>, <a href="http://arxiv.org/find/cs/1/au:+Kudarzi_B/0/1/0/all/0/1">Bahareh Kudarzi</a></p><p>We study the NP-complete Maximum Outerplanar Subgraph problem. The previous
best known approximation ratio for this problem is 2/3. We propose a new
approximation algorithm which improves the ratio to 7/10.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05684'>Space-time Trade-offs for the LCP Array of Wheeler DFAs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicola Cotumaccio, Travis Gagie, Dominik K&#xf6;ppl, Nicola Prezza</p><p>Recently, Conte et al. generalized the longest-common prefix (LCP) array from
strings to Wheeler DFAs, and they showed that it can be used to efficiently
determine matching statistics on a Wheeler DFA [DCC 2023]. However, storing the
LCP array requires $ O(n \log n) $ bits, $ n $ being the number of states,
while the compact representation of Wheeler DFAs often requires much less
space. In particular, the BOSS representation of a de Bruijn graph only
requires a linear number of bits, if the size of alphabet is constant.
</p>
<p>In this paper, we propose a sampling technique that allows to access an entry
of the LCP array in logarithmic time by only storing a linear number of bits.
We use our technique to provide a space-time trade-off to compute matching
statistics on a Wheeler DFA. In addition, we show that by augmenting the BOSS
representation of a $ k $-th order de Bruijn graph with a linear number of bits
we can navigate the underlying variable-order de Bruijn graph in time
logarithmic in $ k $, thus improving a previous bound by Boucher et al. which
was linear in $ k $ [DCC 2015].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cotumaccio_N/0/1/0/all/0/1">Nicola Cotumaccio</a>, <a href="http://arxiv.org/find/cs/1/au:+Gagie_T/0/1/0/all/0/1">Travis Gagie</a>, <a href="http://arxiv.org/find/cs/1/au:+Koppl_D/0/1/0/all/0/1">Dominik K&#xf6;ppl</a>, <a href="http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1">Nicola Prezza</a></p><p>Recently, Conte et al. generalized the longest-common prefix (LCP) array from
strings to Wheeler DFAs, and they showed that it can be used to efficiently
determine matching statistics on a Wheeler DFA [DCC 2023]. However, storing the
LCP array requires $ O(n \log n) $ bits, $ n $ being the number of states,
while the compact representation of Wheeler DFAs often requires much less
space. In particular, the BOSS representation of a de Bruijn graph only
requires a linear number of bits, if the size of alphabet is constant.
</p>
<p>In this paper, we propose a sampling technique that allows to access an entry
of the LCP array in logarithmic time by only storing a linear number of bits.
We use our technique to provide a space-time trade-off to compute matching
statistics on a Wheeler DFA. In addition, we show that by augmenting the BOSS
representation of a $ k $-th order de Bruijn graph with a linear number of bits
we can navigate the underlying variable-order de Bruijn graph in time
logarithmic in $ k $, thus improving a previous bound by Boucher et al. which
was linear in $ k $ [DCC 2015].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05734'>DP-HyPO: An Adaptive Private Hyperparameter Optimization Framework</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hua Wang, Sheng Gao, Huanyu Zhang, Weijie J. Su, Milan Shen</p><p>Hyperparameter optimization, also known as hyperparameter tuning, is a widely
recognized technique for improving model performance. Regrettably, when
training private ML models, many practitioners often overlook the privacy risks
associated with hyperparameter optimization, which could potentially expose
sensitive information about the underlying dataset. Currently, the sole
existing approach to allow privacy-preserving hyperparameter optimization is to
uniformly and randomly select hyperparameters for a number of runs,
subsequently reporting the best-performing hyperparameter. In contrast, in
non-private settings, practitioners commonly utilize "adaptive" hyperparameter
optimization methods such as Gaussian process-based optimization, which select
the next candidate based on information gathered from previous outputs. This
substantial contrast between private and non-private hyperparameter
optimization underscores a critical concern. In our paper, we introduce
DP-HyPO, a pioneering framework for "adaptive" private hyperparameter
optimization, aiming to bridge the gap between private and non-private
hyperparameter optimization. To accomplish this, we provide a comprehensive
differential privacy analysis of our framework. Furthermore, we empirically
demonstrate the effectiveness of DP-HyPO on a diverse set of real-world and
synthetic datasets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hua Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Sheng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huanyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1">Weijie J. Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1">Milan Shen</a></p><p>Hyperparameter optimization, also known as hyperparameter tuning, is a widely
recognized technique for improving model performance. Regrettably, when
training private ML models, many practitioners often overlook the privacy risks
associated with hyperparameter optimization, which could potentially expose
sensitive information about the underlying dataset. Currently, the sole
existing approach to allow privacy-preserving hyperparameter optimization is to
uniformly and randomly select hyperparameters for a number of runs,
subsequently reporting the best-performing hyperparameter. In contrast, in
non-private settings, practitioners commonly utilize "adaptive" hyperparameter
optimization methods such as Gaussian process-based optimization, which select
the next candidate based on information gathered from previous outputs. This
substantial contrast between private and non-private hyperparameter
optimization underscores a critical concern. In our paper, we introduce
DP-HyPO, a pioneering framework for "adaptive" private hyperparameter
optimization, aiming to bridge the gap between private and non-private
hyperparameter optimization. To accomplish this, we provide a comprehensive
differential privacy analysis of our framework. Furthermore, we empirically
demonstrate the effectiveness of DP-HyPO on a diverse set of real-world and
synthetic datasets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05744'>Improved and Deterministic Online Service with Deadlines or Delay</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Noam Touitou</p><p>We consider the problem of online service with delay on a general metric
space, first presented by Azar, Ganesh, Ge and Panigrahi (STOC 2017). The best
known randomized algorithm for this problem, by Azar and Touitou (FOCS 2019),
is $O(\log^2 n)$-competitive, where $n$ is the number of points in the metric
space. This is also the best known result for the special case of online
service with deadlines, which is of independent interest.
</p>
<p>In this paper, we present $O(\log n)$-competitive deterministic algorithms
for online service with deadlines or delay, improving upon the results from
FOCS 2019. Furthermore, our algorithms are the first deterministic algorithms
for online service with deadlines or delay which apply to general metric spaces
and have sub-polynomial competitiveness.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Touitou_N/0/1/0/all/0/1">Noam Touitou</a></p><p>We consider the problem of online service with delay on a general metric
space, first presented by Azar, Ganesh, Ge and Panigrahi (STOC 2017). The best
known randomized algorithm for this problem, by Azar and Touitou (FOCS 2019),
is $O(\log^2 n)$-competitive, where $n$ is the number of points in the metric
space. This is also the best known result for the special case of online
service with deadlines, which is of independent interest.
</p>
<p>In this paper, we present $O(\log n)$-competitive deterministic algorithms
for online service with deadlines or delay, improving upon the results from
FOCS 2019. Furthermore, our algorithms are the first deterministic algorithms
for online service with deadlines or delay which apply to general metric spaces
and have sub-polynomial competitiveness.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05781'>Adaptivity Complexity for Causal Graph Discovery</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Davin Choo, Kirankumar Shiragur</p><p>Causal discovery from interventional data is an important problem, where the
task is to design an interventional strategy that learns the hidden ground
truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of
performed interventions. Most prior interventional strategies broadly fall into
two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a
single fixed set of interventions to be performed while adaptive strategies can
decide on which nodes to intervene on sequentially based on past interventions.
While adaptive algorithms may use exponentially fewer interventions than their
non-adaptive counterparts, there are practical concerns that constrain the
amount of adaptivity allowed. Motivated by this trade-off, we study the problem
of $r$-adaptivity, where the algorithm designer recovers the causal graph under
a total of $r$ sequential rounds whilst trying to minimize the total number of
interventions. For this problem, we provide a $r$-adaptive algorithm that
achieves $O(\min\{r,\log n\} \cdot n^{1/\min\{r,\log n\}})$ approximation with
respect to the verification number, a well-known lower bound for adaptive
algorithms. Furthermore, for every $r$, we show that our approximation is
tight. Our definition of $r$-adaptivity interpolates nicely between the
non-adaptive ($r=1$) and fully adaptive ($r=n$) settings where our
approximation simplifies to $O(n)$ and $O(\log n)$ respectively, matching the
best-known approximation guarantees for both extremes. Our results also extend
naturally to the bounded size interventions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Choo_D/0/1/0/all/0/1">Davin Choo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shiragur_K/0/1/0/all/0/1">Kirankumar Shiragur</a></p><p>Causal discovery from interventional data is an important problem, where the
task is to design an interventional strategy that learns the hidden ground
truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of
performed interventions. Most prior interventional strategies broadly fall into
two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a
single fixed set of interventions to be performed while adaptive strategies can
decide on which nodes to intervene on sequentially based on past interventions.
While adaptive algorithms may use exponentially fewer interventions than their
non-adaptive counterparts, there are practical concerns that constrain the
amount of adaptivity allowed. Motivated by this trade-off, we study the problem
of $r$-adaptivity, where the algorithm designer recovers the causal graph under
a total of $r$ sequential rounds whilst trying to minimize the total number of
interventions. For this problem, we provide a $r$-adaptive algorithm that
achieves $O(\min\{r,\log n\} \cdot n^{1/\min\{r,\log n\}})$ approximation with
respect to the verification number, a well-known lower bound for adaptive
algorithms. Furthermore, for every $r$, we show that our approximation is
tight. Our definition of $r$-adaptivity interpolates nicely between the
non-adaptive ($r=1$) and fully adaptive ($r=n$) settings where our
approximation simplifies to $O(n)$ and $O(\log n)$ respectively, matching the
best-known approximation guarantees for both extremes. Our results also extend
naturally to the bounded size interventions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05838'>Expectation-Complete Graph Representations with Homomorphisms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pascal Welke, Maximilian Thiessen, Fabian Jogl, Thomas G&#xe4;rtner</p><p>We investigate novel random graph embeddings that can be computed in expected
polynomial time and that are able to distinguish all non-isomorphic graphs in
expectation. Previous graph embeddings have limited expressiveness and either
cannot distinguish all graphs or cannot be computed efficiently for every
graph. To be able to approximate arbitrary functions on graphs, we are
interested in efficient alternatives that become arbitrarily expressive with
increasing resources. Our approach is based on Lov\'asz' characterisation of
graph isomorphism through an infinite dimensional vector of homomorphism
counts. Our empirical evaluation shows competitive results on several benchmark
graph learning tasks.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Welke_P/0/1/0/all/0/1">Pascal Welke</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiessen_M/0/1/0/all/0/1">Maximilian Thiessen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jogl_F/0/1/0/all/0/1">Fabian Jogl</a>, <a href="http://arxiv.org/find/cs/1/au:+Gartner_T/0/1/0/all/0/1">Thomas G&#xe4;rtner</a></p><p>We investigate novel random graph embeddings that can be computed in expected
polynomial time and that are able to distinguish all non-isomorphic graphs in
expectation. Previous graph embeddings have limited expressiveness and either
cannot distinguish all graphs or cannot be computed efficiently for every
graph. To be able to approximate arbitrary functions on graphs, we are
interested in efficient alternatives that become arbitrarily expressive with
increasing resources. Our approach is based on Lov\'asz' characterisation of
graph isomorphism through an infinite dimensional vector of homomorphism
counts. Our empirical evaluation shows competitive results on several benchmark
graph learning tasks.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05865'>Faster Discrete Convex Function Minimization with Predictions: The M-Convex Case</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Taihei Oki, Shinsaku Sakaue</p><p>Recent years have seen a growing interest in accelerating optimization
algorithms with machine-learned predictions. Sakaue and Oki (NeurIPS 2022) have
developed a general framework that warm-starts the L-convex function
minimization method with predictions, revealing the idea's usefulness for
various discrete optimization problems. In this paper, we present a framework
for using predictions to accelerate M-convex function minimization, thus
complementing previous research and extending the range of discrete
optimization algorithms that can benefit from predictions. Our framework is
particularly effective for an important subclass called laminar convex
minimization, which appears in many operations research applications. Our
methods can improve time complexity bounds upon the best worst-case results by
using predictions and even have potential to go beyond a lower-bound result.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Oki_T/0/1/0/all/0/1">Taihei Oki</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakaue_S/0/1/0/all/0/1">Shinsaku Sakaue</a></p><p>Recent years have seen a growing interest in accelerating optimization
algorithms with machine-learned predictions. Sakaue and Oki (NeurIPS 2022) have
developed a general framework that warm-starts the L-convex function
minimization method with predictions, revealing the idea's usefulness for
various discrete optimization problems. In this paper, we present a framework
for using predictions to accelerate M-convex function minimization, thus
complementing previous research and extending the range of discrete
optimization algorithms that can benefit from predictions. Our framework is
particularly effective for an important subclass called laminar convex
minimization, which appears in many operations research applications. Our
methods can improve time complexity bounds upon the best worst-case results by
using predictions and even have potential to go beyond a lower-bound result.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05916'>Differentially Private All-Pairs Shortest Distances for Low Tree-Width Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Javad B. Ebrahimi, Alireza Tofighi Mohammadi, Fatemeh Kermani</p><p>In this paper, we present a polynomial time algorithm for the problem of
differentially private all pair shortest distances over the class of low
tree-width graphs. Our result generalizes the result of Sealfon 2016 for the
case of trees to a much larger family of graphs. Furthermore, if we restrict to
the class of low tree-width graphs, the additive error of our algorithm is
significantly smaller than that of the best known algorithm for this problem,
proposed by Chen et. al. 2023.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ebrahimi_J/0/1/0/all/0/1">Javad B. Ebrahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadi_A/0/1/0/all/0/1">Alireza Tofighi Mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kermani_F/0/1/0/all/0/1">Fatemeh Kermani</a></p><p>In this paper, we present a polynomial time algorithm for the problem of
differentially private all pair shortest distances over the class of low
tree-width graphs. Our result generalizes the result of Sealfon 2016 for the
case of trees to a much larger family of graphs. Furthermore, if we restrict to
the class of low tree-width graphs, the additive error of our algorithm is
significantly smaller than that of the best known algorithm for this problem,
proposed by Chen et. al. 2023.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05979'>Optimal distance query reconstruction for graphs without long induced cycles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Paul Bastide, Carla Groenland</p><p>Let $G=(V,E)$ be an $n$-vertex connected graph of maximum degree $\Delta$.
Given access to $V$ and an oracle that given two vertices $u,v\in V$, returns
the shortest path distance between $u$ and $v$, how many queries are needed to
reconstruct $E$? We give a simple deterministic algorithm to reconstruct trees
using $\Delta n\log_\Delta n+(\Delta+2)n$ distance queries and show that even
randomised algorithms need to use at least $\frac1{100} \Delta n\log_\Delta n$
queries in expectation. The best previous lower bound was an
information-theoretic lower bound of $\Omega(n\log n/\log \log n)$. Our lower
bound also extends to related query models including distance queries for
phylogenetic trees, membership queries for learning partitions and path queries
in directed trees.
</p>
<p>We extend our deterministic algorithm to reconstruct graphs without induced
cycles of length at least $k$ using $O_{\Delta,k}(n\log n)$ queries, which
includes various graph classes of interest such as chordal graphs, permutation
graphs and AT-free graphs. Since the previously best known randomised algorithm
for chordal graphs uses $O_{\Delta}(n\log^2 n)$ queries in expectation, we both
get rid off the randomness and get the optimal dependency in $n$ for chordal
graphs and various other graph classes.
</p>
<p>Finally, we build on an algorithm of Kannan, Mathieu, and Zhou [ICALP, 2015]
to give a randomised algorithm for reconstructing graphs of treelength $k$
using $O_{\Delta,k}(n\log^2n)$ queries in expectation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bastide_P/0/1/0/all/0/1">Paul Bastide</a>, <a href="http://arxiv.org/find/cs/1/au:+Groenland_C/0/1/0/all/0/1">Carla Groenland</a></p><p>Let $G=(V,E)$ be an $n$-vertex connected graph of maximum degree $\Delta$.
Given access to $V$ and an oracle that given two vertices $u,v\in V$, returns
the shortest path distance between $u$ and $v$, how many queries are needed to
reconstruct $E$? We give a simple deterministic algorithm to reconstruct trees
using $\Delta n\log_\Delta n+(\Delta+2)n$ distance queries and show that even
randomised algorithms need to use at least $\frac1{100} \Delta n\log_\Delta n$
queries in expectation. The best previous lower bound was an
information-theoretic lower bound of $\Omega(n\log n/\log \log n)$. Our lower
bound also extends to related query models including distance queries for
phylogenetic trees, membership queries for learning partitions and path queries
in directed trees.
</p>
<p>We extend our deterministic algorithm to reconstruct graphs without induced
cycles of length at least $k$ using $O_{\Delta,k}(n\log n)$ queries, which
includes various graph classes of interest such as chordal graphs, permutation
graphs and AT-free graphs. Since the previously best known randomised algorithm
for chordal graphs uses $O_{\Delta}(n\log^2 n)$ queries in expectation, we both
get rid off the randomness and get the optimal dependency in $n$ for chordal
graphs and various other graph classes.
</p>
<p>Finally, we build on an algorithm of Kannan, Mathieu, and Zhou [ICALP, 2015]
to give a randomised algorithm for reconstructing graphs of treelength $k$
using $O_{\Delta,k}(n\log^2n)$ queries in expectation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05986'>Fair Allocation with Binary Valuations for Mixed Divisible and Indivisible Goods</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yasushi Kawase, Koichi Nishimura, Hanna Sumita</p><p>The fair allocation of mixed goods, consisting of both divisible and
indivisible goods, among agents with heterogeneous preferences, has been a
prominent topic of study in economics and computer science. In this paper, we
investigate the nature of fair allocations when agents have binary valuations.
We define an allocation as fair if its utility vector minimizes a symmetric
strictly convex function, which includes conventional fairness criteria such as
maximum egalitarian social welfare and maximum Nash social welfare. While a
good structure is known for the continuous case (where only divisible goods
exist) or the discrete case (where only indivisible goods exist), deriving such
a structure in the hybrid case remains challenging. Our contributions are
twofold. First, we demonstrate that the hybrid case does not inherit some of
the nice properties of continuous or discrete cases, while it does inherit the
proximity theorem. Second, we analyze the computational complexity of finding a
fair allocation of mixed goods based on the proximity theorem. In particular,
we provide a polynomial-time algorithm for the case when all divisible goods
are identical and homogeneous, and demonstrate that the problem is NP-hard in
general. Our results also contribute to a deeper understanding of the hybrid
convex analysis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kawase_Y/0/1/0/all/0/1">Yasushi Kawase</a>, <a href="http://arxiv.org/find/cs/1/au:+Nishimura_K/0/1/0/all/0/1">Koichi Nishimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Sumita_H/0/1/0/all/0/1">Hanna Sumita</a></p><p>The fair allocation of mixed goods, consisting of both divisible and
indivisible goods, among agents with heterogeneous preferences, has been a
prominent topic of study in economics and computer science. In this paper, we
investigate the nature of fair allocations when agents have binary valuations.
We define an allocation as fair if its utility vector minimizes a symmetric
strictly convex function, which includes conventional fairness criteria such as
maximum egalitarian social welfare and maximum Nash social welfare. While a
good structure is known for the continuous case (where only divisible goods
exist) or the discrete case (where only indivisible goods exist), deriving such
a structure in the hybrid case remains challenging. Our contributions are
twofold. First, we demonstrate that the hybrid case does not inherit some of
the nice properties of continuous or discrete cases, while it does inherit the
proximity theorem. Second, we analyze the computational complexity of finding a
fair allocation of mixed goods based on the proximity theorem. In particular,
we provide a polynomial-time algorithm for the case when all divisible goods
are identical and homogeneous, and demonstrate that the problem is NP-hard in
general. Our results also contribute to a deeper understanding of the hybrid
convex analysis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.06003'>Semi-online Scheduling with Lookahead</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Debasis Dwibedy, Rakesh Mohanty</p><p>The knowledge of future partial information in the form of a lookahead to
design efficient online algorithms is a theoretically-efficient and realistic
approach to solving computational problems. Design and analysis of semi-online
algorithms with extra-piece-of-information (EPI) as a new input parameter has
gained the attention of the theoretical computer science community in the last
couple of decades. Though competitive analysis is a pessimistic worst-case
performance measure to analyze online algorithms, it has immense theoretical
value in developing the foundation and advancing the state-of-the-art
contributions in online and semi-online scheduling. In this paper, we study and
explore the impact of lookahead as an EPI in the context of online scheduling
in identical machine frameworks. We introduce a $k$-lookahead model and design
improved competitive semi-online algorithms. For a $2$-identical machine
setting, we prove a lower bound of $\frac{4}{3}$ and design an optimal
algorithm with a matching upper bound of $\frac{4}{3}$ on the competitive
ratio. For a $3$-identical machine setting, we show a lower bound of
$\frac{15}{11}$ and design a $\frac{16}{11}$-competitive improved semi-online
algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dwibedy_D/0/1/0/all/0/1">Debasis Dwibedy</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohanty_R/0/1/0/all/0/1">Rakesh Mohanty</a></p><p>The knowledge of future partial information in the form of a lookahead to
design efficient online algorithms is a theoretically-efficient and realistic
approach to solving computational problems. Design and analysis of semi-online
algorithms with extra-piece-of-information (EPI) as a new input parameter has
gained the attention of the theoretical computer science community in the last
couple of decades. Though competitive analysis is a pessimistic worst-case
performance measure to analyze online algorithms, it has immense theoretical
value in developing the foundation and advancing the state-of-the-art
contributions in online and semi-online scheduling. In this paper, we study and
explore the impact of lookahead as an EPI in the context of online scheduling
in identical machine frameworks. We introduce a $k$-lookahead model and design
improved competitive semi-online algorithms. For a $2$-identical machine
setting, we prove a lower bound of $\frac{4}{3}$ and design an optimal
algorithm with a matching upper bound of $\frac{4}{3}$ on the competitive
ratio. For a $3$-identical machine setting, we show a lower bound of
$\frac{15}{11}$ and design a $\frac{16}{11}$-competitive improved semi-online
algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.06050'>Branching via Cutting Plane Selection: Improving Hybrid Branching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mark Turner, Timo Berthold, Mathieu Besan&#xe7;on, Thorsten Koch</p><p>Cutting planes and branching are two of the most important algorithms for
solving mixed-integer linear programs. For both algorithms, disjunctions play
an important role, being used both as branching candidates and as the
foundation for some cutting planes. We relate branching decisions and cutting
planes to each other through the underlying disjunctions that they are based
on, with a focus on Gomory mixed-integer cuts and their corresponding split
disjunctions. We show that selecting branching decisions based on quality
measures of Gomory mixed-integer cuts leads to relatively small
branch-and-bound trees, and that the result improves when using cuts that more
accurately represent the branching decisions. Finally, we show how the history
of previously computed Gomory mixed-integer cuts can be used to improve the
performance of the state-of-the-art hybrid branching rule of SCIP. Our results
show a 4\% decrease in solve time, and an 8\% decrease in number of nodes over
affected instances of MIPLIB 2017.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Turner_M/0/1/0/all/0/1">Mark Turner</a>, <a href="http://arxiv.org/find/math/1/au:+Berthold_T/0/1/0/all/0/1">Timo Berthold</a>, <a href="http://arxiv.org/find/math/1/au:+Besancon_M/0/1/0/all/0/1">Mathieu Besan&#xe7;on</a>, <a href="http://arxiv.org/find/math/1/au:+Koch_T/0/1/0/all/0/1">Thorsten Koch</a></p><p>Cutting planes and branching are two of the most important algorithms for
solving mixed-integer linear programs. For both algorithms, disjunctions play
an important role, being used both as branching candidates and as the
foundation for some cutting planes. We relate branching decisions and cutting
planes to each other through the underlying disjunctions that they are based
on, with a focus on Gomory mixed-integer cuts and their corresponding split
disjunctions. We show that selecting branching decisions based on quality
measures of Gomory mixed-integer cuts leads to relatively small
branch-and-bound trees, and that the result improves when using cuts that more
accurately represent the branching decisions. Finally, we show how the history
of previously computed Gomory mixed-integer cuts can be used to improve the
performance of the state-of-the-art hybrid branching rule of SCIP. Our results
show a 4\% decrease in solve time, and an 8\% decrease in number of nodes over
affected instances of MIPLIB 2017.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, June 11
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/088'>TR23-088 |  A High Dimensional Goldreich-Levin Theorem | 

	Silas Richelson, 

	Parker Newton, 

	Chase Wilson</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this work we prove a high dimensional analogue of the beloved Goldreich-Levin theorem (STOC 1989).  We consider the following algorithmic problem: given oracle access to a function $f:\mathbb{Z}_q^m\rightarrow\mathbb{Z}_q^n$ such that ${\rm Prob}_{{\bf x}\sim\mathbb{Z}_q^m}\bigl[f({\bf x})={\bf Ax}\bigr]\geq\varepsilon$ for some ${\bf A}\in\mathbb{Z}_q^{n\times m}$ and $\varepsilon&gt;0$, recover ${\bf A}$ (or a list of all such matrices).  We focus on the case $\varepsilon\leq1/q$ since when $\varepsilon\geq1/q+\delta$, the problem is solved by the original Goldreich-Levin theorem.  As stated, this problem cannot be efficiently solved, since when $\varepsilon\leq1/q$ the list of ${\bf A}$ with good agreement with $f$ might be exponentially large.  Our main theorem gives an algorithm which efficiently recovers a list of linear maps of size $\mathcal{O}\bigl(1/\varepsilon\bigr)$ which have good agreement with $f$, and such that every linear map which has good agreement with $f$, also has good agreement with some map in our list.  Our proof makes novel use of Fourier analysis.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In this work we prove a high dimensional analogue of the beloved Goldreich-Levin theorem (STOC 1989).  We consider the following algorithmic problem: given oracle access to a function $f:\mathbb{Z}_q^m\rightarrow\mathbb{Z}_q^n$ such that ${\rm Prob}_{{\bf x}\sim\mathbb{Z}_q^m}\bigl[f({\bf x})={\bf Ax}\bigr]\geq\varepsilon$ for some ${\bf A}\in\mathbb{Z}_q^{n\times m}$ and $\varepsilon&gt;0$, recover ${\bf A}$ (or a list of all such matrices).  We focus on the case $\varepsilon\leq1/q$ since when $\varepsilon\geq1/q+\delta$, the problem is solved by the original Goldreich-Levin theorem.  As stated, this problem cannot be efficiently solved, since when $\varepsilon\leq1/q$ the list of ${\bf A}$ with good agreement with $f$ might be exponentially large.  Our main theorem gives an algorithm which efficiently recovers a list of linear maps of size $\mathcal{O}\bigl(1/\varepsilon\bigr)$ which have good agreement with $f$, and such that every linear map which has good agreement with $f$, also has good agreement with some map in our list.  Our proof makes novel use of Fourier analysis.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-11T04:10:05Z">Sunday, June 11 2023, 04:10</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, June 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/06/posting-book-online-with-password-that.html'>Posting a book online with a password- that you broadcast.</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;Recently Lance, at the request of&nbsp; Vijay Vazirani, tweeted the following (I paraphrase)</p><p>---------------------------------------------------------------------------------------</p><p>Online and Matching-based Market Design book now available as free PDF&nbsp;</p><p>cambridge.org/files/9216/848&nbsp;&nbsp;<br></p><p>The password is OMBMD_CUP</p><p>---------------------------------------------------------------------------------------------</p><p>This tweet raises two questions.</p><p>1) When a book is put online, does it cut into sales? I've heard that people still like paper so the posting on line might be like an ad for the book. Also, for academic books, the authors WANT it to be out there and don't care so much about sales.&nbsp; If Gasarch &amp; Martin's Bounded Queries in Recursion Theory was available for illegal download I would be delighted. And surprised.&nbsp;</p><p>2) SO, they post it to make it more available and generate buzz. So why have a password? Was this a compromise:&nbsp;</p><p>a) We want people to BUY the book so we'll post it with a password and limit access.&nbsp;</p><p>b) We want people to SEE the book since as academics we don't care about sales, and it might generate buzz, so we don't want a password</p><p>c) COMPROMISE: Have a password but tell everyone what it is.&nbsp;</p><p>If you can think of a more plausible scenario, leave a comment.&nbsp;</p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;Recently Lance, at the request of&nbsp; Vijay Vazirani, tweeted the following (I paraphrase)</p><p>---------------------------------------------------------------------------------------</p><p>Online and Matching-based Market Design book now available as free PDF&nbsp;</p><p><a href="https://www.cambridge.org/files/9216/8487/6990/matching_book_pw.pdf">cambridge.org/files/9216/848</a>&nbsp;&nbsp;<br /></p><p>The password is OMBMD_CUP</p><p>---------------------------------------------------------------------------------------------</p><p>This tweet raises two questions.</p><p>1) When a book is put online, does it cut into sales? I've heard that people still like paper so the posting on line might be like an ad for the book. Also, for academic books, the authors WANT it to be out there and don't care so much about sales.&nbsp; If Gasarch &amp; Martin's <i>Bounded Queries in Recursion Theory </i>was available for illegal download I would be delighted. And surprised.&nbsp;</p><p>2) SO, they post it to make it more available and generate buzz. So why have a password? Was this a compromise:&nbsp;</p><p>a) We want people to BUY the book so we'll post it with a password and limit access.&nbsp;</p><p>b) We want people to SEE the book since as academics we don't care about sales, and it might generate buzz, so we don't want a password</p><p>c) COMPROMISE: Have a password but tell everyone what it is.&nbsp;</p><p>If you can think of a more plausible scenario, leave a comment.&nbsp;</p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-10T15:16:00Z">Saturday, June 10 2023, 15:16</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, June 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/087'>TR23-087 |  How to Recover a Secret with $O(n)$ Additions | 

	Benny Applebaum, 

	Oded Nir, 

	Benny Pinkas</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Threshold cryptography is typically based on the idea of secret-sharing a private-key $s\in F$ ``in the exponent&#39;&#39; of some cryptographic group $G$, or more generally, encoding $s$ in some linearly homomorphic domain. In each invocation of the threshold system (e.g., for signing or decrypting) an ``encoding&#39;&#39; of the secret is being recovered and so the complexity, measured as the number of group multiplications over $G$, is equal to the number of $F$-additions that are needed to reconstruct the secret. Motivated by this scenario, we initiate the study of $n$-party secret-sharing schemes whose reconstruction algorithm makes a minimal number of \emph{additions}. The complexity of existing schemes either scales linearly with $n\log |F|$ (e.g., Shamir, CACM&#39;79) or, at least, quadratically with $n$ independently of the size of the domain $F$ (e.g., Cramer-Xing, EUROCRYPT &#39;20). This leaves open the existence of a secret sharing whose recovery algorithm can be computed by performing only $O(n)$ additions.

We resolve the question in the affirmative and present such a near-threshold secret sharing scheme that provides privacy against unauthorized sets of density at most $\tau_p$, and correctness for  authorized sets of density at least $\tau_c$, for any given arbitrarily close constants $\tau_p&lt;\tau_c$. Reconstruction can be computed by making at most $O(n)$ additions and, in addition, (1) the share size is constant, (2) the sharing procedure also makes only $O(n)$ additions, and (3) the scheme is a blackbox secret-sharing scheme, i.e., the sharing and reconstruction algorithms work universally for all finite abelian groups $F$. Prior to our work, no such scheme was known even without features (1)--(3) and even for the ramp setting where $\tau_p$ and $\tau_c$ are far apart. As a by-product, we derive the first blackbox near-threshold secret-sharing scheme with linear-time sharing. We also present several concrete instantiations of our approach that seem practically efficient (e.g., for threshold discrete-log-based signatures).

Our constructions are combinatorial in nature. We combine graph-based erasure codes that support ``peeling-based&#39;&#39; decoding with a new randomness extraction method that is based on inner-product with a small-integer vector. We also introduce a general concatenation-like transform for secret-sharing schemes that allows us to arbitrarily shrink the privacy-correctness gap with a minor overhead. Our techniques enrich the secret-sharing toolbox and, in the context of blackbox secret sharing, provide a new alternative to existing number-theoretic approaches.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Threshold cryptography is typically based on the idea of secret-sharing a private-key $s\in F$ ``in the exponent&#39;&#39; of some cryptographic group $G$, or more generally, encoding $s$ in some linearly homomorphic domain. In each invocation of the threshold system (e.g., for signing or decrypting) an ``encoding&#39;&#39; of the secret is being recovered and so the complexity, measured as the number of group multiplications over $G$, is equal to the number of $F$-additions that are needed to reconstruct the secret. Motivated by this scenario, we initiate the study of $n$-party secret-sharing schemes whose reconstruction algorithm makes a minimal number of \emph{additions}. The complexity of existing schemes either scales linearly with $n\log |F|$ (e.g., Shamir, CACM&#39;79) or, at least, quadratically with $n$ independently of the size of the domain $F$ (e.g., Cramer-Xing, EUROCRYPT &#39;20). This leaves open the existence of a secret sharing whose recovery algorithm can be computed by performing only $O(n)$ additions.

We resolve the question in the affirmative and present such a near-threshold secret sharing scheme that provides privacy against unauthorized sets of density at most $\tau_p$, and correctness for  authorized sets of density at least $\tau_c$, for any given arbitrarily close constants $\tau_p&lt;\tau_c$. Reconstruction can be computed by making at most $O(n)$ additions and, in addition, (1) the share size is constant, (2) the sharing procedure also makes only $O(n)$ additions, and (3) the scheme is a blackbox secret-sharing scheme, i.e., the sharing and reconstruction algorithms work universally for all finite abelian groups $F$. Prior to our work, no such scheme was known even without features (1)--(3) and even for the ramp setting where $\tau_p$ and $\tau_c$ are far apart. As a by-product, we derive the first blackbox near-threshold secret-sharing scheme with linear-time sharing. We also present several concrete instantiations of our approach that seem practically efficient (e.g., for threshold discrete-log-based signatures).

Our constructions are combinatorial in nature. We combine graph-based erasure codes that support ``peeling-based&#39;&#39; decoding with a new randomness extraction method that is based on inner-product with a small-integer vector. We also introduce a general concatenation-like transform for secret-sharing schemes that allows us to arbitrarily shrink the privacy-correctness gap with a minor overhead. Our techniques enrich the secret-sharing toolbox and, in the context of blackbox secret sharing, provide a new alternative to existing number-theoretic approaches.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T13:12:55Z">Friday, June 09 2023, 13:12</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/'>The asymptotics of r(4,t)</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Originally posted on Points And Lines: <br>Jacques Verstraete and I posted a preprint on the arXiv today on the off-diagonal Ramsey number . In short, we show that , which is just a factor shy from the upper bound proved&#8230;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <div class="wpcom-reblog-snapshot"><div class="reblogger-note"><div class='reblogger-note-content'><blockquote><p><a href="https://sammattheus.wordpress.com/"><img loading="lazy" class="alignnone size-full wp-image-24567" src="https://gilkalai.files.wordpress.com/2023/06/pal.png" alt="pal" width="955" height="323" srcset="https://gilkalai.files.wordpress.com/2023/06/pal.png 955w, https://gilkalai.files.wordpress.com/2023/06/pal.png?w=150&amp;h=51 150w, https://gilkalai.files.wordpress.com/2023/06/pal.png?w=300&amp;h=101 300w, https://gilkalai.files.wordpress.com/2023/06/pal.png?w=768&amp;h=260 768w" sizes="(max-width: 955px) 100vw, 955px" /></a></p>
<p><!-- wp:paragraph --></p>
<p>Sam Mattheus wrote on his blog &#8220;Points and Lines&#8221; a summary with a general overview of the proof for his breakthrough with Jacques Verstraete about <img src="https://s0.wp.com/latex.php?latex=r%284%2Ct%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r(4,t)" class="latex" />. </p>
<p><!-- /wp:paragraph --></p>
</blockquote></div></div><div class="reblog-post"><p class="reblog-from"><img alt='' src='https://1.gravatar.com/avatar/46f67c6ee65d82a59f10b8438d0bdfb7676121b31aff9968cd1dfff4b11acaf7?s=32&#038;d=identicon&#038;r=PG' class='avatar avatar-32' height='32' width='32' /><a href="https://sammattheus.wordpress.com/2023/06/07/the-asymptotics-of-r4t/">Points And Lines</a></p><div class="reblogged-content">
<p></p>

<p>Jacques Verstraete and I posted a <a href="https://arxiv.org/abs/2306.04007">preprint</a> on the arXiv today on the off-diagonal Ramsey number $latex r(4,t)$. In short, we show that $latex r(4,t) = Omega(t^3/log^4t)$, which is just a $latex log^2t$ factor shy from the upper bound $latex r(4,t) = O (t^3/log^2t)$ proved by Ajtai, Komlós and Szemerédi in 1980. Erdős [1] conjectured that up to logarithmic factors, $latex t^3$ is the order of growth:</p>

<p></p>

<p></p>

<p class="has-text-align-center"><img class="wp-image-1130" style="width: 600px" src="https://gilkalai.files.wordpress.com/2023/06/erdos-prize-r4t.png"></p>

<p></p>

<p></p>

<p>We thus confirm this conjecture. The previous best lower bound was due to Bohman and Keevash who studied the random $latex K_4$-free process and obtained $latex r(4,t) = widetilde{Omega}(t^{5/2})$, where the tilde hides logarithmic factors. It is not clear whether our methods can be pushed further to obtain asymptotically sharp bounds. In any case, that’s not what I want to speculate about, but rather sketch the proof of our result. It’s in my very biased opinion a nice combination of ideas that existed…</p>
</div><p class="reblog-source"><a href="https://sammattheus.wordpress.com/2023/06/07/the-asymptotics-of-r4t/">View original post</a> <span class="more-words">1,481 more words</span></p></div></div><p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T06:17:30Z">Friday, June 09 2023, 06:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04731'>Free Fermion Distributions Are Hard to Learn</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Nietner</p><p>Free fermions are some of the best studied quantum systems. However, little
is known about the complexity of learning free-fermion distributions. In this
work we establish the hardness of this task in the particle number
non-preserving case. In particular, we give an information theoretical hardness
result for the general task of learning from expectation values and, in the
more general case when the algorithm is given access to samples, we give a
computational hardness result based on the LPN assumption for learning the
probability density function.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Nietner_A/0/1/0/all/0/1">Alexander Nietner</a></p><p>Free fermions are some of the best studied quantum systems. However, little
is known about the complexity of learning free-fermion distributions. In this
work we establish the hardness of this task in the particle number
non-preserving case. In particular, we give an information theoretical hardness
result for the general task of learning from expectation values and, in the
more general case when the algorithm is given access to samples, we give a
computational hardness result based on the LPN assumption for learning the
probability density function.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04843'>Classical Verification of Quantum Learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Matthias C. Caro, Marcel Hinsche, Marios Ioannou, Alexander Nietner, Ryan Sweke</p><p>Quantum data access and quantum processing can make certain classically
intractable learning tasks feasible. However, quantum capabilities will only be
available to a select few in the near future. Thus, reliable schemes that allow
classical clients to delegate learning to untrusted quantum servers are
required to facilitate widespread access to quantum learning advantages.
Building on a recently introduced framework of interactive proof systems for
classical machine learning, we develop a framework for classical verification
of quantum learning. We exhibit learning problems that a classical learner
cannot efficiently solve on their own, but that they can efficiently and
reliably solve when interacting with an untrusted quantum prover. Concretely,
we consider the problems of agnostic learning parities and Fourier-sparse
functions with respect to distributions with uniform input marginal. We propose
a new quantum data access model that we call "mixture-of-superpositions"
quantum examples, based on which we give efficient quantum learning algorithms
for these tasks. Moreover, we prove that agnostic quantum parity and
Fourier-sparse learning can be efficiently verified by a classical verifier
with only random example or statistical query access. Finally, we showcase two
general scenarios in learning and verification in which quantum
mixture-of-superpositions examples do not lead to sample complexity
improvements over classical data. Our results demonstrate that the potential
power of quantum data for learning tasks, while not unlimited, can be utilized
by classical agents through interaction with untrusted quantum entities.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Caro_M/0/1/0/all/0/1">Matthias C. Caro</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hinsche_M/0/1/0/all/0/1">Marcel Hinsche</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ioannou_M/0/1/0/all/0/1">Marios Ioannou</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nietner_A/0/1/0/all/0/1">Alexander Nietner</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sweke_R/0/1/0/all/0/1">Ryan Sweke</a></p><p>Quantum data access and quantum processing can make certain classically
intractable learning tasks feasible. However, quantum capabilities will only be
available to a select few in the near future. Thus, reliable schemes that allow
classical clients to delegate learning to untrusted quantum servers are
required to facilitate widespread access to quantum learning advantages.
Building on a recently introduced framework of interactive proof systems for
classical machine learning, we develop a framework for classical verification
of quantum learning. We exhibit learning problems that a classical learner
cannot efficiently solve on their own, but that they can efficiently and
reliably solve when interacting with an untrusted quantum prover. Concretely,
we consider the problems of agnostic learning parities and Fourier-sparse
functions with respect to distributions with uniform input marginal. We propose
a new quantum data access model that we call "mixture-of-superpositions"
quantum examples, based on which we give efficient quantum learning algorithms
for these tasks. Moreover, we prove that agnostic quantum parity and
Fourier-sparse learning can be efficiently verified by a classical verifier
with only random example or statistical query access. Finally, we showcase two
general scenarios in learning and verification in which quantum
mixture-of-superpositions examples do not lead to sample complexity
improvements over classical data. Our results demonstrate that the potential
power of quantum data for learning tasks, while not unlimited, can be utilized
by classical agents through interaction with untrusted quantum entities.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05253'>Quantum computing algorithms for inverse problems on graphs and an NP-complete inverse problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Joonas Ilmavirta, Matti Lassas, Jinpeng Lu, Lauri Oksanen, Lauri Ylinen</p><p>We consider an inverse problem for a finite graph $(X,E)$ where we are given
a subset of vertices $B\subset X$ and the distances $d_{(X,E)}(b_1,b_2)$ of all
vertices $b_1,b_2\in B$. The distance of points $x_1,x_2\in X$ is defined as
the minimal number of edges needed to connect two vertices, so all edges have
length 1. The inverse problem is a discrete version of the boundary rigidity
problem in Riemannian geometry or the inverse travel time problem in
geophysics. We will show that this problem has unique solution under certain
conditions and develop quantum computing methods to solve it. We prove the
following uniqueness result: when $(X,E)$ is a tree and $B$ is the set of
leaves of the tree, the graph $(X,E)$ can be uniquely determined in the class
of all graphs having a fixed number of vertices. We present a quantum computing
algorithm which produces a graph $(X,E)$, or one of those, which has a given
number of vertices and the required distances between vertices in $B$. To this
end we develop an algorithm that takes in a qubit representation of a graph and
combine it with Grover's search algorithm. The algorithm can be implemented
using only $O(|X|^2)$ qubits, the same order as the number of elements in the
adjacency matrix of $(X,E)$. It also has a quadratic improvement in
computational cost compared to standard classical algorithms. Finally, we
consider applications in theory of computation, and show that a slight
modification of the above inverse problem is NP-complete: all NP-problems can
be reduced to a discrete inverse problem we consider.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Ilmavirta_J/0/1/0/all/0/1">Joonas Ilmavirta</a>, <a href="http://arxiv.org/find/math/1/au:+Lassas_M/0/1/0/all/0/1">Matti Lassas</a>, <a href="http://arxiv.org/find/math/1/au:+Lu_J/0/1/0/all/0/1">Jinpeng Lu</a>, <a href="http://arxiv.org/find/math/1/au:+Oksanen_L/0/1/0/all/0/1">Lauri Oksanen</a>, <a href="http://arxiv.org/find/math/1/au:+Ylinen_L/0/1/0/all/0/1">Lauri Ylinen</a></p><p>We consider an inverse problem for a finite graph $(X,E)$ where we are given
a subset of vertices $B\subset X$ and the distances $d_{(X,E)}(b_1,b_2)$ of all
vertices $b_1,b_2\in B$. The distance of points $x_1,x_2\in X$ is defined as
the minimal number of edges needed to connect two vertices, so all edges have
length 1. The inverse problem is a discrete version of the boundary rigidity
problem in Riemannian geometry or the inverse travel time problem in
geophysics. We will show that this problem has unique solution under certain
conditions and develop quantum computing methods to solve it. We prove the
following uniqueness result: when $(X,E)$ is a tree and $B$ is the set of
leaves of the tree, the graph $(X,E)$ can be uniquely determined in the class
of all graphs having a fixed number of vertices. We present a quantum computing
algorithm which produces a graph $(X,E)$, or one of those, which has a given
number of vertices and the required distances between vertices in $B$. To this
end we develop an algorithm that takes in a qubit representation of a graph and
combine it with Grover's search algorithm. The algorithm can be implemented
using only $O(|X|^2)$ qubits, the same order as the number of elements in the
adjacency matrix of $(X,E)$. It also has a quadratic improvement in
computational cost compared to standard classical algorithms. Finally, we
consider applications in theory of computation, and show that a slight
modification of the above inverse problem is NP-complete: all NP-problems can
be reduced to a discrete inverse problem we consider.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04858'>Scenic Routes with Weighted Points in 2D</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vijayraj Shanmugaraj, Lini Thomas, Kamalakar Karlapalem</p><p>In a given 2D space, we can have points with different levels of importance.
One would prefer viewing those points from a closer/farther position per their
level of importance. A point in 2D from where the user can view two given
points per his/her preference of distance is termed a scenic point. We develop
the concept of scenic paths in a 2D space for two points that have weights
associated with them. Subsequently, we propose algorithms to generate scenic
routes a traveler can take, which cater to certain principles which define the
scenic routes. Following are the contributions of this paper: (1) mathematical
formulation of a scenic point, (2) introduction of scenic routes formed by such
scenic points in two-class point configurations in 2D spaces, and (3) design of
scenic route generation algorithms that fulfill certain defined requirements.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Shanmugaraj_V/0/1/0/all/0/1">Vijayraj Shanmugaraj</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_L/0/1/0/all/0/1">Lini Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlapalem_K/0/1/0/all/0/1">Kamalakar Karlapalem</a></p><p>In a given 2D space, we can have points with different levels of importance.
One would prefer viewing those points from a closer/farther position per their
level of importance. A point in 2D from where the user can view two given
points per his/her preference of distance is termed a scenic point. We develop
the concept of scenic paths in a 2D space for two points that have weights
associated with them. Subsequently, we propose algorithms to generate scenic
routes a traveler can take, which cater to certain principles which define the
scenic routes. Following are the contributions of this paper: (1) mathematical
formulation of a scenic point, (2) introduction of scenic routes formed by such
scenic points in two-class point configurations in 2D spaces, and (3) design of
scenic route generation algorithms that fulfill certain defined requirements.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04953'>Scenic Routes over Points in 2D Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Loay Rashid, Lini Thomas, Kamalakar Karlapalem</p><p>Consider a 2D coordinate space with a set of red and a set of blue points. We
define a scenic point as a point that is equidistant to a red point and a blue
point. The set of contiguous scenic points form a scenic path. The
perpendicular bisectors to the line joining a red point and a blue point forms
a scenic path between the red point and the blue point. A scenic route is a
traversal made from scenic paths. In this paper, we address this novel problem
by (i) designing algorithms for scenic route generation, (ii) studying the
algorithms different properties and (iii) analyzing the routes generated by
these algorithms. Scenic routes have applications in geo-spatial visualizations
and visual analytics.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rashid_L/0/1/0/all/0/1">Loay Rashid</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_L/0/1/0/all/0/1">Lini Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlapalem_K/0/1/0/all/0/1">Kamalakar Karlapalem</a></p><p>Consider a 2D coordinate space with a set of red and a set of blue points. We
define a scenic point as a point that is equidistant to a red point and a blue
point. The set of contiguous scenic points form a scenic path. The
perpendicular bisectors to the line joining a red point and a blue point forms
a scenic path between the red point and the blue point. A scenic route is a
traversal made from scenic paths. In this paper, we address this novel problem
by (i) designing algorithms for scenic route generation, (ii) studying the
algorithms different properties and (iii) analyzing the routes generated by
these algorithms. Scenic routes have applications in geo-spatial visualizations
and visual analytics.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04850'>Longest Common Prefix Arrays for Succinct k-Spectra</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jarno N. Alanko, Elena Biagi, Simon J. Puglisi</p><p>The k-spectrum of a string is the set of all distinct substrings of length k
occurring in the string. K-spectra have many applications in bioinformatics
including pseudoalignment and genome assembly. The Spectral Burrows-Wheeler
Transform (SBWT) has been recently introduced as an algorithmic tool to
efficiently represent and query these objects. The longest common prefix (LCP)
array for a k-spectrum is an array of length n that stores the length of the
longest common prefix of adjacent k-mers as they occur in lexicographical
order. The LCP array has at least two important applications, namely to
accelerate pseudoalignment algorithms using the SBWT and to allow simulation of
variable-order de Bruijn graphs within the SBWT framework. In this paper we
explore algorithms to compute the LCP array efficiently from the SBWT
representation of the k-spectrum. Starting with a straightforward O(nk) time
algorithm, we describe algorithms that are efficient in both theory and
practice. We show that the LCP array can be computed in optimal O(n) time,
where n is the length of the SBWT of the spectrum. In practical genomics
scenarios, we show that this theoretically optimal algorithm is indeed
practical, but is often outperformed on smaller values of k by an
asymptotically suboptimal algorithm that interacts better with the CPU cache.
Our algorithms share some features with both classical Burrows-Wheeler
inversion algorithms and LCP array construction algorithms for suffix arrays.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alanko_J/0/1/0/all/0/1">Jarno N. Alanko</a>, <a href="http://arxiv.org/find/cs/1/au:+Biagi_E/0/1/0/all/0/1">Elena Biagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Puglisi_S/0/1/0/all/0/1">Simon J. Puglisi</a></p><p>The k-spectrum of a string is the set of all distinct substrings of length k
occurring in the string. K-spectra have many applications in bioinformatics
including pseudoalignment and genome assembly. The Spectral Burrows-Wheeler
Transform (SBWT) has been recently introduced as an algorithmic tool to
efficiently represent and query these objects. The longest common prefix (LCP)
array for a k-spectrum is an array of length n that stores the length of the
longest common prefix of adjacent k-mers as they occur in lexicographical
order. The LCP array has at least two important applications, namely to
accelerate pseudoalignment algorithms using the SBWT and to allow simulation of
variable-order de Bruijn graphs within the SBWT framework. In this paper we
explore algorithms to compute the LCP array efficiently from the SBWT
representation of the k-spectrum. Starting with a straightforward O(nk) time
algorithm, we describe algorithms that are efficient in both theory and
practice. We show that the LCP array can be computed in optimal O(n) time,
where n is the length of the SBWT of the spectrum. In practical genomics
scenarios, we show that this theoretically optimal algorithm is indeed
practical, but is often outperformed on smaller values of k by an
asymptotically suboptimal algorithm that interacts better with the CPU cache.
Our algorithms share some features with both classical Burrows-Wheeler
inversion algorithms and LCP array construction algorithms for suffix arrays.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04884'>Faster Approximation Algorithms for Parameterized Graph Clustering and Edge Labeling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vedangi Bengali, Nate Veldt</p><p>Graph clustering is a fundamental task in network analysis where the goal is
to detect sets of nodes that are well-connected to each other but sparsely
connected to the rest of the graph. We present faster approximation algorithms
for an NP-hard parameterized clustering framework called LambdaCC, which is
governed by a tunable resolution parameter and generalizes many other
clustering objectives such as modularity, sparsest cut, and cluster deletion.
Previous LambdaCC algorithms are either heuristics with no approximation
guarantees, or computationally expensive approximation algorithms. We provide
fast new approximation algorithms that can be made purely combinatorial. These
rely on a new parameterized edge labeling problem we introduce that generalizes
previous edge labeling problems that are based on the principle of strong
triadic closure and are of independent interest in social network analysis. Our
methods are orders of magnitude more scalable than previous approximation
algorithms and our lower bounds allow us to obtain a posteriori approximation
guarantees for previous heuristics that have no approximation guarantees of
their own.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bengali_V/0/1/0/all/0/1">Vedangi Bengali</a>, <a href="http://arxiv.org/find/cs/1/au:+Veldt_N/0/1/0/all/0/1">Nate Veldt</a></p><p>Graph clustering is a fundamental task in network analysis where the goal is
to detect sets of nodes that are well-connected to each other but sparsely
connected to the rest of the graph. We present faster approximation algorithms
for an NP-hard parameterized clustering framework called LambdaCC, which is
governed by a tunable resolution parameter and generalizes many other
clustering objectives such as modularity, sparsest cut, and cluster deletion.
Previous LambdaCC algorithms are either heuristics with no approximation
guarantees, or computationally expensive approximation algorithms. We provide
fast new approximation algorithms that can be made purely combinatorial. These
rely on a new parameterized edge labeling problem we introduce that generalizes
previous edge labeling problems that are based on the principle of strong
triadic closure and are of independent interest in social network analysis. Our
methods are orders of magnitude more scalable than previous approximation
algorithms and our lower bounds allow us to obtain a posteriori approximation
guarantees for previous heuristics that have no approximation guarantees of
their own.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04902'>A Cover Time Study of a non-Markovian Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guanhua Fang, Gennady Samorodnitsky, Zhiqiang Xu</p><p>Given a traversal algorithm, cover time is the expected number of steps
needed to visit all nodes in a given graph. A smaller cover time means a higher
exploration efficiency of traversal algorithm. Although random walk algorithms
have been studied extensively in the existing literature, there has been no
cover time result for any non-Markovian method. In this work, we stand on a
theoretical perspective and show that the negative feedback strategy (a
count-based exploration method) is better than the naive random walk search. In
particular, the former strategy can locally improve the search efficiency for
an arbitrary graph. It also achieves smaller cover times for special but
important graphs, including clique graphs, tree graphs, etc. Moreover, we make
connections between our results and reinforcement learning literature to give
new insights on why classical UCB and MCTS algorithms are so useful. Various
numerical results corroborate our theoretical findings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fang_G/0/1/0/all/0/1">Guanhua Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Samorodnitsky_G/0/1/0/all/0/1">Gennady Samorodnitsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhiqiang Xu</a></p><p>Given a traversal algorithm, cover time is the expected number of steps
needed to visit all nodes in a given graph. A smaller cover time means a higher
exploration efficiency of traversal algorithm. Although random walk algorithms
have been studied extensively in the existing literature, there has been no
cover time result for any non-Markovian method. In this work, we stand on a
theoretical perspective and show that the negative feedback strategy (a
count-based exploration method) is better than the naive random walk search. In
particular, the former strategy can locally improve the search efficiency for
an arbitrary graph. It also achieves smaller cover times for special but
important graphs, including clique graphs, tree graphs, etc. Moreover, we make
connections between our results and reinforcement learning literature to give
new insights on why classical UCB and MCTS algorithms are so useful. Various
numerical results corroborate our theoretical findings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05243'>Analysis of Knuth's Sampling Algorithm D and D'</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mridul Nandi, Soumit Paul</p><p>In this research paper, we address the Distinct Elements estimation problem
in the context of streaming algorithms. The problem involves estimating the
number of distinct elements in a given data stream $\mathcal{A} = (a_1,
a_2,\ldots, a_m)$, where $a_i \in \{1, 2, \ldots, n\}$. Over the past four
decades, the Distinct Elements problem has received considerable attention,
theoretically and empirically, leading to the development of space-optimal
algorithms. A recent sampling-based algorithm proposed by Chakraborty et
al.[11] has garnered significant interest and has even attracted the attention
of renowned computer scientist Donald E. Knuth, who wrote an article on the
same topic [6] and called the algorithm CVM. In this paper, we thoroughly
examine the algorithms (referred to as CVM1, CVM2 in [6] and DonD, DonD' in
[6]. We first unify all these algorithms and call them cutoff-based algorithms.
Then we provide an approximation and biasedness analysis of these algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nandi_M/0/1/0/all/0/1">Mridul Nandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1">Soumit Paul</a></p><p>In this research paper, we address the Distinct Elements estimation problem
in the context of streaming algorithms. The problem involves estimating the
number of distinct elements in a given data stream $\mathcal{A} = (a_1,
a_2,\ldots, a_m)$, where $a_i \in \{1, 2, \ldots, n\}$. Over the past four
decades, the Distinct Elements problem has received considerable attention,
theoretically and empirically, leading to the development of space-optimal
algorithms. A recent sampling-based algorithm proposed by Chakraborty et
al.[11] has garnered significant interest and has even attracted the attention
of renowned computer scientist Donald E. Knuth, who wrote an article on the
same topic [6] and called the algorithm CVM. In this paper, we thoroughly
examine the algorithms (referred to as CVM1, CVM2 in [6] and DonD, DonD' in
[6]. We first unify all these algorithms and call them cutoff-based algorithms.
Then we provide an approximation and biasedness analysis of these algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, June 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/'>Human Extinction?</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          And some counter-arguments Hava Siegelmann is the Provost Professor in the Manning College of Information and Computer Sciences at U.Mass. Amherst. She returned in 2019 from serving as a DARPA Program Director. Her work at DARPA included leading two AI initiatives: L2M for &#8220;Lifelong Learning Machines&#8221; and GARD for &#8220;Guaranteeing AI Robustness against Deception.&#8221; Today [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><span style="color: #0044cc;"><br />
<em>And some counter-arguments</em><br />
</span></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/dr-hava-siegelmann/" rel="attachment wp-att-21728"><img data-attachment-id="21728" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/dr-hava-siegelmann/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Dr_Hava_Siegelmann.jpg?fit=400%2C500&amp;ssl=1" data-orig-size="400,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Dr. Hava Siegelmann&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Dr. Hava Siegelmann (PRNewsfoto\/Dr. Hava Siegelmann)&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;This image must be used within the context of the news release it accompanied. Request permission from issuer for other uses.&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Dr Hava Siegelmann&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Dr_Hava_Siegelmann.jpg?fit=240%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Dr_Hava_Siegelmann.jpg?fit=400%2C500&amp;ssl=1" decoding="async" loading="lazy" class="alignright wp-image-21728" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Dr_Hava_Siegelmann.jpg?resize=120%2C150&#038;ssl=1" alt="" width="120" height="150" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Dr_Hava_Siegelmann.jpg?w=400&amp;ssl=1 400w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Dr_Hava_Siegelmann.jpg?resize=240%2C300&amp;ssl=1 240w" sizes="(max-width: 120px) 100vw, 120px" data-recalc-dims="1" /></a></p>
<p>
Hava Siegelmann is the Provost Professor in the Manning College of Information and Computer Sciences at U.Mass. Amherst. She returned in 2019 from serving as a DARPA Program Director. Her work at DARPA included leading two AI initiatives: <a href="https://www.darpa.mil/news-events/2017-03-16">L2M</a> for &#8220;Lifelong Learning Machines&#8221; and <a href="https://www.darpa.mil/program/guaranteeing-ai-robustness-against-deception">GARD</a> for &#8220;Guaranteeing AI Robustness against Deception.&#8221;</p>
<p>
Today we discuss whether we need measures to guarantee human robustness against AI.<br />
<span id="more-21725"></span></p>
<p>
Siegelmann was <a href="https://federalnewsnetwork.com/artificial-intelligence/2020/06/darpa-honors-artificial-intelligence-expert/">awarded</a> the Meritorious Public Service Medal, a rare high honor from the US Department of Defense. Her dean at U.Mass., Laura Haas, stated in a <a href="https://www.prnewswire.com/news-releases/darpa-recognizes-umass-professor-hava-siegelmann-for-major-advances-in-ai-301081766.html">release</a>, &#8220;I am extremely proud of Hava&#8217;s service to DARPA and the nation. Her work at DARPA has helped to advance AI for us all.&#8221; </p>
<p>
One thing that catches our interest, in line with another recent <a href="https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/">post</a>, is that her applied work jumped off from a mainstream topic in theory. Well, one maybe seen as off the mainstream: that of &#8220;super-Turing&#8221; machines. Let&#8217;s discuss that first before coming to AI.</p>
<p><H2> Super-Turing </H2></p>
<p><p>
We who work in polynomial-based complexity often feel that undecidable languages and other aspects of recursion theory are walled off in a different area of theory. Part of the shock of the <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BMIP%5E%2A+%3D+RE%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{MIP^* = RE}}" class="latex" /> <a href="https://arxiv.org/abs/2001.04383">result</a> was breaking down this wall. See this great <a href="https://quantumfrontiers.com/2020/03/01/the-shape-of-mip-re/">post</a> by coauthor Henry Yuen for more aspects.</p>
<p>
The same feeling goes even more for <a href="https://en.wikipedia.org/wiki/Hypercomputation">hypercomputing</a> models, defined as able to compute functions that are not Turing-computable. Our own <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BMIP%5E%2A+%3D+RE%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{MIP^* = RE}}" class="latex" /> <a href="https://rjlipton.wpcomstaging.com/2020/01/15/halting-is-poly-time-quantum-provable/">post</a> includes a story of how David Deutsch in the mid-1980s originally believed that quantum computers could solve the Halting Problem in finite time. </p>
<p>
Yet many of us have done real work with a hypercomputing model so broad that it can recognize uncountably many languages. The model&#8217;s subtle power arguably poses the most trenchant <a href="http://theory.stanford.edu/~liyang/teaching/projects/natural-proofs-barrier-and-P-NP.pdf">barrier</a> to proving <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{P &#92;neq NP}}" class="latex" />. We refer, of course, to the model of <em>nonuniform</em> polynomial-size circuit families and its associated complexity class, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%2Fpoly%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{P/poly}}" class="latex" />. </p>
<p>
Indeed, poly-size circuits are the basis of Siegelmann&#8217;s celebrated 1995 <a href="https://binds.cs.umass.edu/papers/1995_Siegelmann_Science.pdf">paper</a> in <em>Science</em> titled &#8220;Computation beyond the Turing Limit&#8221;&#8212;and a full 1996 <a href="https://www.sciencedirect.com/science/article/pii/S0304397596000874?ref=pdf_download&#038;fr=RR-2&#038;rr=7d3d858de9933344">followup</a> in <em>Theoretical Computer Science</em> titled &#8220;the simple dynamics of super Turing theories.&#8221; One point is that individual circuits are finite objects that can be manipulated&#8212;as likewise are finite neural networks. The analog recurrent neural networks (ARNNs) used by Siegelmann are allowed real-number coefficients. They in turn are related to a class of dynamical systems with simply-specified rules built around <em>analog shift</em> (AS) maps that obey a finite-dependence or finite-effect condition. These models define complexity classes <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BARNN%7D%5Bs%28n%29%5D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{ARNN}[s(n)]}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BAS%7D%5Bs%28n%29%5D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{AS}[s(n)]}" class="latex" /> in the same manner as when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bs%28n%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{s(n)}" class="latex" /> means Boolean circuit size. The main theorem is:</p>
<p>
<blockquote><p><b>Theorem 1</b> <em> For any function <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bs%28n%29+%5Cgeq+n%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{s(n) &#92;geq n}" class="latex" />, we have <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BARNN%7D%5Bs%28n%29%5D+%5Csubseteq+%5Cmathsf%7BAS%7D%5Bs%28n%29%5E%7BO%281%29%7D%5D%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{ARNN}[s(n)] &#92;subseteq &#92;mathsf{AS}[s(n)^{O(1)}]}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BAS%7D%5Bs%28n%29%5D+%5Csubseteq+%5Cmathsf%7BARNN%7D%5Bs%28n%29%5E%7BO%281%29%7D%5D%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{AS}[s(n)] &#92;subseteq &#92;mathsf{ARNN}[s(n)^{O(1)}]}" class="latex" />. In particular, say restricted to languages over a binary alphabet, </em></p>
<p align="center"><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathsf%7BARNN%7D%5Bn%5E%7BO%281%29%7D%5D+%3D+%5Cmathsf%7BAS%7D%5Bn%5E%7BO%281%29%7D%5D+%3D+%5Cmathsf%7BP%2Fpoly%7D.+&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle &#92;mathsf{ARNN}[n^{O(1)}] = &#92;mathsf{AS}[n^{O(1)}] = &#92;mathsf{P/poly}. " class="latex" /></p>
<p>&nbsp;</p></blockquote>
<p>
A 2013 blog <a href="https://www.georgezarkadakis.com/super-turing-machines-and-oracles-the-making-of-a-artificial-mind/">post</a> by George Zarkadakis picks up the thread of how this correspondence fosters the notion of machines that learn by continual adaptation: the &#8220;lifelong learning machines.&#8221; What Siegelmann accomplished with her further work culminating at DARPA was demonstrate that these &#8220;super-Turing&#8221; ideas can be rendered into real applications.</p>
<p>
<p><H2> The View From Inside </H2></p>
<p><p>
The June 2020 PR Newswire item on Siegelmann&#8217;s award has some passages on applications that were at least inspired by her mode of approach (we&#8217;ve added bullets for clarity):</p>
<blockquote><p><b> </b> <em> DARPA points out Siegelmann&#8217;s &#8216;exceptionally productive&#8217; term included </p>
<ul>
<li>
developing a system that intelligently administers insulin and dextrose to maintain safe glucose levels for diabetics and critical care patients; </p>
<li>
sensors to identify dangerous chemicals from a safe distance; </p>
<li>
collaborative, secure learning platforms that allow unaffiliated groups to work synergistically without revealing sensitive data; and </p>
<li>
reverse engineering methods to identify cyber-attacks, secure the system, and find the attacker.
</ul>
<p></em>
</p></blockquote>
<p><p>
And this about Machine Learning (ML):</p>
<blockquote><p><b> </b> <em> Illustrating the difference between current AI and new L2M systems, Siegelmann stated, &#8220;Self-driving cars represent a pinnacle in state-of-the-art computation&#8212;demonstrating how far current technology can take us using increasingly clever programming. However, even these systems fail when encountering circumstances outside their training&#8230;&#8221; [Whereas], L2M systems represent &#8220;a fundamental change in ML,&#8221; she said, &#8220;L2M systems learn; they apply experience and adapt to new situations; instead of failing, they become better, the more they experience.&#8221; </em>
</p></blockquote>
<p><p>
And this: </p>
<blockquote><p><b> </b> <em> &#8220;We made real progress, demonstrated actual learning – something never done before &#8230; L2M improvements are already being incorporated into real-world systems; in five years, AI systems will be mainly of the L2M variety or incorporate L2M components. But it is very hard,&#8221; she adds, &#8220;for a machine to learn actively and there is still much to be done.&#8221; </em>
</p></blockquote>
<p><p>
Note that &#8220;in five years&#8221; meant by <b>2025</b>. We are over halfway there, and the headline-making <a href="https://en.wikipedia.org/wiki/ChatGPT">ChatGPT</a>, <a href="https://en.wikipedia.org/wiki/DALL-E">DALL-E</a>, and other models happened last year. </p>
<p>
<p><H2> The View From Other Insiders </H2></p>
<p><p>
It does not need much experience of dystopian fiction in book or movie form to imagine sinister plot twists of the above items:</p>
<ul>
<li>
The medical system tasked with inferring safe glucose levels discovers circumstances outside its training that enable it to plant chemical time bombs that can be used to control the patients, which include high government officials&#8230; </p>
<li>
The collaborative platform that admits unaffiliated groups reverse-engineers methods to identify cyber-attackers into ones that admit them, then secures the system to find the original defenders and hunt them down&#8230; </p>
<li>
Self-driving cars equipped with manual override learn that the manual operators are idiots (which we are) and &#8230; we get a remake of Alfred Hitchcock&#8217;s <a href="https://en.wikipedia.org/wiki/The_Birds_(film)">The Birds</a> titled <em>The Cars</em>.
</ul>
<p>
Are we being unfair and far-fetched? Perhaps so in these cases. But here are two &#8220;real-life AI risks&#8221; postulated in a <a href="https://www.tableau.com/data-insights/ai/risks#risks">statement</a> by the AI analytics company <a href="https://www.tableau.com">Tableau</a>:</p>
<blockquote><p><b> </b> <em> If companies rely too much on AI predictions for when maintenance will be done without other checks, it could lead to machinery malfunctions that injure workers. Models used in healthcare could cause misdiagnoses. </em>
</p></blockquote>
<p><p>
And a &#8220;hypothetical risk&#8221;:</p>
<blockquote><p><b> </b> <em> [A]n AI system tasked with &#8230; helping to rebuild an endangered marine creature’s ecosystem [could] decide that other parts of the ecosystem are unimportant and destroy their habitats. And it could also view human intervention to fix or prevent this as a threat to its goal. </em>
</p></blockquote>
<p><p>
Last week, an <a href="https://www.safe.ai/statement-on-ai-risk#open-letter">open letter</a> signed by numerous AI luminaries made a simple statement that went all the way to the risk of <em>human extinction</em>, not just bungling a coral reef:</p>
<blockquote><p><b> </b> <em> Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war. </em>
</p></blockquote>
<p><p>
Dan Hendrycks, director of the Center For AI Safety, stated further in his May 30 Twitter <a href="https://twitter.com/DanHendrycks/status/1663474795865059329">thread</a> releasing the letter:</p>
<blockquote><p><b> </b> <em> &#8220;[T]here are many &#8216;important and urgent risks from AI,&#8217; not just the risk of extinction; for example, systemic bias, misinformation, malicious use, cyberattacks, and weaponization.&#8221; </em>
</p></blockquote>
<p><p>
An accompanying NPR <a href="https://www.npr.org/2023/05/30/1178943163/ai-risk-extinction-chatgpt">story</a> also quotes Geoffrey Hinton, first on the list of the letter&#8217;s <a href="https://www.safe.ai/statement-on-ai-risk#signatories">signatories</a>, to the effect that AI programs are on track to outperform their creators sooner than anyone anticipated:</p>
<blockquote><p><b> </b> <em> &#8220;I thought for a long time that we were, like, 30 to 50 years away from that. &#8230; Now, I think we may be much closer, maybe only five years away from that.&#8221; </em>
</p></blockquote>
<p><p>
That five-year horizon means <b>2028</b>. The second signer is Yoshua Bengio, making two of the three researchers who won the 2018 Turing Award for their research on neural networks. The third, Yann LeCun, who leads Meta&#8217;s AI research efforts, has not signed yet. </p>
<table style="margin: auto;">
<tbody>
<tr>
<td><a href="https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/hintonbengiolecun/" rel="attachment wp-att-21730"><img data-attachment-id="21730" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/hintonbengiolecun/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?fit=999%2C374&amp;ssl=1" data-orig-size="999,374" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="HintonBengioLeCun" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?fit=300%2C112&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?fit=600%2C225&amp;ssl=1" decoding="async" loading="lazy" class="aligncenter wp-image-21730" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?resize=360%2C135&#038;ssl=1" alt="" width="360" height="135" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?w=999&amp;ssl=1 999w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?resize=300%2C112&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?resize=768%2C288&amp;ssl=1 768w" sizes="(max-width: 360px) 100vw, 360px" data-recalc-dims="1" /></a></td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from AI Builders <a href="https://aibuilders.ai/le-prix-turing-recompense-trois-pionniers-de-lintelligence-artificielle-yann-lecun-yoshua-bengio-et-geoffrey-hinton/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
That third slot is appropriately filled by Google DeepMind CEO Demis Hassabis, who along with his university friend and the letter&#8217;s 26th signer, David Silver, gained prominence for developing AlphaGo and AlphaZero. Scott <a href="https://www.scottaaronson.com">Aaronson</a>&#8212;of course a famed complexity and quantum computing leader who is now working within OpenAI on a watermarking scheme for detecting ChatGPT usage&#8212;is a signer. Others whom Ken and I have met include Bill McKibben, Peter Norvig, David Chalmers, Bart Selman, Roman Yampolskiy, and Steve Petersen of Niagara University near Ken.</p>
<p>
<p><H2> Shock und D&uuml;rrenmatt? </H2></p>
<p>CNN&#8217;s <a href="https://www.cnn.com/2023/05/30/media/artificial-intelligence-warning-reliable-sources/index.html">story</a> on the letter is subtitled, &#8220;Are we taking it seriously enough?&#8221; It ends by quoting Duke&#8217;s Cynthia Rudin, a star student of Ingrid Daubechies whom we recently <a href="https://rjlipton.wpcomstaging.com/2023/05/14/ingrid-daubechies-prizes-and-art/">profiled</a>:</p>
<blockquote><p><b> </b> <em> &#8220;Do we really need more evidence that AI’s negative impact could be as big as nuclear war?&#8221; </em>
</p></blockquote>
<p><p>
This calls to mind the upcoming <a href="https://en.wikipedia.org/wiki/Oppenheimer_(film)">movie</a> about J. Robert Oppenheimer and also Friedrich D&uuml;rrenmatt&#8217;s play <a href="https://en.wikipedia.org/wiki/The_Physicists">The Physicists</a>, whose last scenes clash two tag lines:</p>
<blockquote><p><b> </b> <em> &#8220;We must take back our science&#8230;&#8221; &#8212;but&#8212; &#8220;something once thought cannot be unthought.&#8221; </em>
</p></blockquote>
<p><p>
There is also the old book <a href="https://en.wikipedia.org/wiki/Future_Shock">Future Shock</a> by Alvin Toffler, which warns of &#8220;<a href="https://en.wikipedia.org/wiki/Information_overload">information overload</a>&#8221; but maybe not AI peril <em>per se</em>. </p>
<p>
Let us nudge &#8220;Shock&#8221; to the German word <em>Schach</em> meaning &#8220;chess.&#8221; The person who might feel he was most viscerally slapped down by AI is Garry Kasparov, the former world chess champion who famously lost to IBM&#8217;s Deep Blue computer in 1997. However, he had <a href="https://www.themanufacturer.com/articles/garry-kasparov-intelligent-machines/">this</a> to say in 2017:</p>
<blockquote><p><b> </b> <em> &#8220;Machines that replace physical labour have allowed us to focus more on what makes us human: our minds. Intelligent machines will continue that process, taking over the more menial aspects of cognition and elevating our mental lives toward creativity, curiosity, beauty, and joy. These are what truly make us human, not any particular activity or skill, like swinging a hammer – or even playing chess.&#8221; </em>
</p></blockquote>
<p><p>
Marc Andreesen, of early <a href="https://en.wikipedia.org/wiki/Mosaic_(web_browser)">Mosaic</a> and <a href="https://en.wikipedia.org/wiki/Netscape">Netscape</a> fame, posted on Tuesday a long <a href="https://a16z.com/2023/06/06/ai-will-save-the-world/">response</a> to the open letter titled &#8220;Why AI Will Save the World.&#8221; It rebuts four of the stated AI risks:</p>
<ol>
<li>
Will AI Kill Us All? </p>
<li>
Will AI Ruin Our Society? </p>
<li>
Will AI Take All Our Jobs? </p>
<li>
Will AI Lead To Crippling Inequality?
</ol>
<p>
It concedes as a point 5 that AI will empower bad actors to be badder and more quickly thus. But it ends with a point that both of us have also heard at DARPA: the motive of not being surprised and subjugated by something that an adversary develops first. On that basis he advocates &#8220;Pursuing AI With Maximum Force And Speed.&#8221; </p>
<p>
I (Ken writing this part) agree with Kasparov and Andreesen&#8212;with one further caveat that reflects the &#8220;guardrails&#8221; concern of a March <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open letter</a> from the Future of Life institute, but without the six-month &#8220;pause&#8221; it advocates. This is that communications should promote their receivers to exercise <em>scientific skepticism</em>, such as we&#8217;ve tried to do in our <a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/">own</a> <a href="https://rjlipton.wpcomstaging.com/2023/04/01/the-chatgpt-conundrum/">jocular</a> <a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/">posts</a> on (Chat)GPT.</p>
<p>
Perhaps the most evocative word will come from the Oscar-nominated film director Bennett Miller. He has evidently <a href="https://www.worldofreel.com/blog/2023/4/1uzqxkaw0hham43fsyux6u7q2vkrd0">revived</a> a documentary project begun in 2016 about the debate over AI. He also opened a Manhattan <a href="https://hypebeast.com/2023/3/bennett-miller-gagosian-exhibition-new-york-ai">exhibit</a> of his own AI-assisted images. The New York Times included his work in a <a href="https://www.nytimes.com/2023/05/03/arts/design/ai-makes-nostalgic-images.html">roundup</a> of AI used to create art that, curiously, is of itself &#8216;borne back ceaselessly into the past.&#8217;</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
I knew some of the early greats in AI. One was Roger <a href="https://en.wikipedia.org/wiki/Roger_Schank">Schank</a> and was at Yale University when I arrived with my then fresh Ph.D. We have talked about Roger previously <a href="https://rjlipton.wpcomstaging.com/2023/02/05/artificial-intelligence-just-lost-a-leader/">here</a>.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/rs-3/" rel="attachment wp-att-21732"><img data-attachment-id="21732" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/rs-3/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?fit=241%2C241&amp;ssl=1" data-orig-size="241,241" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rs" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?fit=241%2C241&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?fit=241%2C241&amp;ssl=1" decoding="async" loading="lazy" class="aligncenter wp-image-21732" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?resize=150%2C150&#038;ssl=1" alt="" width="150" height="150" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?w=241&amp;ssl=1 241w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1" /></a></p>
<p>
I wonder a bit about what Roger would say today about the potential of AI on human extinction. I think he loved AI, was a great leader in all aspects of AI, but perhaps never saw it with the potential to extinct humans? What do you all think?</p>
<p>
Ken adds that it might be fruitful to seek more understanding of what exactly <em>circuit complexity</em> had to do with all this. He notes a long <a href="https://www.quantamagazine.org/in-new-paradox-black-holes-appear-to-evade-heat-death-20230606/">article</a> in <em>Quanta</em> on Tuesday that highlights the emerging role of circuit complexity in resolving issues of information and black holes. There is a hint of similarity to Siegelmann&#8217;s machine-learning mechanism in how quantum systems are said to evolve to embody greater circuit complexity.</p>
<p><P><br />
[&#8220;knowledge&#8221;->&#8221;science&#8221; in Dürrenmatt quote]</p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T20:38:23Z">Thursday, June 08 2023, 20:38</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/'>Determining Ramsey numbers using finite geometry</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Originally posted on Anurag&#039;s Math Blog: <br>Sam Mattheus and Jacques Verstraete have posted a preprint today where they solve the classic open problem of determining the asymptotics of the Ramsey number . They show that which is just a&#8230;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <div class="wpcom-reblog-snapshot"><div class="reblogger-note"><div class='reblogger-note-content'><blockquote><p>Sam Mattheus and Jacques Verstraete made a remarkable breakthrough for Ramsey numbers <img src="https://s0.wp.com/latex.php?latex=R%284%2Ct%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="R(4,t)" class="latex" />, and Anurag Bishnoi wrote a beautiful blog post about it. Congratulations Sam and Jacques! Mattheus and Verstraete <a href="https://arxiv.org/abs/2306.04007">show that</a> <img src="https://s0.wp.com/latex.php?latex=r%284%2Ct%29+%5Cge+c+%5Cfrac+%7Bt%5E3%7D%7B%5Clog+%5E4+t%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r(4,t) &#092;ge c &#092;frac {t^3}{&#092;log ^4 t}" class="latex" />.</p>
</blockquote></div></div><div class="reblog-post"><p class="reblog-from"><img alt='' src='https://0.gravatar.com/avatar/9b550c7bd755079f79698630b9b84e867941554d901106a5e5428c21cd573092?s=32&#038;d=identicon&#038;r=PG' class='avatar avatar-32' height='32' width='32' /><a href="https://anuragbishnoi.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/">Anurag&#039;s Math Blog</a></p><div class="reblogged-content">
<p></p>

<p><a href="https://sammattheus.wordpress.com/author/sammattheus/">Sam Mattheus</a> and <a href="https://math.ucsd.edu/people/profiles/jacques-verstraete">Jacques Verstraete</a> have posted a <a href="https://arxiv.org/abs/2306.04007">preprint</a> today where they solve the classic open problem of determining the asymptotics of the <a href="https://en.wikipedia.org/wiki/Ramsey%27s_theorem#Ramsey_numbers">Ramsey number</a> $latex r(4, t)$.  They <a href="https://arxiv.org/abs/2306.04007">show that</a></p>

<p></p>

<p></p>

<p class="has-text-align-center">$latex r(4, t) geq c frac{t^3}{log^4 t}$</p>

<p></p>

<p></p>

<p>which is just a factor of $latex log^2 t$ away from the upper bound. The only other off-diagonal Ramsey number for which we knew the correct asymptotics prior to their work was $latex r(3, t)$, and the best lower bounds on $latex r(4, t)$ were $latex c’ t^{5/2}/log^2 t$. These earlier bounds are in fact at the limit of what could be proved using the <a href="https://link.springer.com/article/10.1007/s00222-010-0247-x">random $latex H$-free process</a>. That barrier has finally been broken by using completely different techniques involving <a href="https://en.wikipedia.org/wiki/Finite_geometry">finite geometry</a>! It’s an amazing breakthrough that builds up on the recent developments in Ramsey theory using finite geometry (see <a href="https://anuragbishnoi.wordpress.com/minicourse/">this</a> for an online minicourse I gave in 2021…</p>
</div><p class="reblog-source"><a href="https://anuragbishnoi.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/">View original post</a> <span class="more-words">929 more words</span></p></div></div><p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T19:31:29Z">Thursday, June 08 2023, 19:31</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/086'>TR23-086 |  Random $(\log n)$-CNF are Hard for Cutting Planes (Again) | 

	Dmitry Sokolov</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The random $\Delta$-CNF model is one of the most important distribution over $\Delta\text{-}\mathrm{SAT}$ instances. It is closely connected to various areas of computer science, statistical physics, and is a benchmark for satisfiability algorithms. Fleming, Pankratov, Pitassi, and Robere and independently Hrubes and Pudlak showed that when $\Delta = \Theta(\log n)$, any Cutting Planes proof for random $\Delta$-CNF on $n$ variables requires size $2^{n / \mathrm{polylog} n}$ in the regime where the number of clauses guarantees that the formula is unsatisfiable with high probability. In this paper we show tight lower bound $2^{\Omega(n)}$ on size CP-proofs for random $(\log n)$-CNF formulas. Moreover, our proof is much simpler and self-contained in contrast with previous results based on Jukna&#39;s lower bound for monotone circuits.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The random $\Delta$-CNF model is one of the most important distribution over $\Delta\text{-}\mathrm{SAT}$ instances. It is closely connected to various areas of computer science, statistical physics, and is a benchmark for satisfiability algorithms. Fleming, Pankratov, Pitassi, and Robere and independently Hrubes and Pudlak showed that when $\Delta = \Theta(\log n)$, any Cutting Planes proof for random $\Delta$-CNF on $n$ variables requires size $2^{n / \mathrm{polylog} n}$ in the regime where the number of clauses guarantees that the formula is unsatisfiable with high probability. In this paper we show tight lower bound $2^{\Omega(n)}$ on size CP-proofs for random $(\log n)$-CNF formulas. Moreover, our proof is much simpler and self-contained in contrast with previous results based on Jukna&#39;s lower bound for monotone circuits.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T13:55:09Z">Thursday, June 08 2023, 13:55</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://processalgebra.blogspot.com/2023/06/summer-school-on-formal-methods-for.html'>Summer School on Formal Methods for Cyber-Physical Systems and Workshop on Synthesis, Monitoring and Learning in Udine</a></h3>
        <p class='tr-article-feed'>from <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>The third edition of the UniVr/UniUd Summer School on Formal Methods for Cyber-Physical Systems&nbsp; will be held in Udine, Italy, in the period August 28-31. It will be followed by the Workshop on Synthesis, Monitoring and Learning on August 31 and September 1. The list of contributors to those events is top notch.&nbsp;</p><p>The course is offered in a hybrid format giving the possibility to remotely attend the course (on the Microsoft Teams platform).

On-site places are limited and assigned on first come first served basis.

The registration fees are:&nbsp;</p><ul><li>On-site participation, 250.00 Euro + VAT 22%&nbsp;</li><li>Online participation, 120.00 Euro + VAT 22%&nbsp;</li></ul><p>The deadline for online application is August 18, 2023.
Participation application is available at www.cism.it/en/activities/courses/J2303/&nbsp;</p><p>Spread the news and encourage students and young researchers to attend!
</p><p>By Luca Aceto</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The third edition of the <a href="http://tcs.uniud.it/summer-school" target="_blank">UniVr/UniUd Summer School on Formal Methods for Cyber-Physical Systems</a>&nbsp; will be held in Udine, Italy, in the period August 28-31. It will be followed by the <a href="http://tcs.uniud.it/smile" target="_blank">Workshop on Synthesis, Monitoring and Learning</a> on August 31 and September 1. The list of contributors to those events is top notch.&nbsp;</p><p>The course is offered in a hybrid format giving the possibility to remotely attend the course (on the Microsoft Teams platform).

On-site places are limited and assigned on first come first served basis.

The registration fees are:&nbsp;</p><ul style="text-align: left;"><li>On-site participation, 250.00 Euro + VAT 22%&nbsp;</li><li>Online participation, 120.00 Euro + VAT 22%&nbsp;</li></ul><p>The deadline for online application is August 18, 2023.
Participation application is available at <a href="https://www.cism.it/en/activities/courses/J2303/">https://www.cism.it/en/activities/courses/J2303/</a>&nbsp;</p><p>Spread the news and encourage students and young researchers to attend!
</p><p class="authors">By Luca Aceto</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T09:21:00Z">Thursday, June 08 2023, 09:21</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
