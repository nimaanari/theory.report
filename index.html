<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-03-13T02:30:23Z">Monday, March 13 2023, 02:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, March 13
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05614'>On the Existence of Anomalies, The Reals Case</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samuel Epstein</p><p>The Independence Postulate (IP) is a finitary Church-Turing Thesis, saying
mathematical sequences are independent from physical ones. Modelling
observations as infinite sequences of real numbers, IP implies the existence of
anomalies.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1">Samuel Epstein</a></p><p>The Independence Postulate (IP) is a finitary Church-Turing Thesis, saying
mathematical sequences are independent from physical ones. Modelling
observations as infinite sequences of real numbers, IP implies the existence of
anomalies.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05616'>How to Compress the Solution</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samuel Epstein</p><p>Using derandomization, we provide an upper bound on the compression size of
solutions to the graph coloring problem. In general, if solutions to a
combinatorial problem exist with high probability and the probability is
simple, then there exists a simple solution to the problem. Otherwise the
problem instance has high mutual information with the halting problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1">Samuel Epstein</a></p><p>Using derandomization, we provide an upper bound on the compression size of
solutions to the graph coloring problem. In general, if solutions to a
combinatorial problem exist with high probability and the probability is
simple, then there exists a simple solution to the problem. Otherwise the
problem instance has high mutual information with the halting problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05619'>Uniform Tests and Algorithmic Thermodynamic Entropy</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samuel Epstein</p><p>We prove that given a computable metric space and two computable measures,
the set of points that have high universal uniform test scores with respect to
the first measure will have a lower bound with respect to the second measure.
This result is transferred to thermodynamics, showing that algorithmic
thermodynamic entropy must oscillate in the presence of dynamics. Another
application is that outliers will become emergent in computable dynamics of
computable metric spaces.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1">Samuel Epstein</a></p><p>We prove that given a computable metric space and two computable measures,
the set of points that have high universal uniform test scores with respect to
the first measure will have a lower bound with respect to the second measure.
This result is transferred to thermodynamics, showing that algorithmic
thermodynamic entropy must oscillate in the presence of dynamics. Another
application is that outliers will become emergent in computable dynamics of
computable metric spaces.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05989'>DAG Scheduling in the BSP Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: P&#xe1;l Andr&#xe1;s Papp, Georg Anegg, A. N. Yzelman</p><p>We study the problem of scheduling an arbitrary computational DAG on a fixed
number of processors while minimizing the makespan. While previous works have
mostly studied this problem in relatively restricted models, we define and
analyze DAG scheduling in the Bulk Synchronous Parallel (BSP) model, which is a
well-established parallel computing model that captures the communication cost
between processors much more accurately. We provide a detailed taxonomy of
simpler scheduling models that can be understood as variants or special cases
of BSP, and discuss the properties of the problem and the optimum cost in these
models, and how they differ from BSP. This essentially allows us to dissect the
different building blocks of the BSP model, and gain insight into how each of
these influences the scheduling problem.
</p>
<p>We then analyze the hardness of DAG scheduling in BSP in detail. We show that
the problem is solvable in polynomial time for some very simple classes of
DAGs, but it is already NP-hard for in-trees or DAGs of height 2. We also
separately study the subproblem of scheduling communication steps, and we show
that the NP-hardness of this problem can depend on the problem parameters and
the communication rules within the BSP model. Finally, we present and analyze a
natural formulation of our scheduling task as an Integer Linear Program.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Papp_P/0/1/0/all/0/1">P&#xe1;l Andr&#xe1;s Papp</a>, <a href="http://arxiv.org/find/cs/1/au:+Anegg_G/0/1/0/all/0/1">Georg Anegg</a>, <a href="http://arxiv.org/find/cs/1/au:+Yzelman_A/0/1/0/all/0/1">A. N. Yzelman</a></p><p>We study the problem of scheduling an arbitrary computational DAG on a fixed
number of processors while minimizing the makespan. While previous works have
mostly studied this problem in relatively restricted models, we define and
analyze DAG scheduling in the Bulk Synchronous Parallel (BSP) model, which is a
well-established parallel computing model that captures the communication cost
between processors much more accurately. We provide a detailed taxonomy of
simpler scheduling models that can be understood as variants or special cases
of BSP, and discuss the properties of the problem and the optimum cost in these
models, and how they differ from BSP. This essentially allows us to dissect the
different building blocks of the BSP model, and gain insight into how each of
these influences the scheduling problem.
</p>
<p>We then analyze the hardness of DAG scheduling in BSP in detail. We show that
the problem is solvable in polynomial time for some very simple classes of
DAGs, but it is already NP-hard for in-trees or DAGs of height 2. We also
separately study the subproblem of scheduling communication steps, and we show
that the NP-hardness of this problem can depend on the problem parameters and
the communication rules within the BSP model. Finally, we present and analyze a
natural formulation of our scheduling task as an Integer Linear Program.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06001'>Multivariate to Bivariate Reduction for Noncommutative Polynomial Factorization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: V. Arvind, Pushkar S. Joglekar</p><p>Based on a theorem of Bergman we show that multivariate noncommutative
polynomial factorization is deterministic polynomial-time reducible to the
factorization of bivariate noncommutative polynomials. More precisely, we show
the following:
</p>
<p>(1) In the white-box setting, given an n-variate noncommutative polynomial f
in F&lt;X&gt; over a field F (either a finite field or the rationals) as an
arithmetic circuit (or algebraic branching program), computing a complete
factorization of f is deterministic polynomial-time reducible to white-box
factorization of a noncommutative bivariate polynomial g in F&lt;x,y&gt;; the
reduction transforms f into a circuit for g (resp. ABP for g), and given a
complete factorization of g the reduction recovers a complete factorization of
f in polynomial time. We also obtain a similar deterministic polynomial-time
reduction in the black-box setting.
</p>
<p>(2) Additionally, we show over the field of rationals that bivariate linear
matrix factorization of 4 x 4 matrices is at least as hard as factoring
square-free integers. This indicates that reducing noncommutative polynomial
factorization to linear matrix factorization (as done in our recent work
[AJ22]) is unlikely to succeed over the field of rationals even in the
bivariate case.
</p>
<p>In contrast, multivariate linear matrix factorization for 3 x 3 matrices over
rationals is in polynomial time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Arvind_V/0/1/0/all/0/1">V. Arvind</a>, <a href="http://arxiv.org/find/cs/1/au:+Joglekar_P/0/1/0/all/0/1">Pushkar S. Joglekar</a></p><p>Based on a theorem of Bergman we show that multivariate noncommutative
polynomial factorization is deterministic polynomial-time reducible to the
factorization of bivariate noncommutative polynomials. More precisely, we show
the following:
</p>
<p>(1) In the white-box setting, given an n-variate noncommutative polynomial f
in F&lt;X&gt; over a field F (either a finite field or the rationals) as an
arithmetic circuit (or algebraic branching program), computing a complete
factorization of f is deterministic polynomial-time reducible to white-box
factorization of a noncommutative bivariate polynomial g in F&lt;x,y&gt;; the
reduction transforms f into a circuit for g (resp. ABP for g), and given a
complete factorization of g the reduction recovers a complete factorization of
f in polynomial time. We also obtain a similar deterministic polynomial-time
reduction in the black-box setting.
</p>
<p>(2) Additionally, we show over the field of rationals that bivariate linear
matrix factorization of 4 x 4 matrices is at least as hard as factoring
square-free integers. This indicates that reducing noncommutative polynomial
factorization to linear matrix factorization (as done in our recent work
[AJ22]) is unlikely to succeed over the field of rationals even in the
bivariate case.
</p>
<p>In contrast, multivariate linear matrix factorization for 3 x 3 matrices over
rationals is in polynomial time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05965'>Scalable and Efficient Functional Map Computations on Dense Meshes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Robin Magnet, Maks Ovsjanikov</p><p>Spectral geometric methods have brought revolutionary changes to the field of
geometry processing. Of particular interest is the study of the Laplacian
spectrum as a compact, isometry and permutation-invariant representation of a
shape. Some recent works show how the intrinsic geometry of a full shape can be
recovered from its spectrum, but there are approaches that consider the more
challenging problem of recovering the geometry from the spectral information of
partial shapes. In this paper, we propose a possible way to fill this gap. We
introduce a learning-based method to estimate the Laplacian spectrum of the
union of partial non-rigid 3D shapes, without actually computing the 3D
geometry of the union or any correspondence between those partial shapes. We do
so by operating purely in the spectral domain and by defining the union
operation between short sequences of eigenvalues. We show that the approximated
union spectrum can be used as-is to reconstruct the complete geometry [MRC*19],
perform region localization on a template [RTO*19] and retrieve shapes from a
database, generalizing ShapeDNA [RWP06] to work with partialities. Working with
eigenvalues allows us to deal with unknown correspondence, different sampling,
and different discretizations (point clouds and meshes alike), making this
operation especially robust and general. Our approach is data-driven and can
generalize to isometric and non-isometric deformations of the surface, as long
as these stay within the same semantic class (e.g., human bodies or horses), as
well as to partiality artifacts not seen at training time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Magnet_R/0/1/0/all/0/1">Robin Magnet</a>, <a href="http://arxiv.org/find/cs/1/au:+Ovsjanikov_M/0/1/0/all/0/1">Maks Ovsjanikov</a></p><p>Spectral geometric methods have brought revolutionary changes to the field of
geometry processing. Of particular interest is the study of the Laplacian
spectrum as a compact, isometry and permutation-invariant representation of a
shape. Some recent works show how the intrinsic geometry of a full shape can be
recovered from its spectrum, but there are approaches that consider the more
challenging problem of recovering the geometry from the spectral information of
partial shapes. In this paper, we propose a possible way to fill this gap. We
introduce a learning-based method to estimate the Laplacian spectrum of the
union of partial non-rigid 3D shapes, without actually computing the 3D
geometry of the union or any correspondence between those partial shapes. We do
so by operating purely in the spectral domain and by defining the union
operation between short sequences of eigenvalues. We show that the approximated
union spectrum can be used as-is to reconstruct the complete geometry [MRC*19],
perform region localization on a template [RTO*19] and retrieve shapes from a
database, generalizing ShapeDNA [RWP06] to work with partialities. Working with
eigenvalues allows us to deal with unknown correspondence, different sampling,
and different discretizations (point clouds and meshes alike), making this
operation especially robust and general. Our approach is data-driven and can
generalize to isometric and non-isometric deformations of the surface, as long
as these stay within the same semantic class (e.g., human bodies or horses), as
well as to partiality artifacts not seen at training time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06118'>Decomposition of zero-dimensional persistence modules via rooted subsets</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: &#xc1;ngel Javier Alonso, Michael Kerber</p><p>We study the decomposition of zero-dimensional persistence modules, viewed as
functors valued in the category of vector spaces factorizing through sets.
Instead of working directly at the level of vector spaces, we take a step back
and first study the decomposition problem at the level of sets.
</p>
<p>This approach allows us to define the combinatorial notion of rooted subsets.
In the case of a filtered metric space $M$, rooted subsets relate the
clustering behavior of the points of $M$ with the decomposition of the
associated persistence module. In particular, we can identify intervals in such
a decomposition quickly. In addition, rooted subsets can be understood as a
generalization of the elder rule, and are also related to the notion of
constant conqueror of Cai, Kim, M\'emoli and Wang. As an application, we give a
lower bound on the number of intervals that we can expect in the decomposition
of zero-dimensional persistence modules of a density-Rips filtration in
Euclidean space: in the limit, and under very general circumstances, we can
expect that at least 25% of the indecomposable summands are interval modules.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Alonso_A/0/1/0/all/0/1">&#xc1;ngel Javier Alonso</a>, <a href="http://arxiv.org/find/math/1/au:+Kerber_M/0/1/0/all/0/1">Michael Kerber</a></p><p>We study the decomposition of zero-dimensional persistence modules, viewed as
functors valued in the category of vector spaces factorizing through sets.
Instead of working directly at the level of vector spaces, we take a step back
and first study the decomposition problem at the level of sets.
</p>
<p>This approach allows us to define the combinatorial notion of rooted subsets.
In the case of a filtered metric space $M$, rooted subsets relate the
clustering behavior of the points of $M$ with the decomposition of the
associated persistence module. In particular, we can identify intervals in such
a decomposition quickly. In addition, rooted subsets can be understood as a
generalization of the elder rule, and are also related to the notion of
constant conqueror of Cai, Kim, M\'emoli and Wang. As an application, we give a
lower bound on the number of intervals that we can expect in the decomposition
of zero-dimensional persistence modules of a density-Rips filtration in
Euclidean space: in the limit, and under very general circumstances, we can
expect that at least 25% of the indecomposable summands are interval modules.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05799'>Optimal-Hash Exact String Matching Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Thierry Lecroq</p><p>String matching is the problem of finding all the occurrences of a pattern in
a text. We propose improved versions of the fast family of string matching
algorithms based on hashing $q$-grams. The improvement consists of considering
minimal values $q$ such that each $q$-grams of the pattern has a unique hash
value. The new algorithms are fastest than algorithm of the HASH family for
short patterns on large size alphabets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lecroq_T/0/1/0/all/0/1">Thierry Lecroq</a></p><p>String matching is the problem of finding all the occurrences of a pattern in
a text. We propose improved versions of the fast family of string matching
algorithms based on hashing $q$-grams. The improvement consists of considering
minimal values $q$ such that each $q$-grams of the pattern has a unique hash
value. The new algorithms are fastest than algorithm of the HASH family for
short patterns on large size alphabets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05920'>Faster Matroid Partition Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tatsuya Terao</p><p>In the matroid partitioning problem, we are given $k$ matroids $\mathcal{M}_1
= (V, \mathcal{I}_1), \dots , \mathcal{M}_k = (V, \mathcal{I}_k)$ defined over
a common ground set $V$ of $n$ elements, and we need to find a partitionable
set $S \subseteq V$ of largest possible cardinality, denoted by $p$. Here, a
set $S \subseteq V$ is called partitionable if there exists a partition $(S_1,
\dots , S_k)$ of $S$ with $S_i \in \mathcal{I}_i$ for $i = 1, \ldots, k$. In
1986, Cunningham presented a matroid partition algorithm that uses $O(n p^{3/2}
+ k n)$ independence oracle queries, which was the previously known best
algorithm. This query complexity is $O(n^{5/2})$ when $k \leq n$.
</p>
<p>Our main result is to present a matroid partition algorithm that uses
$\tilde{O}(k^{1/3} n p + k n)$ independence oracle queries, which is
$\tilde{O}(n^{7/3})$ when $k \leq n$. This improves upon previous Cunningham's
algorithm. To obtain this, we present a new approach \emph{edge recycling
augmentation}, which can be attained through new ideas: an efficient
utilization of the binary search technique by Nguyen and
Chakrabarty-Lee-Sidford-Singla-Wong and a careful analysis of the number of
independence oracle queries. Our analysis differs significantly from the one
for matroid intersection algorithms, because of the parameter $k$. We also
present a matroid partition algorithm that uses $\tilde{O}((n + k) \sqrt{p})$
rank oracle queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Terao_T/0/1/0/all/0/1">Tatsuya Terao</a></p><p>In the matroid partitioning problem, we are given $k$ matroids $\mathcal{M}_1
= (V, \mathcal{I}_1), \dots , \mathcal{M}_k = (V, \mathcal{I}_k)$ defined over
a common ground set $V$ of $n$ elements, and we need to find a partitionable
set $S \subseteq V$ of largest possible cardinality, denoted by $p$. Here, a
set $S \subseteq V$ is called partitionable if there exists a partition $(S_1,
\dots , S_k)$ of $S$ with $S_i \in \mathcal{I}_i$ for $i = 1, \ldots, k$. In
1986, Cunningham presented a matroid partition algorithm that uses $O(n p^{3/2}
+ k n)$ independence oracle queries, which was the previously known best
algorithm. This query complexity is $O(n^{5/2})$ when $k \leq n$.
</p>
<p>Our main result is to present a matroid partition algorithm that uses
$\tilde{O}(k^{1/3} n p + k n)$ independence oracle queries, which is
$\tilde{O}(n^{7/3})$ when $k \leq n$. This improves upon previous Cunningham's
algorithm. To obtain this, we present a new approach \emph{edge recycling
augmentation}, which can be attained through new ideas: an efficient
utilization of the binary search technique by Nguyen and
Chakrabarty-Lee-Sidford-Singla-Wong and a careful analysis of the number of
independence oracle queries. Our analysis differs significantly from the one
for matroid intersection algorithms, because of the parameter $k$. We also
present a matroid partition algorithm that uses $\tilde{O}((n + k) \sqrt{p})$
rank oracle queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06090'>Simple and efficient four-cycle counting on sparse graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Paul Burkhardt, David G. Harris</p><p>We consider the problem of counting 4-cycles ($C_4$) in a general undirected
graph $G$ of $n$ vertices and $m$ edges (in bipartite graphs, 4-cycles are also
often referred to as $\textit{butterflies}$). There have been a number of
previous algorithms for this problem; some of these are based on fast matrix
multiplication, which is attractive theoretically but not practical, and some
of these are based on randomized hash tables.
</p>
<p>We develop a new simpler algorithm for counting $C_4$, which has several
practical improvements over previous algorithms; for example, it is fully
deterministic and avoids any expensive arithmetic in its inner loops. The
algorithm can also be adapted to count 4-cycles incident to each vertex and
edge. Our algorithm runs in $O(m\bar\delta(G))$ time and $O(n)$ space, where
$\bar \delta(G) \leq O(\sqrt{m})$ is the $\textit{average degeneracy}$
parameter introduced by Burkhardt, Faber &amp; Harris (2020).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Burkhardt_P/0/1/0/all/0/1">Paul Burkhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Harris_D/0/1/0/all/0/1">David G. Harris</a></p><p>We consider the problem of counting 4-cycles ($C_4$) in a general undirected
graph $G$ of $n$ vertices and $m$ edges (in bipartite graphs, 4-cycles are also
often referred to as $\textit{butterflies}$). There have been a number of
previous algorithms for this problem; some of these are based on fast matrix
multiplication, which is attractive theoretically but not practical, and some
of these are based on randomized hash tables.
</p>
<p>We develop a new simpler algorithm for counting $C_4$, which has several
practical improvements over previous algorithms; for example, it is fully
deterministic and avoids any expensive arithmetic in its inner loops. The
algorithm can also be adapted to count 4-cycles incident to each vertex and
edge. Our algorithm runs in $O(m\bar\delta(G))$ time and $O(n)$ space, where
$\bar \delta(G) \leq O(\sqrt{m})$ is the $\textit{average degeneracy}$
parameter introduced by Burkhardt, Faber &amp; Harris (2020).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06102'>Bootstrapping Dynamic Distance Oracles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sebastian Forster, Gramoz Goranci, Yasamin Nazari, Antonis Skarlatos</p><p>Designing approximate all-pairs distance oracles in the fully dynamic setting
is one of the central problems in dynamic graph algorithms. Despite extensive
research on this topic, the first result breaking the $O(\sqrt{n})$ barrier on
the update time for any non-trivial approximation was introduced only recently
by Forster, Goranci and Henzinger [SODA'21] who achieved $m^{1/\rho+o(1)}$
amortized update time with a $O(\log n)^{3\rho-2}$ factor in the approximation
ratio, for any parameter $\rho \geq 1$.
</p>
<p>In this paper, we give the first constant-stretch fully dynamic distance
oracle with a small polynomial update and query time. Prior work required
either at least a poly-logarithmic approximation or much larger update time.
Our result gives a more fine-grained trade-off between stretch and update time,
for instance we can achieve constant stretch of $O(\frac{1}{\rho^2})^{4/\rho}$
in amortized update time $\tilde{O}(n^{\rho})$, and query time
$\tilde{O}(n^{\rho/8})$ for a constant parameter $\rho &lt;1$. Our algorithm is
randomized and assumes an oblivious adversary.
</p>
<p>A core technical idea underlying our construction is to design a black-box
reduction from decremental approximate hub-labeling schemes to fully dynamic
distance oracles, which may be of independent interest. We then apply this
reduction repeatedly to an existing decremental algorithm to bootstrap our
fully dynamic solution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Forster_S/0/1/0/all/0/1">Sebastian Forster</a>, <a href="http://arxiv.org/find/cs/1/au:+Goranci_G/0/1/0/all/0/1">Gramoz Goranci</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazari_Y/0/1/0/all/0/1">Yasamin Nazari</a>, <a href="http://arxiv.org/find/cs/1/au:+Skarlatos_A/0/1/0/all/0/1">Antonis Skarlatos</a></p><p>Designing approximate all-pairs distance oracles in the fully dynamic setting
is one of the central problems in dynamic graph algorithms. Despite extensive
research on this topic, the first result breaking the $O(\sqrt{n})$ barrier on
the update time for any non-trivial approximation was introduced only recently
by Forster, Goranci and Henzinger [SODA'21] who achieved $m^{1/\rho+o(1)}$
amortized update time with a $O(\log n)^{3\rho-2}$ factor in the approximation
ratio, for any parameter $\rho \geq 1$.
</p>
<p>In this paper, we give the first constant-stretch fully dynamic distance
oracle with a small polynomial update and query time. Prior work required
either at least a poly-logarithmic approximation or much larger update time.
Our result gives a more fine-grained trade-off between stretch and update time,
for instance we can achieve constant stretch of $O(\frac{1}{\rho^2})^{4/\rho}$
in amortized update time $\tilde{O}(n^{\rho})$, and query time
$\tilde{O}(n^{\rho/8})$ for a constant parameter $\rho &lt;1$. Our algorithm is
randomized and assumes an oblivious adversary.
</p>
<p>A core technical idea underlying our construction is to design a black-box
reduction from decremental approximate hub-labeling schemes to fully dynamic
distance oracles, which may be of independent interest. We then apply this
reduction repeatedly to an existing decremental algorithm to bootstrap our
fully dynamic solution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.06127'>Any-Order Online Interval Selection</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Allan Borodin, Christodoulos Karavasilis</p><p>We consider the problem of online interval scheduling on a single machine,
where intervals arrive online in an order chosen by an adversary, and the
algorithm must output a set of non-conflicting intervals. Traditionally in
scheduling theory, it is assumed that intervals arrive in order of increasing
start times. We drop that assumption and allow for intervals to arrive in any
possible order. We call this variant any-order interval selection (AOIS). We
assume that some online acceptances can be revoked, but a feasible solution
must always be maintained. For unweighted intervals and deterministic
algorithms, this problem is unbounded. Under the assumption that there are at
most $k$ different interval lengths, we give a simple algorithm that achieves a
competitive ratio of $2k$ and show that it is optimal amongst deterministic
algorithms, and a restricted class of randomized algorithms we call memoryless,
contributing to an open question by Adler and Azar 2003; namely whether a
randomized algorithm without access to history can achieve a constant
competitive ratio. We connect our model to the problem of call control on the
line, and show how the algorithms of Garay et al. 1997 can be applied to our
setting, resulting in an optimal algorithm for the case of proportional
weights. We also consider the case of intervals arriving in a random order, and
show that for single-lengthed instances, a one-directional algorithm (i.e.
replacing intervals in one direction), is the only deterministic memoryless
algorithm that can possibly benefit from random arrivals. Finally, we briefly
discuss the case of intervals with arbitrary weights.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Borodin_A/0/1/0/all/0/1">Allan Borodin</a>, <a href="http://arxiv.org/find/cs/1/au:+Karavasilis_C/0/1/0/all/0/1">Christodoulos Karavasilis</a></p><p>We consider the problem of online interval scheduling on a single machine,
where intervals arrive online in an order chosen by an adversary, and the
algorithm must output a set of non-conflicting intervals. Traditionally in
scheduling theory, it is assumed that intervals arrive in order of increasing
start times. We drop that assumption and allow for intervals to arrive in any
possible order. We call this variant any-order interval selection (AOIS). We
assume that some online acceptances can be revoked, but a feasible solution
must always be maintained. For unweighted intervals and deterministic
algorithms, this problem is unbounded. Under the assumption that there are at
most $k$ different interval lengths, we give a simple algorithm that achieves a
competitive ratio of $2k$ and show that it is optimal amongst deterministic
algorithms, and a restricted class of randomized algorithms we call memoryless,
contributing to an open question by Adler and Azar 2003; namely whether a
randomized algorithm without access to history can achieve a constant
competitive ratio. We connect our model to the problem of call control on the
line, and show how the algorithms of Garay et al. 1997 can be applied to our
setting, resulting in an optimal algorithm for the case of proportional
weights. We also consider the case of intervals arriving in a random order, and
show that for single-lengthed instances, a one-directional algorithm (i.e.
replacing intervals in one direction), is the only deterministic memoryless
algorithm that can possibly benefit from random arrivals. Finally, we briefly
discuss the case of intervals with arbitrary weights.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-13T00:30:00Z">Monday, March 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, March 11
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/022'>TR23-022 |  Unprovability of strong complexity lower bounds in bounded arithmetic | 

	Jiatu Li, 

	Igor Carboni Oliveira</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          While there has been progress in establishing the unprovability of complexity statements in lower fragments of bounded arithmetic, understanding the limits of Jerabek&#39;s theory $\textbf{APC}_1$ (2007) and of higher levels of Buss&#39;s hierarchy $\textbf{S}^i_2$ (1986) has been a more elusive task. Even in the more restricted setting of Cook&#39;s theory $\textbf{PV}$ (1975), known results often rely on a less natural formalization that encodes a complexity statement using a collection of sentences instead of a single sentence. This is done to reduce the quantifier complexity of the resulting sentences so that standard witnessing results can be invoked. 

In this work, we establish unprovability results for stronger theories and for sentences of higher quantifier complexity. In particular, we unconditionally show that $\textbf{APC}_1$ cannot prove strong complexity lower bounds separating the third level of the polynomial hierarchy. In more detail, we consider non-uniform average-case separations, and establish that $\textbf{APC}_1$ cannot prove a sentence stating that
* $\forall n \geq n_0\;\exists\,f_n \in \Pi_3\text{-}\textbf{SIZE}[n^d]$ that is $(1/n)$-far from every $\Sigma_3\text{-}\textbf{SIZE}[2^{n^{\delta}}]$ circuit. 
This is a consequence of a much more general result showing that, for every $i \geq 1$, strong separations for $\Pi_{i}\text{-}\textbf{SIZE}[\textrm{poly}(n)]$ versus $\Sigma_{i}\text{-}\textbf{SIZE}[2^{n^{\Omega(1)}}]$ cannot be proved in the theory $\textbf{T}_\textbf{PV}^i$ consisting of all true $\forall \Sigma^b_{i-1}$-sentences in the language of Cook&#39;s theory $\textbf{PV}$. 

Our argument employs a convenient game-theoretic witnessing result that can be applied to sentences of arbitrary quantifier complexity. We combine it with extensions of a technique introduced by Krajicek (2011) that was recently employed by Pich and Santhanam (2021) to establish the unprovability of lower bounds in $\textbf{PV}$ (i.e., the case $i =1$ above, but under a weaker formalization) and in a fragment of $\textbf{APC}_1$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          While there has been progress in establishing the unprovability of complexity statements in lower fragments of bounded arithmetic, understanding the limits of Jerabek&#39;s theory $\textbf{APC}_1$ (2007) and of higher levels of Buss&#39;s hierarchy $\textbf{S}^i_2$ (1986) has been a more elusive task. Even in the more restricted setting of Cook&#39;s theory $\textbf{PV}$ (1975), known results often rely on a less natural formalization that encodes a complexity statement using a collection of sentences instead of a single sentence. This is done to reduce the quantifier complexity of the resulting sentences so that standard witnessing results can be invoked. 

In this work, we establish unprovability results for stronger theories and for sentences of higher quantifier complexity. In particular, we unconditionally show that $\textbf{APC}_1$ cannot prove strong complexity lower bounds separating the third level of the polynomial hierarchy. In more detail, we consider non-uniform average-case separations, and establish that $\textbf{APC}_1$ cannot prove a sentence stating that
* $\forall n \geq n_0\;\exists\,f_n \in \Pi_3\text{-}\textbf{SIZE}[n^d]$ that is $(1/n)$-far from every $\Sigma_3\text{-}\textbf{SIZE}[2^{n^{\delta}}]$ circuit. 
This is a consequence of a much more general result showing that, for every $i \geq 1$, strong separations for $\Pi_{i}\text{-}\textbf{SIZE}[\textrm{poly}(n)]$ versus $\Sigma_{i}\text{-}\textbf{SIZE}[2^{n^{\Omega(1)}}]$ cannot be proved in the theory $\textbf{T}_\textbf{PV}^i$ consisting of all true $\forall \Sigma^b_{i-1}$-sentences in the language of Cook&#39;s theory $\textbf{PV}$. 

Our argument employs a convenient game-theoretic witnessing result that can be applied to sentences of arbitrary quantifier complexity. We combine it with extensions of a technique introduced by Krajicek (2011) that was recently employed by Pich and Santhanam (2021) to establish the unprovability of lower bounds in $\textbf{PV}$ (i.e., the case $i =1$ above, but under a weaker formalization) and in a fragment of $\textbf{APC}_1$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-11T23:55:20Z">Saturday, March 11 2023, 23:55</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, March 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://dstheory.wordpress.com/2023/03/10/thursday-mar-16th-2023-vladimir-braverman-from-rice-university/'>Thursday, Mar 16th, 2023 â Vladimir Braverman from Rice University</a></h3>
        <p class='tr-article-feed'>from <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next Foundations of Data Science virtual talk series on recent advances in adversarially robust streaming will take place on Thursday, March 16th at 1:00 PM Pacific Time (16:00 Eastern Time, 22:00 Central European Time, 21:00 UTC). Vladimir Braverman from Rice University will talk about âAdversarial Robustness of Streaming Algorithms through Importance Samplingâ. Details ofContinue reading "Thursday, Mar 16th, 2023 â Vladimir Braverman from Rice&#160;University"
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="has-text-align-justify">The next <a rel="noreferrer noopener" href="https://sites.google.com/view/dstheory/home" target="_blank">Foundations of Data Science</a> virtual talk series on recent advances in <em>adversarially robust streaming</em> will take place on <strong>Thursday, March 16th</strong> at<strong> 1:00 PM Pacific Time</strong> (16:00 Eastern Time, 22:00 Central European Time, 21:00 UTC). <a href="https://profiles.rice.edu/faculty/vladimir-braverman">Vladimir Braverman</a> from<strong> Rice University</strong> will talk about <em>âAdversarial Robustness of Streaming Algorithms through Importance Samplingâ</em>.</p>



<p><a href="https://sites.google.com/view/dstheory">Details of the talk (Zoom link) are available here.</a></p>



<p class="has-text-align-justify"><strong>Abstract</strong>: Robustness against adversarial attacks has recently been at the forefront of algorithmic design for machine learning tasks. In the adversarial streaming model, an adversary gives an algorithm a sequence of adaptively chosen updates u1, &#8230; ,un as a data stream. The goal of the algorithm is to compute or approximate some predetermined function for every prefix of the adversarial stream, but the adversary may generate future updates based on previous outputs of the algorithm. In particular, the adversary may gradually learn the random bits internally used by an algorithm to manipulate dependencies in the input. This is especially problematic as many important problems in the streaming model require randomized algorithms, as they are known to not admit any deterministic algorithms that use sublinear space. In this paper, we introduce adversarially robust streaming algorithms for central machine learning and algorithmic tasks, such as regression and clustering, as well as their more general counterparts, subspace embedding, low-rank approximation, and coreset construction. For regression and other numerical linear algebra related tasks, we consider the row arrival streaming model. Our results are based on a simple, but powerful, observation that many importance sampling-based algorithms give rise to adversarial robustness which is in contrast to sketching based algorithms, which are very prevalent in the streaming literature but suffer from adversarial attacks. In addition, we show that the well-known merge and reduce paradigm in streaming is adversarially robust. Since the merge and reduce paradigm allows coreset constructions in the streaming setting, we thus obtain robust algorithms for k-means, k-median, k-center, Bregman clustering, projective clustering, principal component analysis (PCA) and non-negative matrix factorization. To the best of our knowledge, these are the first adversarially robust results for these problems yet require no new algorithmic implementations. Finally, we empirically confirm the robustness of our algorithms on various adversarial attacks and demonstrate that by contrast, some common existing algorithms are not robust.</p>



<p>This is a joint work with Avinatan Hassidim, Yossi Matias, Mariano Schain, Sandeep Silwal, Samson Zhou. This result has appeared in NeurIPS 2021.</p>



<p>&nbsp;The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p>
<p class="authors">By dstheory</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T22:17:33Z">Friday, March 10 2023, 22:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/03/10/subspace-designs-unit-and-distinct-distances-and-piercing-standard-boxes/'>Subspace Designs, Unit and Distinct Distances, and Piercing Standard Boxes.</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A lot of things are happening and let me briefly report on three major advancements in combinatorics. Peter Keevash, Ashwin Sah and Mehtaab Sawhney proved the existence of subspace designs with any given parameters, provided that the dimension of the &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>A lot of things are happening and let me briefly report on three major advancements in combinatorics.</p>
<ol>
<li>Peter Keevash, Ashwin Sah and Mehtaab Sawhney proved the existence of subspace designs with any given parameters, provided that the dimension of the underlying space is sufficiently large in terms of the other parameters of the design and satisfies the obvious necessary divisibility conditions.Â  Here is the link to the paper: <a href="https://arxiv.org/abs/2212.00870">The existence of subspace designs</a>.</li>
<li>Noga Alon, Matija BuciÄ, and Lisa Sauermann made an important advance on the study of unit distances and distinct distances in arbitrary normed space. Here is a link to the paper: <a href="https://arxiv.org/abs/2302.09058">Unit and distinct distances in typical norms.</a> The unit distance and distinct distances problems for Euclidean geometry are old and famous and there was also a lot of attention for the question of what happens for these problems if one considers normed spaces other than the Euclidean plane. Alon, BuciÄ, and Sauermann give an essentially tight answer to both questions for almost all norms on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /> , in a certain Baire categoric sense.</li>
<li>IstvÃ¡n Tomon&#8217;s paper: <a href="https://arxiv.org/abs/2209.09887">Lower bounds for piercing and coloring boxes</a>. Here is Tomon&#8217;s abstract from his recent Copenhagen-Jerusalem seminar: Configurations of axis-parallel boxes in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /> are extensively studied in combinatorial and computational geometry. Despite their innocent appearance, there are many old problems involving their structure that are still not well understood. I will talk about a construction, which addresses several of these problems, and shows that configurations of boxes may be more complex than people conjectured.</li>
</ol>
<h3>Subspace designs and q-analogs</h3>
<p>We talked about subspace designs in <a href="https://gilkalai.wordpress.com/2016/11/23/amazing-stefan-glock-daniela-kuhn-allan-lo-deryk-osthus-give-a-new-proof-for-keevashs-theorem-and-more-news-on-designs/">this post</a>Â  and in particular about the 2016 paper of Michael Â Braun, Tuvi Etzion , Patric R. J. Ãstergard , Alexander Vardy,Â Â and Alferd Wasserman. While preparing this post I learned the sad news that Alexander Vardy, a prominent coding theorist,Â  passed away a year ago at the early age of 58.</p>
<p>The theme of finding <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" />-analogs to combinatorial results and problems is important both in enumerative and algebraic combinatorics and in extremal combinatorics and it will be interesting to discuss it in some future post and while preparing for that I recalled the famous <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" />&#8211;<a href="https://en.wikipedia.org/wiki/Dyson_conjecture">Dyson conjecture</a> that was settled by Zeilberger and Bressoud in 1995. I learned that by now there are simpler proofs:Â  &#8220;A shorter proof, using formal Laurent series, was given in 2004 by Ira Gessel and Guoce Xin, and an even shorter proof, using a quantitative form, due to Karasev and Petrov, and independently to Lason, of Noga Alon&#8217;s Combinatorial Nullstellensatz, was given in 2012 by Gyula Karolyi and Zoltan Lorant Nagy. The latter method was extended, in 2013, by <a href="http://www.math.rutgers.edu/~zeilberg/mamarim/mamarimhtml/qdyson.html">Shalosh B. Ekhad and Doron Zeilberger</a> to derive explicit expressions of any specific coefficient.&#8221; (Wikipedia.)</p>
<h3>Unit and distinct distances</h3>
<p>Here is the abstract of the paper by Alon, BuciÄ, and Sauermann:</p>
<blockquote><p><em>ErdÅs&#8217; unit distance problem and ErdÅs&#8217; distinct distances problem are among the most classical and well-known open problems in all of discrete mathematics. They ask for the maximum number of unit distances, or the minimum number of distinct distances, respectively, determined by $latex <span id="MathJax-Element-1-Frame" class="MathJax"><span id="MathJax-Span-1" class="math"><span id="MathJax-Span-2" class="mrow"><span id="MathJax-Span-3" class="mi">n$</span></span></span></span> points in the Euclidean plane. The question of what happens in these problems if one considers normed spaces other than the Euclidean plane has been raised in the 1980s by Ulam and ErdÅs and attracted a lot of attention over the years. We give an essentially tight answer to both questions for almost all norms on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" />, in a certain Baire categoric sense.</em></p>
<p><em>For the unit distance problem we prove that for almost all norms ||.|| on <span id="MathJax-Element-3-Frame" class="MathJax"><span id="MathJax-Span-11" class="math"><span id="MathJax-Span-12" class="mrow"><span id="MathJax-Span-13" class="msubsup"><span id="MathJax-Span-14" class="texatom"><span id="MathJax-Span-15" class="mrow"><span id="MathJax-Span-16" class="mi"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /></span></span></span></span></span></span></span>, any set of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> points defines at most <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+d+%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+d+%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+d+%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;frac{1}{2} d &#92;cdot n &#92;log_2 n" class="latex" /> unit distances according to ||.||. We also show that this is essentially tight, by proving that for every norm ||.|| on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" />, for any large <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, we can find $latex <span id="MathJax-Element-8-Frame" class="MathJax"><span id="MathJax-Span-44" class="math"><span id="MathJax-Span-45" class="mrow"><span id="MathJax-Span-46" class="mi">n$</span></span></span></span> points defining at least <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D%28d-1-o%281%29%29%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D%28d-1-o%281%29%29%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D%28d-1-o%281%29%29%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;frac{1}{2}(d-1-o(1))&#92;cdot n &#92;log_2 n" class="latex" /> unit distances according to ||.||.</em></p>
<p><em>For the distinct distances problem, we prove that for almost all norms ||.|| on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /> any set of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> <span id="MathJax-Element-11-Frame" class="MathJax"><span id="MathJax-Span-76" class="math"><span id="MathJax-Span-77" class="mrow"><span id="MathJax-Span-78" class="mi"></span></span></span></span> points defines at least $latex <span id="MathJax-Element-12-Frame" class="MathJax"><span id="MathJax-Span-79" class="math"><span id="MathJax-Span-80" class="mrow"><span id="MathJax-Span-81" class="mo">(</span><span id="MathJax-Span-82" class="mn">1</span><span id="MathJax-Span-83" class="mo">â</span><span id="MathJax-Span-84" class="mi">o</span><span id="MathJax-Span-85" class="mo">(</span><span id="MathJax-Span-86" class="mn">1</span><span id="MathJax-Span-87" class="mo">)</span><span id="MathJax-Span-88" class="mo">)</span><span id="MathJax-Span-89" class="mi">n$</span></span></span></span> distinct distances according to ||.||. This is clearly tight up to the $latex <span id="MathJax-Element-13-Frame" class="MathJax"><span id="MathJax-Span-90" class="math"><span id="MathJax-Span-91" class="mrow"><span id="MathJax-Span-92" class="mi">o</span><span id="MathJax-Span-93" class="mo">(</span><span id="MathJax-Span-94" class="mn">1</span><span id="MathJax-Span-95" class="mo">)$</span></span></span></span> term.</em></p>
<p><em>Our results settle, in a strong and somewhat surprising form, problems and conjectures of Brass, of MatouÅ¡ek, and of Brass-Moser-Pach. The proofs combine combinatorial and geometric ideas with tools from Linear Algebra, Topology and Algebraic Geometry.</em></p></blockquote>
<p>We discussed the unit distances and distinct distances in many posts over here, and they are also related to problems around Borsuk&#8217;s problem (see also my survey paper <a href="https://arxiv.org/abs/1505.04952">Some old and new problems in combinatorial geometry I: AroundÂ <span class="search-hit mathjax">Borsuk&#8217;s</span>Â problem</a>).</p>
<h3>Standard boxes</h3>
<p>Here is the abstract of Tomon&#8217;s paper.<br />
<img data-attachment-id="23978" data-permalink="https://gilkalai.wordpress.com/2023/03/10/subspace-designs-unit-and-distinct-distances-and-piercing-standard-boxes/tomon/" data-orig-file="https://gilkalai.files.wordpress.com/2023/03/tomon.png" data-orig-size="663,481" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Tomon" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=640" class="alignnone size-full wp-image-23978" src="https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=640" alt="Tomon" srcset="https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=640 640w, https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=150 150w, https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=300 300w, https://gilkalai.files.wordpress.com/2023/03/tomon.png 663w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p>We discussed the intersection pattern of (standard) boxes on several occasions such as <a href="https://gilkalai.wordpress.com/2014/07/03/my-mathematical-dialogue-with-jurgen-eckhoff/">this post</a> about Jurgen Eckhoff.</p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T11:28:42Z">Friday, March 10 2023, 11:28</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04859'>Agnostic PAC Learning of k-juntas Using L2-Polynomial Regression</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mohsen Heidari, Wojciech Szpankowski</p><p>Many conventional learning algorithms rely on loss functions other than the
natural 0-1 loss for computational efficiency and theoretical tractability.
Among them are approaches based on absolute loss (L1 regression) and square
loss (L2 regression). The first is proved to be an \textit{agnostic} PAC
learner for various important concept classes such as \textit{juntas}, and
\textit{half-spaces}. On the other hand, the second is preferable because of
its computational efficiency, which is linear in the sample size. However, PAC
learnability is still unknown as guarantees have been proved only under
distributional restrictions. The question of whether L2 regression is an
agnostic PAC learner for 0-1 loss has been open since 1993 and yet has to be
answered.
</p>
<p>This paper resolves this problem for the junta class on the Boolean cube --
proving agnostic PAC learning of k-juntas using L2 polynomial regression.
Moreover, we present a new PAC learning algorithm based on the Boolean Fourier
expansion with lower computational complexity. Fourier-based algorithms, such
as Linial et al. (1993), have been used under distributional restrictions, such
as uniform distribution. We show that with an appropriate change, one can apply
those algorithms in agnostic settings without any distributional assumption. We
prove our results by connecting the PAC learning with 0-1 loss to the minimum
mean square estimation (MMSE) problem. We derive an elegant upper bound on the
0-1 loss in terms of the MMSE error and show that the sign of the MMSE is a PAC
learner for any concept class containing it.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Heidari_M/0/1/0/all/0/1">Mohsen Heidari</a>, <a href="http://arxiv.org/find/cs/1/au:+Szpankowski_W/0/1/0/all/0/1">Wojciech Szpankowski</a></p><p>Many conventional learning algorithms rely on loss functions other than the
natural 0-1 loss for computational efficiency and theoretical tractability.
Among them are approaches based on absolute loss (L1 regression) and square
loss (L2 regression). The first is proved to be an \textit{agnostic} PAC
learner for various important concept classes such as \textit{juntas}, and
\textit{half-spaces}. On the other hand, the second is preferable because of
its computational efficiency, which is linear in the sample size. However, PAC
learnability is still unknown as guarantees have been proved only under
distributional restrictions. The question of whether L2 regression is an
agnostic PAC learner for 0-1 loss has been open since 1993 and yet has to be
answered.
</p>
<p>This paper resolves this problem for the junta class on the Boolean cube --
proving agnostic PAC learning of k-juntas using L2 polynomial regression.
Moreover, we present a new PAC learning algorithm based on the Boolean Fourier
expansion with lower computational complexity. Fourier-based algorithms, such
as Linial et al. (1993), have been used under distributional restrictions, such
as uniform distribution. We show that with an appropriate change, one can apply
those algorithms in agnostic settings without any distributional assumption. We
prove our results by connecting the PAC learning with 0-1 loss to the minimum
mean square estimation (MMSE) problem. We derive an elegant upper bound on the
0-1 loss in terms of the MMSE error and show that the sign of the MMSE is a PAC
learner for any concept class containing it.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05136'>A New Heuristic for Rectilinear Crossing Minimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fran&#xe7;ois Dor&#xe9;, Enrico Formenti</p><p>A new heuristic for rectilinear crossing minimization is proposed. It is
based on the idea of iteratively repositioning nodes after a first initial
graph drawing. The new position of a node is computed by casting rays from the
node towards graph edges. Each ray receives a mark and the one with the best
mark determines the new position. The heuristic has interesting performances
when compared to the best competitors which can be found in classical graph
drawing libraries like OGDF.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dore_F/0/1/0/all/0/1">Fran&#xe7;ois Dor&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Formenti_E/0/1/0/all/0/1">Enrico Formenti</a></p><p>A new heuristic for rectilinear crossing minimization is proposed. It is
based on the idea of iteratively repositioning nodes after a first initial
graph drawing. The new position of a node is computed by casting rays from the
node towards graph edges. Each ray receives a mark and the one with the best
mark determines the new position. The heuristic has interesting performances
when compared to the best competitors which can be found in classical graph
drawing libraries like OGDF.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05044'>Range Avoidance for Constant-Depth Circuits: Hardness and Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Karthik Gajulapalli, Alexander Golovnev, Satyajeet Nagargoje, Sidhant Saraogi</p><p>Range Avoidance (AVOID) is a total search problem where, given a Boolean
circuit $C\colon\{0,1\}^n\to\{0,1\}^m$, $m&gt;n$, the task is to find a
$y\in\{0,1\}^m$ outside the range of $C$. For an integer $k\geq 2$,
$NC^0_k$-AVOID is a special case of AVOID where each output bit of $C$ depends
on at most $k$ input bits. Ren, Santhanam, and Wang (FOCS 2022) and Guruswami,
Lyu, and Wang (RANDOM 2022) proved that explicit constructions of functions of
high circuit complexity, rigid matrices, optimal linear codes, Ramsey graphs,
and other combinatorial objects reduce to $NC^0_4$-AVOID, thus establishing
conditional hardness of the $NC^0_4$-AVOID problem. On the other hand,
$NC^0_2$-AVOID admits polynomial-time algorithms, leaving the question about
the complexity of $NC^0_3$-AVOID open. We give the first reduction of an
explicit construction question to $NC^0_3$-AVOID. Specifically, we prove that a
polynomial-time algorithm (with an $NP$ oracle) for $NC^0_3$-AVOID for the case
of $m=n+n^{2/3}$ would imply an explicit construction of a rigid matrix, and,
thus, a super-linear lower bound on the size of log-depth circuits. We also
give deterministic polynomial-time algorithms for all $NC^0_k$-AVOID problems
for ${m\geq n^{k-1}/\log(n)}$. Prior work required an $NP$ oracle, and required
larger stretch, $m \geq n^{k-1}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gajulapalli_K/0/1/0/all/0/1">Karthik Gajulapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Golovnev_A/0/1/0/all/0/1">Alexander Golovnev</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagargoje_S/0/1/0/all/0/1">Satyajeet Nagargoje</a>, <a href="http://arxiv.org/find/cs/1/au:+Saraogi_S/0/1/0/all/0/1">Sidhant Saraogi</a></p><p>Range Avoidance (AVOID) is a total search problem where, given a Boolean
circuit $C\colon\{0,1\}^n\to\{0,1\}^m$, $m&gt;n$, the task is to find a
$y\in\{0,1\}^m$ outside the range of $C$. For an integer $k\geq 2$,
$NC^0_k$-AVOID is a special case of AVOID where each output bit of $C$ depends
on at most $k$ input bits. Ren, Santhanam, and Wang (FOCS 2022) and Guruswami,
Lyu, and Wang (RANDOM 2022) proved that explicit constructions of functions of
high circuit complexity, rigid matrices, optimal linear codes, Ramsey graphs,
and other combinatorial objects reduce to $NC^0_4$-AVOID, thus establishing
conditional hardness of the $NC^0_4$-AVOID problem. On the other hand,
$NC^0_2$-AVOID admits polynomial-time algorithms, leaving the question about
the complexity of $NC^0_3$-AVOID open. We give the first reduction of an
explicit construction question to $NC^0_3$-AVOID. Specifically, we prove that a
polynomial-time algorithm (with an $NP$ oracle) for $NC^0_3$-AVOID for the case
of $m=n+n^{2/3}$ would imply an explicit construction of a rigid matrix, and,
thus, a super-linear lower bound on the size of log-depth circuits. We also
give deterministic polynomial-time algorithms for all $NC^0_k$-AVOID problems
for ${m\geq n^{k-1}/\log(n)}$. Prior work required an $NP$ oracle, and required
larger stretch, $m \geq n^{k-1}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04845'>Smoothed Analysis of Sequential Probability Assignment</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alankrita Bhatt, Nika Haghtalab, Abhishek Shetty</p><p>We initiate the study of smoothed analysis for the sequential probability
assignment problem with contexts. We study information-theoretically optimal
minmax rates as well as a framework for algorithmic reduction involving the
maximum likelihood estimator oracle. Our approach establishes a general-purpose
reduction from minimax rates for sequential probability assignment for smoothed
adversaries to minimax rates for transductive learning. This leads to optimal
(logarithmic) fast rates for parametric classes and classes with finite VC
dimension. On the algorithmic front, we develop an algorithm that efficiently
taps into the MLE oracle, for general classes of functions. We show that under
general conditions this algorithmic approach yields sublinear regret.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhatt_A/0/1/0/all/0/1">Alankrita Bhatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Haghtalab_N/0/1/0/all/0/1">Nika Haghtalab</a>, <a href="http://arxiv.org/find/cs/1/au:+Shetty_A/0/1/0/all/0/1">Abhishek Shetty</a></p><p>We initiate the study of smoothed analysis for the sequential probability
assignment problem with contexts. We study information-theoretically optimal
minmax rates as well as a framework for algorithmic reduction involving the
maximum likelihood estimator oracle. Our approach establishes a general-purpose
reduction from minimax rates for sequential probability assignment for smoothed
adversaries to minimax rates for transductive learning. This leads to optimal
(logarithmic) fast rates for parametric classes and classes with finite VC
dimension. On the algorithmic front, we develop an algorithm that efficiently
taps into the MLE oracle, for general classes of functions. We show that under
general conditions this algorithmic approach yields sublinear regret.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04934'>Parallel Strong Connectivity Based on Faster Reachability</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Letong Wang, Xiaojun Dong, Yan Gu, Yihan Sun</p><p>Computing strongly connected components (SCC) is a fundamental problems in
graph processing. As today's real-world graphs are getting larger and larger,
parallel SCC is increasingly important. SCC is challenging in the parallel
setting and is particularly hard on large-diameter graphs. Many existing
parallel SCC implementations can be even slower than Tarjan's sequential
algorithm on large-diameter graphs.
</p>
<p>To tackle this challenge, we propose an efficient parallel SCC implementation
using a new parallel reachability algorithm. Our solution is based on a novel
idea referred to as vertical granularity control (VGC). It breaks the
synchronization barriers to increase parallelism and hide scheduling overhead.
To use VGC in our SCC algorithm, we also design an efficient data structure
called the \emph{parallel hash bag}. It uses parallel dynamic resizing to avoid
redundant work in maintaining frontiers (vertices processed in a round).
</p>
<p>We implement the parallel SCC algorithm by Blelloch et al.\ (J.\ ACM, 2020)
using our new parallel reachability algorithm. We compare our implementation to
the state-of-the-art systems, including GBBS, iSpan, Multi-step, and our highly
optimized Tarjan's (sequential) algorithm, on 18 graphs, including social, web,
$k$-NN, and lattice graphs. On a machine with 96 cores, our implementation is
the fastest on 16 out of 18 graphs. On average (geometric means) over all
graphs, our SCC is 6.0$\times$ faster than the best previous parallel code
(GBBS), 12.8$\times$ faster than Tarjan's sequential algorithms, and
2.7$\times$ faster than the \emph{best existing implementation on each graph}.
</p>
<p>We believe that our techniques are of independent interest. We also apply our
parallel hash bag and VGC scheme to other graph problems, including
connectivity and least-element lists (LE-lists).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Letong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaojun Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yihan Sun</a></p><p>Computing strongly connected components (SCC) is a fundamental problems in
graph processing. As today's real-world graphs are getting larger and larger,
parallel SCC is increasingly important. SCC is challenging in the parallel
setting and is particularly hard on large-diameter graphs. Many existing
parallel SCC implementations can be even slower than Tarjan's sequential
algorithm on large-diameter graphs.
</p>
<p>To tackle this challenge, we propose an efficient parallel SCC implementation
using a new parallel reachability algorithm. Our solution is based on a novel
idea referred to as vertical granularity control (VGC). It breaks the
synchronization barriers to increase parallelism and hide scheduling overhead.
To use VGC in our SCC algorithm, we also design an efficient data structure
called the \emph{parallel hash bag}. It uses parallel dynamic resizing to avoid
redundant work in maintaining frontiers (vertices processed in a round).
</p>
<p>We implement the parallel SCC algorithm by Blelloch et al.\ (J.\ ACM, 2020)
using our new parallel reachability algorithm. We compare our implementation to
the state-of-the-art systems, including GBBS, iSpan, Multi-step, and our highly
optimized Tarjan's (sequential) algorithm, on 18 graphs, including social, web,
$k$-NN, and lattice graphs. On a machine with 96 cores, our implementation is
the fastest on 16 out of 18 graphs. On average (geometric means) over all
graphs, our SCC is 6.0$\times$ faster than the best previous parallel code
(GBBS), 12.8$\times$ faster than Tarjan's sequential algorithms, and
2.7$\times$ faster than the \emph{best existing implementation on each graph}.
</p>
<p>We believe that our techniques are of independent interest. We also apply our
parallel hash bag and VGC scheme to other graph problems, including
connectivity and least-element lists (LE-lists).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04945'>A Survey of Quantum Alternatives to Randomized Algorithms: Monte Carlo Integration and Beyond</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Philip Intallura, Georgios Korpas, Sudeepto Chakraborty, Vyacheslav Kungurtsev, Jakub Marecek</p><p>Monte Carlo sampling is a powerful toolbox of algorithmic techniques widely
used for a number of applications wherein some noisy quantity, or summary
statistic thereof, is sought to be estimated. In this paper, we survey the
literature for implementing Monte Carlo procedures using quantum circuits,
focusing on the potential to obtain a quantum advantage in the computational
speed of these procedures. We revisit the quantum algorithms that could replace
classical Monte Carlo and then consider both the existing quantum algorithms
and the potential quantum realizations that include adaptive enhancements as
alternatives to the classical procedure.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Intallura_P/0/1/0/all/0/1">Philip Intallura</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Korpas_G/0/1/0/all/0/1">Georgios Korpas</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chakraborty_S/0/1/0/all/0/1">Sudeepto Chakraborty</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kungurtsev_V/0/1/0/all/0/1">Vyacheslav Kungurtsev</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Marecek_J/0/1/0/all/0/1">Jakub Marecek</a></p><p>Monte Carlo sampling is a powerful toolbox of algorithmic techniques widely
used for a number of applications wherein some noisy quantity, or summary
statistic thereof, is sought to be estimated. In this paper, we survey the
literature for implementing Monte Carlo procedures using quantum circuits,
focusing on the potential to obtain a quantum advantage in the computational
speed of these procedures. We revisit the quantum algorithms that could replace
classical Monte Carlo and then consider both the existing quantum algorithms
and the potential quantum realizations that include adaptive enhancements as
alternatives to the classical procedure.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05012'>Spatio-Temporal Trajectory Similarity Measures: A Comprehensive Survey and Quantitative Study</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Danlei Hu, Lu Chen, Hanxi Fang, Ziquan Fang, Tianyi Li, Yunjun Gao</p><p>Spatio-temporal trajectory analytics is at the core of smart mobility
solutions, which offers unprecedented information for diversified applications
such as urban planning, infrastructure development, and vehicular networks.
Trajectory similarity measure, which aims to evaluate the distance between two
trajectories, is a fundamental functionality of trajectory analytics. In this
paper, we propose a comprehensive survey that investigates all the most common
and representative spatio-temporal trajectory measures. First, we provide an
overview of spatio-temporal trajectory measures in terms of three hierarchical
perspectives: Non-learning vs. Learning, Free Space vs. Road Network, and
Standalone vs. Distributed. Next, we present an evaluation benchmark by
designing five real-world transformation scenarios. Based on this benchmark,
extensive experiments are conducted to study the effectiveness,
robustness,nefficiency, and scalability of each measure, which offers
guidelines for trajectory measure selection among multiple techniques and
applications such as trajectory data mining, deep learning, and distributed
processing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Danlei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1">Hanxi Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Ziquan Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yunjun Gao</a></p><p>Spatio-temporal trajectory analytics is at the core of smart mobility
solutions, which offers unprecedented information for diversified applications
such as urban planning, infrastructure development, and vehicular networks.
Trajectory similarity measure, which aims to evaluate the distance between two
trajectories, is a fundamental functionality of trajectory analytics. In this
paper, we propose a comprehensive survey that investigates all the most common
and representative spatio-temporal trajectory measures. First, we provide an
overview of spatio-temporal trajectory measures in terms of three hierarchical
perspectives: Non-learning vs. Learning, Free Space vs. Road Network, and
Standalone vs. Distributed. Next, we present an evaluation benchmark by
designing five real-world transformation scenarios. Based on this benchmark,
extensive experiments are conducted to study the effectiveness,
robustness,nefficiency, and scalability of each measure, which offers
guidelines for trajectory measure selection among multiple techniques and
applications such as trajectory data mining, deep learning, and distributed
processing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05067'>Robust optimization with belief functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marc Goerigk, Romain Guillaume, Adam Kasperski, Pawe&#x142; Zieli&#x144;ski</p><p>In this paper, an optimization problem with uncertain objective function
coefficients is considered. The uncertainty is specified by providing a
discrete scenario set, containing possible realizations of the objective
function coefficients. The concept of belief function in the traditional and
possibilistic setting is applied to define a set of admissible probability
distributions over the scenario set. The generalized Hurwicz criterion is then
used to compute a solution. In this paper, the complexity of the resulting
problem is explored. Some exact and approximation methods of solving it are
proposed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goerigk_M/0/1/0/all/0/1">Marc Goerigk</a>, <a href="http://arxiv.org/find/cs/1/au:+Guillaume_R/0/1/0/all/0/1">Romain Guillaume</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasperski_A/0/1/0/all/0/1">Adam Kasperski</a>, <a href="http://arxiv.org/find/cs/1/au:+Zielinski_P/0/1/0/all/0/1">Pawe&#x142; Zieli&#x144;ski</a></p><p>In this paper, an optimization problem with uncertain objective function
coefficients is considered. The uncertainty is specified by providing a
discrete scenario set, containing possible realizations of the objective
function coefficients. The concept of belief function in the traditional and
possibilistic setting is applied to define a set of admissible probability
distributions over the scenario set. The generalized Hurwicz criterion is then
used to compute a solution. In this paper, the complexity of the resulting
problem is explored. Some exact and approximation methods of solving it are
proposed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05250'>Distributed Half-Integral Matching and Beyond</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sameep Dahal, Jukka Suomela</p><p>By prior work, it is known that any distributed graph algorithm that finds a
maximal matching requires $\Omega(\log^* n)$ communication rounds, while it is
possible to find a maximal fractional matching in $O(1)$ rounds in
bounded-degree graphs. However, all prior $O(1)$-round algorithms for maximal
fractional matching use arbitrarily fine-grained fractional values. In
particular, none of them is able to find a half-integral solution, using only
values from $\{0, \frac12, 1\}$. We show that the use of fine-grained
fractional values is necessary, and moreover we give a complete
characterization on exactly how small values are needed: if we consider maximal
fractional matching in graphs of maximum degree $\Delta = 2d$, and any
distributed graph algorithm with round complexity $T(\Delta)$ that only depends
on $\Delta$ and is independent of $n$, we show that the algorithm has to use
fractional values with a denominator at least $2^d$. We give a new algorithm
that shows that this is also sufficient.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dahal_S/0/1/0/all/0/1">Sameep Dahal</a>, <a href="http://arxiv.org/find/cs/1/au:+Suomela_J/0/1/0/all/0/1">Jukka Suomela</a></p><p>By prior work, it is known that any distributed graph algorithm that finds a
maximal matching requires $\Omega(\log^* n)$ communication rounds, while it is
possible to find a maximal fractional matching in $O(1)$ rounds in
bounded-degree graphs. However, all prior $O(1)$-round algorithms for maximal
fractional matching use arbitrarily fine-grained fractional values. In
particular, none of them is able to find a half-integral solution, using only
values from $\{0, \frac12, 1\}$. We show that the use of fine-grained
fractional values is necessary, and moreover we give a complete
characterization on exactly how small values are needed: if we consider maximal
fractional matching in graphs of maximum degree $\Delta = 2d$, and any
distributed graph algorithm with round complexity $T(\Delta)$ that only depends
on $\Delta$ and is independent of $n$, we show that the algorithm has to use
fractional values with a denominator at least $2^d$. We give a new algorithm
that shows that this is also sufficient.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05327'>Direct Access for Answers to Conjunctive Queries with Aggregation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Idan Eldar, Nofar Carmeli, Benny Kimelfeld</p><p>We study the fine-grained complexity of conjunctive queries with grouping and
aggregation. For some common aggregate functions (e.g., min, max, count, sum),
such a query can be phrased as an ordinary conjunctive query over a database
annotated with a suitable commutative semiring. Specifically, we investigate
the ability to evaluate such queries by constructing in log-linear time a data
structure that provides logarithmic-time direct access to the answers ordered
by a given lexicographic order. This task is nontrivial since the number of
answers might be larger than log-linear in the size of the input, and so, the
data structure needs to provide a compact representation of the space of
answers.
</p>
<p>In the absence of aggregation and annotation, past research provides a
sufficient tractability condition on queries and orders. For queries without
self-joins, this condition is not just sufficient, but also necessary (under
conventional lower-bound assumptions in fine-grained complexity). We show that
all past results continue to hold for annotated databases, assuming that the
annotation itself is not part of the lexicographic order. On the other hand, we
show infeasibility for the case of count-distinct that does not have any
efficient representation as a commutative semiring. We then investigate the
ability to include the aggregate and annotation outcome in the lexicographic
order. Among the hardness results, standing out as tractable is the case of a
semiring with an idempotent addition, such as those of min and max. Notably,
this case captures also count-distinct over a logarithmic-size domain.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Eldar_I/0/1/0/all/0/1">Idan Eldar</a>, <a href="http://arxiv.org/find/cs/1/au:+Carmeli_N/0/1/0/all/0/1">Nofar Carmeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Kimelfeld_B/0/1/0/all/0/1">Benny Kimelfeld</a></p><p>We study the fine-grained complexity of conjunctive queries with grouping and
aggregation. For some common aggregate functions (e.g., min, max, count, sum),
such a query can be phrased as an ordinary conjunctive query over a database
annotated with a suitable commutative semiring. Specifically, we investigate
the ability to evaluate such queries by constructing in log-linear time a data
structure that provides logarithmic-time direct access to the answers ordered
by a given lexicographic order. This task is nontrivial since the number of
answers might be larger than log-linear in the size of the input, and so, the
data structure needs to provide a compact representation of the space of
answers.
</p>
<p>In the absence of aggregation and annotation, past research provides a
sufficient tractability condition on queries and orders. For queries without
self-joins, this condition is not just sufficient, but also necessary (under
conventional lower-bound assumptions in fine-grained complexity). We show that
all past results continue to hold for annotated databases, assuming that the
annotation itself is not part of the lexicographic order. On the other hand, we
show infeasibility for the case of count-distinct that does not have any
efficient representation as a commutative semiring. We then investigate the
ability to include the aggregate and annotation outcome in the lexicographic
order. Among the hardness results, standing out as tractable is the case of a
semiring with an idempotent addition, such as those of min and max. Notably,
this case captures also count-distinct over a logarithmic-size domain.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05336'>Elastic Founder Graphs Improved and Enhanced</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicola Rizzo, Massimo Equi, Tuukka Norri, Veli M&#xe4;kinen</p><p>Indexing labeled graphs for pattern matching is a central challenge of
pangenomics. Equi et al. (Algorithmica, 2022) developed the Elastic Founder
Graph ($\mathsf{EFG}$) representing an alignment of $m$ sequences of length
$n$, drawn from alphabet $\Sigma$ plus the special gap character: the paths
spell the original sequences or their recombination. By enforcing the
semi-repeat-free property, the $\mathsf{EFG}$ admits a polynomial-space index
for linear-time pattern matching, breaking through the conditional lower bounds
on indexing labeled graphs (Equi et al., SOFSEM 2021). In this work we improve
the space of the $\mathsf{EFG}$ index answering pattern matching queries in
linear time, from linear in the length of all strings spelled by three
consecutive node labels, to linear in the size of the edge labels. Then, we
develop linear-time construction algorithms optimizing for different metrics:
we improve the existing linearithmic construction algorithms to $O(mn)$, by
solving the novel exclusive ancestor set problem on trees; we propose, for the
simplified gapless setting, an $O(mn)$-time solution minimizing the maximum
block height, that we generalize by substituting block height with prefix-aware
height. Finally, to show the versatility of the framework, we develop a
BWT-based $\mathsf{EFG}$ index and study how to encode and perform document
listing queries on a set of paths of the graphs, reporting which paths present
a given pattern as a substring. We propose the $\mathsf{EFG}$ framework as an
improved and enhanced version of the framework for the gapless setting, along
with construction methods that are valid in any setting concerned with the
segmentation of aligned sequences.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rizzo_N/0/1/0/all/0/1">Nicola Rizzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Equi_M/0/1/0/all/0/1">Massimo Equi</a>, <a href="http://arxiv.org/find/cs/1/au:+Norri_T/0/1/0/all/0/1">Tuukka Norri</a>, <a href="http://arxiv.org/find/cs/1/au:+Makinen_V/0/1/0/all/0/1">Veli M&#xe4;kinen</a></p><p>Indexing labeled graphs for pattern matching is a central challenge of
pangenomics. Equi et al. (Algorithmica, 2022) developed the Elastic Founder
Graph ($\mathsf{EFG}$) representing an alignment of $m$ sequences of length
$n$, drawn from alphabet $\Sigma$ plus the special gap character: the paths
spell the original sequences or their recombination. By enforcing the
semi-repeat-free property, the $\mathsf{EFG}$ admits a polynomial-space index
for linear-time pattern matching, breaking through the conditional lower bounds
on indexing labeled graphs (Equi et al., SOFSEM 2021). In this work we improve
the space of the $\mathsf{EFG}$ index answering pattern matching queries in
linear time, from linear in the length of all strings spelled by three
consecutive node labels, to linear in the size of the edge labels. Then, we
develop linear-time construction algorithms optimizing for different metrics:
we improve the existing linearithmic construction algorithms to $O(mn)$, by
solving the novel exclusive ancestor set problem on trees; we propose, for the
simplified gapless setting, an $O(mn)$-time solution minimizing the maximum
block height, that we generalize by substituting block height with prefix-aware
height. Finally, to show the versatility of the framework, we develop a
BWT-based $\mathsf{EFG}$ index and study how to encode and perform document
listing queries on a set of paths of the graphs, reporting which paths present
a given pattern as a substring. We propose the $\mathsf{EFG}$ framework as an
improved and enhanced version of the framework for the gapless setting, along
with construction methods that are valid in any setting concerned with the
segmentation of aligned sequences.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05408'>Fast algorithms for Vizing's theorem on bounded degree graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anton Bernshteyn, Abhishek Dhawan</p><p>Vizing's theorem states that every graph $G$ of maximum degree $\Delta$ can
be properly edge-colored using $\Delta + 1$ colors. The fastest currently known
$(\Delta+1)$-edge-coloring algorithm for general graphs is due to Sinnamon and
runs in time $O(m\sqrt{n})$, where $n = |V(G)|$ and $m =|E(G)|$. Using the
bound $m \leq \Delta n/2$, the running time of Sinnamon's algorithm can be
expressed as $O(\Delta n^{3/2})$. In the regime when $\Delta$ is considerably
smaller than $n$ (for instance, when $\Delta$ is a constant), this can be
improved, as Gabow, Nishizeki, Kariv, Leven, and Terada designed an algorithm
with running time $O(\Delta m \log n) = O(\Delta^2 n \log n)$. Here we give an
algorithm whose running time is only linear in $n$ (which is obviously best
possible) and polynomial in $\Delta$. We also develop new algorithms for
$(\Delta+1)$-edge-coloring in the $\mathsf{LOCAL}$ model of distributed
computation. Namely, we design a deterministic $\mathsf{LOCAL}$ algorithm with
running time $\mathsf{poly}(\Delta, \log\log n) \log^5 n$ and a randomized
$\mathsf{LOCAL}$ algorithm with running time $\mathsf{poly}(\Delta) \log^2 n$.
The key new ingredient in our algorithms is a novel application of the entropy
compression method.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bernshteyn_A/0/1/0/all/0/1">Anton Bernshteyn</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhawan_A/0/1/0/all/0/1">Abhishek Dhawan</a></p><p>Vizing's theorem states that every graph $G$ of maximum degree $\Delta$ can
be properly edge-colored using $\Delta + 1$ colors. The fastest currently known
$(\Delta+1)$-edge-coloring algorithm for general graphs is due to Sinnamon and
runs in time $O(m\sqrt{n})$, where $n = |V(G)|$ and $m =|E(G)|$. Using the
bound $m \leq \Delta n/2$, the running time of Sinnamon's algorithm can be
expressed as $O(\Delta n^{3/2})$. In the regime when $\Delta$ is considerably
smaller than $n$ (for instance, when $\Delta$ is a constant), this can be
improved, as Gabow, Nishizeki, Kariv, Leven, and Terada designed an algorithm
with running time $O(\Delta m \log n) = O(\Delta^2 n \log n)$. Here we give an
algorithm whose running time is only linear in $n$ (which is obviously best
possible) and polynomial in $\Delta$. We also develop new algorithms for
$(\Delta+1)$-edge-coloring in the $\mathsf{LOCAL}$ model of distributed
computation. Namely, we design a deterministic $\mathsf{LOCAL}$ algorithm with
running time $\mathsf{poly}(\Delta, \log\log n) \log^5 n$ and a randomized
$\mathsf{LOCAL}$ algorithm with running time $\mathsf{poly}(\Delta) \log^2 n$.
The key new ingredient in our algorithms is a novel application of the entropy
compression method.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T00:30:00Z">Friday, March 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, March 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://processalgebra.blogspot.com/2023/03/ten-fully-funded-phd-positions-in.html'>Ten fully-funded PhD positions in Computer Science at the Gran Sasso Science Institute</a></h3>
        <p class='tr-article-feed'>from <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>The Computer Science group at the GSSI has ten fully-funded PhD positions. See the call for applications for details. The deadline for applications is 30 May 2023. <br></p><p>The Computer Science group at the GSSI provides an excellent environment for PhD students and its group has been ranked as "excellent" by a recent national research assessment exercise. In my, admittedly biased, opinion, it is one of the places to be for research in Computer Science in Italy. </p><p>Spread the news! <br></p><p>&nbsp;<br></p><p>By Luca Aceto</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Computer Science group at the GSSI has ten fully-funded PhD positions. See the <a href="https://www.gssi.it/albo-ufficiale-online-gssi/item/download/4164_c550280ade939db61570a29ef700f63e" target="_blank">call for applications</a> for details. The deadline for applications is 30 May 2023. <br /></p><p>The <a href="https://sites.google.com/gssi.it/csgssi" target="_blank">Computer Science group at the GSSI</a> provides an excellent environment for PhD students and its group has been ranked as <a href="https://processalgebra.blogspot.com/2022/12/computer-science-and-mathematics-at.html" target="_blank">"excellent"</a> by a recent national research assessment exercise. In my, admittedly biased, opinion, it is one of the places to be for research in Computer Science in Italy. </p><p>Spread the news! <br /></p><p>&nbsp;<br /></p><p class="authors">By Luca Aceto</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T13:49:00Z">Thursday, March 09 2023, 13:49</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7094'>The False Promise of Chomskyism</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Important Update (March 10): On deeper reflection, I probably don&#8217;t need to spend emotional energy refuting people like Chomsky, who believe that Large Language Models are just a laughable fad rather than a step-change in how humans can and will use technology, any more than I would&#8217;ve needed to spend it refuting those who said [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Important Update (March 10):</mark></strong> On deeper reflection, I probably don&#8217;t <em>need</em> to spend emotional energy refuting people like Chomsky, who believe that Large Language Models are just a laughable fad rather than a step-change in how humans can and will use technology, any more than I would&#8217;ve needed to spend it refuting those who said the same about the World Wide Web in 1993.  Yes, they&#8217;re wrong, and yes, despite being wrong they&#8217;re self-certain, hostile, and smug, and yes I can see this, and yes it angers me.  But the world is going to make the argument for me.  And if not the world, <a href="https://twitter.com/SebastienBubeck/status/1634009568341622784/photo/1">Bing already does a perfectly serviceable job</a> at refuting Chomsky&#8217;s points (h/t Sebastien Bubeck via Boaz Barak).</p>



<p>Meanwhile, out there in reality, <a href="https://southpark.cc.com/episodes/8byci4/south-park-deep-learning-season-26-ep-4?fbclid=IwAR0hxxqhxF3jsMu7EZvGqJYmFruseZTNL_7W_8i_Y7dfhDYhmMoc9KOYWco">last night&#8217;s <em>South Park</em> episode</a> does a <em>much</em> better job than most academic thinkpieces at exploring how ordinary people are going to respond (and have already responded) to the availability of ChatGPT.  It will <em>not</em>, to put it mildly, be with sneering Chomskyan disdain, whether the effects on the world are for good or ill or (most likely) both.  Among other things&#8212;I don&#8217;t want to give away too much!&#8212;this episode prominently features a soothsayer accompanied by a bird that caws whenever it detects GPT-generated text.  Now why didn&#8217;t I think of that in preference to cryptographic watermarking??</p>



<p><strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Another Update (March 11)</mark></strong>: To my astonishment and delight, even many of the <em>anti</em>-LLM AI experts are refusing to defend Chomskyâs attack-piece.  Thatâs the one important point about which I stand corrected!</p>



<p><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color"><strong>Another Update (March 12):</strong></mark> âAs a Professor of Linguistics myself, I find it a little sad that someone who while young was a profound innovator in linguistics and more is now conservatively trying to block exciting new approaches.â â<a href="https://mobile.twitter.com/chrmanning/status/1633873660221218816">Christopher Manning</a></p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>I was asked to respond to the <em>New York Times</em> opinion piece entitled <a href="https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html">The False Promise of ChatGPT</a>, by Noam Chomsky along with Ian Roberts and Jeffrey Watumull (who once took my class at MIT).  I&#8217;ll be busy all day at the Harvard CS department, where I&#8217;m <a href="https://events.seas.harvard.edu/event/how_much_information_is_in_a_quantum_state">giving a quantum talk</a> this afternoon. <strong>[Added: Several commenters complained that they found this sentence &#8220;condescending,&#8221; but I&#8217;m not sure what exactly they wanted me to say&#8212;that I was visiting some school in Cambridge, MA, two T stops from the school where Chomsky works and I used to work?]</strong></p>



<p>But for now:</p>



<p>In this piece Chomsky, the intellectual godfather god of an effort that failed for 60 years to build machines that can converse in ordinary language, condemns the effort that succeeded.  <strong>[Added: Please, <em>please</em> stop writing that I must be an ignoramus since I don&#8217;t even know that Chomsky has never worked on AI.  I know perfectly well that he hasn&#8217;t, and meant only that he tends to be regarded as authoritative <em>by</em> the &#8220;don&#8217;t-look-through-the-telescope&#8221; AI faction, the ones views he himself fully endorses in his attack-piece.  If you don&#8217;t know the relevant history, <a href="https://norvig.com/chomsky.html">read Norvig</a>.]</strong></p>



<p>Chomsky condemns ChatGPT for four reasons:</p>



<ol>
<li>because it could, in principle, misinterpret sentences that could also be sentence fragments, like &#8220;John is too stubborn to talk to&#8221; (bizarrely, he never checks whether it <em>does</em> misinterpret it&#8212;I just tried it this morning and it seems to decide correctly based on context whether it&#8217;s a sentence or a sentence fragment, much like I would!);</li>



<li>because it doesnât learn the way humans do (personally, I think ChatGPT and other large language models have <em>massively</em> illuminated at least one component of the human language faculty, what you could call its <a href="https://en.wikipedia.org/wiki/Predictive_coding">predictive coding</a> component, though clearly not all of it);</li>



<li>because it could learn false facts or grammatical systems if fed false training data (how could it be otherwise?); and</li>



<li>most of all because itâs âamoral,â refusing to take a stand on potentially controversial issues (he gives an example involving the ethics of terraforming Mars).</li>
</ol>



<p>This last, of course, is a <em>choice</em>, imposed by OpenAI using reinforcement learning.  The reason for it is simply that ChatGPT is a consumer product.  The same people who condemn it for not taking controversial stands would condemn it much more loudly if it did â just like the same people who condemn it for wrong answers and explanations, would condemn it equally for right ones (Chomsky promises as much in the essay).</p>



<p>I submit that, like the Jesuit astronomers declining to look through Galileoâs telescope, what Chomsky and his followers are ultimately angry at is reality itself, for having the temerity to offer something up that they didnât predict and that doesnât fit their worldview.</p>



<p>[<em>Note for people who might be visiting this blog for the first time:</em> I&#8217;m a CS professor at UT Austin, on leave for one year to work at OpenAI on the theoretical foundations of AI safety.  I accepted OpenAI&#8217;s offer in part because I already held the views here, or something close to them; and given that I could see how large language models were poised to change the world for good and ill, I wanted to be part of the effort to help prevent their misuse.  No one at OpenAI asked me to write this or saw it beforehand, and I don&#8217;t even know to what extent they agree with it.]</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T12:01:55Z">Thursday, March 09 2023, 12:01</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/021'>TR23-021 |  Range Avoidance for Constant-Depth Circuits: Hardness and Algorithms | 

	Sidhant Saraogi, 

	Alexander Golovnev, 

	Satyajeet Nagargoje, 

	Karthik Gajulapalli</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Range Avoidance (AVOID) is a total search problem where, given a Boolean circuit $C\colon\{0,1\}^n\to\{0,1\}^m$, $m&gt;n$, the task is to find a $y\in\{0,1\}^m$ outside the range of $C$. For an integer $k\geq 2$, $NC^0_k$-AVOID is a special case of AVOID where each output bit of $C$ depends on at most $k$ input bits. Ren, Santhanam, and Wang (FOCS 2022) and Guruswami, Lyu, and Wang (RANDOM 2022) proved that explicit constructions of functions of high circuit complexity, rigid matrices, optimal linear codes, Ramsey graphs, and other combinatorial objects reduce to $NC^0_4$-AVOID, thus establishing conditional hardness of the $NC^0_4$-AVOID problem. On the other hand, $NC^0_2$-AVOID admits polynomial-time algorithms, leaving the question about the complexity of $NC^0_3$-AVOID open.

We give the first reduction of an explicit construction question to $NC^0_3$-AVOID. Specifically, we prove that a polynomial-time algorithm (with an $NP$ oracle) for $NC^0_3$-AVOID for the case of $m=n+n^{2/3}$ would imply an explicit construction of a rigid matrix, and, thus, a super-linear lower bound on the size of log-depth circuits.

We also give deterministic polynomial-time algorithms for all $NC^0_k$-AVOID problems for ${m\geq n^{k-1}/\log(n)}$. Prior work required an $NP$ oracle, and required larger stretch, $m \geq n^{k-1}$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Range Avoidance (AVOID) is a total search problem where, given a Boolean circuit $C\colon\{0,1\}^n\to\{0,1\}^m$, $m&gt;n$, the task is to find a $y\in\{0,1\}^m$ outside the range of $C$. For an integer $k\geq 2$, $NC^0_k$-AVOID is a special case of AVOID where each output bit of $C$ depends on at most $k$ input bits. Ren, Santhanam, and Wang (FOCS 2022) and Guruswami, Lyu, and Wang (RANDOM 2022) proved that explicit constructions of functions of high circuit complexity, rigid matrices, optimal linear codes, Ramsey graphs, and other combinatorial objects reduce to $NC^0_4$-AVOID, thus establishing conditional hardness of the $NC^0_4$-AVOID problem. On the other hand, $NC^0_2$-AVOID admits polynomial-time algorithms, leaving the question about the complexity of $NC^0_3$-AVOID open.

We give the first reduction of an explicit construction question to $NC^0_3$-AVOID. Specifically, we prove that a polynomial-time algorithm (with an $NP$ oracle) for $NC^0_3$-AVOID for the case of $m=n+n^{2/3}$ would imply an explicit construction of a rigid matrix, and, thus, a super-linear lower bound on the size of log-depth circuits.

We also give deterministic polynomial-time algorithms for all $NC^0_k$-AVOID problems for ${m\geq n^{k-1}/\log(n)}$. Prior work required an $NP$ oracle, and required larger stretch, $m \geq n^{k-1}$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T09:26:46Z">Thursday, March 09 2023, 09:26</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04298'>Classical vs Quantum Advice under Classically-Accessible Oracle</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xingjian Li, Qipeng Liu, Angelos Pelecanos, Takashi Yamakawa</p><p>It is a long-standing open question to construct a classical oracle relative
to which BQP/qpoly $\neq$ BQP/poly or QMA $\neq$ QCMA. In this paper, we
construct classically-accessible classical oracles relative to which BQP/qpoly
$\neq$ BQP/poly. Here, classically-accessible classical oracles are oracles
that can be accessed only classically even for quantum algorithms. Based on a
similar technique, we also show an alternative proof for separation of QMA and
QCMA relative to a distributional quantumly-accessible classical oracles, which
was recently shown by Natarajan and Nirkhe.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Li_X/0/1/0/all/0/1">Xingjian Li</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Liu_Q/0/1/0/all/0/1">Qipeng Liu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Pelecanos_A/0/1/0/all/0/1">Angelos Pelecanos</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yamakawa_T/0/1/0/all/0/1">Takashi Yamakawa</a></p><p>It is a long-standing open question to construct a classical oracle relative
to which BQP/qpoly $\neq$ BQP/poly or QMA $\neq$ QCMA. In this paper, we
construct classically-accessible classical oracles relative to which BQP/qpoly
$\neq$ BQP/poly. Here, classically-accessible classical oracles are oracles
that can be accessed only classically even for quantum algorithms. Based on a
similar technique, we also show an alternative proof for separation of QMA and
QCMA relative to a distributional quantumly-accessible classical oracles, which
was recently shown by Natarajan and Nirkhe.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04613'>The Descriptive Complexity of Graph Neural Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Martin Grohe</p><p>We analyse the power of graph neural networks (GNNs) in terms of Boolean
circuit complexity and descriptive complexity.
</p>
<p>We prove that the graph queries that can be computed by a polynomial-size
bounded-depth family of GNNs are exactly those definable in the guarded
fragment GFO+C of first-order logic with counting and with built-in relations.
This puts GNNs in the circuit complexity class TC^0. Remarkably, the GNN
families may use arbitrary real weights and a wide class of activation
functions that includes the standard ReLU, logistic "sigmoid", and hyperbolic
tangent functions. If the GNNs are allowed to use random initialisation and
global readout (both standard features of GNNs widely used in practice), they
can compute exactly the same queries as bounded depth Boolean circuits with
threshold gates, that is, exactly the queries in TC^0. Moreover, we show that
queries computable by a single GNN with piecewise linear activations and
rational weights are definable in GFO+C without built-in relations. Therefore,
they are contained in uniform TC^0.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1">Martin Grohe</a></p><p>We analyse the power of graph neural networks (GNNs) in terms of Boolean
circuit complexity and descriptive complexity.
</p>
<p>We prove that the graph queries that can be computed by a polynomial-size
bounded-depth family of GNNs are exactly those definable in the guarded
fragment GFO+C of first-order logic with counting and with built-in relations.
This puts GNNs in the circuit complexity class TC^0. Remarkably, the GNN
families may use arbitrary real weights and a wide class of activation
functions that includes the standard ReLU, logistic "sigmoid", and hyperbolic
tangent functions. If the GNNs are allowed to use random initialisation and
global readout (both standard features of GNNs widely used in practice), they
can compute exactly the same queries as bounded depth Boolean circuits with
threshold gates, that is, exactly the queries in TC^0. Moreover, we show that
queries computable by a single GNN with piecewise linear activations and
rational weights are definable in GFO+C without built-in relations. Therefore,
they are contained in uniform TC^0.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04350'>Improved Bounds for Covering Paths and Trees in the Plane</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ahmad Biniaz</p><p>A covering path for a planar point set is a path drawn in the plane with
straight-line edges such that every point lies at a vertex or on an edge of the
path. A covering tree is defined analogously. Let $\pi(n)$ be the minimum
number such that every set of $n$ points in the plane can be covered by a
noncrossing path with at most $\pi(n)$ edges. Let $\tau(n)$ be the analogous
number for noncrossing covering trees. Dumitrescu, Gerbner, Keszegh, and T\'oth
(Discrete &amp; Computational Geometry, 2014) established the following
inequalities: \[\frac{5n}{9} - O(1) &lt; \pi(n) &lt;
\left(1-\frac{1}{601080391}\right)n, \quad\text{and} \quad\frac{9n}{17} - O(1)
&lt; \tau(n)\leqslant \left\lfloor\frac{5n}{6}\right\rfloor.\] We report the
following improved upper bounds: \[\pi(n)\leqslant
\left(1-\frac{1}{22}\right)n, \quad\text{and}\quad \tau(n)\leqslant
\left\lceil\frac{4n}{5}\right\rceil.\]
</p>
<p>In the same context we study rainbow polygons. For a set of colored points in
the plane, a perfect rainbow polygon is a simple polygon that contains exactly
one point of each color in its interior or on its boundary. Let $\rho(k)$ be
the minimum number such that every $k$-colored point set in the plane admits a
perfect rainbow polygon of size $\rho(k)$. Flores-Pe\~naloza, Kano,
Mart\'inez-Sandoval, Orden, Tejel, T\'oth, Urrutia, and Vogtenhuber (Discrete
Mathematics, 2021) proved that $20k/19 - O(1) &lt;\rho(k) &lt; 10k/7 + O(1).$ We
report the improved upper bound $\rho(k)&lt; 7k/5 + O(1)$.
</p>
<p>To obtain the improved bounds we present simple $O(n\log n)$-time algorithms
that achieve paths, trees, and polygons with our desired number of edges.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Biniaz_A/0/1/0/all/0/1">Ahmad Biniaz</a></p><p>A covering path for a planar point set is a path drawn in the plane with
straight-line edges such that every point lies at a vertex or on an edge of the
path. A covering tree is defined analogously. Let $\pi(n)$ be the minimum
number such that every set of $n$ points in the plane can be covered by a
noncrossing path with at most $\pi(n)$ edges. Let $\tau(n)$ be the analogous
number for noncrossing covering trees. Dumitrescu, Gerbner, Keszegh, and T\'oth
(Discrete &amp; Computational Geometry, 2014) established the following
inequalities: \[\frac{5n}{9} - O(1) &lt; \pi(n) &lt;
\left(1-\frac{1}{601080391}\right)n, \quad\text{and} \quad\frac{9n}{17} - O(1)
&lt; \tau(n)\leqslant \left\lfloor\frac{5n}{6}\right\rfloor.\] We report the
following improved upper bounds: \[\pi(n)\leqslant
\left(1-\frac{1}{22}\right)n, \quad\text{and}\quad \tau(n)\leqslant
\left\lceil\frac{4n}{5}\right\rceil.\]
</p>
<p>In the same context we study rainbow polygons. For a set of colored points in
the plane, a perfect rainbow polygon is a simple polygon that contains exactly
one point of each color in its interior or on its boundary. Let $\rho(k)$ be
the minimum number such that every $k$-colored point set in the plane admits a
perfect rainbow polygon of size $\rho(k)$. Flores-Pe\~naloza, Kano,
Mart\'inez-Sandoval, Orden, Tejel, T\'oth, Urrutia, and Vogtenhuber (Discrete
Mathematics, 2021) proved that $20k/19 - O(1) &lt;\rho(k) &lt; 10k/7 + O(1).$ We
report the improved upper bound $\rho(k)&lt; 7k/5 + O(1)$.
</p>
<p>To obtain the improved bounds we present simple $O(n\log n)$-time algorithms
that achieve paths, trees, and polygons with our desired number of edges.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04722'>B-Treaps Revised: Write Efficient Randomized Block Search Trees with High Load</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Roodabeh Safavi, Martin P. Seybold</p><p>Uniquely represented data structures represent each logical state with a
unique storage state. We study the problem of maintaining a dynamic set of $n$
keys from a totally ordered universe in this context.
</p>
<p>We introduce a two-layer data structure called
$(\alpha,\varepsilon)$-Randomized Block Search Tree (RBST) that is uniquely
represented and suitable for external memory. Though RBSTs naturally generalize
the well-known binary Treaps, several new ideas are needed to analyze the {\em
expected} search, update, and storage, efficiency in terms of block-reads,
block-writes, and blocks stored. We prove that searches have
$O(\varepsilon^{-1} + \log_\alpha n)$ block-reads, that $(\alpha,
\varepsilon)$-RBSTs have an asymptotic load-factor of at least
$(1-\varepsilon)$ for every $\varepsilon \in (0,1/2]$, and that dynamic updates
perform $O(\varepsilon^{-1} + \log_\alpha(n)/\alpha)$ block-writes, i.e.
$O(1/\varepsilon)$ writes if $\alpha=\Omega(\frac{\log n}{\log \log n} )$. Thus
$(\alpha, \varepsilon)$-RBSTs provide improved search, storage-, and
write-efficiency bounds in regard to the known, uniquely represented B-Treap
[Golovin; ICALP'09].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Safavi_R/0/1/0/all/0/1">Roodabeh Safavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Seybold_M/0/1/0/all/0/1">Martin P. Seybold</a></p><p>Uniquely represented data structures represent each logical state with a
unique storage state. We study the problem of maintaining a dynamic set of $n$
keys from a totally ordered universe in this context.
</p>
<p>We introduce a two-layer data structure called
$(\alpha,\varepsilon)$-Randomized Block Search Tree (RBST) that is uniquely
represented and suitable for external memory. Though RBSTs naturally generalize
the well-known binary Treaps, several new ideas are needed to analyze the {\em
expected} search, update, and storage, efficiency in terms of block-reads,
block-writes, and blocks stored. We prove that searches have
$O(\varepsilon^{-1} + \log_\alpha n)$ block-reads, that $(\alpha,
\varepsilon)$-RBSTs have an asymptotic load-factor of at least
$(1-\varepsilon)$ for every $\varepsilon \in (0,1/2]$, and that dynamic updates
perform $O(\varepsilon^{-1} + \log_\alpha(n)/\alpha)$ block-writes, i.e.
$O(1/\varepsilon)$ writes if $\alpha=\Omega(\frac{\log n}{\log \log n} )$. Thus
$(\alpha, \varepsilon)$-RBSTs provide improved search, storage-, and
write-efficiency bounds in regard to the known, uniquely represented B-Treap
[Golovin; ICALP'09].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04199'>Diversity Embeddings and the Hypergraph Sparsest Cut</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adam D. Jozefiak, F. Bruce Shepherd</p><p>Good approximations have been attained for the sparsest cut problem by
rounding solutions to convex relaxations via low-distortion metric embeddings.
Recently, Bryant and Tupper showed that this approach extends to the hypergraph
setting by formulating a linear program whose solutions are so-called
diversities which are rounded via diversity embeddings into $\ell_1$.
Diversities are a generalization of metric spaces in which the nonnegative
function is defined on all subsets as opposed to only on pairs of elements.
</p>
<p>We show that this approach yields a polytime $O(\log{n})$-approximation when
either the supply or demands are given by a graph. This result improves upon
Plotkin et al.'s $O(\log{(kn)}\log{n})$-approximation, where $k$ is the number
of demands, for the setting where the supply is given by a graph and the
demands are given by a hypergraph. Additionally, we provide a polytime
$O(\min{\{r_G,r_H\}}\log{r_H}\log{n})$-approximation for when the supply and
demands are given by hypergraphs whose hyperedges are bounded in cardinality by
$r_G$ and $r_H$ respectively.
</p>
<p>To establish these results we provide an $O(\log{n})$-distortion $\ell_1$
embedding for the class of diversities known as diameter diversities. This
improves upon Bryant and Tupper's $O(\log\^2{n})$-distortion embedding. The
smallest known distortion with which an arbitrary diversity can be embedded
into $\ell_1$ is $O(n)$. We show that for any $\epsilon &gt; 0$ and any $p&gt;0$,
there is a family of diversities which cannot be embedded into $\ell_1$ in
polynomial time with distortion smaller than $O(n^{1-\epsilon})$ based on
querying the diversities on sets of cardinality at most $O(\log^p{n})$, unless
$P=NP$. This disproves (an algorithmic refinement of) Bryant and Tupper's
conjecture that there exists an $O(\sqrt{n})$-distortion $\ell_1$ embedding
based off a diversity's induced metric.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jozefiak_A/0/1/0/all/0/1">Adam D. Jozefiak</a>, <a href="http://arxiv.org/find/cs/1/au:+Shepherd_F/0/1/0/all/0/1">F. Bruce Shepherd</a></p><p>Good approximations have been attained for the sparsest cut problem by
rounding solutions to convex relaxations via low-distortion metric embeddings.
Recently, Bryant and Tupper showed that this approach extends to the hypergraph
setting by formulating a linear program whose solutions are so-called
diversities which are rounded via diversity embeddings into $\ell_1$.
Diversities are a generalization of metric spaces in which the nonnegative
function is defined on all subsets as opposed to only on pairs of elements.
</p>
<p>We show that this approach yields a polytime $O(\log{n})$-approximation when
either the supply or demands are given by a graph. This result improves upon
Plotkin et al.'s $O(\log{(kn)}\log{n})$-approximation, where $k$ is the number
of demands, for the setting where the supply is given by a graph and the
demands are given by a hypergraph. Additionally, we provide a polytime
$O(\min{\{r_G,r_H\}}\log{r_H}\log{n})$-approximation for when the supply and
demands are given by hypergraphs whose hyperedges are bounded in cardinality by
$r_G$ and $r_H$ respectively.
</p>
<p>To establish these results we provide an $O(\log{n})$-distortion $\ell_1$
embedding for the class of diversities known as diameter diversities. This
improves upon Bryant and Tupper's $O(\log\^2{n})$-distortion embedding. The
smallest known distortion with which an arbitrary diversity can be embedded
into $\ell_1$ is $O(n)$. We show that for any $\epsilon &gt; 0$ and any $p&gt;0$,
there is a family of diversities which cannot be embedded into $\ell_1$ in
polynomial time with distortion smaller than $O(n^{1-\epsilon})$ based on
querying the diversities on sets of cardinality at most $O(\log^p{n})$, unless
$P=NP$. This disproves (an algorithmic refinement of) Bryant and Tupper's
conjecture that there exists an $O(\sqrt{n})$-distortion $\ell_1$ embedding
based off a diversity's induced metric.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04205'>Investigating the complexity of the double distance problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marilia D. V. Braga, Leonie R. Brockmann, Katharina Klerx, Jens Stoye</p><p>Two genomes over the same set of gene families form a canonical pair when
each of them has exactly one gene from each family. Different distances of
canonical genomes can be derived from a structure called breakpoint graph,
which represents the relation between the two given genomes as a collection of
cycles of even length and paths. Then, the breakpoint distance is equal to n -
(c_2 + p_0/2), where n is the number of genes, c_2 is the number of cycles of
length 2 and p_0 is the number of paths of length 0. Similarly, when the
considered rearrangements are those modeled by the double-cut-and-join (DCJ)
operation, the rearrangement distance is n - (c + p_e/2), where c is the total
number of cycles and p_e is the total number of even paths.
</p>
<p>The distance formulation is a basic unit for several other combinatorial
problems related to genome evolution and ancestral reconstruction, such as
median or double distance. Interestingly, both median and double distance
problems can be solved in polynomial time for the breakpoint distance, while
they are NP-hard for the rearrangement distance. One way of exploring the
complexity space between these two extremes is to consider the {\sigma}_k
distance, defined to be n - [c_2 + c_4 + ... + c_k + (p_0 + p_2 + ... +p_k)/2],
and increasingly investigate the complexities of median and double distance for
the {\sigma}_4 distance, then the {\sigma}_6 distance, and so on. While for the
median much effort was done in our and in other research groups but no progress
was obtained even for the {\sigma}_4 distance, for solving the double distance
under {\sigma}_4 and {\sigma}_6 distances we could devise linear time
algorithms, which we present here.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Braga_M/0/1/0/all/0/1">Marilia D. V. Braga</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockmann_L/0/1/0/all/0/1">Leonie R. Brockmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Klerx_K/0/1/0/all/0/1">Katharina Klerx</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoye_J/0/1/0/all/0/1">Jens Stoye</a></p><p>Two genomes over the same set of gene families form a canonical pair when
each of them has exactly one gene from each family. Different distances of
canonical genomes can be derived from a structure called breakpoint graph,
which represents the relation between the two given genomes as a collection of
cycles of even length and paths. Then, the breakpoint distance is equal to n -
(c_2 + p_0/2), where n is the number of genes, c_2 is the number of cycles of
length 2 and p_0 is the number of paths of length 0. Similarly, when the
considered rearrangements are those modeled by the double-cut-and-join (DCJ)
operation, the rearrangement distance is n - (c + p_e/2), where c is the total
number of cycles and p_e is the total number of even paths.
</p>
<p>The distance formulation is a basic unit for several other combinatorial
problems related to genome evolution and ancestral reconstruction, such as
median or double distance. Interestingly, both median and double distance
problems can be solved in polynomial time for the breakpoint distance, while
they are NP-hard for the rearrangement distance. One way of exploring the
complexity space between these two extremes is to consider the {\sigma}_k
distance, defined to be n - [c_2 + c_4 + ... + c_k + (p_0 + p_2 + ... +p_k)/2],
and increasingly investigate the complexities of median and double distance for
the {\sigma}_4 distance, then the {\sigma}_6 distance, and so on. While for the
median much effort was done in our and in other research groups but no progress
was obtained even for the {\sigma}_4 distance, for solving the double distance
under {\sigma}_4 and {\sigma}_6 distances we could devise linear time
algorithms, which we present here.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04288'>Polynomial Time and Private Learning of Unbounded Gaussian Mixture Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jamil Arbas, Hassan Ashtiani, Christopher Liaw</p><p>We study the problem of privately estimating the parameters of
$d$-dimensional Gaussian Mixture Models (GMMs) with $k$ components. For this,
we develop a technique to reduce the problem to its non-private counterpart.
This allows us to privatize existing non-private algorithms in a blackbox
manner, while incurring only a small overhead in the sample complexity and
running time. As the main application of our framework, we develop an
$(\varepsilon, \delta)$-differentially private algorithm to learn GMMs using
the non-private algorithm of Moitra and Valiant [MV10] as a blackbox.
Consequently, this gives the first sample complexity upper bound and first
polynomial time algorithm for privately learning GMMs without any boundedness
assumptions on the parameters.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Arbas_J/0/1/0/all/0/1">Jamil Arbas</a>, <a href="http://arxiv.org/find/stat/1/au:+Ashtiani_H/0/1/0/all/0/1">Hassan Ashtiani</a>, <a href="http://arxiv.org/find/stat/1/au:+Liaw_C/0/1/0/all/0/1">Christopher Liaw</a></p><p>We study the problem of privately estimating the parameters of
$d$-dimensional Gaussian Mixture Models (GMMs) with $k$ components. For this,
we develop a technique to reduce the problem to its non-private counterpart.
This allows us to privatize existing non-private algorithms in a blackbox
manner, while incurring only a small overhead in the sample complexity and
running time. As the main application of our framework, we develop an
$(\varepsilon, \delta)$-differentially private algorithm to learn GMMs using
the non-private algorithm of Moitra and Valiant [MV10] as a blackbox.
Consequently, this gives the first sample complexity upper bound and first
polynomial time algorithm for privately learning GMMs without any boundedness
assumptions on the parameters.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04301'>Optimal Sparse Recovery with Decision Stumps</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kiarash Banihashem, MohammadTaghi Hajiaghayi, Max Springer</p><p>Decision trees are widely used for their low computational cost, good
predictive performance, and ability to assess the importance of features.
Though often used in practice for feature selection, the theoretical guarantees
of these methods are not well understood. We here obtain a tight finite sample
bound for the feature selection problem in linear regression using single-depth
decision trees. We examine the statistical properties of these "decision
stumps" for the recovery of the $s$ active features from $p$ total features,
where $s \ll p$. Our analysis provides tight sample performance guarantees on
high-dimensional sparse systems which align with the finite sample bound of
$O(s \log p)$ as obtained by Lasso, improving upon previous bounds for both the
median and optimal splitting criteria. Our results extend to the non-linear
regime as well as arbitrary sub-Gaussian distributions, demonstrating that tree
based methods attain strong feature selection properties under a wide variety
of settings and further shedding light on the success of these methods in
practice. As a byproduct of our analysis, we show that we can provably
guarantee recovery even when the number of active features $s$ is unknown. We
further validate our theoretical results and proof methodology using
computational experiments.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Banihashem_K/0/1/0/all/0/1">Kiarash Banihashem</a>, <a href="http://arxiv.org/find/stat/1/au:+Hajiaghayi_M/0/1/0/all/0/1">MohammadTaghi Hajiaghayi</a>, <a href="http://arxiv.org/find/stat/1/au:+Springer_M/0/1/0/all/0/1">Max Springer</a></p><p>Decision trees are widely used for their low computational cost, good
predictive performance, and ability to assess the importance of features.
Though often used in practice for feature selection, the theoretical guarantees
of these methods are not well understood. We here obtain a tight finite sample
bound for the feature selection problem in linear regression using single-depth
decision trees. We examine the statistical properties of these "decision
stumps" for the recovery of the $s$ active features from $p$ total features,
where $s \ll p$. Our analysis provides tight sample performance guarantees on
high-dimensional sparse systems which align with the finite sample bound of
$O(s \log p)$ as obtained by Lasso, improving upon previous bounds for both the
median and optimal splitting criteria. Our results extend to the non-linear
regime as well as arbitrary sub-Gaussian distributions, demonstrating that tree
based methods attain strong feature selection properties under a wide variety
of settings and further shedding light on the success of these methods in
practice. As a byproduct of our analysis, we show that we can provably
guarantee recovery even when the number of active features $s$ is unknown. We
further validate our theoretical results and proof methodology using
computational experiments.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04478'>Change a Bit to save Bytes: Compression for Floating Point Time-Series Data</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Francesco Taurone, Daniel E. Lucani, Marcell Feh&#xe9;r, Qi Zhang</p><p>The number of IoT devices is expected to continue its dramatic growth in the
coming years and, with it, a growth in the amount of data to be transmitted,
processed and stored. Compression techniques that support analytics directly on
the compressed data could pave the way for systems to scale efficiently to
these growing demands. This paper proposes two novel methods for preprocessing
a stream of floating point data to improve the compression capabilities of
various IoT data compressors. In particular, these techniques are shown to be
helpful with recent compressors that allow for random access and analytics
while maintaining good compression. Our techniques improve compression with
reductions up to 80% when allowing for at most 1% of recovery error.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Taurone_F/0/1/0/all/0/1">Francesco Taurone</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucani_D/0/1/0/all/0/1">Daniel E. Lucani</a>, <a href="http://arxiv.org/find/cs/1/au:+Feher_M/0/1/0/all/0/1">Marcell Feh&#xe9;r</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a></p><p>The number of IoT devices is expected to continue its dramatic growth in the
coming years and, with it, a growth in the amount of data to be transmitted,
processed and stored. Compression techniques that support analytics directly on
the compressed data could pave the way for systems to scale efficiently to
these growing demands. This paper proposes two novel methods for preprocessing
a stream of floating point data to improve the compression capabilities of
various IoT data compressors. In particular, these techniques are shown to be
helpful with recent compressors that allow for random access and analytics
while maintaining good compression. Our techniques improve compression with
reductions up to 80% when allowing for at most 1% of recovery error.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04555'>Streaming Kernel PCA Algorithm With Small Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yichuan Deng, Zhao Song, Zifan Wang, Han Zhang</p><p>Principal Component Analysis (PCA) is a widely used technique in machine
learning, data analysis and signal processing. With the increase in the size
and complexity of datasets, it has become important to develop low-space usage
algorithms for PCA. Streaming PCA has gained significant attention in recent
years, as it can handle large datasets efficiently. The kernel method, which is
commonly used in learning algorithms such as Support Vector Machines (SVMs),
has also been applied in PCA algorithms.
</p>
<p>We propose a streaming algorithm for Kernel PCA problems based on the
traditional scheme by Oja. Our algorithm addresses the challenge of reducing
the memory usage of PCA while maintaining its accuracy. We analyze the
performance of our algorithm by studying the conditions under which it
succeeds. Specifically, we show that, when the spectral ratio $R :=
\lambda_1/\lambda_2$ of the target covariance matrix is lower bounded by $C
\cdot \log n\cdot \log d$, the streaming PCA can be solved with $O(d)$ space
cost.
</p>
<p>Our proposed algorithm has several advantages over existing methods. First,
it is a streaming algorithm that can handle large datasets efficiently. Second,
it employs the kernel method, which allows it to capture complex nonlinear
relationships among data points. Third, it has a low-space usage, making it
suitable for applications where memory is limited.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yichuan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zifan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Han Zhang</a></p><p>Principal Component Analysis (PCA) is a widely used technique in machine
learning, data analysis and signal processing. With the increase in the size
and complexity of datasets, it has become important to develop low-space usage
algorithms for PCA. Streaming PCA has gained significant attention in recent
years, as it can handle large datasets efficiently. The kernel method, which is
commonly used in learning algorithms such as Support Vector Machines (SVMs),
has also been applied in PCA algorithms.
</p>
<p>We propose a streaming algorithm for Kernel PCA problems based on the
traditional scheme by Oja. Our algorithm addresses the challenge of reducing
the memory usage of PCA while maintaining its accuracy. We analyze the
performance of our algorithm by studying the conditions under which it
succeeds. Specifically, we show that, when the spectral ratio $R :=
\lambda_1/\lambda_2$ of the target covariance matrix is lower bounded by $C
\cdot \log n\cdot \log d$, the streaming PCA can be solved with $O(d)$ space
cost.
</p>
<p>Our proposed algorithm has several advantages over existing methods. First,
it is a streaming algorithm that can handle large datasets efficiently. Second,
it employs the kernel method, which allows it to capture complex nonlinear
relationships among data points. Third, it has a low-space usage, making it
suitable for applications where memory is limited.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04771'>Interior-point methods on manifolds: theory and applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Harold Nieuwboer, Michael Walter</p><p>Interior-point methods offer a highly versatile framework for convex
optimization that is effective in theory and practice. A key notion in their
theory is that of a self-concordant barrier. We give a suitable generalization
of self-concordance to Riemannian manifolds and show that it gives the same
structural results and guarantees as in the Euclidean setting, in particular
local quadratic convergence of Newton's method. We then analyze a short-step
path-following method for optimizing compatible objectives over a convex domain
for which one has a self-concordant barrier, and obtain the standard complexity
guarantees as in the Euclidean setting. We show that on the positive-definite
matrices and other symmetric spaces, the squared distance to a point is a
self-concordant function. Our work is motivated by recent progress on scaling
problems and non-commutative optimization, and we show that these fit into our
framework, yielding algorithms with state-of-the-art complexity guarantees.
Furthermore, we show how to apply our methods to computing geometric medians on
spaces with constant negative curvature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Nieuwboer_H/0/1/0/all/0/1">Harold Nieuwboer</a>, <a href="http://arxiv.org/find/math/1/au:+Walter_M/0/1/0/all/0/1">Michael Walter</a></p><p>Interior-point methods offer a highly versatile framework for convex
optimization that is effective in theory and practice. A key notion in their
theory is that of a self-concordant barrier. We give a suitable generalization
of self-concordance to Riemannian manifolds and show that it gives the same
structural results and guarantees as in the Euclidean setting, in particular
local quadratic convergence of Newton's method. We then analyze a short-step
path-following method for optimizing compatible objectives over a convex domain
for which one has a self-concordant barrier, and obtain the standard complexity
guarantees as in the Euclidean setting. We show that on the positive-definite
matrices and other symmetric spaces, the squared distance to a point is a
self-concordant function. Our work is motivated by recent progress on scaling
problems and non-commutative optimization, and we show that these fit into our
framework, yielding algorithms with state-of-the-art complexity guarantees.
Furthermore, we show how to apply our methods to computing geometric medians on
spaces with constant negative curvature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, March 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/03/08/more-mathematics-books.html'>More mathematics books by women</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          For the last several years, Iâve been celebrating International Womenâs Day by posting lists of mathematics books written or coauthored by women: 2020, 2021, 2022. Hereâs another set. The links go to Wikipedia articles on the books, where you can find more information about them collated from their published reviews. The level and selection is, as usual, random, based mainly on whether the bookâs topic caught my interest and it had enough published reviews to justify a Wikipedia article.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>For the last several years, Iâve been celebrating International Womenâs Day by posting lists of mathematics books written or coauthored by women: <a href="/blog/2020/03/08/mathematics-books-women.html">2020</a>, <a href="/blog/2021/03/08/more-mathematics-books.html">2021</a>, <a href="/blog/2022/03/08/mathematics-books-by-women.html">2022</a>. Hereâs another set. The links go to Wikipedia articles on the books, where you can find more information about them collated from their published reviews. The level and selection is, as usual, random, based mainly on whether the bookâs topic caught my interest and it had enough published reviews to justify a Wikipedia article.</p>

<ul>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Geometry_of_an_Art">The Geometry of an Art: The History of the Mathematical Theory of Perspective from Alberti to Monge</a></em> (2007), Kirsti Andersen. The development of the mathematics of perspective and descriptive geometry, and its applications by European artists, from the 15th to 18th centuries.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Extrinsic_Geometric_Flows">Extrinsic Geometric Flows</a></em> (2020), Ben Andrews, Bennett Chow, Christine Guenther, and Mat Langford. A geometric flow is a way of continuously moving a curve, surface, or other shape, with the speed and direction of motion depending on its shape. It is âextrinsicâ when the flow depends on a higher-dimensional space in which the moving object is embedded, rather than just on the intrinsic geometry of the object itself. This is a graduate textbook on the subject.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Spatial_Mathematics:_Theory_and_Practice_through_Mapping">Spatial Mathematics: Theory and Practice through Mapping</a></em> (2013), Sandra Arlinghaus and Joseph Kerski. The mathematical background behind geodesy and spatial visualization in geographic information systems.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Problem_Solving_Through_Recreational_Mathematics">Problem Solving Through Recreational Mathematics</a></em> (1980), Bonnie Averbach and Orin Chein. Despite the title this is an undergraduate textbook, for general education courses aimed at non-mathematics students. Its premise is that the use of fun ârecreationalâ problems can help motivate these students to learn mathematical problem-solving techniques.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Geometric_and_Topological_Inference">Geometric and Topological Inference</a></em> (2018), Jean-Daniel Boissonnat, FrÃ©dÃ©ric Chazal, and Mariette Yvinec. Computational geometry meets machine learning.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Independence_Theory_in_Combinatorics">Independence Theory in Combinatorics: An Introductory Account with Applications to Graphs and Transversals</a></em> (1980), Victor Bryant and Hazel Perfect. An undergraduate text on matroid theory, with a particular focus on graph-theoretic applications of matroids.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Beyond_Infinity_(mathematics_book)">Beyond Infinity: An Expedition to the Outer Limits of Mathematics</a></em> (2017), Eugenia Cheng. A general-audience book looking at the many ways mathematics has approached the infinite.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Symmetries_of_Things">The Symmetries of Things</a></em> (2008), John Horton Conway, Heidi Burgiel, and Chaim Goodman-Strauss. A bit annoying for its frequent use of neologism and revisionist history, but packed with detail about discrete symmetries of geometric objects.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/A_Biography_of_Maria_Gaetana_Agnesi">A Biography of Maria Gaetana Agnesi</a></em> (2008), Antonella Cupillari. This mainly consists of a translation of Antonio Francesco Frisiâs Italian-language biography of Agnesi, augmented with many pages of notes and with translations of some of Agnesiâs mathematical works.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Finding_Ellipses">Finding Ellipses: What Blaschke Products, Ponceletâs Theorem, and the Numerical Range Know about Each Other</a></em> (2019), Ulrich Daepp, Pamela Gorkin, Andrew Shaffer, and Karl Voss. An undergraduate-level exposition of some deep connections between functional analysis (analytic functions with specified zeros), geometry (polygons simultaneously inscribed in and circumscribing conics), and linear algebra (convex sets containing the eigenvalues of a matrix).</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Introduction_to_Lattices_and_Order">Introduction to Lattices and Order</a></em> (1990, 2002), Brian A. Davey and Hilary Priestley. A graduate textbook on order theory, also noteworthy for its tips on how to use LaTeX to make order-theoretic mathematical diagrams.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Geometry_of_the_Octonions">The Geometry of the Octonions</a></em> (2015), Tevian Dray and Corinne Manogue. Beyond the real numbers, complex numbers, and quaternions, the next step is the octonions, a division algebra but not a ring. This book surveys this topic at an advanced undergraduate level.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Cube_Made_Interesting">The Cube Made Interesting</a></em> (1960, 1964), Aniela Ehrenfeucht. Aimed at high school students, and originally written in Polish, on the rotational symmetries of a cube, its colorings, and on the ability to pass a cube through a hole in an equal-sized cube (âPrince Rupertâs cubeâ), illustrated with red-blue anaglyphic 3d visualizations.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Erd%C5%91s_Distance_Problem">The ErdÅs Distance Problem</a></em> (2011), Julia Garibaldi, Alex Iosevich, and Steven Senger, an advanced undergraduate monograph on the problem of arranging points to make as few distinct distances as possible, unfortunately made mostly obsolete soon after its publication by the polynomial method of Larry Guth and Nets Katz.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Lumen_Naturae">Lumen Naturae: Visions of the Abstract in Art and Mathematics</a></em> (2020), Matilde Marcolli. On inspirations and analogies connecting modern art, mathematics, and mathematical physics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Black_Mathematicians_and_Their_Works">Black Mathematicians and Their Works</a></em> (1980), Virginia Newell, Joella Gipson, L. Waldo Rich, and Beauregard Stubblefield. Brief biographies of 62 black mathematicians, and reprints of 26 of their papers on mathematics and mathematics education, maybe the only book of its kind.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/From_Zero_to_Infinity">From Zero to Infinity: What Makes Numbers Interesting</a></em> (1955, â¦, 2006), Constance Reid. A classic of general-audience mathematics exposition, on different kinds of numbers and topics in number theory.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Math_on_Trial">Math on Trial: How Numbers Get Used and Abused in the Courtroom</a></em> (2013), Leila Schneps and Coralie Colmez. A collection of case studies on mathematical fallacies occurring in famous court cases, aimed at a general audience.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Curvature_of_Space_and_Time,_with_an_Introduction_to_Geometric_Analysis">Curvature of Space and Time, with an Introduction to Geometric Analysis</a></em> (2020), Iva Stavrov. An undergraduate textbook on differential geometry and its applications in the theory of relativity.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_History_of_Mathematics:_A_Very_Short_Introduction">The History of Mathematics: A Very Short Introduction</a></em> (2012), Jackie Stedall. This is less an overview of the history of mathematics itself (maybe too big a topic for a short book) and more an overview of the philosophy of the history of mathematics, as demonstrated through several case studies.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Ad_Quadratum:_The_Practical_Application_of_Geometry_in_Medieval_Architecture">Ad Quadratum: The Practical Application of Geometry in Medieval Architecture</a></em> (2002), Nancy Y. Wu. An edited volume of papers on geometry in medieval architecture, mostly of Gothic cathedrals.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Do_Not_Erase:_Mathematicians_and_their_Chalkboards">Do Not Erase: Mathematicians and their Chalkboards</a></em> (2021), Jessica Wynne. A photo-essay pairing photographs of mathematicianâs chalkboards with reflections on their contents by the mathematicians. I listed this in last yearâs collection of books for which I could not find enough reviews, but in this case I subsequently did find them.</p>
  </li>
</ul>

<p>(<a href="https://mathstodon.xyz/@11011110/109990803163597638">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T17:40:00Z">Wednesday, March 08 2023, 17:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/03/08/three-assistant-associate-professor-positions-in-security-at-the-vu-amsterdam-at-vrije-universiteit-amsterdam-apply-by-april-13-2023/'>Three assistant/associate professor positions in security at the VU Amsterdam at Vrije Universiteit Amsterdam (apply by April 13, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Department of Computer Science at the Vrije Universiteit Amsterdam offers three open positions for assistant/associate professor in the area of security, related to theory, vulnerability, and AI. Website: werkenbij.vu.nl/vacatures Email: w.j.fokkink@vu.nl
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Department of Computer Science at the Vrije Universiteit Amsterdam offers three open positions for assistant/associate professor in the area of security, related to theory, vulnerability, and AI.</p>
<p>Website: <a href="https://werkenbij.vu.nl/vacatures">https://werkenbij.vu.nl/vacatures</a><br />
Email: w.j.fokkink@vu.nl</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T17:29:12Z">Wednesday, March 08 2023, 17:29</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/03/08/interview-about-this-blog-in-the-bulletin-of-the-eatcs/'>Interview about this blog in the Bulletin of the EATCS</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Luca Trevisan recently interviewed me for the Bulletin of the EATCS (see link for the full issue, including an interview with Alexandra Silva, and technical columns by Naama Ben-David, Ryan Williams, and Yuri Gurevich). With Luca&#8217;s permission, I am cross-posting it here. (I added some hyperlinks to relevant documents.) Q. Boaz, thanks for taking the &#8230; Continue reading Interview about this blog in the Bulletin of the&#160;EATCS
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><a href="https://lucatrevisan.github.io/">Luca Trevisan</a> recently interviewed me for the <a href="https://eatcs.org/images/bulletin/beatcs139.pdf">Bulletin of the EATCS</a> (see link for the full issue, including an interview with Alexandra Silva, and technical columns by Naama Ben-David, Ryan Williams, and Yuri Gurevich). With Luca&#8217;s permission, I am cross-posting it here.  (I added some hyperlinks to relevant documents.)</p>



<p><strong>Q. Boaz, thanks for taking the time to talk about your blog to our readers. When did you start to blog, and what motivated you to start?</strong></p>



<p>In 2012, Omer Reingold <a href="https://windowsontheory.org/about/">started a group blog</a> for the amazing theoretical computer scientists of the Microsoft Research Silicon Valley lab, and called it &#8220;Windows on Theory&#8221;. As a fellow MSR researcher, Omer invited me to join the blog a few months later. Joining a group blog seemed to me like an attractive proposition, since I didn&#8217;t think I will have something interesting to say on a very regular basis.</p>



<p>I liked the idea of explaining technical topics on a blog post, the way you might sketch them on a whiteboard to a colleague. Compared to a survey, where you have to cross all your t&#8217;s and dot all your i&#8217;s, and get all references straight, a blog post can be a good way to convey the heart of the matter without doing as much work.<br>Indeed throughout the years, I&#8217;ve been inspired by several blog posts by you, Luca. <a href="https://lucatrevisan.wordpress.com/">Your blog</a> is a great example of how to explain technical topics in an informal manner.</p>



<p><strong>Q. Thank you so much for that! You have very broad interests in theoretical computer science, and you blog about a great variety of topics. Have there been instances where writing posts or discussing in the comment section has clarified ideas or led to a conjecture or otherwise helped with your research?</strong></p>



<p>I do think that my thinking on several questions, including <a href="https://windowsontheory.org/2013/10/07/structure-vs-combinatorics-in-computational-complexity/">structure vs. combinatorics</a><a href="https://windowsontheory.org/2017/10/30/the-different-forms-of-quantum-computing-skepticism/">, quantum skepticism</a>, <a href="https://windowsontheory.org/2022/06/20/the-uneasy-relationship-between-deep-learning-and-classical-statistics/">theory of deep learning</a>, and more, have been shaped by both the process of writing essays and the discussion in comments or outside the blog that ensues. It is a different form of thinking than the typical scientific paper, and often when you sit down to write, it forces you to clarify your thoughts. This is similar to how often the best way to learn a topic is to teach it.</p>



<p><strong>Q. I have followed on your blog, your course on methods from theoretical physics, and your posts on the <a href="https://windowsontheory.org/2022/06/20/the-uneasy-relationship-between-deep-learning-and-classical-statistics/">foundations of machine learning</a> and AI, and I know you have worked on a <a href="https://introtcs.org/">new approach</a> to teach computability and complexity. What kind of TCS do you think we should teach to CS undergraduates who are interested in AI?</strong></p>



<p>It&#8217;s interesting because I think traditionally, the critique of courses in theoretical CS was that we are teaching all this math, while students are going to be software developers, and they just need to know how to write a website. Now it turns out that we didn&#8217;t teach enough math, and to participate in the AI revolution, students need to know their gradients and Hessians. It&#8217;s also the case that Neural networks are really just arithmetic circuits (and backpropagation has been rediscovered several times, including by <a href="https://core.ac.uk/download/pdf/82480031.pdf">Baur and Strassen</a> in 1982, where they used it for circuit lower bounds).</p>



<p>So I think the tools we teach as theoretical computer scientists are as relevant as ever. I did try to modernize my <a href="https://cs121.boazbarak.org/">course</a>, focusing on circuits, which are relevant not just for AI but also for the foundations of both cryptography and quantum computing. I also talk much more about randomness in computation. This means that some other materials, such as automata, need to be reduced or cut, but I think it&#8217;s a good tradeoff.</p>



<p><strong>Q. On a related note, what do you think that a future satisfactory theory of AI might look like?</strong></p>



<p>As theoretical computer scientists, we are used to being way ahead of practice. For example, people are only starting now to implement the ideas of zero-knowledge and probabilistically-checkable proofs that were put forward by theorists in the 80s and 90s. Dwork and Naor suggested the &#8220;proof of work&#8221; protocol used by Bitcoin in 1992. (They were also ahead of the curve in another way: proposing to combat &#8220;junk email&#8221; before most people had access to email and the term &#8220;spam email&#8221; was even coined.)</p>



<p>In deep learning, we are in a different setting: practice is ahead of theory, and people are implementing systems that they themselves don&#8217;t understand. In that sense, these systems behave more like artifacts that are discovered (or evolved) than like ones that are designed. This forces us to use a different form of theory, and one that relies more heavily on experiments to figure out what are even the right questions to ask.</p>



<p>So, we are not in our usual mode where there are easy-to-state but hard-to-prove conjectures, and our goal is to sit down with pen and paper and to prove them. But for me, theoretical computer science was never about the mode of operation but about the mission of understanding computation. So if understanding deep learning means that I needed to re-learn how to code, and rack up large bills for GPU computation, then so be it.</p>



<p><strong>Q. Can you tell us a bit about the plans for changes in California math education and about your involvement in that debate?</strong></p>



<p>Some colleagues in California have alerted me to a <a href="https://windowsontheory.org/2021/12/03/an-alarming-trend-in-k-12-math-education/">proposed change</a> to the way K-12 math is taught there and that this change is part of a national movement. Part of this is the typical tension that always exists between teaching mathematical topics that are foundational (and often a bit more challenging) vs. &#8220;practical math&#8221;.<br>This is something that I mentioned also in the discussion regarding university teaching.</p>



<p>In the context of high school, the new version of &#8220;practical math&#8221; is no longer accounting but <a href="https://www.educationnext.org/rethinking-math-education-educators-differ-curriculum-methods-forum/">&#8220;data science&#8221;</a>. There is also a twist in which it is claimed that somehow data science is more &#8220;equitable&#8221;, which is something I find offensive, as it tacitly assumes that people from certain groups are inherently incapable of accessing mathematical topics such as algebra and calculus. From my experience in teaching, both at university settings and in Ethiopia and Jamaica, nothing could be further from the truth</p>



<p>Now I am all for teaching students a course in some data literacy, including facility with spreadsheets and understanding the various ways that people can &#8220;lie with statistics&#8221;. It&#8217;s just not a replacement for math courses.</p>



<p>The truth is that, like at the university level, students need more math these days than ever before. By far the largest growth in job opportunities has been in quantitative fields.<br>When data science is offered as an <em>alternative</em> to math, as opposed to complementing them, it basically serves as an &#8220;off ramp&#8221; that shuts students out of these fields, including, ironically, from careers in data science itself.</p>



<p><strong>Q. In general, what are your thoughts about the role of public intellectuals that theoretical computer scientists could fill, and what are public debates where you would like to see more voices coming from our community?</strong></p>



<p>In our field, we often have the experience of being humiliated by either discovering that our conjecture was wrong or being unable to prove it. I think this is not a bad experience to have had for public intellectuals, and so I would hope that theoretical computer scientists speak up more in the public sphere.</p>



<p>Areas including immigration, science funding, open access to publications, and mathematical education are clearly central to our mission to advance science, but I think we can talk about more topics as well. For example, I recently signed an open letter protesting the Israeli government&#8217;s efforts to weaken the judicial branch and the basic laws on human rights. Scientific progress relies on the ability to collaborate, so free speech and human rights are topics that we should talk about as well.</p>



<p><strong>I would like to ask you to pick one or a couple of your favorite posts, and tell us about it/them/</strong></p>



<p>My first blog post was an <a href="https://windowsontheory.org/2012/05/01/the-swiss-army-knife-of-cryptography">exposition</a> of Fully Homomorphic Encryption with Zvika Brakerski. I like that post because we didn&#8217;t just repeat what&#8217;s in the papers but used the flexibility of the blog format to focus on optimizing simplicity and intuition as opposed to precision and computational efficiency. I think people have found it useful over the years. Another blog post I am proud of is my post on <a href="https://windowsontheory.org/2017/08/16/men-in-computer-science/">&#8220;Men in Computer Science&#8221;</a>. I mostly made obvious points in that post, but heard from several women that they appreciated it.</p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T14:13:20Z">Wednesday, March 08 2023, 14:13</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://ptreview.sublinear.info/2023/03/news-for-february-2023/'>News for February 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Despite being a short month, February 2023 has witnessed a significant amount of activity under the sublinear &#8220;regime&#8221;. Let us know if we have missed anything! Dynamic \((1 + \epsilon)\)-Approximate Matching Size in Truly Sublinear Update Time by Sayan Bhattacharya, Peter Kiss, and Thatchaphol Saranurak (arXiv). This work throws light on connections between the dynamic [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Despite being a short month, February 2023 has witnessed a significant amount of activity under the sublinear &#8220;regime&#8221;. Let us know if we have missed anything!</p>



<p><strong>Dynamic \((1 + \epsilon)\)-Approximate Matching Size in Truly Sublinear Update Time</strong> by Sayan Bhattacharya, Peter Kiss, and Thatchaphol Saranurak (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2302.05030" target="_blank">arXiv</a>). This work throws light on connections between the dynamic and query models of computation and uses them for making advances on approximating the size of a maximum cardinality matching (MCM) in a general graph. In particular, as the main technical ingredient in obtaining an improved dynamic algorithm for maintaining an approximation to the size of MCM, the authors provide a \(\pm \epsilon n\) approximation algorithm for estimating the size of MCM in a general \(n\)-vertex graph by making \(n^{2 &#8211; \Omega_{\epsilon}(1)}\) adjacency queries. Prior to this result, the state of the art (Behnezhad, Roghani &amp; Rubinstein; STOC&#8217;23) was a \(n^{2 &#8211; \Omega(1)}\)-query algorithm for the same problem with a multiplicative approximation guarantee of \(1.5\) and an additive guarantee of \(o(n)\). </p>



<p><strong>Uniformity Testing over Hypergrids with Subcube Conditioning</strong> by Xi Chen and Cassandra Marcussen (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2302.09013" target="_blank">arXiv</a>). As the name indicates, the paper studies the fundamental problem of testing uniformity of distributions supported over hypergrids \([m]^n\). The tester that they present make \(O(\text{poly}(m)\sqrt{n}/\epsilon^2)\) queries to a conditional subcube sampling oracle, which, when given a subcube of \([m]^n\), returns a point sampled from the distribution conditioned on the point belonging to the subcube. The result is a generalization of the uniformity tester for distributions supported over the \(n\)-dimensional hypercube (Canonne, Chen, Kamath, Levi and Waingarten; SODA &#8217;21). </p>



<p><strong>Easy Testability for Posets</strong> by Panna Timea Fekete and Gabor Kun (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2302.11390" target="_blank">arXiv</a>). This paper deals with testing properties of directed graphs in the adjacency matrix model. The main characters of the story are posets, or directed acyclic graphs (DAGs) that are transitively closed. Given a family \(\mathcal{F}\) of finite posets, let \(\mathcal{P}_\mathcal{F}\) denote the set of all finite posets that do not contain any element of \(\mathcal{F}\) as a subposet. The main result of the paper is an \(\epsilon\)-tester with query complexity \(\text{poly}(1/\epsilon)\) for \(\mathcal{P}_\mathcal{F}\). The authors obtain this result by proving a removal lemma for posets. The result is placed in the larger context of understanding what properties of graphs can be tested with query complexity that has a polynomial dependence on \(1/\epsilon\) in the adjacency matrix model. </p>



<p><strong>Compressibility-Aware Quantum Algorithms</strong> on Strings by Daniel Gibney and Sharma V. Thankachan (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2302.07235" target="_blank">arXiv</a>). Lastly, we have a paper on quantum string algorithms that run in sublinear time. In short, the authors present quantum algorithms with optimal running times for computing the Lempel-Ziv (LZ) encoding and Burrows Wheeler Transform (BWT) of highly compressible strings. A main consequence of these results is a faster quantum algorithm for computing the longest common subsequence (LCS) of two strings when the concatenation of the strings is highly compressible. It is to be noted that sublinear-time algorithms do not exist for these problems in the classical model of computation. More details follow. <br><br>Factoring a string into disjoint substrings (factors) in an specific manner is the main step in the LZ compression algorithm. The smaller the number of factors, the more compressible the string is.  This paper gives a quantum algorithm for the problem of computing the LZ factorization of a string in time \(\tilde{O}(\sqrt{nz})\), where \(z\) is the number of factors in the string. They also show that their algorithm is optimal. Using this algorithm, they obtain a fast algorithm for computing the BWT of an input string, as well as an algorithm running in time \(\tilde{O}(\sqrt{nz})\) to compute the LCS of two strings, where \(n\) is the length and \(z\) is the number of factors in the concatenation of the two strings. When \(z\) is \(o(n^{1/3})\), this algorithm gives an improvement over the previous best quantum algorithm running in time \(\tilde{O}(n^{2/3})\).</p>
<p class="authors">By Nithin Varma</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T06:59:54Z">Wednesday, March 08 2023, 06:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03645'>Filter Pruning based on Information Capacity and Independence</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiaolong Tang, Tianheng Hu, Yufeng Shi</p><p>Filter pruning has been widely used in the compression and acceleration of
convolutional neural networks (CNNs). However, most existing methods are still
challenged by heavy compute cost and biased filter selection. Moreover, most
designs for filter evaluation miss interpretability due to the lack of
appropriate theoretical guidance. In this paper, we propose a novel filter
pruning method which evaluates filters in a interpretable, multi-persepective
and data-free manner. We introduce information capacity, a metric that
represents the amount of information contained in a filter. Based on the
interpretability and validity of information entropy, we propose to use that as
a quantitative index of information quantity. Besides, we experimently show
that the obvious correlation between the entropy of the feature map and the
corresponding filter, so as to propose an interpretable, data-driven scheme to
measure the information capacity of the filter. Further, we introduce
information independence, another metric that represents the correlation among
differrent filters. Consequently, the least impotant filters, which have less
information capacity and less information independence, will be pruned. We
evaluate our method on two benchmarks using multiple representative CNN
architectures, including VGG-16 and ResNet. On CIFAR-10, we reduce 71.9% of
floating-point operations (FLOPs) and 69.4% of parameters for ResNet-110 with
0.28% accuracy increase. On ILSVRC-2012, we reduce 76.6% of floating-point
operations (FLOPs) and 68.6% of parameters for ResNet-50 with only 2.80%
accuracy decrease, which outperforms the state-of-the-arts.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaolong Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1">Tianheng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yufeng Shi</a></p><p>Filter pruning has been widely used in the compression and acceleration of
convolutional neural networks (CNNs). However, most existing methods are still
challenged by heavy compute cost and biased filter selection. Moreover, most
designs for filter evaluation miss interpretability due to the lack of
appropriate theoretical guidance. In this paper, we propose a novel filter
pruning method which evaluates filters in a interpretable, multi-persepective
and data-free manner. We introduce information capacity, a metric that
represents the amount of information contained in a filter. Based on the
interpretability and validity of information entropy, we propose to use that as
a quantitative index of information quantity. Besides, we experimently show
that the obvious correlation between the entropy of the feature map and the
corresponding filter, so as to propose an interpretable, data-driven scheme to
measure the information capacity of the filter. Further, we introduce
information independence, another metric that represents the correlation among
differrent filters. Consequently, the least impotant filters, which have less
information capacity and less information independence, will be pruned. We
evaluate our method on two benchmarks using multiple representative CNN
architectures, including VGG-16 and ResNet. On CIFAR-10, we reduce 71.9% of
floating-point operations (FLOPs) and 69.4% of parameters for ResNet-110 with
0.28% accuracy increase. On ILSVRC-2012, we reduce 76.6% of floating-point
operations (FLOPs) and 68.6% of parameters for ResNet-50 with only 2.80%
accuracy decrease, which outperforms the state-of-the-arts.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03921'>Approximate degree lower bounds for oracle identification problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mark Bun, Nadezhda Voronova</p><p>The approximate degree of a Boolean function is the minimum degree of real
polynomial that approximates it pointwise. For any Boolean function, its
approximate degree serves as a lower bound on its quantum query complexity, and
generically lifts to a quantum communication lower bound for a related
function.
</p>
<p>We introduce a framework for proving approximate degree lower bounds for
certain oracle identification problems, where the goal is to recover a hidden
binary string $x \in \{0, 1\}^n$ given possibly non-standard oracle access to
it. We apply this framework to the ordered search and hidden string problems,
proving nearly tight approximate degree lower bounds of $\Omega(n/\log^2 n)$
for each.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bun_M/0/1/0/all/0/1">Mark Bun</a>, <a href="http://arxiv.org/find/cs/1/au:+Voronova_N/0/1/0/all/0/1">Nadezhda Voronova</a></p><p>The approximate degree of a Boolean function is the minimum degree of real
polynomial that approximates it pointwise. For any Boolean function, its
approximate degree serves as a lower bound on its quantum query complexity, and
generically lifts to a quantum communication lower bound for a related
function.
</p>
<p>We introduce a framework for proving approximate degree lower bounds for
certain oracle identification problems, where the goal is to recover a hidden
binary string $x \in \{0, 1\}^n$ given possibly non-standard oracle access to
it. We apply this framework to the ordered search and hidden string problems,
proving nearly tight approximate degree lower bounds of $\Omega(n/\log^2 n)$
for each.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03958'>The Linear Correlation of $P$ and $NP$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bojin Zheng, Weiwu Wang</p><p>$P \overset{\text{?}}{=} NP$ or $P\ vs\ NP$ is the core problem in
computational complexity theory. In this paper, we proposed a definition of
linear correlation of derived matrix and system, and discussed the linear
correlation of $P$ and $NP$. We draw a conclusion that $P$ is linearly
dependent and there exists $NP$ which is is linearly independent and take a
3SAT instance which belongs to $NP$ as the example , that is, $P \neq NP$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1">Bojin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiwu Wang</a></p><p>$P \overset{\text{?}}{=} NP$ or $P\ vs\ NP$ is the core problem in
computational complexity theory. In this paper, we proposed a definition of
linear correlation of derived matrix and system, and discussed the linear
correlation of $P$ and $NP$. We draw a conclusion that $P$ is linearly
dependent and there exists $NP$ which is is linearly independent and take a
3SAT instance which belongs to $NP$ as the example , that is, $P \neq NP$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03616'>Geometry-Aware Coverage Path Planning on Complex 3D Surfaces</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Van-Thach Do, Quang-Cuong Pham</p><p>This paper presents a new approach to obtaining nearly complete coverage
paths (CP) with low overlapping on 3D general surfaces using mesh models given
or reconstructed from actual scenes. The CP is obtained by segmenting the mesh
model into a given number of clusters using constrained centroidal Voronoi
tessellation (CCVT) and finding the shortest path from cluster centroids using
the geodesic metric efficiently. We introduce a new cost function to
harmoniously achieve uniform areas of the obtained clusters and a restriction
on the variation of triangle normals during the construction of CCVTs. The
obtained clusters can be used to construct high-quality viewpoints (VP) for
visual coverage tasks. Here, we utilize the planned VPs as cleaning
configurations to perform residual powder removal in additive manufacturing
using manipulator robots. The self-occlusion of VPs and ensuring collision-free
robot configurations are addressed by integrating a proposed optimization-based
strategy to find a set of candidate rays for each VP into the motion planning
phase. CP planning benchmarks and physical experiments are conducted to
demonstrate the effectiveness of the proposed approach. We show that our
approach can compute the CPs and VPs of various mesh models with a massive
number of triangles within a reasonable time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Do_V/0/1/0/all/0/1">Van-Thach Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1">Quang-Cuong Pham</a></p><p>This paper presents a new approach to obtaining nearly complete coverage
paths (CP) with low overlapping on 3D general surfaces using mesh models given
or reconstructed from actual scenes. The CP is obtained by segmenting the mesh
model into a given number of clusters using constrained centroidal Voronoi
tessellation (CCVT) and finding the shortest path from cluster centroids using
the geodesic metric efficiently. We introduce a new cost function to
harmoniously achieve uniform areas of the obtained clusters and a restriction
on the variation of triangle normals during the construction of CCVTs. The
obtained clusters can be used to construct high-quality viewpoints (VP) for
visual coverage tasks. Here, we utilize the planned VPs as cleaning
configurations to perform residual powder removal in additive manufacturing
using manipulator robots. The self-occlusion of VPs and ensuring collision-free
robot configurations are addressed by integrating a proposed optimization-based
strategy to find a set of candidate rays for each VP into the motion planning
phase. CP planning benchmarks and physical experiments are conducted to
demonstrate the effectiveness of the proposed approach. We show that our
approach can compute the CPs and VPs of various mesh models with a massive
number of triangles within a reasonable time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04014'>Hausdorff and Gromov-Hausdorff stable subsets of the medial axis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andr&#xe9; Lieutier, Mathijs Wintraecken</p><p>In this paper we introduce a pruning of the medial axis called the
$(\lambda,\alpha)$-medial axis ($\textrm{ax}_\lambda^\alpha $). We prove that
the $(\lambda,\alpha)$-medial axis of a set $K$ is stable in a Gromov-Hausdorff
sense under weak assumptions. More formally we prove that if $K$ and $K'$ are
close in the Hausdorff ($d_H$) sense then the $(\lambda,\alpha)$-medial axes of
$K$ and $K'$ are close as metric spaces, that is the Gromov-Hausdorff distance
($d_{GH}$) between the two is $\frac{1}{4}$-H{\"o}lder in the sense that
$d_{GH} (\textrm{ax}_\lambda^\alpha (K),\textrm{ax}_\lambda^\alpha (K'))
\lesssim d_H(K,K')^{1/4}$. The Hausdorff distance between the two medial axes
is also bounded, by $d_{H} (\textrm{ax}_\lambda^\alpha
(K),\textrm{ax}_\lambda^\alpha (K')) \lesssim d_H(K,K')^{1/2}$. These
quantified stability results provide guarantees for practical computations of
medial axes from approximations. Moreover, they provide key ingredients for
studying the computability of the medial axis in the context of computable
analysis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lieutier_A/0/1/0/all/0/1">Andr&#xe9; Lieutier</a>, <a href="http://arxiv.org/find/cs/1/au:+Wintraecken_M/0/1/0/all/0/1">Mathijs Wintraecken</a></p><p>In this paper we introduce a pruning of the medial axis called the
$(\lambda,\alpha)$-medial axis ($\textrm{ax}_\lambda^\alpha $). We prove that
the $(\lambda,\alpha)$-medial axis of a set $K$ is stable in a Gromov-Hausdorff
sense under weak assumptions. More formally we prove that if $K$ and $K'$ are
close in the Hausdorff ($d_H$) sense then the $(\lambda,\alpha)$-medial axes of
$K$ and $K'$ are close as metric spaces, that is the Gromov-Hausdorff distance
($d_{GH}$) between the two is $\frac{1}{4}$-H{\"o}lder in the sense that
$d_{GH} (\textrm{ax}_\lambda^\alpha (K),\textrm{ax}_\lambda^\alpha (K'))
\lesssim d_H(K,K')^{1/4}$. The Hausdorff distance between the two medial axes
is also bounded, by $d_{H} (\textrm{ax}_\lambda^\alpha
(K),\textrm{ax}_\lambda^\alpha (K')) \lesssim d_H(K,K')^{1/2}$. These
quantified stability results provide guarantees for practical computations of
medial axes from approximations. Moreover, they provide key ingredients for
studying the computability of the medial axis in the context of computable
analysis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
