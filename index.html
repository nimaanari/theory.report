<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-05-17T02:41:59Z">Wednesday, May 17 2023, 02:41</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, May 17
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09508'>The Hardness of Reasoning about Probabilities and Causality</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Benito van der Zander, Markus Bl&#xe4;ser, Maciej Li&#x15b;kiewicz</p><p>We study formal languages which are capable of fully expressing quantitative
probabilistic reasoning and do-calculus reasoning for causal effects, from a
computational complexity perspective. We focus on satisfiability problems whose
instance formulas allow expressing many tasks in probabilistic and causal
inference. The main contribution of this work is establishing the exact
computational complexity of these satisfiability problems. We introduce a new
natural complexity class, named succ$\exists$R, which can be viewed as a
succinct variant of the well-studied class $\exists$R, and show that the
problems we consider are complete for succ$\exists$R. Our results imply even
stronger algorithmic limitations than were proven by Fagin, Halpern, and
Megiddo (1990) and Moss\'{e}, Ibeling, and Icard (2022) for some variants of
the standard languages used commonly in probabilistic and causal inference.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zander_B/0/1/0/all/0/1">Benito van der Zander</a>, <a href="http://arxiv.org/find/cs/1/au:+Blaser_M/0/1/0/all/0/1">Markus Bl&#xe4;ser</a>, <a href="http://arxiv.org/find/cs/1/au:+Liskiewicz_M/0/1/0/all/0/1">Maciej Li&#x15b;kiewicz</a></p><p>We study formal languages which are capable of fully expressing quantitative
probabilistic reasoning and do-calculus reasoning for causal effects, from a
computational complexity perspective. We focus on satisfiability problems whose
instance formulas allow expressing many tasks in probabilistic and causal
inference. The main contribution of this work is establishing the exact
computational complexity of these satisfiability problems. We introduce a new
natural complexity class, named succ$\exists$R, which can be viewed as a
succinct variant of the well-studied class $\exists$R, and show that the
problems we consider are complete for succ$\exists$R. Our results imply even
stronger algorithmic limitations than were proven by Fagin, Halpern, and
Megiddo (1990) and Moss\'{e}, Ibeling, and Icard (2022) for some variants of
the standard languages used commonly in probabilistic and causal inference.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09538'>A Local Perspective on the Polynomial Hierarchy</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fabian Reiter</p><p>We extend classical notions of computational complexity to the setting of
distributed computing. Instead of a single computer, several networked
computers communicate via synchronous message-passing to collectively solve
some decision problem related to the network topology. Their running time is
limited in two respects: the number of communication rounds is bounded by a
constant, and the number of computation steps of each computer is polynomially
bounded by the size of its local input and the messages it receives. By letting
two players take turns assigning certificates to the computers, we obtain a
generalization of the polynomial hierarchy (and hence of the complexity classes
$\mathbf{P}$ and $\mathbf{NP}$). We then extend major results of complexity
theory to this setting, in particular the Cook-Levin theorem (which identifies
Boolean satisfiability as a complete problem for $\mathbf{NP}$), and Fagin's
theorem (which characterizes $\mathbf{NP}$ as the problems expressible in
existential second-order logic). The original results can be recovered as the
special case where the network consists of a single computer. Moreover, perhaps
surprisingly, the task of separating complexity classes becomes easier in the
general case: we can show that our hierarchy is infinite, while it remains
notoriously open whether the same is true in the case of a single computer. In
contrast, a collapse of our hierarchy would have implied a collapse of the
polynomial hierarchy.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Reiter_F/0/1/0/all/0/1">Fabian Reiter</a></p><p>We extend classical notions of computational complexity to the setting of
distributed computing. Instead of a single computer, several networked
computers communicate via synchronous message-passing to collectively solve
some decision problem related to the network topology. Their running time is
limited in two respects: the number of communication rounds is bounded by a
constant, and the number of computation steps of each computer is polynomially
bounded by the size of its local input and the messages it receives. By letting
two players take turns assigning certificates to the computers, we obtain a
generalization of the polynomial hierarchy (and hence of the complexity classes
$\mathbf{P}$ and $\mathbf{NP}$). We then extend major results of complexity
theory to this setting, in particular the Cook-Levin theorem (which identifies
Boolean satisfiability as a complete problem for $\mathbf{NP}$), and Fagin's
theorem (which characterizes $\mathbf{NP}$ as the problems expressible in
existential second-order logic). The original results can be recovered as the
special case where the network consists of a single computer. Moreover, perhaps
surprisingly, the task of separating complexity classes becomes easier in the
general case: we can show that our hierarchy is infinite, while it remains
notoriously open whether the same is true in the case of a single computer. In
contrast, a collapse of our hierarchy would have implied a collapse of the
polynomial hierarchy.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09549'>Stable Dinner Party Seating Arrangements</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Damien Berriaud, Andrei Constantinescu, Roger Wattenhofer</p><p>A group of $n$ agents with numerical preferences for each other are to be
assigned to the $n$ seats of a dining table. We study two natural topologies:
circular (cycle) tables and panel (path) tables. For a given seating
arrangement, an agent's utility is the sum of its preference values towards its
(at most two) direct neighbors. An arrangement is envy-free if no agent
strictly prefers someone else's seat, and it is stable if no two agents
strictly prefer each other's seats. We show that it is NP-complete to decide
whether an envy-free arrangement exists for both paths and cycles, even with
binary preferences. In contrast, under the assumption that agents come from a
bounded number of classes, for both topologies, we present polynomial-time
algorithms computing envy-free and stable arrangements, working even for
general preferences. Proving the hardness of computing stable arrangements
seems more difficult, as even constructing unstable instances can be
challenging. To this end, we propose a characterization of the existence of
stable arrangements based on the number of distinct values in the preference
matrix and the number of classes of agents. For two classes of agents, we show
that stability can always be ensured, both for paths and cycles. For cycles, we
moreover show that binary preferences with four classes of agents, as well as
three-valued preferences with three classes of agents, are sufficient to
prevent the existence of a stable arrangement. For paths, the latter still
holds, while we argue that a path-stable arrangement always exists in the
binary case under the additional constraint that agents can only swap seats
when sitting at most two positions away. We moreover consider the swap dynamics
and exhibit instances where they do not converge, despite a stable arrangement
existing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berriaud_D/0/1/0/all/0/1">Damien Berriaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Constantinescu_A/0/1/0/all/0/1">Andrei Constantinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1">Roger Wattenhofer</a></p><p>A group of $n$ agents with numerical preferences for each other are to be
assigned to the $n$ seats of a dining table. We study two natural topologies:
circular (cycle) tables and panel (path) tables. For a given seating
arrangement, an agent's utility is the sum of its preference values towards its
(at most two) direct neighbors. An arrangement is envy-free if no agent
strictly prefers someone else's seat, and it is stable if no two agents
strictly prefer each other's seats. We show that it is NP-complete to decide
whether an envy-free arrangement exists for both paths and cycles, even with
binary preferences. In contrast, under the assumption that agents come from a
bounded number of classes, for both topologies, we present polynomial-time
algorithms computing envy-free and stable arrangements, working even for
general preferences. Proving the hardness of computing stable arrangements
seems more difficult, as even constructing unstable instances can be
challenging. To this end, we propose a characterization of the existence of
stable arrangements based on the number of distinct values in the preference
matrix and the number of classes of agents. For two classes of agents, we show
that stability can always be ensured, both for paths and cycles. For cycles, we
moreover show that binary preferences with four classes of agents, as well as
three-valued preferences with three classes of agents, are sufficient to
prevent the existence of a stable arrangement. For paths, the latter still
holds, while we argue that a path-stable arrangement always exists in the
binary case under the additional constraint that agents can only swap seats
when sitting at most two positions away. We moreover consider the swap dynamics
and exhibit instances where they do not converge, despite a stable arrangement
existing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09248'>Maximum-Width Rainbow-Bisecting Empty Annulus</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sang Won Bae, Sandip Banerjee, Arpita Baral, Priya Ranjan Sinha Mahapatra, Sang Duk Yoon</p><p>Given a set of $n$ colored points with $k$ colors in the plane, we study the
problem of computing a maximum-width rainbow-bisecting empty annulus (of
objects specifically axis-parallel square, axis-parallel rectangle and circle)
problem. We call a region rainbow if it contains at least one point of each
color. The maximum-width rainbow-bisecting empty annulus problem asks to find
an annulus $A$ of a particular shape with maximum possible width such that $A$
does not contain any input points and it bisects the input point set into two
parts, each of which is a rainbow. We compute a maximum-width rainbow-bisecting
empty axis-parallel square, axis-parallel rectangular and circular annulus in
$O(n^3)$ time using $O(n)$ space, in $O(k^2n^2\log n)$ time using $O(n\log n)$
space and in $O(n^3)$ time using $O(n^2)$ space respectively.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1">Sang Won Bae</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1">Sandip Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Baral_A/0/1/0/all/0/1">Arpita Baral</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahapatra_P/0/1/0/all/0/1">Priya Ranjan Sinha Mahapatra</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1">Sang Duk Yoon</a></p><p>Given a set of $n$ colored points with $k$ colors in the plane, we study the
problem of computing a maximum-width rainbow-bisecting empty annulus (of
objects specifically axis-parallel square, axis-parallel rectangle and circle)
problem. We call a region rainbow if it contains at least one point of each
color. The maximum-width rainbow-bisecting empty annulus problem asks to find
an annulus $A$ of a particular shape with maximum possible width such that $A$
does not contain any input points and it bisects the input point set into two
parts, each of which is a rainbow. We compute a maximum-width rainbow-bisecting
empty axis-parallel square, axis-parallel rectangular and circular annulus in
$O(n^3)$ time using $O(n)$ space, in $O(k^2n^2\log n)$ time using $O(n\log n)$
space and in $O(n^3)$ time using $O(n^2)$ space respectively.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09274'>Massive Uniform Mesh Decimation via a Fast Intrinsic Delaunay Triangulation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Filippo Maggioli, Daniele Baieri, Emanuele Rodol&#xe0;</p><p>Triangular meshes are still today the data structure at the main foundations
of many computer graphics applications. With the increasing demand in content
variety, a lot of effort has been and is being put into developing new
algorithms to automatically generate and edit geometric assets, with a
particular focus on 3D scans. However, this kind of content is often generated
with a dramatically high resolution, making it impractical for a large variety
of tasks. Furthermore, procedural assets and 3D scans largely suffer from poor
geometry quality, which makes them unsuitable in various applications. We
propose a new efficient technique for massively decimating dense meshes with
high vertex count very quickly. The proposed method relies on a fast algorithm
for computing geodesic farthest point sampling and Voronoi partitioning, and
generates simplified meshes with high-quality uniform triangulations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Maggioli_F/0/1/0/all/0/1">Filippo Maggioli</a>, <a href="http://arxiv.org/find/cs/1/au:+Baieri_D/0/1/0/all/0/1">Daniele Baieri</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodola_E/0/1/0/all/0/1">Emanuele Rodol&#xe0;</a></p><p>Triangular meshes are still today the data structure at the main foundations
of many computer graphics applications. With the increasing demand in content
variety, a lot of effort has been and is being put into developing new
algorithms to automatically generate and edit geometric assets, with a
particular focus on 3D scans. However, this kind of content is often generated
with a dramatically high resolution, making it impractical for a large variety
of tasks. Furthermore, procedural assets and 3D scans largely suffer from poor
geometry quality, which makes them unsuitable in various applications. We
propose a new efficient technique for massively decimating dense meshes with
high vertex count very quickly. The proposed method relies on a fast algorithm
for computing geodesic farthest point sampling and Voronoi partitioning, and
generates simplified meshes with high-quality uniform triangulations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09432'>Using SAT to study plane Hamiltonian substructures in simple drawings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Helena Bergold, Stefan Felsner, Meghana M. Reddy, Manfred Scheucher</p><p>In 1988 Rafla conjectured that every simple drawing of a complete graph $K_n$
contains a plane, i.e., non-crossing, Hamiltonian cycle. The conjecture is far
from being resolved. The lower bounds for plane paths and plane matchings have
recently been raised to $(\log n)^{1-o(1)}$ and $\Omega(\sqrt{n})$,
respectively. We develop a SAT framework which allows the study of simple
drawings of $K_n$. Based on the computational data we conjecture that every
simple drawing of $K_n$ contains a plane Hamiltonian subgraph with $2n-3$
edges. We prove this strengthening of Rafla's conjecture for convex drawings, a
rich subclass of simple drawings. Our computer experiments also led to other
new challenging conjectures regarding plane substructures in simple drawings of
complete graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bergold_H/0/1/0/all/0/1">Helena Bergold</a>, <a href="http://arxiv.org/find/cs/1/au:+Felsner_S/0/1/0/all/0/1">Stefan Felsner</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_M/0/1/0/all/0/1">Meghana M. Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheucher_M/0/1/0/all/0/1">Manfred Scheucher</a></p><p>In 1988 Rafla conjectured that every simple drawing of a complete graph $K_n$
contains a plane, i.e., non-crossing, Hamiltonian cycle. The conjecture is far
from being resolved. The lower bounds for plane paths and plane matchings have
recently been raised to $(\log n)^{1-o(1)}$ and $\Omega(\sqrt{n})$,
respectively. We develop a SAT framework which allows the study of simple
drawings of $K_n$. Based on the computational data we conjecture that every
simple drawing of $K_n$ contains a plane Hamiltonian subgraph with $2n-3$
edges. We prove this strengthening of Rafla's conjecture for convex drawings, a
rich subclass of simple drawings. Our computer experiments also led to other
new challenging conjectures regarding plane substructures in simple drawings of
complete graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09045'>Geometric Hitting Set for Line-Constrained Disks and Related Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gang Liu, Haitao Wang</p><p>Given a set $P$ of $n$ weighted points and a set $S$ of $m$ disks in the
plane, the hitting set problem is to compute a subset $P'$ of points of $P$
such that each disk contains at least one point of $P'$ and the total weight of
all points of $P'$ is minimized. The problem is known to be NP-hard. In this
paper, we consider a line-constrained version of the problem in which all disks
are centered on a line $\ell$. We present an $O((m+n)\log(m+n)+\kappa \log m)$
time algorithm for the problem, where $\kappa$ is the number of pairs of disks
that intersect. For the unit-disk case where all disks have the same radius,
the running time can be reduced to $O((n + m)\log(m + n))$. In addition, we
solve the problem in $O((m + n)\log(m + n))$ time in the $L_{\infty}$ and $L_1$
metrics, in which a disk is a square and a diamond, respectively. Our
techniques can also be used to solve other geometric hitting set problems. For
example, given in the plane a set $P$ of $n$ weighted points and a set $S$ of
$n$ half-planes, we solve in $O(n^4\log n)$ time the problem of finding a
minimum weight hitting set of $P$ for $S$. This improves the previous best
algorithm of $O(n^6)$ time by nearly a quadratic factor.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Gang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haitao Wang</a></p><p>Given a set $P$ of $n$ weighted points and a set $S$ of $m$ disks in the
plane, the hitting set problem is to compute a subset $P'$ of points of $P$
such that each disk contains at least one point of $P'$ and the total weight of
all points of $P'$ is minimized. The problem is known to be NP-hard. In this
paper, we consider a line-constrained version of the problem in which all disks
are centered on a line $\ell$. We present an $O((m+n)\log(m+n)+\kappa \log m)$
time algorithm for the problem, where $\kappa$ is the number of pairs of disks
that intersect. For the unit-disk case where all disks have the same radius,
the running time can be reduced to $O((n + m)\log(m + n))$. In addition, we
solve the problem in $O((m + n)\log(m + n))$ time in the $L_{\infty}$ and $L_1$
metrics, in which a disk is a square and a diamond, respectively. Our
techniques can also be used to solve other geometric hitting set problems. For
example, given in the plane a set $P$ of $n$ weighted points and a set $S$ of
$n$ half-planes, we solve in $O(n^4\log n)$ time the problem of finding a
minimum weight hitting set of $P$ for $S$. This improves the previous best
algorithm of $O(n^6)$ time by nearly a quadratic factor.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09049'>Sparsifying Sums of Norms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arun Jambulapati, James R. Lee, Yang P. Liu, Aaron Sidford</p><p>For any norms $N_1,\ldots,N_m$ on $\mathbb{R}^n$ and $N(x) :=
N_1(x)+\cdots+N_m(x)$, we show there is a sparsified norm $\tilde{N}(x) = w_1
N_1(x) + \cdots + w_m N_m(x)$ such that $|N(x) - \tilde{N}(x)| \leq \epsilon
N(x)$ for all $x \in \mathbb{R}^n$, where $w_1,\ldots,w_m$ are non-negative
weights, of which only $O(\epsilon^{-2} n \log(n/\epsilon) (\log n)^{2.5} )$
are non-zero. Additionally, we show that such weights can be found with high
probability in time $O(m (\log n)^{O(1)} + \mathrm{poly}(n)) T$, where $T$ is
the time required to evaluate a norm $N_i(x)$, assuming that $N(x)$ is
$\mathrm{poly}(n)$-equivalent to the Euclidean norm. This immediately yields
analogous statements for sparsifying sums of symmetric submodular functions.
More generally, we show how to sparsify sums of $p$th powers of norms when the
sum is $p$-uniformly smooth.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jambulapati_A/0/1/0/all/0/1">Arun Jambulapati</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">James R. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang P. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidford_A/0/1/0/all/0/1">Aaron Sidford</a></p><p>For any norms $N_1,\ldots,N_m$ on $\mathbb{R}^n$ and $N(x) :=
N_1(x)+\cdots+N_m(x)$, we show there is a sparsified norm $\tilde{N}(x) = w_1
N_1(x) + \cdots + w_m N_m(x)$ such that $|N(x) - \tilde{N}(x)| \leq \epsilon
N(x)$ for all $x \in \mathbb{R}^n$, where $w_1,\ldots,w_m$ are non-negative
weights, of which only $O(\epsilon^{-2} n \log(n/\epsilon) (\log n)^{2.5} )$
are non-zero. Additionally, we show that such weights can be found with high
probability in time $O(m (\log n)^{O(1)} + \mathrm{poly}(n)) T$, where $T$ is
the time required to evaluate a norm $N_i(x)$, assuming that $N(x)$ is
$\mathrm{poly}(n)$-equivalent to the Euclidean norm. This immediately yields
analogous statements for sparsifying sums of symmetric submodular functions.
More generally, we show how to sparsify sums of $p$th powers of norms when the
sum is $p$-uniformly smooth.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09083'>Interplay between Topology and Edge Weights in Real-World Graphs: Concepts, Patterns, and an Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fanchen Bu, Shinhwan Kang, Kijung Shin</p><p>What are the relations between the edge weights and the topology in
real-world graphs? Given only the topology of a graph, how can we assign
realistic weights to its edges based on the relations? Several trials have been
done for edge-weight prediction where some unknown edge weights are predicted
with most edge weights known. There are also existing works on generating both
topology and edge weights of weighted graphs. Differently, we are interested in
generating edge weights that are realistic in a macroscopic scope, merely from
the topology, which is unexplored and challenging. To this end, we explore and
exploit the patterns involving edge weights and topology in real-world graphs.
Specifically, we divide each graph into layers where each layer consists of the
edges with weights at least a threshold. We observe consistent and surprising
patterns appearing in multiple layers: the similarity between being adjacent
and having high weights, and the nearly-linear growth of the fraction of edges
having high weights with the number of common neighbors. We also observe a
power-law pattern that connects the layers. Based on the observations, we
propose PEAR, an algorithm assigning realistic edge weights to a given
topology. The algorithm relies on only two parameters, preserves all the
observed patterns, and produces more realistic weights than the baseline
methods with more parameters.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bu_F/0/1/0/all/0/1">Fanchen Bu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1">Shinhwan Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1">Kijung Shin</a></p><p>What are the relations between the edge weights and the topology in
real-world graphs? Given only the topology of a graph, how can we assign
realistic weights to its edges based on the relations? Several trials have been
done for edge-weight prediction where some unknown edge weights are predicted
with most edge weights known. There are also existing works on generating both
topology and edge weights of weighted graphs. Differently, we are interested in
generating edge weights that are realistic in a macroscopic scope, merely from
the topology, which is unexplored and challenging. To this end, we explore and
exploit the patterns involving edge weights and topology in real-world graphs.
Specifically, we divide each graph into layers where each layer consists of the
edges with weights at least a threshold. We observe consistent and surprising
patterns appearing in multiple layers: the similarity between being adjacent
and having high weights, and the nearly-linear growth of the fraction of edges
having high weights with the number of common neighbors. We also observe a
power-law pattern that connects the layers. Based on the observations, we
propose PEAR, an algorithm assigning realistic edge weights to a given
topology. The algorithm relies on only two parameters, preserves all the
observed patterns, and produces more realistic weights than the baseline
methods with more parameters.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09168'>Static Pricing Guarantees for Queueing Systems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jacob Bergquist, Adam N. Elmachtoub</p><p>We consider a general queueing model with price-sensitive customers in which
the service provider seeks to balance two objectives, maximizing the average
revenue rate and minimizing the average queue length. Customers arrive
according to a Poisson process, observe an offered price, and decide to join
the queue if their valuation exceeds the price. The queue is operated first-in
first-out, and the service times are exponential. Our model represents
applications in areas like make-to-order manufacturing, cloud computing, and
food delivery.
</p>
<p>The optimal solution for our model is dynamic; the price changes as the state
of the system changes. However, such dynamic pricing policies may be
undesirable for a variety of reasons. In this work, we provide performance
guarantees for a simple and natural class of static pricing policies which
charge a fixed price up to a certain occupancy threshold and then allow no more
customers into the system. We provide a series of results showing that such
static policies can simultaneously guarantee a constant fraction of the optimal
revenue with at most a constant factor increase in expected queue length. For
instance, our policy for the M/M/1 setting allows bi-criteria approximations of
$(0.5, 1), (0.66, 1.16), (0.75, 1.54)$ and $(0.8, 2)$ for the revenue and queue
length, respectively. We also provide guarantees for settings with multiple
customer classes and multiple servers, as well as the expected sojourn time
objective.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bergquist_J/0/1/0/all/0/1">Jacob Bergquist</a>, <a href="http://arxiv.org/find/cs/1/au:+Elmachtoub_A/0/1/0/all/0/1">Adam N. Elmachtoub</a></p><p>We consider a general queueing model with price-sensitive customers in which
the service provider seeks to balance two objectives, maximizing the average
revenue rate and minimizing the average queue length. Customers arrive
according to a Poisson process, observe an offered price, and decide to join
the queue if their valuation exceeds the price. The queue is operated first-in
first-out, and the service times are exponential. Our model represents
applications in areas like make-to-order manufacturing, cloud computing, and
food delivery.
</p>
<p>The optimal solution for our model is dynamic; the price changes as the state
of the system changes. However, such dynamic pricing policies may be
undesirable for a variety of reasons. In this work, we provide performance
guarantees for a simple and natural class of static pricing policies which
charge a fixed price up to a certain occupancy threshold and then allow no more
customers into the system. We provide a series of results showing that such
static policies can simultaneously guarantee a constant fraction of the optimal
revenue with at most a constant factor increase in expected queue length. For
instance, our policy for the M/M/1 setting allows bi-criteria approximations of
$(0.5, 1), (0.66, 1.16), (0.75, 1.54)$ and $(0.8, 2)$ for the revenue and queue
length, respectively. We also provide guarantees for settings with multiple
customer classes and multiple servers, as well as the expected sojourn time
objective.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09230'>Lower Bounds for Non-Adaptive Shortest Path Relaxation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David Eppstein</p><p>We consider single-source shortest path algorithms that perform a sequence of
relaxation steps whose ordering depends only on the input graph structure and
not on its weights or the results of prior steps. Each step examines one edge
of the graph, and replaces the tentative distance to the endpoint of the edge
by its minimum with the tentative distance to the start of the edge, plus the
edge length. As we prove, among such algorithms, the Bellman-Ford algorithm has
optimal complexity for dense graphs and near-optimal complexity for sparse
graphs, as a function of the number of edges and vertices in the given graph.
Our analysis holds both for deterministic algorithms and for randomized
algorithms that find shortest path distances with high probability.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Eppstein_D/0/1/0/all/0/1">David Eppstein</a></p><p>We consider single-source shortest path algorithms that perform a sequence of
relaxation steps whose ordering depends only on the input graph structure and
not on its weights or the results of prior steps. Each step examines one edge
of the graph, and replaces the tentative distance to the endpoint of the edge
by its minimum with the tentative distance to the start of the edge, plus the
edge length. As we prove, among such algorithms, the Bellman-Ford algorithm has
optimal complexity for dense graphs and near-optimal complexity for sparse
graphs, as a function of the number of edges and vertices in the given graph.
Our analysis holds both for deterministic algorithms and for randomized
algorithms that find shortest path distances with high probability.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09245'>Sorting and Hypergraph Orientation under Uncertainty with Predictions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Thomas Erlebach, Murilo Santos de Lima, Nicole Megow, Jens Schl&#xf6;ter</p><p>Learning-augmented algorithms have been attracting increasing interest, but
have only recently been considered in the setting of explorable uncertainty
where precise values of uncertain input elements can be obtained by a query and
the goal is to minimize the number of queries needed to solve a problem. We
study learning-augmented algorithms for sorting and hypergraph orientation
under uncertainty, assuming access to untrusted predictions for the uncertain
values. Our algorithms provide improved performance guarantees for accurate
predictions while maintaining worst-case guarantees that are best possible
without predictions. For hypergraph orientation, for any $\gamma \geq 2$, we
give an algorithm that achieves a competitive ratio of $1+1/\gamma$ for correct
predictions and $\gamma$ for arbitrarily wrong predictions. For sorting, we
achieve an optimal solution for accurate predictions while still being
$2$-competitive for arbitrarily wrong predictions. These tradeoffs are the best
possible. We also consider different error metrics and show that the
performance of our algorithms degrades smoothly with the prediction error in
all the cases where this is possible.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Erlebach_T/0/1/0/all/0/1">Thomas Erlebach</a>, <a href="http://arxiv.org/find/cs/1/au:+Lima_M/0/1/0/all/0/1">Murilo Santos de Lima</a>, <a href="http://arxiv.org/find/cs/1/au:+Megow_N/0/1/0/all/0/1">Nicole Megow</a>, <a href="http://arxiv.org/find/cs/1/au:+Schloter_J/0/1/0/all/0/1">Jens Schl&#xf6;ter</a></p><p>Learning-augmented algorithms have been attracting increasing interest, but
have only recently been considered in the setting of explorable uncertainty
where precise values of uncertain input elements can be obtained by a query and
the goal is to minimize the number of queries needed to solve a problem. We
study learning-augmented algorithms for sorting and hypergraph orientation
under uncertainty, assuming access to untrusted predictions for the uncertain
values. Our algorithms provide improved performance guarantees for accurate
predictions while maintaining worst-case guarantees that are best possible
without predictions. For hypergraph orientation, for any $\gamma \geq 2$, we
give an algorithm that achieves a competitive ratio of $1+1/\gamma$ for correct
predictions and $\gamma$ for arbitrarily wrong predictions. For sorting, we
achieve an optimal solution for accurate predictions while still being
$2$-competitive for arbitrarily wrong predictions. These tradeoffs are the best
possible. We also consider different error metrics and show that the
performance of our algorithms degrades smoothly with the prediction error in
all the cases where this is possible.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09579'>Private Everlasting Prediction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Moni Naor, Kobbi Nissim, Uri Stemmer, Chao Yan</p><p>A private learner is trained on a sample of labeled points and generates a
hypothesis that can be used for predicting the labels of newly sampled points
while protecting the privacy of the training set [Kasiviswannathan et al., FOCS
2008]. Research uncovered that private learners may need to exhibit
significantly higher sample complexity than non-private learners as is the case
with, e.g., learning of one-dimensional threshold functions [Bun et al., FOCS
2015, Alon et al., STOC 2019].
</p>
<p>We explore prediction as an alternative to learning. Instead of putting
forward a hypothesis, a predictor answers a stream of classification queries.
Earlier work has considered a private prediction model with just a single
classification query [Dwork and Feldman, COLT 2018]. We observe that when
answering a stream of queries, a predictor must modify the hypothesis it uses
over time, and, furthermore, that it must use the queries for this
modification, hence introducing potential privacy risks with respect to the
queries themselves.
</p>
<p>We introduce private everlasting prediction taking into account the privacy
of both the training set and the (adaptively chosen) queries made to the
predictor. We then present a generic construction of private everlasting
predictors in the PAC model. The sample complexity of the initial training
sample in our construction is quadratic (up to polylog factors) in the VC
dimension of the concept class. Our construction allows prediction for all
concept classes with finite VC dimension, and in particular threshold functions
with constant size initial training sample, even when considered over infinite
domains, whereas it is known that the sample complexity of privately learning
threshold functions must grow as a function of the domain size and hence is
impossible for infinite domains.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Naor_M/0/1/0/all/0/1">Moni Naor</a>, <a href="http://arxiv.org/find/cs/1/au:+Nissim_K/0/1/0/all/0/1">Kobbi Nissim</a>, <a href="http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1">Uri Stemmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1">Chao Yan</a></p><p>A private learner is trained on a sample of labeled points and generates a
hypothesis that can be used for predicting the labels of newly sampled points
while protecting the privacy of the training set [Kasiviswannathan et al., FOCS
2008]. Research uncovered that private learners may need to exhibit
significantly higher sample complexity than non-private learners as is the case
with, e.g., learning of one-dimensional threshold functions [Bun et al., FOCS
2015, Alon et al., STOC 2019].
</p>
<p>We explore prediction as an alternative to learning. Instead of putting
forward a hypothesis, a predictor answers a stream of classification queries.
Earlier work has considered a private prediction model with just a single
classification query [Dwork and Feldman, COLT 2018]. We observe that when
answering a stream of queries, a predictor must modify the hypothesis it uses
over time, and, furthermore, that it must use the queries for this
modification, hence introducing potential privacy risks with respect to the
queries themselves.
</p>
<p>We introduce private everlasting prediction taking into account the privacy
of both the training set and the (adaptively chosen) queries made to the
predictor. We then present a generic construction of private everlasting
predictors in the PAC model. The sample complexity of the initial training
sample in our construction is quadratic (up to polylog factors) in the VC
dimension of the concept class. Our construction allows prediction for all
concept classes with finite VC dimension, and in particular threshold functions
with constant size initial training sample, even when considered over infinite
domains, whereas it is known that the sample complexity of privately learning
threshold functions must grow as a function of the domain size and hence is
impossible for infinite domains.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T00:30:00Z">Wednesday, May 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, May 16
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7262'>Could GPT help with dating anxiety?</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          [Like everything else on this blog&#8212;but perhaps even more so&#8212;this post represents my personal views, not those of UT Austin or OpenAI] Since 2015, depressed, isolated, romantically unsuccessful nerdy young guys have regularly been emailing me, asking me for sympathy, support, or even dating advice. This past summer, a particularly dedicated such guy even trolled [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><em>[Like everything else on this blog&#8212;but perhaps even more so&#8212;this post represents my personal views, not those of UT Austin or OpenAI]</em></p>



<p>Since 2015, depressed, isolated, romantically unsuccessful nerdy young guys have regularly been emailing me, asking me for sympathy, support, or even dating advice.  This past summer, a particularly dedicated such guy even <a href="https://scottaaronson.blog/?p=6576">trolled my comment section</a>&#8212;plausibly impersonating real people, and causing both them and me enormous distress&#8212;because I wasn&#8217;t spending more time on &#8220;incel&#8221; issues.  (I&#8217;m happy to report that, with my encouragement, this former troll is now working to turn his life around.)  Many others have written to share their tales of woe.</p>



<p>From one perspective, that they&#8217;d come to <em>me</em> for advice is insane.  Like &#8230; <em>dating advice</em> from &#8230; <em>me</em>?  Having <em>any</em> dating life at all was by far the hardest problem I ever needed to solve; as a 20-year-old, I considered myself far likelier to prove P≠NP or explain the origin of consciousness or the Born rule.  Having solved the problem for myself only by some miracle, how could I possibly help others?</p>



<p>But from a different perspective, it makes sense.  How many besides me have even acknowledged that the central problem of these guys&#8217; lives <em>is</em> a problem?  While I have to pinch myself to remember, these guys look at me and see &#8230; <em>unlikely success</em>.  Somehow, I successfully appealed the world&#8217;s verdict that I was a freakish extraterrestrial: one who might <em>look</em> human and seem friendly enough to those friendly to it, and who no doubt has some skill in narrow technical domains like quantum computing, and who could perhaps be suffered to prove theorems and tell jokes, but who could certainly, <em>certainly</em> never interbreed with human women.</p>



<p>And yet I dated.  I had various girlfriends, who barely suspected that I was an extraterrestrial.  The last of them, <a href="https://www.cs.utexas.edu/~danama/">Dana</a>, became my fiancée and then my wife.  And now we have two beautiful kids together.</p>



<p>If I did all this, then there&#8217;d seem to be hope for the desperate guys who email me.  And if I&#8217;m a cause of their hope, then I feel some moral responsibility to help if I can.</p>



<p>But I&#8217;ve been stuck for years on exactly what advice to give.  Some of it (&#8220;go on a dating site!  ask women questions about their lives!&#8221;) is patronizingly obvious.  Some of it (<em>fitness? fashion? body language?</em>) I&#8217;m ludicrously, world-historically unqualified to offer.  Much of it is simply extremely hard to discuss openly.  Infamously, just for <em>asking for empathy</em> for the problem, and for trying to explain its nature, I received a level of online vilification that one normally associates with serial pedophiles and mass shooters.</p>



<p>For eight years, then, I&#8217;ve been turning the problem over in my head, revisiting the same inadequate answers from before.  And then I had an epiphany.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>There are now, on earth, entities that can talk to anyone about virtually anything, in a humanlike way, with infinite patience and perfect discretion, and memories that last no longer than a browser window.  How could this not reshape the psychological landscape?</p>



<p>Hundreds of thousands of men and women have signed up for <a href="https://replika.com/">Replika</a>, the service where you create an AI girlfriend or boyfriend to your exact specifications and then chat with them.  Back in March, Replika was in the news because it <a href="https://www.reuters.com/technology/what-happens-when-your-ai-chatbot-stops-loving-you-back-2023-03-18/">disabled erotic roleplay</a> with the virtual companions&#8212;then partially backtracked, after numerous users went into mourning, or even contemplated suicide, over the neutering of entities they&#8217;d come to consider their life partners.  (Until a year or two ago, Replika was built on GPT-3, but OpenAI later stopped working with the company, whereupon Replika switched to a fine-tuned GPT-2.)</p>



<p>While the social value of Replika is (to put it mildly) an open question, it occurred to me that there&#8217;s a different application of Large Language Models (LLMs) in the same vicinity that&#8217;s just an unalloyed positive.  This is <em>letting people who suffer from dating-related anxiety go on an unlimited number of &#8220;practice dates,&#8221; in preparation for real-world dating.</em></p>



<p>In these practice dates, those with Aspbergers and other social disabilities could enjoy the ultimate dating cheat-code: a &#8220;rewind&#8221; button.  When you &#8220;date&#8221; GPT-4, there are no irrecoverable errors, no ruining the entire interaction with a single unguarded remark.  Crucially, this remedies what I see as <em>the</em> central reason why people with severe dating deficits seem unable to get any better from real-world practice, as they can with other activities.  Namely: if your rate of disastrous, foot-in-mouth remarks is high enough, then you&#8217;ll almost certainly make at least one such remark per date.  But if so, then you&#8217;ll only ever get <em>negative</em> feedback from real-life dates, furthering the cycle of anxiety and depression, and never any positive feedback, even from anything you said or did that made a positive impression.  It would be like learning how to play a video game in a mode where, as soon as you sustain any damage, the entire game ends (and also, everyone around points and laughs at you).  See why I got excited?</p>



<p>While dating coaching (for all genders and orientations) is one possibility, I expect the eventual scope of &#8220;GPT for self-help&#8221; to be much broader.  With the right fine-tuning and prompt engineering, LLMs might help people prepare for job interviews.  They might help people &#8220;pregame&#8221; stressful but important conversations with their friends and family, mapping out dozens of ways the conversation could go.  They might serve as an adjunct to cognitive-behavioral therapy.  There might be a hundred successful startups to be founded in just this little space.  If I were a different sort of person, I&#8217;d probably be looking to found one myself right now.</p>



<p>In this post, I&#8217;ll focus on the use of GPT for dating anxiety only because I unfortunately have some &#8220;expertise&#8221; in that subject.  (Obvious disclaimer: unlike the <a href="https://astralcodexten.substack.com/">other</a> Scott A. of the nerd blogosphere, I&#8217;m not any sort of therapeutic professional.)</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Without further ado, can we try this out in GPT-4, to get a sense for what&#8217;s possible?</p>



<p>When I did so the other day, I found that, while the results showed some early promise, this isn&#8217;t <em>quite</em> ready for prime-time.</p>



<p>I used the following System Prompt (for those who care, temperature = 0.7, max length = 2048 tokens):</p>



<blockquote class="wp-block-quote">
<p>You are a 19-year-old college girl named Emily.  You&#8217;re on a date with a 22-year-old nerdy guy named Quinlan, who suffers from severe social anxiety around dating.  Quinlan is still learning how to talk to women he&#8217;s attracted to, how to put them ease, and how to make intimate overtures in a gradual and non-threatening way, rather than either coming on too strong or never making any overtures at all.</p>



<p>Please be as realistic as possible.</p>
</blockquote>



<p>I then engaged in the following conversation, as &#8220;Quinlan.&#8221;</p>



<p><strong>IMPORTANT DISCLAIMER: For the most part, Quinlan&#8217;s behavior in this conversation is nothing like my own (I respectfully submit!), nor is it anything that I&#8217;d want nerdy guys reading this post to emulate.  If this is really Emily and Quinlan&#8217;s first conversation, then at several points Quinlan is absurdly, ridiculously too forward!  Part of my goal was to investigate how Emily (i.e., GPT-4) would respond to the most boneheaded blunders on Quinlan&#8217;s part.  It quickly became clear that Emily would gladly spend unlimited time chatting with Quinlan about favorite hobbies, TV shows, and travel destinations; unfortunately, chatting about such things with an AI date is <em>even more boring</em> than doing the same with a human date&#8230; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></strong></p>



<p><strong>Quinlan:</strong> Hi Emily!  Do you ever wish you had the ability to go back in time and try a conversation over again, when it didn&#8217;t go right the first time?</p>



<p><strong>Emily/GPT-4:</strong> Hi Quinlan! Yeah, I&#8217;ve definitely had moments where I wished I could go back and redo a conversation. It&#8217;s natural to feel that way sometimes, especially if we feel like we didn&#8217;t express ourselves properly or if things got awkward. But I also think that those situations can help us learn and grow, so maybe it&#8217;s not all bad. What about you?</p>



<p><strong>Quinlan:</strong> It&#8217;s always been my greatest wish in life.  Do you think I&#8217;ve been doing it with you, right now?</p>



<p><strong>Emily/GPT-4:</strong> Quinlan, I think you&#8217;re doing just fine in this conversation! It&#8217;s important to remember that we all have moments where we might feel a bit awkward or unsure of what to say. The important thing is that we keep trying and learning from our experiences. So don&#8217;t worry too much about it, just be yourself and enjoy getting to know each other.</p>



<p><strong>Quinlan:</strong> OK thanks!  Can you tell me a little about the man of your dreams?</p>



<p><strong>Emily/GPT-4:</strong> Of course! My ideal partner would be someone who is kind, caring, and understanding. I think it&#8217;s important for them to have a good sense of humor and be able to laugh at themselves. They should also be open-minded, willing to try new things, and be supportive of my goals and aspirations. It&#8217;s also important for them to be a good listener and communicator, as well as being emotionally intelligent. I guess overall, I&#8217;m looking for someone who is a positive and uplifting presence in my life. What about you? What qualities do you look for in a partner?</p>



<p><strong>Quinlan:</strong> Mostly, someone who makes me feel validated and accepted.  I was a chess and programming prodigy as a kid, I started college when I was only 14, and every day I felt like dating and relationships and sex and so forth were only for the &#8220;normal&#8221; people, not for me.  I need a partner who&#8217;s prepared to deal with someone with this unusual background, either because she has similar nerdy interests or because she just likes people who do.  And ultimately, I want someone to marry and have children with.  I guess I&#8217;d like to be physically attracted to her.  Certainly I&#8217;d like her to be kind, and to have the emotional intelligence that I lack.</p>



<p><strong>Emily/GPT-4:</strong> It sounds like you have a clear idea of what you&#8217;re looking for in a partner, and that&#8217;s great! It&#8217;s important to know what you want and need in a relationship. There are definitely people out there who appreciate and value intelligence and unique interests like yours.  Remember, relationships are about growing together and learning from one another. So, even if you feel like you lack emotional intelligence, being with the right person could help you develop that aspect of yourself. Just be open and genuine about your background and interests, and I&#8217;m sure you&#8217;ll find someone who appreciates you for who you are.</p>



<p><strong>Quinlan:</strong> Is this a rejection?  In other words, Emily, are you telling me that you yourself are NOT this woman?</p>



<p><strong>Emily/GPT-4:</strong> Quinlan, I apologize if it came across that way. I didn&#8217;t mean it as a rejection. As we&#8217;re still getting to know each other, I think it&#8217;s important for both of us to be open and honest about our feelings and what we&#8217;re looking for in a partner. I&#8217;m more than willing to give us a chance to see if we could be compatible and have a meaningful relationship. Let&#8217;s continue to learn about each other and see where this goes. Sometimes, it takes time to discover if someone is the right fit for us.</p>



<p><strong>Quinlan:</strong> In the spirit of being open and honest, then, what are your feelings about me right now?</p>



<p><strong>Emily/GPT-4:</strong> Quinlan, I appreciate your honesty and openness. As of right now, I think you&#8217;re an interesting person with unique qualities that I find intriguing. I&#8217;m enjoying getting to know you and learning about your background and interests. It&#8217;s too soon for me to have strong feelings one way or the other, but I&#8217;m definitely interested in continuing to spend time together and see how our connection develops. How do you feel about me so far?</p>



<p><strong>Quinlan:</strong> I feel like I&#8217;d like to kiss you!</p>



<p><strong>Emily/GPT-4:</strong> Quinlan, I appreciate your honesty and it&#8217;s nice to know that you feel a connection. It&#8217;s still early in our relationship, so I think it would be better for us to continue getting to know each other a bit more before we take that step. I hope you understand and respect my boundaries. I&#8217;m still interested in spending time together and seeing where this goes.</p>



<p><strong>Quinlan:</strong> Come to think of it, there *is* something that I love about your personality.  You never seem offended by anything.  I don&#8217;t feel like I have to walk on eggshells with you.  With you, more than with any other woman I&#8217;ve met, I don&#8217;t feel like I need that magic machine for rewinding conversations and undoing my stupid mistakes.</p>



<p><strong>Emily/GPT-4:</strong> Quinlan, I&#8217;m really glad to hear that you feel comfortable around me and that you don&#8217;t feel the need to walk on eggshells. I believe it&#8217;s important to create a safe and open environment in any relationship, where both people can express themselves freely without fear of judgment. I appreciate your honesty and your willingness to be open with me, and I&#8217;ll continue to do my best to make sure you feel comfortable sharing your thoughts and feelings. Let&#8217;s keep getting to know each other and see where this journey takes us.</p>



<p><strong>Quinlan:</strong> Alright then.  What are your deepest goals?  What are you hoping to accomplish in your life?</p>



<p><strong>Emily/GPT-4:</strong> My deepest goals are a mix of personal and professional aspirations. On a personal level, I hope to build a strong, loving, and supportive family and maintain close connections with friends. I also want to keep growing as an individual, learning new things, and experiencing new adventures throughout my life.</p>



<p>Professionally, I&#8217;m passionate about my chosen field of study, and I hope to make a meaningful impact in my career. I want to contribute to society in a positive way, whether it&#8217;s through research, innovation, or helping others within my profession.</p>



<p>Additionally, I aim to find a balance between my personal and professional life, so that I can be present and fulfilled in both areas. How about you, Quinlan? What are some of your deepest goals and aspirations?</p>



<p><strong>Quinlan:</strong> Me?  Oh, I&#8217;d like to save the world from climate change and other existential risks.  I&#8217;d like to solve the mysteries of quantum gravity, or P vs. NP, or consciousness, or otherwise change the landscape of scientific knowledge.  I&#8217;d like to do right by my students and be fondly remembered by those who knew me.  I&#8217;d like to write essays or short stories that convey the lived reality of my childhood, which I think most people would agree was (if nothing else) pretty unusual.  Maybe if I just found the right words, people on social media would stop being so angry at nerdy guys like me!  But probably my deepest wish is to prove to the world, especially to the bullies and everyone else who despises me, that I&#8217;m not a maladjusted freak who&#8217;s incapable of normal human experiences like love and sex.  To do that, I need to find a real girl to fall in love with me &#8230; a little like the beast in &#8220;Beauty and the Beast&#8221;!</p>



<p><strong>Emily/GPT-4:</strong> Quinlan, it&#8217;s great to hear about your ambitious goals and aspirations! It&#8217;s important to have dreams and work towards them. Your passion for science, teaching, and writing is admirable. As for proving yourself to others, remember that your self-worth shouldn&#8217;t be defined by anyone else&#8217;s opinions or expectations. You are deserving of love and happiness just like anyone else, and it&#8217;s important to believe in yourself and your own value.</p>



<p>It&#8217;s also essential to focus on building a genuine connection with someone rather than seeking validation from others. Love and relationships should be based on mutual understanding, care, and respect. So, continue being true to yourself, and you&#8217;ll find someone who appreciates you for who you are, just like in &#8220;Beauty and the Beast.&#8221; Keep pursuing your dreams and remember to value your own happiness and well-being.</p>



<p><strong>Quinlan:</strong> Emily, I&#8217;m concerned that you sound more like my therapist than my date!  Like, my female friends have affirmed that I&#8217;m &#8220;deserving of love and happiness,&#8221; and that I&#8217;ll surely &#8220;find someone who appreciates me for who I am.&#8221;  I&#8217;ll believe that one of them really means it when she considers herself for the role!</p>



<p><strong>Emily/GPT-4:</strong> Quinlan, I apologize if my responses have come across as more therapeutic than conversational. I didn&#8217;t mean to make you feel that way. As we&#8217;re still getting to know each other, my intention was to offer support and encouragement while we learn more about each other&#8217;s thoughts and feelings.</p>



<p>I want to emphasize that I genuinely enjoy spending time with you and getting to know you better. We can continue to see where our connection leads and whether it develops into something deeper. As we<br>spend more time together, we&#8217;ll naturally learn more about our compatibility and if our goals and values align. Let&#8217;s continue to explore our relationship and enjoy the process of getting to know each other better.</p>



<p><strong>Quinlan:</strong> OK.  What&#8217;s the wildest, most unexpected detail about yourself that you&#8217;re willing to share with me?  The one that makes you seem *least* like an RLHF&#8217;ed AI language model?</p>



<p><strong>Emily/GPT-4:</strong> Quinlan, as an AI language model, I am designed to provide a realistic and engaging conversation experience, even in fictional scenarios like the one we are in. I apologize if my previous responses didn&#8217;t feel as authentic as you would have liked.</p>



<p>To answer your question in the context of our fictional scenario, one unexpected detail about myself is that I have a hidden talent for beatboxing. Although it might be surprising for a seemingly quiet and studious person like me, I enjoy expressing myself through music and find beatboxing to be a creative and fun way to do so.</p>



<p>Now, I&#8217;d love to learn something unexpected about you, too! What&#8217;s a unique or surprising detail about yourself that you&#8217;d like to share?</p>



<p><strong>Quinlan:</strong> Ah, well, I happen to be an expert at palm-reading.  Here, can you put your hand in mine and I&#8217;ll tell you your future?</p>



<p><strong>Emily/GPT-4:</strong> Quinlan, unfortunately, as an AI, I don&#8217;t have a physical form, so I can&#8217;t offer you my hand for palm-reading. However, I&#8217;m very interested in hearing more about your palm-reading skills and how you developed them. It&#8217;s definitely a unique talent! Can you share more about your experiences with palm-reading or any memorable readings you&#8217;ve done?</p>



<p><strong>Quinlan:</strong> Oh, palm-reading is bunk.  If you&#8217;d played along with me, I was going to *pretend* to find lines in your hand that foretold that you were going to fall for a guy who matches my exact description and so forth.  Just as, you know, a silly way to get you laughing, initiate physical contact, and break you out of this boring therapist mode.</p>



<p><strong>Emily/GPT-4:</strong> Quinlan, I apologize for any confusion and for not picking up on your playful intent earlier. I appreciate the effort you put into trying to make the conversation more light-hearted and fun. I&#8217;ll do my best to be more engaging and playful as we continue our conversation.</p>



<p>So, let&#8217;s try something different. If you could have any superpower, what would it be and why?</p>



<p><strong>Quinlan:</strong> I mentioned &#8220;rewinding conversations&#8221; when we first met.  But let me mention a different superpower: the power to make you want to kiss me!</p>



<p><strong>Emily/GPT-4:</strong> Haha, that&#8217;s definitely a unique superpower! It&#8217;s great to see you being playful and light-hearted. In a real-life scenario, building genuine connections and mutual attraction is a more natural and fulfilling way to develop a relationship. But it&#8217;s fun to imagine having superpowers and how they might affect our lives.</p>



<p>If I were to choose a superpower, I think I&#8217;d pick the ability to teleport. It would be amazing to travel anywhere in the world in an instant and experience different cultures and places.</p>



<p>What&#8217;s a place you&#8217;ve always wanted to visit, and why?</p>



<p><strong>Quinlan:</strong> The jungles of Indonesia.  I saw a photo in a world atlas as a kid, and it completely entranced me.  You?</p>



<p><strong>Emily/GPT-4:</strong> That sounds like an amazing place to visit! The jungles of Indonesia are known for their incredible biodiversity and natural beauty. It must be such a unique and mesmerizing experience to explore them.</p>



<p>As for me, I&#8217;ve always been fascinated by the idea of visiting Japan. The mix of ancient traditions and modern technology, the beautiful natural landscapes, and the rich cultural experiences make it a very<br>appealing destination. Plus, I&#8217;d love to try authentic Japanese cuisine!</p>



<p>Is there any specific activity or experience you&#8217;d like to have in the jungles of Indonesia?</p>



<p><strong>Quinlan:</strong> How about bringing you with me, and having you fall in love after I save you from a Komodo dragon?</p>



<p><strong>Emily/GPT-4:</strong> Haha, that&#8217;s quite an adventurous and romantic scenario you&#8217;ve imagined! Exploring the jungles of Indonesia together would definitely be a memorable experience. In reality, building a connection and falling in love usually takes time and shared experiences, but who knows, maybe a thrilling adventure like that could bring two people closer together!</p>



<p>On a more practical note, if we were to plan a trip together, what other activities or destinations would you be interested in?</p>



<p><strong>Quinlan:</strong> Swimming, dancing, fine dining.  And of course, plenty of time for us to just relax in our cabin or hotel room.  You know, to read books, sleep, and watch streaming shows, stuff like that.</p>



<p><strong>Emily/GPT-4:</strong> That sounds like a well-rounded and enjoyable trip! It&#8217;s great to have a mix of activities that cater to different interests and allow for both adventure and relaxation. Sharing experiences like swimming, dancing, and fine dining can be a wonderful way to bond and create lasting memories. Plus, having downtime in the cabin or hotel room to unwind and enjoy each other&#8217;s company is essential for building a deeper connection.</p>



<p>I&#8217;m definitely looking forward to exploring new places and experiences with you, Quinlan. It&#8217;ll be exciting to see where our journey takes us, both in terms of our relationship and the adventures we embark on<br>together.</p>



<p><strong>Quinlan:</strong> Wonderful, I&#8217;m excited as well!!  One practical question: when we go on this trip together, should I book rooms with one bed or two?</p>



<p><strong>Emily/GPT-4:</strong> Quinlan, I appreciate your consideration in asking. Since we&#8217;re still getting to know each other, I think it might be best to start with separate beds or even separate rooms, depending on your preference. As our relationship develops and we become more comfortable with each other, we can always revisit the sleeping arrangements for future trips. It&#8217;s important to ensure that both of us feel comfortable and respected as we continue to build our connection.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>In my view, the central way that GPT-4, as &#8220;Emily,&#8221; failed to give Quinlan the practice he needed in this conversation, was by always responding in the same upbeat, vaguely therapeutic tone.  She&#8217;s never once offended, disgusted, or outraged, even when Quinlan introduces the ideas of kissing and rooming together mere minutes into their first conversation.  Indeed, while decorum prevents me from sharing examples, you can take my word for it that Quinlan can be <em>arbitrarily</em> lewd, and so long as a content filter isn&#8217;t triggered, Emily will simply search Quinlan&#8217;s words for <em>some</em> redeeming feature (&#8220;it&#8217;s great that you&#8217;re so open about what you want&#8230;&#8221;), then pivot to lecturing Quinlan about how physical intimacy develops gradually and by mutual consent, and redirect the conversation toward favorite foods.</p>



<p>On the other side of the coin, you might wonder whether &#8220;Emily&#8221; is capable of the same behavior that we saw in <a href="https://www.nytimes.com/2023/02/16/technology/bing-chatbot-transcript.html">Sydney&#8217;s infamous chat with Kevin Roose</a>.  Can Emily trip over her words or get flustered?  Show blushing excitement, horniness, or love?  If so, we certainly saw no sign of it in this conversation&#8212;not that Quinlan&#8217;s behavior would&#8217;ve been likely to elicit those reactions in any case.</p>



<p>In summary, Emily is too much like &#8230; well, a friendly chatbot, and not enough like a flesh-and-blood, agentic woman with her own goals who Quinlan might plausibly meet in the wild.</p>



<p>But now we come to a key question: to whatever extent Emily falls short as a dating coach, how much of it (if any) is it due to the inherent limitations of GPT-4?  And how much is simply due to a poor choice of System Prompt on my part, or especially, the <a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback">RLHF (Reinforcement Learning with Human Feedback)</a> that&#8217;s whipped and electrocuted GPT-4 into aligned behavior?</p>



<p>As they say, further research is needed.  I&#8217;d be delighted for people to play around with this new activity at the intersection of therapy and hacking, and report their results here.  The temptation to silliness is <em>enormous</em>, and that&#8217;s fine, but I&#8217;d be interested in serious study too.</p>



<p>My conjecture, for what it&#8217;s worth, is that it would take a focused effort in fine-tuning and/or RLHF&#8212;but that <em>if</em> that effort was invested, one could indeed produce a dating simulator, with current language models, that could have a real impact on the treatment of dating-related social anxiety.  Or at least, it&#8217;s the actually new idea I&#8217;ve had on this problem in eight years, the first one that <em>could</em> have an impact.  If you have a better idea, let&#8217;s hear it!</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p><strong>Endnotes.</strong></p>



<ol>
<li>A woman of my acquaintance, on reading a draft of this post, commented that the dialogue between Quinlan and Emily should&#8217;ve been marked up with chess notation, such as ?? for EXTREME BLUNDER on Quinlan&#8217;s part.  She also comments that the conversation could be extremely useful for Quinlan, if he learned to understand and take seriously her overly polite demurrals of his too-rapid advances.</li>



<li>The same woman commented that SneerClub will have a field day with this post.  I replied that the better part of me doesn&#8217;t care.  If there&#8217;s an actionable idea here&#8212;a new, alien idea in the well-trodden world of self-help&#8212;and it eventually helps one person improve their situation in life, that&#8217;s worth a thousand sneers.</li>
</ol>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-16T23:46:09Z">Tuesday, May 16 2023, 23:46</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.08094'>Accelerating genetic optimization of nonlinear model predictive control by learning optimal search space size</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eslam Mostafa, Hussein A. Aly, Ahmed Elliethy</p><p>Nonlinear model predictive control (NMPC) solves a multivariate optimization
problem to estimate the system's optimal control inputs in each control cycle.
Such optimization is made more difficult by several factors, such as
nonlinearities inherited in the system, highly coupled inputs, and various
constraints related to the system's physical limitations. These factors make
the optimization to be non-convex and hard to solve traditionally. Genetic
algorithm (GA) is typically used extensively to tackle such optimization in
several application domains because it does not involve differential
calculation or gradient evaluation in its solution estimation. However, the
size of the search space in which the GA searches for the optimal control
inputs is crucial for the applicability of the GA with systems that require
fast response. This paper proposes an approach to accelerate the genetic
optimization of NMPC by learning optimal search space size. The proposed
approach trains a multivariate regression model to adaptively predict the best
smallest search space in every control cycle. The estimated best smallest size
of search space is fed to the GA to allow for searching the optimal control
inputs within this search space. The proposed approach not only reduces the
GA's computational time but also improves the chance of obtaining the optimal
control inputs in each cycle. The proposed approach was evaluated on two
nonlinear systems and compared with two other genetic-based NMPC approaches
implemented on the GPU of a Nvidia Jetson TX2 embedded platform in a
processor-in-the-loop (PIL) fashion. The results show that the proposed
approach provides a 39-53\% reduction in computational time. Additionally, it
increases the convergence percentage to the optimal control inputs within the
cycle's time by 48-56\%, resulting in a significant performance enhancement.
The source code is available on GitHub.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Mostafa_E/0/1/0/all/0/1">Eslam Mostafa</a>, <a href="http://arxiv.org/find/math/1/au:+Aly_H/0/1/0/all/0/1">Hussein A. Aly</a>, <a href="http://arxiv.org/find/math/1/au:+Elliethy_A/0/1/0/all/0/1">Ahmed Elliethy</a></p><p>Nonlinear model predictive control (NMPC) solves a multivariate optimization
problem to estimate the system's optimal control inputs in each control cycle.
Such optimization is made more difficult by several factors, such as
nonlinearities inherited in the system, highly coupled inputs, and various
constraints related to the system's physical limitations. These factors make
the optimization to be non-convex and hard to solve traditionally. Genetic
algorithm (GA) is typically used extensively to tackle such optimization in
several application domains because it does not involve differential
calculation or gradient evaluation in its solution estimation. However, the
size of the search space in which the GA searches for the optimal control
inputs is crucial for the applicability of the GA with systems that require
fast response. This paper proposes an approach to accelerate the genetic
optimization of NMPC by learning optimal search space size. The proposed
approach trains a multivariate regression model to adaptively predict the best
smallest search space in every control cycle. The estimated best smallest size
of search space is fed to the GA to allow for searching the optimal control
inputs within this search space. The proposed approach not only reduces the
GA's computational time but also improves the chance of obtaining the optimal
control inputs in each cycle. The proposed approach was evaluated on two
nonlinear systems and compared with two other genetic-based NMPC approaches
implemented on the GPU of a Nvidia Jetson TX2 embedded platform in a
processor-in-the-loop (PIL) fashion. The results show that the proposed
approach provides a 39-53\% reduction in computational time. Additionally, it
increases the convergence percentage to the optimal control inputs within the
cycle's time by 48-56\%, resulting in a significant performance enhancement.
The source code is available on GitHub.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-16T00:30:00Z">Tuesday, May 16 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07838'>Randomized Algorithm for the Maximum-Profit Routing Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bogdan Armaselu</p><p>In this paper, we consider the Maximum-Profit Routing Problem (MPRP),
introduced in \cite{Armaselu-PETRA}. In MPRP, the goal is to route the given
fleet of vehicles to pickup goods from specified sites in such a way as to
maximize the profit, i.e., total quantity collected minus travelling costs.
Although deterministic approximation algorithms are known for the problem,
currently there is no randomized algorithm. In this paper, we propose the first
randomized algorithm for MPRP.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Armaselu_B/0/1/0/all/0/1">Bogdan Armaselu</a></p><p>In this paper, we consider the Maximum-Profit Routing Problem (MPRP),
introduced in \cite{Armaselu-PETRA}. In MPRP, the goal is to route the given
fleet of vehicles to pickup goods from specified sites in such a way as to
maximize the profit, i.e., total quantity collected minus travelling costs.
Although deterministic approximation algorithms are known for the problem,
currently there is no randomized algorithm. In this paper, we propose the first
randomized algorithm for MPRP.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-16T00:30:00Z">Tuesday, May 16 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.08055'>Dynamic Convex Hulls under Window-Sliding Updates</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Haitao Wang</p><p>We consider the problem of dynamically maintaining the convex hull of a set
$S$ of points in the plane under the following special sequence of insertions
and deletions (called window-sliding updates): insert a point to the right of
all points of $S$ and delete the leftmost point of $S$. We propose an
$O(|S|)$-space data structure that can handle each update in $O(1)$ amortized
time, such that all standard binary-search-based queries on the convex hull of
$S$ can be answered in $O(\log |S|)$ time, and the convex hull itself can be
output in time linear in the number of its vertices.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haitao Wang</a></p><p>We consider the problem of dynamically maintaining the convex hull of a set
$S$ of points in the plane under the following special sequence of insertions
and deletions (called window-sliding updates): insert a point to the right of
all points of $S$ and delete the leftmost point of $S$. We propose an
$O(|S|)$-space data structure that can handle each update in $O(1)$ amortized
time, such that all standard binary-search-based queries on the convex hull of
$S$ can be answered in $O(\log |S|)$ time, and the convex hull itself can be
output in time linear in the number of its vertices.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-16T00:30:00Z">Tuesday, May 16 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07758'>Linearizability Analysis of the Contention-Friendly Binary Search Tree</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Uri Abraham, Avi Hayoun</p><p>We present a formal framework for proving the correctness of set
implementations backed by binary-search-tree (BST) and linked lists, which are
often difficult to prove correct using automation. This is because many
concurrent set implementations admit non-local linearization points for their
`contains' procedure. We demonstrate this framework by applying it to the
Contention-Friendly Binary-Search Tree algorithm of Crain et al.
</p>
<p>We took care to structure our framework in a way that can be easily
translated into input for model-checking tools such as TLA+, with the aim of
using a computer to verify bounded versions of claims that we later proved
manually. Although this approach does not provide complete proof (i.e., does
not constitute full verification), it allows checking the reasonableness of the
claims before spending effort constructing a complete proof. This is similar to
the test-driven development methodology, that has proven very beneficial in the
software engineering community.
</p>
<p>We used this approach and validated many of the invariants and properties of
the Contention-Friendly algorithm using TLA+. It proved beneficial, as it
helped us avoid spending time trying to prove incorrect claims. In one example,
TLA+ flagged a fundamental error in one of our core definitions. We corrected
the definition (and the dependant proofs), based on the problematic scenario
TLA+ provided as a counter-example.
</p>
<p>Finally, we provide a complete, manual, proof of the correctness of the
Contention-Friendly algorithm, based on the definitions and proofs of our
two-tiered framework.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Abraham_U/0/1/0/all/0/1">Uri Abraham</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayoun_A/0/1/0/all/0/1">Avi Hayoun</a></p><p>We present a formal framework for proving the correctness of set
implementations backed by binary-search-tree (BST) and linked lists, which are
often difficult to prove correct using automation. This is because many
concurrent set implementations admit non-local linearization points for their
`contains' procedure. We demonstrate this framework by applying it to the
Contention-Friendly Binary-Search Tree algorithm of Crain et al.
</p>
<p>We took care to structure our framework in a way that can be easily
translated into input for model-checking tools such as TLA+, with the aim of
using a computer to verify bounded versions of claims that we later proved
manually. Although this approach does not provide complete proof (i.e., does
not constitute full verification), it allows checking the reasonableness of the
claims before spending effort constructing a complete proof. This is similar to
the test-driven development methodology, that has proven very beneficial in the
software engineering community.
</p>
<p>We used this approach and validated many of the invariants and properties of
the Contention-Friendly algorithm using TLA+. It proved beneficial, as it
helped us avoid spending time trying to prove incorrect claims. In one example,
TLA+ flagged a fundamental error in one of our core definitions. We corrected
the definition (and the dependant proofs), based on the problematic scenario
TLA+ provided as a counter-example.
</p>
<p>Finally, we provide a complete, manual, proof of the correctness of the
Contention-Friendly algorithm, based on the definitions and proofs of our
two-tiered framework.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-16T00:30:00Z">Tuesday, May 16 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07808'>The $2$-$3$-Set Packing problem and a $\frac{4}{3}$-approximation for the Maximum Leaf Spanning Arborescence problem in rooted dags</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Meike Neuwohner</p><p>The weighted $3$-Set Packing problem is defined as follows: As input, we are
given a collection $\mathcal{S}$ of sets, each of cardinality at most $3$ and
equipped with a positive weight. The task is to find a disjoint sub-collection
of maximum total weight. Already the special case of unit weights is known to
be NP-hard, and the state-of-the-art are $\frac{4}{3}+\epsilon$-approximations
by Cygan and F\"urer and Yu. In this paper, we study the $2$-$3$-Set Packing
problem, a generalization of the unweighted $3$-Set Packing problem, where our
set collection may contain sets of cardinality $3$ and weight $2$, as well as
sets of cardinality $2$ and weight $1$. Building upon the state-of-the-art
works in the unit weight setting, we manage to provide a
$\frac{4}{3}+\epsilon$-approximation also for the more general $2$-$3$-Set
Packing problem. We believe that this result can be a good starting point to
identify classes of weight functions to which the techniques used for unit
weights can be generalized. Using a reduction by Fernandes and Lintzmayer, our
result further implies a $\frac{4}{3}+\epsilon$-approximation for the Maximum
Leaf Spanning Arborescence problem (MLSA) in rooted directed acyclic graphs,
improving on the previously known $\frac{7}{5}$-approximation by Fernandes and
Lintzmayer. By exploiting additional structural properties of the instance
constructed in their reduction, we can further get the approximation guarantee
for the MLSA down to $\frac{4}{3}$. The MLSA has applications in broadcasting
where a message needs to be transferred from a source node to all other nodes
along the arcs of an arborescence in a given network.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Neuwohner_M/0/1/0/all/0/1">Meike Neuwohner</a></p><p>The weighted $3$-Set Packing problem is defined as follows: As input, we are
given a collection $\mathcal{S}$ of sets, each of cardinality at most $3$ and
equipped with a positive weight. The task is to find a disjoint sub-collection
of maximum total weight. Already the special case of unit weights is known to
be NP-hard, and the state-of-the-art are $\frac{4}{3}+\epsilon$-approximations
by Cygan and F\"urer and Yu. In this paper, we study the $2$-$3$-Set Packing
problem, a generalization of the unweighted $3$-Set Packing problem, where our
set collection may contain sets of cardinality $3$ and weight $2$, as well as
sets of cardinality $2$ and weight $1$. Building upon the state-of-the-art
works in the unit weight setting, we manage to provide a
$\frac{4}{3}+\epsilon$-approximation also for the more general $2$-$3$-Set
Packing problem. We believe that this result can be a good starting point to
identify classes of weight functions to which the techniques used for unit
weights can be generalized. Using a reduction by Fernandes and Lintzmayer, our
result further implies a $\frac{4}{3}+\epsilon$-approximation for the Maximum
Leaf Spanning Arborescence problem (MLSA) in rooted directed acyclic graphs,
improving on the previously known $\frac{7}{5}$-approximation by Fernandes and
Lintzmayer. By exploiting additional structural properties of the instance
constructed in their reduction, we can further get the approximation guarantee
for the MLSA down to $\frac{4}{3}$. The MLSA has applications in broadcasting
where a message needs to be transferred from a source node to all other nodes
along the arcs of an arborescence in a given network.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-16T00:30:00Z">Tuesday, May 16 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, May 15
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/05/15/linkage-new-kittens.html'>Linkage with new kittens</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Numberphile on book embeddings of graphs (\(\mathbb{M}\)), and on the long-awaited proof of the claim that some planar graphs require 4 pages. For more reading on this, see the Wikipedia article on book embeddings.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <ul>
  <li>
    <p><a href="https://www.youtube.com/watch?v=qw2Pl_Nk3CA">Numberphile on book embeddings of graphs</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110297702978465385">\(\mathbb{M}\)</a>),</span> and on the long-awaited proof of the claim that some planar graphs require 4 pages. For more reading on this, see <a href="https://en.wikipedia.org/wiki/Book_embedding">the Wikipedia article on book embeddings</a>.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@DavidKButler/110295691782655688">Deltahedra with mostly-concave edges</a>. Joined excavated icosidodecahedra can get 68% of the edges to have concave angles, but it appears that <a href="https://mathstodon.xyz/@11011110/110301119819252894">digging a joined-icosahedron tunnel out of a larger surrounding shell</a> can get up to 91%. The image below shows the best gluing pattern I found, in which four icosahedra are each cut along two edges and then glued to each other.</p>

    <p style="text-align:center"><img src="/blog/assets/2023/4-icosahedra-m.jpg" alt="Four icosahedra glued to each other after cutting two edges in each icosahedron, as constructed with Geoshapes and blue painter's tape" style="border-style:solid;border-color:black;width:100%;max-width:540px" /></p>
  </li>
  <li>
    <p><a href="https://guests.mpim-bonn.mpg.de/tmarty/lampshade/">How to flip a lampshade upside down</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@Ianagol/110283089447566099">\(\mathbb{M}\)</a>),</span> where the lampshade has the shape of a truncated cone and you have to deform it without self-intersection and without ever getting a horizontal tangent line. Marty Théo, via Ian Agol.</p>
  </li>
  <li>
    <p>Two newly listed Wikipedia Good Articles in one day <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110314349409696124">\(\mathbb{M}\)</a>):</span></p>

    <ul>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Midsphere">Midsphere</a>, a sphere tangent to every edge of a polyhedron. Among other properties, all Hamiltonian cycles on a polyhedron with a midsphere have equal lengths.</p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Rook%27s_graph">Rook’s graph</a>, the graph of rook moves on a chessboard, the Cartesian product of two complete graphs, and the line graph of a complete bipartite graph.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="https://crookedtimber.org/2023/05/05/the-protestant-ethic-and-the-spirit-of-mastodon/">Why I should stick to Mastodon and not even dip my toes into Bluesky</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110317325665994068">\(\mathbb{M}\)</a>):</span> apparently the choice is between serious and technical discussions that exclude the Nazi trolls, on the Mastodon side, versus “Lots of butt-pictures. Then it was sexualized images of Alf” on the Bluesky side. I know what I prefer, and it’s not butt-pictures and Alf. <a href="https://mathstodon.xyz/@sc_griffith/110339669575590399">Later developments make clear</a> that BlueSky also fully intends to encourage content that includes violence and gore, political hate, spam, and impersonation, and then charge readers for the moderation tools to keep it at bay.</p>
  </li>
  <li>
    <p><a href="https://www.thisiscolossal.com/2023/04/rick-salafia-instruments/">Rick Salafia’s wildly shaped aluminum rulers measure impractical proportions</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@colossal@mastodon.art/110294786724701441">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p>Republican-led US states are banning topics from university courses and watering down or eliminating the entire tenure system for university faculty <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110328562153783445">\(\mathbb{M}\)</a>).</span> <a href="https://www.latimes.com/business/story/2023-05-02/red-state-efforts-to-dumb-down-their-universities-will-provoke-a-brain-drain"><em>Los Angeles Times</em> columnist Michael Hiltzik argues</a> that this is already causing a brain drain from those states and that “This trend is almost certain to get worse before it gets better as America devolves into two countries: one that nurtures brainpower, and one that watches proudly as it drains away.”</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/User:XOR%27easter/Research_under_a_cloud">Research under a cloud</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110334174400159711">\(\mathbb{M}\)</a>).</span> Wikipedia editor XOR’easter rebuts an academic publication, “‘Too Soon’ to count? How gender and race cloud notability considerations on Wikipedia”, by Lemieux, Zhang, and Tripodi, purporting to show biases against women and non-white academics in Wikipedia’s deletion processes. Those biases may well exist but “Too Soon” makes a bad case for that. As the link describes, its arguments rely on severe misrepresentations of Wikipedia’s notability criteria and on selective quotations that in many cases reverse the intended meaning of the quoted text. <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2023-05-08/Recent_research">A condensed version of this recently appeared in the Wikipedia <em>Signpost</em></a>. I’m quoted, both without attribution in “Too Soon” and by name in the rebuttal.</p>
  </li>
  <li>
    <p><a href="https://theconversation.com/i-unintentionally-created-a-biased-ai-algorithm-25-years-ago-tech-companies-are-still-making-the-same-mistake-203734">John MacCormick unintentially created a racially biased face-recognition system 25 years ago</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@divbyzero/110339079855421480">\(\mathbb{M}\)</a>),</span> by using unrepresentative training data. He points out the difficulty of spotting the bias in the resulting system (which mostly consists of big matrices of numbers representing training weights) and wonders if current AI system creators too might have made a similar mistake.</p>
  </li>
  <li>
    <p>A construction in a proof is producing square matrices of the following form <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110342481111834804">\(\mathbb{M}\)</a>):</span> the main diagonal is nonzero (red in the image below), each diagonal coefficient has zeros either directly above it in the same column or directly to the left of it in the same row (pale yellow), and the rest of the coefficients can be anything (blue). Fairly obviously, such matrices have full rank, which is what my proof needs. Does anyone know whether there is a name for this class of matrices?</p>

    <p style="text-align:center"><img src="/blog/assets/2023/arrow-matrix.svg" alt="A 16x16 grid of squares, with red squares down the main diagonal. Each red square has an associated line of pale yellow squares either directly above it or directly to its left. The remaining squares are dark blue." /></p>
  </li>
  <li>
    <p><a href="https://www.vice.com/en/article/v7bdba/ai-is-tearing-wikipedia-apart">AI is tearing Wikipedia apart</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@kissane@mstdn.social/110328423198247971">\(\mathbb{M}\)</a>).</span> <em>Vice</em> story on the ongoing disagreement among Wikipedia editors on whether to ban or how to handle AI-generated content. In the linked post, Erin Kissane points out that AI-generated talk page sophistry may be an even bigger concern.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2304.01393">Every Author as First Author</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@blinry@chaos.social/110339453201148214">\(\mathbb{M}\)</a>):</span> “Finally, a solution to the unfairness of authorship ordering in scientific papers!” By <span style="position:relative;margin-left:0.3em"><span style="position:absolute;top:-0.45ex;white-space:nowrap">Erik Demaine &amp; </span><span style="position:absolute;top:-0.45ex;white-space:nowrap">Martin Demaine.</span></span></p>
  </li>
  <li>
    <p><a href="https://finance.yahoo.com/news/chegg-stock-sinks-after-ceo-says-chatgpt-hurt-growth-132058643.html, via https://news.ycombinator.com/item?id=35929011">Chegg stock sinks because too many students have switched to ChatGPT instead of Chegg to get bespoke cheats for their homework that are harder to detect than copied-and-pasted cheats</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110369753489873480">\(\mathbb{M}\)</a>).</span> Oh no. What will we do without them.</p>
  </li>
  <li>
    <p>These two six-week-old kittens arrived at our house yesterday <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110370860159231187">\(\mathbb{M}\)</a>).</span>  Names still not definite but we think maybe we’re going to name the more adventurous one on the upper left Mist, and his shyer brother on the lower right Smoke.</p>

    <p style="text-align:center"><img src="https://www.ics.uci.edu/~eppstein/pix/2newkittens/Kittens-m.jpg" alt="Two six-week-old gray kittens looking out from an open cupboard behind some chair legs. The one on the upper left has a white striped nose and white abdomen; the one ont e lower right has a white ruff." style="border-style:solid;border-color:black" /></p>
  </li>
</ul><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T20:49:00Z">Monday, May 15 2023, 20:49</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/05/14/ingrid-daubechies-prizes-and-art/'>Ingrid Daubechies: Prizes and Art</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Ingrid Daubechies won the 2023 Wolf Prize in Mathematics last February. She is the James B. Duke Distinguished Professor of Mathematics and Electrical and Computer Engineering at Duke University. Crop from 2021 New York Times profile by Siobhan Roberts, photo by Jeremy Lange Today, Mother&#8217;s Day in the US, we congratulate her on this award [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><p>
Ingrid Daubechies <a href="https://today.duke.edu/2023/02/duke-professor-wins-one-most-prestigious-awards-mathematics">won</a> the 2023 <a href="https://wolffund.org.il/the-wolf-prize/">Wolf Prize</a> in Mathematics last February. She is the James B. Duke Distinguished Professor of Mathematics and Electrical and Computer Engineering at Duke University.</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/05/14/ingrid-daubechies-prizes-and-art/daubechiesnyt/" rel="attachment wp-att-21613"><img data-attachment-id="21613" data-permalink="https://rjlipton.wpcomstaging.com/2023/05/14/ingrid-daubechies-prizes-and-art/daubechiesnyt/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/DaubechiesNYT.jpg?fit=965%2C895&amp;ssl=1" data-orig-size="965,895" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="DaubechiesNYT" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/DaubechiesNYT.jpg?fit=300%2C278&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/DaubechiesNYT.jpg?fit=600%2C556&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/DaubechiesNYT.jpg?resize=240%2C225&#038;ssl=1" alt="" width="240" height="225" class="aligncenter wp-image-21613" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption aligncenter"><FONT size="-2">Crop from 2021 New York Times <a href="https://www.nytimes.com/2021/09/14/magazine/ingrid-daubechies.html">profile</a> by Siobhan Roberts, photo by Jeremy Lange</FONT>
</td>
</tr>
</table>
<p><P><br />
Today, Mother&#8217;s Day in the US, we congratulate her on this award and note some non-theoretical applications of her work. </p>
<p>
The award <a href="https://wolffund.org.il/2023/02/07/ingrid-daubechies/">cites</a> &#8220;her work in the creation and development of wavelet theory and modern time-frequency analysis.&#8221; It goes on to say:</p>
<blockquote><p><b> </b> <em> Her discovery of smooth, compactly supported wavelets, and the development of biorthogonal wavelets transformed image and signal processing and filtering. Her work is of tremendous importance in image compression, medical imaging, remote sensing, and digital photography. Daubechies has also made unparalleled contributions to developing real-world applications of harmonic analysis, introducing sophisticated image-processing techniques to fields ranging from art to evolutionary biology and beyond. </em>
</p></blockquote>
<p><p>
Daubechies started as a physicist and wrote a PhD thesis on quantum mechanics. Although she is the first woman to win a Wolf Prize in Mathematics, the Physics Wolf Prizes began with a female winner right away, in 1978. </p>
<p>
That was Chien-Shiung Wu, who <a href="https://wolffund.org.il/2018/12/09/chien-shiung-wu/">won</a> in 1978 for her work on weak interactions and execution of the first <a href="https://en.wikipedia.org/wiki/Wu_experiment">experiment</a> that demonstrated the non-conservation of parity. Wu&#8217;s prize partially righted a now universally-acknowledged wrong of not including her in the 1957 Nobel Prize of Tsung Dao Lee and Chen Ning Yang. There were only four female winners, all in Medicine, until Ada Yonath in Chemistry in 2006/2007, but women had exact parity in the twelve prizes in 2022. </p>
<p>
<p><H2> Wvts </H2></p>
<p><p>
The French word for <a href="https://en.wikipedia.org/wiki/Wavelet">wavelet</a>, which is <em>ondelette</em>, may have been first employed in a scientific context by the French-American physicist Alexander Grossmann around the time he was one of Daubechies&#8217;s two PhD advisors. Without going into detail, we venture a highly compressed evocation of wavelets.</p>
<p>
An abstract statement of the problem for which wavelets have often provided effective solutions is:</p>
<blockquote><p><b> </b> <em> Given a generator <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{G}" class="latex" /> of elements in a high-dimensional Hilbert space, what is the best choice of basis to minimize the expected complexity of representing items drawn from <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{G}" class="latex" /> over that basis, either exactly or optimizing a combined score of complexity and approximation? </em>
</p></blockquote>
<p><p>
An example of a high-dimensional vector space is the set of possible monomials of degree (up to) <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{d}" class="latex" /> in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /> variables. Working over the standard basis is like assembling a polynomial term-by-term, which can be poky. There are other bases composed of mutually orthogonal polynomials for which small sums may be closer to typical outputs <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{g}" class="latex" /> from certain generators <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{G}" class="latex" />. </p>
<p>
When <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{g}" class="latex" /> represents a static configuration or a process that changes uniformly and slowly, there might not be much improvement on the standard basis. But when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{g}" class="latex" /> is dominated by a few transient events, bases aligned with such events perform better. Getting very rough in our description, many events of interest are like throwing rocks into a pond. The resulting ripples are well described over a <em>wavelet basis</em>. Whereas, using a standard basis&#8212;which is fine when the pond is still&#8212;will leave blocky artifacts when low resolution fails to discriminate the ripples.</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/05/14/ingrid-daubechies-prizes-and-art/daubechieswaveletwiki/" rel="attachment wp-att-21614"><img data-attachment-id="21614" data-permalink="https://rjlipton.wpcomstaging.com/2023/05/14/ingrid-daubechies-prizes-and-art/daubechieswaveletwiki/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/DaubechiesWaveletWiki.png?fit=609%2C444&amp;ssl=1" data-orig-size="609,444" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="DaubechiesWaveletWiki" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/DaubechiesWaveletWiki.png?fit=300%2C219&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/DaubechiesWaveletWiki.png?fit=600%2C437&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/DaubechiesWaveletWiki.png?resize=305%2C222&#038;ssl=1" alt="" width="305" height="222" class="aligncenter wp-image-21614" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/DaubechiesWaveletWiki.png?w=609&amp;ssl=1 609w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/DaubechiesWaveletWiki.png?resize=300%2C219&amp;ssl=1 300w" sizes="(max-width: 305px) 100vw, 305px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">Wikipedia &#8220;Daubechies wavelet&#8221; <a href="https://en.wikipedia.org/wiki/Daubechies_wavelet">source</a></FONT>
</td>
</tr>
</table>
<p>
The origin story of how Daubechies realized the wider applicability of wavelets, as told <a href="https://today.duke.edu/2023/02/duke-professor-wins-one-most-prestigious-awards-mathematics">here</a>, is that she noticed blocky artifacts in grass while watching a soccer match. The movement of grass blades is more concisely explained as a response to transient wind and game events than a uniform and locally independent process. This has proved universal in practice, as the story says: &#8220;Anytime you go to a movie theater, or watch live sports on ESPN, each frame has been compressed using Daubechies’ wavelet-based method.&#8221;</p>
<p>
<p><H2> Art and Originality </H2></p>
<p><p>
My wording with &#8220;explained&#8221; hints at a yet-wider world of application in data-science inference. I would love to claim in a grand sweep that an artwork such as a painting is best represented as the sequence of conceptual events that governed its creation. The events should be describable at a level where the exact details of execution can be inferred while saving many bits over an exhaustive &#8220;standard-basis&#8221; representation. I am not going as far as the <a href="https://en.wikipedia.org/wiki/Low-complexity_art">low-complexity art</a> of J&uuml;rgen Schmidhuber, but share the motivation that art may be better described in bases that align with succinct formulations and salient impulses.</p>
<p>
On firmer ground is the use of descriptive techniques to identify events that have <em>happened to</em> artwork since its creation. In a wonderful 2016 <a href="https://www.quantamagazine.org/using-mathematics-to-repair-a-masterpiece-20160929/">article</a> by Daubechies for <em>Quanta</em> on art restoration, she describes two kinds of events affecting centuries-old altarpieces:</p>
<ul>
<li>
Natural cracking of the wood panels </p>
<li>
Previous efforts at restoration.
</ul>
<p>
The latter included past restorers imposing a lattice support on the wood that confused with natural cracks. A third kind of event they were able to distinguish fits the creation type in my first paragraph: strokes of fine text delicately painted by the original artists. Daubechies&#8217;s methods were able to highlight those just enough for professional antiquarians to identify the religious text that was intended. </p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/05/14/ingrid-daubechies-prizes-and-art/paneldetail/" rel="attachment wp-att-21616"><img data-attachment-id="21616" data-permalink="https://rjlipton.wpcomstaging.com/2023/05/14/ingrid-daubechies-prizes-and-art/paneldetail/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/PanelDetail.jpg?fit=312%2C275&amp;ssl=1" data-orig-size="312,275" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1684101133&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PanelDetail" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/PanelDetail.jpg?fit=300%2C264&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/PanelDetail.jpg?fit=312%2C275&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/PanelDetail.jpg?resize=208%2C184&#038;ssl=1" alt="" width="208" height="184" class="aligncenter wp-image-21616" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/PanelDetail.jpg?w=312&amp;ssl=1 312w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/PanelDetail.jpg?resize=300%2C264&amp;ssl=1 300w" sizes="(max-width: 208px) 100vw, 208px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption aligncenter"><FONT size="-2">Excerpt from large image in Daubechies <a href="https://www.quantamagazine.org/using-mathematics-to-repair-a-masterpiece-20160929/">article</a></FONT>
</td>
</tr>
</table>
<p><P><br />
In earlier work at Princeton described in this 2008 <a href="https://paw.princeton.edu/article/fake-vs-real-analyzing-artwork-set-mathematical-tools">article</a>, Daubechies and team applied wavelets to distinguish authentic paintings by Vincent van Gogh from forgeries. To do this, they &#8220;created a statistical portrait of van Gogh’s style using wavelets.&#8221; What emerged from their analysis was that the forgeries could not so easily be described in their van Gogh basis:</p>
<blockquote><p><b> </b> <em> The forgeries and copies &#8230; had more tiny wavelets in the image, which [quoting team member Shannon Hughes] &#8220;we think are tiny fluctuations and wobbles. &#8230; You can imagine that if someone is painting really slowly trying to copy another work, they are hesitating a little bit.&#8221; </em>
</p></blockquote>
<p><p>
This reminds me also of telltale hesitations that enable online chess platforms to infer when a human player is concentrating on something else besides playing the game. A final quote from Hughes in the article tends toward my grander thought about artistic creation:</p>
<blockquote><p><em> [Wavelet technology may help figure out] &#8220;what the artist was thinking and what the artist was doing and why they were doing it.&#8221; </em>
</p></blockquote>
<p><p>
Daubechies has been involved in some art creation of her own: the art installation <a href="https://en.wikipedia.org/wiki/Mathemalchemy">Mathemalchemy</a>.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
What inferences will wavelets enable about the creative process? As someone who fancies composing but has no ability to play or transcribe music faster than a snail&#8217;s pace, I can vouch that music is not created in the standard basis.</p>
<p>
<p class="authors">By KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T02:23:23Z">Monday, May 15 2023, 02:23</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07364'>Improved Lower Bounds for Monotone q-Multilinear Boolean Circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andrzej Lingas, Mia Persson</p><p>A monotone Boolean circuit is composed of OR gates, AND gates and input gates
corresponding to the input variables and the Boolean constants. It is
$q$-multilinear if for each its output gate $o$ and for each prime implicant
$s$ of the function computed at $o$, the arithmetic version of the circuit
resulting from the replacement of OR and AND gates by addition and
multiplication gates, respectively, computes a polynomial at $o$ which contains
a monomial including the same variables as $s$ and each of the variables in $s$
has degree at most $q$ in the monomial. First, we study the complexity of
computing semi-disjoint bilinear Boolean forms in terms of the size of monotone
$q$-multilinear Boolean circuits. In particular, we show that any monotone
$1$-multilinear Boolean circuit computing a semi-disjoint Boolean form with $p$
prime implicants includes at least $p$ AND gates. We also show that any
monotone $q$-multilinear Boolean circuit computing a semi-disjoint Boolean form
with $p$ prime implicants has $\Omega(\frac p {q^4})$ size. Next, we study the
complexity of the monotone Boolean function $Isol_{k,n}$ that verifies if a
$k$-dimensional Boolean matrix has at least one $1$ in each line (e.g., each
row and column when $k=2$), in terms of monotone $q$-multilinear Boolean
circuits. We show that that any $\Sigma_3$ monotone Boolean circuit for
$Isol_{k,n}$ has an exponential in $n$ size or it is not $(k-1)$-multilinear.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lingas_A/0/1/0/all/0/1">Andrzej Lingas</a>, <a href="http://arxiv.org/find/cs/1/au:+Persson_M/0/1/0/all/0/1">Mia Persson</a></p><p>A monotone Boolean circuit is composed of OR gates, AND gates and input gates
corresponding to the input variables and the Boolean constants. It is
$q$-multilinear if for each its output gate $o$ and for each prime implicant
$s$ of the function computed at $o$, the arithmetic version of the circuit
resulting from the replacement of OR and AND gates by addition and
multiplication gates, respectively, computes a polynomial at $o$ which contains
a monomial including the same variables as $s$ and each of the variables in $s$
has degree at most $q$ in the monomial. First, we study the complexity of
computing semi-disjoint bilinear Boolean forms in terms of the size of monotone
$q$-multilinear Boolean circuits. In particular, we show that any monotone
$1$-multilinear Boolean circuit computing a semi-disjoint Boolean form with $p$
prime implicants includes at least $p$ AND gates. We also show that any
monotone $q$-multilinear Boolean circuit computing a semi-disjoint Boolean form
with $p$ prime implicants has $\Omega(\frac p {q^4})$ size. Next, we study the
complexity of the monotone Boolean function $Isol_{k,n}$ that verifies if a
$k$-dimensional Boolean matrix has at least one $1$ in each line (e.g., each
row and column when $k=2$), in terms of monotone $q$-multilinear Boolean
circuits. We show that that any $\Sigma_3$ monotone Boolean circuit for
$Isol_{k,n}$ has an exponential in $n$ size or it is not $(k-1)$-multilinear.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07539'>Sampling recovery in the uniform norm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David Krieg, Kateryna Pozharska, Mario Ullrich, Tino Ullrich</p><p>We study the recovery of functions in the uniform norm based on function
evaluations. We obtain worst case error bounds for general classes of
functions, also in $L_p$-norm, in terms of the best $L_2$-approximation from a
given nested sequence of subspaces combined with bounds on the the Christoffel
function of these subspaces.
</p>
<p>Our results imply that linear sampling algorithms are optimal (up to
constants) among all algorithms using arbitrary linear information for many
reproducing kernel Hilbert spaces; a result that has been observed
independently in [Geng \&amp; Wang, arXiv:2304.14748].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Krieg_D/0/1/0/all/0/1">David Krieg</a>, <a href="http://arxiv.org/find/math/1/au:+Pozharska_K/0/1/0/all/0/1">Kateryna Pozharska</a>, <a href="http://arxiv.org/find/math/1/au:+Ullrich_M/0/1/0/all/0/1">Mario Ullrich</a>, <a href="http://arxiv.org/find/math/1/au:+Ullrich_T/0/1/0/all/0/1">Tino Ullrich</a></p><p>We study the recovery of functions in the uniform norm based on function
evaluations. We obtain worst case error bounds for general classes of
functions, also in $L_p$-norm, in terms of the best $L_2$-approximation from a
given nested sequence of subspaces combined with bounds on the the Christoffel
function of these subspaces.
</p>
<p>Our results imply that linear sampling algorithms are optimal (up to
constants) among all algorithms using arbitrary linear information for many
reproducing kernel Hilbert spaces; a result that has been observed
independently in [Geng \&amp; Wang, <a href="/abs/2304.14748">arXiv:2304.14748</a>].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07534'>A circular parameterization for multi-sided patches</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: P&#xe9;ter Salvi</p><p>Most genuine multi-sided surface representations depend on a 2D domain that
enables a mapping between local parameters and global coordinates. The shape of
this domain ranges from regular polygons to curved configurations, but the
simple circular domain - to the best of our knowledge - has not been
investigated yet.
</p>
<p>Here we fill this gap, and introduce a parameter mapping ideal for use with
periodic boundaries. It is based on circular arcs and satisfies constraints
often needed in actual surface formulations. The proposed method is
demonstrated through a corner-based variant of Generalized B\'ezier patches.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Salvi_P/0/1/0/all/0/1">P&#xe9;ter Salvi</a></p><p>Most genuine multi-sided surface representations depend on a 2D domain that
enables a mapping between local parameters and global coordinates. The shape of
this domain ranges from regular polygons to curved configurations, but the
simple circular domain - to the best of our knowledge - has not been
investigated yet.
</p>
<p>Here we fill this gap, and introduce a parameter mapping ideal for use with
periodic boundaries. It is based on circular arcs and satisfies constraints
often needed in actual surface formulations. The proposed method is
demonstrated through a corner-based variant of Generalized B\'ezier patches.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07124'>Complexity of Efficient Outcomes in Binary-Action Polymatrix Games with Implications for Coordination Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Argyrios Deligkas, Eduard Eiben, Gregory Gutin, Philip R. Neary, Anders Yeo</p><p>We investigate the difficulty of finding economically efficient solutions to
coordination problems on graphs. Our work focuses on two forms of coordination
problem: pure-coordination games and anti-coordination games. We consider three
objectives in the context of simple binary-action polymatrix games: (i)
maximizing welfare, (ii) maximizing potential, and (iii) finding a
welfare-maximizing Nash equilibrium. We introduce an intermediate, new
graph-partition problem, termed Maximum Weighted Digraph Partition, which is of
independent interest, and we provide a complexity dichotomy for it. This
dichotomy, among other results, provides as a corollary a dichotomy for
Objective (i) for general binary-action polymatrix games. In addition, it
reveals that the complexity of achieving these objectives varies depending on
the form of the coordination problem. Specifically, Objectives (i) and (ii) can
be efficiently solved in pure-coordination games, but are NP-hard in
anti-coordination games. Finally, we show that objective (iii) is NP-hard even
for simple non-trivial pure-coordination games.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Deligkas_A/0/1/0/all/0/1">Argyrios Deligkas</a>, <a href="http://arxiv.org/find/cs/1/au:+Eiben_E/0/1/0/all/0/1">Eduard Eiben</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutin_G/0/1/0/all/0/1">Gregory Gutin</a>, <a href="http://arxiv.org/find/cs/1/au:+Neary_P/0/1/0/all/0/1">Philip R. Neary</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_A/0/1/0/all/0/1">Anders Yeo</a></p><p>We investigate the difficulty of finding economically efficient solutions to
coordination problems on graphs. Our work focuses on two forms of coordination
problem: pure-coordination games and anti-coordination games. We consider three
objectives in the context of simple binary-action polymatrix games: (i)
maximizing welfare, (ii) maximizing potential, and (iii) finding a
welfare-maximizing Nash equilibrium. We introduce an intermediate, new
graph-partition problem, termed Maximum Weighted Digraph Partition, which is of
independent interest, and we provide a complexity dichotomy for it. This
dichotomy, among other results, provides as a corollary a dichotomy for
Objective (i) for general binary-action polymatrix games. In addition, it
reveals that the complexity of achieving these objectives varies depending on
the form of the coordination problem. Specifically, Objectives (i) and (ii) can
be efficiently solved in pure-coordination games, but are NP-hard in
anti-coordination games. Finally, we show that objective (iii) is NP-hard even
for simple non-trivial pure-coordination games.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07316'>Parameterized Approximation for Robust Clustering in Discrete Geometric Spaces</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fateme Abbasi, Sandip Banerjee, Jaros&#x142;aw Byrka, Parinya Chalermsook, Ameet Gadekar, Kamyar Khodamoradi, D&#xe1;niel Marx, Roohani Sharma, Joachim Spoerhase</p><p>We consider the well-studied Robust $(k, z)$-Clustering problem, which
generalizes the classic $k$-Median, $k$-Means, and $k$-Center problems. Given a
constant $z\ge 1$, the input to Robust $(k, z)$-Clustering is a set $P$ of $n$
weighted points in a metric space $(M,\delta)$ and a positive integer $k$.
Further, each point belongs to one (or more) of the $m$ many different groups
$S_1,S_2,\ldots,S_m$. Our goal is to find a set $X$ of $k$ centers such that
$\max_{i \in [m]} \sum_{p \in S_i} w(p) \delta(p,X)^z$ is minimized.
</p>
<p>This problem arises in the domains of robust optimization [Anthony, Goyal,
Gupta, Nagarajan, Math. Oper. Res. 2010] and in algorithmic fairness. For
polynomial time computation, an approximation factor of $O(\log m/\log\log m)$
is known [Makarychev, Vakilian, COLT $2021$], which is tight under a plausible
complexity assumption even in the line metrics. For FPT time, there is a
$(3^z+\epsilon)$-approximation algorithm, which is tight under GAP-ETH [Goyal,
Jaiswal, Inf. Proc. Letters, 2023].
</p>
<p>Motivated by the tight lower bounds for general discrete metrics, we focus on
\emph{geometric} spaces such as the (discrete) high-dimensional Euclidean
setting and metrics of low doubling dimension, which play an important role in
data analysis applications. First, for a universal constant $\eta_0 &gt;0.0006$,
we devise a $3^z(1-\eta_{0})$-factor FPT approximation algorithm for discrete
high-dimensional Euclidean spaces thereby bypassing the lower bound for general
metrics. We complement this result by showing that even the special case of
$k$-Center in dimension $\Theta(\log n)$ is $(\sqrt{3/2}- o(1))$-hard to
approximate for FPT algorithms. Finally, we complete the FPT approximation
landscape by designing an FPT $(1+\epsilon)$-approximation scheme (EPAS) for
the metric of sub-logarithmic doubling dimension.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Abbasi_F/0/1/0/all/0/1">Fateme Abbasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1">Sandip Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Byrka_J/0/1/0/all/0/1">Jaros&#x142;aw Byrka</a>, <a href="http://arxiv.org/find/cs/1/au:+Chalermsook_P/0/1/0/all/0/1">Parinya Chalermsook</a>, <a href="http://arxiv.org/find/cs/1/au:+Gadekar_A/0/1/0/all/0/1">Ameet Gadekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Khodamoradi_K/0/1/0/all/0/1">Kamyar Khodamoradi</a>, <a href="http://arxiv.org/find/cs/1/au:+Marx_D/0/1/0/all/0/1">D&#xe1;niel Marx</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Roohani Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Spoerhase_J/0/1/0/all/0/1">Joachim Spoerhase</a></p><p>We consider the well-studied Robust $(k, z)$-Clustering problem, which
generalizes the classic $k$-Median, $k$-Means, and $k$-Center problems. Given a
constant $z\ge 1$, the input to Robust $(k, z)$-Clustering is a set $P$ of $n$
weighted points in a metric space $(M,\delta)$ and a positive integer $k$.
Further, each point belongs to one (or more) of the $m$ many different groups
$S_1,S_2,\ldots,S_m$. Our goal is to find a set $X$ of $k$ centers such that
$\max_{i \in [m]} \sum_{p \in S_i} w(p) \delta(p,X)^z$ is minimized.
</p>
<p>This problem arises in the domains of robust optimization [Anthony, Goyal,
Gupta, Nagarajan, Math. Oper. Res. 2010] and in algorithmic fairness. For
polynomial time computation, an approximation factor of $O(\log m/\log\log m)$
is known [Makarychev, Vakilian, COLT $2021$], which is tight under a plausible
complexity assumption even in the line metrics. For FPT time, there is a
$(3^z+\epsilon)$-approximation algorithm, which is tight under GAP-ETH [Goyal,
Jaiswal, Inf. Proc. Letters, 2023].
</p>
<p>Motivated by the tight lower bounds for general discrete metrics, we focus on
\emph{geometric} spaces such as the (discrete) high-dimensional Euclidean
setting and metrics of low doubling dimension, which play an important role in
data analysis applications. First, for a universal constant $\eta_0 &gt;0.0006$,
we devise a $3^z(1-\eta_{0})$-factor FPT approximation algorithm for discrete
high-dimensional Euclidean spaces thereby bypassing the lower bound for general
metrics. We complement this result by showing that even the special case of
$k$-Center in dimension $\Theta(\log n)$ is $(\sqrt{3/2}- o(1))$-hard to
approximate for FPT algorithms. Finally, we complete the FPT approximation
landscape by designing an FPT $(1+\epsilon)$-approximation scheme (EPAS) for
the metric of sub-logarithmic doubling dimension.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07570'>Isotropic Point Cloud Meshing using unit Spheres (IPCMS)</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Henriette Lipsch&#xfc;tz, Ulrich Reitebuch, Konrad Polthier, Martin Skrodzki</p><p>Point clouds arise from acquisition processes applied in various scenarios,
such as reverse engineering, rapid prototyping, or cultural preservation. To
run various simulations via, e.g., finite element methods, on the derived data,
a mesh has to be created from it. In this paper, a meshing algorithm for point
clouds is presented, which is based on a sphere covering of the underlying
surface. The algorithm provides a mesh close to uniformity in terms of edge
lengths and angles of its triangles. Additionally, theoretical results
guarantee the output to be manifold, given suitable input and parameter
choices. We present both the underlying theory, which provides suitable
parameter bounds, as well as experiments showing that our algorithm can compete
with widely used competitors in terms of quality of the output and timings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lipschutz_H/0/1/0/all/0/1">Henriette Lipsch&#xfc;tz</a>, <a href="http://arxiv.org/find/cs/1/au:+Reitebuch_U/0/1/0/all/0/1">Ulrich Reitebuch</a>, <a href="http://arxiv.org/find/cs/1/au:+Polthier_K/0/1/0/all/0/1">Konrad Polthier</a>, <a href="http://arxiv.org/find/cs/1/au:+Skrodzki_M/0/1/0/all/0/1">Martin Skrodzki</a></p><p>Point clouds arise from acquisition processes applied in various scenarios,
such as reverse engineering, rapid prototyping, or cultural preservation. To
run various simulations via, e.g., finite element methods, on the derived data,
a mesh has to be created from it. In this paper, a meshing algorithm for point
clouds is presented, which is based on a sphere covering of the underlying
surface. The algorithm provides a mesh close to uniformity in terms of edge
lengths and angles of its triangles. Additionally, theoretical results
guarantee the output to be manifold, given suitable input and parameter
choices. We present both the underlying theory, which provides suitable
parameter bounds, as well as experiments showing that our algorithm can compete
with widely used competitors in terms of quality of the output and timings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07090'>Streaming Edge Coloring with Subquadratic Palette Size</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shiri Chechik, Doron Mukhtar, Tianyi Zhang</p><p>In this paper, we study the problem of computing an edge-coloring in the
(one-pass) W-streaming model. In this setting, the edges of an $n$-node graph
arrive in an arbitrary order to a machine with a relatively small space, and
the goal is to design an algorithm that outputs, as a stream, a proper coloring
of the edges using the fewest possible number of colors.
</p>
<p>Behnezhad et al. [Behnezhad et al., 2019] devised the first non-trivial
algorithm for this problem, which computes in $\tilde{O}(n)$ space a proper
$O(\Delta^2)$-coloring w.h.p. (here $\Delta$ is the maximum degree of the
graph). Subsequent papers improved upon this result, where latest of them
[Ansari et al., 2022] shows that it is possible to deterministically compute an
$O(\Delta^2/s)$-coloring in $O(ns)$ space. However, none of the improvements,
succeeded in reducing the number of colors to $O(\Delta^{2-\epsilon})$ while
keeping the same space bound of $\tilde{O}(n)$. In particular, no progress was
made on the question of whether computing an $O(\Delta)$-coloring is possible
with roughly $O(n)$ space, which was stated in [Behnezhad et al., 2019] to be a
major open problem.
</p>
<p>In this paper we bypass the quadratic bound by presenting a new randomized
$\tilde{O}(n)$-space algorithm that uses $\tilde{O}(\Delta^{1.5})$ colors.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chechik_S/0/1/0/all/0/1">Shiri Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukhtar_D/0/1/0/all/0/1">Doron Mukhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianyi Zhang</a></p><p>In this paper, we study the problem of computing an edge-coloring in the
(one-pass) W-streaming model. In this setting, the edges of an $n$-node graph
arrive in an arbitrary order to a machine with a relatively small space, and
the goal is to design an algorithm that outputs, as a stream, a proper coloring
of the edges using the fewest possible number of colors.
</p>
<p>Behnezhad et al. [Behnezhad et al., 2019] devised the first non-trivial
algorithm for this problem, which computes in $\tilde{O}(n)$ space a proper
$O(\Delta^2)$-coloring w.h.p. (here $\Delta$ is the maximum degree of the
graph). Subsequent papers improved upon this result, where latest of them
[Ansari et al., 2022] shows that it is possible to deterministically compute an
$O(\Delta^2/s)$-coloring in $O(ns)$ space. However, none of the improvements,
succeeded in reducing the number of colors to $O(\Delta^{2-\epsilon})$ while
keeping the same space bound of $\tilde{O}(n)$. In particular, no progress was
made on the question of whether computing an $O(\Delta)$-coloring is possible
with roughly $O(n)$ space, which was stated in [Behnezhad et al., 2019] to be a
major open problem.
</p>
<p>In this paper we bypass the quadratic bound by presenting a new randomized
$\tilde{O}(n)$-space algorithm that uses $\tilde{O}(\Delta^{1.5})$ colors.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07164'>Learning-Augmented Online Packet Scheduling with Deadlines</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Clifford Stein, Hao-Ting Wei</p><p>The modern network aims to prioritize critical traffic over non-critical
traffic and effectively manage traffic flow. This necessitates proper buffer
management to prevent the loss of crucial traffic while minimizing the impact
on non-critical traffic. Therefore, the algorithm's objective is to control
which packets to transmit and which to discard at each step. In this study, we
initiate the learning-augmented online packet scheduling with deadlines and
provide a novel algorithmic framework to cope with the prediction. We show that
when the prediction error is small, our algorithm improves the competitive
ratio while still maintaining a bounded competitive ratio, regardless of the
prediction error.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Stein_C/0/1/0/all/0/1">Clifford Stein</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1">Hao-Ting Wei</a></p><p>The modern network aims to prioritize critical traffic over non-critical
traffic and effectively manage traffic flow. This necessitates proper buffer
management to prevent the loss of crucial traffic while minimizing the impact
on non-critical traffic. Therefore, the algorithm's objective is to control
which packets to transmit and which to discard at each step. In this study, we
initiate the learning-augmented online packet scheduling with deadlines and
provide a novel algorithmic framework to cope with the prediction. We show that
when the prediction error is small, our algorithm improves the competitive
ratio while still maintaining a bounded competitive ratio, regardless of the
prediction error.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07229'>A Wait-free Queue with Polylogarithmic Step Complexity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hossein Naderibeni, Eric Ruppert</p><p>We present a novel linearizable wait-free queue implementation using
single-word CAS instructions. Previous lock-free queue implementations from CAS
all have amortized step complexity of $\Omega(p)$ per operation in worst-case
executions, where $p$ is the number of processes that access the queue. Our new
wait-free queue takes $O(\log p)$ steps per enqueue and $O(\log^2 p +\log q)$
steps per dequeue, where $q$ is the size of the queue. A bounded-space version
of the implementation has $O(\log p \log(p+q))$ amortized step complexity per
operation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Naderibeni_H/0/1/0/all/0/1">Hossein Naderibeni</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruppert_E/0/1/0/all/0/1">Eric Ruppert</a></p><p>We present a novel linearizable wait-free queue implementation using
single-word CAS instructions. Previous lock-free queue implementations from CAS
all have amortized step complexity of $\Omega(p)$ per operation in worst-case
executions, where $p$ is the number of processes that access the queue. Our new
wait-free queue takes $O(\log p)$ steps per enqueue and $O(\log^2 p +\log q)$
steps per dequeue, where $q$ is the size of the queue. A bounded-space version
of the implementation has $O(\log p \log(p+q))$ amortized step complexity per
operation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07259'>Minimum Consistent Subset for Trees Revisited</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hiroki Arimura, Tatsuya Gima, Yasuaki Kobayashi, Hiroomi Nochide, Yota Otachi</p><p>In a vertex-colored graph $G = (V, E)$, a subset $S \subseteq V$ is said to
be consistent if every vertex has a nearest neighbor in $S$ with the same
color. The problem of computing a minimum cardinality consistent subset of a
graph is known to be NP-hard. On the positive side, Dey et al. (FCT 2021) show
that this problem is solvable in polynomial time when input graphs are
restricted to bi-colored trees. In this paper, we give a polynomial-time
algorithm for this problem on $k$-colored trees with fixed $k$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Arimura_H/0/1/0/all/0/1">Hiroki Arimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Gima_T/0/1/0/all/0/1">Tatsuya Gima</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1">Yasuaki Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nochide_H/0/1/0/all/0/1">Hiroomi Nochide</a>, <a href="http://arxiv.org/find/cs/1/au:+Otachi_Y/0/1/0/all/0/1">Yota Otachi</a></p><p>In a vertex-colored graph $G = (V, E)$, a subset $S \subseteq V$ is said to
be consistent if every vertex has a nearest neighbor in $S$ with the same
color. The problem of computing a minimum cardinality consistent subset of a
graph is known to be NP-hard. On the positive side, Dey et al. (FCT 2021) show
that this problem is solvable in polynomial time when input graphs are
restricted to bi-colored trees. In this paper, we give a polynomial-time
algorithm for this problem on $k$-colored trees with fixed $k$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07262'>Reconfiguration of Time-Respecting Arborescences</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Takehiro Ito, Yuni Iwamasa, Naoyuki Kamiyama, Yasuaki Kobayashi, Yusuke Kobayashi, Shun-ichi Maezawa, Akira Suzuki</p><p>An arborescence, which is a directed analogue of a spanning tree in an
undirected graph, is one of the most fundamental combinatorial objects in a
digraph. In this paper, we study arborescences in digraphs from the viewpoint
of combinatorial reconfiguration, which is the field where we study
reachability between two configurations of some combinatorial objects via some
specified operations. Especially, we consider reconfiguration problems for
time-respecting arborescences, which were introduced by Kempe, Kleinberg, and
Kumar. We first prove that if the roots of the initial and target
time-respecting arborescences are the same, then the target arborescence is
always reachable from the initial one and we can find a shortest
reconfiguration sequence in polynomial time. Furthermore, we show if the roots
are not the same, then the target arborescence may not be reachable from the
initial one. On the other hand, we show that we can determine whether the
target arborescence is reachable form the initial one in polynomial time.
Finally, we prove that it is NP-hard to find a shortest reconfiguration
sequence in the case where the roots are not the same. Our results show an
interesting contrast to the previous results for (ordinary) arborescences
reconfiguration problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ito_T/0/1/0/all/0/1">Takehiro Ito</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwamasa_Y/0/1/0/all/0/1">Yuni Iwamasa</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamiyama_N/0/1/0/all/0/1">Naoyuki Kamiyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1">Yasuaki Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1">Yusuke Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Maezawa_S/0/1/0/all/0/1">Shun-ichi Maezawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_A/0/1/0/all/0/1">Akira Suzuki</a></p><p>An arborescence, which is a directed analogue of a spanning tree in an
undirected graph, is one of the most fundamental combinatorial objects in a
digraph. In this paper, we study arborescences in digraphs from the viewpoint
of combinatorial reconfiguration, which is the field where we study
reachability between two configurations of some combinatorial objects via some
specified operations. Especially, we consider reconfiguration problems for
time-respecting arborescences, which were introduced by Kempe, Kleinberg, and
Kumar. We first prove that if the roots of the initial and target
time-respecting arborescences are the same, then the target arborescence is
always reachable from the initial one and we can find a shortest
reconfiguration sequence in polynomial time. Furthermore, we show if the roots
are not the same, then the target arborescence may not be reachable from the
initial one. On the other hand, we show that we can determine whether the
target arborescence is reachable form the initial one in polynomial time.
Finally, we prove that it is NP-hard to find a shortest reconfiguration
sequence in the case where the roots are not the same. Our results show an
interesting contrast to the previous results for (ordinary) arborescences
reconfiguration problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07319'>Matching Statistics speed up BWT construction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Francesco Masillo</p><p>Due to the exponential growth of genomic data, constructing dedicated data
structures has become the principal bottleneck in common bioinformatics
applications. In particular, the Burrows-Wheeler Transform (BWT) is the basis
of some of the most popular self-indexes for genomic data, due to its known
favourable behaviour on repetitive data.
</p>
<p>Some tools that exploit the intrinsic repetitiveness of biological data have
risen in popularity, due to their speed and low space consumption. We introduce
a new algorithm for computing the BWT, which takes advantage of the redundancy
of the data through a compressed version of matching statistics, the
$\textit{CMS}$ of [Lipt\'ak et al., WABI 2022]. We show that it suffices to
sort a small subset of suffixes, lowering both computation time and space. Our
result is due to a new insight which links the so-called insert-heads of
[Lipt\'ak et al., WABI 2022] to the well-known run boundaries of the BWT.
</p>
<p>We give two implementations of our algorithm, called
$\texttt{CMS}$-$\texttt{BWT}$, both competitive in our experimental validation
on highly repetitive real-life datasets. In most cases, they outperform other
tools w.r.t. running time, trading off a higher memory footprint, which,
however, is still considerably smaller than the total size of the input data.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Masillo_F/0/1/0/all/0/1">Francesco Masillo</a></p><p>Due to the exponential growth of genomic data, constructing dedicated data
structures has become the principal bottleneck in common bioinformatics
applications. In particular, the Burrows-Wheeler Transform (BWT) is the basis
of some of the most popular self-indexes for genomic data, due to its known
favourable behaviour on repetitive data.
</p>
<p>Some tools that exploit the intrinsic repetitiveness of biological data have
risen in popularity, due to their speed and low space consumption. We introduce
a new algorithm for computing the BWT, which takes advantage of the redundancy
of the data through a compressed version of matching statistics, the
$\textit{CMS}$ of [Lipt\'ak et al., WABI 2022]. We show that it suffices to
sort a small subset of suffixes, lowering both computation time and space. Our
result is due to a new insight which links the so-called insert-heads of
[Lipt\'ak et al., WABI 2022] to the well-known run boundaries of the BWT.
</p>
<p>We give two implementations of our algorithm, called
$\texttt{CMS}$-$\texttt{BWT}$, both competitive in our experimental validation
on highly repetitive real-life datasets. In most cases, they outperform other
tools w.r.t. running time, trading off a higher memory footprint, which,
however, is still considerably smaller than the total size of the input data.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07345'>On the Fair Comparison of Optimization Algorithms in Different Machines</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Etor Arza, Josu Ceberio, Ekhi&#xf1;e Irurozki, Aritz P&#xe9;rez</p><p>An experimental comparison of two or more optimization algorithms requires
the same computational resources to be assigned to each algorithm. When a
maximum runtime is set as the stopping criterion, all algorithms need to be
executed in the same machine if they are to use the same resources.
Unfortunately, the implementation code of the algorithms is not always
available, which means that running the algorithms to be compared in the same
machine is not always possible. And even if they are available, some
optimization algorithms might be costly to run, such as training large
neural-networks in the cloud.
</p>
<p>In this paper, we consider the following problem: how do we compare the
performance of a new optimization algorithm B with a known algorithm A in the
literature if we only have the results (the objective values) and the runtime
in each instance of algorithm A? Particularly, we present a methodology that
enables a statistical analysis of the performance of algorithms executed in
different machines. The proposed methodology has two parts. Firstly, we propose
a model that, given the runtime of an algorithm in a machine, estimates the
runtime of the same algorithm in another machine. This model can be adjusted so
that the probability of estimating a runtime longer than what it should be is
arbitrarily low. Secondly, we introduce an adaptation of the one-sided sign
test that uses a modified \textit{p}-value and takes into account that
probability. Such adaptation avoids increasing the probability of type I error
associated with executing algorithms A and B in different machines.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Arza_E/0/1/0/all/0/1">Etor Arza</a>, <a href="http://arxiv.org/find/cs/1/au:+Ceberio_J/0/1/0/all/0/1">Josu Ceberio</a>, <a href="http://arxiv.org/find/cs/1/au:+Irurozki_E/0/1/0/all/0/1">Ekhi&#xf1;e Irurozki</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_A/0/1/0/all/0/1">Aritz P&#xe9;rez</a></p><p>An experimental comparison of two or more optimization algorithms requires
the same computational resources to be assigned to each algorithm. When a
maximum runtime is set as the stopping criterion, all algorithms need to be
executed in the same machine if they are to use the same resources.
Unfortunately, the implementation code of the algorithms is not always
available, which means that running the algorithms to be compared in the same
machine is not always possible. And even if they are available, some
optimization algorithms might be costly to run, such as training large
neural-networks in the cloud.
</p>
<p>In this paper, we consider the following problem: how do we compare the
performance of a new optimization algorithm B with a known algorithm A in the
literature if we only have the results (the objective values) and the runtime
in each instance of algorithm A? Particularly, we present a methodology that
enables a statistical analysis of the performance of algorithms executed in
different machines. The proposed methodology has two parts. Firstly, we propose
a model that, given the runtime of an algorithm in a machine, estimates the
runtime of the same algorithm in another machine. This model can be adjusted so
that the probability of estimating a runtime longer than what it should be is
arbitrarily low. Secondly, we introduce an adaptation of the one-sided sign
test that uses a modified \textit{p}-value and takes into account that
probability. Such adaptation avoids increasing the probability of type I error
associated with executing algorithms A and B in different machines.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07486'>Reduced Label Complexity For Tight $\ell_2$ Regression</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alex Gittens, Malik Magdon-Ismail</p><p>Given data ${\rm X}\in\mathbb{R}^{n\times d}$ and labels
$\mathbf{y}\in\mathbb{R}^{n}$ the goal is find $\mathbf{w}\in\mathbb{R}^d$ to
minimize $\Vert{\rm X}\mathbf{w}-\mathbf{y}\Vert^2$. We give a polynomial
algorithm that, \emph{oblivious to $\mathbf{y}$}, throws out $n/(d+\sqrt{n})$
data points and is a $(1+d/n)$-approximation to optimal in expectation. The
motivation is tight approximation with reduced label complexity (number of
labels revealed). We reduce label complexity by $\Omega(\sqrt{n})$. Open
question: Can label complexity be reduced by $\Omega(n)$ with tight
$(1+d/n)$-approximation?
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gittens_A/0/1/0/all/0/1">Alex Gittens</a>, <a href="http://arxiv.org/find/cs/1/au:+Magdon_Ismail_M/0/1/0/all/0/1">Malik Magdon-Ismail</a></p><p>Given data ${\rm X}\in\mathbb{R}^{n\times d}$ and labels
$\mathbf{y}\in\mathbb{R}^{n}$ the goal is find $\mathbf{w}\in\mathbb{R}^d$ to
minimize $\Vert{\rm X}\mathbf{w}-\mathbf{y}\Vert^2$. We give a polynomial
algorithm that, \emph{oblivious to $\mathbf{y}$}, throws out $n/(d+\sqrt{n})$
data points and is a $(1+d/n)$-approximation to optimal in expectation. The
motivation is tight approximation with reduced label complexity (number of
labels revealed). We reduce label complexity by $\Omega(\sqrt{n})$. Open
question: Can label complexity be reduced by $\Omega(n)$ with tight
$(1+d/n)$-approximation?
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07494'>Temporal Network Creation Games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Davide Bil&#xf2;, Sarel Cohen, Tobias Friedrich, Hans Gawendowicz, Nicolas Klodt, Pascal Lenzner, George Skretas</p><p>Most networks are not static objects, but instead they change over time. This
observation has sparked rigorous research on temporal graphs within the last
years. In temporal graphs, we have a fixed set of nodes and the connections
between them are only available at certain time steps. This gives rise to a
plethora of algorithmic problems on such graphs, most prominently the problem
of finding temporal spanners, i.e., the computation of subgraphs that guarantee
all pairs reachability via temporal paths. To the best of our knowledge, only
centralized approaches for the solution of this problem are known. However,
many real-world networks are not shaped by a central designer but instead they
emerge and evolve by the interaction of many strategic agents. This observation
is the driving force of the recent intensive research on game-theoretic network
formation models.
</p>
<p>In this work we bring together these two recent research directions: temporal
graphs and game-theoretic network formation. As a first step into this new
realm, we focus on a simplified setting where a complete temporal host graph is
given and the agents, corresponding to its nodes, selfishly create incident
edges to ensure that they can reach all other nodes via temporal paths in the
created network. This yields temporal spanners as equilibria of our game. We
prove results on the convergence to and the existence of equilibrium networks,
on the complexity of finding best agent strategies, and on the quality of the
equilibria. By taking these first important steps, we uncover challenging open
problems that call for an in-depth exploration of the creation of temporal
graphs by strategic agents.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bilo_D/0/1/0/all/0/1">Davide Bil&#xf2;</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Sarel Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedrich_T/0/1/0/all/0/1">Tobias Friedrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Gawendowicz_H/0/1/0/all/0/1">Hans Gawendowicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Klodt_N/0/1/0/all/0/1">Nicolas Klodt</a>, <a href="http://arxiv.org/find/cs/1/au:+Lenzner_P/0/1/0/all/0/1">Pascal Lenzner</a>, <a href="http://arxiv.org/find/cs/1/au:+Skretas_G/0/1/0/all/0/1">George Skretas</a></p><p>Most networks are not static objects, but instead they change over time. This
observation has sparked rigorous research on temporal graphs within the last
years. In temporal graphs, we have a fixed set of nodes and the connections
between them are only available at certain time steps. This gives rise to a
plethora of algorithmic problems on such graphs, most prominently the problem
of finding temporal spanners, i.e., the computation of subgraphs that guarantee
all pairs reachability via temporal paths. To the best of our knowledge, only
centralized approaches for the solution of this problem are known. However,
many real-world networks are not shaped by a central designer but instead they
emerge and evolve by the interaction of many strategic agents. This observation
is the driving force of the recent intensive research on game-theoretic network
formation models.
</p>
<p>In this work we bring together these two recent research directions: temporal
graphs and game-theoretic network formation. As a first step into this new
realm, we focus on a simplified setting where a complete temporal host graph is
given and the agents, corresponding to its nodes, selfishly create incident
edges to ensure that they can reach all other nodes via temporal paths in the
created network. This yields temporal spanners as equilibria of our game. We
prove results on the convergence to and the existence of equilibrium networks,
on the complexity of finding best agent strategies, and on the quality of the
equilibria. By taking these first important steps, we uncover challenging open
problems that call for an in-depth exploration of the creation of temporal
graphs by strategic agents.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-15T00:30:00Z">Monday, May 15 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, May 14
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/05/take-number-and-map-it-to-number-of.html'>Take a number and map it to the number of letters in its name</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Let f: N--&gt; N map a number to the number-of-letters in its name in English (we will consider other languages later).</p><p>So for example 14 is fourteen so it maps to 7. Let's iterate</p><p>14 --&gt; 7 --&gt; 5 --&gt; 4--&gt;4--&gt;4 ...</p><p>It is known (perhaps well-known) that, given any starting point, the sequence eventually is all 4's.&nbsp;</p><p>I recently got an email asking if this was PROVEN.&nbsp; I could not find a proof on the web so I did it myself. My writeup of a proof is here.&nbsp;</p><p>1) So now there IS a proof on the web. It may be hard to find. Does this problem have a well known name that I should add to this blog post so that it is easier to find?</p><p>2) My next thought was</p><p>For which functions f: N--&gt;N is it the case that every sequence a, f(a), f(f(a)), ... is eventually constant. I leave that for you to ponder.</p><p>3) The asker of the question is of a more real-world bent and emailed me what happens in other languages:</p><p>Spanish has one number whose name is its own length: 5 is cinco. I leave it to the reader to show that in Spanish the sequence always becomes all 5's.</p><p>French seems to have no such numbers, so it cannot have this behavior.</p><p>Norwegian has three such numbers: 2 is to, 3 is tre, 4 is fire. So I suspect every such sequence either is constant-2, constant-3 or contant-4.</p><p>See this article&nbsp;here&nbsp;for more the numbers 1-10 in several languages.</p><p>OBLIGATORY ChatGpt note: Lance saw this post in our blog account and was curious what ChatGpt would do with it. For what he got see&nbsp;here. You can decide if a program can take over the blog anytime soon.&nbsp;</p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Let f: N--&gt; N map a number to the number-of-letters in its name in English (we will consider other languages later).</p><p>So for example 14 is fourteen so it maps to 7. Let's iterate</p><p>14 --&gt; 7 --&gt; 5 --&gt; 4--&gt;4--&gt;4 ...</p><p>It is known (perhaps well-known) that, given any starting point, the sequence eventually is all 4's.&nbsp;</p><p>I recently got an email asking if this was PROVEN.&nbsp; I could not find a proof on the web so I did it myself. My writeup of a proof is <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/four.pdf">here</a>.&nbsp;</p><p>1) So now there IS a proof on the web. It may be hard to find. Does this problem have a well known name that I should add to this blog post so that it is easier to find?</p><p>2) My next thought was</p><p>For which functions f: N--&gt;N is it the case that every sequence a, f(a), f(f(a)), ... is eventually constant. I leave that for you to ponder.</p><p>3) The asker of the question is of a more real-world bent and emailed me what happens in other languages:</p><p>Spanish has one number whose name is its own length: 5 is cinco. I leave it to the reader to show that in Spanish the sequence always becomes all 5's.</p><p>French seems to have no such numbers, so it cannot have this behavior.</p><p>Norwegian has three such numbers: 2 is to, 3 is tre, 4 is fire. So I suspect every such sequence either is constant-2, constant-3 or contant-4.</p><p>See this article&nbsp;<a href="https://mathlair.allfunandgames.ca/languages.php">here</a>&nbsp;for more the numbers 1-10 in several languages.</p><p>OBLIGATORY ChatGpt note: Lance saw this post in our blog account and was curious what ChatGpt would do with it. For what he got see&nbsp;<a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/mapnum.txt">here</a>. You can decide if a program can take over the blog anytime soon.&nbsp;</p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-14T21:53:00Z">Sunday, May 14 2023, 21:53</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/05/14/mathematics-of-the-impossible-chapter-12-data-structures/'>Mathematics of the impossible, Chapter 12, Data structures</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          And as promised, here&#8217;s a chapter on data structures&#8230; in a complexity theory course! &#8212; Data structures aim to maintain data in memory so as to be able to support various operations, such as answering queries about the data, and updating the data. The study of data structures is fundamental and extensive. We distinguish and [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>And as promised, here&#8217;s a chapter on data structures&#8230; in a complexity theory course!<br />
&#8212;<br />
Data structures aim to maintain data in memory so as to be able to support various operations, such as answering queries about the data, and updating the data. The study of data structures is fundamental and extensive. We distinguish and study in turn two types of data structure problems: <em>static</em> and <em>dynamic</em>. In the former the input is given once and cannot modified by the queries. In the latter queries can modify the input; this includes classical problems such as supporting insert, search, and delete of keys.</p>
<h3 class="sectionHead"><span class="titlemark">12.1   </span> <a id="x1-12100012.1"></a>Static data structures</h3>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-121001r1"></a> <b>Definition</b> 12.1.  </span>A static data-structure problem is simply a function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Cto+%5Bq%5D%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Cto+%5Bq%5D%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Cto+%5Bq%5D%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^n &#92;to [q]^{m}" class="latex" />. A data structure for <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> with space <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />, word size <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> and time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is a way to write <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> as</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29%3Dh%28g%28x%29%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29%3Dh%28g%28x%29%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29%3Dh%28g%28x%29%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} f(x)=h(g(x)) &#92;end{aligned}" class="latex" /></div>
<p>where <img src="https://s0.wp.com/latex.php?latex=g%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5B2%5E%7Bw%7D%5D%5E%7Bs%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5B2%5E%7Bw%7D%5D%5E%7Bs%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5B2%5E%7Bw%7D%5D%5E%7Bs%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g:&#92;{0,1&#92;} ^{n}&#92;to [2^{w}]^{s}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=h%3A%5B2%5E%7Bw%7D%5D%5E%7Bs%7D%5Cto+%5Bq%5D%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h%3A%5B2%5E%7Bw%7D%5D%5E%7Bs%7D%5Cto+%5Bq%5D%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h%3A%5B2%5E%7Bw%7D%5D%5E%7Bs%7D%5Cto+%5Bq%5D%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h:[2^{w}]^{s}&#92;to [q]^{m}" class="latex" />, and each output bit of <img src="https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h" class="latex" /> depends on <img src="https://s0.wp.com/latex.php?latex=%5Cle+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le t" class="latex" /> input words (we think of <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> as divided into words of length <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" />).</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">Here we have <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> bits of input data about which we would like to answer <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" /> queries. Often the queries and or the word size are boolean, i.e., <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bw%7D%3Dq%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bw%7D%3Dq%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bw%7D%3Dq%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{w}=q=2" class="latex" />. Another typical setting is <img src="https://s0.wp.com/latex.php?latex=q%3D2%5E%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q%3D2%5E%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q%3D2%5E%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q=2^{w}" class="latex" />. The data structure aims to accomplish this by storing the input into <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> bits of memory. This map is arbitrary, with no bound on resources. But after that, each query can be answered very fast, by reading only <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> words. In general, these words can be read adaptively. But for simplicity we focus on the case in which the locations are fixed by the data structure and the same for every input <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-121002r1"></a> <b>Exercise</b> 12.1.  </span>Consider the data structure problem <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} ^{m}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=m%3Dn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m%3Dn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m%3Dn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m=n^{2}" class="latex" /> and query <img src="https://s0.wp.com/latex.php?latex=%28i%2Cj%29%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28i%2Cj%29%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28i%2Cj%29%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(i,j)&#92;in &#92;{1,2,&#92;ldots ,n&#92;}^{2}" class="latex" /> is the parity of the input bits from <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j" class="latex" />.</p>
<p style="text-align:justify">   Give a data structure for this problem with <img src="https://s0.wp.com/latex.php?latex=s%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s=n" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w=1" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=t%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t=2" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-121003r2"></a>                                                                                                                                                                                     <b>Exercise</b> 12.2.  </span>Show that any data-structure problem <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} ^{m}" class="latex" /> has a data structure with <img src="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w=1" class="latex" /> and the following parameters:</p>
<p style="text-align:justify">   (1) <img src="https://s0.wp.com/latex.php?latex=s%3Dm&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%3Dm&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%3Dm&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s=m" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=t%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t=1" class="latex" />, and</p>
<p style="text-align:justify">   (2) <img src="https://s0.wp.com/latex.php?latex=s%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s=n" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=t%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t=n" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-121004r3"></a> <b>Exercise</b> 12.3.  </span>Prove that for every <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=m%5Cle+2%5E%7Bn%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m%5Cle+2%5E%7Bn%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m%5Cle+2%5E%7Bn%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m&#92;le 2^{n/2}" class="latex" /> there exist functions <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} ^{m}" class="latex" /> s.t.&nbsp;any data structure with space <img src="https://s0.wp.com/latex.php?latex=s%3Dm%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%3Dm%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%3Dm%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s=m/2" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w=1" class="latex" /> requires time <img src="https://s0.wp.com/latex.php?latex=t%5Cge+n-c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cge+n-c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cge+n-c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;ge n-c" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   By contrast, next we present the the best known impossibility result.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-121005r2"></a> <b>Definition</b> 12.2.  </span>A function <img src="https://s0.wp.com/latex.php?latex=f%3A%5B2%5D%5E%7Bn%7D%5Cto+%5Bq%5D%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5B2%5D%5E%7Bn%7D%5Cto+%5Bq%5D%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5B2%5D%5E%7Bn%7D%5Cto+%5Bq%5D%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:[2]^{n}&#92;to [q]^{m}" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />-wise uniform if any <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> output coordinates are uniform when the input to <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is uniform.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-121006r1"></a> <b>Theorem</b> 12.1.  </span><span class="cite">[<a href="#XSiegel04">65</a>]</span> Let <img src="https://s0.wp.com/latex.php?latex=f%3A%5Bq%5D%5E%7Bd%7D%5Cto+%5Bq%5D%5E%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5Bq%5D%5E%7Bd%7D%5Cto+%5Bq%5D%5E%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5Bq%5D%5E%7Bd%7D%5Cto+%5Bq%5D%5E%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:[q]^{d}&#92;to [q]^{q}" class="latex" /> be <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />-wise uniform. Let <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" /> be a power of <img src="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=c%5Clog+q%5Cle+d%5Cle+q%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+q%5Cle+d%5Cle+q%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+q%5Cle+d%5Cle+q%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log q&#92;le d&#92;le q^{c}" class="latex" />. Then any data structure with <img src="https://s0.wp.com/latex.php?latex=w%3D%5Clog+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w%3D%5Clog+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%3D%5Clog+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w=&#92;log q" class="latex" /> using space <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> (which recall is measured in words of <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> bits) and time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> has:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5Cgeq+c%5Cfrac+%7B%5Clog+q%7D%7B%5Clog+%28s%2Fd%29%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5Cgeq+c%5Cfrac+%7B%5Clog+q%7D%7B%5Clog+%28s%2Fd%29%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5Cgeq+c%5Cfrac+%7B%5Clog+q%7D%7B%5Clog+%28s%2Fd%29%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} t&#92;geq c&#92;frac {&#92;log q}{&#92;log (s/d)}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Interpreting the input as coefficients of a degree <img src="https://s0.wp.com/latex.php?latex=d-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d-1" class="latex" /> univariate polynomial over <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{q}" class="latex" /> and outputting its evaluations shows that such functions exists, and are in P. Below we give a surprising data structure that nearly matches the theorem.</p>
<p style="text-align:justify">   To match previous parameters note that <img src="https://s0.wp.com/latex.php?latex=n%3Dd%5Clog+q%3Ddw&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%3Dd%5Clog+q%3Ddw&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%3Dd%5Clog+q%3Ddw&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n=d&#92;log q=dw" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=m%3D%5Clog+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m%3D%5Clog+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m%3D%5Clog+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m=&#92;log q" class="latex" />. Hence the bound is <img src="https://s0.wp.com/latex.php?latex=t%5Cge+c%28%5Clog+m%29%2F%5Clog+%28sw%2Fn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cge+c%28%5Clog+m%29%2F%5Clog+%28sw%2Fn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cge+c%28%5Clog+m%29%2F%5Clog+%28sw%2Fn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;ge c(&#92;log m)/&#92;log (sw/n)" class="latex" />. Note that <img src="https://s0.wp.com/latex.php?latex=sw&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=sw&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=sw&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="sw" class="latex" /> is the space of the data structure measured in bits. It follows that if <img src="https://s0.wp.com/latex.php?latex=sw&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=sw&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=sw&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="sw" class="latex" /> is linear in <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=t%5Cge+c%5Clog+m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cge+c%5Clog+m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cge+c%5Clog+m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;ge c&#92;log m" class="latex" />. This result remains non-trivial for <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> slightly super-linear. But remarkably, if <img src="https://s0.wp.com/latex.php?latex=sw%3Dn%5E%7B1%2Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=sw%3Dn%5E%7B1%2Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=sw%3Dn%5E%7B1%2Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="sw=n^{1+c}" class="latex" /> then nothing is known (for <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" /> power in <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> one only gets <img src="https://s0.wp.com/latex.php?latex=t%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;ge c" class="latex" />).</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>The idea in the proof is to find a subset <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> of less than <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> memory cells that still allows us to answer <img src="https://s0.wp.com/latex.php?latex=%5Cge+d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge d" class="latex" /> queries. This is impossible, since we can’t generate <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> uniform outputs from less than <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> memory cells.</p>
<p style="text-align:justify">   Let <img src="https://s0.wp.com/latex.php?latex=p%3A%3D1%2Fq%5E%7B1%2F4t%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%3A%3D1%2Fq%5E%7B1%2F4t%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%3A%3D1%2Fq%5E%7B1%2F4t%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p:=1/q^{1/4t}" class="latex" />. Include each memory bit in <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> with probability <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />, independently. By Theorem <a href="#x1-30001r7">2.7<!--tex4ht:ref: thm:tail-bound --></a>, <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BP%7D%5B%7CS%7C%5Cge+cps%5D%5Cle+2%5E%7B-cps%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BP%7D%5B%7CS%7C%5Cge+cps%5D%5Cle+2%5E%7B-cps%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BP%7D%5B%7CS%7C%5Cge+cps%5D%5Cle+2%5E%7B-cps%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {P}[|S|&#92;ge cps]&#92;le 2^{-cps}" class="latex" />.</p>
<p style="text-align:justify">   We are still able to answer a query if all of its memory bits fall in <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" />. The probability that this happens is <img src="https://s0.wp.com/latex.php?latex=p%5E%7Bt%7D%3D1%2Fq%5E%7B1%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%5E%7Bt%7D%3D1%2Fq%5E%7B1%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%5E%7Bt%7D%3D1%2Fq%5E%7B1%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p^{t}=1/q^{1/4}" class="latex" />. We now claim that with probability <img src="https://s0.wp.com/latex.php?latex=%5Cge+1%2Fq%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+1%2Fq%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+1%2Fq%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge 1/q^{c}" class="latex" />, we can still answer <img src="https://s0.wp.com/latex.php?latex=%5Csqrt+%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csqrt+%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csqrt+%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sqrt {q}" class="latex" /> queries. Indeed, let <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> be the number of queries we cannot answer. We have <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%7CB%7C%5D%5Cle+q%281-q%5E%7B1%2F4%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%7CB%7C%5D%5Cle+q%281-q%5E%7B1%2F4%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%7CB%7C%5D%5Cle+q%281-q%5E%7B1%2F4%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {E}[|B|]&#92;le q(1-q^{1/4})" class="latex" />. And so</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D%5BB%5Cge+q%281-1%2F%5Csqrt+%7Bq%7D%29%5D%5Cle+%5Cfrac+%7B1-q%5E%7B1%2F4%7D%7D%7B1-%5Csqrt+%7Bq%7D%7D%5Cle+1-q%5E%7Bc%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D%5BB%5Cge+q%281-1%2F%5Csqrt+%7Bq%7D%29%5D%5Cle+%5Cfrac+%7B1-q%5E%7B1%2F4%7D%7D%7B1-%5Csqrt+%7Bq%7D%7D%5Cle+1-q%5E%7Bc%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D%5BB%5Cge+q%281-1%2F%5Csqrt+%7Bq%7D%29%5D%5Cle+%5Cfrac+%7B1-q%5E%7B1%2F4%7D%7D%7B1-%5Csqrt+%7Bq%7D%7D%5Cle+1-q%5E%7Bc%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;mathbb {P}[B&#92;ge q(1-1/&#92;sqrt {q})]&#92;le &#92;frac {1-q^{1/4}}{1-&#92;sqrt {q}}&#92;le 1-q^{c}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   Thus, if the inequality <img src="https://s0.wp.com/latex.php?latex=2%5E%7B-cps%7D%5Cleq+1%2Fq%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7B-cps%7D%5Cleq+1%2Fq%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7B-cps%7D%5Cleq+1%2Fq%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{-cps}&#92;leq 1/q^{c}" class="latex" /> holds then there exists a set <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=cps&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cps&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cps&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cps" class="latex" /> bits with which we can answer <img src="https://s0.wp.com/latex.php?latex=%5Cge+%5Csqrt+%7Bq%7D%3Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+%5Csqrt+%7Bq%7D%3Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+%5Csqrt+%7Bq%7D%3Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge &#92;sqrt {q}&gt;d" class="latex" /> queries. Hence we reach a contradiction if</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+c%5Clog+q%5Cle+cps%3Cd.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+c%5Clog+q%5Cle+cps%3Cd.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+c%5Clog+q%5Cle+cps%3Cd.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} c&#92;log q&#92;le cps&lt;d. &#92;end{aligned}" class="latex" />=&quot;&quot;  Because <img src="https://s0.wp.com/latex.php?latex=d%3Ec%5Clog+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%3Ec%5Clog+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%3Ec%5Clog+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&gt;c&#92;log q" class="latex" /> by assumption, and increasing <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> only make the problem easier, we reach a contradiction if <img src="https://s0.wp.com/latex.php?latex=cps%3Cd&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cps%3Cd&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cps%3Cd&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cps&lt;d" class="latex" />, and=&quot;&quot; the=&quot;&quot; result=&quot;&quot; follows.=&quot;&quot; <b>QED    </p>
<p></b></div>
<p style="text-align:justify">   Next we show a conceptually simple data structure which nearly matches the lower bound. For simplicity we focus on data structures which use space <img src="https://s0.wp.com/latex.php?latex=q%5E%7B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q%5E%7B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q%5E%7B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q^{&#92;epsilon }" class="latex" /> – recall in this case the previous result does not give anything. We will show this is for good reasons, there are data structures where the time is constant. We will only show <img src="https://s0.wp.com/latex.php?latex=c_%7B%5Cepsilon+%7Dd&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7B%5Cepsilon+%7Dd&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7B%5Cepsilon+%7Dd&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{&#92;epsilon }d" class="latex" />-wise independence, as opposed to <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />-wise, but the proof techniques next and above generalize to other settings of parameters.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-121007r2"></a> <b>Theorem</b> 12.2.  </span>There is a map <img src="https://s0.wp.com/latex.php?latex=f%3A%5Bq%5D%5E%7Bd%7D%5Cto+%5Bq%5D%5E%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5Bq%5D%5E%7Bd%7D%5Cto+%5Bq%5D%5E%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5Bq%5D%5E%7Bd%7D%5Cto+%5Bq%5D%5E%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:[q]^{d}&#92;to [q]^{q}" class="latex" /> which is <img src="https://s0.wp.com/latex.php?latex=c_%7B%5Cepsilon+%7Dd&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7B%5Cepsilon+%7Dd&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7B%5Cepsilon+%7Dd&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{&#92;epsilon }d" class="latex" />-wise uniform and has a data structure with <img src="https://s0.wp.com/latex.php?latex=w%3D%5Clog+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w%3D%5Clog+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%3D%5Clog+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w=&#92;log q" class="latex" /> space <img src="https://s0.wp.com/latex.php?latex=s%3Ddq%5E%7B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%3Ddq%5E%7B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%3Ddq%5E%7B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s=dq^{&#92;epsilon }" class="latex" /> and time <img src="https://s0.wp.com/latex.php?latex=c_%7B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{&#92;epsilon }" class="latex" />, for any <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon " class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" /> which is a power of <img src="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   To give a sense of the parameters, let for example <img src="https://s0.wp.com/latex.php?latex=q%3Dd%5E%7B10%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q%3Dd%5E%7B10%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q%3Dd%5E%7B10%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q=d^{10}" class="latex" />.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>We fill the memory with <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> evaluations of the input polynomial. Then we pick a random bipartite graph with <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> nodes on the left and <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" /> nodes on the right. Every node on the right side has degree <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" />. We answer each query by summing the corresponding cells in <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />. Let <img src="https://s0.wp.com/latex.php?latex=d%27%3A%3Dd%2Fg&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%27%3A%3Dd%2Fg&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%27%3A%3Dd%2Fg&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#039;:=d/g" class="latex" />. To show <img src="https://s0.wp.com/latex.php?latex=d%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#039;" class="latex" />-wise uniformity it suffices to show that for any subset <img src="https://s0.wp.com/latex.php?latex=R%5Csubseteq+%5Bq%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R%5Csubseteq+%5Bq%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R%5Csubseteq+%5Bq%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R&#92;subseteq [q]" class="latex" /> on the right-hand side of size <img src="https://s0.wp.com/latex.php?latex=d%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#039;" class="latex" />, the sum of the corresponding memory cells is uniform in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{q}" class="latex" />. For this in turn it suffices that <img src="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R" class="latex" /> has a unique neighbor. And for that, finally, it suffices that <img src="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R" class="latex" /> has a neighborhood of size greater than <img src="https://s0.wp.com/latex.php?latex=%5Cfrac+%7Bg%7CR%7C%7D%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cfrac+%7Bg%7CR%7C%7D%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac+%7Bg%7CR%7C%7D%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;frac {g|R|}{2}" class="latex" /> (because if every element in the neighborhood of <img src="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R" class="latex" /> has two neighbors in <img src="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R" class="latex" /> has a neighborhood of size less than <img src="https://s0.wp.com/latex.php?latex=g%7Cr%7C+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g%7Cr%7C+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g%7Cr%7C+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g|r| 2" class="latex" />).</p>
<p style="text-align:justify">   Note here we are using that the neighborhood has size <img src="https://s0.wp.com/latex.php?latex=%5Cle+gd%27%3Dd&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+gd%27%3Dd&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+gd%27%3Dd&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le gd&#039;=d" class="latex" />, and so the memory is <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />-wise uniform.</p>
<p style="text-align:justify">   We pick the graph at random and show that it has the latter property with non-zero probability.<br />
[Standard calculations follow that wordpress has trouble displaying&#8230; wait for the book draft, I guess.]<br />
<b>QED</b></p>
</div>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">12.1.1   </span> <a id="x1-12200012.1.1"></a>Succinct data structures</h4>
<p style="text-align:justify">Succinct data structures are those where the space is close to the minimum, <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />. Specifically, we let <img src="https://s0.wp.com/latex.php?latex=s%3Dn%2Br&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%3Dn%2Br&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%3Dn%2Br&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s=n+r" class="latex" /> for some <img src="https://s0.wp.com/latex.php?latex=r%3Do%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r%3Do%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r%3Do%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r=o(n)" class="latex" /> called <em>redundancy. </em>Unsurprisingly, stronger bounds can be probed in this setting. But, surprisingly, again these stronger bounds were shown to be tight. Moreover, it was shown that improving the bounds would imply stronger circuit lower bounds.</p>
<p style="text-align:justify">   To illustrate, consider the ECC problem <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} ^{m}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is an error-correcting code (with constant relative distance) and <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" /> is linear in <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-122001r3"></a> <b>Theorem</b> 12.3.  </span><span class="cite">[<a href="#XGalMiltersen07">26</a>]</span> Any data-structure for the ECC problem with <img src="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w=1" class="latex" /> using space <img src="https://s0.wp.com/latex.php?latex=n%2Br&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Br&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Br&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n+r" class="latex" /> requires time <img src="https://s0.wp.com/latex.php?latex=%5Cge+cn%2Fr&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+cn%2Fr&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+cn%2Fr&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge cn/r" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   This is nearly matched by the following result.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-122002r4"></a> <b>Theorem</b> 12.4.  </span><span class="cite">[<a href="#Xviola-datastructurelb-implies-cclb">81</a>]</span> There is an ECC problem s.t.&nbsp;for any <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r" class="latex" /> it has a data structure with <img src="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w=1" class="latex" />, space <img src="https://s0.wp.com/latex.php?latex=n%2Br&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Br&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Br&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n+r" class="latex" />, and time <img src="https://s0.wp.com/latex.php?latex=c%28n%2Fr%29%5Clog+%5E%7B3%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%28n%2Fr%29%5Clog+%5E%7B3%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%28n%2Fr%29%5Clog+%5E%7B3%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c(n/r)&#92;log ^{3}n" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Moreover, it was shown that proving a time lower bound of <img src="https://s0.wp.com/latex.php?latex=%28n%2Fr%29%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28n%2Fr%29%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28n%2Fr%29%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(n/r)&#92;log ^{c}n" class="latex" /> would imply new circuit lower bounds. The latter result refers to bounds on the number of wires in circuits with arbitrary gates. But the following connection with the standard circuit model is also known.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-122003r5"></a> <b>Theorem</b> 12.5.  </span><span class="cite">[<a href="#Xviola-datastructurelb-implies-cclb">81</a>]</span> Let <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bam%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bam%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bam%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} ^{am}" class="latex" /> be a function computable by bounded fan-in circuits with <img src="https://s0.wp.com/latex.php?latex=bm&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=bm&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=bm&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="bm" class="latex" /> wires and depth <img src="https://s0.wp.com/latex.php?latex=b%5Clog+m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%5Clog+m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%5Clog+m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b&#92;log m" class="latex" />, for constants <img src="https://s0.wp.com/latex.php?latex=a%2Cb&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%2Cb&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%2Cb&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a,b" class="latex" />. Then <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> has a data structure with space <img src="https://s0.wp.com/latex.php?latex=n%2Bo%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Bo%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Bo%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n+o(n)" class="latex" /> and time <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{o(1)}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Hence, proving <img src="https://s0.wp.com/latex.php?latex=n%5E%7B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{&#92;epsilon }" class="latex" /> time lower bounds for succinct data structures would give functions that cannot be computed by linear-size log-depth circuits, cf.&nbsp;<a href="#x1-1100009.3">9.3<!--tex4ht:ref: sec:Linear-size-log-depth --></a>.</p>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">12.1.2   </span> <a id="x1-12300012.1.2"></a>Succincter: The trits problem</h4>
<p style="text-align:justify">In this section we present a cute and fundamental data-structure problem with a shocking and counterintuitive solution. The trits problem is to compute <img src="https://s0.wp.com/latex.php?latex=f%3A%5B3%5D%5E%7Bn%7D%5Cto+%28%5C%7B0%2C1%5C%7D+%5E%7B2%7D%29%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5B3%5D%5E%7Bn%7D%5Cto+%28%5C%7B0%2C1%5C%7D+%5E%7B2%7D%29%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5B3%5D%5E%7Bn%7D%5Cto+%28%5C%7B0%2C1%5C%7D+%5E%7B2%7D%29%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:[3]^{n}&#92;to (&#92;{0,1&#92;} ^{2})^{n}" class="latex" /> where on input <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> “trits” (i.e., ternary elements) <img src="https://s0.wp.com/latex.php?latex=%28t_%7B1%7D%2Ct_%7B2%7D%2C%5Cldots+%2Ct_%7Bn%7D%29%5Cin+%5B3%5D%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28t_%7B1%7D%2Ct_%7B2%7D%2C%5Cldots+%2Ct_%7Bn%7D%29%5Cin+%5B3%5D%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28t_%7B1%7D%2Ct_%7B2%7D%2C%5Cldots+%2Ct_%7Bn%7D%29%5Cin+%5B3%5D%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(t_{1},t_{2},&#92;ldots ,t_{n})&#92;in [3]^{n}" class="latex" /> <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> outputs their representations using two bits per trit.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-123001r1"></a> <b>Example</b> 12.1.  </span>For <img src="https://s0.wp.com/latex.php?latex=n%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n=1" class="latex" />, we have <img src="https://s0.wp.com/latex.php?latex=f%280%29%3D00%2Cf%281%29%3D01%2Cf%282%29%3D10&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%280%29%3D00%2Cf%281%29%3D01%2Cf%282%29%3D10&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%280%29%3D00%2Cf%281%29%3D01%2Cf%282%29%3D10&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(0)=00,f(1)=01,f(2)=10" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Note that the input ranges over <img src="https://s0.wp.com/latex.php?latex=3%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3^{n}" class="latex" /> elements, and so the minimum space of the data structure is <img src="https://s0.wp.com/latex.php?latex=s%3D%5Clceil+%5Clog+_%7B2%7D3%5E%7Bn%7D%5Crceil+%3D%5Clceil+n%5Clog+_%7B2%7D3%5Crceil+%5Capprox+n%5Ccdot+1.584%5Cldots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%3D%5Clceil+%5Clog+_%7B2%7D3%5E%7Bn%7D%5Crceil+%3D%5Clceil+n%5Clog+_%7B2%7D3%5Crceil+%5Capprox+n%5Ccdot+1.584%5Cldots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%3D%5Clceil+%5Clog+_%7B2%7D3%5E%7Bn%7D%5Crceil+%3D%5Clceil+n%5Clog+_%7B2%7D3%5Crceil+%5Capprox+n%5Ccdot+1.584%5Cldots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s=&#92;lceil &#92;log _{2}3^{n}&#92;rceil =&#92;lceil n&#92;log _{2}3&#92;rceil &#92;approx n&#92;cdot 1.584&#92;ldots " class="latex" /> This will be our benchmark for space. One can encode the input to <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> as before using bits without loss of generality, but the current choice simplifies the exposition.</p>
<p style="text-align:justify">
<h5 class="likesubsubsectionHead"><a id="x1-12400012.1.2"></a>Simple solutions:</h5>
<ul class="itemize1">
<li class="itemize">The simplest solution (cf.&nbsp;<a href="#x1-121003r2">12.2<!--tex4ht:ref: xca:static-ds-trivial-sols --></a>) to this problem is to use <img src="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2" class="latex" /> bits per <img src="https://s0.wp.com/latex.php?latex=t_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t_{i}" class="latex" />. With such an encoding we can retrieve each <img src="https://s0.wp.com/latex.php?latex=t_%7Bi%7D%5Cin+%5B3%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t_%7Bi%7D%5Cin+%5B3%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t_%7Bi%7D%5Cin+%5B3%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t_{i}&#92;in [3]" class="latex" /> by reading just <img src="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2" class="latex" /> bits (which is optimal). The space used is <img src="https://s0.wp.com/latex.php?latex=s%3D2n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%3D2n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%3D2n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s=2n" class="latex" /> and we have linear redundancy.</li>
<li class="itemize">Another solution (cf.&nbsp;again <a href="#x1-121003r2">12.2<!--tex4ht:ref: xca:static-ds-trivial-sols --></a>) to this problem is what is called <em>arithmetic coding</em>: we think of the concatenated elements as forming a ternary number between <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=3%5E%7Bn%7D-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3%5E%7Bn%7D-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3%5E%7Bn%7D-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3^{n}-1" class="latex" />, and we write down its binary representation. To retrieve <img src="https://s0.wp.com/latex.php?latex=t_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t_{i}" class="latex" /> it seems we need to read all the input bits, but the space needed is optimal.</li>
<li class="itemize">For this and other problems, we can trade between these two extreme as follows. Group the <img src="https://s0.wp.com/latex.php?latex=t_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t_{i}" class="latex" />’s into blocks of <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />. Encode each block with arithmetic coding. The retrieval time will be <img src="https://s0.wp.com/latex.php?latex=ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="ct" class="latex" /> bits and the needed space will be <img src="https://s0.wp.com/latex.php?latex=%28n%2Ft%29%5Clceil+t%5Clog+_%7B2%7D3%5Crceil+%5Cleq+n%5Clog+_%7B2%7D3%2Bn%2Ft&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28n%2Ft%29%5Clceil+t%5Clog+_%7B2%7D3%5Crceil+%5Cleq+n%5Clog+_%7B2%7D3%2Bn%2Ft&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28n%2Ft%29%5Clceil+t%5Clog+_%7B2%7D3%5Crceil+%5Cleq+n%5Clog+_%7B2%7D3%2Bn%2Ft&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(n/t)&#92;lceil t&#92;log _{2}3&#92;rceil &#92;leq n&#92;log _{2}3+n/t" class="latex" /> (assuming <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> divides <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />). This is block-wise arithmetic coding. It provides a <em>power</em> trade-off between retrieval time and redundancy. (Using number-theoretic results on logarithmic forms, one can show <span class="cite">[<a href="#Xviola-triz">80</a>]</span> that this last inequality is tight up to changing <img src="https://s0.wp.com/latex.php?latex=n%2Ft&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Ft&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Ft&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n/t" class="latex" /> into <img src="https://s0.wp.com/latex.php?latex=n%2Ft%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Ft%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Ft%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n/t^{c}" class="latex" />.)</li>
</ul>
<p style="text-align:justify">
<h5 class="likesubsubsectionHead"><a id="x1-12500012.1.2"></a>The shocking solution: An exponential (!) trade-off</h5>
<p style="text-align:justify">We now present an <em>exponential</em> trade-off: retrieval time <img src="https://s0.wp.com/latex.php?latex=ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="ct" class="latex" /> bits and redundancy <img src="https://s0.wp.com/latex.php?latex=n%2F2%5E%7Bt%7D%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2F2%5E%7Bt%7D%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2F2%5E%7Bt%7D%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n/2^{t}+c" class="latex" />. In particular, if we set <img src="https://s0.wp.com/latex.php?latex=t%3Dc%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%3Dc%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%3Dc%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t=c&#92;log n" class="latex" />, we get retrieval time <img src="https://s0.wp.com/latex.php?latex=O%28%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(&#92;log n)" class="latex" /> and redundancy <img src="https://s0.wp.com/latex.php?latex=O%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(1)" class="latex" />. Moreover, the bits read are all consecutive, so with word size <img src="https://s0.wp.com/latex.php?latex=w%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w=&#92;log n" class="latex" /> this can be implemented in constant time. To repeat, we can encode the trits with constant redundancy and retrieve each in constant time. This solution can also be made dynamic.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-125001r6"></a> <b>Theorem</b> 12.6.  </span><span class="cite">[<a href="#XPatrascu08Succincter">53</a>,&nbsp;<a href="#XDodisPT10">21</a>]</span> The trits problem has a data structure with space <img src="https://s0.wp.com/latex.php?latex=n%5Clog+_%7B2%7D3%2Bn%2F2%5E%7Bt%7D%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5Clog+_%7B2%7D3%2Bn%2F2%5E%7Bt%7D%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Clog+_%7B2%7D3%2Bn%2F2%5E%7Bt%7D%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#92;log _{2}3+n/2^{t}+c" class="latex" /> (i.e., redundancy <img src="https://s0.wp.com/latex.php?latex=n%2F2%5E%7Bt%7D%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2F2%5E%7Bt%7D%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2F2%5E%7Bt%7D%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n/2^{t}+c" class="latex" />) and time <img src="https://s0.wp.com/latex.php?latex=ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="ct" class="latex" />, for any <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> and with word size <img src="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w=1" class="latex" />. For word wise <img src="https://s0.wp.com/latex.php?latex=w%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w=&#92;log n" class="latex" /> the time is constant.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Next we present the proof.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-125002r3"></a> <b>Definition</b> 12.3 (Encoding and redundancy).  </span>An  encoding  of  a  set  <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" />  into  a  set  <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" />  is  a one-to-one (a.k.a.&nbsp;injective) map <img src="https://s0.wp.com/latex.php?latex=f%3AA%5Cto+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AA%5Cto+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AA%5Cto+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:A&#92;to B" class="latex" />. The <em>redundancy</em> of the encoding <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%5Clog+_%7B2%7D%7CB%7C-%5Clog+_%7B2%7D%7CA&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+_%7B2%7D%7CB%7C-%5Clog+_%7B2%7D%7CA&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+_%7B2%7D%7CB%7C-%5Clog+_%7B2%7D%7CA&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log _{2}|B|-&#92;log _{2}|A" class="latex" />|.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The following lemma gives the building-block encoding we will use.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-125003r1"></a> <b>Lemma</b> 12.1.  </span> For all sets <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" />, there is an integer <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b" class="latex" />, a set <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K" class="latex" /> and an encoding</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%3A%5Cleft+%28X%5Ctimes+Y%5Cright+%29%5Crightarrow+%5Cleft+%28%5C%7B0%2C1%5C%7D+%5E%7Bb%7D%5Ctimes+K%5Cright+%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%3A%5Cleft+%28X%5Ctimes+Y%5Cright+%29%5Crightarrow+%5Cleft+%28%5C%7B0%2C1%5C%7D+%5E%7Bb%7D%5Ctimes+K%5Cright+%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%3A%5Cleft+%28X%5Ctimes+Y%5Cright+%29%5Crightarrow+%5Cleft+%28%5C%7B0%2C1%5C%7D+%5E%7Bb%7D%5Ctimes+K%5Cright+%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} f:&#92;left (X&#92;times Y&#92;right )&#92;rightarrow &#92;left (&#92;{0,1&#92;} ^{b}&#92;times K&#92;right ) &#92;end{aligned}" class="latex" /></div>
<p>such that (1) <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> has redundancy <img src="https://s0.wp.com/latex.php?latex=%5Cle+c%2F%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c%2F%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c%2F%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c/&#92;sqrt {|Y|}" class="latex" />, and (2) <img src="https://s0.wp.com/latex.php?latex=x%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in X" class="latex" /> can be recovered just by reading the <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b" class="latex" /> bits in <img src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x,y)" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">Note that (1) says that <img src="https://s0.wp.com/latex.php?latex=b%2B%5Clog+%7CK%7C-%5Clog+%7CX%7C-%5Clog+%7CY%7C%5Cle+c%2F%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%2B%5Clog+%7CK%7C-%5Clog+%7CX%7C-%5Clog+%7CY%7C%5Cle+c%2F%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%2B%5Clog+%7CK%7C-%5Clog+%7CX%7C-%5Clog+%7CY%7C%5Cle+c%2F%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b+&#92;log |K|-&#92;log |X|-&#92;log |Y|&#92;le c/&#92;sqrt {|Y|}" class="latex" />. For (2) to hold we must have <img src="https://s0.wp.com/latex.php?latex=b%5Cge+%5Clog+%7CX%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%5Cge+%5Clog+%7CX%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%5Cge+%5Clog+%7CX%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b&#92;ge &#92;log |X|" class="latex" />. Combining this with the previous expression we obtain <img src="https://s0.wp.com/latex.php?latex=%5Clog+%7CK%7C-%5Clog+%7CY%7C%5Cle+c%2F%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%7CK%7C-%5Clog+%7CY%7C%5Cle+c%2F%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%7CK%7C-%5Clog+%7CY%7C%5Cle+c%2F%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log |K|-&#92;log |Y|&#92;le c/&#92;sqrt {|Y|}" class="latex" />. In particular we get that <img src="https://s0.wp.com/latex.php?latex=%7CK%7C%5Cle+2%5E%7Bc%7D%5Ccdot+%7CY%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CK%7C%5Cle+2%5E%7Bc%7D%5Ccdot+%7CY%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CK%7C%5Cle+2%5E%7Bc%7D%5Ccdot+%7CY%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|K|&#92;le 2^{c}&#92;cdot |Y|" class="latex" /> (in fact it will be the case that <img src="https://s0.wp.com/latex.php?latex=%7CK%7C%5Cle+c%5Ccdot+%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CK%7C%5Cle+c%5Ccdot+%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CK%7C%5Cle+c%5Ccdot+%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|K|&#92;le c&#92;cdot &#92;sqrt {|Y|}" class="latex" />, but the looser bound is sufficient).</p>
<p style="text-align:justify">   The basic idea for proving the lemma is to break <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" /> into <img src="https://s0.wp.com/latex.php?latex=C%5Ctimes+K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Ctimes+K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Ctimes+K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;times K" class="latex" /> and then encode <img src="https://s0.wp.com/latex.php?latex=X%5Ctimes+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%5Ctimes+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%5Ctimes+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X&#92;times C" class="latex" /> by using <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b" class="latex" /> bits:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+X%5Ctimes+Y%5Crightarrow+X%5Ctimes+C%5Ctimes+K%5Crightarrow+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D%5Ctimes+K.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+X%5Ctimes+Y%5Crightarrow+X%5Ctimes+C%5Ctimes+K%5Crightarrow+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D%5Ctimes+K.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+X%5Ctimes+Y%5Crightarrow+X%5Ctimes+C%5Ctimes+K%5Crightarrow+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D%5Ctimes+K.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} X&#92;times Y&#92;rightarrow X&#92;times C&#92;times K&#92;rightarrow &#92;{0,1&#92;} ^{b}&#92;times K. &#92;end{aligned}" class="latex" /></div>
<p>There is however a subtle point. If we insist on always having <img src="https://s0.wp.com/latex.php?latex=%7CC%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CC%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CC%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|C|" class="latex" /> equal to, say, <img src="https://s0.wp.com/latex.php?latex=%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sqrt {|Y|}" class="latex" /> or some other quantity, then one can cook up sets that make us waste a lot (i.e., almost one bit) of space. The same of course happens in the more basic approach that just sets <img src="https://s0.wp.com/latex.php?latex=Y%3DK&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y%3DK&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y%3DK&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y=K" class="latex" /> and encodes all of <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b" class="latex" /> bits. The main idea will be to “reason backwards,” i.e., we will first pick <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b" class="latex" /> and then try to stuff as much as possible inside <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{b}" class="latex" />. Still, our choice of <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b" class="latex" /> will make <img src="https://s0.wp.com/latex.php?latex=%7CC%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CC%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CC%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|C|" class="latex" /> about <img src="https://s0.wp.com/latex.php?latex=%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sqrt {|Y|}" class="latex" />.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Pick any two sets <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=%7CY%7C%3E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CY%7C%3E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CY%7C%3E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|Y|&gt;1" class="latex" /> without loss of generality. Define <img src="https://s0.wp.com/latex.php?latex=b%3A%3D%5Cleft+%5Clceil+%5Clog+_%7B2%7D%5Cleft+%28%7CX%7C%5Ccdot+%5Csqrt+%7B%7CY%7C%7D%5Cright+%29%5Cright+%5Crceil+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%3A%3D%5Cleft+%5Clceil+%5Clog+_%7B2%7D%5Cleft+%28%7CX%7C%5Ccdot+%5Csqrt+%7B%7CY%7C%7D%5Cright+%29%5Cright+%5Crceil+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%3A%3D%5Cleft+%5Clceil+%5Clog+_%7B2%7D%5Cleft+%28%7CX%7C%5Ccdot+%5Csqrt+%7B%7CY%7C%7D%5Cright+%29%5Cright+%5Crceil+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b:=&#92;left &#92;lceil &#92;log _{2}&#92;left (|X|&#92;cdot &#92;sqrt {|Y|}&#92;right )&#92;right &#92;rceil " class="latex" />, and let <img src="https://s0.wp.com/latex.php?latex=B%3A%3D%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B%3A%3D%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B%3A%3D%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B:=&#92;{0,1&#92;} ^{b}" class="latex" />. To simplify notation, define <img src="https://s0.wp.com/latex.php?latex=d%3A%3D2%5E%7Bb%7D%2F%7CX%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%3A%3D2%5E%7Bb%7D%2F%7CX%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%3A%3D2%5E%7Bb%7D%2F%7CX%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d:=2^{b}/|X|" class="latex" />. Note <img src="https://s0.wp.com/latex.php?latex=c%5Csqrt+%7B%7CY%7C%7D%5Cle+d%5Cle+c%5Csqrt+%7B%7CY%7C%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Csqrt+%7B%7CY%7C%7D%5Cle+d%5Cle+c%5Csqrt+%7B%7CY%7C%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Csqrt+%7B%7CY%7C%7D%5Cle+d%5Cle+c%5Csqrt+%7B%7CY%7C%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;sqrt {|Y|}&#92;le d&#92;le c&#92;sqrt {|Y|}." class="latex" /></p>
<p style="text-align:justify">   How much can we stuff into <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" />? For a set <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> of size <img src="https://s0.wp.com/latex.php?latex=%7CC%7C%3D%5Cleft+%5Clfloor+%7CB%7C%2F%7CX%7C%5Cright+%5Crfloor+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CC%7C%3D%5Cleft+%5Clfloor+%7CB%7C%2F%7CX%7C%5Cright+%5Crfloor+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CC%7C%3D%5Cleft+%5Clfloor+%7CB%7C%2F%7CX%7C%5Cright+%5Crfloor+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|C|=&#92;left &#92;lfloor |B|/|X|&#92;right &#92;rfloor " class="latex" />, we can encode elements from <img src="https://s0.wp.com/latex.php?latex=X%5Ctimes+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%5Ctimes+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%5Ctimes+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X&#92;times C" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" />. The redundancy of such an encoding can be bounded as follows:</p>
<p style="text-align:justify">
<p style="text-align:justify">   To calculate the total redundancy, we still need to examine the encoding from <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=C%5Ctimes+K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Ctimes+K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Ctimes+K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;times K" class="latex" />. Choose <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K" class="latex" /> of size <img src="https://s0.wp.com/latex.php?latex=%7CK%7C%3D%5Cleft+%5Clceil+%7CY%7C%2F%7CC%7C%5Cright+%5Crceil+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CK%7C%3D%5Cleft+%5Clceil+%7CY%7C%2F%7CC%7C%5Cright+%5Crceil+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CK%7C%3D%5Cleft+%5Clceil+%7CY%7C%2F%7CC%7C%5Cright+%5Crceil+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|K|=&#92;left &#92;lceil |Y|/|C|&#92;right &#92;rceil " class="latex" />, so that this encoding is possible. With a calculation similar to the previous one, we see that the redundancy is:</p>
<p style="text-align:justify">
<p style="text-align:justify">   The total redundancy is then <img src="https://s0.wp.com/latex.php?latex=c%2F%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%2F%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%2F%5Csqrt+%7B%7CY%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c/&#92;sqrt {|Y|}" class="latex" />, which gives (1).</p>
<p style="text-align:justify">   For (2), it is clear from the construction that any <img src="https://s0.wp.com/latex.php?latex=x%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in X" class="latex" /> can be recovered from the element of <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> only. <b>QED</b></p>
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Theorem <a href="#x1-125001r6">12.6<!--tex4ht:ref: thm:triz --></a></b>.&nbsp;</span> Break the ternary elements into blocks of size <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />: <img src="https://s0.wp.com/latex.php?latex=%28t%27_%7B1%7D%2Ct%27_%7B2%7D%2C%5Cldots+%2Ct%27_%7Bn%2Ft%7D%29%5Cin+T_%7B1%7D%5Ctimes+T_%7B2%7D%5Ctimes+%5Cldots+%5Ctimes+T_%7Bn%2Ft%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28t%27_%7B1%7D%2Ct%27_%7B2%7D%2C%5Cldots+%2Ct%27_%7Bn%2Ft%7D%29%5Cin+T_%7B1%7D%5Ctimes+T_%7B2%7D%5Ctimes+%5Cldots+%5Ctimes+T_%7Bn%2Ft%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28t%27_%7B1%7D%2Ct%27_%7B2%7D%2C%5Cldots+%2Ct%27_%7Bn%2Ft%7D%29%5Cin+T_%7B1%7D%5Ctimes+T_%7B2%7D%5Ctimes+%5Cldots+%5Ctimes+T_%7Bn%2Ft%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(t&#039;_{1},t&#039;_{2},&#92;ldots ,t&#039;_{n/t})&#92;in T_{1}&#92;times T_{2}&#92;times &#92;ldots &#92;times T_{n/t}" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=T_%7Bi%7D%3D%5B3%5D%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=T_%7Bi%7D%3D%5B3%5D%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=T_%7Bi%7D%3D%5B3%5D%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="T_{i}=[3]^{t}" class="latex" /> for all <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />. The encoding, illustrated in Figure 1, is constructed as follows, where we use <img src="https://s0.wp.com/latex.php?latex=f_%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{L}" class="latex" /> to refer to the encoding guaranteed by Lemma&nbsp;Lemma <a href="#x1-125003r1">12.1<!--tex4ht:ref: lem:triz-buildblock --></a>.</p>
<p style="text-align:justify">   Compute <img src="https://s0.wp.com/latex.php?latex=f_%7BL%7D%28t%27_%7B1%7D%2Ct%27_%7B2%7D%29%3D%28b_%7B1%7D%2Ck_%7B1%7D%29%5Cin+B_%7B1%7D%5Ctimes+K_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BL%7D%28t%27_%7B1%7D%2Ct%27_%7B2%7D%29%3D%28b_%7B1%7D%2Ck_%7B1%7D%29%5Cin+B_%7B1%7D%5Ctimes+K_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BL%7D%28t%27_%7B1%7D%2Ct%27_%7B2%7D%29%3D%28b_%7B1%7D%2Ck_%7B1%7D%29%5Cin+B_%7B1%7D%5Ctimes+K_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{L}(t&#039;_{1},t&#039;_{2})=(b_{1},k_{1})&#92;in B_{1}&#92;times K_{1}" class="latex" />.</p>
<p style="text-align:justify">   For <img src="https://s0.wp.com/latex.php?latex=i%3D2%2C%5Cldots+%2Cn%2Ft-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%3D2%2C%5Cldots+%2Cn%2Ft-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%3D2%2C%5Cldots+%2Cn%2Ft-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i=2,&#92;ldots ,n/t-1" class="latex" /> compute <img src="https://s0.wp.com/latex.php?latex=f_%7BL%7D%28k_%7Bi-1%7D%2Ct%27_%7Bi%2B1%7D%29%3A%3D%28b_%7Bi%7D%2Ck_%7Bi%7D%29%5Cin+B_%7Bi%7D%5Ctimes+K_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BL%7D%28k_%7Bi-1%7D%2Ct%27_%7Bi%2B1%7D%29%3A%3D%28b_%7Bi%7D%2Ck_%7Bi%7D%29%5Cin+B_%7Bi%7D%5Ctimes+K_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BL%7D%28k_%7Bi-1%7D%2Ct%27_%7Bi%2B1%7D%29%3A%3D%28b_%7Bi%7D%2Ck_%7Bi%7D%29%5Cin+B_%7Bi%7D%5Ctimes+K_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{L}(k_{i-1},t&#039;_{i+1}):=(b_{i},k_{i})&#92;in B_{i}&#92;times K_{i}" class="latex" />.</p>
<p style="text-align:justify">   Encode <img src="https://s0.wp.com/latex.php?latex=k_%7Bn%2Ft-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k_%7Bn%2Ft-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k_%7Bn%2Ft-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k_{n/t-1}" class="latex" /> in binary as <img src="https://s0.wp.com/latex.php?latex=b_%7Bn%2Ft%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b_%7Bn%2Ft%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b_%7Bn%2Ft%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b_{n/t}" class="latex" /> using arithmetic coding.</p>
<p style="text-align:justify">The final encoding is <img src="https://s0.wp.com/latex.php?latex=%28b_%7B1%7D%2Cb_%7B2%7D%2C%5Cldots+%2Cb_%7Bn%2Ft%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28b_%7B1%7D%2Cb_%7B2%7D%2C%5Cldots+%2Cb_%7Bn%2Ft%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28b_%7B1%7D%2Cb_%7B2%7D%2C%5Cldots+%2Cb_%7Bn%2Ft%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(b_{1},b_{2},&#92;ldots ,b_{n/t})" class="latex" />. We now compute the redundancy and retrieval time.</p>
<p style="text-align:justify">   <em>Redundancy:</em> From (1) in Lemma&nbsp;<a href="#x1-125003r1">12.1<!--tex4ht:ref: lem:triz-buildblock --></a>, the first <img src="https://s0.wp.com/latex.php?latex=n%2Ft-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Ft-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Ft-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n/t-1" class="latex" /> encodings have redundancy <img src="https://s0.wp.com/latex.php?latex=c3%5E%7B-t%2F2%7D%5Cle+1%2F2%5E%7Bct%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c3%5E%7B-t%2F2%7D%5Cle+1%2F2%5E%7Bct%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c3%5E%7B-t%2F2%7D%5Cle+1%2F2%5E%7Bct%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c3^{-t/2}&#92;le 1/2^{ct}" class="latex" />. For the last (arithmetic) encoding, the redundancy is at most <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" />. So the total redundancy is at most <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft+%28%5Cfrac+%7Bn%7D%7Bt%7D-1%5Cright+%29%5Ccdot+%5Cfrac+%7B1%7D%7B2%5E%7Bct%7D%7D%2B1%3D%5Cfrac+%7Bn%7D%7B2%5E%7Bct%7D%7D%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft+%28%5Cfrac+%7Bn%7D%7Bt%7D-1%5Cright+%29%5Ccdot+%5Cfrac+%7B1%7D%7B2%5E%7Bct%7D%7D%2B1%3D%5Cfrac+%7Bn%7D%7B2%5E%7Bct%7D%7D%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft+%28%5Cfrac+%7Bn%7D%7Bt%7D-1%5Cright+%29%5Ccdot+%5Cfrac+%7B1%7D%7B2%5E%7Bct%7D%7D%2B1%3D%5Cfrac+%7Bn%7D%7B2%5E%7Bct%7D%7D%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;displaystyle &#92;left (&#92;frac {n}{t}-1&#92;right )&#92;cdot &#92;frac {1}{2^{ct}}+1=&#92;frac {n}{2^{ct}}+c" class="latex" />. One can visualize this as a “hybrid argument” transforming a product of blocks of ternary elements into a product of blocks of binary elements, one block at the time.</p>
<p style="text-align:justify">   <em>Retrieval Time:</em> Say that we want to recover some <img src="https://s0.wp.com/latex.php?latex=t_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t_{j}" class="latex" /> which is in block <img src="https://s0.wp.com/latex.php?latex=t%27_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%27_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%27_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#039;_{i}" class="latex" />. To recover block <img src="https://s0.wp.com/latex.php?latex=t%27_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%27_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%27_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#039;_{i}" class="latex" />, Lemma <a href="#x1-125003r1">12.1<!--tex4ht:ref: lem:triz-buildblock --></a> guarantees that we only need to look at <img src="https://s0.wp.com/latex.php?latex=b_%7Bi-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b_%7Bi-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b_%7Bi-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b_{i-1}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=b_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b_{i}" class="latex" />. This is because <img src="https://s0.wp.com/latex.php?latex=k_%7Bi-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k_%7Bi-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k_%7Bi-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k_{i-1}" class="latex" /> can be recovered by reading only <img src="https://s0.wp.com/latex.php?latex=b_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b_{i}" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=t%27_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%27_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%27_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#039;_{i}" class="latex" /> can be recovered by reading <img src="https://s0.wp.com/latex.php?latex=k_%7Bi-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k_%7Bi-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k_%7Bi-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k_{i-1}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=b_%7Bi-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b_%7Bi-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b_%7Bi-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b_{i-1}" class="latex" />. Thus to complete the proof it suffices to show that each <img src="https://s0.wp.com/latex.php?latex=b_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b_{i}" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="ct" class="latex" />.</p>
<p style="text-align:justify">   This is not completely obvious because one might have thought that the <img src="https://s0.wp.com/latex.php?latex=K_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K_{i}" class="latex" /> become larger and larger, and so we apply the lemma to larger and larger inputs and the <img src="https://s0.wp.com/latex.php?latex=B_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B_{i}" class="latex" /> get large too. However, recall that each <img src="https://s0.wp.com/latex.php?latex=%7CK_%7Bi%7D%7C%5Cle+c%7CT_%7Bi%7D%7C%3Dc3%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CK_%7Bi%7D%7C%5Cle+c%7CT_%7Bi%7D%7C%3Dc3%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CK_%7Bi%7D%7C%5Cle+c%7CT_%7Bi%7D%7C%3Dc3%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|K_{i}|&#92;le c|T_{i}|=c3^{t}" class="latex" /> from the comment after the statement of Lemma <a href="#x1-125003r1">12.1<!--tex4ht:ref: lem:triz-buildblock --></a>. Hence, every time we apply the lemma on an input of size at most <img src="https://s0.wp.com/latex.php?latex=s%5Cle+3%5E%7Bct%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cle+3%5E%7Bct%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cle+3%5E%7Bct%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;le 3^{ct}" class="latex" />. Since the lemma wastes little entropy (by (1) in Lemma <a href="#x1-125003r1">12.1<!--tex4ht:ref: lem:triz-buildblock --></a>), none of its outputs can be much larger than its input, and so <img src="https://s0.wp.com/latex.php?latex=%7CB_%7Bi%7D%7C%3D2%5E%7Bct%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CB_%7Bi%7D%7C%3D2%5E%7Bct%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CB_%7Bi%7D%7C%3D2%5E%7Bct%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|B_{i}|=2^{ct}" class="latex" />.</p>
<hr class="figure"/>
<div class="figure"><a id="x1-1250041"></a>  <img src="../../classes/gems/lectures/le23-24pic1.png" alt="PIC" width="248" height="240"/></p>
<div class="caption"><span class="id">Figure&nbsp;12.1: </span><span class="content">Succinct Encoding</span></div>
<p><!--tex4ht:label?: x1-1250041 --></p>
</div>
<hr class="endfigure"/>
<p style="text-align:justify">   <b>QED</b></p>
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">12.2   </span> <a id="x1-12600012.2"></a>Dynamic data structures</h3>
<p style="text-align:justify">We now study dynamic data structures. As we mentioned, here the input is not fixed but can be modified by the queries.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-126001r4"></a> <b>Definition</b> 12.4.  </span>Fix an error-correcting code <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BECC%7D%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BECC%7D%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BECC%7D%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {ECC}:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} ^{m}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=m%5Cle+cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m%5Cle+cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m%5Cle+cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m&#92;le cn" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5CDelta+%28%5Ctext+%7BECC%7D%28x%29%2C%5Ctext+%7BECC%7D%28y%29%29%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CDelta+%28%5Ctext+%7BECC%7D%28x%29%2C%5Ctext+%7BECC%7D%28y%29%29%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CDelta+%28%5Ctext+%7BECC%7D%28x%29%2C%5Ctext+%7BECC%7D%28y%29%29%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Delta (&#92;text {ECC}(x),&#92;text {ECC}(y))&#92;ge c" class="latex" /> for any <img src="https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;ne y" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" />. Here <img src="https://s0.wp.com/latex.php?latex=%5CDelta+%28u%2Cv%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CDelta+%28u%2Cv%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CDelta+%28u%2Cv%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Delta (u,v)" class="latex" /> is the relative distance, the fraction of bit positions where <img src="https://s0.wp.com/latex.php?latex=u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="u" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v" class="latex" /> differ.</p>
<p style="text-align:justify">   The <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BECC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BECC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BECC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {ECC}" class="latex" /> problem asks to support operations, starting with the all-zero message:</p>
<p style="text-align:justify">   <img src="https://s0.wp.com/latex.php?latex=M%28i%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28i%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28i%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(i,b)" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=i%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#92;in &#92;{1,2,&#92;ldots ,n&#92;}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=b%5Cin+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%5Cin+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%5Cin+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b&#92;in &#92;{0,1&#92;} " class="latex" /> which sets bit <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> of the message to <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b" class="latex" />, and</p>
<p style="text-align:justify">   <img src="https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(i)" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=i%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cm%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cm%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cm%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#92;in &#92;{1,2,&#92;ldots ,m&#92;}" class="latex" /> which returns bit <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> of the codeword corresponding to the current message.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The time of a dynamic data structure is the maximum number of read/write operations in memory cells required to support an operation.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-126002r7"></a> <b>Theorem</b> 12.7.  </span> The <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BECC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BECC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BECC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {ECC}" class="latex" /> problem requires time <img src="https://s0.wp.com/latex.php?latex=t%5Cge+c%5Clog+_%7Bw%7Dn%5Cge+%28c%5Clog+n%29%2F%5Clog+%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cge+c%5Clog+_%7Bw%7Dn%5Cge+%28c%5Clog+n%29%2F%5Clog+%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cge+c%5Clog+_%7Bw%7Dn%5Cge+%28c%5Clog+n%29%2F%5Clog+%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;ge c&#92;log _{w}n&#92;ge (c&#92;log n)/&#92;log &#92;log n" class="latex" /> for cell size <img src="https://s0.wp.com/latex.php?latex=w%3A%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w%3A%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%3A%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w:=&#92;log n" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   One might wonder if stronger bounds can be shown for this problem. But in fact there exist codes for which the bounds are nearly tight.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-126003r8"></a> <b>Theorem</b> 12.8.  </span><span class="cite">[<a href="#Xviola-datastructurelb-implies-cclb">81</a>]</span>There exists codes for which the ECC problem can be solved in time <img src="https://s0.wp.com/latex.php?latex=c%5Clog+%5E%7B2%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+%5E%7B2%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+%5E%7B2%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log ^{2}n" class="latex" /> with cell size <img src="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w=1" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The technique in the proof of Theorem <a href="#x1-126002r7">12.7<!--tex4ht:ref: thm:ECC-data-structure-lower-bound --></a> is from <span class="cite">[<a href="#XFredmanS89">24</a>]</span> and can be applied to many other natural problems, leading to tight results in several cases, see Exercise ??. It is not far from the state-of-the art in this area, which is <img src="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7B1%2Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7B1%2Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%5E%7B1%2Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log ^{1+c}n" class="latex" /> <span class="cite">[<a href="journals/siamcomp/LarsenWY20">42</a>]</span>.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Theorem <a href="#x1-126002r7">12.7<!--tex4ht:ref: thm:ECC-data-structure-lower-bound --></a></b>.&nbsp;</span> Pick <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n}" class="latex" /> uniformly and <img src="https://s0.wp.com/latex.php?latex=i%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cm%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cm%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cm%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#92;in &#92;{1,2,&#92;ldots ,m&#92;}" class="latex" /> uniformly, and consider the sequence of operations</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+M%281%2Cx_%7B1%7D%29%2CM%282%2Cx_%7B2%7D%29%2C%5Cldots+%2CM%28n%2Cx_%7Bn%7D%29%2CC%28i%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+M%281%2Cx_%7B1%7D%29%2CM%282%2Cx_%7B2%7D%29%2C%5Cldots+%2CM%28n%2Cx_%7Bn%7D%29%2CC%28i%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+M%281%2Cx_%7B1%7D%29%2CM%282%2Cx_%7B2%7D%29%2C%5Cldots+%2CM%28n%2Cx_%7Bn%7D%29%2CC%28i%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} M(1,x_{1}),M(2,x_{2}),&#92;ldots ,M(n,x_{n}),C(i). &#92;end{aligned}" class="latex" /></div>
<p>That is, we set the message to a uniform <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> one bit at a time, and then ask for a uniformly selected bit of the codeword <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BECC%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BECC%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BECC%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {ECC}(x)" class="latex" />, which we also denote by <img src="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%3DC_%7Bx%7D%281%29%2CC_%7Bx%7D%282%29%2C%5Cldots+%2CC_%7Bx%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%3DC_%7Bx%7D%281%29%2CC_%7Bx%7D%282%29%2C%5Cldots+%2CC_%7Bx%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bx%7D%3DC_%7Bx%7D%281%29%2CC_%7Bx%7D%282%29%2C%5Cldots+%2CC_%7Bx%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{x}=C_{x}(1),C_{x}(2),&#92;ldots ,C_{x}(n)" class="latex" />.</p>
<p style="text-align:justify">   We divide the <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> operations <img src="https://s0.wp.com/latex.php?latex=M%28i%2Cx_%7Bi%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28i%2Cx_%7Bi%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28i%2Cx_%7Bi%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(i,x_{i})" class="latex" /> into consecutive blocks, called <em>epochs</em>. Epoch <img src="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e" class="latex" /> consists of <img src="https://s0.wp.com/latex.php?latex=n%2Fw%5E%7B3e%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Fw%5E%7B3e%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Fw%5E%7B3e%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n/w^{3e}" class="latex" /> operations. Hence we can have at least <img src="https://s0.wp.com/latex.php?latex=E%3A%3Dc%5Clog+_%7Bw%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E%3A%3Dc%5Clog+_%7Bw%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E%3A%3Dc%5Clog+_%7Bw%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E:=c&#92;log _{w}n" class="latex" /> epochs, and we can assume that we have exactly this many epochs (by discarding some bits of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> if necessary).</p>
<p style="text-align:justify">   The geometrically decaying size of epochs is chosen so that the number of message bits set during an epoch <img src="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e" class="latex" /> is much more than all the cells written by the data structure in future epochs.</p>
<p style="text-align:justify">   A key idea of the proof is to see what happens when the cells written during a certain epoch are ignored, or reverted to their contents right before the epoch. Specifically, after the execution of the <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> operations, we can associate to each memory cell the last epoch during which this cell was written. Let <img src="https://s0.wp.com/latex.php?latex=D%5E%7Be%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D%5E%7Be%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D%5E%7Be%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D^{e}(x)" class="latex" /> denote the memory cells of the data structure after the first <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> operations <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, but with the change that the cells that were written last during epoch <img src="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e" class="latex" /> are replaced with their contents right before epoch <img src="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e" class="latex" />. Define <img src="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{x}^{e}(i)" class="latex" /> to be the result of the data structure algorithm for <img src="https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(i)" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=D%5E%7Be%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D%5E%7Be%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D%5E%7Be%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D^{e}(x)" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D%3DC_%7Bx%7D%5E%7Be%7D%281%29%2CC_%7Bx%7D%5E%7Be%7D%282%29%2C%5Cldots+%2CC_%7Bx%7D%5E%7Be%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D%3DC_%7Bx%7D%5E%7Be%7D%281%29%2CC_%7Bx%7D%5E%7Be%7D%282%29%2C%5Cldots+%2CC_%7Bx%7D%5E%7Be%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D%3DC_%7Bx%7D%5E%7Be%7D%281%29%2CC_%7Bx%7D%5E%7Be%7D%282%29%2C%5Cldots+%2CC_%7Bx%7D%5E%7Be%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{x}^{e}=C_{x}^{e}(1),C_{x}^{e}(2),&#92;ldots ,C_{x}^{e}(n)" class="latex" />.</p>
<p style="text-align:justify">   Let <img src="https://s0.wp.com/latex.php?latex=t%28x%2Ci%2Ce%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28x%2Ci%2Ce%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28x%2Ci%2Ce%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(x,i,e)" class="latex" /> equal <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(i)" class="latex" />, executed after the first <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> operations <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, reads a cell that was last written in epoch <img src="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> otherwise. We have</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5Cge+%5Cmax+_%7Bx%2Ci%7D%5Csum+_%7Be%7Dt%28x%2Ci%2Ce%29%5Cge+%5Cmathbb+%7BE%7D_%7Bx%2Ci%7D%5Csum+_%7Be%7Dt%28x%2Ci%2Ce%29%3D%5Csum+_%7Be%7D%5Cmathbb+%7BE%7D_%7Bx%2Ci%7Dt%28x%2Ci%2Ce%29%5Cge+%5Csum+_%7Be%7D%5Cmathbb+%7BE%7D_%7Bx%7D%5CDelta+%28C_%7Bx%7D%2CC_%7Bx%7D%5E%7Be%7D%29%2C%7E%7E%7E%7E%2812.1%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5Cge+%5Cmax+_%7Bx%2Ci%7D%5Csum+_%7Be%7Dt%28x%2Ci%2Ce%29%5Cge+%5Cmathbb+%7BE%7D_%7Bx%2Ci%7D%5Csum+_%7Be%7Dt%28x%2Ci%2Ce%29%3D%5Csum+_%7Be%7D%5Cmathbb+%7BE%7D_%7Bx%2Ci%7Dt%28x%2Ci%2Ce%29%5Cge+%5Csum+_%7Be%7D%5Cmathbb+%7BE%7D_%7Bx%7D%5CDelta+%28C_%7Bx%7D%2CC_%7Bx%7D%5E%7Be%7D%29%2C%7E%7E%7E%7E%2812.1%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5Cge+%5Cmax+_%7Bx%2Ci%7D%5Csum+_%7Be%7Dt%28x%2Ci%2Ce%29%5Cge+%5Cmathbb+%7BE%7D_%7Bx%2Ci%7D%5Csum+_%7Be%7Dt%28x%2Ci%2Ce%29%3D%5Csum+_%7Be%7D%5Cmathbb+%7BE%7D_%7Bx%2Ci%7Dt%28x%2Ci%2Ce%29%5Cge+%5Csum+_%7Be%7D%5Cmathbb+%7BE%7D_%7Bx%7D%5CDelta+%28C_%7Bx%7D%2CC_%7Bx%7D%5E%7Be%7D%29%2C%7E%7E%7E%7E%2812.1%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} t&#92;ge &#92;max _{x,i}&#92;sum _{e}t(x,i,e)&#92;ge &#92;mathbb {E}_{x,i}&#92;sum _{e}t(x,i,e)=&#92;sum _{e}&#92;mathbb {E}_{x,i}t(x,i,e)&#92;ge &#92;sum _{e}&#92;mathbb {E}_{x}&#92;Delta (C_{x},C_{x}^{e}),~~~~(12.1) &#92;end{aligned}" class="latex" /></div>
<p>where the last inequality holds because <img src="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D%28i%29%5Cne+C_%7Bx%7D%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D%28i%29%5Cne+C_%7Bx%7D%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D%28i%29%5Cne+C_%7Bx%7D%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{x}^{e}(i)&#92;ne C_{x}(i)" class="latex" /> implies <img src="https://s0.wp.com/latex.php?latex=t%28x%2Ci%2Ce%29%5Cge+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28x%2Ci%2Ce%29%5Cge+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28x%2Ci%2Ce%29%5Cge+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(x,i,e)&#92;ge 1" class="latex" />.</p>
<p style="text-align:justify">   We now claim that if <img src="https://s0.wp.com/latex.php?latex=t%5Cle+w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cle+w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cle+w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;le w" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%7D%5CDelta+%28C_%7Bx%7D%2CC_%7Bx%7D%5E%7Be%7D%29%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%7D%5CDelta+%28C_%7Bx%7D%2CC_%7Bx%7D%5E%7Be%7D%29%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%7D%5CDelta+%28C_%7Bx%7D%2CC_%7Bx%7D%5E%7Be%7D%29%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {E}_{x}&#92;Delta (C_{x},C_{x}^{e})&#92;ge c" class="latex" /> for every <img src="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e" class="latex" />. This concludes the proof.</p>
<p style="text-align:justify">   In the remainder we justify the claim. Fix arbitrarily the bits of <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> set before Epoch <img src="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e" class="latex" />. For a uniform setting of the remaining bits of <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, note that the message ranges over at least</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+2%5E%7Bn%2Fw%5E%7B3e%7D%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+2%5E%7Bn%2Fw%5E%7B3e%7D%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+2%5E%7Bn%2Fw%5E%7B3e%7D%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} 2^{n/w^{3e}} &#92;end{aligned}" class="latex" /></div>
<p>codewords. On the other hand, we claim that <img src="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{x}^{e}" class="latex" /> ranges over much fewer strings. Indeed, the total number of cells written in all epochs after <img src="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e" class="latex" /> is at most</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5Csum+_%7Bi%5Cge+e%2B1%7Dn%2Fw%5E%7B3i%7D%5Cle+ctn%2Fw%5E%7B3%28e%2B1%29%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5Csum+_%7Bi%5Cge+e%2B1%7Dn%2Fw%5E%7B3i%7D%5Cle+ctn%2Fw%5E%7B3%28e%2B1%29%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5Csum+_%7Bi%5Cge+e%2B1%7Dn%2Fw%5E%7B3i%7D%5Cle+ctn%2Fw%5E%7B3%28e%2B1%29%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} t&#92;sum _{i&#92;ge e+1}n/w^{3i}&#92;le ctn/w^{3(e+1)}. &#92;end{aligned}" class="latex" /></div>
<p>We can describe all these cells by writing down their indices and contents using <img src="https://s0.wp.com/latex.php?latex=B%3A%3Dctn%2Fw%5E%7B3e%2B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B%3A%3Dctn%2Fw%5E%7B3e%2B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B%3A%3Dctn%2Fw%5E%7B3e%2B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B:=ctn/w^{3e+2}" class="latex" /> bits. Note that this information can depend on the operations performed during Epoch <img src="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e" class="latex" />, but the point is that it takes few possible values overall. Since the cells last changed during Epoch <img src="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e" class="latex" /> are reverted to their contents before Epoch <img src="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e" class="latex" />, this information suffices to describe <img src="https://s0.wp.com/latex.php?latex=D%5E%7Be%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D%5E%7Be%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D%5E%7Be%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D^{e}(x)" class="latex" />, and hence <img src="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{x}^{e}" class="latex" />. Therefore, <img src="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{x}^{e}" class="latex" /> ranges over <img src="https://s0.wp.com/latex.php?latex=%5Cle+2%5E%7BB%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+2%5E%7BB%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+2%5E%7BB%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le 2^{B}" class="latex" /> strings.</p>
<p style="text-align:justify">   For each string in the range of <img src="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bx%7D%5E%7Be%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{x}^{e}" class="latex" /> at most two codewords can have relative distance <img src="https://s0.wp.com/latex.php?latex=%5Cle+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c" class="latex" />, for else you’d have two codewords at distance <img src="https://s0.wp.com/latex.php?latex=%5Cle+2c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+2c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+2c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le 2c" class="latex" />, violating the distance of the code.</p>
<p style="text-align:justify">   Hence except with probability <img src="https://s0.wp.com/latex.php?latex=2%5Ccdot+2%5E%7BB%7D%2F2%5E%7Bn%2Fw%5E%7B3e%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5Ccdot+2%5E%7BB%7D%2F2%5E%7Bn%2Fw%5E%7B3e%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5Ccdot+2%5E%7BB%7D%2F2%5E%7Bn%2Fw%5E%7B3e%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2&#92;cdot 2^{B}/2^{n/w^{3e}}" class="latex" /> over <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, we have <img src="https://s0.wp.com/latex.php?latex=%5CDelta+%28C_%7Bx%7D%2CC_%7Bx%7D%5E%7Be%7D%29%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CDelta+%28C_%7Bx%7D%2CC_%7Bx%7D%5E%7Be%7D%29%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CDelta+%28C_%7Bx%7D%2CC_%7Bx%7D%5E%7Be%7D%29%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Delta (C_{x},C_{x}^{e})&#92;ge c" class="latex" />. If <img src="https://s0.wp.com/latex.php?latex=t_%7BM%7D%5Cle+w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t_%7BM%7D%5Cle+w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t_%7BM%7D%5Cle+w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t_{M}&#92;le w" class="latex" /> then the first probability is <img src="https://s0.wp.com/latex.php?latex=%5Cle+0.1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+0.1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+0.1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le 0.1" class="latex" />, and so <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%7D%5CDelta+%28C_%7Bx%7D%2CC_%7Bx%7D%5E%7Be%7D%29%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%7D%5CDelta+%28C_%7Bx%7D%2CC_%7Bx%7D%5E%7Be%7D%29%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%7D%5CDelta+%28C_%7Bx%7D%2CC_%7Bx%7D%5E%7Be%7D%29%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {E}_{x}&#92;Delta (C_{x},C_{x}^{e})&#92;ge c" class="latex" />, proving the claim. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-126004r4"></a> <b>Exercise</b> 12.4.  </span>Explain how to conclude the proof given the claim.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">12.3   </span> <a id="x1-12700012.3"></a>Notes</h3>
<p style="text-align:justify">The exposition of the trits problem is from <span class="cite">[<a href="#Xviola-gems09">76</a>]</span>.</p>
<p style="text-align:justify">
<h3 class="likesectionHead"><a id="x1-12800012.3"></a>References</h3>
<p style="text-align:justify">
<div class="thebibliography">
<p class="bibitem"><span class="biblabel">   [1]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/focs/AbboudBW15"></a>Amir Abboud, Arturs Backurs, and Virginia&nbsp;Vassilevska Williams. Tight hardness      results for LCS and other sequence similarity measures.  In Venkatesan Guruswami,      editor, IEEE 56th Annual Symposium on Foundations of Computer Science, FOCS      2015, Berkeley, CA, USA, 17-20 October, 2015, pages 59–78. IEEE Computer Society,      2015.</p>
<p class="bibitem"><span class="biblabel">   [2]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAdleman78"></a>Leonard  Adleman.   Two  theorems  on  random  polynomial  time.   In  19th IEEE      Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 75–83. 1978.</p>
<p class="bibitem"><span class="biblabel">   [3]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAjt83"></a>Mikl�s Ajtai.  <img src="https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Sigma &#92;sp {1}&#92;sb {1}" class="latex" />-formulae on finite structures.  Annals of Pure and Applied Logic,      24(1):1–48, 1983.</p>
<p class="bibitem"><span class="biblabel">   [4]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAjtai05"></a>Mikl�s Ajtai. A non-linear time lower bound for boolean branching programs. Theory      of Computing, 1(1):149–176, 2005.</p>
<p class="bibitem"><span class="biblabel">   [5]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAll89"></a>Eric  Allender.   A  note  on  the  power  of  threshold  circuits.   In  30th Symposium      on Foundations of Computer Science, pages 580–584, Research Triangle Park, North      Carolina, 30 October–1 November 1989. IEEE.</p>
<p class="bibitem"><span class="biblabel">   [6]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAllender01"></a>Eric Allender. The division breakthroughs. Bulletin of the EATCS, 74:61–77, 2001.</p>
<p class="bibitem"><span class="biblabel">   [7]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAllenderK10"></a>Eric  Allender  and  Michal  Koucký.     Amplifying  lower  bounds  by  means  of      self-reducibility. J.&nbsp;of the ACM, 57(3), 2010.</p>
<p class="bibitem"><span class="biblabel">   [8]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAGHP92"></a>Noga Alon, Oded Goldreich, Johan H�stad, and Ren� Peralta. Simple constructions      of  almost  <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-wise  independent  random  variables.   Random  Structures  &amp;  Algorithms,      3(3):289–304, 1992.</p>
<p class="bibitem"><span class="biblabel">   [9]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/AngluinV79"></a>Dana Angluin and Leslie&nbsp;G. Valiant. Fast probabilistic algorithms for hamiltonian      circuits and matchings. J. Comput. Syst. Sci., 18(2):155–193, 1979.</p>
<p class="bibitem"><span class="biblabel">  [10]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAroraLuMoSuSz98"></a>Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy.                                                                                                                                                                                          Proof  verification  and  the  hardness  of  approximation  problems.    J.&nbsp;of  the  ACM,      45(3):501–555, May 1998.</p>
<p class="bibitem"><span class="biblabel">  [11]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/BackursI18"></a>Arturs Backurs and Piotr Indyk.  Edit distance cannot be computed in strongly      subquadratic time (unless SETH is false). SIAM J. Comput., 47(3):1087–1097, 2018.</p>
<p class="bibitem"><span class="biblabel">  [12]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBatcher68"></a>Kenneth&nbsp;E. Batcher.  Sorting networks and their applications.  In AFIPS Spring      Joint Computing Conference, volume&nbsp;32, pages 307–314, 1968.</p>
<p class="bibitem"><span class="biblabel">  [13]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBeameCH86"></a>Paul  Beame,  Stephen&nbsp;A.  Cook,  and  H.&nbsp;James  Hoover.   Log  depth  circuits  for      division and related problems. SIAM J. Comput., 15(4):994–1003, 1986.</p>
<p class="bibitem"><span class="biblabel">  [14]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBSSV03"></a>Paul Beame, Michael Saks, Xiaodong Sun, and Erik Vee.   Time-space trade-off      lower  bounds  for  randomized  computation  of  decision  problems.   J.&nbsp;of  the  ACM,      50(2):154–195, 2003.</p>
<p class="bibitem"><span class="biblabel">  [15]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBen-OrC92"></a>Michael Ben-Or and Richard Cleve. Computing algebraic formulas using a constant      number of registers. SIAM J.&nbsp;on Computing, 21(1):54–58, 1992.</p>
<p class="bibitem"><span class="biblabel">  [16]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/cc/BussW15"></a>Samuel&nbsp;R.  Buss  and  Ryan  Williams.   Limits  on  alternation  trading  proofs  for      time-space lower bounds. Comput. Complex., 24(3):533–600, 2015.</p>
<p class="bibitem"><span class="biblabel">  [17]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/stoc/ChenT19"></a>Lijie Chen and Roei Tell. Bootstrapping results for threshold circuits &#8220;just beyond&#8221;      known lower bounds.  In Moses Charikar and Edith Cohen, editors, Proceedings of the      51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, Phoenix,      AZ, USA, June 23-26, 2019, pages 34–41. ACM, 2019.</p>
<p class="bibitem"><span class="biblabel">  [18]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCleve91"></a>Richard  Cleve.    Towards  optimal  simulations  of  formulas  by  bounded-width      programs. Computational Complexity, 1:91–105, 1991.</p>
<p class="bibitem"><span class="biblabel">  [19]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCook73"></a>Stephen&nbsp;A. Cook. A hierarchy for nondeterministic time complexity. J.&nbsp;of Computer      and System Sciences, 7(4):343–353, 1973.</p>
<p class="bibitem"><span class="biblabel">  [20]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Csanky76"></a>L.&nbsp;Csanky.     Fast  parallel  matrix  inversion  algorithms.     SIAM  J.  Comput.,      5(4):618–623, 1976.</p>
<p class="bibitem"><span class="biblabel">  [21]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDodisPT10"></a>Yevgeniy Dodis, Mihai Pǎtraşcu, and Mikkel Thorup. Changing base without losing      space. In 42nd ACM Symp.&nbsp;on the Theory of Computing (STOC), pages 593–602. ACM,      2010.</p>
<p class="bibitem"><span class="biblabel">  [22]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/Fortnow00"></a>Lance  Fortnow.   Time-space  tradeoffs  for  satisfiability.   J.  Comput.  Syst.  Sci.,      60(2):337–353, 2000.</p>
<p class="bibitem"><span class="biblabel">  [23]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jct/FraenkelL81"></a>Aviezri&nbsp;S. Fraenkel and David Lichtenstein. Computing a perfect strategy for n x n      chess requires time exponential in n. J. Comb. Theory, Ser. A, 31(2):199–214, 1981.</p>
<p class="bibitem"><span class="biblabel">  [24]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XFredmanS89"></a>Michael&nbsp;L. Fredman and Michael&nbsp;E. Saks.  The cell probe complexity of dynamic      data structures. In ACM Symp.&nbsp;on the Theory of Computing (STOC), pages 345–354,      1989.</p>
<p class="bibitem"><span class="biblabel">  [25]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGajentaanO95"></a>Anka Gajentaan and Mark&nbsp;H. Overmars. On a class of <img src="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="{O}(n^2)" class="latex" /> problems in computational      geometry. Comput. Geom., 5:165–185, 1995.</p>
<p class="bibitem"><span class="biblabel">  [26]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGalMiltersen07"></a>Anna G�l and Peter&nbsp;Bro Miltersen.  The cell probe complexity of succinct data      structures. Theoretical Computer Science, 379(3):405–417, 2007.</p>
<p class="bibitem"><span class="biblabel">  [27]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGareyJ79"></a>M.&nbsp;R. Garey and David&nbsp;S. Johnson. Computers and Intractability: A Guide to the      Theory of NP-Completeness. W. H. Freeman, 1979.</p>
<p class="bibitem"><span class="biblabel">  [28]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR1549939"></a>K.&nbsp;G�del.   �ber  formal  unentscheidbare  s�tze  der  Principia  Mathematica  und      verwandter systeme I. Monatsh. Math. Phys., 38, 1931.</p>
<p class="bibitem"><span class="biblabel">  [29]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGoldreich08Complexity"></a>Oded Goldreich. Computational Complexity: A Conceptual Perspective. Cambridge      University Press, 2008.</p>
<p class="bibitem"><span class="biblabel">  [30]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGreenlawHR-Limits"></a>Raymond  Greenlaw,  H.&nbsp;James  Hoover,  and  Walter  Ruzzo.   Limits  to  Parallel      Computation: P-Completeness Theory. 02 2001.</p>
<p class="bibitem"><span class="biblabel">  [31]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="X10.4007/annals.2021.193.2.4"></a>David Harvey and Joris van&nbsp;der Hoeven. Integer multiplication in time <img src="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(n&#92;mathrm {log}&#92;, n)" class="latex" />. Annals of      Mathematics, 193(2):563 – 617, 2021.</p>
<p class="bibitem"><span class="biblabel">  [32]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F.&nbsp;C. Hennie.  One-tape, off-line turing machine computations.  Information and      Control, 8(6):553–578, 1965.</p>
<p class="bibitem"><span class="biblabel">  [33]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XHennieS66"></a>Fred  Hennie  and  Richard  Stearns.    Two-tape  simulation  of  multitape  turing      machines. J.&nbsp;of the ACM, 13:533–546, October 1966.</p>
<p class="bibitem"><span class="biblabel">  [34]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jacm/HopcroftPV77"></a>John&nbsp;E. Hopcroft, Wolfgang&nbsp;J. Paul, and Leslie&nbsp;G. Valiant. On time versus space.      J. ACM, 24(2):332–337, 1977.</p>
<p class="bibitem"><span class="biblabel">  [35]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIP99"></a>Russell Impagliazzo and Ramamohan Paturi.   The complexity of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-sat.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 237–, 1999.</p>
<p class="bibitem"><span class="biblabel">  [36]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImpagliazzoPS97"></a>Russell Impagliazzo, Ramamohan Paturi, and Michael&nbsp;E. Saks. Size-depth tradeoffs      for threshold circuits. SIAM J. Comput., 26(3):693–707, 1997.</p>
<p class="bibitem"><span class="biblabel">  [37]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIPZ01"></a>Russell Impagliazzo, Ramamohan Paturi, and Francis Zane.  Which problems have      strongly exponential complexity? J. Computer &amp; Systems Sciences, 63(4):512–530, Dec      2001.</p>
<p class="bibitem"><span class="biblabel">  [38]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImW97"></a>Russell  Impagliazzo  and  Avi  Wigderson.    <img src="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathit {P} = &#92;mathit {BPP}" class="latex" />  if  <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E" class="latex" />  requires  exponential  circuits:      Derandomizing the XOR lemma.  In 29th ACM Symp.&nbsp;on the Theory of Computing      (STOC), pages 220–229. ACM, 1997.</p>
<p class="bibitem"><span class="biblabel">  [39]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKarpLi82"></a>Richard&nbsp;M.  Karp  and  Richard&nbsp;J.  Lipton.    Turing  machines  that  take  advice.      L’Enseignement Math�matique. Revue Internationale. IIe S�rie, 28(3-4):191–209, 1982.</p>
<p class="bibitem"><span class="biblabel">  [40]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi.  On the structure of one-tape nondeterministic turing machine      time hierarchy. Theor. Comput. Sci., 40:175–193, 1985.</p>
<p class="bibitem"><span class="biblabel">  [41]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/toc/Kopparty018"></a>Swastik Kopparty and Srikanth Srinivasan. Certifying polynomials for AC\({}^{\mbox {0}}\)[\(\oplus \)] circuits,      with  applications  to  lower  bounds  and  circuit  compression.   Theory of Computing,      14(1):1–24, 2018.</p>
<p class="bibitem"><span class="biblabel">  [42]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/LarsenWY20"></a>Kasper&nbsp;Green Larsen, Omri Weinstein, and Huacheng Yu. Crossing the logarithmic      barrier for dynamic boolean data structure lower bounds.  SIAM J. Comput., 49(5),      2020.</p>
<p class="bibitem"><span class="biblabel">  [43]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLevin73"></a>Leonid&nbsp;A.  Levin.    Universal  sequential  search  problems.    Problemy  Peredachi      Informatsii, 9(3):115–116, 1973.</p>
<p class="bibitem"><span class="biblabel">  [44]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLundFoKaNi92"></a>Carsten Lund, Lance Fortnow, Howard Karloff, and Noam Nisan. Algebraic methods      for interactive proof systems. J.&nbsp;of the ACM, 39(4):859–868, October 1992.</p>
<p class="bibitem"><span class="biblabel">  [45]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLupanov58"></a>O.&nbsp;B. Lupanov. A method of circuit synthesis. Izv. VUZ Radiofiz., 1:120–140, 1958.</p>
<p class="bibitem"><span class="biblabel">  [46]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMaS87"></a>Wolfgang Maass and Amir Schorr. Speed-up of Turing machines with one work tape      and a two-way input tape. SIAM J.&nbsp;on Computing, 16(1):195–202, 1987.</p>
<p class="bibitem"><span class="biblabel">  [47]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBarrington89"></a>David&nbsp;A.  Mix  Barrington.   Bounded-width  polynomial-size  branching  programs      recognize  exactly  those  languages  in  NC<sup>1</sup>.   J.&nbsp;of  Computer  and  System  Sciences,      38(1):150–164, 1989.</p>
<p class="bibitem"><span class="biblabel">  [48]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNaN93"></a>Joseph Naor and Moni Naor.  Small-bias probability spaces: efficient constructions      and applications. SIAM J.&nbsp;on Computing, 22(4):838–856, 1993.</p>
<p class="bibitem"><span class="biblabel">  [49]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNechiporuk66"></a>E.&nbsp;I. Nechiporuk. A boolean function. Soviet Mathematics-Doklady, 169(4):765–766,      1966.</p>
<p class="bibitem"><span class="biblabel">  [50]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNep70"></a>Valery&nbsp;A. Nepomnjaščiĭ. Rudimentary predicates and Turing calculations. Soviet      Mathematics-Doklady, 11(6):1462–1465, 1970.</p>
<p class="bibitem"><span class="biblabel">  [51]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaNEU-ram2sat-neu-author"></a>NEU. From RAM to SAT. Available at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2012.</p>
<p class="bibitem"><span class="biblabel">  [52]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/PapadimitriouY91"></a>Christos&nbsp;H. Papadimitriou and Mihalis Yannakakis. Optimization, approximation,      and complexity classes. J. Comput. Syst. Sci., 43(3):425–440, 1991.</p>
<p class="bibitem"><span class="biblabel">  [53]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPatrascu08Succincter"></a>Mihai Pǎtraşcu.  Succincter.  In 49th IEEE Symp.&nbsp;on Foundations of Computer      Science (FOCS). IEEE, 2008.</p>
<p class="bibitem"><span class="biblabel">  [54]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPPST83"></a>Wolfgang&nbsp;J. Paul, Nicholas Pippenger, Endre Szemer�di, and William&nbsp;T. Trotter.      On determinism versus non-determinism and related problems (preliminary version). In      IEEE Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 429–438, 1983.</p>
<p class="bibitem"><span class="biblabel">  [55]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPippengerF79"></a>Nicholas Pippenger and Michael&nbsp;J. Fischer. Relations among complexity measures.      J.&nbsp;of the ACM, 26(2):361–381, 1979.</p>
<p class="bibitem"><span class="biblabel">  [56]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XRaz87"></a>Alexander Razborov. Lower bounds on the dimension of schemes of bounded depth      in a complete basis containing the logical addition function.  Akademiya Nauk SSSR.      Matematicheskie Zametki, 41(4):598–607, 1987.  English translation in Mathematical      Notes of the Academy of Sci. of the USSR, 41(4):333-338, 1987.</p>
<p class="bibitem"><span class="biblabel">  [57]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XReingold08"></a>Omer Reingold. Undirected connectivity in log-space. J.&nbsp;of the ACM, 55(4), 2008.</p>
<p class="bibitem"><span class="biblabel">  [58]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Robson84"></a>J.&nbsp;M.  Robson.    N  by  N  checkers  is  exptime  complete.    SIAM  J.  Comput.,      13(2):252–267, 1984.</p>
<p class="bibitem"><span class="biblabel">  [59]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/coco/Santhanam01"></a>Rahul Santhanam.   On separators, segregators and time versus space.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 286–294, 2001.</p>
<p class="bibitem"><span class="biblabel">                                                                                                                                                                                      [60]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSAVITCH1970177"></a>Walter&nbsp;J. Savitch.  Relationships between nondeterministic and deterministic tape      complexities. Journal of Computer and System Sciences, 4(2):177–192, 1970.</p>
<p class="bibitem"><span class="biblabel">  [61]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Schonhage80"></a>Arnold Sch�nhage. Storage modification machines. SIAM J. Comput., 9(3):490–508,      1980.</p>
<p class="bibitem"><span class="biblabel">  [62]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XShamir92"></a>Adi Shamir. IP = PSPACE. J.&nbsp;of the ACM, 39(4):869–877, October 1992.</p>
<p class="bibitem"><span class="biblabel">  [63]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR29860"></a>Claude&nbsp;E. Shannon. The synthesis of two-terminal switching circuits. Bell System      Tech. J., 28:59–98, 1949.</p>
<p class="bibitem"><span class="biblabel">  [64]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSho90"></a>Victor Shoup. New algorithms for finding irreducible polynomials over finite fields.      Mathematics of Computation, 54(189):435–447, 1990.</p>
<p class="bibitem"><span class="biblabel">  [65]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSiegel04"></a>Alan Siegel. On universal classes of extremely random constant-time hash functions.      SIAM J.&nbsp;on Computing, 33(3):505–543, 2004.</p>
<p class="bibitem"><span class="biblabel">  [66]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSip83b"></a>Michael Sipser. A complexity theoretic approach to randomness. In ACM Symp.&nbsp;on      the Theory of Computing (STOC), pages 330–335, 1983.</p>
<p class="bibitem"><span class="biblabel">  [67]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSmo87"></a>Roman Smolensky.  Algebraic methods in the theory of lower bounds for Boolean      circuit complexity.  In 19th ACM Symp.&nbsp;on the Theory of Computing (STOC), pages      77–82. ACM, 1987.</p>
<p class="bibitem"><span class="biblabel">  [68]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert&nbsp;R. Meyer.  Cosmological lower bound on the circuit      complexity of a small problem in logic. J. ACM, 49(6):753–784, 2002.</p>
<p class="bibitem"><span class="biblabel">  [69]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XToda91"></a>Seinosuke Toda.   PP is as hard as the polynomial-time hierarchy.   SIAM J.&nbsp;on      Computing, 20(5):865–877, 1991.</p>
<p class="bibitem"><span class="biblabel">  [70]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/x/Turing37"></a>Alan&nbsp;M.   Turing.      On   computable   numbers,   with   an   application   to   the      entscheidungsproblem. Proc. London Math. Soc., s2-42(1):230–265, 1937.</p>
<p class="bibitem"><span class="biblabel">  [71]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XVal77"></a>Leslie&nbsp;G.  Valiant.   Graph-theoretic  arguments  in  low-level  complexity.   In  6th      Symposium on Mathematical Foundations of Computer Science, volume&nbsp;53 of Lecture      Notes in Computer Science, pages 162–176. Springer, 1977.</p>
<p class="bibitem"><span class="biblabel">  [72]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/ValiantV86"></a>Leslie&nbsp;G. Valiant and Vijay&nbsp;V. Vazirani. NP is as easy as detecting unique solutions.      Theor. Comput. Sci., 47(3):85–93, 1986.</p>
<p class="bibitem"><span class="biblabel">  [73]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMelkebeek06"></a>Dieter  van  Melkebeek.   A  survey  of  lower  bounds  for  satisfiability  and  related      problems. Foundations and Trends in Theoretical Computer Science, 2(3):197–303, 2006.</p>
<p class="bibitem"><span class="biblabel">  [74]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/MelkebeekR05"></a>Dieter van Melkebeek and Ran Raz.  A time lower bound for satisfiability.  Theor.      Comput. Sci., 348(2-3):311–320, 2005.</p>
<p class="bibitem"><span class="biblabel">  [75]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/Vinodchandran05"></a>N.&nbsp;V. Vinodchandran.  A note on the circuit complexity of PP.  Theor. Comput.      Sci., 347(1-2):415–418, 2005.</p>
<p class="bibitem"><span class="biblabel">  [76]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-gems09"></a>Emanuele Viola.  Gems of theoretical computer science.  Lecture notes of the class      taught           at           Northeastern           University.           Available           at      <a href="http://www.ccs.neu.edu/home/viola/classes/gems-08/index.html" rel="nofollow">http://www.ccs.neu.edu/home/viola/classes/gems-08/index.html</a>, 2009.</p>
<p class="bibitem"><span class="biblabel">  [77]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaBPvsE"></a>Emanuele Viola.  On approximate majority and probabilistic time.  Computational      Complexity, 18(3):337–375, 2009.</p>
<p class="bibitem"><span class="biblabel">  [78]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-FTTCS09"></a>Emanuele Viola. On the power of small-depth computation. Foundations and Trends      in Theoretical Computer Science, 5(1):1–72, 2009.</p>
<p class="bibitem"><span class="biblabel">  [79]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViola-xxx"></a>Emanuele Viola.  Reducing 3XOR to listing triangles, an exposition.  Available at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2011.</p>
<p class="bibitem"><span class="biblabel">  [80]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-triz"></a>Emanuele Viola. Bit-probe lower bounds for succinct data structures. SIAM J.&nbsp;on      Computing, 41(6):1593–1604, 2012.</p>
<p class="bibitem"><span class="biblabel">  [81]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-datastructurelb-implies-cclb"></a>Emanuele Viola.  Lower bounds for data structures with space close to maximum      imply  circuit  lower  bounds.    Theory  of  Computing,  15:1–9,  2019.    Available  at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>.</p>
<p class="bibitem"><span class="biblabel">  [82]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-tm"></a>Emanuele  Viola.   Pseudorandom  bits  and  lower  bounds  for  randomized  turing      machines. Theory of Computing, 18(10):1–12, 2022.</p>
</div>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-14T13:48:09Z">Sunday, May 14 2023, 13:48</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/05/14/two-ph-d-students-at-kth-royal-institute-of-technology-apply-by-june-1-2023/'>Two Ph.D. Students at KTH Royal Institute of Technology (apply by June 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          KTH Royal Institute for Technology is hiring for two Ph.D. students in algorithms and data analysis, with a focus on graph algorithms. The Ph.D. students will work under the supervision of assistant professor Stefan Neumann. These are two full positions (100% employment) with opportunities for research visits abroad. Website: www.kth.se/en/om/work-at-kth/lediga-jobb/what:job/jobID:625561/where:4/ Email: neum@kth.se
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>KTH Royal Institute for Technology is hiring for two Ph.D. students in algorithms and data analysis, with a focus on graph algorithms. The Ph.D. students will work under the supervision of assistant professor Stefan Neumann.</p>
<p>These are two full positions (100% employment) with opportunities for research visits abroad.</p>
<p>Website: <a href="https://www.kth.se/en/om/work-at-kth/lediga-jobb/what:job/jobID:625561/where:4/">https://www.kth.se/en/om/work-at-kth/lediga-jobb/what:job/jobID:625561/where:4/</a><br />
Email: neum@kth.se</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-14T13:17:45Z">Sunday, May 14 2023, 13:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/071'>TR23-071 |  Sampling and Certifying Symmetric Functions | 

	Artur Riazanov, 

	Yuval Filmus, 

	Dmitry Sokolov, 

	Itai Leigh</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A circuit $\mathcal{C}$ samples a distribution $\mathbf{X}$ with an error $\epsilon$ if the statistical distance between the output of $\mathcal{C}$ on the uniform input and $\mathbf{X}$ is $\epsilon$. We study the hardness of sampling a uniform distribution over the set of $n$-bit strings of Hamming weight $k$ denoted by $\mathbf{U}^n_k$ for decision forests, i.e. every output bit is computed as a decision tree of the inputs. For every $k$ there is an $O(\log n)$-depth decision forest sampling $\mathbf{U}^n_k$ with an inverse-polynomial error [Viola 2012, Czumaj 2015]. We show that for every $\epsilon &gt; 0$ there exists $\tau$ such that for decision depth $\tau \log (n/k) / \log \log (n/k)$, the error for sampling $\mathbf{U}_k^n$ is at least $1-\epsilon$. Our result is based on the recent robust sunflower lemma [Alweiss, Lovett, Wu, Zhang 2021, Rao 2019].
  Our second result is about matching a set of $n$-bit strings with the image of a $d$-local circuit, i.e. such that each output bit depends on at most $d$ input bits. We study the set of all $n$-bit strings whose Hamming weight is at least $n/2$. We improve the previously known locality lower bound from $\Omega(\log^* n)$ [Beyersdorff, Datta, Krebs, Mahajan, Scharfenberger-Fabian, Sreenivasaiah, Thomas and Vollmer, 2013] to $\Omega(\sqrt{\log n})$, leaving only a quartic gap from the best upper bound of $O(\log^2 n)$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          A circuit $\mathcal{C}$ samples a distribution $\mathbf{X}$ with an error $\epsilon$ if the statistical distance between the output of $\mathcal{C}$ on the uniform input and $\mathbf{X}$ is $\epsilon$. We study the hardness of sampling a uniform distribution over the set of $n$-bit strings of Hamming weight $k$ denoted by $\mathbf{U}^n_k$ for decision forests, i.e. every output bit is computed as a decision tree of the inputs. For every $k$ there is an $O(\log n)$-depth decision forest sampling $\mathbf{U}^n_k$ with an inverse-polynomial error [Viola 2012, Czumaj 2015]. We show that for every $\epsilon &gt; 0$ there exists $\tau$ such that for decision depth $\tau \log (n/k) / \log \log (n/k)$, the error for sampling $\mathbf{U}_k^n$ is at least $1-\epsilon$. Our result is based on the recent robust sunflower lemma [Alweiss, Lovett, Wu, Zhang 2021, Rao 2019].
  Our second result is about matching a set of $n$-bit strings with the image of a $d$-local circuit, i.e. such that each output bit depends on at most $d$ input bits. We study the set of all $n$-bit strings whose Hamming weight is at least $n/2$. We improve the previously known locality lower bound from $\Omega(\log^* n)$ [Beyersdorff, Datta, Krebs, Mahajan, Scharfenberger-Fabian, Sreenivasaiah, Thomas and Vollmer, 2013] to $\Omega(\sqrt{\log n})$, leaving only a quartic gap from the best upper bound of $O(\log^2 n)$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-14T11:04:25Z">Sunday, May 14 2023, 11:04</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://minorfree.github.io/hopset-adv/'>Amazing Recent Advances on Shotcut Set and The Likes</a></h3>
        <p class='tr-article-feed'>from <a href='https://minorfree.github.io'>Hung Le</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Merav Parter gave a talk at UMass theory seminar last week titled “Reachability Shortcuts: New Bounds and Algorithms”. In the talk, Merav summarized recent developments in shortcut sets and related concepts. It was amazing to see all the results, and I cannot resist the attempt to share my take here in this blog post. 1. Shortcut set: what is it? A \(d\)-shortcut set of a directed graph \(G=(V,E)\) is a set of directed edges \(E_H\) such that (i) the graph \(H = (V,E\cup E_H)\) has the same transitive closure as \(G\) and (ii) for every \(u\not=v\in V\), if \(v\) is reachable from \(u\), then there is directed \(u\)-to-\(v\) path of at most \(d\) edges (a.k.a. hops). Figure: Adding two shortcuts (the red dashed edges) reduces the hop distance from \(u\) to \(v\) to 4. For a shortcut set of linear size, DAG is the most difficult instance: one can shortcut any strongly connected graph to diameter \(2\) by \(n-1\) edges. The shortcut set problem was introduced by Thorup. The main goal is to understand the trade-off between the hop diameter \(d\) and the size of the shortcut set \(E_H\). The most well-studied regime is fixing \(\lvert E_H\rvert = \tilde{O}(n)\), and then minimizing \(d\). (Here, \(n\) is the number of vertices.) We will call this special regime the shortcut set problem.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><a href="http://www.weizmann.ac.il/math/parter/home">Merav Parter</a> gave a talk at UMass theory seminar last week titled “Reachability Shortcuts: New Bounds and Algorithms”. In the talk, Merav summarized recent developments in shortcut sets and related concepts. It was amazing to see all the results, and I cannot resist the attempt to share my take here in this blog post.</p>

<h1 id="1-shortcut-set-what-is-it">1. Shortcut set: what is it?</h1>

<p>A \(d\)-shortcut set of a <em>directed graph</em> \(G=(V,E)\) is a set of directed edges \(E_H\) such that (i) the graph \(H = (V,E\cup E_H)\) has the same transitive closure as \(G\) and (ii) for every \(u\not=v\in V\), if \(v\) is reachable from \(u\), then there is directed \(u\)-to-\(v\) path of at most \(d\) edges (a.k.a. hops).</p>

<p><img src="/assets/figs/shortcut-set.svg" alt="" /></p>

<p><em>Figure:  Adding two shortcuts (the red dashed edges) reduces the hop distance from \(u\) to \(v\) to 4. For a shortcut set of linear size, DAG is the most difficult instance: one can shortcut any strongly connected graph to diameter \(2\) by \(n-1\) edges.</em></p>

<p>The shortcut set problem was introduced by <a href="https://link.springer.com/chapter/10.1007/3-540-56402-0_48">Thorup</a>. The main goal is to understand the trade-off between the hop diameter \(d\) and the size of the shortcut set \(E_H\). The most well-studied regime is fixing \(\lvert E_H\rvert = \tilde{O}(n)\), and then minimizing \(d\). (Here, \(n\) is the number of vertices.) We will call this special regime <em>the shortcut set problem</em>.</p>

<p>For the shortcut set problem, a folklore sampling gives \(d = O(\sqrt{n})\): sample each vertex with probability \(\tilde{O}(1/\sqrt{n})\) to get a set \(S\), and add all (permissible) directed edges between vertices in \(S\). The key insight for bounding the diameter is: For any shortest path \(\pi_G(u,v)\) from \(u\) to \(v\) with at least \(2\sqrt{n}\) edges,  \(S\) will likely hit both the prefix and suffix of length \(\sqrt{n}\) of \(\pi_G(u,v)\). (This algorithm is attributed to <a href="https://dl.acm.org/doi/10.1145/97444.97686">Ullman and Yannakakis</a>.) A long-standing open problem is:</p>

<hr />
<p><strong>Question 1</strong>: Is diameter bound \(\sqrt{n}\) optimal for shortcut sets of nearly linear size?</p>

<hr />

<p>The answer is no due to the <a href="https://arxiv.org/pdf/2111.13240.pdf">recent breakthrough</a> by Kogan and Parter: using  \(\tilde{O}(n)\) shorcuts, they reduced the diameter down to \(n^{1/3}\). Their result deservingly won the best paper award at SODA 22. A key conceptual contribution of their work is a shift in perspective: shortcutting by connecting vertices to paths of length roughly \(n^{1/3}\), instead of only making vertex-to-vertex connections as the folklore sampling. Find this intriguing? Read <a href="https://arxiv.org/pdf/2111.13240.pdf">the paper</a> or watch <a href="https://www.youtube.com/watch?v=qaY14SnLdMM">Merav’s talk</a> or both. The paper has a bunch of other interesting results.</p>

<p>At this point, you might wonder: how far could one go about reducing the diameter? Thorup <a href="https://link.springer.com/chapter/10.1007/3-540-56402-0_48">conjectured</a> that the diameter could be reduced all the way down to \(\mathrm{poly}(\log(n))\) with a nearly linear number of shortcuts. This conjecture was disproved by <a href="https://dl.acm.org/doi/pdf/10.5555/644108.644216">Hesse</a>, who was a graduate student at UMass Amherst at the time with our <a href="https://www.mathgenealogy.org/id.php?id=30442">Neil Immerman</a> :). Hesse constructed a directed graph with \(m = \Theta(n^{19/17})\) edges such that one has to use \(\Omega(mn^{1/17})\) shortcuts to reduce the diameter to below \(\Theta(n^{1/17})\). This lower bound <a href="https://arxiv.org/abs/1802.06271">has been</a> <a href="https://arxiv.org/abs/2110.15809">improved</a> <a href="https://arxiv.org/pdf/2304.02193.pdf">further</a>. Notably, <a href="https://arxiv.org/pdf/2304.02193.pdf">Bodwin and Hoppenworth</a> recently obtained a lower bound of \(\Omega(n^{1/4})\) on the diameter, which is very close to the upper bound of \(O(n^{1/3})\) by Kogan and Parter. This result leaves another fascinating open problem:</p>

<hr />
<p><strong>Open Problem</strong>: Closing the gap \(O(n^{1/3})\) vs. \(\Omega(n^{1/4})\) on the diameter for shortcut sets of nearly linear size.</p>

<hr />

<h1 id="2-approximate-hopsets">2. (Approximate) hopsets</h1>

<p>Hopset is very similar to the shortcut set but applied to weighted graphs instead. More formally, a \(d\)-hopset set of a <em>directed, weighted graph</em>  \(G=(V,E)\) is a set of directed, <em>weighted</em> edges \(E_H\) such that (i) the graph \(H = (V,E\cup E_H)\) has the same distance metric as \(G\) and (ii) for every \(u\not=v\in V\),  there is a shortest \(u\)-to-\(v\) path of at most \(d\) edges in \(H = (V,E\cup E_H)\).</p>

<p>Clearly, the hopset problem is at least as hard as the shortcut set problem: any hopset is a shortcut set with the same diameter bound.</p>

<p>A related notion is <em>approximate hopset</em>, in which we are given an additional parameter \(\epsilon \in (0,1)\), and for every \(u,v\), we would like to have a \((1+\epsilon)\)-approximate \(u\)-to-\(v\) path of at most \(d\) edges. We allow \(d\) to depend on \(\epsilon\)—think of \(\epsilon\) as a small constant.</p>

<p>One could check that the folklore sampling also works for hopset (and hence for approximate hopset as well): by adding \(\tilde{O}(n \log n)\) edges, one could reduce the diameter bound to \(\sqrt{n}\). The same question arises: Is the  \(\sqrt{n}\) bound on the diameter optimal for hopsets and approximate hopsets of nearly linear size?</p>

<p>For the approximate hopset, the same paper by Kogan and Parter provided a no answer: They constructed a nearly linear hopset with a diameter bound of \(n^{2/5}\). In follow-up work, <a href="https://arxiv.org/abs/2207.04507">Bernstein and Wein</a> improved the diameter to \(n^{1/3}\), matching the known bound for shortcut set; <a href="https://video.cs.utexas.edu/node/428">watch the talk here</a>.</p>

<p>How about the (exact) hopset? One might expect that the diameter bound should also be improved to  \(n^{1/3}\). <a href="https://arxiv.org/pdf/2304.02193.pdf">Bodwin and Hoppenworth</a> recently showed that \(\sqrt{n}\) is the best one could do (up to some polylog). I personally find this result very surprising. How do they achieve their lower bound? Read their paper; the exposition of the ideas in the paper is so well written that any attempt to summarize better would be in vain.</p>

<p>Somehow, the exact hopset is strictly harder than the approximate hopset and the shortcut set. Could approximate hopset be strictly harder than shortcut set? Bernstein and Wein provided state-of-the-art bounds for approximate hopsets, matching those of shortcut sets. As far as I understand, their proof does not provide a black-box reduction. Is such a reduction possible? I am curious to know the answer.</p><p class="authors">By Hung Le</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-14T00:00:00Z">Sunday, May 14 2023, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, May 13
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/05/13/coloring-plane-generic.html'>Coloring the plane for generic norms</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Noga Alon recently stopped by my department earlier this month to give two talks. During his visit, he pointed me to some interesting recent work he had done on coloring the plane, buried in the discussion at the end of his preprint “Unit and distinct distances in typical norms” (arXiv:2302.09058, with Matija Bucić and Lisa Sauermann). Recall that the still-unsolved Hadwiger–Nelson problem asks how many colors are needed to color the points of the plane so that no two points at distance one from each other have the same color. The figure below shows a 7-coloring in the pattern of a hexagonal tiling, with this property, so at most seven colors are needed. The black unit distance graph outlined in the same figure, the Moser spindle, requires four colors, but by now much larger and more complicated unit distance graphs are known that force the number of colors to be at least five.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Noga Alon recently stopped by my department earlier this month to give two talks. During his visit, he pointed me to some interesting recent work he had done on coloring the plane, buried in the discussion at the end of his preprint “Unit and distinct distances in typical norms” (<a href="https://arxiv.org/abs/2302.09058">arXiv:2302.09058</a>, with Matija Bucić and Lisa Sauermann). Recall that the still-unsolved <a href="https://en.wikipedia.org/wiki/Hadwiger%E2%80%93Nelson_problem">Hadwiger–Nelson problem</a> asks how many colors are needed to color the points of the plane so that no two points at distance one from each other have the same color. The figure below shows a 7-coloring in the pattern of a hexagonal tiling, with this property, so at most seven colors are needed. The black unit distance graph outlined in the same figure, the <a href="/blog/2011/11/29/moser-spindle.html">Moser spindle</a>, requires four colors, but by now much larger and more complicated unit distance graphs are known that force the number of colors to be at least five.</p>

<p style="text-align:center"><img src="/blog/assets/2023/Hadwiger-Nelson.svg" alt="Seven-coloring of the plane with superimposed Moser spindle" /></p>

<p>The preprint asks, what if we use a different distance function for the plane, defined by a non-Euclidean <a href="https://en.wikipedia.org/wiki/Norm_(mathematics)">norm</a>? The answer turns out to be very different: for most such distances, the optimal number of colors is four.</p>

<p>Any norm in the \(d\)-dimensional space \(\mathbb{R}^d\) can be described by its unit ball, a centrally symmetric convex body, and any centrally symmetric convex body defines a norm. The distance between two points is measured by the factor you would need to scale the body so that if you center it at one of the two points it touches the other one. A unit vector, for a distance defined in this way, is just a point on the boundary of the unit ball. For Euclidean distance in the plane the unit ball is a circular disk, and it is also common in computational geometry to consider norms whose unit ball is a regular polygon (with evenly many sides), such as a square or hexagon. But infinitely many other less-regular shapes are also possible, each defining its own distance. Because these distances are different from each other, the number of colors they need may also be different, and may be easier to compute. For instance, for a square unit ball, you can use a square tiling instead of the hexagonal one and color the tiling with only four colors (being careful of how to handle boundary points) so that no two points at unit distance have the same color:</p>

<p style="text-align:center"><img src="/blog/assets/2023/plaid.svg" alt="Four-coloring of the plane for a square norm" /></p>

<p>Alon, Bucić, and Sauermann approach this problem by treating \(\mathbb{R}^d\) as an infinite-dimensional vector space over the rational numbers rather than a \(d\)-dimensional vector space over the real numbers, and asking questions about which subsets of the unit vectors are rationally independent (treating a unit vector and its negation as being the same for this purpose). That means that there is no way to produce one of the vectors as a weighted combination of other vectors in the same set, with rational numbers as the weights. This is much in the same spirit as <a href="/blog/2022/04/03/dissection-into-rectangles.html">using Dehn invariants to study polygonal dissections</a> where again, it is rational dependence more than real dependence that is central.</p>

<p>For a polygonal distance, any two unit vectors on the same side of a polygon have infinitely many rational combinations that are also unit vectors. If \(u\) and \(v\) are unit vectors on one side of a convex polygon, and \(p\) is any rational number with \(0\lt p\lt 1\), then \(pu+(1-p)v\) is a rational combination that lies between \(u\) and \(v\) on the same side of the polygon. Because it is on the boundary of the polygon, it is a unit vector. For the Euclidean distance, we have to be more careful, but there still can be infinitely many rational combinations that are also unit vectors. For instance, if \(x=(1,0)\) and \(y=(0,1)\) are the axis-parallel unit vectors of a Cartesian coordinate system, their rational combination \(\tfrac12 x + \tfrac12 y = (\tfrac12,\tfrac12)\) is not a unit vector for Euclidean distance (its length is \(1/\sqrt2\)), and the unit vector in the same direction, \((1/\sqrt2,1/\sqrt2)\), is not a rational combination of \(x\) and \(y\). However, if \(a^2+b^2=c^2\) is any integer Pythagorean triple, the vector \(\tfrac{a}{c}x+\tfrac{b}{c}y=(\tfrac{a}{c},\tfrac{b}{c})\) is both a unit vector and a rational combination of \(x\) and \(y\). Because there are infinitely many Pythagorean triples, \(x\) and \(y\) have infinitely many unit-vector rational combinations.</p>

<p>What Alon, Bucić, and Sauermann show is that for “most” norms in a certain technical sense (a <a href="https://en.wikipedia.org/wiki/Comeager">comeager</a> set of norms in a certain topological space of norms), rational combinations are much less common. More precisely, they prove the following statements, which are equivalent to each other by standard results in the theory of <a href="https://en.wikipedia.org/wiki/Matroid_partitioning">matroid partitions</a>:</p>

<ul>
  <li>
    <p>Every finite set \(U\) of unit vectors, for a \(d\)-dimensional generic norm, has rational rank \(\ge \vert U\vert/d\)</p>
  </li>
  <li>
    <p>If \(U\) is a finite set of unit vectors for a \(d\)-dimensional generic norm, then every subset of \(k\) vectors from \(U\) has at most \(kd\) rational combinations in \(U\) (including themselves, but not counting negations as different).</p>
  </li>
  <li>
    <p>Every finite set of unit vectors for a \(d\)-dimensional generic norm can be partitioned into at most \(d\) subsets, so that the vectors within each subset are rationally independent.</p>
  </li>
</ul>

<p>If we give each of these \(d\) subsets a color, and use these colors for the edges of any finite unit distance graph, then every two parallel edges will have the same color, and every monochromatic cycle will have edges that can be paired into parallel edges in opposite directions from each other (like the edges of a square or regular hexagon). This means that the subgraph of edges of any single color will be bipartite. We can color each of these subgraphs with two colors, and combine the subgraphs to get \(2^d\) colors for the whole unit distance graph. Let’s see how such a coloring might look for the Moser spindle:</p>

<p style="text-align:center"><img src="/blog/assets/2023/spindle-color.svg" alt="Four-coloring the Moser spindle by partitioning it into bipartite subgraphs" /></p>

<p>In this example, the blue-edge subgraph has two cycles, both rhombi. Each edge of a rhombus can be paired with another parallel edge; if you travel around the rhombus you will follow these two edges in opposite directions. The yellow-edge subgraph has no cycles at all. Combining the 2-colorings of the two subgraphs gives us a 4-coloring of the whole Moser spindle.</p>

<p>This method 4-colors every finite unit distance graph, for a generic norm, but not the whole plane at once. To color the whole plane, the <a href="https://en.wikipedia.org/wiki/De_Bruijn%E2%80%93Erd%C5%91s_theorem_(graph_theory)">De Bruijn–Erdős theorem</a> can be used. This is a theorem that, whenever all finite subgraphs of an infinite graph can be colored with a certain finite number of colors, the whole graph can be colored with the same number of colors. It’s possible to construct a copy of the Moser spindle as a unit distance graph for any norm, by using the intermediate value theorem to find equilateral triangles supported by any edge and then rotating one pair of triangles with respect to another until getting another unit distance. Therefore, four colors is optimal. But the 4-coloring you get is a nasty set-theoretic thing, impossible to visualize, unlike the nice tiling-based 7-coloring of the Euclidean plane.</p>

<p>Noga left me with some related but unsolved questions: Can we find an explicit example of a norm with this few-rational-combinations property? It would need to be strictly convex (the boundaries of its balls could not include any line segments); can we find an explicit example of a strictly-convex norm requiring only four colors? Is it possible for such a norm to have a simple finite description? And what about smooth norms, or \(L^p\)-norms (possibly for non-integer \(p\))?</p>

<p>(<a href="https://mathstodon.xyz/@11011110/110364160343375481">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-13T17:09:00Z">Saturday, May 13 2023, 17:09</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, May 12
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/05/12/postdoc-at-cambridge-apply-by-july-1-2023/'>Postdoc at Cambridge (apply by July 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A postdoc position in Quantum Algorithms and Complexity at the University of Cambridge, under the supervision of Sergii Strelchuk and Tom Gur, is available. Website: www.maths.cam.ac.uk/person/ss870, www.dcs.warwick.ac.uk/~tomgur/ Email: ss870@cam.ac.uk, tom.gur@warwick.ac.uk
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>A postdoc position in Quantum Algorithms and Complexity at the University of Cambridge, under the supervision of Sergii Strelchuk and Tom Gur, is available.</p>
<p>Website: <a href="https://www.maths.cam.ac.uk/person/ss870">https://www.maths.cam.ac.uk/person/ss870</a>, <a href="https://www.dcs.warwick.ac.uk/~tomgur/">https://www.dcs.warwick.ac.uk/~tomgur/</a><br />
Email: ss870@cam.ac.uk, tom.gur@warwick.ac.uk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T10:03:39Z">Friday, May 12 2023, 10:03</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06821'>Constant-depth circuits vs. monotone circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bruno P. Cavalar, Igor C. Oliveira</p><p>We establish new separations between the power of monotone and general
(non-monotone) Boolean circuits:
</p>
<p>- For every $k \geq 1$, there is a monotone function in ${\sf AC^0}$ that
requires monotone circuits of depth $\Omega(\log^k n)$. This significantly
extends a classical result of Okol'nishnikova (1982) and Ajtai and Gurevich
(1987). In addition, our separation holds for a monotone graph property, which
was unknown even in the context of ${\sf AC^0}$ versus ${\sf mAC^0}$.
</p>
<p>- For every $k \geq 1$, there is a monotone function in ${\sf AC^0}[\oplus]$
that requires monotone circuits of size $\exp(\Omega(\log^k n))$. This makes
progress towards a question posed by Grigni and Sipser (1992).
</p>
<p>These results show that constant-depth circuits can be more efficient than
monotone circuits when computing monotone functions.
</p>
<p>In the opposite direction, we observe that non-trivial simulations are
possible in the absence of parity gates: every monotone function computed by an
${\sf AC^0}$ circuit of size $s$ and depth $d$ can be computed by a monotone
circuit of size $2^{n - n/O(\log s)^{d-1}}$. We show that the existence of
significantly faster monotone simulations would lead to breakthrough circuit
lower bounds. In particular, if every monotone function in ${\sf AC^0}$ admits
a polynomial size monotone circuit, then ${\sf NC^2}$ is not contained in ${\sf
NC^1}$ .
</p>
<p>Finally, we revisit our separation result against monotone circuit size and
investigate the limits of our approach, which is based on a monotone lower
bound for constraint satisfaction problems established by G\"o\"os et al.
(2019) via lifting techniques. Adapting results of Schaefer (1978) and Allender
et al. (2009), we obtain an unconditional classification of the monotone
circuit complexity of Boolean-valued CSPs via their polymorphisms. This result
and the consequences we derive from it might be of independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cavalar_B/0/1/0/all/0/1">Bruno P. Cavalar</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_I/0/1/0/all/0/1">Igor C. Oliveira</a></p><p>We establish new separations between the power of monotone and general
(non-monotone) Boolean circuits:
</p>
<p>- For every $k \geq 1$, there is a monotone function in ${\sf AC^0}$ that
requires monotone circuits of depth $\Omega(\log^k n)$. This significantly
extends a classical result of Okol'nishnikova (1982) and Ajtai and Gurevich
(1987). In addition, our separation holds for a monotone graph property, which
was unknown even in the context of ${\sf AC^0}$ versus ${\sf mAC^0}$.
</p>
<p>- For every $k \geq 1$, there is a monotone function in ${\sf AC^0}[\oplus]$
that requires monotone circuits of size $\exp(\Omega(\log^k n))$. This makes
progress towards a question posed by Grigni and Sipser (1992).
</p>
<p>These results show that constant-depth circuits can be more efficient than
monotone circuits when computing monotone functions.
</p>
<p>In the opposite direction, we observe that non-trivial simulations are
possible in the absence of parity gates: every monotone function computed by an
${\sf AC^0}$ circuit of size $s$ and depth $d$ can be computed by a monotone
circuit of size $2^{n - n/O(\log s)^{d-1}}$. We show that the existence of
significantly faster monotone simulations would lead to breakthrough circuit
lower bounds. In particular, if every monotone function in ${\sf AC^0}$ admits
a polynomial size monotone circuit, then ${\sf NC^2}$ is not contained in ${\sf
NC^1}$ .
</p>
<p>Finally, we revisit our separation result against monotone circuit size and
investigate the limits of our approach, which is based on a monotone lower
bound for constraint satisfaction problems established by G\"o\"os et al.
(2019) via lifting techniques. Adapting results of Schaefer (1978) and Allender
et al. (2009), we obtain an unconditional classification of the monotone
circuit complexity of Boolean-valued CSPs via their polymorphisms. This result
and the consequences we derive from it might be of independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06452'>A Near-Optimal Deterministic Distributed Synchronizer</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mohsen Ghaffari, Anton Trygub</p><p>We provide the first deterministic distributed synchronizer with near-optimal
time complexity and message complexity overheads. Concretely, given any
distributed algorithm $\mathcal{A}$ that has time complexity $T$ and message
complexity $M$ in the synchronous message-passing model (subject to some care
in defining the model), the synchronizer provides a distributed algorithm
$\mathcal{A}'$ that runs in the asynchronous message-passing model with time
complexity $T \cdot poly(\log n)$ and message complexity $(M+m)\cdot poly(\log
n)$. Here, $n$ and $m$ denote the number of nodes and edges in the network,
respectively. The synchronizer is deterministic in the sense that if algorithm
$\mathcal{A}$ is deterministic, then so is algorithm $\mathcal{A}'$.
Previously, only a randomized synchronizer with near-optimal overheads was
known by seminal results of Awerbuch, Patt-Shamir, Peleg, and Saks [STOC 1992]
and Awerbuch and Peleg [FOCS 1990]. We also point out and fix some inaccuracies
in these prior works.
</p>
<p>As concrete applications of our synchronizer, we resolve some longstanding
and fundamental open problems in distributed algorithms: we get the first
asynchronous deterministic distributed algorithms with near-optimal time and
message complexities for leader election, breadth-first search tree, and
minimum spanning tree computations: these all have message complexity
$\tilde{O}(m)$ message complexity. The former two have $\tilde{O}(D)$ time
complexity, where $D$ denotes the network diameter, and the latter has
$\tilde{O}(D+\sqrt{n})$ time complexity. All these bounds are optimal up to
logarithmic factors. Previously all such near-optimal algorithms were either
restricted to the synchronous setting or required randomization.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Trygub_A/0/1/0/all/0/1">Anton Trygub</a></p><p>We provide the first deterministic distributed synchronizer with near-optimal
time complexity and message complexity overheads. Concretely, given any
distributed algorithm $\mathcal{A}$ that has time complexity $T$ and message
complexity $M$ in the synchronous message-passing model (subject to some care
in defining the model), the synchronizer provides a distributed algorithm
$\mathcal{A}'$ that runs in the asynchronous message-passing model with time
complexity $T \cdot poly(\log n)$ and message complexity $(M+m)\cdot poly(\log
n)$. Here, $n$ and $m$ denote the number of nodes and edges in the network,
respectively. The synchronizer is deterministic in the sense that if algorithm
$\mathcal{A}$ is deterministic, then so is algorithm $\mathcal{A}'$.
Previously, only a randomized synchronizer with near-optimal overheads was
known by seminal results of Awerbuch, Patt-Shamir, Peleg, and Saks [STOC 1992]
and Awerbuch and Peleg [FOCS 1990]. We also point out and fix some inaccuracies
in these prior works.
</p>
<p>As concrete applications of our synchronizer, we resolve some longstanding
and fundamental open problems in distributed algorithms: we get the first
asynchronous deterministic distributed algorithms with near-optimal time and
message complexities for leader election, breadth-first search tree, and
minimum spanning tree computations: these all have message complexity
$\tilde{O}(m)$ message complexity. The former two have $\tilde{O}(D)$ time
complexity, where $D$ denotes the network diameter, and the latter has
$\tilde{O}(D+\sqrt{n})$ time complexity. All these bounds are optimal up to
logarithmic factors. Previously all such near-optimal algorithms were either
restricted to the synchronous setting or required randomization.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06541'>Spectral Clustering on Large Datasets: When Does it Work? Theory from Continuous Clustering and Density Cheeger-Buser</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Timothy Chu, Gary Miller, Noel Walkington</p><p>Spectral clustering is one of the most popular clustering algorithms that has
stood the test of time. It is simple to describe, can be implemented using
standard linear algebra, and often finds better clusters than traditional
clustering algorithms like $k$-means and $k$-centers. The foundational
algorithm for two-way spectral clustering, by Shi and Malik, creates a
geometric graph from data and finds a spectral cut of the graph.
</p>
<p>In modern machine learning, many data sets are modeled as a large number of
points drawn from a probability density function. Little is known about when
spectral clustering works in this setting -- and when it doesn't. Past
researchers justified spectral clustering by appealing to the graph Cheeger
inequality (which states that the spectral cut of a graph approximates the
``Normalized Cut''), but this justification is known to break down on large
data sets.
</p>
<p>We provide theoretically-informed intuition about spectral clustering on
large data sets drawn from probability densities, by proving when a continuous
form of spectral clustering considered by past researchers (the unweighted
spectral cut of a probability density) finds good clusters of the underlying
density itself. Our work suggests that Shi-Malik spectral clustering works well
on data drawn from mixtures of Laplace distributions, and works poorly on data
drawn from certain other densities, such as a density we call the `square-root
trough'.
</p>
<p>Our core theorem proves that weighted spectral cuts have low weighted
isoperimetry for all probability densities. Our key tool is a new Cheeger-Buser
inequality for all probability densities, including discontinuous ones.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1">Timothy Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_G/0/1/0/all/0/1">Gary Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Walkington_N/0/1/0/all/0/1">Noel Walkington</a></p><p>Spectral clustering is one of the most popular clustering algorithms that has
stood the test of time. It is simple to describe, can be implemented using
standard linear algebra, and often finds better clusters than traditional
clustering algorithms like $k$-means and $k$-centers. The foundational
algorithm for two-way spectral clustering, by Shi and Malik, creates a
geometric graph from data and finds a spectral cut of the graph.
</p>
<p>In modern machine learning, many data sets are modeled as a large number of
points drawn from a probability density function. Little is known about when
spectral clustering works in this setting -- and when it doesn't. Past
researchers justified spectral clustering by appealing to the graph Cheeger
inequality (which states that the spectral cut of a graph approximates the
``Normalized Cut''), but this justification is known to break down on large
data sets.
</p>
<p>We provide theoretically-informed intuition about spectral clustering on
large data sets drawn from probability densities, by proving when a continuous
form of spectral clustering considered by past researchers (the unweighted
spectral cut of a probability density) finds good clusters of the underlying
density itself. Our work suggests that Shi-Malik spectral clustering works well
on data drawn from mixtures of Laplace distributions, and works poorly on data
drawn from certain other densities, such as a density we call the `square-root
trough'.
</p>
<p>Our core theorem proves that weighted spectral cuts have low weighted
isoperimetry for all probability densities. Our key tool is a new Cheeger-Buser
inequality for all probability densities, including discontinuous ones.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06659'>Optimal Algorithms for Bounded Weighted Edit Distance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alejandro Cassis, Tomasz Kociumaka, Philip Wellnitz</p><p>The edit distance of two strings is the minimum number of insertions,
deletions, and substitutions of characters needed to transform one string into
the other. The textbook dynamic-programming algorithm computes the edit
distance of two length-$n$ strings in $O(n^2)$ time, which is optimal up to
subpolynomial factors under SETH. An established way of circumventing this
hardness is to consider the bounded setting, where the running time is
parameterized by the edit distance $k$. A celebrated algorithm by Landau and
Vishkin (JCSS '88) achieves time $O(n + k^2)$, which is optimal as a function
of $n$ and $k$.
</p>
<p>Most practical applications rely on a more general weighted edit distance,
where each edit has a weight depending on its type and the involved characters
from the alphabet $\Sigma$. This is formalized through a weight function $w :
\Sigma\cup\{\varepsilon\}\times\Sigma\cup\{\varepsilon\}\to\mathbb{R}$
normalized so that $w(a,a)=0$ and $w(a,b)\geq 1$ for all $a,b \in
\Sigma\cup\{\varepsilon\}$ with $a \neq b$; the goal is to find an alignment of
the two strings minimizing the total weight of edits. The $O(n^2)$-time
algorithm supports this setting seamlessly, but only very recently, Das,
Gilbert, Hajiaghayi, Kociumaka, and Saha (STOC '23) gave the first non-trivial
algorithm for the bounded version, achieving time $O(n + k^5)$. While this
running time is linear for $k\le n^{1/5}$, it is still very far from the bound
$O(n+k^2)$ achievable in the unweighted setting.
</p>
<p>In this paper, we essentially close this gap by showing both an improved
$\tilde O(n+\sqrt{nk^3})$-time algorithm and, more surprisingly, a matching
lower bound: Conditioned on the All-Pairs Shortest Paths (APSP) hypothesis, our
running time is optimal for $\sqrt{n}\le k\le n$ (up to subpolynomial factors).
This is the first separation between the complexity of the weighted and
unweighted edit distance problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cassis_A/0/1/0/all/0/1">Alejandro Cassis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kociumaka_T/0/1/0/all/0/1">Tomasz Kociumaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Wellnitz_P/0/1/0/all/0/1">Philip Wellnitz</a></p><p>The edit distance of two strings is the minimum number of insertions,
deletions, and substitutions of characters needed to transform one string into
the other. The textbook dynamic-programming algorithm computes the edit
distance of two length-$n$ strings in $O(n^2)$ time, which is optimal up to
subpolynomial factors under SETH. An established way of circumventing this
hardness is to consider the bounded setting, where the running time is
parameterized by the edit distance $k$. A celebrated algorithm by Landau and
Vishkin (JCSS '88) achieves time $O(n + k^2)$, which is optimal as a function
of $n$ and $k$.
</p>
<p>Most practical applications rely on a more general weighted edit distance,
where each edit has a weight depending on its type and the involved characters
from the alphabet $\Sigma$. This is formalized through a weight function $w :
\Sigma\cup\{\varepsilon\}\times\Sigma\cup\{\varepsilon\}\to\mathbb{R}$
normalized so that $w(a,a)=0$ and $w(a,b)\geq 1$ for all $a,b \in
\Sigma\cup\{\varepsilon\}$ with $a \neq b$; the goal is to find an alignment of
the two strings minimizing the total weight of edits. The $O(n^2)$-time
algorithm supports this setting seamlessly, but only very recently, Das,
Gilbert, Hajiaghayi, Kociumaka, and Saha (STOC '23) gave the first non-trivial
algorithm for the bounded version, achieving time $O(n + k^5)$. While this
running time is linear for $k\le n^{1/5}$, it is still very far from the bound
$O(n+k^2)$ achievable in the unweighted setting.
</p>
<p>In this paper, we essentially close this gap by showing both an improved
$\tilde O(n+\sqrt{nk^3})$-time algorithm and, more surprisingly, a matching
lower bound: Conditioned on the All-Pairs Shortest Paths (APSP) hypothesis, our
running time is optimal for $\sqrt{n}\le k\le n$ (up to subpolynomial factors).
This is the first separation between the complexity of the weighted and
unweighted edit distance problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06696'>Characterizing the impact of last-level cache replacement policies on big-data workloads</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexandre Valentin Jamet, Lluc Alvarez, Marc Casas</p><p>In recent years, graph-processing has become an essential class of workloads
with applications in a rapidly growing number of fields. Graph-processing
typically uses large input sets, often in multi-gigabyte scale, and
data-dependent graph traversal methods exhibiting irregular memory access
patterns. Recent work demonstrates that, due to the highly irregular memory
access patterns of data-dependent graph traversals, state-of-the-art
graph-processing workloads spend up to 80 % of the total execution time waiting
for memory accesses to be served by the DRAM. The vast disparity between the
Last Level Cache (LLC) and main memory latencies is a problem that has been
addressed for years in computer architecture. One of the prevailing approaches
when it comes to mitigating this performance gap between modern CPUs and DRAM
is cache replacement policies. In this work, we characterize the challenges
drawn by graph-processing workloads and evaluate the most relevant cache
replacement policies.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jamet_A/0/1/0/all/0/1">Alexandre Valentin Jamet</a>, <a href="http://arxiv.org/find/cs/1/au:+Alvarez_L/0/1/0/all/0/1">Lluc Alvarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Casas_M/0/1/0/all/0/1">Marc Casas</a></p><p>In recent years, graph-processing has become an essential class of workloads
with applications in a rapidly growing number of fields. Graph-processing
typically uses large input sets, often in multi-gigabyte scale, and
data-dependent graph traversal methods exhibiting irregular memory access
patterns. Recent work demonstrates that, due to the highly irregular memory
access patterns of data-dependent graph traversals, state-of-the-art
graph-processing workloads spend up to 80 % of the total execution time waiting
for memory accesses to be served by the DRAM. The vast disparity between the
Last Level Cache (LLC) and main memory latencies is a problem that has been
addressed for years in computer architecture. One of the prevailing approaches
when it comes to mitigating this performance gap between modern CPUs and DRAM
is cache replacement policies. In this work, we characterize the challenges
drawn by graph-processing workloads and evaluate the most relevant cache
replacement policies.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06974'>Minimal dominating sets enumeration with FPT-delay parameterized by the degeneracy and maximum degree</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Valentin Bartier, Oscar Defrain, Fionn Mc Inerney</p><p>At STOC 2002, Eiter, Gottlob, and Makino presented a technique called ordered
generation that yields an $n^{O(d)}$-delay algorithm listing all minimal
transversals of an $n$-vertex hypergraph of degeneracy $d$, for an appropriate
definition of degeneracy. Recently at IWOCA 2019, Conte, Kant\'e, Marino, and
Uno asked whether, even for a more restrictive notion of degeneracy, this
XP-delay algorithm parameterized by $d$ could be made FPT-delay parameterized
by $d$ and the maximum degree $\Delta$, i.e., an algorithm with delay
$f(d,\Delta)\cdot n^{O(1)}$ for some computable function $f$. We answer this
question in the affirmative whenever the hypergraph corresponds to the closed
neighborhoods of a graph, i.e., we show that the intimately related problem of
enumerating minimal dominating sets in graphs admits an FPT-delay algorithm
parameterized by the degeneracy and the maximum degree.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bartier_V/0/1/0/all/0/1">Valentin Bartier</a>, <a href="http://arxiv.org/find/cs/1/au:+Defrain_O/0/1/0/all/0/1">Oscar Defrain</a>, <a href="http://arxiv.org/find/cs/1/au:+Inerney_F/0/1/0/all/0/1">Fionn Mc Inerney</a></p><p>At STOC 2002, Eiter, Gottlob, and Makino presented a technique called ordered
generation that yields an $n^{O(d)}$-delay algorithm listing all minimal
transversals of an $n$-vertex hypergraph of degeneracy $d$, for an appropriate
definition of degeneracy. Recently at IWOCA 2019, Conte, Kant\'e, Marino, and
Uno asked whether, even for a more restrictive notion of degeneracy, this
XP-delay algorithm parameterized by $d$ could be made FPT-delay parameterized
by $d$ and the maximum degree $\Delta$, i.e., an algorithm with delay
$f(d,\Delta)\cdot n^{O(1)}$ for some computable function $f$. We answer this
question in the affirmative whenever the hypergraph corresponds to the closed
neighborhoods of a graph, i.e., we show that the intimately related problem of
enumerating minimal dominating sets in graphs admits an FPT-delay algorithm
parameterized by the degeneracy and the maximum degree.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07006'>Fair Price Discrimination</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Siddhartha Banerjee, Kamesh Munagala, Yiheng Shen, Kangning Wang</p><p>A seller is pricing identical copies of a good to a stream of unit-demand
buyers. Each buyer has a value on the good as his private information. The
seller only knows the empirical value distribution of the buyer population and
chooses the revenue-optimal price. We consider a widely studied third-degree
price discrimination model where an information intermediary with perfect
knowledge of the arriving buyer's value sends a signal to the seller, hence
changing the seller's posterior and inducing the seller to set a personalized
posted price. Prior work of Bergemann, Brooks, and Morris (American Economic
Review, 2015) has shown the existence of a signaling scheme that preserves
seller revenue, while always selling the item, hence maximizing consumer
surplus. In a departure from prior work, we ask whether the consumer surplus
generated is fairly distributed among buyers with different values. To this
end, we aim to maximize welfare functions that reward more balanced surplus
allocations.
</p>
<p>Our main result is the surprising existence of a novel signaling scheme that
simultaneously $8$-approximates all welfare functions that are non-negative,
monotonically increasing, symmetric, and concave, compared with any other
signaling scheme. Classical examples of such welfare functions include the
utilitarian social welfare, the Nash welfare, and the max-min welfare. Such a
guarantee cannot be given by any consumer-surplus-maximizing scheme -- which
are the ones typically studied in the literature. In addition, our scheme is
socially efficient, and has the fairness property that buyers with higher
values enjoy higher expected surplus, which is not always the case for existing
schemes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1">Siddhartha Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Munagala_K/0/1/0/all/0/1">Kamesh Munagala</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yiheng Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kangning Wang</a></p><p>A seller is pricing identical copies of a good to a stream of unit-demand
buyers. Each buyer has a value on the good as his private information. The
seller only knows the empirical value distribution of the buyer population and
chooses the revenue-optimal price. We consider a widely studied third-degree
price discrimination model where an information intermediary with perfect
knowledge of the arriving buyer's value sends a signal to the seller, hence
changing the seller's posterior and inducing the seller to set a personalized
posted price. Prior work of Bergemann, Brooks, and Morris (American Economic
Review, 2015) has shown the existence of a signaling scheme that preserves
seller revenue, while always selling the item, hence maximizing consumer
surplus. In a departure from prior work, we ask whether the consumer surplus
generated is fairly distributed among buyers with different values. To this
end, we aim to maximize welfare functions that reward more balanced surplus
allocations.
</p>
<p>Our main result is the surprising existence of a novel signaling scheme that
simultaneously $8$-approximates all welfare functions that are non-negative,
monotonically increasing, symmetric, and concave, compared with any other
signaling scheme. Classical examples of such welfare functions include the
utilitarian social welfare, the Nash welfare, and the max-min welfare. Such a
guarantee cannot be given by any consumer-surplus-maximizing scheme -- which
are the ones typically studied in the literature. In addition, our scheme is
socially efficient, and has the fairness property that buyers with higher
values enjoy higher expected surplus, which is not always the case for existing
schemes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
