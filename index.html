<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2022-10-31T09:40:27Z">Monday, October 31 2022, 09:40</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, October 31
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=6784'>Oh right, quantum computing</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          These days, I often need to remind myself that, as an undergrad, grad student, postdoc, or professor, I&#8217;ve now been doing quantum computing research for a quarter-century&#8212;i.e., well over half of the subject&#8217;s existence. As a direct result, when I feel completely jaded about a new development in QC, it might actually be exciting. When [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>These days, I often need to remind myself that, as an undergrad, grad student, postdoc, or professor, I&#8217;ve now been doing quantum computing research for a quarter-century&#8212;i.e., well over half of the subject&#8217;s existence.  As a direct result, when I feel completely jaded about a new development in QC, it might actually be exciting.  When I feel moderately excited, it might actually be the most exciting thing for years.</p>



<p>With that in mind:</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>(1) Last week National Public Radio&#8217;s Marketplace <a href="https://www.marketplace.org/2022/10/27/china-and-the-us-vie-for-quantum-computing-supremacy/amp/">interviewed</a> me, John Martinis, and others about the current state of quantum computing.  While the piece wasn&#8217;t entirely hype-free, I&#8217;m pleased to report that my own views were represented accurately!  To wit:</p>



<blockquote class="wp-block-quote"><p>“There is a tsunami of hype about what quantum computers are going to revolutionize,” said Scott Aaronson, a professor of computer science at the University of Texas at Austin. “Quantum computing has turned into a word that venture capitalists or people seeking government funding will sprinkle on anything because it sounds good.”</p><p>Aaronson warned we can’t be certain that these computers will in fact revolutionize machine learning and finance and optimization problems.  “We can’t prove that there’s not a quantum algorithm that solves all these problems super fast, but we can’t even prove there’s not an algorithm for a conventional computer that does it,” he said.  [In the recorded version, they replaced this by a simpler but also accurate thought: namely, that we can&#8217;t prove one way or the other whether there&#8217;s a useful quantum advantage for these tasks.]</p><p><span style="font-size: revert; color: initial;"></span></p></blockquote>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>(2) I don&#8217;t like to use this blog to toot my own research horn, but on Thursday my postdoc Jason Pollack and I released a paper, entitled <a href="https://arxiv.org/pdf/2210.15601.pdf">Discrete Bulk Reconstruction</a>. And to be honest, I&#8217;m pretty damned excited about it.  It represents about 8 months of Jason&#8212;a cosmologist and string theorist who studied under Sean Carroll&#8212;helping me understand <a href="https://en.wikipedia.org/wiki/AdS/CFT_correspondence">AdS/CFT</a> in the language of the undergraduate CS curriculum, like min-cuts on undirected graphs, so that we could then look for polynomial-time algorithms to implement the holographic mapping from boundary quantum states to the spatial geometry in the bulk.  We drew heavily on previous work in the same direction, especially the already-seminal 2015 <a href="https://arxiv.org/abs/1505.07839">holographic entropy cone</a> paper by Ning Bao et al.  But I&#8217;d like to think that, among other things, our work represents a new frontier in just how accessible AdS/CFT itself can be made to CS and discrete math types.  Anyway, here&#8217;s the abstract if you&#8217;re interested:</p>



<blockquote class="wp-block-quote"><p>According to the <i>AdS/CFT correspondence</i>, the geometries of certain spacetimes are fully determined by quantum states that live on their boundaries &#8212; indeed, by the von Neumann entropies of portions of those boundary states. This work investigates to what extent the geometries can be reconstructed from the entropies <i>in polynomial time</i>. Bouland, Fefferman, and Vazirani (2019) argued that the AdS/CFT map can be exponentially complex if one wants to reconstruct regions such as the interiors of black holes. Our main result provides a sort of converse: we show that, in the special case of a single 1D boundary, if the input data consists of a list of entropies of <i>contiguous</i> boundary regions, and if the entropies satisfy a single inequality called Strong Subadditivity, then we can construct a graph model for the bulk in linear time. Moreover, the bulk graph is planar, it has O(N<sup>2</sup>) vertices (the information-theoretic minimum), and it&#8217;s &#8220;universal,&#8221; with only the edge weights depending on the specific entropies in question. From a combinatorial perspective, our problem boils down to an &#8220;inverse&#8221; of the famous min-cut problem: rather than being given a graph and asked to find a min-cut, here we&#8217;re given the values of min-cuts separating various sets of vertices, and need to find a weighted undirected graph consistent with those values. Our solution to this problem relies on the notion of a &#8220;bulkless&#8221; graph, which might be of independent interest for AdS/CFT. We also make initial progress on the case of multiple 1D boundaries &#8212; where the boundaries could be connected via wormholes &#8212; including an upper bound of O(N<sup>4</sup>) vertices whenever a planar bulk graph exists (thus putting the problem into the complexity class NP).</p></blockquote>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>(3) Anand Natarajan and Chinmay Nirkhe posted a preprint entitled <a href="https://arxiv.org/pdf/2210.15380.pdf">A classical oracle separation between QMA and QCMA</a>, which makes progress on a problem that&#8217;s been raised on this blog all the way back to its inception.  A bit of context: <a href="https://en.wikipedia.org/wiki/QMA">QMA</a>, Quantum Merlin-Arthur, captures what can be proven using a quantum state with poly(n) qubits as the proof, and a polynomial-time quantum algorithm as the verifier.  QCMA, or Quantum Classical Merlin-Arthur, is the same as QMA except that now the proof has to be classical.  A fundamental problem of quantum complexity theory, first raised by <a href="https://arxiv.org/abs/quant-ph/0210077">Aharonov and Naveh</a> in 2002, is whether QMA=QCMA.  In 2007, <a href="https://arxiv.org/abs/quant-ph/0604056">Greg Kuperberg and I</a> introduced the concept of quantum oracle separation&#8212;that is, a unitary that can be applied in a black-box manner&#8212;in order to show that there&#8217;s a quantum oracle relative to which QCMA≠QMA.  In 2015, <a href="https://arxiv.org/abs/1510.06750">Fefferman and Kimmel</a> improved this, to show that there&#8217;s a &#8220;randomized in-place&#8221; oracle relative to which QCMA≠QMA.  Natarajan and Nirkhe now remove the &#8220;in-place&#8221; part, meaning the only thing still &#8220;wrong&#8221; with their oracle is that it&#8217;s randomized.  Derandomizing their construction would finally settle this 20-year-old open problem (except, of course, for the minor detail of whether QMA=QCMA in the &#8220;real,&#8221; unrelativized world!).</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>(4) Oh right, the Google group reports the use of their superconducting processor to <a href="https://arxiv.org/pdf/2210.10255.pdf">simulate non-abelian anyons</a>.  Cool.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-31T05:26:35Z">Monday, October 31 2022, 05:26</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15714'>List Agreement Expansion from Coboundary Expansion</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Roy Gotlib, Tali Kaufman</p><p>One of the key components in PCP constructions are agreement tests. In
agreement test the tester is given access to subsets of fixed size of some set,
each equipped with an assignment. The tester is then tasked with testing
whether these local assignments agree with some global assignment over the
entire set. One natural generalization of this concept is the case where,
instead of a single assignment to each local view, the tester is given access
to $l$ different assignments for every subset. The tester is then tasked with
testing whether there exist $l$ global functions that agree with all of the
assignments of all of the local views.
</p>
<p>In this work we present sufficient condition for a set system to exhibit this
generalized definition of list agreement expansion. This is, to our knowledge,
the first work to consider this natural generalization of agreement testing.
Despite initially appearing very similar to agreement expansion, list agreement
expansion seem to require a different set of techniques. This is due to the
fact that the natural extension of agreement testing does not suffice when
testing for list agreement, as list agreement crucially relies on a global
structure. It follows that if a local assignments satisfy list agreement they
must not only agree locally but also exhibit some additional structure. In
order to test for the existence of this additional structure we use a
connection between covering spaces of a high dimensional complex and its
coboundaries. We use this connection as a form of ``decoupling''.
</p>
<p>Moreover, we show that any set system that exhibits list agreement expansion
also supports direct sum testing. This is the first scheme for direct sum
testing that works regardless of the parity of the sizes of the local sets.
Prior to our work the schemes for direct sum testing were based on the parity
of the sizes of the local tests.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gotlib_R/0/1/0/all/0/1">Roy Gotlib</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaufman_T/0/1/0/all/0/1">Tali Kaufman</a></p><p>One of the key components in PCP constructions are agreement tests. In
agreement test the tester is given access to subsets of fixed size of some set,
each equipped with an assignment. The tester is then tasked with testing
whether these local assignments agree with some global assignment over the
entire set. One natural generalization of this concept is the case where,
instead of a single assignment to each local view, the tester is given access
to $l$ different assignments for every subset. The tester is then tasked with
testing whether there exist $l$ global functions that agree with all of the
assignments of all of the local views.
</p>
<p>In this work we present sufficient condition for a set system to exhibit this
generalized definition of list agreement expansion. This is, to our knowledge,
the first work to consider this natural generalization of agreement testing.
Despite initially appearing very similar to agreement expansion, list agreement
expansion seem to require a different set of techniques. This is due to the
fact that the natural extension of agreement testing does not suffice when
testing for list agreement, as list agreement crucially relies on a global
structure. It follows that if a local assignments satisfy list agreement they
must not only agree locally but also exhibit some additional structure. In
order to test for the existence of this additional structure we use a
connection between covering spaces of a high dimensional complex and its
coboundaries. We use this connection as a form of ``decoupling''.
</p>
<p>Moreover, we show that any set system that exhibits list agreement expansion
also supports direct sum testing. This is the first scheme for direct sum
testing that works regardless of the parity of the sizes of the local sets.
Prior to our work the schemes for direct sum testing were based on the parity
of the sizes of the local tests.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-31T00:30:00Z">Monday, October 31 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15748'>DESSERT: An Efficient Algorithm for Vector Set Search with Vector Set Queries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Joshua Engels, Benjamin Coleman, Vihan Lakshman, Anshumali Shrivastava</p><p>We study the problem of \emph{vector set search} with \emph{vector set
queries}. This task is analogous to traditional near-neighbor search, with the
exception that both the query and each element in the collection are
\textit{sets} of vectors. We identify this problem as a core subroutine for
many web applications and find that existing solutions are unacceptably slow.
Towards this end, we present a new approximate search algorithm, DESSERT ({\bf
D}ESSERT {\bf E}ffeciently {\bf S}earches {\bf S}ets of {\bf E}mbeddings via
{\bf R}etrieval {\bf T}ables). DESSERT is a general tool with strong
theoretical guarantees and excellent empirical performance. When we integrate
DESSERT into ColBERT, a highly optimized state-of-the-art semantic search
method, we find a 2-5x speedup on the MSMarco passage ranking task with minimal
loss in recall, underscoring the effectiveness and practical applicability of
our proposal.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Engels_J/0/1/0/all/0/1">Joshua Engels</a>, <a href="http://arxiv.org/find/cs/1/au:+Coleman_B/0/1/0/all/0/1">Benjamin Coleman</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakshman_V/0/1/0/all/0/1">Vihan Lakshman</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1">Anshumali Shrivastava</a></p><p>We study the problem of \emph{vector set search} with \emph{vector set
queries}. This task is analogous to traditional near-neighbor search, with the
exception that both the query and each element in the collection are
\textit{sets} of vectors. We identify this problem as a core subroutine for
many web applications and find that existing solutions are unacceptably slow.
Towards this end, we present a new approximate search algorithm, DESSERT ({\bf
D}ESSERT {\bf E}ffeciently {\bf S}earches {\bf S}ets of {\bf E}mbeddings via
{\bf R}etrieval {\bf T}ables). DESSERT is a general tool with strong
theoretical guarantees and excellent empirical performance. When we integrate
DESSERT into ColBERT, a highly optimized state-of-the-art semantic search
method, we find a 2-5x speedup on the MSMarco passage ranking task with minimal
loss in recall, underscoring the effectiveness and practical applicability of
our proposal.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-31T00:30:00Z">Monday, October 31 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15962'>Parallel Self-Avoiding Walks for a Low-Autocorrelation Binary Sequences Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Borko Bo&#x161;kovi&#x107;, Jana Herzog, Janez Brest</p><p>A low-autocorrelation binary sequences problem with a high figure of merit
factor represents a formidable computational challenge. An efficient parallel
computing algorithm is required to reach the new best-known solutions for this
problem. Therefore, we developed the $\mathit{sokol}_{\mathit{skew}}$ solver
for the skew-symmetric search space. The developed solver takes the advantage
of parallel computing on graphics processing units. The solver organized the
search process as a sequence of parallel and contiguous self-avoiding walks and
achieved a speedup factor of 387 compared with $\mathit{lssOrel}$, its
predecessor. The $\mathit{sokol}_{\mathit{skew}}$ solver belongs to stochastic
solvers and can not guarantee the optimality of solutions. To mitigate this
problem, we established the predictive model of stopping conditions according
to the small instances for which the optimal skew-symmetric solutions are
known. With its help and 99% probability, the $\mathit{sokol}_{\mathit{skew}}$
solver found all the known and seven new best-known skew-symmetric sequences
for odd instances from $L=121$ to $L=223$. For larger instances, the solver can
not reach 99% probability within our limitations, but it still found several
new best-known binary sequences. We also analyzed the trend of the best merit
factor values, and it shows that as sequence size increases, the value of the
merit factor also increases, and this trend is flatter for larger instances.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Boskovic_B/0/1/0/all/0/1">Borko Bo&#x161;kovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Herzog_J/0/1/0/all/0/1">Jana Herzog</a>, <a href="http://arxiv.org/find/cs/1/au:+Brest_J/0/1/0/all/0/1">Janez Brest</a></p><p>A low-autocorrelation binary sequences problem with a high figure of merit
factor represents a formidable computational challenge. An efficient parallel
computing algorithm is required to reach the new best-known solutions for this
problem. Therefore, we developed the $\mathit{sokol}_{\mathit{skew}}$ solver
for the skew-symmetric search space. The developed solver takes the advantage
of parallel computing on graphics processing units. The solver organized the
search process as a sequence of parallel and contiguous self-avoiding walks and
achieved a speedup factor of 387 compared with $\mathit{lssOrel}$, its
predecessor. The $\mathit{sokol}_{\mathit{skew}}$ solver belongs to stochastic
solvers and can not guarantee the optimality of solutions. To mitigate this
problem, we established the predictive model of stopping conditions according
to the small instances for which the optimal skew-symmetric solutions are
known. With its help and 99% probability, the $\mathit{sokol}_{\mathit{skew}}$
solver found all the known and seven new best-known skew-symmetric sequences
for odd instances from $L=121$ to $L=223$. For larger instances, the solver can
not reach 99% probability within our limitations, but it still found several
new best-known binary sequences. We also analyzed the trend of the best merit
factor values, and it shows that as sequence size increases, the value of the
merit factor also increases, and this trend is flatter for larger instances.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-31T00:30:00Z">Monday, October 31 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, October 30
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/30/lecturer-teaching-faculty-at-princeton-university-apply-by-february-1-2023/'>Lecturer (Teaching Faculty) at Princeton University (apply by February 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Princeton University CS Department invites applications to join our teaching faculty. The teaching load for teaching faculty is typically one course per semester plus independent work advising, leaving time to pursue other activities, such as engaging in research. Review of applications will begin November 2022 on a rolling basis for Fall 2023 appointments. Website: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Princeton University CS Department invites applications to join our teaching faculty. The teaching load for teaching faculty is typically one course per semester plus independent work advising, leaving time to pursue other activities, such as engaging in research.</p>
<p>Review of applications will begin November 2022 on a rolling basis for Fall 2023 appointments.</p>
<p>Website: <a href="https://lift.cs.princeton.edu/hiring.html">https://lift.cs.princeton.edu/hiring.html</a><br />
Email: pparedes@cs.princeton.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-30T21:11:58Z">Sunday, October 30 2022, 21:11</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/30/assistant-professor-of-teaching-at-university-at-buffalo-apply-by-november-15-2022/'>Assistant Professor of Teaching at University at Buffalo (apply by November 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We have an opening for a teaching position for teaching courses in algorithms and computer security. Successful candidates will help support the establishment of a new course-based MS program. The deadline is a soft deadline as we will consider candidates until the position is filled but applying by Nov 15 would ensure timely consideration of [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We have an opening for a teaching position for teaching courses in algorithms and computer security. Successful candidates will help support the establishment of a new course-based MS program. The deadline is a soft deadline as we will consider candidates until the position is filled but applying by Nov 15 would ensure timely consideration of your application!</p>
<p>Website: <a href="https://www.ubjobs.buffalo.edu/postings/36683">https://www.ubjobs.buffalo.edu/postings/36683</a><br />
Email: atri@buffalo.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-30T20:46:24Z">Sunday, October 30 2022, 20:46</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/30/tenure-track-faculty-position-at-university-at-buffalo-apply-by-december-30-2022/'>Tenure track faculty position at University at Buffalo (apply by December 30, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We are hiring tenure track/tenured professor in theory (among four areas in total). We also have positions open for machine learning and security/privacy that would also be theory friendly. Website: www.ubjobs.buffalo.edu/postings/37335 Email: atri@buffalo.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We are hiring tenure track/tenured professor in theory (among four areas in total). We also have positions open for machine learning and security/privacy that would also be theory friendly.</p>
<p>Website: <a href="https://www.ubjobs.buffalo.edu/postings/37335">https://www.ubjobs.buffalo.edu/postings/37335</a><br />
Email: atri@buffalo.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-30T20:43:18Z">Sunday, October 30 2022, 20:43</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/10/does-physics-nobel-prize-winner.html'>What was the recent  Nobel Prize in Physics really about?(Guest Post)</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;David Marcus was a Math major a year ahead of me at SUNY Stony brook (he graduated in 1979,</p><p>I graduated in 1980). He then got a PhD from MIT in Math, and is a reader of this blog.&nbsp; Recently he emailed me that he thinks the current Nobel Prize Winners in Physics do not understand their own work. Is it true? Let's find out!</p><p>------------------------</p><p>(Guest blog from David Marcus)</p><p>2022 Nobel Prize in Physics Awarded for Experiments that Demonstrate Nonlocality</p><p>The 2022 Nobel Prize in Physics was recently awarded to experimenters who demonstrated that the world is nonlocal. The curious thing is that neither the writers of the Nobel Prize press release nor the recipients seem to understand that this is what they demonstrated.</p><p><br></p><p>For example, the press release (see here) says: "John Clauser developed John Bell's ideas, leading to a practical experiment. When he took the measurements, they supported quantum mechanics by clearly violating a Bell inequality. This means that quantum mechanics cannot be replaced by a theory that uses hidden variables." That is not what the experiments mean, and the statement is false.</p><p>The word "locality" means that doing something here cannot instantly change something other there.</p><p>The experimental setup is the following: You prepare two particles, A and B, and send them in opposite directions so that they are far apart. You and your colleague do experiments on each particle at the same time. If you and your colleague perform the same experiment, then, from your experiment on A, you can predict with certainty the result of your colleague's experiment on B (and vice versa).</p><p>In a paper in 1935, Einstein, Podolsky, and Rosen pointed out that, assuming locality, the experimental results at A and B must be determined by the source that prepared the particles. They didn't actually say, "assuming locality", but they implicitly assumed it. (If you disagree with them, please offer an alternative.)</p><p>In 1964, John Bell published his paper. In it, he considered three of the experiments that could be done on the particles A and B. Assuming the results are determined by the source (which follows from Einstein, Podolsky, and Rosen's argument), he derived an inequality on the correlations between the results of the three experiments on the two particles. The math is simple; for details, see&nbsp;here.</p><p>The Nobel Prize winners did experiments, and their results violated Bell's inequality (or similar inequalities). Hence, the world is nonlocal.</p><p>The simplest theory that agrees with experiment is Bohmian Mechanics. This is a deterministic theory of particles whose motion is governed by a wave (the wave function being the solution of the Schrödinger equation). Of course, Bohmian Mechanics is nonlocal, as is the world.</p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;David Marcus was a Math major a year ahead of me at SUNY Stony brook (he graduated in 1979,</p><p>I graduated in 1980). He then got a PhD from MIT in Math, and is a reader of this blog.&nbsp; Recently he emailed me that he thinks the current Nobel Prize Winners in Physics do not understand their own work. Is it true? Let's find out!</p><p>------------------------</p><p>(Guest blog from David Marcus)</p><p>2022 Nobel Prize in Physics Awarded for Experiments that Demonstrate Nonlocality</p><p>The 2022 Nobel Prize in Physics was recently awarded to experimenters who demonstrated that the world is nonlocal. The curious thing is that neither the writers of the Nobel Prize press release nor the recipients seem to understand that this is what they demonstrated.</p><p><br /></p><p>For example, the press release (see <a href="https://www.nobelprize.org/prizes/physics/2022/press-release/">here</a>) says: "John Clauser developed John Bell's ideas, leading to a practical experiment. When he took the measurements, they supported quantum mechanics by clearly violating a Bell inequality. This means that quantum mechanics cannot be replaced by a theory that uses hidden variables." That is not what the experiments mean, and the statement is false.</p><p>The word "locality" means that doing something here cannot instantly change something other there.</p><p>The experimental setup is the following: You prepare two particles, A and B, and send them in opposite directions so that they are far apart. You and your colleague do experiments on each particle at the same time. If you and your colleague perform the same experiment, then, from your experiment on A, you can predict with certainty the result of your colleague's experiment on B (and vice versa).</p><p>In a paper in 1935, Einstein, Podolsky, and Rosen pointed out that, assuming locality, the experimental results at A and B must be determined by the source that prepared the particles. They didn't actually say, "assuming locality", but they implicitly assumed it. (If you disagree with them, please offer an alternative.)</p><p>In 1964, John Bell published his paper. In it, he considered three of the experiments that could be done on the particles A and B. Assuming the results are determined by the source (which follows from Einstein, Podolsky, and Rosen's argument), he derived an inequality on the correlations between the results of the three experiments on the two particles. The math is simple; for details, see&nbsp;<a href="http://www.scholarpedia.org/article/Bell%27s_theorem">here</a>.</p><p>The Nobel Prize winners did experiments, and their results violated Bell's inequality (or similar inequalities). Hence, the world is nonlocal.</p><p>The simplest theory that agrees with experiment is Bohmian Mechanics. This is a deterministic theory of particles whose motion is governed by a wave (the wave function being the solution of the Schrödinger equation). Of course, Bohmian Mechanics is nonlocal, as is the world.</p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-30T17:35:00Z">Sunday, October 30 2022, 17:35</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, October 29
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/29/postdoc-at-linkoping-university-apply-by-november-7-2022/'>Postdoc at Linköping University (apply by November 7, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Linköping University invites applications for postdoc positions. In particular, the Theoretical Computer Science Laboratory is looking for postdocs with a strong background in theoretical computer science. Examples of research topics include (1) fine-grained complexity, (2) algebraic methods for CSPs, (3) parameterized complexity, and (4) randomized and approximation algorithms. Website: liu.se/en/work-at-liu/vacancies?rmpage=job&#38;rmjob=20079&#38;rmlang=UK Email: peter.jonsson@liu.se
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Linköping University invites applications for postdoc positions. In particular, the Theoretical Computer Science Laboratory<br />
is looking for postdocs with a strong background in theoretical computer science. Examples of research topics include (1) fine-grained complexity, (2) algebraic methods for CSPs, (3) parameterized complexity, and (4) randomized and approximation algorithms.</p>
<p>Website: <a href="https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=20079&amp;rmlang=UK">https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=20079&amp;rmlang=UK</a><br />
Email: peter.jonsson@liu.se</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-29T05:59:45Z">Saturday, October 29 2022, 05:59</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, October 28
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/28/assisstant-professor-at-university-of-british-columbia-apply-by-november-15-2022/'>assisstant professor at University of British Columbia (apply by November 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The UBC math department seeks candidates for a tenure-track assistant professor position, with expertise in the mathematics of Machine Learning and AI. Specific topics of interest include, but are not limited to, neural nets, statistical learning theory, inverse problems, optimization, mathematical data science, and mathematics of information, with a strong theoretical component. Website: www.mathjobs.org/jobs/list/20980 Email: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The UBC math department seeks candidates for a tenure-track assistant professor position, with expertise in the mathematics of Machine Learning and AI. Specific topics of interest include, but are not limited to, neural nets, statistical learning theory, inverse problems, optimization, mathematical data science, and mathematics of information, with a strong theoretical component.</p>
<p>Website: <a href="https://www.mathjobs.org/jobs/list/20980">https://www.mathjobs.org/jobs/list/20980</a><br />
Email: exec-coord@math.ubc.ca</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T19:41:58Z">Friday, October 28 2022, 19:41</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=6778'>On Bryan Caplan and his new book</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Yesterday I attended a lecture by George Mason University economist Bryan Caplan, who&#8217;s currently visiting UT Austin, about his new book entitled Don’t Be a Feminist. (See also here for previous back-and-forth between me and Bryan about his book.) A few remarks: (1) Maybe surprisingly, there were no protesters storming the lectern, no security detail, [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Yesterday I attended a lecture by George Mason University economist <a href="https://betonit.substack.com/">Bryan Caplan</a>, who&#8217;s currently visiting UT Austin, about his new book entitled <em><a href="https://www.amazon.com/Dont-Be-Feminist-Genuine-Justice/dp/B0BD3DFMMH/ref=asc_df_B0BD3DFMMH/">Don’t Be a Feminist</a></em>.  (<a href="https://betonit.substack.com/p/aaronson-on-feminism-my-reply">See also here</a> for previous back-and-forth between me and Bryan about his book.)  A few remarks:</p>



<p>(1) Maybe surprisingly, there were no protesters storming the lectern, no security detail, not even a single rotten vegetable thrown. About 30 people showed up, majority men but women too. They listened politely and asked polite questions afterward. One feminist civilly challenged Bryan during the Q&amp;A about his gender pay gap statistics.</p>



<p>(2) How is it that I got denounced <a></a>by half the planet for saying once, in a blog comment, that I agreed with 97% of feminism but had concerns with one particular way it was operationalized, whereas Bryan seems to be … not denounced in the slightest for publishing a book and going on a lecture tour about how he rejects feminism in its entirety as angry and self-pitying in addition to factually false? Who can explain this to me?</p>



<p>(3) For purposes of his argument, Bryan defines feminism as &#8220;the view that women are generally treated less fairly than men,&#8221; rather than (say) &#8220;the view that men and women <em>ought</em> to be treated equally,&#8221; or &#8220;the radical belief that women are people,&#8221; or other formulations that Bryan considers too obvious to debate.  He then rebuts feminism as he&#8217;s defined it, by taking the audience on a horror tour of all the ways society treats men less fairly than women (expectations of doing dirty and dangerous work, divorce law, military drafts as in Ukraine right now, &#8230;), as well as potentially benign explanations for apparent unfairness toward women, to argue that it&#8217;s at least <em>debatable</em> which sex gets the rawer deal on average.</p>



<p>During the Q&amp;A, I raised what I thought was the central objection to Bryan&#8217;s relatively narrow definition of feminism. Namely that, by the standards of 150 years ago, Bryan is <em>obviously</em> a feminist, and so am I, and so is everyone in the room. (Whereupon a right-wing business school professor interjected: &#8220;please don’t make assumptions about me!&#8221;)</p>



<p>I explained that <em>this</em> is why I call myself a feminist, despite agreeing with many of Bryan&#8217;s substantive points: because I want no one to imagine for a nanosecond that, if I had the power, I&#8217;d take gender relations back to how they were generations ago.</p>



<p>Bryan replied that >60% of Americans call themselves non-feminists in surveys. So, he asked me rhetorically, do <em>all</em> those Americans secretly yearn to take us back to the 19th century? Such a position, he said, seemed so absurdly uncharitable as not to be worth responding to.</p>



<p>Reflecting about it on my walk home, I realized: actually, give or take the exact percentages, this is <em>precisely</em> the progressive thesis. I.e., that just like at least a solid minority of Germans turned out to be totally fine with Nazism, however much they might&#8217;ve denied it beforehand, so too at least a solid minority of Americans would be fine with&#8212;if not ecstatic about&#8212;<em>The Handmaid&#8217;s Tale</em> made real. Indeed, they&#8217;d add, it&#8217;s only vociferous progressive activism that stands between us and that dystopia.</p>



<p>And if anyone were tempted to doubt this, progressives might point to the election of Donald Trump, the failed insurrection to maintain his power, and the repeal of <em>Roe</em> as proof enough to last for a quadrillion years.</p>



<p>Bryan would probably reply: why even waste time engaging with such a hysterical position? To me, though, the hysterical position sadly has more than a grain of truth to it. I <em>wish</em> we lived in a world where there was no point in calling oneself a pro-democracy anti-racist feminist and a hundred other banal and obvious things. I just don&#8217;t think that we do.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T16:54:52Z">Friday, October 28 2022, 16:54</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://thmatters.wordpress.com/2022/10/28/acm-survey-on-math-requirements-for-the-cs-major/'>ACM survey on math requirements for the CS major</a></h3>
        <p class='tr-article-feed'>from <a href='https://thmatters.wordpress.com'>Theory Matters</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The ACM/IEEE-CS/AAAI CS2023 Curricular Task Force is working on updating the undergraduate CS curriculum guidelines for the next decade. They have distributed a survey about the role of math in that curriculum, which is of direct interest to the TCS community. Please consider taking the survey so your opinion is heard! From the Task Force: &#8212;&#8212;&#8212;&#8211; [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The <strong>ACM/IEEE-CS/AAAI CS2023 Curricular Task Force </strong>is working on updating the undergraduate CS curriculum guidelines for the next decade. They have distributed a survey about the role of math in that curriculum, which is of direct interest to the TCS community. Please consider taking the survey so your opinion is heard!</p>



<p>From the Task Force:</p>



<p>&#8212;&#8212;&#8212;&#8211;</p>



<p>Dear educator,</p>



<p>What math should undergraduate Computer Science students know?</p>



<p>The CS2023 Task Force is collecting (and will share!) input from the community on this very important topic both as a useful “sense of the community” for everyone and, pertinent to our immediate goal, to shape our decennial curricular recommendations.</p>



<p>We invite you to fill out a survey: <a href="https://tinyurl.com/7zjbu7pr" target="_blank" rel="noreferrer noopener">https://tinyurl.com/7zjbu7pr</a></p>



<p>As you fill out this survey, we ask you to reflect on:</p>



<ul>
<li>Discrete mathematics: student preparedness, topics covered, what’s missing?</li>



<li>What should come beyond discrete mathematics, if anything?</li>



<li>What do the new high-growth areas (AI, ML, quantum computing, data science) need by way of mathematical preparation?</li>



<li>Do most CS jobs need much mathematics, and do current mathematical requirements pose a barrier to some populations of students?</li>
</ul>



<p>Thank you in advance for taking the time to fill out the survey!</p>



<p><em>If you believe that other colleagues in your department can contribute, please forward the survey link to them</em>.</p>



<p>Amruth Kumar and Rajendra Raj</p>



<p>On behalf of the of the ACM/IEEE-CS/AAAI CS2023 Curricular Task Force</p>



<p>NOTE: By participating, you agree that we may use your responses for this study; and that this data may be presented in aggregate form (with no personally identifying information) in articles or websites.</p>



<p>&#8212;&#8212;&#8211;</p>
<p class="authors">By shuchic</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T15:09:38Z">Friday, October 28 2022, 15:09</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/28/postdoc-at-university-of-michigan-apply-by-january-10-2023/'>Postdoc at University of Michigan (apply by January 10, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Theory Group at the University of Michigan invites applications for postdoctoral position(s) beginning September 2023. The position will have an initial appointment for one year but may be extended depending on circumstances. Applicants should be recent PhDs with interests that align well with our ongoing research. Website: forms.gle/P9SAVGhP3tu9rayZA Email: thsa@umich.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Theory Group at the University of Michigan invites applications for postdoctoral position(s) beginning September 2023. The position will have an initial appointment for one year but may be extended depending on circumstances.</p>
<p>Applicants should be recent PhDs with interests that align well with our ongoing research.</p>
<p>Website: <a href="https://forms.gle/P9SAVGhP3tu9rayZA">https://forms.gle/P9SAVGhP3tu9rayZA</a><br />
Email: thsa@umich.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T13:06:28Z">Friday, October 28 2022, 13:06</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15325'>Geodesic packing in graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Paul Manuel, Bostjan Bresar, Sandi Klavzar</p><p>Given a graph $G$, a geodesic packing in $G$ is a set of vertex-disjoint
maximal geodesics, and the geodesic packing number of $G$, ${\gpack}(G)$, is
the maximum cardinality of a geodesic packing in $G$. It is proved that the
decision version of the geodesic packing number is NP-complete. We also
consider the geodesic transversal number, ${\gt}(G)$, which is the minimum
cardinality of a set of vertices that hit all maximal geodesics in $G$. While
$\gt(G)\ge \gpack(G)$ in every graph $G$, the quotient ${\rm gt}(G)/{\rm
gpack}(G)$ is investigated. By using the rook's graph, it is proved that there
does not exist a constant $C &lt; 3$ such that $\frac{{\rm gt}(G)}{{\rm
gpack}(G)}\le C$ would hold for all graphs $G$. If $T$ is a tree, then it is
proved that ${\rm gpack}(T) = {\rm gt}(T)$, and a linear algorithm for
determining ${\rm gpack}(T)$ is derived. The geodesic packing number is also
determined for the strong product of paths.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Manuel_P/0/1/0/all/0/1">Paul Manuel</a>, <a href="http://arxiv.org/find/math/1/au:+Bresar_B/0/1/0/all/0/1">Bostjan Bresar</a>, <a href="http://arxiv.org/find/math/1/au:+Klavzar_S/0/1/0/all/0/1">Sandi Klavzar</a></p><p>Given a graph $G$, a geodesic packing in $G$ is a set of vertex-disjoint
maximal geodesics, and the geodesic packing number of $G$, ${\gpack}(G)$, is
the maximum cardinality of a geodesic packing in $G$. It is proved that the
decision version of the geodesic packing number is NP-complete. We also
consider the geodesic transversal number, ${\gt}(G)$, which is the minimum
cardinality of a set of vertices that hit all maximal geodesics in $G$. While
$\gt(G)\ge \gpack(G)$ in every graph $G$, the quotient ${\rm gt}(G)/{\rm
gpack}(G)$ is investigated. By using the rook's graph, it is proved that there
does not exist a constant $C &lt; 3$ such that $\frac{{\rm gt}(G)}{{\rm
gpack}(G)}\le C$ would hold for all graphs $G$. If $T$ is a tree, then it is
proved that ${\rm gpack}(T) = {\rm gt}(T)$, and a linear algorithm for
determining ${\rm gpack}(T)$ is derived. The geodesic packing number is also
determined for the strong product of paths.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T00:30:00Z">Friday, October 28 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15509'>On Tsirelson pairs of C*-algebras</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Isaac Goldbring, Bradd Hart</p><p>We introduce the notion of a Tsirelson pair of C*-algebras, which is a pair
of C*-algebras for which the space of quantum strategies obtained by using
states on the minimal tensor product of the pair and the space of quantum
strategies obtained by using states on the maximal tensor product of the pair
coincide. We exhibit a number of examples of such pairs that are ``nontrivial''
in the sense that the minimal tensor product and the maximal tensor product of
the pair are not isomorphic. For example, we prove that any pair containing a
C*-algebra with Kirchberg's QWEP property is a Tsirelson pair. We then
introduce the notion of a C*-algebra with the Tsirelson property (TP) and
establish a number of closure properties for this class. We also show that the
class of C*-algebras with the TP form an axiomatizable class (in the sense of
model theory), but that this class admits no ``effective'' axiomatization.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Goldbring_I/0/1/0/all/0/1">Isaac Goldbring</a>, <a href="http://arxiv.org/find/math/1/au:+Hart_B/0/1/0/all/0/1">Bradd Hart</a></p><p>We introduce the notion of a Tsirelson pair of C*-algebras, which is a pair
of C*-algebras for which the space of quantum strategies obtained by using
states on the minimal tensor product of the pair and the space of quantum
strategies obtained by using states on the maximal tensor product of the pair
coincide. We exhibit a number of examples of such pairs that are ``nontrivial''
in the sense that the minimal tensor product and the maximal tensor product of
the pair are not isomorphic. For example, we prove that any pair containing a
C*-algebra with Kirchberg's QWEP property is a Tsirelson pair. We then
introduce the notion of a C*-algebra with the Tsirelson property (TP) and
establish a number of closure properties for this class. We also show that the
class of C*-algebras with the TP form an axiomatizable class (in the sense of
model theory), but that this class admits no ``effective'' axiomatization.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T00:30:00Z">Friday, October 28 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15601'>Discrete Bulk Reconstruction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Scott Aaronson, Jason Pollack</p><p>According to the AdS/CFT correspondence, the geometries of certain spacetimes
are fully determined by quantum states that live on their boundaries -- indeed,
by the von Neumann entropies of portions of those boundary states. This work
investigates to what extent the geometries can be reconstructed from the
entropies in polynomial time. Bouland, Fefferman, and Vazirani (2019) argued
that the AdS/CFT map can be exponentially complex if one wants to reconstruct
regions such as the interiors of black holes. Our main result provides a sort
of converse: we show that, in the special case of a single 1D boundary, if the
input data consists of a list of entropies of contiguous boundary regions, and
if the entropies satisfy a single inequality called Strong Subadditivity, then
we can construct a graph model for the bulk in linear time. Moreover, the bulk
graph is planar, it has $O(N^2)$ vertices (the information-theoretic minimum),
and it's ``universal,'' with only the edge weights depending on the specific
entropies in question. From a combinatorial perspective, our problem boils down
to an ``inverse'' of the famous min-cut problem: rather than being given a
graph and asked to find a min-cut, here we're given the values of min-cuts
separating various sets of vertices, and need to find a weighted undirected
graph consistent with those values. Our solution to this problem relies on the
notion of a ``bulkless'' graph, which might be of independent interest for
AdS/CFT. We also make initial progress on the case of multiple 1D boundaries --
where the boundaries could be connected via wormholes -- including an upper
bound of $O(N^4)$ vertices whenever a planar bulk graph exists (thus putting
the problem into the complexity class $\mathsf{NP}$).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Aaronson_S/0/1/0/all/0/1">Scott Aaronson</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Pollack_J/0/1/0/all/0/1">Jason Pollack</a></p><p>According to the AdS/CFT correspondence, the geometries of certain spacetimes
are fully determined by quantum states that live on their boundaries -- indeed,
by the von Neumann entropies of portions of those boundary states. This work
investigates to what extent the geometries can be reconstructed from the
entropies in polynomial time. Bouland, Fefferman, and Vazirani (2019) argued
that the AdS/CFT map can be exponentially complex if one wants to reconstruct
regions such as the interiors of black holes. Our main result provides a sort
of converse: we show that, in the special case of a single 1D boundary, if the
input data consists of a list of entropies of contiguous boundary regions, and
if the entropies satisfy a single inequality called Strong Subadditivity, then
we can construct a graph model for the bulk in linear time. Moreover, the bulk
graph is planar, it has $O(N^2)$ vertices (the information-theoretic minimum),
and it's ``universal,'' with only the edge weights depending on the specific
entropies in question. From a combinatorial perspective, our problem boils down
to an ``inverse'' of the famous min-cut problem: rather than being given a
graph and asked to find a min-cut, here we're given the values of min-cuts
separating various sets of vertices, and need to find a weighted undirected
graph consistent with those values. Our solution to this problem relies on the
notion of a ``bulkless'' graph, which might be of independent interest for
AdS/CFT. We also make initial progress on the case of multiple 1D boundaries --
where the boundaries could be connected via wormholes -- including an upper
bound of $O(N^4)$ vertices whenever a planar bulk graph exists (thus putting
the problem into the complexity class $\mathsf{NP}$).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T00:30:00Z">Friday, October 28 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14982'>LinearCoFold and LinearCoPartition: Linear-Time Algorithms for Secondary Structure Prediction of Interacting RNA molecules</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: He Zhang, Sizhen Li, Liang Zhang, David H. Mathews, Liang Huang</p><p>Many ncRNAs function through RNA-RNA interactions. Fast and reliable RNA
structure prediction with consideration of RNA-RNA interaction is useful. Some
existing tools are less accurate due to omitting the competing of
intermolecular and intramolecular base pairs, or focus more on predicting the
binding region rather than predicting the complete secondary structure of two
interacting strands. Vienna RNAcofold, which reduces the problem into the
classical single sequence folding by concatenating two strands, scales in cubic
time against the combined sequence length, and is slow for long sequences. To
address these issues, we present LinearCoFold, which predicts the complete
minimum free energy structure of two strands in linear runtime, and
LinearCoPartition, which calculates the cofolding partition function and base
pairing probabilities in linear runtime. LinearCoFold and LinearCoPartition
follows the concatenation strategy of RNAcofold, but are orders of magnitude
faster than RNAcofold. For example, on a sequence pair with combined length of
26,190 nt, LinearCoFold is 86.8x faster than RNAcofold MFE mode (0.6 minutes
vs. 52.1 minutes), and LinearCoPartition is 642.3x faster than RNAcofold
partition function mode (1.8 minutes vs. 1156.2 minutes). Different from the
local algorithms, LinearCoFold and LinearCoPartition are global cofolding
algorithms without restriction on base pair length. Surprisingly, LinearCoFold
and LinearCoPartition's predictions have higher PPV and sensitivity of
intermolecular base pairs. Furthermore, we apply LinearCoFold to predict the
RNA-RNA interaction between SARS-CoV-2 gRNA and human U4 snRNA, which has been
experimentally studied, and observe that LinearCoFold's prediction correlates
better to the wet lab results.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_H/0/1/0/all/0/1">He Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_S/0/1/0/all/0/1">Sizhen Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_L/0/1/0/all/0/1">Liang Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Mathews_D/0/1/0/all/0/1">David H. Mathews</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Huang_L/0/1/0/all/0/1">Liang Huang</a></p><p>Many ncRNAs function through RNA-RNA interactions. Fast and reliable RNA
structure prediction with consideration of RNA-RNA interaction is useful. Some
existing tools are less accurate due to omitting the competing of
intermolecular and intramolecular base pairs, or focus more on predicting the
binding region rather than predicting the complete secondary structure of two
interacting strands. Vienna RNAcofold, which reduces the problem into the
classical single sequence folding by concatenating two strands, scales in cubic
time against the combined sequence length, and is slow for long sequences. To
address these issues, we present LinearCoFold, which predicts the complete
minimum free energy structure of two strands in linear runtime, and
LinearCoPartition, which calculates the cofolding partition function and base
pairing probabilities in linear runtime. LinearCoFold and LinearCoPartition
follows the concatenation strategy of RNAcofold, but are orders of magnitude
faster than RNAcofold. For example, on a sequence pair with combined length of
26,190 nt, LinearCoFold is 86.8x faster than RNAcofold MFE mode (0.6 minutes
vs. 52.1 minutes), and LinearCoPartition is 642.3x faster than RNAcofold
partition function mode (1.8 minutes vs. 1156.2 minutes). Different from the
local algorithms, LinearCoFold and LinearCoPartition are global cofolding
algorithms without restriction on base pair length. Surprisingly, LinearCoFold
and LinearCoPartition's predictions have higher PPV and sensitivity of
intermolecular base pairs. Furthermore, we apply LinearCoFold to predict the
RNA-RNA interaction between SARS-CoV-2 gRNA and human U4 snRNA, which has been
experimentally studied, and observe that LinearCoFold's prediction correlates
better to the wet lab results.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T00:30:00Z">Friday, October 28 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15014'>Counting Perfect Matchings in Dense Graphs Is Hard</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicolas El Maalouly, Yanheng Wang</p><p>We show that the problem of counting perfect matchings remains #P-complete
even if we restrict the input to very dense graphs, proving the conjecture in
[5]. Here "dense graphs" refer to bipartite graphs of bipartite independence
number $\leq 2$, or general graphs of independence number $\leq 2$. Our proof
is by reduction from counting perfect matchings in bipartite graphs, via
elementary linear algebra tricks and graph constructions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Maalouly_N/0/1/0/all/0/1">Nicolas El Maalouly</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanheng Wang</a></p><p>We show that the problem of counting perfect matchings remains #P-complete
even if we restrict the input to very dense graphs, proving the conjecture in
[5]. Here "dense graphs" refer to bipartite graphs of bipartite independence
number $\leq 2$, or general graphs of independence number $\leq 2$. Our proof
is by reduction from counting perfect matchings in bipartite graphs, via
elementary linear algebra tricks and graph constructions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T00:30:00Z">Friday, October 28 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15114'>Faster Linear Algebra for Distance Matrices</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Piotr Indyk, Sandeep Silwal</p><p>The distance matrix of a dataset $X$ of $n$ points with respect to a distance
function $f$ represents all pairwise distances between points in $X$ induced by
$f$. Due to their wide applicability, distance matrices and related families of
matrices have been the focus of many recent algorithmic works. We continue this
line of research and take a broad view of algorithm design for distance
matrices with the goal of designing fast algorithms, which are specifically
tailored for distance matrices, for fundamental linear algebraic primitives.
Our results include efficient algorithms for computing matrix-vector products
for a wide class of distance matrices, such as the $\ell_1$ metric for which we
get a linear runtime, as well as an $\Omega(n^2)$ lower bound for any algorithm
which computes a matrix-vector product for the $\ell_{\infty}$ case, showing a
separation between the $\ell_1$ and the $\ell_{\infty}$ metrics. Our upper
bound results, in conjunction with recent works on the matrix-vector query
model, have many further downstream applications, including the fastest
algorithm for computing a relative error low-rank approximation for the
distance matrix induced by $\ell_1$ and $\ell_2^2$ functions and the fastest
algorithm for computing an additive error low-rank approximation for the
$\ell_2$ metric, in addition to applications for fast matrix multiplication
among others. We also give algorithms for constructing distance matrices and
show that one can construct an approximate $\ell_2$ distance matrix in time
faster than the bound implied by the Johnson-Lindenstrauss lemma.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Indyk_P/0/1/0/all/0/1">Piotr Indyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1">Sandeep Silwal</a></p><p>The distance matrix of a dataset $X$ of $n$ points with respect to a distance
function $f$ represents all pairwise distances between points in $X$ induced by
$f$. Due to their wide applicability, distance matrices and related families of
matrices have been the focus of many recent algorithmic works. We continue this
line of research and take a broad view of algorithm design for distance
matrices with the goal of designing fast algorithms, which are specifically
tailored for distance matrices, for fundamental linear algebraic primitives.
Our results include efficient algorithms for computing matrix-vector products
for a wide class of distance matrices, such as the $\ell_1$ metric for which we
get a linear runtime, as well as an $\Omega(n^2)$ lower bound for any algorithm
which computes a matrix-vector product for the $\ell_{\infty}$ case, showing a
separation between the $\ell_1$ and the $\ell_{\infty}$ metrics. Our upper
bound results, in conjunction with recent works on the matrix-vector query
model, have many further downstream applications, including the fastest
algorithm for computing a relative error low-rank approximation for the
distance matrix induced by $\ell_1$ and $\ell_2^2$ functions and the fastest
algorithm for computing an additive error low-rank approximation for the
$\ell_2$ metric, in addition to applications for fast matrix multiplication
among others. We also give algorithms for constructing distance matrices and
show that one can construct an approximate $\ell_2$ distance matrix in time
faster than the bound implied by the Johnson-Lindenstrauss lemma.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T00:30:00Z">Friday, October 28 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15178'>Anonymized Histograms in Intermediate Privacy Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi</p><p>We study the problem of privately computing the anonymized histogram (a.k.a.
unattributed histogram), which is defined as the histogram without item labels.
Previous works have provided algorithms with $\ell_1$- and $\ell_2^2$-errors of
$O_\varepsilon(\sqrt{n})$ in the central model of differential privacy (DP).
</p>
<p>In this work, we provide an algorithm with a nearly matching error guarantee
of $\tilde{O}_\varepsilon(\sqrt{n})$ in the shuffle DP and pan-private models.
Our algorithm is very simple: it just post-processes the discrete
Laplace-noised histogram! Using this algorithm as a subroutine, we show
applications in privately estimating symmetric properties of distributions such
as entropy, support coverage, and support size.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghazi_B/0/1/0/all/0/1">Badih Ghazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamath_P/0/1/0/all/0/1">Pritish Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Ravi Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1">Pasin Manurangsi</a></p><p>We study the problem of privately computing the anonymized histogram (a.k.a.
unattributed histogram), which is defined as the histogram without item labels.
Previous works have provided algorithms with $\ell_1$- and $\ell_2^2$-errors of
$O_\varepsilon(\sqrt{n})$ in the central model of differential privacy (DP).
</p>
<p>In this work, we provide an algorithm with a nearly matching error guarantee
of $\tilde{O}_\varepsilon(\sqrt{n})$ in the shuffle DP and pan-private models.
Our algorithm is very simple: it just post-processes the discrete
Laplace-noised histogram! Using this algorithm as a subroutine, we show
applications in privately estimating symmetric properties of distributions such
as entropy, support coverage, and support size.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T00:30:00Z">Friday, October 28 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15193'>A framework of distributionally robust possibilistic optimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Romain Guillaume, Adam Kasperski, Pawel Zielinski</p><p>In this paper, an optimization problem with uncertain constraint coefficients
is considered. Possibility theory is used to model the uncertainty. Namely, a
joint possibility distribution in constraint coefficient realizations, called
scenarios, is specified. This possibility distribution induces a necessity
measure in scenario set, which in turn describes an ambiguity set of
probability distributions in scenario set. The distributionally robust approach
is then used to convert the imprecise constraints into deterministic
equivalents. Namely, the left-hand side of an imprecise constraint is evaluated
by using a risk measure with respect to the worst probability distribution that
can occur. In this paper, the Conditional Value at Risk is used as the risk
measure, which generalizes the strict robust and expected value approaches,
commonly used in literature. A general framework for solving such a class of
problems is described. Some cases which can be solved in polynomial time are
identified.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Guillaume_R/0/1/0/all/0/1">Romain Guillaume</a>, <a href="http://arxiv.org/find/math/1/au:+Kasperski_A/0/1/0/all/0/1">Adam Kasperski</a>, <a href="http://arxiv.org/find/math/1/au:+Zielinski_P/0/1/0/all/0/1">Pawel Zielinski</a></p><p>In this paper, an optimization problem with uncertain constraint coefficients
is considered. Possibility theory is used to model the uncertainty. Namely, a
joint possibility distribution in constraint coefficient realizations, called
scenarios, is specified. This possibility distribution induces a necessity
measure in scenario set, which in turn describes an ambiguity set of
probability distributions in scenario set. The distributionally robust approach
is then used to convert the imprecise constraints into deterministic
equivalents. Namely, the left-hand side of an imprecise constraint is evaluated
by using a risk measure with respect to the worst probability distribution that
can occur. In this paper, the Conditional Value at Risk is used as the risk
measure, which generalizes the strict robust and expected value approaches,
commonly used in literature. A general framework for solving such a class of
problems is described. Some cases which can be solved in polynomial time are
identified.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T00:30:00Z">Friday, October 28 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15421'>AnyDijkstra, an algorithm to compute shortest paths on images with anytime properties</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Diego Ulisse Pizzagalli, Rolf Krause</p><p>Images conveniently capture the result of physical processes, representing
rich source of information for data driven medicine, engineering, and science.
The modeling of an image as a graph allows the application of graph-based
algorithms for content analysis. Amongst these, one of the most used is the
Dijkstra Single Source Shortest Path algorithm (DSSSP), which computes the path
with minimal cost from one starting node to all the other nodes of the graph.
However, the results of DSSSP remains unknown for nodes until they are
explored. Moreover, DSSSP execution is associated to frequent jumps between
distant locations in the graph, which results in non-optimal memory access,
reduced parallelization, and finally increased execution time. Therefore, we
propose AnyDijkstra, an iterative implementation of the Dijkstra SSSP algorithm
optimized for images, that retains anytime properties while accessing memory
following a cache-friendly scheme and maximizing parallelization.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pizzagalli_D/0/1/0/all/0/1">Diego Ulisse Pizzagalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_R/0/1/0/all/0/1">Rolf Krause</a></p><p>Images conveniently capture the result of physical processes, representing
rich source of information for data driven medicine, engineering, and science.
The modeling of an image as a graph allows the application of graph-based
algorithms for content analysis. Amongst these, one of the most used is the
Dijkstra Single Source Shortest Path algorithm (DSSSP), which computes the path
with minimal cost from one starting node to all the other nodes of the graph.
However, the results of DSSSP remains unknown for nodes until they are
explored. Moreover, DSSSP execution is associated to frequent jumps between
distant locations in the graph, which results in non-optimal memory access,
reduced parallelization, and finally increased execution time. Therefore, we
propose AnyDijkstra, an iterative implementation of the Dijkstra SSSP algorithm
optimized for images, that retains anytime properties while accessing memory
following a cache-friendly scheme and maximizing parallelization.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T00:30:00Z">Friday, October 28 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15439'>Learning versus Refutation in Noninteractive Local Differential Privacy</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Edmonds, Aleksandar Nikolov, Toniann Pitassi</p><p>We study two basic statistical tasks in non-interactive local differential
privacy (LDP): learning and refutation. Learning requires finding a concept
that best fits an unknown target function (from labelled samples drawn from a
distribution), whereas refutation requires distinguishing between data
distributions that are well-correlated with some concept in the class, versus
distributions where the labels are random. Our main result is a complete
characterization of the sample complexity of agnostic PAC learning for
non-interactive LDP protocols. We show that the optimal sample complexity for
any concept class is captured by the approximate $\gamma_2$~norm of a natural
matrix associated with the class. Combined with previous work [Edmonds, Nikolov
and Ullman, 2019] this gives an equivalence between learning and refutation in
the agnostic setting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Edmonds_A/0/1/0/all/0/1">Alexander Edmonds</a>, <a href="http://arxiv.org/find/stat/1/au:+Nikolov_A/0/1/0/all/0/1">Aleksandar Nikolov</a>, <a href="http://arxiv.org/find/stat/1/au:+Pitassi_T/0/1/0/all/0/1">Toniann Pitassi</a></p><p>We study two basic statistical tasks in non-interactive local differential
privacy (LDP): learning and refutation. Learning requires finding a concept
that best fits an unknown target function (from labelled samples drawn from a
distribution), whereas refutation requires distinguishing between data
distributions that are well-correlated with some concept in the class, versus
distributions where the labels are random. Our main result is a complete
characterization of the sample complexity of agnostic PAC learning for
non-interactive LDP protocols. We show that the optimal sample complexity for
any concept class is captured by the approximate $\gamma_2$~norm of a natural
matrix associated with the class. Combined with previous work [Edmonds, Nikolov
and Ullman, 2019] this gives an equivalence between learning and refutation in
the agnostic setting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T00:30:00Z">Friday, October 28 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.15630'>In-stream Probabilistic Cardinality Estimation for Bloom Filters</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Remy Scholler, Jean-Francois Couchot, Oumaima Alaoui-Ismaili, Denis Renaud, Eric Ballot</p><p>The amount of data coming from different sources such as IoT-sensors, social
networks, cellular networks, has increased exponentially during the last few
years. Probabilistic Data Structures (PDS) are efficient alternatives to
deterministic data structures suitable for large data processing and streaming
applications. They are mainly used for approximate membership queries,
frequency count, cardinality estimation and similarity research. Finding the
number of distinct elements in a large dataset or in streaming data is an
active research area. In this work, we show that usual methods based on Bloom
filters for this kind of cardinality estimation are relatively accurate on
average but have a high variance. Therefore, reducing this variance is
interesting to obtain accurate statistics. We propose a probabilistic approach
to estimate more accurately the cardinality of a Bloom filter based on its
parameters, i.e., number of hash functions $k$, size $m$, and a counter $s$
which is incremented whenever an element is not in the filter (i.e., when the
result of the membership query for this element is negative). The value of the
counter can never be larger than the exact cardinality due to the Bloom
filter's nature, but hash collisions can cause it to underestimate it. This
creates a counting error that we estimate accurately, in-stream, along with its
standard deviation. We also discuss a way to optimize the parameters of a Bloom
filter based on its counting error. We evaluate our approach with synthetic
data created from an analysis of a real mobility dataset provided by a mobile
network operator in the form of displacement matrices computed from mobile
phone records. The approach proposed here performs at least as well on average
and has a much lower variance (about 6 to 7 times less) than state of the art
methods.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Scholler_R/0/1/0/all/0/1">Remy Scholler</a>, <a href="http://arxiv.org/find/cs/1/au:+Couchot_J/0/1/0/all/0/1">Jean-Francois Couchot</a>, <a href="http://arxiv.org/find/cs/1/au:+Alaoui_Ismaili_O/0/1/0/all/0/1">Oumaima Alaoui-Ismaili</a>, <a href="http://arxiv.org/find/cs/1/au:+Renaud_D/0/1/0/all/0/1">Denis Renaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballot_E/0/1/0/all/0/1">Eric Ballot</a></p><p>The amount of data coming from different sources such as IoT-sensors, social
networks, cellular networks, has increased exponentially during the last few
years. Probabilistic Data Structures (PDS) are efficient alternatives to
deterministic data structures suitable for large data processing and streaming
applications. They are mainly used for approximate membership queries,
frequency count, cardinality estimation and similarity research. Finding the
number of distinct elements in a large dataset or in streaming data is an
active research area. In this work, we show that usual methods based on Bloom
filters for this kind of cardinality estimation are relatively accurate on
average but have a high variance. Therefore, reducing this variance is
interesting to obtain accurate statistics. We propose a probabilistic approach
to estimate more accurately the cardinality of a Bloom filter based on its
parameters, i.e., number of hash functions $k$, size $m$, and a counter $s$
which is incremented whenever an element is not in the filter (i.e., when the
result of the membership query for this element is negative). The value of the
counter can never be larger than the exact cardinality due to the Bloom
filter's nature, but hash collisions can cause it to underestimate it. This
creates a counting error that we estimate accurately, in-stream, along with its
standard deviation. We also discuss a way to optimize the parameters of a Bloom
filter based on its counting error. We evaluate our approach with synthetic
data created from an analysis of a real mobility dataset provided by a mobile
network operator in the form of displacement matrices computed from mobile
phone records. The approach proposed here performs at least as well on average
and has a much lower variance (about 6 to 7 times less) than state of the art
methods.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-28T00:30:00Z">Friday, October 28 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, October 27
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/27/postdoctoral-fellowship-the-institute-for-emerging-core-methods-in-data-science-encore-at-university-of-california-san-diego-apply-by-december-15-2022/'>Postdoctoral fellowship – The Institute for Emerging CORE Methods in Data Science (EnCORE) at University of California – San Diego (apply by December 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Multiple postdoctoral fellowship opportunities are available with The Institute for Emerging CORE Methods in Data Science (EnCORE), a TRIPODS Phase II institute funded by the National Science Foundation. The EnCORE Institute is a collaboration of researchers between UC San Diego, UCLA, UT Austin and Penn. Website: academicjobsonline.org/ajo/jobs/23469 Email: bsaha@eng.ucsd.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Multiple postdoctoral fellowship opportunities are available with The Institute for Emerging CORE Methods in Data Science (EnCORE), a TRIPODS Phase II institute funded by the National Science Foundation. The EnCORE Institute is a collaboration of researchers between UC San Diego, UCLA, UT Austin and Penn.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/23469">https://academicjobsonline.org/ajo/jobs/23469</a><br />
Email: bsaha@eng.ucsd.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T23:19:32Z">Thursday, October 27 2022, 23:19</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/27/postdoc-at-sandia-national-labs-apply-by-december-20-2022/'>postdoc at Sandia National Labs (apply by December 20, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Sandia Labs is seeking a postdoc to work on quantum or quantum-inspired classical approximation, sublinear, or streaming algorithms, as part of a DOE-funded collaboration among several national labs and universities. We encourage theoretical computer scientists interested in quantum information but without prior expertise to apply! Website: far-qc.sandia.gov/job-opportunities/ Email: odparek@sandia.gov
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Sandia Labs is seeking a postdoc to work on quantum or quantum-inspired classical approximation, sublinear, or streaming algorithms, as part of a DOE-funded collaboration among several national labs and universities. We encourage theoretical computer scientists interested in quantum information but without prior expertise to apply!</p>
<p>Website: <a href="https://far-qc.sandia.gov/job-opportunities/">https://far-qc.sandia.gov/job-opportunities/</a><br />
Email: odparek@sandia.gov</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T20:38:30Z">Thursday, October 27 2022, 20:38</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/10/the-media-coverage-of-matrix-result-is.html'>The Media Coverage of the Matrix result is Terrible (though not worse than usual)</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;BILL: A computer program (or an AI or an ML or whatever) found a BETTER way to do matrix mult! Its in the same spirit as Strassen. I've always wondered if Strassen was practical&nbsp; since it is simple, and computers have come a long way since 1969, though I suspect not (I WAS WRONG ABOUT THAT). I'll blog about and ask if Strassen will ever be used/practical&nbsp; &nbsp;(I did that post&nbsp;here).</p><p>READERS: Uh, Bill,&nbsp; (1) Strassen IS used and practical and (2) the new algorithm only works in&nbsp; GF(2). (Lance did a post about the new algorithm where he makes this explicit&nbsp;here.) Some readers claimed it was GF(2^k) and some that it was fields if char 2. In any case NO it is not a general algorithm.</p><p>BILL: There is good news and what others might consider bad news but I do not.</p><p>GOOD NEWS: I learned that Strassen IS practical and used, which I did not know.&nbsp;</p><p>GOOD NEWS: I learned that I was WRONG about the new algorithm since I just assumed it worked in general, and updated the post so others would not be deceived.&nbsp;</p><p>BAD NEWS: Darling asked if I was embarrassed to be wrong. If I am embarrassed that easily I would have quit blogging in 2009.&nbsp;</p><p>DARLING: So Bill, how did you get it so wrong?</p><p>BILL: Well obviously my bad for not doing my due diligence. But that's not what's interesting. What's interesting is that if you read the articles about it for the popular press you would have NO IDEA that it only works for mod 2. Its like reading that quantum computing will solve world hunger.</p><p>DARLING: It won't?</p><p>BILL: No it won't.&nbsp;</p><p>DARLING: I was being sarcastic.&nbsp;</p><p>BILL: Anyway, the coverage pushed two points</p><p>a) IMPRESSIVE that a computer could FIND these things that humans could not. This is TRUE (gee, how do I know that? The Gell-Mann Effect,&nbsp; is that people disgusted when they read a newspaper article on something they know about and find the mistakes later assume that the other articles are fine. SHOUT OUT to Jim Hefferon who telling me the name Gell-Mann Effect and left a comment with a pointer. The original version of this post had a BLANK there.)&nbsp;</p><p>b) The algorithm is practical! They did not quite say that but it was implied. And certainly there was NO mention of it only working in GF(2). And I was fooled into thinking that it might be competitive with Strassen.&nbsp;</p><p>READERS (of this blog entry, I predict) Uh, Bill, the popular press getting science news wrong and saying its more practical than it is probably predates the Bible. I can imagine&nbsp; the Cairo Times in 2000BC writing&nbsp;`Scientists discover that in any right triangle with sides a,b,c&nbsp; a^2+b^2=c^2 and this will enable us to build food silos and cure Hunger. In reality they knew that the 3,4,5 triangle was a right triangle, were no where near a proof of a general theorem, and I doubt it would have helped cure hunger.&nbsp;</p><p>BILL: This time the news was REALLY CLOSE to what I do (if&nbsp; R(5) is found by a computer and the media claims its practical I'll either have a very angry blog or repost my April Fools' day article on Ramsey Theory's application to&nbsp; History) AND I posted incorrectly about it. So, to quote many a bad movie</p><p>THIS TIME ITS PERSONAL!</p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;BILL: A computer program (or an AI or an ML or whatever) found a BETTER way to do matrix mult! Its in the same spirit as Strassen. I've always wondered if Strassen was practical&nbsp; since it is simple, and computers have come a long way since 1969, though I suspect not (I WAS WRONG ABOUT THAT). I'll blog about and ask if Strassen will ever be used/practical&nbsp; &nbsp;(I did that post&nbsp;<a href="https://blog.computationalcomplexity.org/2022/10/will-strassens-matrix-mult-alg-ever-be.html">here</a>).</p><p>READERS: Uh, Bill,&nbsp; (1) Strassen IS used and practical and (2) the new algorithm only works in&nbsp; GF(2). (Lance did a post about the new algorithm where he makes this explicit&nbsp;<a href="https://blog.computationalcomplexity.org/2022/10/alpha-tensor.html">here</a>.) Some readers claimed it was GF(2^k) and some that it was fields if char 2. In any case NO it is not a general algorithm.</p><p>BILL: There is good news and what others might consider bad news but I do not.</p><p>GOOD NEWS: I learned that Strassen IS practical and used, which I did not know.&nbsp;</p><p>GOOD NEWS: I learned that I was WRONG about the new algorithm since I just assumed it worked in general, and updated the post so others would not be deceived.&nbsp;</p><p>BAD NEWS: Darling asked if I was embarrassed to be wrong. If I am embarrassed that easily I would have quit blogging in 2009.&nbsp;</p><p>DARLING: So Bill, how did you get it so wrong?</p><p>BILL: Well obviously my bad for not doing my due diligence. But that's not what's interesting. What's interesting is that if you read the articles about it for the popular press you would have NO IDEA that it only works for mod 2. Its like reading that quantum computing will solve world hunger.</p><p>DARLING: It won't?</p><p>BILL: No it won't.&nbsp;</p><p>DARLING: I was being sarcastic.&nbsp;</p><p>BILL: Anyway, the coverage pushed two points</p><p>a) IMPRESSIVE that a computer could FIND these things that humans could not. This is TRUE (gee, how do I know that? <i>The Gell-Mann Effec</i>t,&nbsp; is that people disgusted when they read a newspaper article on something they know about and find the mistakes later assume that the other articles are fine. SHOUT OUT to Jim Hefferon who telling me the name <i>Gell-Mann Effect</i> and left a comment with a pointer. The original version of this post had a BLANK there.)&nbsp;</p><p>b) The algorithm is practical! They did not quite say that but it was implied. And certainly there was NO mention of it only working in GF(2). And I was fooled into thinking that it might be competitive with Strassen.&nbsp;</p><p>READERS (of this blog entry, I predict) Uh, Bill, the popular press getting science news wrong and saying its more practical than it is probably predates the Bible. I can imagine&nbsp; the Cairo Times in 2000BC writing&nbsp;<i>`Scientists discover that in any right triangle with sides a,b,c&nbsp; a^2+b^2=c^2 and this will</i> <i>enable us to build food silos and cure Hunger</i>. In reality they knew that the 3,4,5 triangle was a right triangle, were no where near a proof of a general theorem, and I doubt it would have helped cure hunger.&nbsp;</p><p>BILL: This time the news was REALLY CLOSE to what I do (if&nbsp; R(5) is found by a computer and the media claims its practical I'll either have a very angry blog or repost my April Fools' day article on Ramsey Theory's application to&nbsp; History) AND I posted incorrectly about it. So, to quote many a bad movie</p><p><b>THIS TIME ITS PERSONAL!</b></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T11:46:00Z">Thursday, October 27 2022, 11:46</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14259'>Net Separation-Oriented Printed Circuit Board Placement via Margin Maximization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chung-Kuan Cheng, Chia-Tung Ho, Chester Holtz</p><p>Packaging has become a crucial process due to the paradigm shift of More than
Moore. Addressing manufacturing and yield issues is a significant challenge for
modern layout algorithms.
</p>
<p>We propose to use printed circuit board (PCB) placement as a benchmark for
the packaging problem. A maximum-margin formulation is devised to improve the
separation between nets. Our framework includes seed layout proposals, a
coordinate descent-based procedure to optimize routability, and a mixed-integer
linear programming method to legalize the layout. We perform an extensive study
with 14 PCB designs and an open-source router. We show that the placements
produced by NS-place improve routed wirelength by up to 25\%, reduce the number
of vias by up to 50\%, and reduce the number of DRVs by 79\% compared to manual
and wirelength-minimal placements.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Chung-Kuan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_C/0/1/0/all/0/1">Chia-Tung Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Holtz_C/0/1/0/all/0/1">Chester Holtz</a></p><p>Packaging has become a crucial process due to the paradigm shift of More than
Moore. Addressing manufacturing and yield issues is a significant challenge for
modern layout algorithms.
</p>
<p>We propose to use printed circuit board (PCB) placement as a benchmark for
the packaging problem. A maximum-margin formulation is devised to improve the
separation between nets. Our framework includes seed layout proposals, a
coordinate descent-based procedure to optimize routability, and a mixed-integer
linear programming method to legalize the layout. We perform an extensive study
with 14 PCB designs and an open-source router. We show that the placements
produced by NS-place improve routed wirelength by up to 25\%, reduce the number
of vias by up to 50\%, and reduce the number of DRVs by 79\% compared to manual
and wirelength-minimal placements.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14736'>An Optimal Lower Bound for Simplex Range Reporting</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Peyman Afshani, Pingan Cheng</p><p>We give a simplified and improved lower bound for the simplex range reporting
problem. We show that given a set $P$ of $n$ points in $\mathbb{R}^d$, any data
structure that uses $S(n)$ space to answer such queries must have
$Q(n)=\Omega((n^2/S(n))^{(d-1)/d}+k)$ query time, where $k$ is the output size.
For near-linear space data structures, i.e., $S(n)=O(n\log^{O(1)}n)$, this
improves the previous lower bounds by Chazelle and Rosenberg [CR96] and Afshani
[A12] but perhaps more importantly, it is the first ever tight lower bound for
any variant of simplex range searching for $d\ge 3$ dimensions.
</p>
<p>We obtain our lower bound by making a simple connection to well-studied
problems in incident geometry which allows us to use known constructions in the
area. We observe that a small modification of a simple already existing
construction can lead to our lower bound. We believe that our proof is
accessible to a much wider audience, at least compared to the previous
intricate probabilistic proofs based on measure arguments by Chazelle and
Rosenberg [CR96] and Afshani [A12].
</p>
<p>The lack of tight or almost-tight (up to polylogarithmic factor) lower bounds
for near-linear space data structures is a major bottleneck in making progress
on problems such as proving lower bounds for multilevel data structures. It is
our hope that this new line of attack based on incidence geometry can lead to
further progress in this area.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Afshani_P/0/1/0/all/0/1">Peyman Afshani</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1">Pingan Cheng</a></p><p>We give a simplified and improved lower bound for the simplex range reporting
problem. We show that given a set $P$ of $n$ points in $\mathbb{R}^d$, any data
structure that uses $S(n)$ space to answer such queries must have
$Q(n)=\Omega((n^2/S(n))^{(d-1)/d}+k)$ query time, where $k$ is the output size.
For near-linear space data structures, i.e., $S(n)=O(n\log^{O(1)}n)$, this
improves the previous lower bounds by Chazelle and Rosenberg [CR96] and Afshani
[A12] but perhaps more importantly, it is the first ever tight lower bound for
any variant of simplex range searching for $d\ge 3$ dimensions.
</p>
<p>We obtain our lower bound by making a simple connection to well-studied
problems in incident geometry which allows us to use known constructions in the
area. We observe that a small modification of a simple already existing
construction can lead to our lower bound. We believe that our proof is
accessible to a much wider audience, at least compared to the previous
intricate probabilistic proofs based on measure arguments by Chazelle and
Rosenberg [CR96] and Afshani [A12].
</p>
<p>The lack of tight or almost-tight (up to polylogarithmic factor) lower bounds
for near-linear space data structures is a major bottleneck in making progress
on problems such as proving lower bounds for multilevel data structures. It is
our hope that this new line of attack based on incidence geometry can lead to
further progress in this area.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14664'>Coresets for Vertical Federated Learning: Regularized Linear Regression and $K$-Means Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lingxiao Huang, Zhize Li, Jialin Sun, Haoyu Zhao</p><p>Vertical federated learning (VFL), where data features are stored in multiple
parties distributively, is an important area in machine learning. However, the
communication complexity for VFL is typically very high. In this paper, we
propose a unified framework by constructing coresets in a distributed fashion
for communication-efficient VFL. We study two important learning tasks in the
VFL setting: regularized linear regression and $k$-means clustering, and apply
our coreset framework to both problems. We theoretically show that using
coresets can drastically alleviate the communication complexity, while nearly
maintain the solution quality. Numerical experiments are conducted to
corroborate our theoretical findings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhize Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jialin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haoyu Zhao</a></p><p>Vertical federated learning (VFL), where data features are stored in multiple
parties distributively, is an important area in machine learning. However, the
communication complexity for VFL is typically very high. In this paper, we
propose a unified framework by constructing coresets in a distributed fashion
for communication-efficient VFL. We study two important learning tasks in the
VFL setting: regularized linear regression and $k$-means clustering, and apply
our coreset framework to both problems. We theoretically show that using
coresets can drastically alleviate the communication complexity, while nearly
maintain the solution quality. Numerical experiments are conducted to
corroborate our theoretical findings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14315'>Streaming Submodular Maximization with Differential Privacy</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anamay Chaturvedi, Huy L&#xea; Nguyen, Thy Nguyen</p><p>In this work, we study the problem of privately maximizing a submodular
function in the streaming setting. Extensive work has been done on privately
maximizing submodular functions in the general case when the function depends
upon the private data of individuals. However, when the size of the data stream
drawn from the domain of the objective function is large or arrives very fast,
one must privately optimize the objective within the constraints of the
streaming setting. We establish fundamental differentially private baselines
for this problem and then derive better trade-offs between privacy and utility
for the special case of decomposable submodular functions. A submodular
function is decomposable when it can be written as a sum of submodular
functions; this structure arises naturally when each summand function models
the utility of an individual and the goal is to study the total utility of the
whole population as in the well-known Combinatorial Public Projects Problem.
Finally, we complement our theoretical analysis with experimental
corroboration.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chaturvedi_A/0/1/0/all/0/1">Anamay Chaturvedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Huy L&#xea; Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thy Nguyen</a></p><p>In this work, we study the problem of privately maximizing a submodular
function in the streaming setting. Extensive work has been done on privately
maximizing submodular functions in the general case when the function depends
upon the private data of individuals. However, when the size of the data stream
drawn from the domain of the objective function is large or arrives very fast,
one must privately optimize the objective within the constraints of the
streaming setting. We establish fundamental differentially private baselines
for this problem and then derive better trade-offs between privacy and utility
for the special case of decomposable submodular functions. A submodular
function is decomposable when it can be written as a sum of submodular
functions; this structure arises naturally when each summand function models
the utility of an individual and the goal is to study the total utility of the
whole population as in the well-known Combinatorial Public Projects Problem.
Finally, we complement our theoretical analysis with experimental
corroboration.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14582'>WebCrack: Dynamic Dictionary Adjustment for Web Weak Password Detection based on Blasting Response Event Discrimination</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiang Long, Yan Huang, Zhendong Liu, Lansheng Han, Haili Sun, Jingyuan He</p><p>The feature diversity of different web systems in page elements, submission
contents and return information makes it difficult to detect weak password
automatically. To solve this problem, multi-factor correlation detection method
as integrated in the DBKER algorithm is proposed to achieve automatic detection
of web weak passwords and universal passwords. It generates password
dictionaries based on PCFG algorithm, proposes to judge blasting result via 4
steps with traditional static keyword features and dynamic page feature
information. Then the blasting failure events are discriminated and the
usernames are blasted based on response time. Thereafter the weak password
dictionary is dynamically adjusted according to the hints provided by the
response failure page. Based on the algorithm, this paper implements a
detection system named WebCrack. Experimental results of two blasting tests on
DedeCMS and Discuz! systems as well as a random backend test show that the
proposed method can detect weak passwords and universal passwords of various
web systems with an average accuracy rate of about 93.75%, providing security
advisories for users' password settings with strong practicability.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Long_X/0/1/0/all/0/1">Xiang Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhendong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Lansheng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haili Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jingyuan He</a></p><p>The feature diversity of different web systems in page elements, submission
contents and return information makes it difficult to detect weak password
automatically. To solve this problem, multi-factor correlation detection method
as integrated in the DBKER algorithm is proposed to achieve automatic detection
of web weak passwords and universal passwords. It generates password
dictionaries based on PCFG algorithm, proposes to judge blasting result via 4
steps with traditional static keyword features and dynamic page feature
information. Then the blasting failure events are discriminated and the
usernames are blasted based on response time. Thereafter the weak password
dictionary is dynamically adjusted according to the hints provided by the
response failure page. Based on the algorithm, this paper implements a
detection system named WebCrack. Experimental results of two blasting tests on
DedeCMS and Discuz! systems as well as a random backend test show that the
proposed method can detect weak passwords and universal passwords of various
web systems with an average accuracy rate of about 93.75%, providing security
advisories for users' password settings with strong practicability.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14608'>Inapproximability of shortest paths on perfect matching polytopes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jean Cardinal, Raphael Steiner</p><p>We consider the computational problem of finding short paths in the skeleton
of the perfect matching polytope of a bipartite graph. We prove that unless
$P=NP$, there is no polynomial-time algorithm that computes a path of constant
length between two vertices at distance two of the perfect matching polytope of
a bipartite graph. Conditioned on $P\neq NP$, this disproves a conjecture by
Ito, Kakimura, Kamiyama, Kobayashi and Okamoto [SIAM Journal on Discrete
Mathematics, 36(2), pp. 1102-1123 (2022)]. Assuming the Exponential Time
Hypothesis we prove the stronger result that there exists no polynomial-time
algorithm computing a path of length at most
$\left(\frac{1}{4}-o(1)\right)\frac{\log N}{\log \log N}$ between two vertices
at distance two of the perfect matching polytope of an $N$-vertex bipartite
graph. These results remain true if the bipartite graph is restricted to be of
maximum degree three. The above has the following interesting implication for
the performance of pivot rules for the simplex algorithm on simply-structured
combinatorial polytopes: If $P\neq NP$, then for every simplex pivot rule
executable in polynomial time and every constant $k \in \mathbb{N}$ there
exists a linear program on a perfect matching polytope and a starting vertex of
the polytope such that the optimal solution can be reached in two monotone
steps from the starting vertex, yet the pivot rule will require at least $k$
steps to reach the optimal solution. This result remains true in the more
general setting of pivot rules for so-called circuit-augmentation algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Cardinal_J/0/1/0/all/0/1">Jean Cardinal</a>, <a href="http://arxiv.org/find/math/1/au:+Steiner_R/0/1/0/all/0/1">Raphael Steiner</a></p><p>We consider the computational problem of finding short paths in the skeleton
of the perfect matching polytope of a bipartite graph. We prove that unless
$P=NP$, there is no polynomial-time algorithm that computes a path of constant
length between two vertices at distance two of the perfect matching polytope of
a bipartite graph. Conditioned on $P\neq NP$, this disproves a conjecture by
Ito, Kakimura, Kamiyama, Kobayashi and Okamoto [SIAM Journal on Discrete
Mathematics, 36(2), pp. 1102-1123 (2022)]. Assuming the Exponential Time
Hypothesis we prove the stronger result that there exists no polynomial-time
algorithm computing a path of length at most
$\left(\frac{1}{4}-o(1)\right)\frac{\log N}{\log \log N}$ between two vertices
at distance two of the perfect matching polytope of an $N$-vertex bipartite
graph. These results remain true if the bipartite graph is restricted to be of
maximum degree three. The above has the following interesting implication for
the performance of pivot rules for the simplex algorithm on simply-structured
combinatorial polytopes: If $P\neq NP$, then for every simplex pivot rule
executable in polynomial time and every constant $k \in \mathbb{N}$ there
exists a linear program on a perfect matching polytope and a starting vertex of
the polytope such that the optimal solution can be reached in two monotone
steps from the starting vertex, yet the pivot rule will require at least $k$
steps to reach the optimal solution. This result remains true in the more
general setting of pivot rules for so-called circuit-augmentation algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14629'>Highly unbreakable graph with a fixed excluded minor are almost rigid</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Lokshtanov, Marcin Pilipczuk, Micha&#x142; Pilipczuk, Saket Saurabh</p><p>A set $X \subseteq V(G)$ in a graph $G$ is $(q,k)$-unbreakable if every
separation $(A,B)$ of order at most $k$ in $G$ satisfies $|A \cap X| \leq q$ or
$|B \cap X| \leq q$. In this paper, we prove the following result: If a graph
$G$ excludes a fixed complete graph $K_h$ as a minor and satisfies certain
unbreakability guarantees, then $G$ is almost rigid in the following sense: the
vertices of $G$ can be partitioned in an isomorphism-invariant way into a part
inducing a graph of bounded treewidth and a part that admits a small
isomorphism-invariant family of labelings. This result is the key ingredient in
the fixed-parameter algorithm for Graph Isomorphism parameterized by the
Hadwiger number of the graph, which is presented in a companion paper.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Lokshtanov_D/0/1/0/all/0/1">Daniel Lokshtanov</a>, <a href="http://arxiv.org/find/math/1/au:+Pilipczuk_M/0/1/0/all/0/1">Marcin Pilipczuk</a>, <a href="http://arxiv.org/find/math/1/au:+Pilipczuk_M/0/1/0/all/0/1">Micha&#x142; Pilipczuk</a>, <a href="http://arxiv.org/find/math/1/au:+Saurabh_S/0/1/0/all/0/1">Saket Saurabh</a></p><p>A set $X \subseteq V(G)$ in a graph $G$ is $(q,k)$-unbreakable if every
separation $(A,B)$ of order at most $k$ in $G$ satisfies $|A \cap X| \leq q$ or
$|B \cap X| \leq q$. In this paper, we prove the following result: If a graph
$G$ excludes a fixed complete graph $K_h$ as a minor and satisfies certain
unbreakability guarantees, then $G$ is almost rigid in the following sense: the
vertices of $G$ can be partitioned in an isomorphism-invariant way into a part
inducing a graph of bounded treewidth and a part that admits a small
isomorphism-invariant family of labelings. This result is the key ingredient in
the fixed-parameter algorithm for Graph Isomorphism parameterized by the
Hadwiger number of the graph, which is presented in a companion paper.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14638'>Fixed-parameter tractability of Graph Isomorphism in graphs with an excluded minor</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Lokshtanov, Marcin Pilipczuk, Micha&#x142; Pilipczuk, Saket Saurabh</p><p>We prove that Graph Isomorphism and Canonization in graphs excluding a fixed
graph $H$ as a minor can be solved by an algorithm working in time $f(H)\cdot
n^{O(1)}$, where $f$ is some function. In other words, we show that these
problems are fixed-parameter tractable when parameterized by the size of the
excluded minor, with the caveat that the bound on the running time is not
necessarily computable. The underlying approach is based on decomposing the
graph in a canonical way into unbreakable (intuitively, well-connected) parts,
which essentially provides a reduction to the case where the given
$H$-minor-free graph is unbreakable itself. This is complemented by an analysis
of unbreakable $H$-minor-free graphs, performed in a second subordinate
manuscript, which reveals that every such graph can be canonically decomposed
into a part that admits few automorphisms and a part that has bounded
treewidth.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lokshtanov_D/0/1/0/all/0/1">Daniel Lokshtanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Marcin Pilipczuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Micha&#x142; Pilipczuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1">Saket Saurabh</a></p><p>We prove that Graph Isomorphism and Canonization in graphs excluding a fixed
graph $H$ as a minor can be solved by an algorithm working in time $f(H)\cdot
n^{O(1)}$, where $f$ is some function. In other words, we show that these
problems are fixed-parameter tractable when parameterized by the size of the
excluded minor, with the caveat that the bound on the running time is not
necessarily computable. The underlying approach is based on decomposing the
graph in a canonical way into unbreakable (intuitively, well-connected) parts,
which essentially provides a reduction to the case where the given
$H$-minor-free graph is unbreakable itself. This is complemented by an analysis
of unbreakable $H$-minor-free graphs, performed in a second subordinate
manuscript, which reveals that every such graph can be canonically decomposed
into a part that admits few automorphisms and a part that has bounded
treewidth.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14722'>Online TSP with Known Locations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Evripidis Bampis, Bruno Escoffier, Niklas Hahn, Michalis Xefteris</p><p>In this paper, we consider the Online Traveling Salesperson Problem (OLTSP)
where the locations of the requests are known in advance, but not their arrival
times. We study both the open variant, in which the algorithm is not required
to return to the origin when all the requests are served, as well as the closed
variant, in which the algorithm has to return to the origin after serving all
the requests. Our aim is to measure the impact of the extra knowledge of the
locations on the competitiveness of the problem. We present an online
3/2-competitive algorithm for the general case and a matching lower bound for
both the open and the closed variant. Then, we focus on some interesting metric
spaces (ring, star, semi-line), providing both lower bounds and polynomial time
online algorithms for the problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bampis_E/0/1/0/all/0/1">Evripidis Bampis</a>, <a href="http://arxiv.org/find/cs/1/au:+Escoffier_B/0/1/0/all/0/1">Bruno Escoffier</a>, <a href="http://arxiv.org/find/cs/1/au:+Hahn_N/0/1/0/all/0/1">Niklas Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Xefteris_M/0/1/0/all/0/1">Michalis Xefteris</a></p><p>In this paper, we consider the Online Traveling Salesperson Problem (OLTSP)
where the locations of the requests are known in advance, but not their arrival
times. We study both the open variant, in which the algorithm is not required
to return to the origin when all the requests are served, as well as the closed
variant, in which the algorithm has to return to the origin after serving all
the requests. Our aim is to measure the impact of the extra knowledge of the
locations on the competitiveness of the problem. We present an online
3/2-competitive algorithm for the general case and a matching lower bound for
both the open and the closed variant. Then, we focus on some interesting metric
spaces (ring, star, semi-line), providing both lower bounds and polynomial time
online algorithms for the problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14869'>An Efficient Dynamic Multi-Sources To Single-Destination (DMS-SD) Algorithm In Smart City Navigation Using Adjacent Matrix</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ziren Xiao, Ruxin Xiao, Chang Liu, Honghao Gao, Xiaolong Xu, Shan Luo, Xinheng Wang</p><p>Dijkstra's algorithm is one of the most popular classic path planning
algorithms, achieving optimal solutions across a wide range of challenging
tasks. However, it only calculates the shortest distance from one vertex to
another, which is hard to directly apply to the Dynamic Multi-Sources to
Single-Destination (DMS-SD) problem. This paper proposes a modified Dijkstra
algorithm to address the DMS-SD problem, where the destination can be
dynamically changed. Our method deploys the concept of Adjacent Matrix from
Floyd's algorithm and achieves the goal with mathematical calculations. We
formally show that all-pairs shortest distance information in Floyd's algorithm
is not required in our algorithm. Extensive experiments verify the scalability
and optimality of the proposed method.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1">Ziren Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_R/0/1/0/all/0/1">Ruxin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1">Honghao Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaolong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinheng Wang</a></p><p>Dijkstra's algorithm is one of the most popular classic path planning
algorithms, achieving optimal solutions across a wide range of challenging
tasks. However, it only calculates the shortest distance from one vertex to
another, which is hard to directly apply to the Dynamic Multi-Sources to
Single-Destination (DMS-SD) problem. This paper proposes a modified Dijkstra
algorithm to address the DMS-SD problem, where the destination can be
dynamically changed. Our method deploys the concept of Adjacent Matrix from
Floyd's algorithm and achieves the goal with mathematical calculations. We
formally show that all-pairs shortest distance information in Floyd's algorithm
is not required in our algorithm. Extensive experiments verify the scalability
and optimality of the proposed method.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.14894'>Learning to predict arbitrary quantum processes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hsin-Yuan Huang, Sitan Chen, John Preskill</p><p>We present an efficient machine learning (ML) algorithm for predicting any
unknown quantum process $\mathcal{E}$ over $n$ qubits. For a wide range of
distributions $\mathcal{D}$ on arbitrary $n$-qubit states, we show that this ML
algorithm can learn to predict any local property of the output from the
unknown process $\mathcal{E}$, with a small average error over input states
drawn from $\mathcal{D}$. The ML algorithm is computationally efficient even
when the unknown process is a quantum circuit with exponentially many gates.
Our algorithm combines efficient procedures for learning properties of an
unknown state and for learning a low-degree approximation to an unknown
observable. The analysis hinges on proving new norm inequalities, including a
quantum analogue of the classical Bohnenblust-Hille inequality, which we derive
by giving an improved algorithm for optimizing local Hamiltonians. Overall, our
results highlight the potential for ML models to predict the output of complex
quantum dynamics much faster than the time needed to run the process itself.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Huang_H/0/1/0/all/0/1">Hsin-Yuan Huang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chen_S/0/1/0/all/0/1">Sitan Chen</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Preskill_J/0/1/0/all/0/1">John Preskill</a></p><p>We present an efficient machine learning (ML) algorithm for predicting any
unknown quantum process $\mathcal{E}$ over $n$ qubits. For a wide range of
distributions $\mathcal{D}$ on arbitrary $n$-qubit states, we show that this ML
algorithm can learn to predict any local property of the output from the
unknown process $\mathcal{E}$, with a small average error over input states
drawn from $\mathcal{D}$. The ML algorithm is computationally efficient even
when the unknown process is a quantum circuit with exponentially many gates.
Our algorithm combines efficient procedures for learning properties of an
unknown state and for learning a low-degree approximation to an unknown
observable. The analysis hinges on proving new norm inequalities, including a
quantum analogue of the classical Bohnenblust-Hille inequality, which we derive
by giving an improved algorithm for optimizing local Hamiltonians. Overall, our
results highlight the potential for ML models to predict the output of complex
quantum dynamics much faster than the time needed to run the process itself.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-27T00:30:00Z">Thursday, October 27 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, October 26
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/26/faculty-at-johns-hopkins-university-apply-by-january-6-2023/'>Faculty at Johns Hopkins University (apply by January 6, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Johns Hopkins University’s Department of Computer Science invites applications for tenure-track faculty positions at all levels and across all areas of computer science. We are particularly interested in applicants in computer vision, networked systems, theoretical computer science, and machine learning. Website: cra.org/job/johns-hopkins-university-tenure-track-faculty-department-of-computer-science-4/ Email: fsearch2022@cs.jhu.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Johns Hopkins University’s Department of Computer Science invites applications for tenure-track faculty positions at all levels and across all areas of computer science. We are particularly interested in applicants in computer vision, networked systems, theoretical computer science, and machine learning.</p>
<p>Website: <a href="https://cra.org/job/johns-hopkins-university-tenure-track-faculty-department-of-computer-science-4/">https://cra.org/job/johns-hopkins-university-tenure-track-faculty-department-of-computer-science-4/</a><br />
Email: fsearch2022@cs.jhu.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T22:56:02Z">Wednesday, October 26 2022, 22:56</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/26/tenured-tenure-track-positions-in-computer-science-at-nyu-shanghai-apply-by-february-1-2023/'>Tenured/Tenure-track Positions in Computer Science  at NYU Shanghai (apply by February 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          NYU Shanghai is currently inviting applications for Tenured or Tenure-Track positions in Computer Science. The search is not restricted to any rank and outstanding candidates at all levels are encouraged to apply. We seek candidates who have completed a Ph.D. in Computer Science, or a closely related discipline. We seek candidates in all sub-fields of [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>NYU Shanghai is currently inviting applications for Tenured or Tenure-Track positions in Computer Science. The search is not restricted to any rank and outstanding candidates at all levels are encouraged to apply. We seek candidates who have completed a Ph.D. in Computer Science, or a closely related discipline. We seek candidates in all sub-fields of Computer Science.</p>
<p>Website: <a href="https://apply.interfolio.com/116511">https://apply.interfolio.com/116511</a><br />
Email: shanghai.faculty.recruitment@nyu.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T16:37:08Z">Wednesday, October 26 2022, 16:37</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13741'>Deep Neural Networks as the Semi-classical Limit of Topological Quantum Neural Networks: The problem of generalisation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Antonino Marciano, Deen Chen, Filippo Fabrocini, Chris Fields, Matteo Lulli, Emanuele Zappala</p><p>Deep Neural Networks miss a principled model of their operation. A novel
framework for supervised learning based on Topological Quantum Field Theory
that looks particularly well suited for implementation on quantum processors
has been recently explored. We propose the use of this framework for
understanding the problem of generalization in Deep Neural Networks. More
specifically, in this approach Deep Neural Networks are viewed as the
semi-classical limit of Topological Quantum Neural Networks. A framework of
this kind explains easily the overfitting behavior of Deep Neural Networks
during the training step and the corresponding generalization capabilities.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Marciano_A/0/1/0/all/0/1">Antonino Marciano</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chen_D/0/1/0/all/0/1">Deen Chen</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Fabrocini_F/0/1/0/all/0/1">Filippo Fabrocini</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Fields_C/0/1/0/all/0/1">Chris Fields</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Lulli_M/0/1/0/all/0/1">Matteo Lulli</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zappala_E/0/1/0/all/0/1">Emanuele Zappala</a></p><p>Deep Neural Networks miss a principled model of their operation. A novel
framework for supervised learning based on Topological Quantum Field Theory
that looks particularly well suited for implementation on quantum processors
has been recently explored. We propose the use of this framework for
understanding the problem of generalization in Deep Neural Networks. More
specifically, in this approach Deep Neural Networks are viewed as the
semi-classical limit of Topological Quantum Neural Networks. A framework of
this kind explains easily the overfitting behavior of Deep Neural Networks
during the training step and the corresponding generalization capabilities.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13694'>Worst-Case Adaptive Submodular Cover</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jing Yuan, Shaojie Tang</p><p>In this paper, we study the adaptive submodular cover problem under the
worst-case setting. This problem generalizes many previously studied problems,
namely, the pool-based active learning and the stochastic submodular set cover.
The input of our problem is a set of items (e.g., medical tests) and each item
has a random state (e.g., the outcome of a medical test), whose realization is
initially unknown. One must select an item at a fixed cost in order to observe
its realization. There is an utility function which is defined over items and
their states. Our goal is to sequentially select a group of items to achieve a
``goal value'' while minimizing the maximum cost across realizations (a.k.a.
worst-case cost). To facilitate our study, we introduce a broad class of
stochastic functions, called \emph{worst-case submodular function}. Assume the
utility function is worst-case submodular, we develop a tight $(\log
(Q/\eta)+1)$-approximation policy, where $Q$ is the ``goal value'' and $\eta$
is the minimum gap between $Q$ and any attainable utility value $\hat{Q}&lt;Q$. We
also study a worst-case maximum-coverage problem, whose goal is to select a
group of items to maximize its worst-case utility subject to a budget
constraint. This is a flipped problem of the minimum-cost-cover problem, and to
solve this problem, we develop a tight $(1-1/e)$-approximation solution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Jing Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Shaojie Tang</a></p><p>In this paper, we study the adaptive submodular cover problem under the
worst-case setting. This problem generalizes many previously studied problems,
namely, the pool-based active learning and the stochastic submodular set cover.
The input of our problem is a set of items (e.g., medical tests) and each item
has a random state (e.g., the outcome of a medical test), whose realization is
initially unknown. One must select an item at a fixed cost in order to observe
its realization. There is an utility function which is defined over items and
their states. Our goal is to sequentially select a group of items to achieve a
``goal value'' while minimizing the maximum cost across realizations (a.k.a.
worst-case cost). To facilitate our study, we introduce a broad class of
stochastic functions, called \emph{worst-case submodular function}. Assume the
utility function is worst-case submodular, we develop a tight $(\log
(Q/\eta)+1)$-approximation policy, where $Q$ is the ``goal value'' and $\eta$
is the minimum gap between $Q$ and any attainable utility value $\hat{Q}&lt;Q$. We
also study a worst-case maximum-coverage problem, whose goal is to select a
group of items to maximize its worst-case utility subject to a budget
constraint. This is a flipped problem of the minimum-cost-cover problem, and to
solve this problem, we develop a tight $(1-1/e)$-approximation solution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13706'>Gaussian Mean Testing Made Simple</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ilias Diakonikolas, Daniel M. Kane, Ankit Pensia</p><p>We study the following fundamental hypothesis testing problem, which we term
Gaussian mean testing. Given i.i.d. samples from a distribution $p$ on
$\mathbb{R}^d$, the task is to distinguish, with high probability, between the
following cases: (i) $p$ is the standard Gaussian distribution,
$\mathcal{N}(0,I_d)$, and (ii) $p$ is a Gaussian $\mathcal{N}(\mu,\Sigma)$ for
some unknown covariance $\Sigma$ and mean $\mu \in \mathbb{R}^d$ satisfying
$\|\mu\|_2 \geq \epsilon$. Recent work gave an algorithm for this testing
problem with the optimal sample complexity of $\Theta(\sqrt{d}/\epsilon^2)$.
Both the previous algorithm and its analysis are quite complicated. Here we
give an extremely simple algorithm for Gaussian mean testing with a one-page
analysis. Our algorithm is sample optimal and runs in sample linear time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Diakonikolas_I/0/1/0/all/0/1">Ilias Diakonikolas</a>, <a href="http://arxiv.org/find/math/1/au:+Kane_D/0/1/0/all/0/1">Daniel M. Kane</a>, <a href="http://arxiv.org/find/math/1/au:+Pensia_A/0/1/0/all/0/1">Ankit Pensia</a></p><p>We study the following fundamental hypothesis testing problem, which we term
Gaussian mean testing. Given i.i.d. samples from a distribution $p$ on
$\mathbb{R}^d$, the task is to distinguish, with high probability, between the
following cases: (i) $p$ is the standard Gaussian distribution,
$\mathcal{N}(0,I_d)$, and (ii) $p$ is a Gaussian $\mathcal{N}(\mu,\Sigma)$ for
some unknown covariance $\Sigma$ and mean $\mu \in \mathbb{R}^d$ satisfying
$\|\mu\|_2 \geq \epsilon$. Recent work gave an algorithm for this testing
problem with the optimal sample complexity of $\Theta(\sqrt{d}/\epsilon^2)$.
Both the previous algorithm and its analysis are quite complicated. Here we
give an extremely simple algorithm for Gaussian mean testing with a one-page
analysis. Our algorithm is sample optimal and runs in sample linear time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13739'>Deterministic Small Vertex Connectivity in Almost Linear Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Thatchaphol Saranurak, Sorrachai Yingchareonthawornchai</p><p>In the vertex connectivity problem, given an undirected $n$-vertex $m$-edge
graph $G$, we need to compute the minimum number of vertices that can
disconnect $G$ after removing them. This problem is one of the most
well-studied graph problems. From 2019, a new line of work [Nanongkai et
al.~STOC'19;SODA'20;STOC'21] has used randomized techniques to break the
quadratic-time barrier and, very recently, culminated in an almost-linear time
algorithm via the recently announced maxflow algorithm by Chen et al. In
contrast, all known deterministic algorithms are much slower. The fastest
algorithm [Gabow FOCS'00] takes $O(m(n+\min\{c^{5/2},cn^{3/4}\}))$ time where
$c$ is the vertex connectivity. It remains open whether there exists a
subquadratic-time deterministic algorithm for any constant $c&gt;3$.
</p>
<p>In this paper, we give the first deterministic almost-linear time vertex
connectivity algorithm for all constants $c$. Our running time is
$m^{1+o(1)}2^{O(c^{2})}$ time, which is almost-linear for all $c=o(\sqrt{\log
n})$. This is the first deterministic algorithm that breaks the $O(n^{2})$-time
bound on sparse graphs where $m=O(n)$, which is known for more than 50 years
ago [Kleitman'69]. Towards our result, we give a new reduction framework to
vertex expanders which in turn exploits our new almost-linear time construction
of mimicking network for vertex connectivity. The previous construction by
Kratsch and Wahlstr\"{o}m [FOCS'12] requires large polynomial time and is
randomized.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Saranurak_T/0/1/0/all/0/1">Thatchaphol Saranurak</a>, <a href="http://arxiv.org/find/cs/1/au:+Yingchareonthawornchai_S/0/1/0/all/0/1">Sorrachai Yingchareonthawornchai</a></p><p>In the vertex connectivity problem, given an undirected $n$-vertex $m$-edge
graph $G$, we need to compute the minimum number of vertices that can
disconnect $G$ after removing them. This problem is one of the most
well-studied graph problems. From 2019, a new line of work [Nanongkai et
al.~STOC'19;SODA'20;STOC'21] has used randomized techniques to break the
quadratic-time barrier and, very recently, culminated in an almost-linear time
algorithm via the recently announced maxflow algorithm by Chen et al. In
contrast, all known deterministic algorithms are much slower. The fastest
algorithm [Gabow FOCS'00] takes $O(m(n+\min\{c^{5/2},cn^{3/4}\}))$ time where
$c$ is the vertex connectivity. It remains open whether there exists a
subquadratic-time deterministic algorithm for any constant $c&gt;3$.
</p>
<p>In this paper, we give the first deterministic almost-linear time vertex
connectivity algorithm for all constants $c$. Our running time is
$m^{1+o(1)}2^{O(c^{2})}$ time, which is almost-linear for all $c=o(\sqrt{\log
n})$. This is the first deterministic algorithm that breaks the $O(n^{2})$-time
bound on sparse graphs where $m=O(n)$, which is known for more than 50 years
ago [Kleitman'69]. Towards our result, we give a new reduction framework to
vertex expanders which in turn exploits our new almost-linear time construction
of mimicking network for vertex connectivity. The previous construction by
Kratsch and Wahlstr\"{o}m [FOCS'12] requires large polynomial time and is
randomized.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13755'>Online and Bandit Algorithms Beyond $\ell_p$ Norms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Thomas Kesselheim, Marco Molinaro, Sahil Singla</p><p>Vector norms play a fundamental role in computer science and optimization, so
there is an ongoing effort to generalize existing algorithms to settings beyond
$\ell_\infty$ and $\ell_p$ norms. We show that many online and bandit
applications for general norms admit good algorithms as long as the norm can be
approximated by a function that is ``gradient-stable'', a notion that we
introduce. Roughly it says that the gradient of the function should not
drastically decrease (multiplicatively) in any component as we increase the
input vector. We prove that several families of norms, including all monotone
symmetric norms, admit a gradient-stable approximation, giving us the first
online and bandit algorithms for these norm families.
</p>
<p>In particular, our notion of gradient-stability gives $O\big(\log^2
(\text{dimension})\big)$-competitive algorithms for the symmetric norm
generalizations of Online Generalized Load Balancing and Bandits with
Knapsacks. Our techniques extend to applications beyond symmetric norms as
well, e.g., to Online Vector Scheduling and to Online Generalized Assignment
with Convex Costs. Some key properties underlying our applications that are
implied by gradient-stable approximations are a ``smooth game inequality'' and
an approximate converse to Jensen's inequality.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kesselheim_T/0/1/0/all/0/1">Thomas Kesselheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Molinaro_M/0/1/0/all/0/1">Marco Molinaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1">Sahil Singla</a></p><p>Vector norms play a fundamental role in computer science and optimization, so
there is an ongoing effort to generalize existing algorithms to settings beyond
$\ell_\infty$ and $\ell_p$ norms. We show that many online and bandit
applications for general norms admit good algorithms as long as the norm can be
approximated by a function that is ``gradient-stable'', a notion that we
introduce. Roughly it says that the gradient of the function should not
drastically decrease (multiplicatively) in any component as we increase the
input vector. We prove that several families of norms, including all monotone
symmetric norms, admit a gradient-stable approximation, giving us the first
online and bandit algorithms for these norm families.
</p>
<p>In particular, our notion of gradient-stability gives $O\big(\log^2
(\text{dimension})\big)$-competitive algorithms for the symmetric norm
generalizations of Online Generalized Load Balancing and Bandits with
Knapsacks. Our techniques extend to applications beyond symmetric norms as
well, e.g., to Online Vector Scheduling and to Online Generalized Assignment
with Convex Costs. Some key properties underlying our applications that are
implied by gradient-stable approximations are a ``smooth game inequality'' and
an approximate converse to Jensen's inequality.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13850'>Tight analysis of lazy: an improved algorithm for open online dial-a-ride</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Julia Baligacs, Yann Disser, David Weckbecker</p><p>In the open online dial-a-ride problem, a single server has to carry
transportation requests appearing over time in some metric space, subject to
minimizing the completion time. We improve on the best known upper bounds on
the competitive ratio on general metric spaces and on the half-line, in both,
the preemptive and non-preemptive version of the problem. We achieve this by
revisiting the algorithm Lazy recently suggested in [WAOA, 2022] and giving an
improved and tight analysis. More precisely, we show that it is
$(\frac{3}{2}+\sqrt{11/12}\thickapprox 2.457)$-competitive on general metric
spaces and $(1+\frac{1}{2}(1+\sqrt{3})\approx 2.366)$-competitive on the
half-line.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Baligacs_J/0/1/0/all/0/1">Julia Baligacs</a>, <a href="http://arxiv.org/find/cs/1/au:+Disser_Y/0/1/0/all/0/1">Yann Disser</a>, <a href="http://arxiv.org/find/cs/1/au:+Weckbecker_D/0/1/0/all/0/1">David Weckbecker</a></p><p>In the open online dial-a-ride problem, a single server has to carry
transportation requests appearing over time in some metric space, subject to
minimizing the completion time. We improve on the best known upper bounds on
the competitive ratio on general metric spaces and on the half-line, in both,
the preemptive and non-preemptive version of the problem. We achieve this by
revisiting the algorithm Lazy recently suggested in [WAOA, 2022] and giving an
improved and tight analysis. More precisely, we show that it is
$(\frac{3}{2}+\sqrt{11/12}\thickapprox 2.457)$-competitive on general metric
spaces and $(1+\frac{1}{2}(1+\sqrt{3})\approx 2.366)$-competitive on the
half-line.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13854'>An Improved Algorithm for Open Online Dial-a-Ride</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Julia Baligacs, Yann Disser, Nils Mosis, David Weckbecker</p><p>We consider the open online dial-a-ride problem, where transportation
requests appear online in a metric space and need to be served by a single
server. The objective is to minimize the completion time until all requests
have been served. We present a new, parameterized algorithm for this problem
and prove that it attains a competitive ratio of $1 + \varphi \approx 2.618$
for some choice of its parameter, where $\varphi$ is the golden ratio. This
improves the best known bounds for open online dial-a-ride both for general
metric spaces as well as for the real line. We also give a lower bound
of~$2.457$ for the competitive ratio of our algorithm for any parameter choice.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Baligacs_J/0/1/0/all/0/1">Julia Baligacs</a>, <a href="http://arxiv.org/find/cs/1/au:+Disser_Y/0/1/0/all/0/1">Yann Disser</a>, <a href="http://arxiv.org/find/cs/1/au:+Mosis_N/0/1/0/all/0/1">Nils Mosis</a>, <a href="http://arxiv.org/find/cs/1/au:+Weckbecker_D/0/1/0/all/0/1">David Weckbecker</a></p><p>We consider the open online dial-a-ride problem, where transportation
requests appear online in a metric space and need to be served by a single
server. The objective is to minimize the completion time until all requests
have been served. We present a new, parameterized algorithm for this problem
and prove that it attains a competitive ratio of $1 + \varphi \approx 2.618$
for some choice of its parameter, where $\varphi$ is the golden ratio. This
improves the best known bounds for open online dial-a-ride both for general
metric spaces as well as for the real line. We also give a lower bound
of~$2.457$ for the competitive ratio of our algorithm for any parameter choice.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.13880'>Efficient and Stable Fully Dynamic Facility Location</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sayan Bhattacharya, Silvio Lattanzi, Nikos Parotsidis</p><p>We consider the classic facility location problem in fully dynamic data
streams, where elements can be both inserted and deleted. In this problem, one
is interested in maintaining a stable and high quality solution throughout the
data stream while using only little time per update (insertion or deletion). We
study the problem and provide the first algorithm that at the same time
maintains a constant approximation and incurs polylogarithmic amortized
recourse per update. We complement our theoretical results with an experimental
analysis showing the practical efficiency of our method.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1">Sayan Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Lattanzi_S/0/1/0/all/0/1">Silvio Lattanzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Parotsidis_N/0/1/0/all/0/1">Nikos Parotsidis</a></p><p>We consider the classic facility location problem in fully dynamic data
streams, where elements can be both inserted and deleted. In this problem, one
is interested in maintaining a stable and high quality solution throughout the
data stream while using only little time per update (insertion or deletion). We
study the problem and provide the first algorithm that at the same time
maintains a constant approximation and incurs polylogarithmic amortized
recourse per update. We complement our theoretical results with an experimental
analysis showing the practical efficiency of our method.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:30:00Z">Wednesday, October 26 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://benjamin-recht.github.io/2022/10/26/ai-image-search/'>Does AI Suck at Art?</a></h3>
        <p class='tr-article-feed'>from <a href='http://benjamin-recht.github.io/'>Ben Recht</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>I’ve been researching machine learning for a little over 20 years. For the past five years or so, with the latest wave of AI overpromising, I think I’ve been mostly known as an AI skeptic. But I’ve been engaging with these new AI image generation tools, and they are delightful. They have a lot of promise, and I want to explain why and suggest a few ways to make them even better.</p>

<p>Though I don’t talk about it much, for the past 20 years I’ve also been playing in an ambient shoegazer band called “the fun years.” My bandmate, Isaac Sparks, has been in charge of our visual design from the get-go. Over the years, he’s progressively refined his style, and he has been dipping his toes into the weird world of prompt-to-art.</p>

<p>Last week, we re-released an old single from 2006, and Isaac used midjourney for the cover art. Isaac is a turntablist, and approaches his art similarly to how he approaches searching for records. He seeks out happy accidents that can take on some new life when repurposed in new contexts. The cover of our first CDR, now that’s what i call droning, volume 4, was a photograph Isaac had taken out of my apartment window on a foggy evening. Over time, his covers grew more abstract. The cover of baby it’s cold inside is a collage of close up images of an old paint can Isaac found in the basement of his apartment complex. Most recently, the cover of our latest album typos in your obituary is a photograph of a stark, black, sculpture Isaac made out of wood scraps (He made a similar, Big Lebowski inspired sculpture for the cover art of my book with Steve Wright Optimization for Data Analysis).</p>

<p>For our new single, Isaac tried to come up with a midjourney prompt that captured the appropriate aesthetic of a fun years cover. It only took a couple of iterations to get what he wanted:</p>

<blockquote>
  <p>A mess of scrap paper, dull color plastic caps, dust, paint smear, chip, cruft, drinking straw, rusty nails, wooden lath, mold fractal, layers, black and white, realistic</p>
</blockquote>

<p>♦</p>

<p>And we went with the image in the bottom left.</p>

<p>♦</p>

<p>The image didn’t have any obvious visual artifacts and looked like something Isaac might have found out in the world. Having read recent reporting on some rather suspect copyright infringement, Isaac and I wondered if midjourney had obviously just ripped off the image.</p>

<p>For a lot of the early DALL-E memes that I saw on social media, I could often find strikingly similar pictures by pasting the prompt into google image search. But for Isaac’s mess prompt, we came up pretty empty, with some rather hilariously bad results.</p>

<p>♦</p>

<p>♦</p>

<p>Vaishaal Shankar then reminded me that there was a much better image search engine. The original DALL-E model which started the prompt-to-image craze was based on a neural network model called CLIP that learned a model to compare images and text. The model was trained on a huge data set of images paired with captions. It produced two functions: one that mapped images to a code book and one that mapped text to a code book. When you compared codes for two snippets of text, this would tell you how similar the snippets were. When you compared codes of two images, this would tell you how similar the images were. But one of the more amazing things about CLIP is that you could compare the codes of text and images and find images which were similar to the text.</p>

<p>Romain Beaumont built an image search system, clip-retrieval that used CLIP and a new data set LAION-5B consisting of 5 billion images scraped by common crawl. 5 billion! (Insert Dr. Evil meme). Romain hosts a free version of this system, where you type some text, it computes the codebook, and it returns all of the images in LAION-5B which have similar codes to your text. We tried Isaac’s prompt here, and now found some strikingly similar images.</p>

<p>♦</p>

<p>There were hundreds of art pieces and stock photos that captured elements of the spirit of the prompt. Again, with 5 billion images, it’s hard to imagine what’s not in there. But after scrolling through pages of similar images, we couldn’t find any of the four renderings produced by midjourney.</p>

<p>We tried the reverse image search in both clip-retrieval and google, and though we got back some similar textures, we couldn’t find the image itself.</p>

<p>♦</p>

<p>Now, just because we didn’t find our image doesn’t mean it’s not in the corpus somewhere. We looked at around 100 images, but what if we had looked at 1000? Or 10000? Perhaps it’s buried in the corner of some thumbnail in the LAION set. The biggest flaw of these tools is making artist attribution impossible. There should be some simple way of tracing back to the training set. Without traceback and attribution, this is just going to lead to annoying copyright lawsuits like we saw in the early days of sampling in music. We’d be better off if we could avoid those legal battles before they happen.</p>

<p>All that said, it really seems like the midjourney neural nets are doing something more than re-displaying images from the training set. There are certainly billions of amazing textures out in the world, and CLIP-style models make them easier to bring to the surface. But midjourney adds something extra to fuse these textures into something new. It’s much more than a “copyright infringing blur filter” and that’s pretty cool!</p>

<p>I still maintain that AI was and is overhyped. We were promised self-driving cars and cures for cancer, and we ended up with splashy tools for image generation. I’m not sure we can justify the billions of dollars of investment. But the image processing tools are still super fun and I want more to play with, so I’ll be selfish and hope OpenAI raises more money. I hope future variants allow for clearer navigation and enable more intentional sampling and pastiche of the source materials. And I can’t wait until they figure out how to make a plugin for Ableton Live that scours huge audio libraries to produce melted sonic textures. At that point, you won’t hear from me as an AI skeptic anymore as I’ll be blissfully hiding in my music studio.</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I’ve been researching machine learning for a little over 20 years. For the past five years or so, with the latest wave of AI overpromising, I think I’ve been mostly known as an AI skeptic. But I’ve been engaging with these new AI image generation tools, and they are delightful. They have a lot of promise, and I want to explain why and suggest a few ways to make them even better.</p>

<p>Though I don’t talk about it much, for the past 20 years I’ve also been playing in an ambient shoegazer band called <a href="https://thefunyears.bandcamp.com/">“the fun years.”</a> My bandmate, <a href="http://www.isaacsparks.com/">Isaac Sparks</a>, has been in charge of our visual design from the get-go. Over the years, he’s progressively refined his style, and he has been dipping his toes into the weird world of prompt-to-art.</p>

<p>Last week, <a href="https://thefunyears.bandcamp.com/track/electricity-is-a-scarce-commodity">we re-released an old single from 2006</a>, and Isaac used <a href="https://www.midjourney.com/home/">midjourney</a> for the cover art. Isaac is a turntablist, and approaches his art similarly to how he approaches searching for records. He seeks out happy accidents that can take on some new life when repurposed in new contexts. The cover of our first CDR, <a href="https://thefunyears.bandcamp.com/album/now-thats-what-i-call-droning-volume-4"><em>now that’s what i call droning, volume 4</em></a>, was a photograph Isaac had taken out of my apartment window on a foggy evening. Over time, his covers grew more abstract. The cover of <a href="https://thefunyears.bandcamp.com/album/baby-its-cold-inside"><em>baby it’s cold inside</em></a> is a collage of close up images of an old paint can Isaac found in the basement of his apartment complex. Most recently, the cover of our latest album <a href="https://thefunyears.bandcamp.com/album/typos-in-your-obituary"><em>typos in your obituary</em></a> is a photograph of a stark, black, sculpture Isaac made out of wood scraps (He made a similar, Big Lebowski inspired sculpture for the cover art of my book with Steve Wright <a href="https://www.cambridge.org/core/books/optimization-for-data-analysis/C02C3708905D236AA354D1CE1739A6A2"><em>Optimization for Data Analysis</em></a>).</p>

<p>For our new single, Isaac tried to come up with a midjourney prompt that captured the appropriate aesthetic of a fun years cover. It only took a couple of iterations to get what he wanted:</p>

<blockquote>
  <p>A mess of scrap paper, dull color plastic caps, dust, paint smear, chip, cruft, drinking straw, rusty nails, wooden lath, mold fractal, layers, black and white, realistic</p>
</blockquote>

<p class="center"><img src="/assets/ai-art/mid_query_return.jpg" alt="midjourney returns some pretty cool cover art." width="100%" /></p>

<p>And we went with the image in the bottom left.</p>

<p class="center"><img src="/assets/ai-art/EIASC.jpg" alt="cover art of electricity is a scarce commodity." width="100%" /></p>

<p>The image didn’t have any obvious visual artifacts and looked like something Isaac might have found out in the world. Having read <a href="https://www.technologyreview.com/2022/09/16/1059598/this-artist-is-dominating-ai-generated-art-and-hes-not-happy-about-it/">recent reporting</a> on some rather suspect copyright infringement, Isaac and I wondered if midjourney had obviously just ripped off the image.</p>

<p>For a lot of the early <a href="https://openai.com/blog/dall-e/">DALL-E</a> memes that I saw on social media, I could often find strikingly similar pictures by pasting the prompt into google image search. But for Isaac’s mess prompt, we came up pretty empty, with some rather hilariously bad results.</p>

<p class="center"><img src="/assets/ai-art/google_image_stinks.png" alt="google image search results for Isaac's query." width="100%" /></p>

<p class="center"><img src="/assets/ai-art/google_image_stinks2.png" alt="more google image search results." width="100%" /></p>

<p><a href="http://vaishaal.com/">Vaishaal Shankar</a> then reminded me that there was a much better image search engine. The original <a href="https://openai.com/blog/dall-e/">DALL-E</a> model which started the prompt-to-image craze was based on a neural network model called <a href="https://openai.com/blog/clip/">CLIP</a> that learned a model to compare images and text. The model was trained on a huge data set of images paired with captions. It produced two functions: one that mapped images to a code book and one that mapped text to a code book. When you compared codes for two snippets of text, this would tell you how similar the snippets were. When you compared codes of two images, this would tell you how similar the images were. But one of the more amazing things about CLIP is that you could compare the codes of text and images and find images which were similar to the text.</p>

<p><a href="https://github.com/rom1504">Romain Beaumont</a> built an image search system, <a href="https://rom1504.github.io/clip-retrieval">clip-retrieval</a> that used CLIP and a new data set <a href="https://laion.ai/blog/laion-5b/">LAION-5B</a> consisting of 5 billion images scraped by <a href="https://commoncrawl.org/">common crawl</a>. 5 billion! (Insert Dr. Evil meme). Romain hosts a <a href="https://rom1504.github.io/clip-retrieval">free version of this system</a>, where you type some text, it computes the codebook, and it returns all of the images in LAION-5B which have similar codes to your text. We tried Isaac’s prompt here, and now found some strikingly similar images.</p>

<p class="center"><img src="/assets/ai-art/clip-retrieval-works.png" alt="clip-retrieval image search results for Isaac's query." width="100%" /></p>

<p>There were hundreds of art pieces and stock photos that captured elements of the spirit of the prompt. Again, with 5 billion images, it’s hard to imagine what’s not in there. But after scrolling through pages of similar images, we couldn’t find any of the four renderings produced by midjourney.</p>

<p>We tried the reverse image search in both clip-retrieval and google, and though we got back some similar textures, we couldn’t find the image itself.</p>

<p class="center"><img src="/assets/ai-art/clip-retrieval-image-search.png" alt="clip-retrieval reverse image search results for the cover art image." width="100%" /></p>

<p>Now, just because we didn’t find our image doesn’t mean it’s not in the corpus somewhere. We looked at around 100 images, but what if we had looked at 1000? Or 10000? Perhaps it’s buried in the corner of some thumbnail in the LAION set. The biggest flaw of these tools is making artist attribution impossible. There should be some simple way of tracing back to the training set. Without traceback and attribution, this is just going to lead to annoying copyright lawsuits like we saw in the early days of sampling in music. We’d be better off if we could avoid those legal battles before they happen.</p>

<p>All that said, it really seems like the midjourney neural nets are doing something more than re-displaying images from the training set. There are certainly billions of amazing textures out in the world, and CLIP-style models make them easier to bring to the surface. But midjourney adds something extra to fuse these textures into something new. It’s much more than a “copyright infringing blur filter” and that’s pretty cool!</p>

<p>I still maintain that AI was and is overhyped. We were promised self-driving cars and cures for cancer, and we ended up with splashy tools for image generation. I’m not sure we can justify the billions of dollars of investment. But the image processing tools are still super fun and I want more to play with, so I’ll be selfish and hope OpenAI raises more money. I hope future variants allow for clearer navigation and enable more intentional sampling and pastiche of the source materials. And I can’t wait until they figure out how to make a plugin for Ableton Live that scours huge audio libraries to produce melted sonic textures. At that point, you won’t hear from me as an AI skeptic anymore as I’ll be blissfully hiding in my music studio.</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-26T00:00:00Z">Wednesday, October 26 2022, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, October 25
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/25/tenure-track-faculty-at-university-of-rochester-apply-by-december-1-2022/'>Tenure-track Faculty at University of Rochester (apply by December 1, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The department of Computer Science at the University of Rochester is looking to hire three tenure-track faculty. One position is targeting cryptography/security but exceptional theory candidates in all other areas are welcome. Other positions are targeting computer systems and machine learning (broadly construed). Website: www.cs.rochester.edu/about/recruit.html#Faculty Email: kristi@cs.rochester.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The department of Computer Science at the University of Rochester is looking to hire three tenure-track faculty. One position is targeting cryptography/security but exceptional theory candidates in all other areas are welcome. Other positions are targeting computer systems and machine learning (broadly construed).</p>
<p>Website: <a href="https://www.cs.rochester.edu/about/recruit.html#Faculty">https://www.cs.rochester.edu/about/recruit.html#Faculty</a><br />
Email: kristi@cs.rochester.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T17:06:44Z">Tuesday, October 25 2022, 17:06</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
