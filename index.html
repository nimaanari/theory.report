<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-02-08T23:30:28Z">Wednesday, February 08 2023, 23:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, February 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://ptreview.sublinear.info/2023/02/news-for-january-2023/'>News for January 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Welcome to the first batch of 2023. Looks like it&#8217;s going to be a good year, with 5 property testing or related papers (that I could find) already: An efficient asymmetric removal lemma and its limitations, by Lior Gishboliner, Asaf Shapira, and Yuval Wigderson (arXiv). One of the jewels of graph property testing is the [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Welcome to the first batch of 2023. Looks like it&#8217;s going to be a good year, with 5 property testing or related papers (that I could find) already: </p>



<p><strong>An efficient asymmetric removal lemma and its limitations</strong>, by Lior Gishboliner, Asaf Shapira, and Yuval Wigderson (<a href="https://arxiv.org/abs/2301.07693">arXiv</a>). One of the jewels of graph property testing is the triangle removel lemma (and its many generalizations and variants), which relates the number of triangles in a dense graph to its distance from being triangle-free: namely, any graph \(\varepsilon\)-far from being triangle-free must have \(\delta(\varepsilon)n^3\) triangles, where the density \(\delta(\varepsilon)\) only depends on the distance (and not the size of the graph!). This immediately leads to constant-query testers (and even &#8220;proximity-oblivious&#8221; testers) for triangle-freness (and, more generally, pattern-freeness). Unfortunately, the dependence on \(\varepsilon\) is quite bad, essentially a tower-type function (and it is known no polynomial bound is possible). This work attempts to bypass this impossibility result by proving an asymmetric removal lemma, or the form &#8220;any graph \(\varepsilon\)-far from being triangle-free must have \(\mathrm{poly}(\varepsilon)n^5\) 5-cycles&#8221; (and generalizations beyond triangles). This seems like a very interesting direction, with potential applications to property testing, and (who knows!) efficient testers for many properties hithertho only known to be (practically) testable for constant \(\varepsilon\).</p>



<p>Related (more removal lemmata!), a different work on this topic:</p>



<p><strong>The Minimum Degree Removal Lemma Thresholds</strong>, by Lior Gishboliner, Zhihan Jin, and Benny Sudakov (<a href="https://arxiv.org/abs/2301.13789">arXiv</a>). As mentioned above, removal lemmata relate the distance \(\varepsilon\) from being \(H\)-free (for a given subgraph \(H\)) to the density \(\delta(\varepsilon)\) of occurrences of \(H\) in the graph. Sadly, it is known that this density will be superpolynomial (in the distance) unless \(H\) is bipartite… which, while technically still yielding testing algorithms (query complexity independent of the size of the graph!), yields very inefficient testers (very bad dependence on \(\varepsilon\)!). This paper studies one direction to bypass this sad state of affairs: under which additional assumption on the underlying graph (specifically, bounds on its minimum degree) can we obtain a polynomial bound on \(\delta(\varepsilon)\)? And a linear bound? The authors give a tight degree condition for \(\delta(\varepsilon)\) to be polynomial when \(H\) is an odd cycle, and their results for the linear-dependence case establishes a separation between the two. Put differently: obtaining polynomial-query testers via removal lemmas is possible for a strictly larger class of graphs than linear-query ones!</p>



<p>And now, for something completely different: testing binary matrices!</p>



<p><strong>A Note on Property Testing of the Binary Rank</strong>, by Nader H. Bshouty (<a href="https://arxiv.org/abs/2301.04406">arXiv</a>). The binary rank of a matrix \(M\in\{0,1\}^{n\times m}\) is the smallest \(d\) such that there exist \(A\in\{0,1\}^{n\times d}\) and \(B\in\{0,1\}^{d\times m}\) with \(M=AB\); this can also be seen as the minimal number of bipartite cliques needed to partition the edges of a bipartite graph represented by \(M\). One can also define the relaxed notion of \(s\)-binary rank, if one enforces that each edge of the bipartite graph is covered by at most \(s\) bipartite cliques. The property testing question is then to decide, given inputs \(s,d,\varepsilon\), if \(M\) has \(s\)-binary rank at most \(d\), or is \(\varepsilon\)-far from it. The main result of this note is to give one-sided testers (one adaptive, and one non-adaptive) for \(s\)-binary rank with query complexity \(\tilde{O}(2^d)\) (for constant \(s\)), improving on the previous algorithms by a factor \(2^d\).</p>



<p>Into the quantum realm!</p>



<p><strong>Testing quantum satisfiability,</strong> by Ashley Montanaro, Changpeng Shao, and Dominic Verdon (<a href="https://arxiv.org/abs/2301.10699">arXiv</a>). Classically, one can study the property version of \(k\)-SAT, which asks to decide whether a given instance is satisfiable or far from being so. And people (namely, Alon and Shapira, in 2003) did! Quantumly, one can define an analogue of \(k\)-SAT, &#8220;quantum \(k\)-SAT&#8221;: and people (namely, Bravyi, in 2011) did! But what about property testing of quantum \(k\)-SAT? Well, now, people (namely, the authors of this paper) just did! Showing (Corollary 1.10) that one can efficiently distinguish between (1) the quantum \(k\)-SAT is satisfiable, and (2) it is far from satisfiable by a product state. This, effectively, extends the result of Alon–Shapira&#8217;03 to the quantum realm.</p>



<p>And to conclude, a foray into reinforcement learning via distribution testing…</p>



<p><strong>Lower Bounds for Learning in Revealing POMDPs</strong>, by Fan Chen, Huan Wang, Caiming Xiong, Song Mei, and Yu Bai (<a href="https://arxiv.org/abs/2302.01333">arXiv</a>). Alright, I&#8217;m even more out of my depth than usual here, so I&#8217;ll just copy (part of) the abstract, for fear I don&#8217;t do justice to the authors&#8217; work: &#8220;This paper studies the fundamental limits of reinforcement learning (RL) in the challenging <em>partially observable</em> setting. While it is well-established that learning in Partially Observable Markov Decision Processes (POMDPs) requires exponentially many samples in the worst case, a surge of recent work shows that polynomial sample complexities are achievable under the <em>revealing condition</em> &#8212; A natural condition that requires the observables to reveal some information about the unobserved latent states. However, the fundamental limits for learning in revealing POMDPs are much less understood, with existing lower bounds being rather preliminary and having substantial gaps from the current best upper bounds. We establish strong PAC and regret lower bounds for learning in revealing POMDPs. […] <strong>Technically, our hard instance construction adapts techniques in distribution testing, which is new to the RL literature and may be of independent interest.</strong>&#8221; (Emphasis mine)</p>



<p></p>
<p class="authors">By Clement Canonne</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T06:04:08Z">Wednesday, February 08 2023, 06:04</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03569'>Label propagation on binomial random graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marcos Kiwi, Lyuben Lichev, Dieter Mitsche, Pawe&#x142; Pra&#x142;at</p><p>We study a variant of the widely popular, fast and often used ``family'' of
community detection procedures referred to as label propagation algorithms.
Initially, given a network, each vertex starts with a random label in the
interval $[0,1]$. Then, in each round of the algorithm, every vertex switches
its label to the majority label in its neighborhood (including its own label).
At the first round, ties are broken towards smaller labels, while at each of
the next rounds, ties are broken uniformly at random.
</p>
<p>We investigate the performance of this algorithm on the binomial random graph
$\mathcal G(n,p)$. We show that for $np \ge n^{5/8+\varepsilon}$, the algorithm
terminates with a single label a.a.s. (which was previously known only for
$np\ge n^{3/4+\varepsilon}$). Moreover, we show that if $np\gg n^{2/3}$, a.a.s.
this label is the smallest one, whereas if $n^{5/8+\varepsilon}\le np\ll
n^{2/3}$, the surviving label is a.a.s. not the smallest one.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Kiwi_M/0/1/0/all/0/1">Marcos Kiwi</a>, <a href="http://arxiv.org/find/math/1/au:+Lichev_L/0/1/0/all/0/1">Lyuben Lichev</a>, <a href="http://arxiv.org/find/math/1/au:+Mitsche_D/0/1/0/all/0/1">Dieter Mitsche</a>, <a href="http://arxiv.org/find/math/1/au:+Pralat_P/0/1/0/all/0/1">Pawe&#x142; Pra&#x142;at</a></p><p>We study a variant of the widely popular, fast and often used ``family'' of
community detection procedures referred to as label propagation algorithms.
Initially, given a network, each vertex starts with a random label in the
interval $[0,1]$. Then, in each round of the algorithm, every vertex switches
its label to the majority label in its neighborhood (including its own label).
At the first round, ties are broken towards smaller labels, while at each of
the next rounds, ties are broken uniformly at random.
</p>
<p>We investigate the performance of this algorithm on the binomial random graph
$\mathcal G(n,p)$. We show that for $np \ge n^{5/8+\varepsilon}$, the algorithm
terminates with a single label a.a.s. (which was previously known only for
$np\ge n^{3/4+\varepsilon}$). Moreover, we show that if $np\gg n^{2/3}$, a.a.s.
this label is the smallest one, whereas if $n^{5/8+\varepsilon}\le np\ll
n^{2/3}$, the surviving label is a.a.s. not the smallest one.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03451'>The Solidarity Cover Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eran Rosenbluth</p><p>Various real-world problems consist of partitioning a set of locations into
disjoint subsets, each subset spread in a way that it covers the whole set with
a certain radius. Given a finite set S, a metric d, and a radius r, define a
subset (of S) S' to be an r-cover if and only if forall s in S there exists s'
in S' such that d(s,s') is less or equal to r. We examine the problem of
determining whether there exist m disjoint r-covers, naming it the Solidarity
Cover Problem (SCP). We consider as well the related optimization problems of
maximizing the number of r-covers, referred to as the partition size, and
minimizing the radius. We analyze the relation between the SCP and a graph
problem known as the Domatic Number Problem (DNP), both hard problems in the
general case. We show that the SCP is hard already in the Euclidean 2D setting,
implying hardness of the DNP already in the unit-disc-graph setting. As far as
we know, the latter is a result yet to be shown. We use the tight approximation
bound of (1-o(1))/ln(n) for the DNP's general case, shown by U.Feige,
M.Halld'orsson, G.Kortsarz, and A.Srinivasan (SIAM Journal on computing, 2002),
to deduce the same bound for partition-size approximation of the SCP in the
Euclidean space setting. We show an upper bound of 3 and lower bounds of 2 and
sqrt(2) for approximating the minimal radius in different settings of the SCP.
Lastly, in the Euclidean 2D setting we provide a general
bicriteria-approximation scheme which allows a range of possibilities for
trading the optimality of the radius in return for better approximation of the
partition size and vice versa. We demonstrate a usage of the scheme which
achieves an approximation of (1/16,2) for the partition size and radius
respectively.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rosenbluth_E/0/1/0/all/0/1">Eran Rosenbluth</a></p><p>Various real-world problems consist of partitioning a set of locations into
disjoint subsets, each subset spread in a way that it covers the whole set with
a certain radius. Given a finite set S, a metric d, and a radius r, define a
subset (of S) S' to be an r-cover if and only if forall s in S there exists s'
in S' such that d(s,s') is less or equal to r. We examine the problem of
determining whether there exist m disjoint r-covers, naming it the Solidarity
Cover Problem (SCP). We consider as well the related optimization problems of
maximizing the number of r-covers, referred to as the partition size, and
minimizing the radius. We analyze the relation between the SCP and a graph
problem known as the Domatic Number Problem (DNP), both hard problems in the
general case. We show that the SCP is hard already in the Euclidean 2D setting,
implying hardness of the DNP already in the unit-disc-graph setting. As far as
we know, the latter is a result yet to be shown. We use the tight approximation
bound of (1-o(1))/ln(n) for the DNP's general case, shown by U.Feige,
M.Halld'orsson, G.Kortsarz, and A.Srinivasan (SIAM Journal on computing, 2002),
to deduce the same bound for partition-size approximation of the SCP in the
Euclidean space setting. We show an upper bound of 3 and lower bounds of 2 and
sqrt(2) for approximating the minimal radius in different settings of the SCP.
Lastly, in the Euclidean 2D setting we provide a general
bicriteria-approximation scheme which allows a range of possibilities for
trading the optimality of the radius in return for better approximation of the
partition size and vice versa. We demonstrate a usage of the scheme which
achieves an approximation of (1/16,2) for the partition size and radius
respectively.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03456'>On the complexity of the approximate hypergraph homomorphism problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lorenzo Ciardo, Marcin Kozik, Andrei Krokhin, Tamio-Vesa Nakajima, Stanislav &#x17d;ivn&#xfd;</p><p>Understanding the computational complexity of fragments of the Constraint
Satisfaction Problem (CSP) has been instrumental in the formulation of
Feder-Vardi's Dichotomy Conjecture and its positive resolution by Bulatov and
Zhuk. An approximation version of the CSP - known as the promise CSP - has
recently gained prominence as an exciting generalisation of the CSP that
captures many fundamental computational problems. In this work, we establish a
computational complexity dichotomy for a natural fragment of the promise CSP
consisting of homomorphism problems involving a class of 3-uniform hypergraphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ciardo_L/0/1/0/all/0/1">Lorenzo Ciardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozik_M/0/1/0/all/0/1">Marcin Kozik</a>, <a href="http://arxiv.org/find/cs/1/au:+Krokhin_A/0/1/0/all/0/1">Andrei Krokhin</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakajima_T/0/1/0/all/0/1">Tamio-Vesa Nakajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Zivny_S/0/1/0/all/0/1">Stanislav &#x17d;ivn&#xfd;</a></p><p>Understanding the computational complexity of fragments of the Constraint
Satisfaction Problem (CSP) has been instrumental in the formulation of
Feder-Vardi's Dichotomy Conjecture and its positive resolution by Bulatov and
Zhuk. An approximation version of the CSP - known as the promise CSP - has
recently gained prominence as an exciting generalisation of the CSP that
captures many fundamental computational problems. In this work, we establish a
computational complexity dichotomy for a natural fragment of the promise CSP
consisting of homomorphism problems involving a class of 3-uniform hypergraphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03071'>Optimally Interpolating between Ex-Ante Fairness and Welfare</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mikael H&#xf8;gsgaard, Panagiotis Karras, Wenyue Ma, Nidhi Rathi, Chris Schwiegelshohn</p><p>For the fundamental problem of allocating a set of resources among
individuals with varied preferences, the quality of an allocation relates to
the degree of fairness and the collective welfare achieved. Unfortunately, in
many resource-allocation settings, it is computationally hard to maximize
welfare while achieving fairness goals.
</p>
<p>In this work, we consider ex-ante notions of fairness; popular examples
include the \emph{randomized round-robin algorithm} and \emph{sortition
mechanism}. We propose a general framework to systematically study the
\emph{interpolation} between fairness and welfare goals in a multi-criteria
setting. We develop two efficient algorithms ($\varepsilon-Mix$ and
$Simple-Mix$) that achieve different trade-off guarantees with respect to
fairness and welfare. $\varepsilon-Mix$ achieves an optimal multi-criteria
approximation with respect to fairness and welfare, while $Simple-Mix$ achieves
optimality up to a constant factor with zero computational overhead beyond the
underlying \emph{welfare-maximizing mechanism} and the \emph{ex-ante fair
mechanism}. Our framework makes no assumptions on either of the two underlying
mechanisms, other than that the fair mechanism produces a distribution over the
set of all allocations. Indeed, if these mechanisms are themselves
approximation algorithms, our framework will retain the approximation factor,
guaranteeing sensitivity to the quality of the underlying mechanisms, while
being \emph{oblivious} to them. We also give an extensive experimental analysis
for the aforementioned ex-ante fair mechanisms on real data sets, confirming
our theoretical analysis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hogsgaard_M/0/1/0/all/0/1">Mikael H&#xf8;gsgaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Karras_P/0/1/0/all/0/1">Panagiotis Karras</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Wenyue Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Rathi_N/0/1/0/all/0/1">Nidhi Rathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwiegelshohn_C/0/1/0/all/0/1">Chris Schwiegelshohn</a></p><p>For the fundamental problem of allocating a set of resources among
individuals with varied preferences, the quality of an allocation relates to
the degree of fairness and the collective welfare achieved. Unfortunately, in
many resource-allocation settings, it is computationally hard to maximize
welfare while achieving fairness goals.
</p>
<p>In this work, we consider ex-ante notions of fairness; popular examples
include the \emph{randomized round-robin algorithm} and \emph{sortition
mechanism}. We propose a general framework to systematically study the
\emph{interpolation} between fairness and welfare goals in a multi-criteria
setting. We develop two efficient algorithms ($\varepsilon-Mix$ and
$Simple-Mix$) that achieve different trade-off guarantees with respect to
fairness and welfare. $\varepsilon-Mix$ achieves an optimal multi-criteria
approximation with respect to fairness and welfare, while $Simple-Mix$ achieves
optimality up to a constant factor with zero computational overhead beyond the
underlying \emph{welfare-maximizing mechanism} and the \emph{ex-ante fair
mechanism}. Our framework makes no assumptions on either of the two underlying
mechanisms, other than that the fair mechanism produces a distribution over the
set of all allocations. Indeed, if these mechanisms are themselves
approximation algorithms, our framework will retain the approximation factor,
guaranteeing sensitivity to the quality of the underlying mechanisms, while
being \emph{oblivious} to them. We also give an extensive experimental analysis
for the aforementioned ex-ante fair mechanisms on real data sets, confirming
our theoretical analysis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03143'>Sparsification of Monotone $k$-Submodular Functions of Low Curvature</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jannik Kudla, Stanislav &#x17d;ivn&#xfd;</p><p>Pioneered by Benczur and Karger for cuts in graphs [STOC'96], sparsification
is a fundamental topic with wide-ranging applications that has been studied,
e.g., for graphs and hypergraphs, in a combinatorial and a spectral setting,
and with additive and multiplicate error bounds. Rafiey and Yoshida recently
considered sparsification of decomposable submodular functions [AAAI'22]. We
extend their work by presenting an efficient algorithm for a sparsifier for
monotone $k$-submodular functions of low curvature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kudla_J/0/1/0/all/0/1">Jannik Kudla</a>, <a href="http://arxiv.org/find/cs/1/au:+Zivny_S/0/1/0/all/0/1">Stanislav &#x17d;ivn&#xfd;</a></p><p>Pioneered by Benczur and Karger for cuts in graphs [STOC'96], sparsification
is a fundamental topic with wide-ranging applications that has been studied,
e.g., for graphs and hypergraphs, in a combinatorial and a spectral setting,
and with additive and multiplicate error bounds. Rafiey and Yoshida recently
considered sparsification of decomposable submodular functions [AAAI'22]. We
extend their work by presenting an efficient algorithm for a sparsifier for
monotone $k$-submodular functions of low curvature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03239'>Calibrated Recommendations for Users with Decaying Attention</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jon Kleinberg, Emily Ryu, &#xc9;va Tardos</p><p>Recommendation systems capable of providing diverse sets of results are a
focus of increasing importance, with motivations ranging from fairness to
novelty and other aspects of optimizing user experience. One form of diversity
of recent interest is calibration, the notion that personalized recommendations
should reflect the full distribution of a user's interests, rather than a
single predominant category -- for instance, a user who mainly reads
entertainment news but also wants to keep up with news on the environment and
the economy would prefer to see a mixture of these genres, not solely
entertainment news. Existing work has formulated calibration as a subset
selection problem; this line of work observes that the formulation requires the
unrealistic assumption that all recommended items receive equal consideration
from the user, but leaves as an open question the more realistic setting in
which user attention decays as they move down the list of results.
</p>
<p>In this paper, we consider calibration with decaying user attention under two
different models. In both models, there is a set of underlying genres that
items can belong to. In the first setting, where items are represented by
fine-grained mixtures of genre percentages, we provide a
$(1-1/e)$-approximation algorithm by extending techniques for constrained
submodular optimization. In the second setting, where items are coarsely binned
into a single genre each, we surpass the $(1-1/e)$ barrier imposed by
submodular maximization and give a $2/3$-approximate greedy algorithm. Our work
thus addresses the problem of capturing ordering effects due to decaying
attention, allowing for the extension of near-optimal calibration from
recommendation sets to recommendation lists.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1">Jon Kleinberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryu_E/0/1/0/all/0/1">Emily Ryu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tardos_E/0/1/0/all/0/1">&#xc9;va Tardos</a></p><p>Recommendation systems capable of providing diverse sets of results are a
focus of increasing importance, with motivations ranging from fairness to
novelty and other aspects of optimizing user experience. One form of diversity
of recent interest is calibration, the notion that personalized recommendations
should reflect the full distribution of a user's interests, rather than a
single predominant category -- for instance, a user who mainly reads
entertainment news but also wants to keep up with news on the environment and
the economy would prefer to see a mixture of these genres, not solely
entertainment news. Existing work has formulated calibration as a subset
selection problem; this line of work observes that the formulation requires the
unrealistic assumption that all recommended items receive equal consideration
from the user, but leaves as an open question the more realistic setting in
which user attention decays as they move down the list of results.
</p>
<p>In this paper, we consider calibration with decaying user attention under two
different models. In both models, there is a set of underlying genres that
items can belong to. In the first setting, where items are represented by
fine-grained mixtures of genre percentages, we provide a
$(1-1/e)$-approximation algorithm by extending techniques for constrained
submodular optimization. In the second setting, where items are coarsely binned
into a single genre each, we surpass the $(1-1/e)$ barrier imposed by
submodular maximization and give a $2/3$-approximate greedy algorithm. Our work
thus addresses the problem of capturing ordering effects due to decaying
attention, allowing for the extension of near-optimal calibration from
recommendation sets to recommendation lists.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03245'>Two Parallel PageRank Algorithms via Improving Forward Push</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Qi Zhang, Rongxia Tang, Zhengan Yao, Jun Liang</p><p>Initially used to rank web pages, PageRank has now been applied in many
fields. With the growing scale of graph, accelerating PageRank computing is
urged and designing parallel algorithm is a feasible solution. In this paper,
two parallel PageRank algorithms IFP1 and IFP2 are proposed via improving the
state-of-the-art Personalized PageRank algorithm, i.e., Forward Push.
Theoretical analysis indicates that, IFP1 can take advantage of the DAG
structure of the graph, where the dangling vertices improves the convergence
rate and the unreferenced vertices decreases the computation amount. As an
improvement of IFP1, IFP2 pushes mass to the dangling vertices only once but
rather many times, and thus decreases the computation amount further.
Experiments on six data sets illustrate that both IFP1 and IFP2 outperform
Power method, where IFP2 with 38 parallelism can be at most 50 times as fast as
the Power method.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1">Rongxia Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1">Zhengan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jun Liang</a></p><p>Initially used to rank web pages, PageRank has now been applied in many
fields. With the growing scale of graph, accelerating PageRank computing is
urged and designing parallel algorithm is a feasible solution. In this paper,
two parallel PageRank algorithms IFP1 and IFP2 are proposed via improving the
state-of-the-art Personalized PageRank algorithm, i.e., Forward Push.
Theoretical analysis indicates that, IFP1 can take advantage of the DAG
structure of the graph, where the dangling vertices improves the convergence
rate and the unreferenced vertices decreases the computation amount. As an
improvement of IFP1, IFP2 pushes mass to the dangling vertices only once but
rather many times, and thus decreases the computation amount further.
Experiments on six data sets illustrate that both IFP1 and IFP2 outperform
Power method, where IFP2 with 38 parallelism can be at most 50 times as fast as
the Power method.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03317'>Engineering Shared-Memory Parallel Shuffling to Generate Random Permutations In-Place</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Manuel Penschuck</p><p>Shuffling is the process of rearranging a sequence of elements into a random
order such that any permutation occurs with equal probability. It is an
important building block in a plethora of techniques used in virtually all
scientific areas. Consequently considerable work has been devoted to the design
and implementation of shuffling algorithms.
</p>
<p>We engineer, -- to the best of our knowledge -- for the first time, a
practically fast, parallel shuffling algorithm with $\Oh{\sqrt{n}\log n}$
parallel depth that requires only poly-logarithmic auxiliary memory. Our
reference implementations in Rust are freely available, easy to include in
other projects, and can process large data sets approaching the size of the
system's memory. In an empirical evaluation, we compare our implementations
with a number of existing solutions on various computer architectures. Our
algorithms consistently achieve the highest through-put on all machines.
Further, we demonstrate that the runtime of our parallel algorithm is
comparable to the time that other algorithms may take to acquire the memory
from the operating system to copy the input.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Penschuck_M/0/1/0/all/0/1">Manuel Penschuck</a></p><p>Shuffling is the process of rearranging a sequence of elements into a random
order such that any permutation occurs with equal probability. It is an
important building block in a plethora of techniques used in virtually all
scientific areas. Consequently considerable work has been devoted to the design
and implementation of shuffling algorithms.
</p>
<p>We engineer, -- to the best of our knowledge -- for the first time, a
practically fast, parallel shuffling algorithm with $\Oh{\sqrt{n}\log n}$
parallel depth that requires only poly-logarithmic auxiliary memory. Our
reference implementations in Rust are freely available, easy to include in
other projects, and can process large data sets approaching the size of the
system's memory. In an empirical evaluation, we compare our implementations
with a number of existing solutions on various computer architectures. Our
algorithms consistently achieve the highest through-put on all machines.
Further, we demonstrate that the runtime of our parallel algorithm is
comparable to the time that other algorithms may take to acquire the memory
from the operating system to copy the input.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03527'>First-Order Model Checking on Structurally Sparse Graph Classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jan Dreier, Nikolas M&#xe4;hlmann, Sebastian Siebertz</p><p>A class of graphs is structurally nowhere dense if it can be constructed from
a nowhere dense class by a first-order transduction. Structurally nowhere dense
classes vastly generalize nowhere dense classes and constitute important
examples of monadically stable classes. We show that the first-order model
checking problem is fixed-parameter tractable on every structurally nowhere
dense class of graphs.
</p>
<p>Our result builds on a recently developed game-theoretic characterization of
monadically stable graph classes. As a second key ingredient of independent
interest, we provide a polynomial-time algorithm for approximating weak
neighborhood covers (on general graphs). We combine the two tools into a
recursive locality-based model checking algorithm. This algorithm is efficient
on every monadically stable graph class admitting flip-closed sparse weak
neighborhood covers, where flip-closure is a mild additional assumption.
Thereby, establishing efficient first-order model checking on monadically
stable classes is reduced to proving the existence of flip-closed sparse weak
neighborhood covers on these classes - a purely combinatorial problem. We
complete the picture by proving the existence of the desired covers for
structurally nowhere dense classes: we show that every structurally nowhere
dense class can be sparsified by contracting local sets of vertices, enabling
us to lift the existence of covers from sparse classes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dreier_J/0/1/0/all/0/1">Jan Dreier</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahlmann_N/0/1/0/all/0/1">Nikolas M&#xe4;hlmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Siebertz_S/0/1/0/all/0/1">Sebastian Siebertz</a></p><p>A class of graphs is structurally nowhere dense if it can be constructed from
a nowhere dense class by a first-order transduction. Structurally nowhere dense
classes vastly generalize nowhere dense classes and constitute important
examples of monadically stable classes. We show that the first-order model
checking problem is fixed-parameter tractable on every structurally nowhere
dense class of graphs.
</p>
<p>Our result builds on a recently developed game-theoretic characterization of
monadically stable graph classes. As a second key ingredient of independent
interest, we provide a polynomial-time algorithm for approximating weak
neighborhood covers (on general graphs). We combine the two tools into a
recursive locality-based model checking algorithm. This algorithm is efficient
on every monadically stable graph class admitting flip-closed sparse weak
neighborhood covers, where flip-closure is a mild additional assumption.
Thereby, establishing efficient first-order model checking on monadically
stable classes is reduced to proving the existence of flip-closed sparse weak
neighborhood covers on these classes - a purely combinatorial problem. We
complete the picture by proving the existence of the desired covers for
structurally nowhere dense classes: we show that every structurally nowhere
dense class can be sparsified by contracting local sets of vertices, enabling
us to lift the existence of covers from sparse classes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03627'>Tight algorithms for connectivity problems parameterized by clique-width</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Falko Hegerfeld, Stefan Kratsch</p><p>The complexity of problems involving global constraints is usually much more
difficult to understand than the complexity of problems only involving local
constraints. A natural form of global constraints are connectivity constraints.
We study connectivity problems from a fine-grained parameterized perspective.
In a breakthrough, Cygan et al. (TALG 2022) first obtained algorithms with
single-exponential running time c^{tw} n^O(1) for connectivity problems
parameterized by treewidth by introducing the cut-and-count-technique.
Furthermore, the obtained bases c were shown to be optimal under the Strong
Exponential-Time Hypothesis (SETH).
</p>
<p>However, since only sparse graphs may admit small treewidth, we lack
knowledge of the fine-grained complexity of connectivity problems with respect
to dense structure. The most popular graph parameter to measure dense structure
is arguably clique-width, which intuitively measures how easily a graph can be
constructed by repeatedly adding bicliques. Bergougnoux and Kant\'e (TCS 2019)
have shown, using the rank-based approach, that also parameterized by
clique-width many connectivity problems admit single-exponential algorithms.
Unfortunately, the obtained running times are far from optimal under SETH.
</p>
<p>We show how to obtain optimal running times parameterized by clique-width for
two benchmark connectivity problems, namely Connected Vertex Cover and
Connected Dominating Set. These are the first tight results for connectivity
problems with respect to clique-width and these results are obtained by
developing new algorithms based on the cut-and-count-technique and novel lower
bound constructions. Precisely, we show that there exist one-sided error
Monte-Carlo algorithms that given a k-clique-expression solve Connected Vertex
Cover in time 6^k n^O(1), and Connected Dominating Set in time 5^k n^O(1). Both
results are shown to be tight under SETH.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hegerfeld_F/0/1/0/all/0/1">Falko Hegerfeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Kratsch_S/0/1/0/all/0/1">Stefan Kratsch</a></p><p>The complexity of problems involving global constraints is usually much more
difficult to understand than the complexity of problems only involving local
constraints. A natural form of global constraints are connectivity constraints.
We study connectivity problems from a fine-grained parameterized perspective.
In a breakthrough, Cygan et al. (TALG 2022) first obtained algorithms with
single-exponential running time c^{tw} n^O(1) for connectivity problems
parameterized by treewidth by introducing the cut-and-count-technique.
Furthermore, the obtained bases c were shown to be optimal under the Strong
Exponential-Time Hypothesis (SETH).
</p>
<p>However, since only sparse graphs may admit small treewidth, we lack
knowledge of the fine-grained complexity of connectivity problems with respect
to dense structure. The most popular graph parameter to measure dense structure
is arguably clique-width, which intuitively measures how easily a graph can be
constructed by repeatedly adding bicliques. Bergougnoux and Kant\'e (TCS 2019)
have shown, using the rank-based approach, that also parameterized by
clique-width many connectivity problems admit single-exponential algorithms.
Unfortunately, the obtained running times are far from optimal under SETH.
</p>
<p>We show how to obtain optimal running times parameterized by clique-width for
two benchmark connectivity problems, namely Connected Vertex Cover and
Connected Dominating Set. These are the first tight results for connectivity
problems with respect to clique-width and these results are obtained by
developing new algorithms based on the cut-and-count-technique and novel lower
bound constructions. Precisely, we show that there exist one-sided error
Monte-Carlo algorithms that given a k-clique-expression solve Connected Vertex
Cover in time 6^k n^O(1), and Connected Dominating Set in time 5^k n^O(1). Both
results are shown to be tight under SETH.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03658'>Planted Bipartite Graph Detection</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Asaf Rotenberg, Wasim Huleihel, Ofer Shayevitz</p><p>We consider the task of detecting a hidden bipartite subgraph in a given
random graph. Specifically, under the null hypothesis, the graph is a
realization of an Erd\H{o}s-R\'{e}nyi random graph over $n$ vertices with edge
density $q$. Under the alternative, there exists a planted $k_{\mathsf{R}}
\times k_{\mathsf{L}}$ bipartite subgraph with edge density $p&gt;q$. We derive
asymptotically tight upper and lower bounds for this detection problem in both
the dense regime, where $q,p = \Theta\left(1\right)$, and the sparse regime
where $q,p = \Theta\left(n^{-\alpha}\right), \alpha \in \left(0,2\right]$.
Moreover, we consider a variant of the above problem, where one can only
observe a relatively small part of the graph, by using at most $\mathsf{Q}$
edge queries. For this problem, we derive upper and lower bounds in both the
dense and sparse regimes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rotenberg_A/0/1/0/all/0/1">Asaf Rotenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Huleihel_W/0/1/0/all/0/1">Wasim Huleihel</a>, <a href="http://arxiv.org/find/cs/1/au:+Shayevitz_O/0/1/0/all/0/1">Ofer Shayevitz</a></p><p>We consider the task of detecting a hidden bipartite subgraph in a given
random graph. Specifically, under the null hypothesis, the graph is a
realization of an Erd\H{o}s-R\'{e}nyi random graph over $n$ vertices with edge
density $q$. Under the alternative, there exists a planted $k_{\mathsf{R}}
\times k_{\mathsf{L}}$ bipartite subgraph with edge density $p&gt;q$. We derive
asymptotically tight upper and lower bounds for this detection problem in both
the dense regime, where $q,p = \Theta\left(1\right)$, and the sparse regime
where $q,p = \Theta\left(n^{-\alpha}\right), \alpha \in \left(0,2\right]$.
Moreover, we consider a variant of the above problem, where one can only
observe a relatively small part of the graph, by using at most $\mathsf{Q}$
edge queries. For this problem, we derive upper and lower bounds in both the
dense and sparse regimes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-08T01:30:00Z">Wednesday, February 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, February 07
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/07/postdoc-at-department-of-computer-science-stony-brook-university-apply-by-april-8-2023/'>Postdoc at Department of Computer Science, Stony Brook University (apply by April 8, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The department of Computer Science at Stony Brook University is looking to hire a postdoc in quantum information science, including but not limited to complexity theory, property testing, algorithms, sensing, and program analysis, with an expected start date in May 2023 and a duration of 1+1 years. The postdocs will work closely with Prof Nengkun [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The department of Computer Science at Stony Brook University is looking to hire a postdoc in quantum information science, including but not limited to complexity theory, property testing, algorithms, sensing, and program analysis, with an expected start date in May 2023 and a duration of 1+1 years. The postdocs will work closely with Prof Nengkun Yu and Prof Supartha Podder.</p>
<p>Website: <a href="https://stonybrooku.taleo.net/careersection/2/jobdetail.ftl?job=2204491&amp;tz=GMT-05%3A00&amp;tzname=America%2FNew_York">https://stonybrooku.taleo.net/careersection/2/jobdetail.ftl?job=2204491&amp;tz=GMT-05%3A00&amp;tzname=America%2FNew_York</a><br />
Email: nengkun.yu@cs.stonybrook.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-07T17:30:54Z">Tuesday, February 07 2023, 17:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/02/07/focs-2022-program/'>FOCS 2022 Program</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Alvy Ray Smith designed the distinctive cover art that was a notable feature of FOCS proceedings until FOCS ended the production of printed proceedings in 2010. FOCS was founded in 1960 as the Symposium on Switching Circuit Theory and Logical Design. The 1960 conference did not have a separate published proceedings but most of the [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Alvy Ray Smith designed the distinctive cover art that was a notable feature of FOCS proceedings until FOCS ended the production of printed proceedings in 2010. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/07/focs-2022-program/ars/" rel="attachment wp-att-21047"><img data-attachment-id="21047" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/07/focs-2022-program/ars/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?fit=225%2C225&amp;ssl=1" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ars" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?fit=225%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?fit=225%2C225&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?resize=225%2C225&#038;ssl=1" alt="" width="225" height="225" class="aligncenter size-full wp-image-21047" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?w=225&amp;ssl=1 225w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ars.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1" /></a></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/07/focs-2022-program/cover-2/" rel="attachment wp-att-21048"><img data-attachment-id="21048" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/07/focs-2022-program/cover-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpg?fit=378%2C450&amp;ssl=1" data-orig-size="378,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="cover" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpg?fit=252%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpg?fit=378%2C450&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpg?resize=378%2C450&#038;ssl=1" alt="" width="378" height="450" class="aligncenter size-full wp-image-21048" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpg?w=378&amp;ssl=1 378w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpg?resize=252%2C300&amp;ssl=1 252w" sizes="(max-width: 378px) 100vw, 378px" data-recalc-dims="1" /></a></p>
<p>FOCS was founded in 1960 as the Symposium on Switching Circuit Theory and Logical Design. The 1960 conference did not have a separate published proceedings but most of the papers were published in the second half of the proceedings of the 1961 conference. For the 7th instantiation of the conference in 1966, the name was changed to the Symposium on Switching and Automata Theory (SWAT). The greatly increased breadth of the conference led to a name change to its present one in 1975. </p>
<p><strong>FOCS 2022</strong></p>
<p>Yes the FOCS 2023 is about to be out. But I was looking at the &#8220;old&#8221; ones and thought this might be useful. So here are the papers with pointers to online versions. We will do the same for the 2023 version.</p>
<p><a href="https://arxiv.org/pdf/2202.04551.pdf">Shortest Paths without a Map, but with an Entropic Regularizer.</a><br />
Sebastien Bubeck (Microsoft Research), Christian Coester (University of Sheffield), Yuval Rabani (Hebrew University).</p>
<p><a href="https://arxiv.org/abs/2203.02763">Online List Labeling: Breaking the <span class="math inline">log<sup>2</sup><em>n</em></span> Barrier.</a><br />
Michael A. Bender (Stony Brook University), Alex Conway (VMWare Research), Martin Farach-Colton (Rutgers University), Hanna Komlos (Rutgers University), William Kuszmaul (MIT), Nicole Wein (DIMACS).</p>
<p><a href="https://arxiv.org/abs/2205.07175">Simple Hard Instances for Low-Depth Algebraic Proofs.</a><br />
Nashlen Govindasamy (Imperial College London), Tuomas Hakoniemi (Imperial College London), Iddo Tzameret (Imperial College London).</p>
<p><a href="https://arxiv.org/abs/1904.05390">Constant Approximation of Min-Distances in Near-Linear Time.</a><br />
Shiri Chechik (Tel Aviv University), Tianyi Zhang (Tel Aviv University).</p>
<p><a href="https://arxiv.org/abs/2207.01761">First Price Auction is <span class="math inline">1 − 1/<em>e</em><sup>2</sup></span> Efficient.</a><br />
Yaonan Jin (Columbia University), Pinyan Lu (Shanghai University of Finance and Economics).</p>
<p><a href="https://arxiv.org/abs/2112.05106">Estimating the Longest Increasing Subsequence in Nearly Optimal Time.</a><br />
Alexandr Andoni (Columbia University), Negev Shekel Nosatzki (Columbia University), Sandip Sinha (Columbia University), Clifford Stein (Columbia University).</p>
<p><a href="https://arxiv.org/abs/2204.01425">Order Selection Prophet Inequality: From Threshold Optimization to Arrival Time Design.</a><br />
Bo Peng (ITCS, Shanghai University of Finance and Economics), Zhihao Gavin Tang (ITCS, Shanghai University of Finance and Economics).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996652">Using invariant theory to fool polynomials.</a><br />
Harm Derksen (Northeastern University), Emanuele Viola (Northeastern University).</p>
<p><a href="https://arxiv.org/pdf/2111.13198.pdf">The Implicit Graph Conjecture is False.</a><br />
Hamed Hatami (McGill University), Pooya Hatami (Ohio State University).</p>
<p><a href="https://arxiv.org/abs/2201.05674">Cut Query Algorithms with Star Contraction.</a><br />
Yuval Efron (Columbia University), Danupon Nanongkai (University of Copenhagen &amp; KTH), Sagnik Mukhopadhyay (University of Sheffield), Simon Apers (CNRS IRIF), Troy Lee (University of Technology Sydney), Pawel Gawrychowski (University of Wroc?aw).</p>
<p><a href="https://arxiv.org/abs/2202.08688">Improved Optimal Testing Results from Global Hypercontractivity.</a><br />
Tali Kaufman (Bar Ilan University), Dor Minzer (MIT).</p>
<p><a href="https://arxiv.org/abs/2209.06038">A Hash Table Without Hash Functions, and How to Get the Most out of Your Random Bits.</a><br />
William Henry Kuszmaul (Massachusetts Institute of Technology (MIT)).</p>
<p><a href="https://arxiv.org/abs/2205.06558">Balanced Allocations: The Heavily Loaded Case with Deletions.</a><br />
Nikhil Bansal (University of Michigan), William Kuszmaul (MIT).</p>
<p><a href="https://arxiv.org/abs/2203.01550">A Characterization of Multiclass Learnability.</a><br />
Nataly Brukhim (Princeton University), Daniel Carmon (Technion), Irit Dinur (Weizmann), Shay Moran (Technion and Google), Amir Yehudayoff (Technion-IIT).</p>
<p><a href="https://arxiv.org/abs/2209.07016">Algorithms and Lower Bounds for Replacement Paths under Multiple Edge Failures.</a><br />
Virginia Vassilevska Williams (Massachusetts Institute of Technology), Eyob Woldeghebriel (Massachusetts Institute of Technology), Yinzhan Xu (Massachusetts Institute of Technology).</p>
<p><a href="https://arxiv.org/abs/2208.10959">Derandomizing Directed Random Walks in Almost-Linear Time.</a><br />
Rasmus Kyng (ETH Zurich, Department of Computer Science), Simon Meierhans (ETH Zurich, Department of Computer Science), Maximilian Probst Gutenberg (ETH Zurich, Department of Computer Science).</p>
<p><a href="https://arxiv.org/abs/2203.07346">Sparse random hypergraphs: Non-backtracking spectra and community detection.</a><br />
Ludovic Stephan (Ecole Polytechnique Federale de Lausanne), Yizhe Zhu (University of California, Irvine).</p>
<p><a href="https://arxiv.org/abs/2207.04923">Killing a Vortex.</a><br />
Dimitrios Thilikos (LIRMM, Univ Montpellier, CNRS, Montpellier, France), Sebastian Wiederrecht (LIRMM, Univ Montpellier, CNRS, Montpellier, France).</p>
<p><a href="https://arxiv.org/abs/2203.15627">Low Treewidth Embeddings of Planar and Minor-Free Metrics.</a><br />
Hung Le (University of Massachusetts), Arnold Filtser (Bar-Ilan University).</p>
<p><a href="https://arxiv.org/abs/2203.06168">Cheeger Inequalities for Vertex Expansion and Reweighted Eigenvalues.</a><br />
Tsz Chiu Kwok (Shanghai University of Finance and Economics), Lap Chi Lau (University of Waterloo), Kam Chuen Tung (University of Waterloo).</p>
<p><a href="https://arxiv.org/abs/2204.01923">Algorithms for the ferromagnetic Potts model on expanders.</a><br />
Charlie Carlson (University of Colorado, Boulder), Ewan Davies (University of Colorado, Boulder), Nicolas Fraiman (University of North Carolina at Chapel Hill), Alexandra Kolla (University of Colorado, Boulder and University of California Santa Cruz), Aditya Potukuchi (University of Illinois at Chicago), Corrine Yap (Rutgers University).</p>
<p><a href="https://arxiv.org/abs/2208.02526">Nearly Optimal Communication and Query Complexity of Bipartite Matching.</a><br />
Joakim Blikstad (KTH Royal Institute of Technology), Jan van den Brand (Simons Institute and UC Berkeley), Yuval Efron (Columbia University USA), Sagnik Mukhopadhyay (University of Sheffield UK), Danupon Nanongkai (University of Copenhagen &amp; KTH).</p>
<p><a href="https://arxiv.org/abs/2204.02550">Continuous LWE is as Hard as LWE &amp; Applications to Learning Gaussian Mixtures.</a><br />
Aparna Gupte (MIT CSAIL), Neekon Vafa (MIT CSAIL), Vinod Vaikuntanathan (MIT CSAIL).</p>
<p><a href="https://arxiv.org/abs/2204.02063">Verifiable Quantum Advantage without Structure.</a><br />
Takashi Yamakawa (NTT Social Informatics Laboratories), Mark Zhandry (Princeton University and NTT Research).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996896">Separated borders: Exponential-gap fanin-hierarchy theorem for approximative depth-3 circuits.</a><br />
Pranjal Dutta (Chennai Mathematical Institute), Nitin Saxena (Department of Computer Science &amp; Engg., Indian Institute of Technology Kanpur).</p>
<p><a href="https://arxiv.org/abs/2208.13920">Fitting Metrics and Ultrametrics with Minimum Disagreements.</a><br />
Vincent Cohen-Addad (Google), Chenglin Fan (Sorbonne Universite, Paris, France), Euiwoong Lee (University of Michigan), Arnaud de Mesmay (CNRS, LIGM, Universite Gustave Eiffel).</p>
<p><a href="https://arxiv.org/abs/2203.15667">Algorithms and Barriers in the Symmetric Binary Perceptron Model.</a><br />
David Gamarnik (MIT), Eren Can Kizildag (MIT), Will Perkins (University of Illinois at Chicago), Changji Xu (Harvard).</p>
<p><a href="https://arxiv.org/abs/2211.10887">Differential Privacy from Locally Adjustable Graph Algorithms: k-Core Decomposition, Low Outdegree Ordering, and Densest Subgraphs.</a><br />
Laxman Dhulipala (Google Research), Quanquan C. Liu (Northwestern University), Sofya Raskhodnikova (Boston University), Jessica Shi (Massahusetts Institute of Technology), Julian Shun (Massahusetts Institute of Technology), Shangdi Yu (Massachusetts Institute of Technology).</p>
<p><a href="https://www.math.ucla.edu/~pak/papers/SharpP11.pdf">What is in <span class="math inline">#<em>P</em></span> and what is not?.</a><br />
Christian Ikenmeyer (University of Liverpool), Igor Pak (University of California, Los Angeles).</p>
<p><a href="https://arxiv.org/abs/2203.05093">Sampling from the Sherrington-Kirkpatrick Gibbs measure via algorithmic stochastic localization.</a><br />
Ahmed El Alaoui (Cornell University), Andrea Montanari (Stanford University), Mark Sellke (Stanford University).</p>
<p><a href="https://arxiv.org/abs/2206.00213">The Quantum and Classical Streaming Complexity of Quantum and Classical Max-Cut.</a><br />
John Kallaugher (Sandia National Laboratories), Ojas Parekh (Sandia National Laboratories).</p>
<p><a href="https://arxiv.org/abs/2204.01665">Linear Hashing with <span class="math inline">ℓ<sub>∞</sub></span> guarantees and two-sided Kakeya bounds.</a><br />
Manik Dhar (Princeton University), Zeev Dvir (Princeton University).</p>
<p><a href="https://arxiv.org/abs/2204.03790">High-Dimensional Geometric Streaming in Polynomial Space.</a><br />
David P. Woodruff (Carnegie Mellon University), Taisuke Yasuda (Carnegie Mellon University).</p>
<p><a href="https://arxiv.org/abs/2111.04888">Active Linear Regression for <span class="math inline">ℓ<sub><em>p</em></sub></span> Norms and Beyond.</a><br />
Cameron Musco (University of Massachusetts Amherst), Christopher Musco (New York University), David P. Woodruff (Carnegie Mellon University), Taisuke Yasuda (Carnegie Mellon University).</p>
<p><a href="https://arxiv.org/abs/2110.07847">Tight Lipschitz Hardness for Optimizing Mean Field Spin Glasses.</a><br />
Brice Huang (Massachusetts Institute of Technology), Mark Sellke (Stanford University).</p>
<p><a href="https://arxiv.org/abs/2207.10889">Correlation Clustering with Sherali-Adams.</a><br />
Vincent Cohen-Addad (Google Research), Euiwoong Lee (University of Michigan), Alantha Newman (Laboratoire G-SCOP (CNRS, Grenoble-INP)).</p>
<p><a href="https://arxiv.org/abs/2101.08208">Solving SDP Faster: A Robust IPM Framework and Efficient Implementation.</a><br />
Baihe Huang (Peking University), Shunhua Jiang (Columbia University), Zhao Song (Adobe Research), Runzhou Tao (Columbia University), Ruizhe Zhang (The University of Texas at Austin).</p>
<p><a href="https://arxiv.org/abs/2204.06974">Planting Undetectable Backdoors in Machine Learning Models.</a><br />
Shafi Goldwasser (UC Berkeley), Michael P. Kim (UC Berkeley), Vinod Vaikuntanathan (MIT), Or Zamir (IAS).</p>
<p><a href="https://arxiv.org/abs/2209.05839">Bounded depth proof for Tseitin formulas on the grid; revisited.</a><br />
Johan Hastad (KTH Royal Institute of Technology), Kilian Risse (KTH Royal Institute of Technology).</p>
<p><a href="https://arxiv.org/abs/2210.01104">Local Computation of Maximal Independent Set.</a><br />
Mohsen Ghaffari (MIT).</p>
<p><a href="https://arxiv.org/abs/2204.13648">Survivable Network Design Revisited: Group-Connectivity.</a><br />
Qingyun Chen (University of California, Merced), Bundit Laekhanukit (Shanghai University of Finance and Economics), Chao Liao (Huawei TCS Lab), Yuhao Zhang (Shanghai Jiao Tong University).</p>
<p><a href="https://arxiv.org/abs/2209.01873">Induced Cycles and Paths Are Harder Than You Think.</a><br />
Mina Dalirrooyfard (Massachusetts Institute of Technology), Virginia Vassilevska Williams (Massachusetts Institute of Technology).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996753">Binary Codes with Resilience Beyond 1/4 via Interaction.</a><br />
Klim Efremenko (Ben-Gurion University), Gillat Kol (Princeton University), Raghuvansh Saxena (Microsoft Research), Zhijun Zhang (Princeton University).</p>
<p><a href="https://arxiv.org/abs/2203.03456">Negative-Weight Single-Source Shortest Paths in Near-Linear Time.</a><br />
Aaron Bernstein (Rutgers University), Danupon Nanongkai (University of Copenhagen), Christian Wulff-Nilsen (University of Copenhagen).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996716">Error Correcting Codes that Achieve BSC Capacity Against Channels that are Poly-Size Circuits.</a><br />
Ronen Shaltiel (University of Haifa), Jad Silbak (Tel Aviv University).</p>
<p><a href="https://arxiv.org/abs/2208.00122">Polynomial-Time Power-Sum Decomposition of Polynomials.</a><br />
Mitali Bafna (Harvard University), Jun-Ting Hsieh (Carnegie Mellon University), Pravesh Kothari (CMU), Jeff Xu (Carnegie Mellon University).</p>
<p><a href="https://eccc.weizmann.ac.il/report/2022/045/">Relaxed Locally Decodable and Correctable Codes: Beyond Tensoring.</a><br />
Gil Cohen (Tel Aviv University), Tal Yankovitz (Tel Aviv University).</p>
<p><a href="https://arxiv.org/abs/2207.04342">Improved Lower Bounds for Submodular Function Minimization.</a><br />
Deeparnab Chakrabarty (Dartmouth College), Andrei Graur (Stanford University), Haotian Jiang (University of Washington), Aaron Sidford (Stanford University).</p>
<p><a href="https://eccc.weizmann.ac.il/report/2022/048/">On the Range Avoidance Problem for Circuits.</a><br />
Hanlin Ren (University of Oxford), Rahul Santhanam (University of Oxford), Zhikun Wang (Xi’an Jiaotong University).</p>
<p><a href="https://arxiv.org/abs/2205.03930">Near-Optimal Deterministic Vertex-Failure Connectivity Oracles.</a><br />
Yaowei Long (University of Michigan), Thatchaphol Saranurak (University of Michigan).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996620">Solving the Hamilton Cycle problem fast on average.</a><br />
Michael Anastos (Institute of Science and Technology Austria).</p>
<p><a href="https://arxiv.org/abs/2204.11894">Properly learning monotone functions via local correction.</a><br />
Jane Lange (MIT), Ronitt Rubinfeld (MIT), Arsen Vasilyan (MIT).</p>
<p><a href="https://arxiv.org/abs/2109.11725">Punctured Low-Bias Codes Behave Like Random Linear Codes.</a><br />
Venkatesan Guruswami (UC Berkeley), Jonathan Mosheiff (Ben-Gurion University).</p>
<p><a href="https://arxiv.org/abs/2209.07024">Almost Ramanujan Expanders from Arbitrary Expanders via Operator Amplification.</a><br />
Fernando Granha Jeronimo (Institute of Advanced Study), Tushant Mittal (University of Chicago), Sourya Roy (University of California, Riverside), Avi Wigderson (Institute for Advanced Study).</p>
<p><a href="https://arxiv.org/abs/2204.01520">Sampling Lovasz Local Lemma For General Constraint Satisfaction Solutions In Near-Linear Time.</a><br />
Kun He (Chinese Academy of Sciences), Chunyang Wang (Nanjing University), Yitong Yin (Nanjing University).</p>
<p><a href="https://arxiv.org/abs/2204.03782">Testing Positive Semidefiniteness Using Linear Measurements.</a><br />
Deanna Needell (University of California Los Angeles), William Swartworth (University of California Los Angeles), David P Woodruff (CMU).</p>
<p><a href="https://eccc.weizmann.ac.il/report/2022/108/">Hardness Self-Amplification from Feasible Hard-Core Sets.</a><br />
Shuichi Hirahara (National Institute of Informatics), Nobutaka Shimizu (Tokyo Institute of Technology).</p>
<p><a href="https://arxiv.org/abs/2209.07524"><span class="math inline"><em>O</em>(<em>n</em>+<em>p</em><em>o</em><em>l</em><em>y</em>(<em>k</em>))</span>-time Algorithm for Distance k Tree Edit Distance.</a><br />
Debarati Das (Penn State University), Jacob Gilbert (University of Maryland), MohammadTaghi Hajiaghayi (University of Maryland), Tomasz Kociumaka (UC Berkeley), Barna Saha (University of California San Diego), Hamed Saleh (University of Maryland).</p>
<p><a href="https://arxiv.org/abs/2204.03076">Approximation Algorithms and Hardness for n-Pairs Shortest Paths and All-Nodes Shortest Cycles.</a><br />
Mina Dalirooyfard (MIT), Ce Jin (MIT), Virginia Vassilevska Williams (MIT), Nicole Wein (DIMACS).</p>
<p><a href="https://arxiv.org/abs/2010.01513">Radical Sylvester-Gallai Theorem for Cubics.</a><br />
Rafael Oliveira (University of Waterloo), Akash Kumar Sengupta (Columbia University).</p>
<p><a href="https://arxiv.org/abs/2204.11469">Explicit Lower Bounds Against <span class="math inline"><em>Ω</em>(<em>n</em>)</span>-Rounds of Sum-of-Squares.</a><br />
Max Hopkins (UCSD), Ting-Chun Lin (UCSD, Hong Hai Research Institute).</p>
<p><a href="https://arxiv.org/abs/2110.10091">Factorial Lower Bounds for (Almost) Random Order Streams.</a><br />
Ashish Chiplunkar (IIT Delhi), John Kallaugher (Sandia National Labs), Michael Kapralov (EPFL), Eric Price (The University of Texas at Austin).</p>
<p><a href="https://arxiv.org/abs/2207.03427">Binary Iterative Hard Thresholding Converges with Optimal Number of Measurements for 1-Bit Compressed Sensing.</a><br />
Namiko Matsumoto (UC San Diego), Arya Mazumdar (UC San Diego).</p>
<p><a href="https://arxiv.org/abs/2203.07771">Optimal mixing for two-state anti-ferromagnetic spin systems.</a><br />
Xiaoyu Chen (Nanjing University), Weiming Feng (University of Edinburgh), Yitong Yin (Nanjing University), Xinyuan Zhang (Nanjing University).</p>
<p><a href="https://arxiv.org/abs/2207.04318">Determinant Maximization via Matroid Intersection Algorithms.</a><br />
Adam Brown (Georgia Insittute of Technology), Aditi Laddha (Georgia Insittute of Technology), Madhusudhan Pittu (Carnegie Mellon University), Mohit Singh (Georgia Insittute of Technology), Prasad Tetali (Carnegie Mellon University).</p>
<p><a href="https://arxiv.org/abs/2111.04958">Breaking the Cubic Barrier for All-Pairs Max-Flow: Gomory-Hu Tree in Nearly Quadratic Time.</a><br />
Amir Abboud (Weizmann Institute of Science), Robert Krauthgamer (Weizmann Institute of Science), Jason Li (UC Berkeley), Debmalya Panigrahi (Duke University), Thatchaphol Saranurak (University of Michigan), Ohad Trabelsi (University of Michigan).</p>
<p><a href="https://arxiv.org/abs/2203.04989">Generalised entropy accumulation.</a><br />
Tony Metger (ETH Zurich), Omar Fawzi (ENS Lyon), David Sutter (IBM Quantum, IBM Research Zurich), Renato Renner (ETH Zurich).</p>
<p><a href="https://arxiv.org/abs/2203.04163">Localization schemes: A framework for proving mixing bounds for Markov chains.</a><br />
Yuansi Chen (Duke University), Ronen Eldan (Microsoft Research).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996905">A tight (non-combinatorial) conditional lower bound for Klee’s Measure Problem in 3D.</a><br />
Marvin Kunnemann (TU Kaiserslautern).</p>
<p><a href="https://arxiv.org/abs/2111.03361">Fast Deterministic Fully Dynamic Distance Approximation.</a><br />
Jan van den Brand (Simons Institute and UC Berkeley), Sebastian Forster (University of Salzburg), Yasamin Nazari (University of Salzburg).</p>
<p><a href="https://arxiv.org/abs/2209.07729">On Weighted Graph Sparsification by Linear Sketching.</a><br />
Yu Chen (University of Pennsylvania), Sanjeev Khanna (University of Pennsylvania), Huan Li (University of Pennsylvania).</p>
<p><a href="https://arxiv.org/abs/2204.03087">Faster Pattern Matching under Edit Distance.</a><br />
Panagiotis Charalampopoulos (Reichman University, Herzliya, Israel and Birkbeck, University of London), Tomasz Kociumaka (UC Berkeley and Max Planck Institute for Informatics, SIC, Germany), Philip Wellnitz (Max Planck Institute for Informatics, SIC, Germany).</p>
<p><a href="https://eccc.weizmann.ac.il/report/2022/119/">NP-Hardness of Learning Programs and Partial MCSP.</a><br />
Shuichi Hirahara (National Institute of Informatics).</p>
<p><a href="https://arxiv.org/abs/2208.00795">An Approximate Generalization of the Okamura-Seymour Theorem.</a><br />
Nikhil Kumar (Hasso Plattner Institute Potsdam).</p>
<p><a href="https://arxiv.org/abs/2111.12706">Gap Edit Distance via Non-Adaptive Queries: Simple and Optimal.</a><br />
Elazar Goldenberg (The Academic College of Tel Aviv-Yafo), Tomasz Kociumaka (UC Berkeley), Robert Krauthgamer (Weizmann Institute of Science), Barna Saha (University of California San Diego).</p>
<p><a href="https://arxiv.org/abs/2208.01078">On Matrix Multiplication and Polynomial Identity Testing.</a><br />
Robert Andrews (University of Illinois Urbana-Champaign).</p>
<p><a href="https://arxiv.org/abs/2204.02095">Streaming Facility Location in High Dimension via Geometric Hashing.</a><br />
Artur Czumaj (University of Warwick), Shaofeng Jiang (Peking University), Robert Krauthgamer (Weizmann Institute of Science), Pavel Vesel? (Charles University), Mingwei Yang (Peking University).</p>
<p><a href="https://arxiv.org/abs/2204.10830">Memory Bounds for Continual Learning.</a><br />
Binghui Peng (Columbia), Christos Papadimitriou (Columbia University), Xi Chen (Columbia University).</p>
<p><a href="https://arxiv.org/abs/2204.08254">Deterministic Low-Diameter Decompositions for Weighted Graphs and Distributed and Parallel Applications.</a><br />
Michael Elkin (Ben-Gurion University of the Negev), Bernhard Haeupler (ETHZ &amp; Carnegie Mellon University), Vaclav Rozho? (ETH Zurich), Christoph Grunau (ETH Zurich).</p>
<p><a href="https://arxiv.org/abs/2211.06920">Having Hope in Hops: New Spanners, Preservers and Lower Bounds for Hopsets.</a><br />
Shimon Kogan (Weizmann Institute), Merav Parter (Weizmann Institute).</p>
<p><a href="https://arxiv.org/abs/2208.11152">Strong XOR Lemma for Communication with Bounded Rounds.</a><br />
Huacheng Yu (Princeton University).</p>
<p><a href="https://arxiv.org/abs/2202.13641">Quantum Tanner codes.</a><br />
Anthony Leverrier (Inria), Gilles Zemor (University of Bordeaux).</p>
<p><a href="https://arxiv.org/abs/2108.04842">Optimal learning of quantum Hamiltonians from high-temperature Gibbs states.</a><br />
Jeongwan Haah (Microsoft Research), Robin Kothari (Microsoft), Ewin Tang (University of Washington).</p>
<p><a href="https://arxiv.org/abs/2204.09951">Motif Cut Sparsifiers.</a><br />
Michael Kapralov (EPFL), Mikhail Makarov (EPFL), Sandeep Silwal (MIT), Christian Sohler (University of Cologne), Jakab Tardos (EPFL).</p>
<p><a href="https://arxiv.org/abs/2203.00671">Maximum Flow and Minimum-Cost Flow in Almost-Linear Time.</a><br />
Li Chen (Georgia Tech), Rasmus Kyng (ETH Zurich), Yang P. Liu (Stanford University), Richard Peng (University of Waterloo), Maximilian Probst Gutenberg (ETH Zurich), Sushant Sachdeva (University of Toronto).</p>
<p><a href="https://arxiv.org/abs/2207.11903">Minimax Rates for Robust Community Detection.</a><br />
Allen Liu (MIT), Ankur Moitra (Math &amp; CSAIL, MIT).</p>
<p><a href="https://eprint.iacr.org/2021/1543.pdf">Post-Quantum Zero Knowledge, Revisited (or: How to Do Quantum Rewinding Undetectably).</a><br />
Alex Lombardi (MIT), Fermi Ma (Simons Institute and UC Berkeley), Nicholas Spooner (University of Warwick).</p>
<p><a href="https://arxiv.org/abs/2206.08810">Interior point methods are not worse than Simplex.</a><br />
Xavier Allamigeon (INRIA &amp; Ecole Polytechnique), Daniel Dadush (CWI Amsterdam), Georg Loho (University of Twente), Bento Natura (London School of Economics and Political Science), Laszlo A. Vegh (London School of Economics and Political Science).</p>
<p><a href="https://arxiv.org/abs/2105.10043">A (Slightly) Improved Bound on the Integrality Gap of the Subtour LP for TSP.</a><br />
Anna Karlin (University of Washington), Nathan Klein (University of Washington), Shayan Oveis Gharan (University of Washington).</p>
<p><a href="https://arxiv.org/abs/2204.07155">Tight Bounds for Quantum State Certification with Incoherent Measurements.</a><br />
Sitan Chen (UC Berkeley), Brice Huang (MIT), Jerry Li (Microsoft Research), Allen Liu (MIT).</p>
<p><a href="https://arxiv.org/abs/2205.00342">Fast Multivariate Multipoint Evaluation Over All Finite Fields.</a><br />
Vishwas Bhargava (Rutgers University), Sumanta Ghosh (Caltech), Zeyu Guo (UT Austin), Mrinal Kumar (IIT Bombay), Chris Umans (Caltech).</p>
<p><a href="https://eprint.iacr.org/2022/1236">Rate-1 Non-Interactive Arguments for Batch-NP and Applications.</a><br />
Lalita Devadas (MIT CSAIL), Rishab Goyal (MIT CSAIL), Yael Tauman Kalai (MIT and Microsoft Research), Vinod Vaikuntanathan (MIT CSAIL).</p>
<p><a href="https://arxiv.org/abs/2205.02168">Separations in Proof Complexity and TFNP.</a><br />
Mika Goos (EPFL), Alexandros Hollender (University of Oxford), Siddhartha Jain (EPFL), Gilbert Maystre (EPFL), William Pires (McGill), Robert Robere (McGill), Ran Tao (McGill).</p>
<p><a href="https://arxiv.org/abs/2208.12896">Randomised Composition and Small-Bias Minimax.</a><br />
Shalev Ben-David (University of Waterloo), Eric Blais (University of Waterloo), Mika Goos (EPFL), Gilbert Maystre (EPFL).</p>
<p><a href="https://ieeexplore.ieee.org/document/9996646">Incrementally Verifiable Computation via Rate-1 Batch Arguments.</a><br />
Omer Paneth (Tel Aviv University), Rafael Pass (Cornell Tech and Tel Aviv University).</p>
<p><a href="https://eccc.weizmann.ac.il/report/2022/097/">Unstructured Hardness to Average-Case Randomness.</a><br />
Lijie Chen (MIT), Ron Rothblum (Technion), Roei Tell (IAS + DIMACS).</p>
<p><a href="https://arxiv.org/abs/2207.11832">New Additive Spanner Lower Bounds by an Unlayered Obstacle Product.</a><br />
Greg Bodwin (University of Michigan), Gary Hoppenworth (University of Michigan).</p>
<p><a href="https://arxiv.org/abs/2209.01901">The Power of Uniform Sampling for Coresets.</a><br />
Vladimir Braverman (Johns Hopkins University), Vincent Cohen-Addad (Google Research, Switzerland), Shaofeng Jiang (Peking University), Robert Krauthgamer (Weizmann Institute of Science), Chris Schwiegelshohn (Aarhus University), Mads Bech Toftrup (Aarhus University), Xuan Wu (Johns Hopkins University).</p>
<p><a href="https://www.cs.purdue.edu/homes/hmaji/papers/BKMN22.pdf">Geometry of Secure Two-party Computation.</a><br />
Saugata Basu (Purdue University), Hamidreza Amini Khorasgani (Purdue University), Hemanta K. Maji (Purdue University), Hai H. Nguyen (Purdue University).</p>
<p><a href="https://arxiv.org/abs/2204.02128">Computing in Anonymous Dynamic Networks Is Linear.</a><br />
Giuseppe Antonio Di Luna (Sapienza University of Rome), Giovanni Viglietta (Japan Advanced Institute of Science and Technology (JAIST)).</p>
<p><a href="https://arxiv.org/abs/2202.13997">Classical Verification of Quantum Computations in Linear Time.</a><br />
Jiayu Zhang (California Institute of Technology).</p>
<p><a href="https://arxiv.org/abs/2209.15149">Pure-Circuit: Strong Inapproximability for PPAD.</a><br />
Argyrios Deligkas (Royal Holloway, University of London), John Fearnley (University of Liverpool), Alexandros Hollender (University of Oxford), Themistoklis Melissourgos (University of Essex).</p>
<p><a href="https://arxiv.org/abs/2204.10306">Performance and limitations of the QAOA at constant levels on large sparse hypergraphs and spin glass models.</a><br />
Joao Basso (Google), David Gamarnik (MIT), Song Mei (University of California, Berkeley), Leo Zhou (California Institute of Technology).</p>
<p><a href="https://arxiv.org/abs/2209.09049">Rounds vs Communication Tradeoffs for Maximal Independent Sets.</a><br />
Sepehr Assadi (Rutgers University), Gillat Kol (Princeton University), Zhijun Zhang (Princeton University).</p>
<p><a href="https://arxiv.org/abs/2205.03710">Almost 3-Approximate Correlation Clustering in Constant Rounds.</a><br />
Soheil Behnezhad (Stanford University), Moses Charikar (Stanford University), Weiyun Ma (Stanford University), Li-Yang Tan (Stanford University).</p>
<p><a href="https://arxiv.org/abs/2111.03142">Inapproximability of Positive Semidefinite Permanents and Quantum State Tomography.</a><br />
Alexander Meiburg (UCSB).</p>
<p><a href="https://arxiv.org/abs/2203.17207">A Proof of the Kahn-Kalai Conjecture.</a><br />
Huy Tuan Pham (Stanford University), Jinyoung Park (Stanford University).</p>
<p><a href="https://arxiv.org/abs/2210.13739">Deterministic Small Vertex Connectivity in Almost Linear Time.</a><br />
Thatchaphol Saranurak (University of Michigan), Sorrachai Yingchareonthawornchai (Aalto University).</p>
<p><a href="https://arxiv.org/abs/2204.02570">Optimal Sublinear Sampling of Spanning Trees and Determinantal Point Processes via Average-Case Entropic Independence.</a><br />
Nima Anari (Stanford University), Yang P. Liu (Stanford University), Thuy-Duong Vuong (Stanford University).</p>
<p><a href="https://eprint.iacr.org/2022/1430">Indistinguishability Obfuscation via Mathematical Proofs of Equivalence.</a><br />
Abhishek Jain (Johns Hopkins University), Zhengzhong Jin (Johns Hopkins University).</p>
<p><strong>Open Problems</strong></p>
<p>Is this of any value? Should we do it for FOCS 2023?</p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-07T13:44:21Z">Tuesday, February 07 2023, 13:44</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/after-you-are-notified-that-article-is.html'>After you are notified that an article is accepted...</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;After just one round of referees reports</p><p>(they send me the reports, I made the corrections, they were happy) I got email saying my paper on proving the primes are infinite FROM Schur's theorem in Ramsey was ACCEPTED. Yeah! Now What?&nbsp;</p><p>1) The journal send me an email with a link GOOD FOR ONLY FIFTY DAYS to help me publicize the article. Here is the link:</p><p>authors.elsevier.com/a/1gTyD,H-cWw6X</p><p><br>Will this really help? The article is already on arxiv. Also, I can blog about it, but how do non-bloggers publicize their work? Do they need to?&nbsp;</p><p>(ADDED LATER: A commenter wanted to know why I am publishing in an Elsevier journal. This was a memorial issue in honor of Bruce Landman, a combinatorist who died young.&nbsp; I was invited to submit an article.)&nbsp;</p><p>QUESTION: Is this common practice? If so, what do you do with those links? Email them to all of your the people who should care about the article?</p><p>2) I got some forms to fill out that asked how many offprints I wanted. While my readers can probably guess what that means, I will remind you: paper copies of the article. I filled out the form:</p><p>I want 0 of them.</p><p>They still wanted to know the address to send the 0 copies to, so I gave that as well.</p><p>Does anyone actually get offprints anymore? That seems so 1990's. With everything on the web I tend to email people who want article pointers. In fact, that happens rarely - either nobody wants to read my articles (quite possible) or they find them on my website (quite possible).&nbsp;</p><p>In 1991 when I went up for tenure the dept wanted 15 copies of every article I wrote so they could send my letter writers (and others) all my stuff. Rumor is that the Governor of Maryland got a copy of every article I ever wrote. I hoped he was a fan of oracle constructions.&nbsp;</p><p>In 1998 when I went up for full prof they did not do this, assuming that the letter writers could find what the needed on the web. I do wonder about that- it might have been a nice courtesy to send them stuff directly and that would be a use for offprints. Depends on if my letter writers prefer reading online or on paper. They could of course print out my papers, but again- as a courtesy perhaps we should have supplied the papers.&nbsp;</p><p>QUESTION: Do you order a non-zero number of offprints and if so why?&nbsp;</p><p>3) The journal offered to have my article to be open access at their site for a price. I did not do this as, again, the article is already on arxiv.</p><p>QUESTION: Is there a reason to have your article formally open-access given that its already on arixv?&nbsp;</p><p>4) One of my co-authors on a different article asked me When will it appear IN PRINT?&nbsp; I can't imagine caring about that. Its already on arxiv and I doubt having it in a journal behind paywalls will increase its visibility AT ALL. The only reason to care about when it appears IN PRINT is so I can update my resume from TO APPEAR to the actual volume and number and year.&nbsp;</p><p>QUESTION: Aside from updating your resume do you care when an article that was accepted appears IN PRINT? And if so why?&nbsp;</p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;After just one round of referees reports</p><p>(they send me the reports, I made the corrections, they were happy) I got email saying my paper on proving the primes are infinite FROM Schur's theorem in Ramsey was ACCEPTED. Yeah! Now What?&nbsp;</p><p>1) The journal send me an email with a link GOOD FOR ONLY FIFTY DAYS to help me publicize the article. Here is the link:</p><p><a data-saferedirecturl="https://www.google.com/url?q=https://authors.elsevier.com/a/1gTyD,H-cWw6X&amp;source=gmail&amp;ust=1674683686602000&amp;usg=AOvVaw2aEyfN69fYfqlMmiFLM6l6" fg_scanned="1" href="https://authors.elsevier.com/a/1gTyD,H-cWw6X" style="background-color: white; color: #007398; font-family: Arial, Helvetica, sans-serif; font-size: 18px; text-align: -webkit-center;" target="_blank">https://authors.elsevier.com/<wbr></wbr>a/1gTyD,H-cWw6X</a></p><p><br />Will this really help? The article is already on arxiv. Also, I can blog about it, but how do non-bloggers publicize their work? Do they need to?&nbsp;</p><p>(ADDED LATER: A commenter wanted to know why I am publishing in an Elsevier journal. This was a memorial issue in honor of Bruce Landman, a combinatorist who died young.&nbsp; I was invited to submit an article.)&nbsp;</p><p>QUESTION: Is this common practice? If so, what do you do with those links? Email them to all of your the people who should care about the article?</p><p>2) I got some forms to fill out that asked how many offprints I wanted. While my readers can probably guess what that means, I will remind you: paper copies of the article. I filled out the form:</p><p>I want 0 of them.</p><p>They still wanted to know the address to send the 0 copies to, so I gave that as well.</p><p>Does anyone actually get offprints anymore? That seems so 1990's. With everything on the web I tend to email people who want article pointers. In fact, that happens rarely - either nobody wants to read my articles (quite possible) or they find them on my website (quite possible).&nbsp;</p><p>In 1991 when I went up for tenure the dept wanted 15 copies of every article I wrote so they could send my letter writers (and others) all my stuff. Rumor is that the Governor of Maryland got a copy of every article I ever wrote. I hoped he was a fan of oracle constructions.&nbsp;</p><p>In 1998 when I went up for full prof they did not do this, assuming that the letter writers could find what the needed on the web. I do wonder about that- it might have been a nice courtesy to send them stuff directly and that would be a use for offprints. Depends on if my letter writers prefer reading online or on paper. They could of course print out my papers, but again- as a courtesy perhaps we should have supplied the papers.&nbsp;</p><p>QUESTION: Do you order a non-zero number of offprints and if so why?&nbsp;</p><p>3) The journal offered to have my article to be open access at their site for a price. I did not do this as, again, the article is already on arxiv.</p><p>QUESTION: Is there a reason to have your article formally open-access given that its already on arixv?&nbsp;</p><p>4) One of my co-authors on a different article asked me <i>When will it appear IN PRINT</i>?&nbsp; I can't imagine caring about that. Its already on arxiv and I doubt having it in a journal behind paywalls will increase its visibility AT ALL. The only reason to care about when it appears IN PRINT is so I can update my resume from TO APPEAR to the actual volume and number and year.&nbsp;</p><p>QUESTION: Aside from updating your resume do you care when an article that was accepted appears IN PRINT? And if so why?&nbsp;</p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-07T01:56:00Z">Tuesday, February 07 2023, 01:56</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.02132'>Reducing Nearest Neighbor Training Sets Optimally and Exactly</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Josiah Rohrer, Simon Weber</p><p>In nearest-neighbor classification, a training set $P$ of points in
$\mathbb{R}^d$ with given classification is used to classify every point in
$\mathbb{R}^d$: Every point gets the same classification as its nearest
neighbor in $P$. Recently, Eppstein [SOSA'22] developed an algorithm to detect
the relevant training points, those points $p\in P$, such that $P$ and
$P\setminus\{p\}$ induce different classifications. We investigate the problem
of finding the minimum cardinality reduced training set $P'\subseteq P$ such
that $P$ and $P'$ induce the same classification. We show that the set of
relevant points is such a minimum cardinality reduced training set if $P$ is in
general position. Furthermore, we show that finding a minimum cardinality
reduced training set for possibly degenerate $P$ is in P for $d=1$, and
NP-complete for $d\geq 2$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rohrer_J/0/1/0/all/0/1">Josiah Rohrer</a>, <a href="http://arxiv.org/find/cs/1/au:+Weber_S/0/1/0/all/0/1">Simon Weber</a></p><p>In nearest-neighbor classification, a training set $P$ of points in
$\mathbb{R}^d$ with given classification is used to classify every point in
$\mathbb{R}^d$: Every point gets the same classification as its nearest
neighbor in $P$. Recently, Eppstein [SOSA'22] developed an algorithm to detect
the relevant training points, those points $p\in P$, such that $P$ and
$P\setminus\{p\}$ induce different classifications. We investigate the problem
of finding the minimum cardinality reduced training set $P'\subseteq P$ such
that $P$ and $P'$ induce the same classification. We show that the set of
relevant points is such a minimum cardinality reduced training set if $P$ is in
general position. Furthermore, we show that finding a minimum cardinality
reduced training set for possibly degenerate $P$ is in P for $d=1$, and
NP-complete for $d\geq 2$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-07T01:30:00Z">Tuesday, February 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.02006'>Robust Budget Pacing with a Single Sample</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Santiago Balseiro, Rachitesh Kumar, Vahab Mirrokni, Balasubramanian Sivan, Di Wang</p><p>Major Internet advertising platforms offer budget pacing tools as a standard
service for advertisers to manage their ad campaigns. Given the inherent
non-stationarity in an advertiser's value and also competing advertisers'
values over time, a commonly used approach is to learn a target expenditure
plan that specifies a target spend as a function of time, and then run a
controller that tracks this plan. This raises the question: how many historical
samples are required to learn a good expenditure plan? We study this question
by considering an advertiser repeatedly participating in $T$ second-price
auctions, where the tuple of her value and the highest competing bid is drawn
from an unknown time-varying distribution. The advertiser seeks to maximize her
total utility subject to her budget constraint. Prior work has shown the
sufficiency of $T\log T$ samples per distribution to achieve the optimal
$O(\sqrt{T})$-regret. We dramatically improve this state-of-the-art and show
that just one sample per distribution is enough to achieve the near-optimal
$\tilde O(\sqrt{T})$-regret, while still being robust to noise in the sampling
distributions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Balseiro_S/0/1/0/all/0/1">Santiago Balseiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Rachitesh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivan_B/0/1/0/all/0/1">Balasubramanian Sivan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Di Wang</a></p><p>Major Internet advertising platforms offer budget pacing tools as a standard
service for advertisers to manage their ad campaigns. Given the inherent
non-stationarity in an advertiser's value and also competing advertisers'
values over time, a commonly used approach is to learn a target expenditure
plan that specifies a target spend as a function of time, and then run a
controller that tracks this plan. This raises the question: how many historical
samples are required to learn a good expenditure plan? We study this question
by considering an advertiser repeatedly participating in $T$ second-price
auctions, where the tuple of her value and the highest competing bid is drawn
from an unknown time-varying distribution. The advertiser seeks to maximize her
total utility subject to her budget constraint. Prior work has shown the
sufficiency of $T\log T$ samples per distribution to achieve the optimal
$O(\sqrt{T})$-regret. We dramatically improve this state-of-the-art and show
that just one sample per distribution is enough to achieve the near-optimal
$\tilde O(\sqrt{T})$-regret, while still being robust to noise in the sampling
distributions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-07T01:30:00Z">Tuesday, February 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.02056'>Sketch-Flip-Merge: Mergeable Sketches for Private Distinct Counting</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jonathan Hehir, Daniel Ting, Graham Cormode</p><p>Data sketching is a critical tool for distinct counting, enabling multisets
to be represented by compact summaries that admit fast cardinality estimates.
Because sketches may be merged to summarize multiset unions, they are a basic
building block in data warehouses. Although many practical sketches for
cardinality estimation exist, none provide privacy when merging. We propose the
first practical cardinality sketches that are simultaneously mergeable,
differentially private (DP), and have low empirical errors. These introduce a
novel randomized algorithm for performing logical operations on noisy bits, a
tight privacy analysis, and provably optimal estimation. Our sketches
dramatically outperform existing theoretical solutions in simulations and on
real-world data.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hehir_J/0/1/0/all/0/1">Jonathan Hehir</a>, <a href="http://arxiv.org/find/cs/1/au:+Ting_D/0/1/0/all/0/1">Daniel Ting</a>, <a href="http://arxiv.org/find/cs/1/au:+Cormode_G/0/1/0/all/0/1">Graham Cormode</a></p><p>Data sketching is a critical tool for distinct counting, enabling multisets
to be represented by compact summaries that admit fast cardinality estimates.
Because sketches may be merged to summarize multiset unions, they are a basic
building block in data warehouses. Although many practical sketches for
cardinality estimation exist, none provide privacy when merging. We propose the
first practical cardinality sketches that are simultaneously mergeable,
differentially private (DP), and have low empirical errors. These introduce a
novel randomized algorithm for performing logical operations on noisy bits, a
tight privacy analysis, and provably optimal estimation. Our sketches
dramatically outperform existing theoretical solutions in simulations and on
real-world data.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-07T01:30:00Z">Tuesday, February 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.02158'>An Effective and Differentially Private Protocol for Secure Distributed Cardinality Estimation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pinghui Wang, Chengjin Yang, Dongdong Xie, Junzhou Zhao, Hui Li, Jing Tao, Xiaohong Guan</p><p>Counting the number of distinct elements distributed over multiple data
holders is a fundamental problem with many real-world applications ranging from
crowd counting to network monitoring. Although a number of space and
computational efficient sketch methods (e.g., the Flajolet-Martin sketch and
the HyperLogLog sketch) for cardinality estimation have been proposed to solve
the above problem, these sketch methods are insecure when considering privacy
concerns related to the use of each data holder's personal dataset. Despite a
recently proposed protocol that successfully implements the well-known
Flajolet-Martin (FM) sketch on a secret-sharing based multiparty computation
(MPC) framework for solving the problem of private distributed cardinality
estimation (PDCE), we observe that this MPC-FM protocol is not differentially
private. In addition, the MPC-FM protocol is computationally expensive, which
limits its applications to data holders with limited computation resources. To
address the above issues, in this paper we propose a novel protocol DP-DICE,
which is computationally efficient and differentially private for solving the
problem of PDCE. Experimental results show that our DP-DICE achieves orders of
magnitude speedup and reduces the estimation error by several times in
comparison with state-of-the-arts under the same security requirements.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pinghui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chengjin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_D/0/1/0/all/0/1">Dongdong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Junzhou Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_J/0/1/0/all/0/1">Jing Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_X/0/1/0/all/0/1">Xiaohong Guan</a></p><p>Counting the number of distinct elements distributed over multiple data
holders is a fundamental problem with many real-world applications ranging from
crowd counting to network monitoring. Although a number of space and
computational efficient sketch methods (e.g., the Flajolet-Martin sketch and
the HyperLogLog sketch) for cardinality estimation have been proposed to solve
the above problem, these sketch methods are insecure when considering privacy
concerns related to the use of each data holder's personal dataset. Despite a
recently proposed protocol that successfully implements the well-known
Flajolet-Martin (FM) sketch on a secret-sharing based multiparty computation
(MPC) framework for solving the problem of private distributed cardinality
estimation (PDCE), we observe that this MPC-FM protocol is not differentially
private. In addition, the MPC-FM protocol is computationally expensive, which
limits its applications to data holders with limited computation resources. To
address the above issues, in this paper we propose a novel protocol DP-DICE,
which is computationally efficient and differentially private for solving the
problem of PDCE. Experimental results show that our DP-DICE achieves orders of
magnitude speedup and reduces the estimation error by several times in
comparison with state-of-the-arts under the same security requirements.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-07T01:30:00Z">Tuesday, February 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.02215'>Linear-time 2-strong connectivity orientations of mixed graphs and related problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Loukas Georgiadis, Dionysios Kefallinos, Evangelos Kosinas</p><p>A mixed graph $G$ is a graph that consists of both undirected and directed
edges. An orientation of $G$ is formed by orienting all the undirected edges of
$G$, i.e., converting each undirected edge $\{u,v\}$ into a directed edge that
is either $(u,v)$ or $(v,u)$. The problem of finding an orientation of a mixed
graph that makes it strongly connected is well understood and can be solved in
linear time. Here we introduce the following orientation problem in mixed
graphs. Given a mixed graph $G$, we wish to compute its maximal sets of
vertices $C_1,C_2,\ldots,C_k$ with the property that by removing any edge $e$
from $G$ (directed or undirected), there is an orientation $R_i$ of
$G\setminus{e}$ such that all vertices in $C_i$ are strongly connected in
$R_i$. We discuss properties of those sets, and we show how to solve this
problem in linear time by reducing it to the computation of the $2$-edge
twinless strongly connected components of a directed graph. A directed graph
$G=(V,E)$ is twinless strongly connected if it contains a strongly connected
spanning subgraph without any pair of antiparallel (or twin) edges. The
twinless strongly connected components (TSCCs) of a directed graph $G$ are its
maximal twinless strongly connected subgraphs. A $2$-edge twinless strongly
connected component (2eTSCC) of $G$ is a maximal subset of vertices $C$ such
that any two vertices $u, v \in C$ are in the same twinless strongly connected
component of $G \setminus e$, for any edge $e$. These concepts have several
diverse applications, such as the design of road and telecommunication
networks, and the structural stability of buildings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Georgiadis_L/0/1/0/all/0/1">Loukas Georgiadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kefallinos_D/0/1/0/all/0/1">Dionysios Kefallinos</a>, <a href="http://arxiv.org/find/cs/1/au:+Kosinas_E/0/1/0/all/0/1">Evangelos Kosinas</a></p><p>A mixed graph $G$ is a graph that consists of both undirected and directed
edges. An orientation of $G$ is formed by orienting all the undirected edges of
$G$, i.e., converting each undirected edge $\{u,v\}$ into a directed edge that
is either $(u,v)$ or $(v,u)$. The problem of finding an orientation of a mixed
graph that makes it strongly connected is well understood and can be solved in
linear time. Here we introduce the following orientation problem in mixed
graphs. Given a mixed graph $G$, we wish to compute its maximal sets of
vertices $C_1,C_2,\ldots,C_k$ with the property that by removing any edge $e$
from $G$ (directed or undirected), there is an orientation $R_i$ of
$G\setminus{e}$ such that all vertices in $C_i$ are strongly connected in
$R_i$. We discuss properties of those sets, and we show how to solve this
problem in linear time by reducing it to the computation of the $2$-edge
twinless strongly connected components of a directed graph. A directed graph
$G=(V,E)$ is twinless strongly connected if it contains a strongly connected
spanning subgraph without any pair of antiparallel (or twin) edges. The
twinless strongly connected components (TSCCs) of a directed graph $G$ are its
maximal twinless strongly connected subgraphs. A $2$-edge twinless strongly
connected component (2eTSCC) of $G$ is a maximal subset of vertices $C$ such
that any two vertices $u, v \in C$ are in the same twinless strongly connected
component of $G \setminus e$, for any edge $e$. These concepts have several
diverse applications, such as the design of road and telecommunication
networks, and the structural stability of buildings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-07T01:30:00Z">Tuesday, February 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.02290'>Maximal $k$-Edge-Connected Subgraphs in Weighted Graphs via Local Random Contraction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chaitanya Nalam, Thatchaphol Saranurak</p><p>The \emph{maximal $k$-edge-connected subgraphs} problem is a classical graph
clustering problem studied since the 70's. Surprisingly, no non-trivial
technique for this problem in weighted graphs is known: a very straightforward
recursive-mincut algorithm with $\Omega(mn)$ time has remained the fastest
algorithm until now. All previous progress gives a speed-up only when the graph
is unweighted, and $k$ is small enough (e.g.~Henzinger~et~al.~(ICALP'15),
Chechik~et~al.~(SODA'17), and Forster~et~al.~(SODA'20)).
</p>
<p>We give the first algorithm that breaks through the long-standing
$\tilde{O}(mn)$-time barrier in \emph{weighted undirected} graphs. More
specifically, we show a maximal $k$-edge-connected subgraphs algorithm that
takes only $\tilde{O}(m\cdot\min\{m^{3/4},n^{4/5}\})$ time. As an immediate
application, we can $(1+\epsilon)$-approximate the \emph{strength} of all edges
in undirected graphs in the same running time.
</p>
<p>Our key technique is the first local cut algorithm with \emph{exact}
cut-value guarantees whose running time depends only on the output size. All
previous local cut algorithms either have running time depending on the cut
value of the output, which can be arbitrarily slow in weighted graphs or have
approximate cut guarantees.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nalam_C/0/1/0/all/0/1">Chaitanya Nalam</a>, <a href="http://arxiv.org/find/cs/1/au:+Saranurak_T/0/1/0/all/0/1">Thatchaphol Saranurak</a></p><p>The \emph{maximal $k$-edge-connected subgraphs} problem is a classical graph
clustering problem studied since the 70's. Surprisingly, no non-trivial
technique for this problem in weighted graphs is known: a very straightforward
recursive-mincut algorithm with $\Omega(mn)$ time has remained the fastest
algorithm until now. All previous progress gives a speed-up only when the graph
is unweighted, and $k$ is small enough (e.g.~Henzinger~et~al.~(ICALP'15),
Chechik~et~al.~(SODA'17), and Forster~et~al.~(SODA'20)).
</p>
<p>We give the first algorithm that breaks through the long-standing
$\tilde{O}(mn)$-time barrier in \emph{weighted undirected} graphs. More
specifically, we show a maximal $k$-edge-connected subgraphs algorithm that
takes only $\tilde{O}(m\cdot\min\{m^{3/4},n^{4/5}\})$ time. As an immediate
application, we can $(1+\epsilon)$-approximate the \emph{strength} of all edges
in undirected graphs in the same running time.
</p>
<p>Our key technique is the first local cut algorithm with \emph{exact}
cut-value guarantees whose running time depends only on the output size. All
previous local cut algorithms either have running time depending on the cut
value of the output, which can be arbitrarily slow in weighted graphs or have
approximate cut guarantees.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-07T01:30:00Z">Tuesday, February 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, February 06
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/02/06/back-from-a-vacation/'>Back From A Vacation</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I am just back from a multi-week vacation on the cruise ship the Voyager. My dear wife&#8212;Kathryn Farley&#8212;and I were on the trip together with her brother. It was wonderful. It was relaxing and terrific. Well Not Exactly When I first got on the ship I had to reset my wifi connection on my laptop. [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I am just back from a multi-week vacation on the cruise ship the Voyager.<br />
<a href="https://rjlipton.wpcomstaging.com/2023/02/06/back-from-a-vacation/ship/" rel="attachment wp-att-20993"><img data-attachment-id="20993" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/06/back-from-a-vacation/ship/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ship.jpg?fit=550%2C366&amp;ssl=1" data-orig-size="550,366" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ship" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ship.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ship.jpg?fit=550%2C366&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ship.jpg?resize=550%2C366&#038;ssl=1" alt="" width="550" height="366" class="aligncenter size-full wp-image-20993" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ship.jpg?w=550&amp;ssl=1 550w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ship.jpg?resize=300%2C200&amp;ssl=1 300w" sizes="(max-width: 550px) 100vw, 550px" data-recalc-dims="1" /></a></p>
<p>My dear wife&#8212;Kathryn Farley&#8212;and I were on the trip together with<br />
<a href="https://rjlipton.wpcomstaging.com/2023/02/06/back-from-a-vacation/kf/" rel="attachment wp-att-20991"><img data-attachment-id="20991" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/06/back-from-a-vacation/kf/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/kf.jpg?fit=1200%2C1005&amp;ssl=1" data-orig-size="1200,1005" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kf" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/kf.jpg?fit=300%2C251&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/kf.jpg?fit=600%2C503&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/kf.jpg?resize=600%2C503&#038;ssl=1" alt="" width="600" height="503" class="aligncenter size-full wp-image-20991" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/kf.jpg?w=1200&amp;ssl=1 1200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/kf.jpg?resize=300%2C251&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/kf.jpg?resize=1024%2C858&amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/kf.jpg?resize=768%2C643&amp;ssl=1 768w" sizes="(max-width: 600px) 100vw, 600px" data-recalc-dims="1" /></a></p>
<p>her brother. It was wonderful. It was relaxing and terrific.</p>
<p><H1>Well Not Exactly</H1></p>
<p>When I first got on the ship I had to reset my wifi connection on my laptop. Somehow I messed it up and it failed. I then tried to reconnect and the internet connection failed again and I could not reconnect it ever. Suggestions like: Open your Settings app and tap Network &#038; internet or Connections. Depending on your device, these options may be different. Turn Wi-Fi off and mobile data on, and check if there&#8217;s a difference. If not, turn mobile data off and Wi-Fi on and check again. never worked. Not ever. The rest of the cruise I gave up&#8212;I was after all on a vacation. I decided I did not need the internet, email, or Google. I still enjoyed the time.</p>
<p><H2The Problem More Exactly</H2></p>
<p>But this raised an interesting problem: How do we search the settings of a laptop and reset the state? Somehow the state of the laptop got messed up and then I could not get it reset to the correct state. Being on a ship made it harder to reconnect and actually made it impossible. I just got stuff working after being back at home in NYC</p>
<p>Here is the technical problem that I faced. My laptop was in a correct state let&#8217;s denote it as <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{S}" class="latex" />. Then I messed it up somehow to the state <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BS%5E%7B%5Cbf+bad%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{S^{&#92;bf bad}}" class="latex" />. Since I cleverly did not keep a clean state I did not know how to get back to the state <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{S}" class="latex" />. The trouble with this problem was:</p>
<blockquote><p>
The state I was in on the laptop did not work; the state was not one that allowed the laptop to do anything useful. Anything. For example it did not allow me to do Google searches. Thus I could not try to see how to get to a useful state.
</p></blockquote>
<p>I did ask an &#8220;expert&#8221; that was on the ship for help. But he was an expert but not one who could help.</p>
<p><H2>The Problem Even More Exactly</H2></p>
<p>Imagine the laptop is in some state <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BS%5E%7B%5Cbf+bad%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{S^{&#92;bf bad}}" class="latex" />. How do we try to find the correct state <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{S}" class="latex" />? The interesting issue is that tools like Google are not available while you are in the wrong state. You can edit some part of the state but then when you try and use the laptop the state may still not work. You can then try another state, but it may stlll be broken. Good luck.</p>
<p><H2>Open Problems</H2></p>
<p>How would you have attacked this problem? I gave up after a while. What would you have done?</p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-06T13:22:30Z">Monday, February 06 2023, 13:22</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.01858'>A Computational Separation Between Quantum No-cloning and No-teleportation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Barak Nehoran, Mark Zhandry</p><p>Two of the fundamental no-go theorems of quantum information are the
no-cloning theorem (that it is impossible to make copies of general quantum
states) and the no-teleportation theorem (the prohibition on sending quantum
states over classical channels without pre-shared entanglement). They are known
to be equivalent, in the sense that a collection of quantum states is clonable
if and only if it is teleportable. Our main result suggests that this is not
the case when computational efficiency is considered. We give a collection of
quantum states and oracles relative to which these states are efficiently
clonable but not efficiently teleportable. Given that the opposite scenario is
impossible (states that can be teleported can always trivially be cloned), this
gives the most complete oracle separation possible between these two important
no-go properties. In doing so, we introduce a related quantum no-go property,
reconstructibility, which refers to the ability to construct a quantum state
from a uniquely identifying classical description. We show the stronger result
of a collection of quantum states that are efficiently clonable but not
efficiently reconstructible. This novel no-go property only exists in relation
to computational efficiency, as it is trivial for unbounded computation. It
thus opens up the possibility of further computational no-go properties that
have not yet been studied because they do not exist outside the computational
context.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Nehoran_B/0/1/0/all/0/1">Barak Nehoran</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhandry_M/0/1/0/all/0/1">Mark Zhandry</a></p><p>Two of the fundamental no-go theorems of quantum information are the
no-cloning theorem (that it is impossible to make copies of general quantum
states) and the no-teleportation theorem (the prohibition on sending quantum
states over classical channels without pre-shared entanglement). They are known
to be equivalent, in the sense that a collection of quantum states is clonable
if and only if it is teleportable. Our main result suggests that this is not
the case when computational efficiency is considered. We give a collection of
quantum states and oracles relative to which these states are efficiently
clonable but not efficiently teleportable. Given that the opposite scenario is
impossible (states that can be teleported can always trivially be cloned), this
gives the most complete oracle separation possible between these two important
no-go properties. In doing so, we introduce a related quantum no-go property,
reconstructibility, which refers to the ability to construct a quantum state
from a uniquely identifying classical description. We show the stronger result
of a collection of quantum states that are efficiently clonable but not
efficiently reconstructible. This novel no-go property only exists in relation
to computational efficiency, as it is trivial for unbounded computation. It
thus opens up the possibility of further computational no-go properties that
have not yet been studied because they do not exist outside the computational
context.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-06T01:30:00Z">Monday, February 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.01405'>Complexity of Solo Chess with Unlimited Moves</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Josh Brunner, Lily Chung, Michael Coulombe, Erik D. Demaine, Timothy Gomez, Jayson Lynch</p><p>We analyze Solo Chess puzzles, where the input is an $n \times n$ board
containing some standard Chess pieces of the same color, and the goal is to
make a sequence of capture moves to reduce down to a single piece. Prior work
analyzes this puzzle for a single piece type when each piece is limited to make
at most two capture moves (as in the Solo Chess puzzles on chess.com). By
contrast, we study when each piece can make an unlimited number of capture
moves. We show that any single piece type can be solved in polynomial time in a
general model of piece types, while any two standard Chess piece types are
NP-complete. We also analyze the restriction (as on chess.com) that one piece
type is unique and must be the last surviving piece, showing that in this case
some pairs of piece types become tractable while others remain hard.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brunner_J/0/1/0/all/0/1">Josh Brunner</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_L/0/1/0/all/0/1">Lily Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Coulombe_M/0/1/0/all/0/1">Michael Coulombe</a>, <a href="http://arxiv.org/find/cs/1/au:+Demaine_E/0/1/0/all/0/1">Erik D. Demaine</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_T/0/1/0/all/0/1">Timothy Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Lynch_J/0/1/0/all/0/1">Jayson Lynch</a></p><p>We analyze Solo Chess puzzles, where the input is an $n \times n$ board
containing some standard Chess pieces of the same color, and the goal is to
make a sequence of capture moves to reduce down to a single piece. Prior work
analyzes this puzzle for a single piece type when each piece is limited to make
at most two capture moves (as in the Solo Chess puzzles on chess.com). By
contrast, we study when each piece can make an unlimited number of capture
moves. We show that any single piece type can be solved in polynomial time in a
general model of piece types, while any two standard Chess piece types are
NP-complete. We also analyze the restriction (as on chess.com) that one piece
type is unique and must be the last surviving piece, showing that in this case
some pairs of piece types become tractable while others remain hard.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-06T01:30:00Z">Monday, February 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.01373'>Optimal Heaviest Induced Ancestors</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Panagiotis Charalampopoulos, Bart&#x142;omiej Dudek, Pawe&#x142; Gawrychowski, Karol Pokorski</p><p>We revisit the Heaviest Induced Ancestors (HIA) problem that was introduced
by Gagie, Gawrychowski, and Nekrich [CCCG 2013] and has a number of
applications in string algorithms. Let $T_1$ and $T_2$ be two rooted trees
whose nodes have weights that are increasing in all root-to-leaf paths, and
labels on the leaves, such that no two leaves of a tree have the same label. A
pair of nodes $(u, v)\in T_1 \times T_2$ is \emph{induced} if and only if there
is a label shared by leaf-descendants of $u$ and $v$. In an HIA query, given
nodes $x \in T_1$ and $y \in T_2$, the goal is to find an induced pair of nodes
$(u, v)$ of the maximum total weight such that $u$ is an ancestor of~$x$ and
$v$ is an ancestor of $y$.
</p>
<p>Let $n$ be the upper bound on the sizes of the two trees. It is known that no
data structure of size $\tilde{\mathcal{O}}(n)$ can answer HIA queries in
$o(\log n / \log \log n)$ time [Charalampopoulos, Gawrychowski, Pokorski; ICALP
2020]. This (unconditional) lower bound is a $\operatorname{polyloglog} n$
factor away from the query time of the fastest $\tilde{\mathcal{O}}(n)$-size
data structure known to date for the HIA problem [Abedin, Hooshmand, Ganguly,
Thankachan; Algorithmica 2022]. In this work, we resolve the query-time
complexity of the HIA problem for the near-linear space regime by presenting a
data structure that can be built in $\tilde{\mathcal{O}}(n)$ time and answers
HIA queries in $\mathcal{O}(\log n/\log\log n)$ time. As a direct corollary, we
obtain an $\tilde{\mathcal{O}}(n)$-size data structure that maintains the LCS
of a static string and a dynamic string, both of length at most $n$, in time
optimal for this space regime.
</p>
<p>The main ingredients of our approach are fractional cascading and the
utilization of an $\mathcal{O}(\log n/ \log\log n)$-depth tree decomposition.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Charalampopoulos_P/0/1/0/all/0/1">Panagiotis Charalampopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Dudek_B/0/1/0/all/0/1">Bart&#x142;omiej Dudek</a>, <a href="http://arxiv.org/find/cs/1/au:+Gawrychowski_P/0/1/0/all/0/1">Pawe&#x142; Gawrychowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Pokorski_K/0/1/0/all/0/1">Karol Pokorski</a></p><p>We revisit the Heaviest Induced Ancestors (HIA) problem that was introduced
by Gagie, Gawrychowski, and Nekrich [CCCG 2013] and has a number of
applications in string algorithms. Let $T_1$ and $T_2$ be two rooted trees
whose nodes have weights that are increasing in all root-to-leaf paths, and
labels on the leaves, such that no two leaves of a tree have the same label. A
pair of nodes $(u, v)\in T_1 \times T_2$ is \emph{induced} if and only if there
is a label shared by leaf-descendants of $u$ and $v$. In an HIA query, given
nodes $x \in T_1$ and $y \in T_2$, the goal is to find an induced pair of nodes
$(u, v)$ of the maximum total weight such that $u$ is an ancestor of~$x$ and
$v$ is an ancestor of $y$.
</p>
<p>Let $n$ be the upper bound on the sizes of the two trees. It is known that no
data structure of size $\tilde{\mathcal{O}}(n)$ can answer HIA queries in
$o(\log n / \log \log n)$ time [Charalampopoulos, Gawrychowski, Pokorski; ICALP
2020]. This (unconditional) lower bound is a $\operatorname{polyloglog} n$
factor away from the query time of the fastest $\tilde{\mathcal{O}}(n)$-size
data structure known to date for the HIA problem [Abedin, Hooshmand, Ganguly,
Thankachan; Algorithmica 2022]. In this work, we resolve the query-time
complexity of the HIA problem for the near-linear space regime by presenting a
data structure that can be built in $\tilde{\mathcal{O}}(n)$ time and answers
HIA queries in $\mathcal{O}(\log n/\log\log n)$ time. As a direct corollary, we
obtain an $\tilde{\mathcal{O}}(n)$-size data structure that maintains the LCS
of a static string and a dynamic string, both of length at most $n$, in time
optimal for this space regime.
</p>
<p>The main ingredients of our approach are fractional cascading and the
utilization of an $\mathcal{O}(\log n/ \log\log n)$-depth tree decomposition.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-06T01:30:00Z">Monday, February 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.01546'>Group Fairness in Non-monotone Submodular Maximization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jing Yuan, Shaojie Tang</p><p>Maximizing a submodular function has a wide range of applications in machine
learning and data mining. One such application is data summarization whose goal
is to select a small set of representative and diverse data items from a large
dataset. However, data items might have sensitive attributes such as race or
gender, in this setting, it is important to design \emph{fairness-aware}
algorithms to mitigate potential algorithmic bias that may cause over- or
under- representation of particular groups. Motivated by that, we propose and
study the classic non-monotone submodular maximization problem subject to novel
group fairness constraints. Our goal is to select a set of items that maximizes
a non-monotone submodular function, while ensuring that the number of selected
items from each group is proportionate to its size, to the extent specified by
the decision maker. We develop the first constant-factor approximation
algorithms for this problem. We also extend the basic model to incorporate an
additional global size constraint on the total number of selected items.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Jing Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Shaojie Tang</a></p><p>Maximizing a submodular function has a wide range of applications in machine
learning and data mining. One such application is data summarization whose goal
is to select a small set of representative and diverse data items from a large
dataset. However, data items might have sensitive attributes such as race or
gender, in this setting, it is important to design \emph{fairness-aware}
algorithms to mitigate potential algorithmic bias that may cause over- or
under- representation of particular groups. Motivated by that, we propose and
study the classic non-monotone submodular maximization problem subject to novel
group fairness constraints. Our goal is to select a set of items that maximizes
a non-monotone submodular function, while ensuring that the number of selected
items from each group is proportionate to its size, to the extent specified by
the decision maker. We develop the first constant-factor approximation
algorithms for this problem. We also extend the basic model to incorporate an
additional global size constraint on the total number of selected items.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-06T01:30:00Z">Monday, February 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.01748'>Chaining of Maximal Exact Matches in Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicola Rizzo, Manuel C&#xe1;ceres, Veli M&#xe4;kinen</p><p>We study the problem of finding maximal exact matches (MEMs) between a query
string $Q$ and a labeled directed acyclic graph (DAG) $G=(V,E,\ell)$ and
subsequently co-linearly chaining these matches. We show that it suffices to
compute MEMs between node labels and $Q$ (node MEMs) to encode full MEMs. Node
MEMs can be computed in linear time and we show how to co-linearly chain them
to solve the Longest Common Subsequence (LCS) problem between $Q$ and $G$. Our
chaining algorithm is the first to consider a symmetric formulation of the
chaining problem in graphs and runs in $O(k^2|V| + |E| + kN\log N)$ time, where
$k$ is the width (minimum number of paths covering the nodes) of $G$, and $N$
is the number of node MEMs. We then consider the problem of finding MEMs when
the input graph is an indexable elastic founder graph (subclass of labeled DAGs
studied by Equi et al., Algorithmica 2022). For arbitrary input graphs, the
problem cannot be solved in truly sub-quadratic time under SETH (Equi et al.,
ICALP 2019). We show that we can report all MEMs between $Q$ and an indexable
elastic founder graph in time $O(nH^2 + m + M_\kappa)$, where $n$ is the total
length of node labels, $H$ is the maximum number of nodes in a block of the
graph, $m = |Q|$, and $M_\kappa$ is the number of MEMs of length at least
$\kappa$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rizzo_N/0/1/0/all/0/1">Nicola Rizzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Caceres_M/0/1/0/all/0/1">Manuel C&#xe1;ceres</a>, <a href="http://arxiv.org/find/cs/1/au:+Makinen_V/0/1/0/all/0/1">Veli M&#xe4;kinen</a></p><p>We study the problem of finding maximal exact matches (MEMs) between a query
string $Q$ and a labeled directed acyclic graph (DAG) $G=(V,E,\ell)$ and
subsequently co-linearly chaining these matches. We show that it suffices to
compute MEMs between node labels and $Q$ (node MEMs) to encode full MEMs. Node
MEMs can be computed in linear time and we show how to co-linearly chain them
to solve the Longest Common Subsequence (LCS) problem between $Q$ and $G$. Our
chaining algorithm is the first to consider a symmetric formulation of the
chaining problem in graphs and runs in $O(k^2|V| + |E| + kN\log N)$ time, where
$k$ is the width (minimum number of paths covering the nodes) of $G$, and $N$
is the number of node MEMs. We then consider the problem of finding MEMs when
the input graph is an indexable elastic founder graph (subclass of labeled DAGs
studied by Equi et al., Algorithmica 2022). For arbitrary input graphs, the
problem cannot be solved in truly sub-quadratic time under SETH (Equi et al.,
ICALP 2019). We show that we can report all MEMs between $Q$ and an indexable
elastic founder graph in time $O(nH^2 + m + M_\kappa)$, where $n$ is the total
length of node labels, $H$ is the maximum number of nodes in a block of the
graph, $m = |Q|$, and $M_\kappa$ is the number of MEMs of length at least
$\kappa$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-06T01:30:00Z">Monday, February 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.01827'>Online Ad Allocation with Predictions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fabian Spaeh, Alina Ene</p><p>Display Ads and the generalized assignment problem are two well-studied
online packing problems with important applications in ad allocation and other
areas. In both problems, ad impressions arrive online and have to be allocated
immediately to budget-constrained advertisers. Worst-case algorithms that
achieve the ideal competitive ratio are known, but might act overly
conservative given the predictable and usually tame nature of real-world input.
Given this discrepancy, we develop an algorithm for both problems that
incorporate machine-learned predictions and can thus improve the performance
beyond the worst-case. Our algorithm is based on the work of Feldman et al.
(2009) and similar in nature to Mahdian et al. (2007) who were the first to
develop a learning-augmented algorithm for the related, but more structured Ad
Words problem. We use a novel analysis to show that our algorithm is able to
capitalize on a good prediction, while being robust against poor predictions.
We experimentally evaluate our algorithm on synthetic and real-world data on a
wide range of predictions. Our algorithm is consistently outperforming the
worst-case algorithm without predictions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Spaeh_F/0/1/0/all/0/1">Fabian Spaeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ene_A/0/1/0/all/0/1">Alina Ene</a></p><p>Display Ads and the generalized assignment problem are two well-studied
online packing problems with important applications in ad allocation and other
areas. In both problems, ad impressions arrive online and have to be allocated
immediately to budget-constrained advertisers. Worst-case algorithms that
achieve the ideal competitive ratio are known, but might act overly
conservative given the predictable and usually tame nature of real-world input.
Given this discrepancy, we develop an algorithm for both problems that
incorporate machine-learned predictions and can thus improve the performance
beyond the worst-case. Our algorithm is based on the work of Feldman et al.
(2009) and similar in nature to Mahdian et al. (2007) who were the first to
develop a learning-augmented algorithm for the related, but more structured Ad
Words problem. We use a novel analysis to show that our algorithm is able to
capitalize on a good prediction, while being robust against poor predictions.
We experimentally evaluate our algorithm on synthetic and real-world data on a
wide range of predictions. Our algorithm is consistently outperforming the
worst-case algorithm without predictions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-06T01:30:00Z">Monday, February 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.01873'>Qubit-Efficient Randomized Quantum Algorithms for Linear Algebra</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samson Wang, Sam McArdle, Mario Berta</p><p>We propose a class of randomized quantum algorithms for the task of sampling
from matrix functions, without the use of quantum block encodings or any other
coherent oracle access to the matrix elements. As such, our use of qubits is
purely algorithmic, and no additional qubits are required for quantum data
structures. For $N\times N$ Hermitian matrices, the space cost is $\log(N)+1$
qubits and depending on the structure of the matrices, the gate complexity can
be comparable to state-of-the-art methods that use quantum data structures of
up to size $O(N^2)$, when considering equivalent end-to-end problems. Within
our framework, we present a quantum linear system solver that allows one to
sample properties of the solution vector, as well as an algorithm for sampling
properties of ground states of Hamiltonians. As a concrete application, we
combine these two sub-routines to present a scheme for calculating Green's
functions of quantum many-body systems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Wang_S/0/1/0/all/0/1">Samson Wang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+McArdle_S/0/1/0/all/0/1">Sam McArdle</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Berta_M/0/1/0/all/0/1">Mario Berta</a></p><p>We propose a class of randomized quantum algorithms for the task of sampling
from matrix functions, without the use of quantum block encodings or any other
coherent oracle access to the matrix elements. As such, our use of qubits is
purely algorithmic, and no additional qubits are required for quantum data
structures. For $N\times N$ Hermitian matrices, the space cost is $\log(N)+1$
qubits and depending on the structure of the matrices, the gate complexity can
be comparable to state-of-the-art methods that use quantum data structures of
up to size $O(N^2)$, when considering equivalent end-to-end problems. Within
our framework, we present a quantum linear system solver that allows one to
sample properties of the solution vector, as well as an algorithm for sampling
properties of ground states of Hamiltonians. As a concrete application, we
combine these two sub-routines to present a scheme for calculating Green's
functions of quantum many-body systems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-06T01:30:00Z">Monday, February 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, February 05
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/02/05/nathan-never-strikes-back/'>Nathan Never strikes back</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Amiga Germany Fan’zine – #5 features Nathan Never, 30 years after the game came out (the article is from some months ago, but I just found out). You can read the article here. My first day of high school I was looking for a desk, and the one that was left was occupied by Marco [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><a href="http://amiga-germany-fanzine.de/produkt/amiga-germany-fanzine-5/">Amiga Germany Fan’zine – #5</a> features <a href="https://www.ccs.neu.edu/home/viola/#Nineties">Nathan Never</a>, 30 years after the game came out (the article is from some months ago, but I just found out).  You can read the article <a href="https://www.ccs.neu.edu/home/viola/pix/nathan-never-press">here</a>.</p>



<p>My first day of high school I was looking for a desk, and the one that was left was occupied by <a href="http://www.marcogenovesi.com/">Marco Genovesi</a> (also see <a href="https://emanueleviola.wordpress.com/2016/12/10/black-viper/">previous post about Black Viper</a>, our other game together, also featured in article). We had both programmed a little the mythical C64.  I had written in basic a fighting game inspired by <a href="https://emanueleviola.wordpress.com/2016/08/05/hokuto-no-ken-and-growing-up-in-italy/">Hokuto No Ken</a>. It was hand-coded pixellated sprites doing flying martial arts kicks.  It was on a cassette &#8212; I didn&#8217;t have a floppy disk. I would love to see it again, but it seems lost forever. It was my first game, written sometime when I was between 10 and 12.</p>



<p>If I think back at my schools, from elementary to high, I scream in horror.  There was <em>nothing</em>.  No play-yard, no props, nothing.  Even the walls! How much does it cost to hang a world map? Instead they were solid color. We were 8-1 or something, every day, including Saturdays, in a room with solid color walls, solid color desks, and a blackboard, and that&#8217;s it. Perhaps no wonder that I exercised my art and craft on what I had. I dismembered floppy disks, cassettes, speakers etc. and stuck them on the wall.  I scribbled all over my desk.</p>



<p>At some point I got an Amiga 1000 (my trajectory was Spectrum 48K, Commodore 64, Amiga 1000). Naturally I wanted to program, but had <em>zero </em>leads.  Unlike today, it was very hard to get started.  Interestingly, people more experienced than me had the same complaint, like &#8220;when I was 13 myself good luck finding an assembler.&#8221; Actually, I think things will continue to move in this direction. Even today, learning something isn&#8217;t that easy, and one can imagine how in 20 years you&#8217;ll have tutorials precisely tailored to <em>your</em> background, instead of having to zap through youtube to find the small step you&#8217;re missing.<br /></p>



<p>So for a while I was stuck fiddling with startup sequences and shell commands. I remember my parents puzzled at why I wasn&#8217;t doing anything fancy like on the C64.<br />&#8220;You&#8217;re still at <em>popcli</em>&#8221; (a type of shell, known back then as CLI, command line interface) they told me once &#8212;  I am cursed with good memory.<br />My reply was &#8220;You need a program to write a program.&#8221; They looked puzzled. (And so was I, after all, I didn&#8217;t need one on the C64.)</p>



<p>My turning point occurred when I did one of my stupid things. I was balancing myself on the top beam of a swing. Naturally, I fell, didn&#8217;t land right, and injured my ankle. I was stuck in my room for a month, and one day Marco showed up and brought me the <em>Amiga hardware reference manual</em>, a book we had overheard was critical.  I thanked him and I remember him saying: &#8220;I am doing it for me.&#8221;  This book became my bible. I thrashed the stupid C compilers, got an assembler, and started &#8220;bashing metal&#8221; and having <em>fun</em>.</p>



<p>Then there was the store. I don&#8217;t remember how I ended up there. It sold games, so maybe I was just there to buy games.  But I never bought a new game &#8212; only pirate &#8212; so the explanation doesn&#8217;t stand.  Anyway, we were there and the person there was a techno-musician who knew people who wanted to make a game on Nathan Never, a pretty high-profile graphic novel series in Italy.</p>



<p>To this day I am shocked they didn&#8217;t find anyone else, since as I said it&#8217;s pretty high-profile. Maybe the programmer wanted too much money, or ditched them last moment and they needed the game fast. Who knows. I had just barely started programming on Amiga, but&#8230; I know blitter, I know copper; I am obviously ready for a major project.</p>



<p>So we signed the contract, and I insisted on some money upfront which I got. A few Ks. The development of the game was covered in <a href="https://www.ccs.neu.edu/home/viola/pix/nathan-never-press/">games magazines, </a>which other people in our high school were devouring. They were shocked to find out the team was us! Waking around, we would pass by a store and find the box of the game on display.</p>



<p>As part of my deal I managed to get an Amiga 3000 tower, a one-of-a-kind machine, which for a kid like me was a dream. Before that, I didn&#8217;t have enough memory to play the game from the assembler with the graphics loaded, so when I tested it I would see dots instead of sprites.  Marco, who did the graphics, at the beginning didn&#8217;t have a color monitor, and would pick colors from the hex code, quite cool.  I brought the 3000T to our vacation that summer, and instead of going to the sea (which I hated) I stayed indoor to program.  Naturally, I spent 50% (easily) of that time programming a script that would compile an animation through a landscape of fractal mountains. The final animation was quite cool.</p>



<p>I wish the game was more fun to play.  It isn&#8217;t really my fault: no experience, no time, and crucially the people who imposed the game design on us were not players but exclusively concerned with showing the main character, whose frames occupy most of the memory. More than the game they cared about the graphic novel that came with it in the box.  Of all the people buzzing around the game, I was the only one who actually played computer games (I still do).  Still, of course, I could have improved the gameplay.  Instead, on an ultra-tight deadline, I decided to embark on a 3D &#8220;escape from the tunnel&#8221; last level, something they didn&#8217;t ask for (they were happy with an animation, which would have cost me zero effort) and that probably almost noone has seen, since to get there you need to beat two grueling platform levels a puzzle level, with one life and no save state.  (The 3D level starts at 20:09 in <a href="https://www.ccs.neu.edu/home/viola/movies/NathanNever.mp4">this long play</a>.) And this is what it means to be 14.</p>



<p>On the bright side, however, perhaps the game has its unique charm, and today it can be played on a hard disk through the emulator, even though the game was not designed to be installed on a hard disk.  And this is great because playing the game from the disks is <em>really</em> painful, despite or in part because of a crazy color hack to make a 3D &#8220;change disk&#8221; message (another uncalled-for feature). And it&#8217;s a good feeling that after 30+ years some people are still watching and playing the game.</p>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-05T16:17:22Z">Sunday, February 05 2023, 16:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/02/05/artificial-intelligence-just-lost-a-leader/'>Artificial Intelligence Just Lost a Leader</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Plus a position-search announcement from NSF Roger Schank just passed away. Roger was a top leader of AI. I overlapped with him for my time at Yale. In 1974, he became a professor of computer science and psychology at Yale University. In 1981, Schank became Chairman of Computer Science at Yale and director of the [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>Plus a position-search announcement from NSF</em><br />
<font color="#000000"></p>
<p>Roger Schank just passed away. Roger was a top leader of AI. I overlapped with him for my time at Yale. In 1974, he became a professor of computer science and psychology at Yale University. In 1981, Schank became Chairman of Computer Science at Yale and director of the Yale Artificial Intelligence Project. I was gone by then off to Berkeley.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/05/artificial-intelligence-just-lost-a-leader/rs-2/" rel="attachment wp-att-20982"><img data-attachment-id="20982" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/05/artificial-intelligence-just-lost-a-leader/rs-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/rs.jpeg?fit=268%2C188&amp;ssl=1" data-orig-size="268,188" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rs" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/rs.jpeg?fit=268%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/rs.jpeg?fit=268%2C188&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/rs.jpeg?resize=268%2C188&#038;ssl=1" alt="" width="268" height="188" class="aligncenter size-full wp-image-20982" data-recalc-dims="1" /></a></p>
<p>John Brockman <a href="https://www.edge.org/3rd_culture/schank/schank_index.html#:~:text=Roger%20Schank%20is%20a%20computer,to%20deconstruct%20the%20human%20mind.">wrote</a>: He is a computer scientist and cognitive psychologist who has worked in the AI field for twenty-five years. Like Marvin Minsky, he takes the strong AI view, but rather than trying to build an intelligent machine he wants to deconstruct the human mind. He wants to know, in particular, how natural language&#8212; one&#8217;s mother tongue &#8212; is processed, how memory works, and how learning occurs. Schank thinks of the human mind as a learning device, and he thinks that it is being taught in the wrong way. He is something of a gadfly; he deplores the curriculum-based, drill-oriented methods in today&#8217;s schools, and his most recent contributions have been in the area of education, looking at ways to use computers to enhance the learning process.</p>
<p><strong>Roger&#8217;s View</strong></p>
<p>Roger was a scary guy&#8212;especially for junior theory faculty like me. I did get along with Roger and he did support me when I was up for tenure. But he was scary no matter what. Part of the issue was that Roger did not think much of any research that was not AI based. Theory was not a top issue in his view.</p>
<p><strong>Beat Roger Out</strong></p>
<p>At Yale once Schank walked into Alan Perlis&#8217;s office and told Alan that he had thought about some post-doc position we had funding for. Schank began to explain to Perlis that he, Roger, had a couple of ideas of who he planned to hire to fill this position&#8212;of course the position was his. Perlis waved him off and said,</p>
<p><em>Lipton already has found a candidate and the position is gone.</em></p>
<p>I was not there, so all this is second-hand from Perlis, but I can imagine that Roger was not pleased&#8212;in his mind all resources of the department should have gone to build up the AI group. Roger was initially upset, but after this event he acted differently toward me. He treated me with more respect&#8212;in general theory was not his type of research. I always thought that he respected someone who &#8220;beat&#8221; him at the resource game, since he was such a strong player. I probably should not do it again, but doing it once was cool.</p>
<p>Years later, after Roger had moved to Northwestern University, he tried hard to hire me. Perhaps I should have gone. Oh well.</p>
<p><strong>Open Problems</strong></p>
<p>We want to announce this from Dilma Da Silva:</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/05/artificial-intelligence-just-lost-a-leader/dd-2/" rel="attachment wp-att-20983"><img data-attachment-id="20983" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/05/artificial-intelligence-just-lost-a-leader/dd-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/dd.jpeg?fit=299%2C168&amp;ssl=1" data-orig-size="299,168" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="dd" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/dd.jpeg?fit=299%2C168&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/dd.jpeg?fit=299%2C168&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/dd.jpeg?resize=299%2C168&#038;ssl=1" alt="" width="299" height="168" class="aligncenter size-full wp-image-20983" data-recalc-dims="1" /></a></p>
<blockquote><p>
The Division Director, Computing and Communication Foundations (CCF) of NSF: NSF/CCF is looking for an IPA (rotator) Program Director (PD) for the Algorithm Foundation cluster. The job posting for the IPA PD position is available at here. My colleague Tracy Kimbrel and I will be happy to address any questions that potential applicants may have.
</p></blockquote>
<p>
[sourced Brockman quote, added subtitle for NSF announcement]</p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-05T15:03:39Z">Sunday, February 05 2023, 15:03</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/008'>TR23-008 |  Limits of structures and Total NP Search Problems | 

	Ond?ej Ježil</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          For a class of finite graphs, we define a limit object relative to some computationally restricted class of functions. The properties of the limit object then reflect how a computationally restricted viewer &quot;sees&quot; a generic instance from the class. The construction uses Krají?ek&#39;s forcing with random variables [7]. We prove sufficient conditions for universal and existential sentences to be valid in the limit, provide several examples, and prove that such a limit object can then be expanded to a model of weak arithmetic. We then take the limit of all finite pointed paths to obtain a model of arithmetic where the problem OntoWeakPigeon is total but Leaf (the complete problem for $\textbf{PPA}$) is not. This can be viewed as a logical separation of the oracle classes of total NP search problems, which in our setting implies standard nonreducibility of Leaf to OntoWeakPigeon.
        
        </div>

        <div class='tr-article-summary'>
        
          
          For a class of finite graphs, we define a limit object relative to some computationally restricted class of functions. The properties of the limit object then reflect how a computationally restricted viewer &quot;sees&quot; a generic instance from the class. The construction uses Krají?ek&#39;s forcing with random variables [7]. We prove sufficient conditions for universal and existential sentences to be valid in the limit, provide several examples, and prove that such a limit object can then be expanded to a model of weak arithmetic. We then take the limit of all finite pointed paths to obtain a model of arithmetic where the problem OntoWeakPigeon is total but Leaf (the complete problem for $\textbf{PPA}$) is not. This can be viewed as a logical separation of the oracle classes of total NP search problems, which in our setting implies standard nonreducibility of Leaf to OntoWeakPigeon.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-05T08:30:13Z">Sunday, February 05 2023, 08:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, February 04
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://dstheory.wordpress.com/2023/02/04/thursday-feb-9th-2023-amit-chakrabarti-from-dartmouth-college/'>Thursday, Feb 9th, 2023 — Amit Chakrabarti from Dartmouth College</a></h3>
        <p class='tr-article-feed'>from <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next Foundations of Data Science virtual talk series on recent advances in adversarially robust streaming will take place on Thursday, February 9th at 2:00 PM Pacific Time (17:00 Eastern Time, 23:59 Central European Time, 22:00 UTC). Amit Chakrabarti from Dartmouth College will talk about “How to color your adversary&#8217;s graph” Details of the talkContinue reading "Thursday, Feb 9th, 2023 — Amit Chakrabarti from Dartmouth&#160;College"
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="has-text-align-justify">The next <a rel="noreferrer noopener" href="https://sites.google.com/view/dstheory/home" target="_blank">Foundations of Data Science</a> virtual talk series on recent advances in <em>adversarially robust streaming</em> will take place on <strong>Thursday, February 9th</strong> at <strong>2:00 PM Pacific Time</strong> (17:00 Eastern Time, 23:59 Central European Time, 22:00 UTC). <a href="http://www.cs.dartmouth.edu/~ac">Amit Chakrabarti</a> from<strong> Dartmouth College</strong> will talk about <em>“How to color your adversary&#8217;s graph”</em></p>



<p><a href="https://sites.google.com/view/dstheory">Details of the talk (Zoom link) are available here.</a></p>



<p class="has-text-align-justify">An n-vertex graph with maximum degree D is (D+1)-colorable: an almost trivial combinatorial result, with an equally simple greedy algorithm to produce a (D+1)-coloring. However, given a stream of edges of such a graph, can we maintain a valid (D+1)-coloring as the edges arrive, while using not much more than O(n) space? What if the edges are chosen by an adversary who can look at our current coloring and add additional edges to try to confound us? This is the newly-popular setting of adversarially robust streaming algorithms and this talk is about the coloring problem in this setting.</p>



<p class="has-text-align-justify">We obtain upper and lower bound results for this problem. In O(n polylog n) space, we can maintain an O(D^(5/2))-coloring of such an adversarial graph. On the other hand, every adversarially robust coloring algorithm under the same space limitation must spend Omega(D^2) colors. We in fact prove more general. results that trade off the space usage against the color budget.&nbsp; One interesting by-product of our work is that in combination with the celebrated Assadi-Chen-Khanna algorithm (SODA 2019), it provides the first separation between randomized and deterministic algorithms for the (ordinary, non-robust) streaming graph coloring problem.</p>



<p>Based on joint works [C.-Ghosh-Stoeckl] and [Assadi-C.-Ghosh-Stoeckl].</p>



<p>&nbsp;The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p>
<p class="authors">By dstheory</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-04T19:49:34Z">Saturday, February 04 2023, 19:49</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, February 03
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/03/postdoc-at-ist-austria-apply-by-march-15-2023/'>Postdoc at IST Austria (apply by March 15, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Postdoctorial positions at IST Austria are available funded by the ERC Advanced Grant &#8220;Modern Dynamic Data Structures, led by Prof. Monika Henzinger Website: ist.ac.at/en/job/postdoc-research-group-monika-henzinger/ Email: monika.henzinger@ista.ac.at
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Postdoctorial positions at IST Austria are available funded by the ERC Advanced Grant &#8220;Modern Dynamic Data Structures, led by Prof. Monika Henzinger</p>
<p>Website: <a href="https://ist.ac.at/en/job/postdoc-research-group-monika-henzinger/">https://ist.ac.at/en/job/postdoc-research-group-monika-henzinger/</a><br />
Email: monika.henzinger@ista.ac.at</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T12:26:50Z">Friday, February 03 2023, 12:26</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/007'>TR23-007 |  Extended Nullstellensatz proof systems | 

	Jan  Krajicek</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          For a finite set $\cal F$ of polynomials over a fixed finite prime field of size  $p$ containing all polynomials $x^2 - x$, a Nullstellensatz proof of the unsolvability of the system
$$
	f = 0\ ,\ \mbox{ all } f \in {\cal F}
$$
is a linear combination $\sum_{f \in {\cal F}} \ h_f \cdot f$ that equals to $1$ in the ring of polynomials. The measure of complexity of such a proof is its degree: $\max_f deg(h_f f)$.

We study the problem to establish degree lower bounds for some {\em extended} NS proof systems: these systems prove the unsolvability of $\cal F$ by proving the unsolvability of a bigger set ${\cal F}\cup {\cal E}$, where set $\cal E$ may use more variables $r$ and contains polynomials $r^p - r$ for them, and satisfies the following soundness condition:
 
-- Any $0,1$-assignment ${\overline a}$ to variables ${\overline x}$ can be appended by an assignment ${\overline b}$ to variables $\overline r$ such that for all $g \in {\cal E}$ it holds that $g(\overline a, \overline b) = 0$.

We define a notion of pseudo-solutions of $\cal F$ and prove that the existence of pseudo-solutions with suitable parameters implies lower bounds for two extended NS proof systems ENS and UENS defined in Buss et al. (1996/97). Further we give a combinatorial example of $\cal F$ and candidate pseudo-solutions based on the pigeonhole principle.
        
        </div>

        <div class='tr-article-summary'>
        
          
          For a finite set $\cal F$ of polynomials over a fixed finite prime field of size  $p$ containing all polynomials $x^2 - x$, a Nullstellensatz proof of the unsolvability of the system
$$
	f = 0\ ,\ \mbox{ all } f \in {\cal F}
$$
is a linear combination $\sum_{f \in {\cal F}} \ h_f \cdot f$ that equals to $1$ in the ring of polynomials. The measure of complexity of such a proof is its degree: $\max_f deg(h_f f)$.

We study the problem to establish degree lower bounds for some {\em extended} NS proof systems: these systems prove the unsolvability of $\cal F$ by proving the unsolvability of a bigger set ${\cal F}\cup {\cal E}$, where set $\cal E$ may use more variables $r$ and contains polynomials $r^p - r$ for them, and satisfies the following soundness condition:
 
-- Any $0,1$-assignment ${\overline a}$ to variables ${\overline x}$ can be appended by an assignment ${\overline b}$ to variables $\overline r$ such that for all $g \in {\cal E}$ it holds that $g(\overline a, \overline b) = 0$.

We define a notion of pseudo-solutions of $\cal F$ and prove that the existence of pseudo-solutions with suitable parameters implies lower bounds for two extended NS proof systems ENS and UENS defined in Buss et al. (1996/97). Further we give a combinatorial example of $\cal F$ and candidate pseudo-solutions based on the pigeonhole principle.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T08:33:12Z">Friday, February 03 2023, 08:33</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.01145'>This Game Is Not Going To Analyze Itself</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aviv Adler, Joshua Ani, Lily Chung, Michael Coulombe, Erik D. Demaine, Yevhenii Diomidov, Dylan Hendrickson, Jayson Lynch</p><p>We analyze the puzzle video game This Game Is Not Going To Load Itself, where
the player routes data packets of three different colors from given sources to
given sinks of the correct color. Given the sources, sinks, and some previously
placed arrow tiles, we prove that the game is in Sigma_2^P; in NP for sources
of equal period; NP-complete for three colors and six equal-period sources with
player input; and even without player input, simulating the game is both NP-
and coNP-hard for two colors and many sources with different periods. On the
other hand, we characterize which locations for three data sinks admit a
perfect placement of arrow tiles that guarantee correct routing no matter the
placement of the data sources, effectively solving most instances of the game
as it is normally played.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Adler_A/0/1/0/all/0/1">Aviv Adler</a>, <a href="http://arxiv.org/find/cs/1/au:+Ani_J/0/1/0/all/0/1">Joshua Ani</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_L/0/1/0/all/0/1">Lily Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Coulombe_M/0/1/0/all/0/1">Michael Coulombe</a>, <a href="http://arxiv.org/find/cs/1/au:+Demaine_E/0/1/0/all/0/1">Erik D. Demaine</a>, <a href="http://arxiv.org/find/cs/1/au:+Diomidov_Y/0/1/0/all/0/1">Yevhenii Diomidov</a>, <a href="http://arxiv.org/find/cs/1/au:+Hendrickson_D/0/1/0/all/0/1">Dylan Hendrickson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lynch_J/0/1/0/all/0/1">Jayson Lynch</a></p><p>We analyze the puzzle video game This Game Is Not Going To Load Itself, where
the player routes data packets of three different colors from given sources to
given sinks of the correct color. Given the sources, sinks, and some previously
placed arrow tiles, we prove that the game is in Sigma_2^P; in NP for sources
of equal period; NP-complete for three colors and six equal-period sources with
player input; and even without player input, simulating the game is both NP-
and coNP-hard for two colors and many sources with different periods. On the
other hand, we characterize which locations for three data sinks admit a
perfect placement of arrow tiles that guarantee correct routing no matter the
placement of the data sources, effectively solving most instances of the game
as it is normally played.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T01:30:00Z">Friday, February 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00724'>Order-Preserving Squares in Strings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pawe&#x142; Gawrychowski, Samah Ghazawi, Gad M. Landau</p><p>An order-preserving square in a string is a fragment of the form $uv$ where
$u\neq v$ and $u$ is order-isomorphic to $v$. We show that a string $w$ of
length $n$ over an alphabet of size $\sigma$ contains $\mathcal{O}(\sigma n)$
order-preserving squares that are distinct as words. This improves the upper
bound of $\mathcal{O}(\sigma^{2}n)$ by Kociumaka, Radoszewski, Rytter, and
Wale\'n [TCS 2016]. Further, for every $\sigma$ and $n$ we exhibit a string
with $\Omega(\sigma n)$ order-preserving squares that are distinct as words,
thus establishing that our upper bound is asymptotically tight. Finally, we
design an $\mathcal{O}(\sigma n)$ time algorithm that outputs all
order-preserving squares that occur in a given string and are distinct as
words. By our lower bound, this is optimal in the worst case.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gawrychowski_P/0/1/0/all/0/1">Pawe&#x142; Gawrychowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghazawi_S/0/1/0/all/0/1">Samah Ghazawi</a>, <a href="http://arxiv.org/find/cs/1/au:+Landau_G/0/1/0/all/0/1">Gad M. Landau</a></p><p>An order-preserving square in a string is a fragment of the form $uv$ where
$u\neq v$ and $u$ is order-isomorphic to $v$. We show that a string $w$ of
length $n$ over an alphabet of size $\sigma$ contains $\mathcal{O}(\sigma n)$
order-preserving squares that are distinct as words. This improves the upper
bound of $\mathcal{O}(\sigma^{2}n)$ by Kociumaka, Radoszewski, Rytter, and
Wale\'n [TCS 2016]. Further, for every $\sigma$ and $n$ we exhibit a string
with $\Omega(\sigma n)$ order-preserving squares that are distinct as words,
thus establishing that our upper bound is asymptotically tight. Finally, we
design an $\mathcal{O}(\sigma n)$ time algorithm that outputs all
order-preserving squares that occur in a given string and are distinct as
words. By our lower bound, this is optimal in the worst case.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T01:30:00Z">Friday, February 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00737'>A Universal Technique for Machine-Certified Proofs of Linearizable Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prasad Jayanti, Siddhartha Jayanti, Ugur Y. Yavuz, Lizzie Hernandez</p><p>Linearizability has been the long standing gold standard for consistency in
concurrent data structures. However, proofs of linearizability can be long and
intricate, hard to produce, and extremely time consuming even to verify. In
this work, we address this issue by introducing simple $universal$, $sound$,
and $complete$ proof methods for producing machine-verifiable proofs of
linearizability and its close cousin, strong linearizability. Universality
means that our method works for any object type; soundness means that an
algorithm can be proved correct by our method only if it is linearizable (resp.
strong linearizable); and completeness means that any linearizable (resp.
strong linearizable) implementation can be proved so using our method. We
demonstrate the simplicity and power of our method by producing proofs of
linearizability for the Herlihy-Wing queue and Jayanti's single-scanner
snapshot, as well as a proof of strong linearizability of the Jayanti-Tarjan
union-find object. All three of these proofs are machine-verified by TLAPS (the
Temporal Logic of Actions Proof System).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jayanti_P/0/1/0/all/0/1">Prasad Jayanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayanti_S/0/1/0/all/0/1">Siddhartha Jayanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Yavuz_U/0/1/0/all/0/1">Ugur Y. Yavuz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_L/0/1/0/all/0/1">Lizzie Hernandez</a></p><p>Linearizability has been the long standing gold standard for consistency in
concurrent data structures. However, proofs of linearizability can be long and
intricate, hard to produce, and extremely time consuming even to verify. In
this work, we address this issue by introducing simple $universal$, $sound$,
and $complete$ proof methods for producing machine-verifiable proofs of
linearizability and its close cousin, strong linearizability. Universality
means that our method works for any object type; soundness means that an
algorithm can be proved correct by our method only if it is linearizable (resp.
strong linearizable); and completeness means that any linearizable (resp.
strong linearizable) implementation can be proved so using our method. We
demonstrate the simplicity and power of our method by producing proofs of
linearizability for the Herlihy-Wing queue and Jayanti's single-scanner
snapshot, as well as a proof of strong linearizability of the Jayanti-Tarjan
union-find object. All three of these proofs are machine-verified by TLAPS (the
Temporal Logic of Actions Proof System).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T01:30:00Z">Friday, February 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00748'>Constant RMR Recoverable Mutex under System-wide Crashes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prasad Jayanti, Siddhartha Jayanti, Anup Joshi</p><p>We design two Recoverable Mutual Exclusion (RME) locks for the system-wide
crash model. Our first algorithm requires only $O(1)$ space per process, and
achieves $O(1)$ worst-case RMR complexity in the CC model. Our second algorithm
enhances the first algorithm to achieve (the same) $O(1)$ space per process and
$O(1)$ worst-case RMR complexity in both the CC and DSM models. Furthermore,
both algorithms allow dynamically created threads of arbitrary names to join
the protocol and access the locks. To our knowledge, these are the only RME
locks to achieve worst-case $O(1)$ RMR complexity assuming nothing more than
standard hardware support. In light of Chan and Woelfel's $\Omega(\log n /
\log\log n)$ worst-case RMR lower bound for RME in the individual crash model,
our results show a separation between the system-wide crash and individual
crash models in worst-case RMR complexity in both the CC and DSM models.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jayanti_P/0/1/0/all/0/1">Prasad Jayanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayanti_S/0/1/0/all/0/1">Siddhartha Jayanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1">Anup Joshi</a></p><p>We design two Recoverable Mutual Exclusion (RME) locks for the system-wide
crash model. Our first algorithm requires only $O(1)$ space per process, and
achieves $O(1)$ worst-case RMR complexity in the CC model. Our second algorithm
enhances the first algorithm to achieve (the same) $O(1)$ space per process and
$O(1)$ worst-case RMR complexity in both the CC and DSM models. Furthermore,
both algorithms allow dynamically created threads of arbitrary names to join
the protocol and access the locks. To our knowledge, these are the only RME
locks to achieve worst-case $O(1)$ RMR complexity assuming nothing more than
standard hardware support. In light of Chan and Woelfel's $\Omega(\log n /
\log\log n)$ worst-case RMR lower bound for RME in the individual crash model,
our results show a separation between the system-wide crash and individual
crash models in worst-case RMR complexity in both the CC and DSM models.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T01:30:00Z">Friday, February 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00928'>Rethinking Warm-Starts with Predictions: Learning Predictions Close to Sets of Optimal Solutions for Faster $\text{L}$-/$\text{L}^\natural$-Convex Function Minimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shinsaku Sakaue, Taihei Oki</p><p>An emerging line of work has shown that machine-learned predictions are
useful to warm-start algorithms for discrete optimization problems, such as
bipartite matching. Previous studies have shown time complexity bounds
proportional to some distance between a prediction and an optimal solution,
which we can approximately minimize by learning predictions from past optimal
solutions. However, such guarantees may not be meaningful when multiple optimal
solutions exist. Indeed, the dual problem of bipartite matching and, more
generally, $\text{L}$-/$\text{L}^\natural$-convex function minimization have
arbitrarily many optimal solutions, making such prediction-dependent bounds
arbitrarily large. To resolve this theoretically critical issue, we present a
new warm-start-with-prediction framework for
$\text{L}$-/$\text{L}^\natural$-convex function minimization. Our framework
offers time complexity bounds proportional to the distance between a prediction
and the set of all optimal solutions. The main technical difficulty lies in
learning predictions that are provably close to sets of all optimal solutions,
for which we present an online-gradient-descent-based method. We thus give the
first polynomial-time learnability of predictions that can provably warm-start
algorithms regardless of multiple optimal solutions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sakaue_S/0/1/0/all/0/1">Shinsaku Sakaue</a>, <a href="http://arxiv.org/find/cs/1/au:+Oki_T/0/1/0/all/0/1">Taihei Oki</a></p><p>An emerging line of work has shown that machine-learned predictions are
useful to warm-start algorithms for discrete optimization problems, such as
bipartite matching. Previous studies have shown time complexity bounds
proportional to some distance between a prediction and an optimal solution,
which we can approximately minimize by learning predictions from past optimal
solutions. However, such guarantees may not be meaningful when multiple optimal
solutions exist. Indeed, the dual problem of bipartite matching and, more
generally, $\text{L}$-/$\text{L}^\natural$-convex function minimization have
arbitrarily many optimal solutions, making such prediction-dependent bounds
arbitrarily large. To resolve this theoretically critical issue, we present a
new warm-start-with-prediction framework for
$\text{L}$-/$\text{L}^\natural$-convex function minimization. Our framework
offers time complexity bounds proportional to the distance between a prediction
and the set of all optimal solutions. The main technical difficulty lies in
learning predictions that are provably close to sets of all optimal solutions,
for which we present an online-gradient-descent-based method. We thus give the
first polynomial-time learnability of predictions that can provably warm-start
algorithms regardless of multiple optimal solutions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T01:30:00Z">Friday, February 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00985'>Speed-Oblivious Online Scheduling: Knowing (Precise) Speeds is not Necessary</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Lindermayr, Nicole Megow, Martin Rapp</p><p>We consider online scheduling on unrelated (heterogeneous) machines in a
speed-oblivious setting, where an algorithm is unaware of the exact
job-dependent processing speeds. We show strong impossibility results for
clairvoyant and non-clairvoyant algorithms and overcome them in models inspired
by practical settings: (i) we provide competitive learning-augmented
algorithms, assuming that (possibly erroneous) predictions on the speeds are
given, and (ii) we provide competitive algorithms for the speed-ordered model,
where a single global order of machines according to their unknown
job-dependent speeds is known. We prove strong theoretical guarantees and
evaluate our findings on a representative heterogeneous multi-core processor.
These seem to be the first empirical results for algorithms with predictions
that are performed in a non-synthetic environment on real hardware.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lindermayr_A/0/1/0/all/0/1">Alexander Lindermayr</a>, <a href="http://arxiv.org/find/cs/1/au:+Megow_N/0/1/0/all/0/1">Nicole Megow</a>, <a href="http://arxiv.org/find/cs/1/au:+Rapp_M/0/1/0/all/0/1">Martin Rapp</a></p><p>We consider online scheduling on unrelated (heterogeneous) machines in a
speed-oblivious setting, where an algorithm is unaware of the exact
job-dependent processing speeds. We show strong impossibility results for
clairvoyant and non-clairvoyant algorithms and overcome them in models inspired
by practical settings: (i) we provide competitive learning-augmented
algorithms, assuming that (possibly erroneous) predictions on the speeds are
given, and (ii) we provide competitive algorithms for the speed-ordered model,
where a single global order of machines according to their unknown
job-dependent speeds is known. We prove strong theoretical guarantees and
evaluate our findings on a representative heterogeneous multi-core processor.
These seem to be the first empirical results for algorithms with predictions
that are performed in a non-synthetic environment on real hardware.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T01:30:00Z">Friday, February 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, February 02
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/02/postdoc-at-centre-for-quantum-computer-science-university-of-latvia-apply-by-february-20-2023/'>Postdoc at Centre for Quantum Computer Science, University of Latvia (apply by February 20, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Applications are invited for a postdoctoral position at the Centre for Quantum Computer Science, University of Latvia (www.quantum.lu.lv), lead by prof. Andris Ambainis. The Centre is among the strongest European research groups in quantum algorithms and currently consists of 18 researchers (including postdocs and graduate students). Website: quantum.lu.lv/join-us/ Email: andris.ambainis@lu.lv
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Applications are invited for a postdoctoral position at the Centre for Quantum Computer Science, University of Latvia (<a href="https://www.quantum.lu.lv">https://www.quantum.lu.lv</a>), lead by prof. Andris Ambainis. The Centre is among the strongest European research groups in quantum algorithms and currently consists of 18 researchers (including postdocs and graduate students).</p>
<p>Website: <a href="https://quantum.lu.lv/join-us/">https://quantum.lu.lv/join-us/</a><br />
Email: andris.ambainis@lu.lv</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T22:21:11Z">Thursday, February 02 2023, 22:21</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://francisbach.com/non-convex-quadratic-problems/'>Non-convex quadratic optimization problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://francisbach.com'>Francis Bach</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Among continuous optimization problems, convex problems (with convex objectives and convex constraints) define a class that can be solved efficiently with a variety of algorithms and with arbitrary precision. This is not true more generally when the convexity assumption is removed (see this post). This of course does not mean that (1) nobody should attempt...
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="justify-text">Among continuous optimization problems, convex problems (with convex objectives and convex constraints) define a class that can be solved efficiently with a variety of algorithms and with arbitrary precision. This is not true more generally when the convexity assumption is removed (see <a href="https://francisbach.com/optimization-is-as-hard-as-approximation/">this post</a>). This of course does not mean that (1) nobody should attempt to solve high-dimensional non-convex problems (in fact, the spell checker run on this document was trained solving such a problem&#8230;), and that (2) no other problems have efficient solutions.</p>



<p class="justify-text">In this post, we will look at a classical class of continuous optimization problems that can be solved efficiently, namely quadratic optimization problems on the Euclidean sphere or ball. That is, we look at solving $$\tag{1} \min_{ \| x\| \leqslant 1} \ \frac{1}{2} x^\top A x \ &#8211; b^\top x, $$ and $$\tag{2} \min_{ \| x\| = 1} \ \frac{1}{2} x^\top A x \ &#8211; b^\top x,  $$ for \(\|x\|^2 = x^\top x\) the standard squared Euclidean norm.</p>



<p class="justify-text">The matrix \(A \in \mathbb{R}^{n \times n}\) is assumed only symmetric (no need to be positive semi-definite), and \(b \in \mathbb{R}^n\). Therefore, the objective may not be convex, and the constraint set (in the case of the sphere), is not convex either. We could replace the standard squared Euclidean norm \(x^\top x\) by any Mahanalobis squared norm \(x^\top B x\) for \(B\) positive-definite, but to keep it simple, let&#8217;s only consider \(B = I\).</p>



<p class="justify-text">Note that there are other continuous non-convex optimization problems that can be solved efficiently through a convex reformulation, such as the minimization of one-dimensional (trigonometric) polynomials, and more generally sum-of-squares problems (see <a href="https://francisbach.com/sums-of-squares-for-dummies/">this post</a>). If you are aware of many more beyond combinatorial optimization problems, please let me know.</p>



<p class="justify-text"><strong>Special case of eigenvalues.</strong> If \(b=0\) (no linear term), then the solution of Problem \((2)\) is the eigenvector associated with the smallest eigenvalue of \(A\), while the solution of Problem \((1)\) is the same eigenvector if the smallest eigenvalue of \(A\) is negative, and zero otherwise. This has a large number of applications, is the topic of tons of <a href="https://www.google.com/search?q=spectral+relaxation">&#8220;spectral relaxation&#8221; works</a>, and will not be the focus of this post.</p>



<h2>Applications</h2>



<p class="justify-text">Problems \((1)\) and \((2)\) appear in several areas and first appeared in [<a href="https://epubs.siam.org/doi/epdfplus/10.1137/0113073">2</a>] in 1965 (if you know of an earlier reference, please let me know). The three main occurrences that I am aware of are in <a href="https://en.wikipedia.org/wiki/Trust_region">trust-region methods</a>, constrained eigenvalue problems, and relaxation of binary optimization problems.</p>



<p class="justify-text"><strong>Trust-region methods.</strong> When minimizing a differentiable function \(f\) on \(\mathbb{R}^n\), the classical gradient descent iteration $$x^+ = x \, &#8211; \gamma f(x)$$ can be seen as the solution of $$\min_{y \in \mathbb{R}^n} \ f(x) + f'(x)^\top ( y\,  &#8211; x ) \mbox{ such that } \| y\,  &#8211; x\| \leqslant \delta,$$ for \(\delta = \gamma  \| f'(x)\|_2\). This corresponds to minimizing the first-order Taylor expansion in a ball centered at \(x\), and leads to the minimization of an affine function on an Euclidean ball. When using the second order model, we get to solve $$\min_{y \in \mathbb{R}^n} \ f(x) + f'(x)^\top ( y \, &#8211; x ) + \frac{1}{2} ( y\,  -x )^\top f^{\prime \prime}(x) ( y \, -x ) \mbox{ such that } \| y \, &#8211; x\| \leqslant \delta, $$ which can be cast as Problem \((1)\).</p>



<p class="justify-text">The intuitive idea is that the Taylor expansion is only local, so we optimize it locally, instead of globally, like the classical Newton method would do. Moreover, it is well-defined even for singular Hessians. See figure below and [4] for more details.</p>


<div class="wp-block-image justify-text">
<figure class="aligncenter size-full is-resized"><img src="https://francisbach.com/wp-content/uploads/2023/01/tr-2.png" alt="" class="wp-image-8723" width="779" height="280" srcset="https://francisbach.com/wp-content/uploads/2023/01/tr-2.png 2514w, https://francisbach.com/wp-content/uploads/2023/01/tr-2-300x108.png 300w, https://francisbach.com/wp-content/uploads/2023/01/tr-2-1024x369.png 1024w, https://francisbach.com/wp-content/uploads/2023/01/tr-2-768x277.png 768w, https://francisbach.com/wp-content/uploads/2023/01/tr-2-1536x554.png 1536w, https://francisbach.com/wp-content/uploads/2023/01/tr-2-2048x738.png 2048w, https://francisbach.com/wp-content/uploads/2023/01/tr-2-850x306.png 850w" sizes="(max-width: 779px) 100vw, 779px" /><figcaption>We consider two quadratic functions and we compare the minimization of their linear and quadratic Taylor expansions under a ball constraint with increasing radius. Left: convex function (hence the quadratic minimization ends up reaching the global minimum). Right: function with a saddle. Below, only the quadratic minimization path is shown for several starting points.</figcaption></figure></div>

<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img loading="lazy" src="https://francisbach.com/wp-content/uploads/2023/01/video_tr-1.gif" alt="" class="wp-image-8747" width="547" height="353"/></figure></div>


<p class="justify-text"><strong>Constrained eigenvalue problems.</strong> If we aim to minimize \(x^\top A x\) subject to \(x^\top x = 1\) and an affine constraint [<a href="https://www.sciencedirect.com/science/article/pii/0024379589904941/pdf?md5=754201682cef36aa80a3ef681fce6d62&amp;pid=1-s2.0-0024379589904941-main.pdf">3</a>], then, by writing the affine constraint as \(x = Cz+d\), we obtain the minimization of a quadratic-linear function subject to a quadratic-linear constraint, which we can rewrite in a form similar to Problem \((2)\).</p>



<p class="justify-text"><strong>Relaxation of binary optimization problems.</strong> When minimizing a linear-quadratic function on \(\{-1,1\}^n\), we can relax it by replacing the constraint \(x \in \{-1,1\}^n\) by \(x^\top x = n\).</p>



<h2>From local to global optimality conditions</h2>



<p class="justify-text">Let&#8217;s now look at optimality conditions from first principles (see [<a href="http://users.clas.ufl.edu/hager/papers/Regular/sphere.pdf">5</a>, <a href="https://epubs.siam.org/doi/epdf/10.1137/0719026">6</a>] for more details), before relating them to a broader discussion on tight semi-definite relaxations.</p>



<p class="justify-text"><strong>Existence of minimizers.</strong> Minimizers always exists for \(f(x) = \frac{1}{2} x^\top A x \ &#8211; b^\top x\) since the two sets \(\mathbb{S} = \{ x \in \mathbb{R}^n, x^\top x = 1\}\) and \(\mathbb{B} = \{ x \in \mathbb{R}^n, x^\top x \leqslant 1\}\) are compact. Therefore, the problems are well-formulated.</p>



<p class="justify-text"><strong>First-order necessary conditions on the sphere. </strong>We consider an optimal \(x \in \mathbb{S}\). For any \(y \in \mathbb{S}\) which is orthogonal to \(x\), and any \(\theta  \in \mathbb{R}\), we have: $$f( \cos \theta \cdot x + \sin \theta \cdot y) = f(x) + f'(x)^\top y \cdot \theta + o(\theta).$$ Thus, since \(\cos \theta \cdot x + \sin \theta \cdot y\) is always on \(\mathbb{S}\), we must have \(f'(x)^\top y=0\), and this holds for all \(y\) orthogonal to \(x\). Thus \(f'(x)\) has to be proportional to \(x\), that is, there exists \(\mu \in \mathbb{R}\) such that \(f'(x) + \mu x = 0\), that is, \((A + \mu I) x = b\).  </p>



<p class="justify-text"><strong>First-order necessary conditions on the ball.</strong> If \(x \in \mathbb{B}\) is optimal and in the interior, that is, \(x^\top x &lt; 1\), then we directly have \(f'(x) = 0\). If \(x \in \mathbb{S}\), it has to be optimal for the sphere, and thus there exists \(\mu \in \mathbb{R}\) such that \(f'(x) + \mu x = 0\).  By considering that \(g: t \mapsto f(t x)\) has to be minimized on \([0,1]\), for \(t=1\), we must have \(g'(1) \leqslant 0\), i.e., \(\mu = \, &#8211; f'(x) ^\top x \geqslant 0\). </p>



<p class="justify-text">In order to cover the interior case, we need to add the &#8220;complementary slackness&#8221; condition \(\mu ( 1 -x^\top x)=0\).</p>



<p class="justify-text"><strong>Obtaining necessary conditions from Lagrange duality.</strong> We can obtain the same first-order optimality conditions using <a href="https://en.wikipedia.org/wiki/Duality_(optimization)">Lagrange duality</a>, by adding a Lagrange multiplier \(\mu \in \mathbb{R}\) for the equality constraint \(x^\top x = 1\), or \(\mu \in \mathbb{R}_+\) for the inequality constraint \(x^\top x \leqslant 1\), and forming the Lagrangian $$\tag{3} \mathcal{L}(x,\mu) = \frac{1}{2} x^\top A x\, &#8211; b^\top x + \frac{1}{2} \mu ( x^\top x\, &#8211; 1).$$ A necessary condition is thus that the partial derivative with respect to \(x\) is zero for a certain \(\mu\), which is exactly the condition \(f'(x) + \mu x = 0\) above.</p>



<p class="justify-text"><strong>Second-order conditions on the sphere.</strong> Assuming that \(f'(x) + \mu x = 0\), with \(\mu\) potentially negative (i.e., the first-order optimality conditions are satisfied), we then have, for any \(y \in \mathbb{S}\), $$\begin{array}{rcl}f(y) &amp; = &amp; f(x) + f'(x)^\top(y-x) + \frac{1}{2}(x-y)^\top A ( x-y) \\ &amp; = &amp;  f(x) + \frac{1}{2}(x-y)^\top (  A + \mu I) ( x-y) + \frac{\mu}{2} ( x^\top x &#8211; y^\top y). \end{array}$$ Thus, if \(x\) is optimal, we must have \((x-y)^\top (  A + \mu I) ( x-y) \geqslant 0\) for all \(y \in \mathbb{S}\), which implies that \(A+ \mu I \succcurlyeq 0\). Note that our reasoning implies that the optimality condition, that is, existence of \(\mu \in \mathbb{R}\) such that $$\begin{array}{l} ( A+ \mu I) x = b \\ A+ \mu I \succcurlyeq 0 \\ x^\top x = 1 , \end{array} $$ is necessary and sufficient for the optimality of \(x\). The sufficiency can also be obtained through <a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions#:~:text=In%20mathematical%20optimization%2C%20the%20Karush,some%20regularity%20conditions%20are%20satisfied.">Karush-Kuhn-Tucker (KKT) conditions</a>, which apply regardless of convexity. This is one of few problems where strong duality holds for a non-convex optimization problems.</p>



<p class="justify-text"><strong>Second-order necessary condition on the ball.</strong> We also get the following necessary and sufficient condition, that is, the existence of \(\mu \in \mathbb{R}_+\) such that $$\begin{array}{l} ( A+ \mu I) x = b \\ A+ \mu I  \succcurlyeq 0 \\ x^\top x \leqslant 1 \\ \mu \, ( 1 \, &#8211; \, x^\top x) = 0.  \end{array}$$</p>



<p class="justify-text">In both cases, once \(\mu\) is known, we can recover the optimizers \(x\). We now focus on the sphere for simplicity.</p>



<h2>Equivalence to a one-dimensional problem</h2>



<p class="justify-text">We can define the function \((M,u) \mapsto u^\top M^{-1} u\) as the minimal \(t \in \mathbb{R}\) such that the matrix \(\bigg( \begin{array}{cc} \!M\!\! &amp; \!u\! \\[-.1cm] \!u^\top \!\! &amp; \! t \! \end{array} \bigg) \succcurlyeq 0\). It is thus jointly convex in \((M,u)\), is infinite when \(M\) is not positive-semidefinite (PSD). When \(M\) is PSD but not invertible, the function is finite if and only if \(u\) is in the column space of \(M\). We can define similarly \(u^\top M^{-2} u\).</p>



<p class="justify-text">We can now get the dual problem associated to the Lagrangian in \((3)\), by minimizing it with respect to \(x\), leading to $$\max_{\mu \in \mathbb{R}} \  &#8211; \frac{\mu}{2} \, &#8211; \frac{1}{2} b^\top ( A+\mu I)^{-1} b, $$ which is a concave maximization problem in one dimension (with the constraint that \(A + \mu I \succcurlyeq 0\)).</p>



<p class="justify-text">Thus, a simple algorithm for solving the problem is to solve this one-dimensional concave maximization problem. Once an eigenvalue decomposition \(A = \sum_{i=1}^n \! \lambda_i u_i u_i^\top\) has been obtained, we need to minimize $$ \tag{4} &#8211; \frac{\mu}{2} \, &#8211; \frac{1}{2} \sum_{i=1}^n \frac{ (b^\top u_i)^2}{\lambda_i + \mu}. $$</p>



<p class="justify-text">Assuming that \(\lambda_1 \geqslant \lambda_2 \geqslant \cdots \geqslant \lambda_n\), we have the constraint \(\lambda_n + \mu \geqslant 0\). We first need to check if \(\mu = \, &#8211; \lambda_n\) is the solution, which occurs when \(b^\top ( A+ \mu I)^{-2} b \leqslant 1\) (the problem is then called &#8220;degenerate&#8221;, and this can only happen if \(b\) in the eigensubspace of \(A\) associated with eigenvalue \(&#8211; \lambda_n\), which is rather uncommon). Otherwise, the minimum is attained at \(\mu &gt; -\lambda_n\) (note that since we have assumed \(b \neq 0\), the problem is strictly concave and thus has a unique maximizer in \(\mu\)). Moreover, \(\mu\) is characterized by the equation $$ \tag{5}   b^\top ( A+ \mu I)^{-2} b = 1,$$ which can be obtained directly from the optimality conditions.</p>



<p class="justify-text">This one-dimensional problem can be solved using Newton&#8217;s method [<a href="https://epubs.siam.org/doi/epdf/10.1137/0719026">6</a>, <a href="https://epubs.siam.org/doi/epdf/10.1137/S1052623494274374">7</a>] to estimate \(\mu\) given the eigendecomposition of \(A\). There are also cheaper less precise algorithms that do not require a full eigendecomposition. We will also see below a surprising reformulation as a simple eigenvalue problem.</p>



<p class="justify-text"><strong>Other &#8220;secular&#8221; equations.</strong> Equation \((5)\) is often referred to a <a href="https://en.wikipedia.org/wiki/Characteristic_polynomial">secular equation</a>. There are other types of similar equations, in particular for rank-one perturbations of the symmetric eigenvalue problem [<a href="https://link.springer.com/content/pdf/10.1007/BF01396012.pdf?pdf=button">8</a>, <a href="https://epubs.siam.org/doi/epdf/10.1137/S089547989223924X">9</a>].</p>



<h2>Semi-definite relaxations</h2>



<p class="justify-text">We can now give a more modern take on the quadratic maximization problem on the sphere, using <a href="https://en.wikipedia.org/wiki/Semidefinite_programming">semi-definite programming</a>. We can first rewrite the objective function in Equation \((1)\) as $$f(x) = \frac{1}{2}x^\top A x \, &#8211; b^\top x = \frac{1}{2} {\rm tr}(AX) \, &#8211; b^\top x, $$ with \(X = xx^\top\). We now have a linear objective in \((X,x)\). Moreover, the matrix \(X\) satisfies the convex constraints $$ X \succcurlyeq xx^\top \Leftrightarrow \left( \begin{array}{cc} \!X\!\! &amp; \!x\! \\[-.1cm] \!x^\top \!\!&amp;\!  1\!  \end{array} \right) \succcurlyeq 0, $$ and \({\rm tr}(X) = x^\top x = 1\). However the rank-one constraint is not convex. </p>



<p class="justify-text">A classical tool in optimization is to remove the rank-one constraint, and only obtain a lower bound (a so-called &#8220;relaxation&#8221;), with the following optimization problem: $$\tag{6} \min_{ X, x} \frac{1}{2} {\rm tr}(AX)-b^\top x \mbox{ such that } \left( \begin{array}{cc} \!X\!\! &amp; \!x\! \\[-.1cm] \!x^\top \!\!&amp;\!  1\!  \end{array} \right)  \succcurlyeq 0 \mbox{ and } {\rm tr}(X)=1. $$ One can check that the dual problem is exactly Equation \((4)\), and thus the relaxation is here tight. Moreover, the SDP formulation can be used to derive algorithms that do not need a full eigenvalue decomposition [<a href="https://link.springer.com/content/pdf/10.1007/BF02614438.pdf?pdf=button">12</a>].</p>



<p class="justify-text"><strong>Semi-definite relaxation of QCQP&#8217;s.</strong> Problems \((1)\) and \((2)\) are in fact instances of <a href="https://en.wikipedia.org/wiki/Quadratically_constrained_quadratic_program">quadratically constrained quadratic programming</a> problems, and the problem \((6)\) is the usual semi-definite relaxation. It turns out that with a single constraint, such relaxations are always tight, owing to the <a href="https://en.wikipedia.org/wiki/S-procedure">S-lemma</a> [<a href="https://epubs.siam.org/doi/epdf/10.1137/S003614450444614X">10</a>] (see a nice derivation in Boyd and Vandenberghe&#8217;s book [<a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">11</a>, Appendix B.1]).</p>



<p class="justify-text"><strong>Tight <span style="font-size: revert; color: initial; font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen-Sans, Ubuntu, Cantarell, &quot;Helvetica Neue&quot;, sans-serif;">sum-of-squares relaxation.</span></strong> Yet another reformulation is through sum-of-squares (see an earlier <a href="https://francisbach.com/finding-global-minima-with-kernel-approximations/">post</a>), where we consider the feature vector \(\varphi(x) = {x \choose 1}\) and represent non-negative functions as quadratic forms \(x \mapsto \varphi(x)^\top B \varphi(x)\). The problem in \((2)\) can then be relaxed as $$\max_{c \in \mathbb{R}, \ B \succcurlyeq 0} c \ \mbox{ such that } \ f(x) \, &#8211; c = \varphi(x)^\top B \varphi(x),$$ which is exactly the tight SDP relaxation above.</p>



<p class="justify-text"><strong>Having fun with adding affine constraints. </strong>Recently I had to look at Problem \((2)\) with an extra affine constraint, which I will take for simplicity of the form \(c^\top x = 1\) (for a vector \(c \in \mathbb{R}^n\) such that \(\|c\| &gt; 1\) to avoid a trivial problem). By projecting on the subspace orthogonal to \(c \in \mathbb{R}^n\), we obtain again a quadratic minimization problem, this time on a Euclidean sphere embedded in a space of dimension \(n-1\). Therefore, we can apply the above techniques on the reduced problem. However, I did not want to do that and wanted keep the original formulation on \(\mathbb{R}^n\), and then tried to use duality to solve it. Two natural possibilities emerge here.</p>



<p class="justify-text">In order to solve it, we could first imagine using Lagrange duality, with a Lagrange multiplier \(\mu\) for the constraint \(x^\top x = 1\) (this worked exactly without the extra affine constraint), and now an extra Lagrange multiplier \(\nu\) for the constraint \(c^\top x = 1\). This leads to the Lagrangian $$ \mathcal{L}(x,\mu,\nu) = \frac{1}{2} x^\top A x\, &#8211; b^\top x + \frac{1}{2} \mu ( x^\top x\, &#8211; 1) + \nu( c^\top x -1),$$ and thus, after a short calculation, the dual problem $$\max_{\mu,\nu \in \mathbb{R}} \ -\frac{\mu}{2} \, &#8211; \nu   \, &#8211; \frac{1}{2} (b \, &#8211; \nu c)^\top ( A + \mu I)^{-1} (b \, &#8211; \nu c).$$ Another Lagrangian can be obtained with the equivalent constraint \((c^\top x\, &#8211; 1)^2 = 0\), leading to a new Lagrangian $$ \mathcal{L}'(x,\mu,\nu&#8217;) = \frac{1}{2} x^\top A  x\, -b^\top x + \frac{1}{2} \mu ( x^\top x\, &#8211; 1) + \frac{1}{2} \nu&#8217;  (c^\top x \, &#8211; 1)^2,$$ and then the dual problem $$\max_{\mu,\nu&#8217; \in \mathbb{R}} \ -\frac{\mu}{2} \, -\frac{\nu&#8217;}{2} \, &#8211; \frac{1}{2} (b+\nu&#8217; c)^\top ( A +  \nu&#8217; cc^\top  +  \mu I)^{-1} (b+\nu&#8217; c).$$ Are they both tight? Make up your own mind and see the bottom of the post for the answer.</p>



<h2>Amazing eigenvalue reformulations</h2>



<p class="justify-text">The Newton method to solve the one-dimensional problem is efficient, but requires some safeguards to work properly, and a full eigenvalue decomposition. It turns out that one can obtain <em>exact</em> reformulations as eigenvalue problems <em>for a single eigenvalue</em>, for which efficient <a href="https://en.wikipedia.org/wiki/ARPACK">packages</a> exist.</p>



<p class="justify-text">From [<a href="https://reader.elsevier.com/reader/sd/pii/0024379589904941?token=5ED11F6E1B740CDF399B40623394985F3CDDA6BEF749F490CA64773677A63CBDE4C213284E03445941BCF501D0C12336&amp;originRegion=eu-west-1&amp;originCreation=20230128095330">3</a>], for the optimization on the sphere, we can obtain the optimal \(\mu\) from the largest real eigenvalue of the following non symmetric matrix: $$\left( \begin{array}{cc} \!-A\!  &amp; \!\! I\!  \\[-.1cm]   \! bb^\top \!&amp; \!\! -A\!  \end{array} \right).$$ Indeed, one can check that, in the non-degenerate case, given the optimal \((x,\mu)\), then \(y = \left( \begin{array}{c} \!(A+\mu I)^{-1} x \!    \\[-.1cm]  x  \end{array} \right)\) is an eigenvector of the \(2n \times 2n\) matrix above, with eigenvalue \(\mu\).</p>



<p class="justify-text">This leads to two lines of code to solve the problem, at least for the non-degenerate case! See more details in [<a href="https://reader.elsevier.com/reader/sd/pii/0024379589904941?token=5ED11F6E1B740CDF399B40623394985F3CDDA6BEF749F490CA64773677A63CBDE4C213284E03445941BCF501D0C12336&amp;originRegion=eu-west-1&amp;originCreation=20230128095330">3</a>, <a href="https://epubs.siam.org/doi/epdf/10.1137/16M1058200">14</a>], in particular, to deal with the degenerate case, often called the &#8220;hard case&#8221;. See the code snippets in Matlab, Julia, and Python.</p>



<figure class="wp-block-table"><table><tbody><tr><td>Matlab</td><td><code>[y,mu] = eigs([-A, eye(n); b*b', -A],1,'largestreal');&nbsp;<br>x&nbsp;= y(n+1:2*n) / (b'*y(1:n));&nbsp;<br></code>or <code>x = sign(b'*y(1:n)) * y(n+1:2*n) / norm(y(n+1:2*n))</code>;</td></tr><tr><td>Julia</td><td><code>E = eigs([-A I(n) ; b*b' -A ], nev=1 , which=:LR )<br>y, μ = E[2][:, 1], E[1][1]<br>x = y[n+1:2n] ./ (b' * y[1:n])<br></code>or <code>x = sign.(b' * y[1:n]) .* y[n+1:2n] / norm(y[n+1:2*n])</code></td></tr><tr><td>Python</td><td><code>M = np.block([[-A, np.eye(n)], [np.outer(b,b), -A]])<br>mu, y = scipy.sparse.linalg.eigs(M, k=1, which='LR', return_eigenvectors=True)<br>x = y[n:2*n]/(np.dot(b,y[:n]))&nbsp;<br></code>or <code>x&nbsp;= np.sign(np.dot(b,y[:n]))*y[n:2*n]/np.linalg.norm(y[n:2*n])</code></td></tr></tbody></table></figure>



<p class="justify-text"><strong>Symmetric generalized eigenproblems. </strong>If you prefer symmetric matrices, one can obtain a similar result with the generalized eigenvector of the two matrices $$\left( \begin{array}{cc} \!I\!\!  &amp; \!\!-A\! \\ \!-A\!\! &amp; \! bb^\top\! \end{array} \right) \ \mbox{ and }   \  \left( \begin{array}{cc} \! 0  \! &amp; \! \! I \\[-.1cm] I \!\! &amp; \!\! 0   \end{array} \right).$$ If you want to avoid forming a potentially dense matrix \(bb^\top\), you and use instead the matrices $$\left( \begin{array}{ccc}  \!-1\!  &amp; \! 0\! &amp; \! b^\top \! \\[-1.cm] \!0\! &amp;\!  I \!&amp;\! -A \! \\[-.1cm]\! b \!&amp;\! -A \!&amp; \!0\! \end{array} \right) \  \mbox{ and } \  \left( \begin{array}{ccc} \! 0\! &amp;\! 0 \!&amp; \! 0\! \\[-.1cm]\! 0 \! &amp; \! 0 \!&amp;\! I \! \\[-.1cm] \! 0 \! &amp;\! I \! &amp;\! 0 \!  \end{array} \right).$$ See all details in [<a href="https://epubs.siam.org/doi/epdf/10.1137/16M1058200">14</a>]. Note that beyond the two-line code above that lead to precise solutions, more efficient algorithms exist that lead to approximate solutions [<a href="https://link.springer.com/content/pdf/10.1007/s10107-015-0933-y.pdf?pdf=button">14</a>, <a href="https://epubs.siam.org/doi/epdf/10.1137/16M1150281">15</a>].</p>



<h2>Conclusion</h2>



<p class="justify-text">In this blog post, I described one of the few non-convex problems where strong duality holds. There are many other instances within combinatorial optimization (that is, with variables in \(\{0,1\}^n\) or \(\{-1,1\}^n\)), in particular related to <a href="https://en.wikipedia.org/wiki/Submodular_set_function">submodularity</a>. I will hopefully cover these in future posts. </p>



<p class="justify-text"><strong>Acknowledgements.</strong> I would like to thank Alessandro Rudi, Gaspard Beugnot, and ChatGPT for helping with the code snippets.</p>



<h2>References</h2>



<p class="justify-text">[2] George E. Forsythe, and Gene H. Golub. <a href="https://epubs.siam.org/doi/epdfplus/10.1137/0113073">On the stationary values of a second-degree polynomial on the unit sphere</a>.&nbsp;<em>Journal of the Society for Industrial and Applied Mathematics</em>,&nbsp;13(4): 1050-1068, 1965.[3] Walter Gander, Gene H. Golub, and Urs Von Matt. <a href="https://www.sciencedirect.com/science/article/pii/0024379589904941/pdf?md5=754201682cef36aa80a3ef681fce6d62&amp;pid=1-s2.0-0024379589904941-main.pdf">A constrained eigenvalue problem</a>.&nbsp;<em>Linear Algebra and its applications</em>&nbsp;114: 815-839, 1989.<br>[4] Andrew R. Conn, Nicholas I. M. Gould, and Philippe L. Toint.&nbsp;<em>Trust region methods</em>. Society for Industrial and Applied Mathematics, 2000.<br>[5] William W. Hager. <a href="http://users.clas.ufl.edu/hager/papers/Regular/sphere.pdf">Minimizing a quadratic over a sphere</a>.&nbsp;<em>SIAM Journal on Optimization</em>,&nbsp;12(1):188-208, 2001.<br>[6] Danny C. Sorensen. <a href="https://epubs.siam.org/doi/epdf/10.1137/0719026">Newton’s method with a model trust region modification</a>. <em>SIAM Journal on Numerical Analysis</em>,&nbsp;19(2):409-426, 1982.<br>[7] Danny C. Sorensen. <a href="https://epubs.siam.org/doi/epdf/10.1137/S1052623494274374">Minimization of a large-scale quadratic function subject to a spherical constraint</a>.&nbsp;<em>SIAM Journal on Optimization</em>,&nbsp;7(1):141-161, 1997.<br>[8] James R. Bunch, Christopher P. Nielsen, Danny C. Sorensen. <a href="https://link.springer.com/content/pdf/10.1007/BF01396012.pdf?pdf=button">Rank-one modification of the symmetric eigenproblem</a>.&nbsp;<em>Numerische Mathematik</em>,&nbsp;31(1):31-48, 1978.<br>[9] Ming Gu, Stanley C. Eisenstat. <a href="https://epubs.siam.org/doi/epdf/10.1137/S089547989223924X">A stable and efficient algorithm for the rank-one modification of the symmetric eigenproblem</a>.&nbsp;<em>SIAM Journal on Matrix Analysis and Applications</em>&nbsp;,15(4):1266-1276, 1994.<br>[10] Imre Pólik, Tamás Terlaky. <a href="https://epubs.siam.org/doi/epdf/10.1137/S003614450444614X">A survey of the S-lemma</a>.&nbsp;<em>SIAM Review</em>,&nbsp;49(3):371-418, 2007.<br>[11] Stephen P. Boyd, Lieven Vandenberghe.&nbsp;<em><a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">Convex Optimization</a></em>. Cambridge University Press, 2004.<br>[12] Franz Rendl, Henry Wolkowicz. <a href="https://link.springer.com/content/pdf/10.1007/BF02614438.pdf?pdf=button">A semidefinite framework for trust region subproblems with applications to large scale minimization</a>.&nbsp;<em>Mathematical Programming</em>,&nbsp;77(1):273-299, 1997.<br>[13] Satoru Adachi, Satoru Iwata, Yuji Nakatsukasa, Akiko Takeda. <a href="https://epubs.siam.org/doi/epdf/10.1137/16M1058200">Solving the trust-region subproblem by a generalized eigenvalue problem</a>.&nbsp;<em>SIAM Journal on Optimization</em>,&nbsp;<em>27</em>(1):269-291, 2017.<br>[14] Elad Hazan, Tomer Koren. <a href="https://link.springer.com/content/pdf/10.1007/s10107-015-0933-y.pdf?pdf=button">A linear-time algorithm for trust region problems</a>.&nbsp;<em>Mathematical Programming</em>,&nbsp;158(1-2):363-381, 2016.<br>[15] Amir Beck, Yakov Vaisbourd. <a href="https://epubs.siam.org/doi/epdf/10.1137/16M1150281">Globally solving the trust region subproblem using simple first-order methods</a>.&nbsp;<em>SIAM Journal on Optimization</em>,&nbsp;28(3):1951-1967, 2018.</p>



<h2>Having fun with affine constraints</h2>



<p class="justify-text">Let&#8217;s know look at the solution! The second relaxation is tight, while the first is not. To prove that we have a non-tight solution for the first relaxation, we can simply find a counter-example from random matrices in dimension \(n = 2\). For example, for $$A = \left( \begin{array}{cc} \!3\! &amp;\! 0\! \\[-.1cm] \! 0\! &amp; \!-2 \!  \end{array} \right) , \ \ b = \left( \begin{array}{c} \! 0\! \\[-.1cm] \!-1 \! \end{array} \right), \mbox{ and } \ c = \left( \begin{array}{c} \! 0\! \\[-.1cm] \!2 \! \end{array} \right),$$ a minimizer is \( x =  \left( \begin{array}{c}\! \sqrt{3}/2\! \\[-.1cm] \! 1/2 \! \end{array} \right)\), with optimal value \(11/8\), while the non-tight relaxation leads to a value of \(-1/2\). </p>



<p class="justify-text">To show the tightness of the second relaxation, we first notice that the convex problem is equivalent to the following SDP relaxation:  $$\min_{ X, x} \frac{1}{2} {\rm tr}(AX)-b^\top x \mbox{ such that } \left( \begin{array}{cc} \!X\!\! &amp; \!x\! \\[-.1cm] \!x^\top \!\!&amp;\!  1\!  \end{array} \right) \succcurlyeq 0, {\rm tr}(X)=1, \mbox{ and } {\rm tr}(cc^\top X)\,  &#8211; 2 t c^\top x + t^2 = 0. $$ Given the PSD constraint and the fact that $${\rm tr}(cc^\top X)\,  &#8211; 2 t c^\top x + t^2 = {\rm tr} \left( \begin{array}{cc} \!X\!\! &amp; \!x\! \\[-.1cm] \!x^\top \!\!&amp;\!  1\!  \end{array} \right)\left( \begin{array}{cc} \! cc^\top \! &amp; \! -tc \! \\[-.1cm] \!-tc^\top \! &amp; \! t^2 \! \end{array} \right),$$ the new constraint implies that $$ \left( \begin{array}{cc} \!X\!\! &amp; \!x\! \\[-.1cm] \!x^\top \!\!&amp;\!  1\!  \end{array} \right) \left( \begin{array}{c} \!c\!  \\[-.1cm] \!-t \!  \end{array} \right)= 0, $$ that is, \(Xc = t x\) and \(c^\top x = t\). One can then check that these constraints are exactly equivalent to a projection of the problem in to a space of dimension \(n-1\). The incorrect relaxation only has \(c^\top x = t\), which is not enough. It took me a while to realize it&#8230;</p>
<p class="authors">By Francis Bach</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T14:46:35Z">Thursday, February 02 2023, 14:46</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/responsibility.html'>Responsibility</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Nature laid out their ground rules for large language models like ChatGPT including</p><p></p><blockquote><p>No LLM tool will be accepted as a credited author on a research paper. That is because any attribution of authorship carries with it accountability for the work, and AI tools cannot take such responsibility.</p></blockquote><p>Let's focus on the last word "responsibility". What does that mean for an author? It means we can hold an author, or set of authors, responsible for any issues in the paper such as</p><p></p><ul><li>The proofs, calculations, code, formulas, measurements, statistics, and other details of the research.</li><li>Any interpretation or conclusions made in the article</li><li>Properly citing related work, especially work that calls into question the novelty of this research</li><li>The article does not contain text identical or very similar to previous work.</li><li>Anything else described in the article.</li></ul>The authors should take reasonable measures to ensure that a paper is free from any issues above. Nobody is perfect and if you make a mistake in a paper, you should, as with all mistakes, take responsibility and acknowledge the problems, do everything you can to rectify the issues, such as publishing a corrigendum if needed, and work to ensure you won't make similar mistakes in the future.<br>Mistakes can arise outside of an author's actions. Perhaps a computer chip makes faulty calculations, you relied on a faulty theorem in another paper, your main result appeared in a paper fifteen years ago in an obscure journal, a LaTeX package for the journal created some mistakes in the formulas or a student who helped with the research or exposition took a lazy way out, or you put too much trust in AI generative text. Nevertheless the responsibility remains with the authors.&nbsp;<br>Could an AI ever take responsibility for an academic paper? Would a toaster ever take responsibility for burning my breakfast?<br><br>&nbsp;<p></p><p></p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Nature <a href="https://www.nature.com/articles/d41586-023-00191-1">laid out their ground rules</a> for large language models like ChatGPT including</p><p></p><blockquote><p>No LLM tool will be accepted as a credited author on a research paper. That is because any attribution of authorship carries with it accountability for the work, and AI tools cannot take such responsibility.</p></blockquote><p>Let's focus on the last word "responsibility". What does that mean for an author? It means we can hold an author, or set of authors, responsible for any issues in the paper such as</p><p></p><ul style="text-align: left;"><li>The proofs, calculations, code, formulas, measurements, statistics, and other details of the research.</li><li>Any interpretation or conclusions made in the article</li><li>Properly citing related work, especially work that calls into question the novelty of this research</li><li>The article does not contain text identical or very similar to previous work.</li><li>Anything else described in the article.</li></ul><div>The authors should take reasonable measures to ensure that a paper is free from any issues above. Nobody is perfect and if you make a mistake in a paper, you should, as with all mistakes, take responsibility and acknowledge the problems, do everything you can to rectify the issues, such as publishing a corrigendum if needed, and work to ensure you won't make similar mistakes in the future.</div><div><br /></div><div>Mistakes can arise outside of an author's actions. Perhaps a computer chip <a href="https://en.wikipedia.org/wiki/Pentium_FDIV_bug">makes faulty calculations</a>, you relied on a faulty theorem in another paper, your main result appeared in a paper fifteen years ago in an obscure journal, a LaTeX package for the journal created some mistakes in the formulas or a student who helped with the research or exposition took a lazy way out, or you put too much trust in AI generative text. Nevertheless the responsibility remains with the authors.&nbsp;</div><div><br /></div><div>Could an AI ever take responsibility for an academic paper? Would a toaster ever take responsibility for burning my breakfast?</div><div><br /></div><div><br /></div><div>&nbsp;</div><p></p><p></p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T14:39:00Z">Thursday, February 02 2023, 14:39</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/02/assistant-associate-professor-at-ecole-polytechnique-institut-polytechnique-de-paris-apply-by-march-15-2023/'>Assistant/Associate Professor at Ecole polytechnique, Institut Polytechnique de Paris (apply by March 15, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Ecole polytechnique, leading engineering school in France, member of the Institut Polytechnique de Paris, welcomes outstanding applications for one assistant Monge Professor in Computer Science, specialty &#8220;Foundations of Computer Science&#8221;, tenure track teaching/research position. Website: portail.polytechnique.edu/informatique/en/recruitment2023 Email: samuel.mimram@polytechnique.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Ecole polytechnique, leading engineering school in France, member of the<br />
Institut Polytechnique de Paris, welcomes outstanding applications for one assistant Monge Professor in Computer Science, specialty &#8220;Foundations of Computer Science&#8221;, tenure track teaching/research position.</p>
<p>Website: <a href="https://portail.polytechnique.edu/informatique/en/recruitment2023">https://portail.polytechnique.edu/informatique/en/recruitment2023</a><br />
Email: samuel.mimram@polytechnique.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T13:54:05Z">Thursday, February 02 2023, 13:54</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/02/02/mathematics-of-the-impossible-computational-complexity-chapter-3-the-grand-challenge/'>Mathematics of the impossible: Computational Complexity,  Chapter 3: The grand challenge</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          All posts in this series. A PDF version of this post will be published with a delay, but if you&#8217;d like to have it soon let me know. Contents 1 The grand challenge 1.1 Information bottleneck: Palindromes requires quadratic time on TMs 1.2 Counting: impossibility results for non-explicit functions 1.3 Diagonalization: Enumerating machines 1.3.1 1.4 [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><a href="https://emanueleviola.wordpress.com/tag/moti/">All posts in this series.</a><br />
A PDF version of this post will be published with a delay, but if you&#8217;d like to have it soon let me know.</p>
<hr />
<p><!--?xml version="1.0" encoding="iso-8859-1" ?--> <!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd--> <!-- html,xhtml,-css,NoFonts --></p>
<h2 class="likechapterHead"><a id="x1-1000"></a>Contents</h2>
<div class="tableofcontents"><span class="chapterToc">1 <a id="QQ2-1-2" href="#x1-20001">The grand challenge</a></span><br />
<span class="sectionToc">1.1 <a id="QQ2-1-3" href="#x1-30001.1">Information bottleneck: Palindromes requires quadratic time on TMs</a></span><br />
<span class="sectionToc">1.2 <a id="QQ2-1-4" href="#x1-40001.2">Counting: impossibility results for non-explicit functions</a></span><br />
<span class="sectionToc">1.3 <a id="QQ2-1-5" href="#x1-50001.3">Diagonalization: Enumerating machines</a></span><br />
<span class="subsectionToc">1.3.1 <a id="QQ2-1-6" href="#x1-60001.3.1"><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28o%28n+%5Clog+n%29%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28o%28n+%5Clog+n%29%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28o%28n+%5Clog+n%29%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(o(n &#92;log n))=&#92;text {TM-Time}(n)" class="latex" /></a></span><br />
<span class="sectionToc">1.4 <a id="QQ2-1-7" href="#x1-70001.4">Circuits</a></span><br />
<span class="subsectionToc">1.4.1 <a id="QQ2-1-8" href="#x1-80001.4.1">The circuit won’t fit in the universe: Non-asymptotic, cosmological results</a></span><br />
<span class="sectionToc">1.5 <a id="QQ2-1-9" href="#x1-90001.5">Problems</a></span></div>
<div id="verbatim-1" class="verbatim"></div>
<div></div>
<p style="text-align: justify"><img loading="lazy" data-attachment-id="1160" data-permalink="https://emanueleviola.wordpress.com/2023/02/02/mathematics-of-the-impossible-computational-complexity-chapter-3-the-grand-challenge/phdcomics/" data-orig-file="https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png" data-orig-size="600,260" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PhDComics" data-image-description="" data-image-caption="" data-medium-file="https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png?w=300" data-large-file="https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png?w=600" class="alignnone size-full wp-image-1160" src="https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png" alt="PhDComics" width="600" height="260" srcset="https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png 600w, https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png?w=150&amp;h=65 150w, https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png?w=300&amp;h=130 300w" sizes="(max-width: 600px) 100vw, 600px" /></p>
<p style="text-align: justify">As mentioned in Chapter ??, our ability to prove impossibility results related to efficient computation appears very limited. We can now express this situation more precisely with the models we’ve introduced since then.</p>
<div style="text-align: center">
<p style="text-align: justify">
<div class="minipage">It is consistent with our knowledge that any problem in a standard algorithm textbook can be solved</p>
<ol class="enumerate1">
<li id="x1-2002x1" class="enumerate">in Time <img src="https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn^{2}" class="latex" /> on a TM, and</li>
<li id="x1-2004x2" class="enumerate">in Time <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" /> on a 2-TM, and</li>
<li id="x1-2006x3" class="enumerate">by circuits of size <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" />.</li>
</ol>
</div>
</div>
<p style="text-align: justify">Note that 2. implies 1. by Theorem ??.</p>
<p style="text-align: justify">In this chapter we begin to present several impossibility results, covering a variety of techniques which will be used later as well. As hinted above, they appear somewhat weak. However, jumping ahead, there is a flip side to all of this:</p>
<ol class="enumerate1">
<li id="x1-2008x1" class="enumerate">At times, contrary to our intuition, stronger impossibility results are actually <em>false</em>. One example appears in Chapter ??. A list will be given later.</li>
<li id="x1-2010x2" class="enumerate">Many times, the impossibility results that we can prove turn out to be, surprisingly, just “short” of proving major results. Here by “major result” I mean a result that would be phenomenal and that was in focus long before the connection was established. We will see several examples of this (section º??, section º??).</li>
<li id="x1-2012x3" class="enumerate">Yet other times, one can identify broad classes of proof techniques, and argue that impossibility results can’t be proved with them (section º??).</li>
</ol>
<p style="text-align: justify">Given this situation, I don’t subscribe to the general belief that stronger impossibility results are true and we just can’t prove them.</p>
<h3 class="sectionHead"><span class="titlemark">1.1 </span> <a id="x1-30001.1"></a>Information bottleneck: Palindromes requires quadratic time on TMs</h3>
<p style="text-align: justify">Intuitively, the weakness of TMs is the bottleneck of passing information from one end of the tape to the other. We now show how to formalize this and use it show that deciding if a string is a palindrome requires <em>quadratic </em>time on TMs, which is tight and likely matches the time in Exercise ??. The same bound can be shown for other functions; palindromes just happen to be convenient to obtain matching bounds.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-3001r1"></a> <b>Theorem</b> 1.1. </span> <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BPalindromes%7D%5Cnot+%5Cin+%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BPalindromes%7D%5Cnot+%5Cin+%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BPalindromes%7D%5Cnot+%5Cin+%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Palindromes}&#92;not &#92;in &#92;text {TM-Time}(t(n))" class="latex" /> for any <img src="https://s0.wp.com/latex.php?latex=t%28n%29%3Do%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%3Do%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%3Do%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)=o(n^{2})" class="latex" />.</p>
<p style="text-align: justify">More precisely, for every <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />, an <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />-state TM that decides if an <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />-bit input is a palindrome requires time <img src="https://s0.wp.com/latex.php?latex=%5Cge+cn%5E%7B2%7D%2F%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+cn%5E%7B2%7D%2F%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+cn%5E%7B2%7D%2F%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge cn^{2}/&#92;log s" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">The main concept that allows us to formalize the information bottleneck mentioned above is the following.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-3002r1"></a> <b>Definition</b> 1.1. </span>A <em>crossing sequence</em> of a TM <em>M</em> on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and boundary <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />, abbreviated <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS, is the sequence of states that <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is transitioning to when crossing cell boundary <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> (i.e., going from Cell <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=i%2B1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%2B1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%2B1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i+1" class="latex" /> or vice versa) during the computation on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">The idea in the proof is very interesting. If <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> accepts inputs <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> and those two inputs have the same <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS for some <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />, then we can “stitch together” the computation of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> at boundary <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> to create a new input <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> that is still accepted by <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />. The input <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> is formed by picking bits from <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> to the left of cell boundary <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> and bits from <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> to the right of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />:</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+z%3A%3Dx_%7B1%7Dx_%7B2%7D%5Ccdots+x_%7Bi%7Dy_%7Bi%2B1%7Dy_%7Bi%2B2%7D%5Ccdots+y_%7Bn%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+z%3A%3Dx_%7B1%7Dx_%7B2%7D%5Ccdots+x_%7Bi%7Dy_%7Bi%2B1%7Dy_%7Bi%2B2%7D%5Ccdots+y_%7Bn%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+z%3A%3Dx_%7B1%7Dx_%7B2%7D%5Ccdots+x_%7Bi%7Dy_%7Bi%2B1%7Dy_%7Bi%2B2%7D%5Ccdots+y_%7Bn%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} z:=x_{1}x_{2}&#92;cdots x_{i}y_{i+1}y_{i+2}&#92;cdots y_{n}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">The proof that <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> is still accepted is left as an exercise.</p>
<p style="text-align: justify">Now, for many problems, input <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> should <em>not</em> be accepted by <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, and this gives a contradiction. In particular this will be be the case for palindromes. We are going to find two palindromes <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> that have the same <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS for some <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />, but the corresponding <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> is not a palindrome, yet it is still accepted by <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />. We can find these two palindromes if <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> takes too little time. The basic idea is that if <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> runs in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />, because <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CSs for different <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> correspond to different steps of the computation, for every input there is a value of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> such that the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS is short, namely has length at most <img src="https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(|x|)/n" class="latex" />. If <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" /> is much less than <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}" class="latex" />, the length of this CS is much less than <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, from which we can conclude that the number of CSs is much less than the number of inputs, and so we can find two inputs with the same CS.</p>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>Let <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> be divisible by four, without loss of generality, and consider palindromes of the form</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+p%28x%29%3A%3Dx0%5E%7Bn%2F2%7Dx%5E%7BR%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+p%28x%29%3A%3Dx0%5E%7Bn%2F2%7Dx%5E%7BR%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+p%28x%29%3A%3Dx0%5E%7Bn%2F2%7Dx%5E%7BR%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} p(x):=x0^{n/2}x^{R} &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">where <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n/4}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=x%5E%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5E%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5E%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x^{R}" class="latex" /> is the reverse of <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<p style="text-align: justify">Assume there are <img src="https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;ne y" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n/4}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> in the middle part, i.e., <img src="https://s0.wp.com/latex.php?latex=n%2F4%5Cle+i%5Cle+3n%2F4-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2F4%5Cle+i%5Cle+3n%2F4-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2F4%5Cle+i%5Cle+3n%2F4-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n/4&#92;le i&#92;le 3n/4-1" class="latex" />, so that the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(x)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=p%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(y)" class="latex" /> is the same. Then we can define <img src="https://s0.wp.com/latex.php?latex=z%3A%3Dx0%5E%7Bn%2F2%7Dy%5E%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z%3A%3Dx0%5E%7Bn%2F2%7Dy%5E%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z%3A%3Dx0%5E%7Bn%2F2%7Dy%5E%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z:=x0^{n/2}y^{R}" class="latex" /> which is not a palindrome but is still accepted by <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, concluding the proof.</p>
<p style="text-align: justify">There remains to prove that the assumption of Theorem <a href="#x1-3001r1">1.1<!--tex4ht:ref: thm:TM-pal-requires-quadratic --></a> implies the assumption in the previous paragraph. Suppose <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> runs in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />. Since crossing sequences at different boundaries correspond to different steps of the computation, for every <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n/4}" class="latex" /> there is a value of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> in the middle part such that the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(x)" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+ct%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+ct%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+ct%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le ct/n" class="latex" />. This implies that there is an <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> in the middle s.t. there are <img src="https://s0.wp.com/latex.php?latex=%5Cge+c2%5E%7Bn%2F4%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c2%5E%7Bn%2F4%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c2%5E%7Bn%2F4%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c2^{n/4}/n" class="latex" /> inputs <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> for which the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+ct%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+ct%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+ct%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le ct/n" class="latex" />.</p>
<p style="text-align: justify">For fixed <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />, the number of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS of length <img src="https://s0.wp.com/latex.php?latex=%5Cle+%5Cell+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+%5Cell+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+%5Cell+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le &#92;ell " class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cle+%28s%2B1%29%5E%7B%5Cell+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+%28s%2B1%29%5E%7B%5Cell+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+%28s%2B1%29%5E%7B%5Cell+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le (s+1)^{&#92;ell }" class="latex" />.</p>
<p style="text-align: justify">Hence there are <img src="https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;ne y" class="latex" /> for which <img src="https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(x)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=p%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(y)" class="latex" /> have the same <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS whenever <img src="https://s0.wp.com/latex.php?latex=c2%5E%7Bn%2F4%7D%2Fn%5Cge+%28s%2B1%29%5E%7Bct%2Fn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c2%5E%7Bn%2F4%7D%2Fn%5Cge+%28s%2B1%29%5E%7Bct%2Fn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c2%5E%7Bn%2F4%7D%2Fn%5Cge+%28s%2B1%29%5E%7Bct%2Fn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c2^{n/4}/n&#92;ge (s+1)^{ct/n}" class="latex" />. Taking logs one gets <img src="https://s0.wp.com/latex.php?latex=ct%5Clog+%28s%29%2Fn%5Cle+cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=ct%5Clog+%28s%29%2Fn%5Cle+cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=ct%5Clog+%28s%29%2Fn%5Cle+cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="ct&#92;log (s)/n&#92;le cn" class="latex" />. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-3003r1"></a> <b>Exercise</b> 1.1. </span>For every <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> describe an <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />-state TM deciding palindromes in time <img src="https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D%2F%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D%2F%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D%2F%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn^{2}/&#92;log s" class="latex" /> (matching Theorem <a href="#x1-3001r1">1.1<!--tex4ht:ref: thm:TM-pal-requires-quadratic --></a>).</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-3004r2"></a> <b>Exercise</b> 1.2. </span>Let <img src="https://s0.wp.com/latex.php?latex=L%3A%3D%5C%7Bxx%3Ax%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%2A%7D%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%3A%3D%5C%7Bxx%3Ax%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%2A%7D%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%3A%3D%5C%7Bxx%3Ax%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%2A%7D%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L:=&#92;{xx:x&#92;in &#92;{0,1&#92;} ^{*}&#92;}" class="latex" />. Show <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BTM-Time%5Censuremath+%7B%28cn%5E%7B2%7D%29%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BTM-Time%5Censuremath+%7B%28cn%5E%7B2%7D%29%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BTM-Time%5Censuremath+%7B%28cn%5E%7B2%7D%29%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {TM-Time&#92;ensuremath {(cn^{2})}}" class="latex" />, and prove this is tight up to constants.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">One may be tempted to think that it is not hard to prove stronger bounds for similar functions. In fact as mentioned above this has resisted all attempts!</p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">1.2 </span> <a id="x1-40001.2"></a>Counting: impossibility results for non-explicit functions</h3>
<p style="text-align: justify">Proving the <em>existence</em> of hard functions is simple: Just count. If there are more functions than efficient machines, some function is not efficiently computable. This is applicable to any model; next we state it for TMs for concreteness. Later we will state it for circuits.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-4001r2"></a> <b>Theorem</b> 1.2. </span>There exists a function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} " class="latex" /> that cannot be computed by a TM with <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> states unless <img src="https://s0.wp.com/latex.php?latex=cs%5Clog+s%5Cge+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cs%5Clog+s%5Cge+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cs%5Clog+s%5Cge+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cs&#92;log s&#92;ge 2^{n}" class="latex" />, regardless of time.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>The number of TMs with <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> states is <img src="https://s0.wp.com/latex.php?latex=%5Cle+s%7B%7D%5E%7Bcs%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+s%7B%7D%5E%7Bcs%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+s%7B%7D%5E%7Bcs%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le s{}^{cs}," class="latex" /> and each TM computes at most one function (it may compute none, if it does not stop). The number of functions on <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> bits is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{2^{n}}" class="latex" />. Hence if <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%3Ecs%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%3Ecs%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%3Ecs%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{n}&gt;cs&#92;log s" class="latex" /> some function cannot be computed. <b>QED</b></p>
</div>
<p style="text-align: justify">Note this bound is not far from that in Exercise ??.</p>
<p style="text-align: justify">It is instructive to present this basic result as an application of the probabilistic method:</p>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>Let us pick <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> uniformly at random. We want to show that</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7Bf%7D%5B%5Cexists+%5Ctext+%7B+an+%7Ds%5Ctext+%7B-state+TM+%7DM%5Ctext+%7B+such+that+%7DM%28x%29%3Df%28x%29%5Ctext+%7B+for+every+%7Dx%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5D%3C1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7Bf%7D%5B%5Cexists+%5Ctext+%7B+an+%7Ds%5Ctext+%7B-state+TM+%7DM%5Ctext+%7B+such+that+%7DM%28x%29%3Df%28x%29%5Ctext+%7B+for+every+%7Dx%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5D%3C1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7Bf%7D%5B%5Cexists+%5Ctext+%7B+an+%7Ds%5Ctext+%7B-state+TM+%7DM%5Ctext+%7B+such+that+%7DM%28x%29%3Df%28x%29%5Ctext+%7B+for+every+%7Dx%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5D%3C1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;mathbb {P}_{f}[&#92;exists &#92;text { an }s&#92;text {-state TM }M&#92;text { such that }M(x)=f(x)&#92;text { for every }x&#92;in &#92;{0,1&#92;} ^{n}]&lt;1. &#92;end{aligned}" class="latex" /></div>
<p>Indeed, if the probability is less than <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> than some function exists that cannot be computed. By a union bound we can say that this probability is</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+%5Csum+_%7BM%7D%5Cmathbb+%7BP%7D_%7Bf%7D%5BM%28x%29%3Df%28x%29%5Ctext+%7B+for+every+%7Dx%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5D%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+%5Csum+_%7BM%7D%5Cmathbb+%7BP%7D_%7Bf%7D%5BM%28x%29%3Df%28x%29%5Ctext+%7B+for+every+%7Dx%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5D%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+%5Csum+_%7BM%7D%5Cmathbb+%7BP%7D_%7Bf%7D%5BM%28x%29%3Df%28x%29%5Ctext+%7B+for+every+%7Dx%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5D%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;le &#92;sum _{M}&#92;mathbb {P}_{f}[M(x)=f(x)&#92;text { for every }x&#92;in &#92;{0,1&#92;} ^{n}], &#92;end{aligned}" class="latex" /></div>
<p>where the sum is over all <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />-state machines. Each probability in the sum is <img src="https://s0.wp.com/latex.php?latex=%281%2F2%29%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%281%2F2%29%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%281%2F2%29%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(1/2)^{2^{n}}" class="latex" />, since <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is fixed. The number of <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />-state machines is <img src="https://s0.wp.com/latex.php?latex=%5Cle+s%5E%7Bcs%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+s%5E%7Bcs%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+s%5E%7Bcs%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le s^{cs}" class="latex" />. So the sum is <img src="https://s0.wp.com/latex.php?latex=%5Cle+s%5E%7Bcs%7D%281%2F2%29%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+s%5E%7Bcs%7D%281%2F2%29%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+s%5E%7Bcs%7D%281%2F2%29%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le s^{cs}(1/2)^{2^{n}}" class="latex" />, and we can conclude as before taking logs. <b>QED</b></p>
</div>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">1.3 </span> <a id="x1-50001.3"></a>Diagonalization: Enumerating machines</h3>
<p style="text-align: justify">Can you compute more if you have more time? For example, can you write a program that runs in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}" class="latex" /> and computes something that cannot be computed in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1.5%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B1.5%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B1.5%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{1.5}" class="latex" />? The answer is yes for trivial reasons if we allow for non-boolean functions.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-5001r3"></a> <b>Exercise</b> 1.3. </span>Give a function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;}^* " class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29%5Csetminus+%5Ctext+%7BTime%7D%28n%5E%7B1.5%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29%5Csetminus+%5Ctext+%7BTime%7D%28n%5E%7B1.5%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29%5Csetminus+%5Ctext+%7BTime%7D%28n%5E%7B1.5%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(n^{2})&#92;setminus &#92;text {Time}(n^{1.5})" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">The answer is more interesting if the functions are boolean. Such results are known as <em>time hierarchies</em>, and a generic technique for proving them is <em>diagonalization, </em>applicable to any model.</p>
<p style="text-align: justify">We first illustrate the result in the simpler case of partial functions, which contains the main ideas. Later we discuss total functions.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-5002r3"></a> <b>Theorem</b> 1.3. </span>There is a partial function in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(t(n))" class="latex" /> such that any TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> computing it runs in time <img src="https://s0.wp.com/latex.php?latex=%5Cge+c_%7BM%7Dt%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c_%7BM%7Dt%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c_%7BM%7Dt%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c_{M}t(n)" class="latex" />, for any <img src="https://s0.wp.com/latex.php?latex=t%28n%29%3D%5Comega+%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%3D%5Comega+%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%3D%5Comega+%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)=&#92;omega (1)" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">In other words, <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28t%28n%29%29%5Csupsetneq+%5Ctext+%7BTime%7D%28o%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28t%28n%29%29%5Csupsetneq+%5Ctext+%7BTime%7D%28o%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28t%28n%29%29%5Csupsetneq+%5Ctext+%7BTime%7D%28o%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(t(n))&#92;supsetneq &#92;text {Time}(o(t(n))" class="latex" />.</p>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>Consider the TM <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> that on input <img src="https://s0.wp.com/latex.php?latex=x%3D%28M%2C1%5E%7Bn-%7CM%7C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%3D%28M%2C1%5E%7Bn-%7CM%7C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%3D%28M%2C1%5E%7Bn-%7CM%7C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x=(M,1^{n-|M|})" class="latex" /> of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> runs <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> until it stops and then complements the answer. (We can use a simple encoding of these pairs, for example every even-position bit of the description of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is a <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" />.)</p>
<p style="text-align: justify">Now define <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> to be the subset of pairs s.t. <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> runs in time <img src="https://s0.wp.com/latex.php?latex=%5Cle+t%28n%29%2F%7CM%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+t%28n%29%2F%7CM%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+t%28n%29%2F%7CM%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le t(n)/|M|^{c}" class="latex" /> on inputs of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|M|^{c}&#92;le t(n)/2" class="latex" />.</p>
<p style="text-align: justify">On these inputs, <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> runs in time <img src="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%2B%7CM%7C%5E%7Bc%7D%5Ccdot+t%28n%29%2F%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%2B%7CM%7C%5E%7Bc%7D%5Ccdot+t%28n%29%2F%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%2B%7CM%7C%5E%7Bc%7D%5Ccdot+t%28n%29%2F%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|M|^{c}+|M|^{c}&#92;cdot t(n)/|M|^{c}&#92;le t(n)" class="latex" />, as desired. To accomplish this, <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> can begin by making a copy of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> in time <img src="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|M|^{c}&#92;le t(n)/2" class="latex" />. Then every step of the computation of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> can be simulated by <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|M|^{c}" class="latex" /> steps, always keeping the description of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> to the left of the head.</p>
<p style="text-align: justify">Now suppose <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N" class="latex" /> computes the same function as <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> in time <img src="https://s0.wp.com/latex.php?latex=t%28n%29%2F%7CN%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%2F%7CN%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%2F%7CN%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)/|N|^{c}" class="latex" />. Note that <img src="https://s0.wp.com/latex.php?latex=x%3A%3D%28N%2C1%5E%7Bn-%7CN%7C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%3A%3D%28N%2C1%5E%7Bn-%7CN%7C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%3A%3D%28N%2C1%5E%7Bn-%7CN%7C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x:=(N,1^{n-|N|})" class="latex" /> falls in the domain <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> of the function, for <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> sufficiently large, using that <img src="https://s0.wp.com/latex.php?latex=t%28n%29%3D%5Comega+%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%3D%5Comega+%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%3D%5Comega+%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)=&#92;omega (1)" class="latex" />. Now consider running <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />. We have <img src="https://s0.wp.com/latex.php?latex=N%28x%29%3DH%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N%28x%29%3DH%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N%28x%29%3DH%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N(x)=H(x)" class="latex" /> by supposition, but <img src="https://s0.wp.com/latex.php?latex=H%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H(x)" class="latex" /> is the complement of <img src="https://s0.wp.com/latex.php?latex=N%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N(x)" class="latex" />, contradiction. <b>QED</b></p>
</div>
<p style="text-align: justify">This proof is somewhat unsatisfactory; in particular we have no control on the running time of <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> on inputs not in <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" />. It is desirable to have a version of this fundamental result for total functions. Such a version is stated next. It requires additional assumptions on <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> and a larger gap between the running times. Perhaps surprisingly, as we shall discuss, both requirements are essential.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-5003r4"></a> <b>Theorem</b> 1.4. </span> Let <img src="https://s0.wp.com/latex.php?latex=t%28n%29%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)&#92;ge n" class="latex" /> be a function. Suppose that <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3A%3Dt%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3A%3Dt%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3A%3Dt%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x):=t(|x|)" class="latex" /> is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%2F%5Clog+%5E%7Bc%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%2F%5Clog+%5E%7Bc%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%2F%5Clog+%5E%7Bc%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(t(n)/&#92;log ^{c}n)" class="latex" />.</p>
<p style="text-align: justify">There is a total function in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28ct%28n%29%5Clog+t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28ct%28n%29%5Clog+t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28ct%28n%29%5Clog+t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(ct(n)&#92;log t(n))" class="latex" /> that cannot be computed by any TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> in time <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}t(n)" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">The assumption about <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is satisfied by all standard functions, including all those in this book. (For example, take <img src="https://s0.wp.com/latex.php?latex=t%28n%29%3A%3Dn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%3A%3Dn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%3A%3Dn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n):=n^{2}" class="latex" />. The corresponding <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is then <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|^{2}" class="latex" />. To compute <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> bits we can first compute <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|=n" class="latex" /> in time <img src="https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn&#92;log n" class="latex" /> (Exercise ??). This is a number of <img src="https://s0.wp.com/latex.php?latex=b%3A%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%3A%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%3A%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b:=&#92;log n" class="latex" /> bits. We can then square this number in time <img src="https://s0.wp.com/latex.php?latex=b%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b^{c}" class="latex" />. Note that the time to compute <img src="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)" class="latex" /> is dominated by the <img src="https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn&#92;log n" class="latex" /> term coming from computing <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|" class="latex" />, which does not depend on <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> and is much less than the <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}/&#92;log ^{c}n" class="latex" /> in the assumption.) The assumption cannot be removed altogether because there exist pathological functions <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> for which the result is false.</p>
<p style="text-align: justify">The proof is similar to that of Theorem <a href="#x1-5002r3">1.3<!--tex4ht:ref: thm:time-hierarchy-TM-Time-partial --></a>. However, to make the function total we need to deal with arbitrary machines, which may not run in the desired time or even stop at all. The solution is to clock <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> in a manner similar to the proof of the universal machine, Lemma ??.</p>
<p style="text-align: justify">Also, we define a slightly different language to give a stronger result – a unary language – and to avoid some minor technical details (the possibility that the computation of <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> erases the input).</p>
<p style="text-align: justify">We define a TM <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> that on input <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" /> obtains a description of a TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, computes <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />, and then simulates <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on input <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" /> steps in a way similar to Lemma ??, and if <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> stops then <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> outputs the complement of the output of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />; and if <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> does not stop then <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> stops and outputs anything. Now <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> computes a function in time about <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />. We argue that this function cannot be computed in much less time as follows. Suppose some TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> computes the function in time somewhat less than <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />. Then we can pick an <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" /> for which <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> obtains the description of this <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, and the simulation always stops. Hence, for that <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" /> we would obtain <img src="https://s0.wp.com/latex.php?latex=M%281%5E%7Bn%7D%29%3DH%281%5E%7Bn%7D%29%3D1-M%281%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%281%5E%7Bn%7D%29%3DH%281%5E%7Bn%7D%29%3D1-M%281%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%281%5E%7Bn%7D%29%3DH%281%5E%7Bn%7D%29%3D1-M%281%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(1^{n})=H(1^{n})=1-M(1^{n})" class="latex" />, which is a contradiction.</p>
<p style="text-align: justify">However, there are interesting differences with the simulation in Lemma ??. In that lemma the universal machine <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> was clocking the steps of the machine <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> being simulated. Now instead we need to clock the steps of <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> itself, even while <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> is parsing the description of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> to compute its transition function. This is necessary to guarantee that <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> does not waste time on big TM descriptions.</p>
<p style="text-align: justify">Whereas in Lemma ?? the tape was arranged as</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2CM%2C%5Cunderline+%7Bi%7D%2Ct%27%2Cy%29%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2CM%2C%5Cunderline+%7Bi%7D%2Ct%27%2Cy%29%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2CM%2C%5Cunderline+%7Bi%7D%2Ct%27%2Cy%29%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} (x,M,&#92;underline {i},t&#039;,y), &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">it will now be arranged as</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2CM%27%2C%5Cunderline+%7Bi%7D%2Ct%27%2CM%27%27%2Cy%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2CM%27%2C%5Cunderline+%7Bi%7D%2Ct%27%2CM%27%27%2Cy%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2CM%27%2C%5Cunderline+%7Bi%7D%2Ct%27%2CM%27%27%2Cy%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} (x,M&#039;,&#92;underline {i},t&#039;,M&#039;&#039;,y) &#92;end{aligned}" class="latex" /></div>
<p>which is parsed as follows. The description of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=M%27M%27%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%27M%27%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%27M%27%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M&#039;M&#039;&#039;" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is in state <img src="https://s0.wp.com/latex.php?latex=%5Cunderline+%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cunderline+%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cunderline+%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;underline {i}" class="latex" />, the tape of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> contains <img src="https://s0.wp.com/latex.php?latex=xy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=xy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=xy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="xy" class="latex" /> and the head is on the left-most symbol of <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />. The integer <img src="https://s0.wp.com/latex.php?latex=t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#039;" class="latex" /> is the counter decreased at every step</p>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>Define TM <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> that on input <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" />:</p>
<ol class="enumerate1">
<li id="x1-5005x1" class="enumerate">Compute <img src="https://s0.wp.com/latex.php?latex=%28n%2Ct%28n%29%2C1%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28n%2Ct%28n%29%2C1%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28n%2Ct%28n%29%2C1%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(n,t(n),1^{n})" class="latex" />.</li>
<li id="x1-5007x2" class="enumerate">Compute <img src="https://s0.wp.com/latex.php?latex=%28M_%7Bn%7D%2Ct%28n%29%2C1%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28M_%7Bn%7D%2Ct%28n%29%2C1%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28M_%7Bn%7D%2Ct%28n%29%2C1%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(M_{n},t(n),1^{n})" class="latex" />. Here <img src="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{n}" class="latex" /> is obtained from <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> by removing all left-most zeroes until the first <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" />. I.e., if <img src="https://s0.wp.com/latex.php?latex=n%3D0%5E%7Bj%7D1x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%3D0%5E%7Bj%7D1x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%3D0%5E%7Bj%7D1x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n=0^{j}1x" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=M_%7Bn%7D%3Dx&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7Bn%7D%3Dx&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7Bn%7D%3Dx&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{n}=x" class="latex" />. This is similar to the fact that a program does not change if you add, say, empty lines at the bottom.</li>
<li id="x1-5009x3" class="enumerate">Simulate <img src="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{n}" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" />, reducing the counter <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" /> at every step, including those parsing <img src="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{n}" class="latex" />, as explained before.</li>
<li id="x1-5011x4" class="enumerate">If <img src="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{n}" class="latex" /> stops before the counter reaches <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" />, output the complement of its output. If the counter reaches <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> stop and output anything.</li>
</ol>
<p style="text-align: justify"><em>Running time of <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" />.</em></p>
<ol class="enumerate1">
<li id="x1-5013x1" class="enumerate">Computing <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> is similar to Exercise ??. By assumption <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" /> is computable in time <img src="https://s0.wp.com/latex.php?latex=t%28n%29%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)/&#92;log ^{c}n" class="latex" />. Our definition of computation allows for erasing the input, but we can keep <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> around spending at most another <img src="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log ^{c}n" class="latex" /> factor. Thus we can compute <img src="https://s0.wp.com/latex.php?latex=%28n%2Ct%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28n%2Ct%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28n%2Ct%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(n,t(n))" class="latex" /> in time <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />. Finally, in case it was erased, we can re-compute <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" /> in time <img src="https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn&#92;log n" class="latex" /> by keeping a counter (initialized to a copy of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />).</li>
<li id="x1-5015x2" class="enumerate">This takes time <img src="https://s0.wp.com/latex.php?latex=c%28n%2Bt%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%28n%2Bt%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%28n%2Bt%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c(n+t(n))" class="latex" />: simply scan the input and remove zeroes.</li>
<li id="x1-5017x3" class="enumerate">Decreasing the counter takes <img src="https://s0.wp.com/latex.php?latex=c%7Ct%28n%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%7Ct%28n%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%7Ct%28n%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c|t(n)|" class="latex" /> steps. Hence this simulation will take <img src="https://s0.wp.com/latex.php?latex=ct%28n%29%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=ct%28n%29%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=ct%28n%29%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="ct(n)&#92;log t(n)" class="latex" /> time.</li>
</ol>
<p style="text-align: justify">Overall the running time is <img src="https://s0.wp.com/latex.php?latex=ct%28n%29%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=ct%28n%29%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=ct%28n%29%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="ct(n)&#92;log t(n)" class="latex" />.</p>
<p style="text-align: justify"><em>Proof that the function computed by <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> requires much time.</em> Suppose some TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> computes the same function as <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" />. Consider inputs <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=n%3D0%5E%7Bj%7D1M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%3D0%5E%7Bj%7D1M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%3D0%5E%7Bj%7D1M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n=0^{j}1M" class="latex" />. Parsing the description of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> to compute its transition function takes time <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}" class="latex" />, a value that depends on <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> only and not on <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j" class="latex" />. Hence <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> will simulate <img src="https://s0.wp.com/latex.php?latex=%5Clfloor+t%28n%29%2Fc_%7BM%7D%5Crfloor+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clfloor+t%28n%29%2Fc_%7BM%7D%5Crfloor+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clfloor+t%28n%29%2Fc_%7BM%7D%5Crfloor+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lfloor t(n)/c_{M}&#92;rfloor " class="latex" /> steps of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />. If <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> stops within that time (which requires <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" /> to be larger than <img src="https://s0.wp.com/latex.php?latex=b_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b_{M}" class="latex" />, and so <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j" class="latex" /> sufficiently large compared to <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />) then the simulation terminates and we reach a contradiction as explained before. <b>QED</b></p>
</div>
<p style="text-align: justify">The extra <img src="https://s0.wp.com/latex.php?latex=%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log t(n)" class="latex" /> factor cannot be reduced because of the surprising result presented in Theorem <a href="#x1-6001r5">1.5<!--tex4ht:ref: thm:TIMEonlogn=00003Dregular --></a> showing that, on TMs, time <img src="https://s0.wp.com/latex.php?latex=o%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=o%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=o%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="o(n&#92;log n)" class="latex" /> equals time <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> for computing total functions.</p>
<p style="text-align: justify">However, tighter time hierarchies hold for more powerful models, like RAMs. Also, a time hierarchy for total functions for <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPTime}" class="latex" /> is&#8230; an open problem! But a hierarchy is known for partial functions.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-5018r4"></a> <b>Exercise</b> 1.4. </span>(1) State and prove a tighter time hierarchy for Time (which recall corresponds to RAMs) for total functions. You don’t need to address simulation details, but you need to explain why a sharper separation is possible.</p>
<p style="text-align: justify">(2) Explain the difficulty in extending (1) to <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPTime}" class="latex" />.</p>
<p style="text-align: justify">(3) State and prove a time hierarchy for <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPTime}" class="latex" /> for partial functions.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<h4 class="subsectionHead"><span class="titlemark">1.3.1 </span> <a id="x1-60001.3.1"></a><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28o%28n%5Clog+n%29%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28o%28n%5Clog+n%29%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28o%28n%5Clog+n%29%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(o(n&#92;log n))=&#92;text {TM-Time}(n)" class="latex" /></h4>
<p style="text-align: justify">In this subsection we prove the result in the title, which we also mentioned earlier. First let us state the result formally.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-6001r5"></a> <b>Theorem</b> 1.5. </span> <span class="cite">[<a href="journals/iandc/Hennie65">1</a>, <a href="#XKobayashi1985OnTS">2</a>]</span> Let <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} " class="latex" /> be in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(t(n))" class="latex" /> for a <img src="https://s0.wp.com/latex.php?latex=t%28n%29%3Do%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%3Do%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%3Do%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)=o(n&#92;log n)" class="latex" />. Then <img src="https://s0.wp.com/latex.php?latex=f%5Cin+%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%5Cin+%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%5Cin+%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f&#92;in &#92;text {TM-Time}(n)" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Note that time <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> is barely enough to scan the input. Indeed, the corresponding machines in Theorem <a href="#x1-6001r5">1.5<!--tex4ht:ref: thm:TIMEonlogn=00003Dregular --></a> will only move the head in one direction.</p>
<p style="text-align: justify">The rest of this section is devoted to proving the above theorem. Let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be a machine for <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> witnessing the assumption of the theorem. We can assume that <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> stops on every input (even though our definition of time only applies to large enough inputs), possibly by adding <img src="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n" class="latex" /> to the time, which does not change the assumption on <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />. The theorem now follows from the combination of the next two lemmas.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-6002r1"></a> <b>Lemma</b> 1.1. </span>Let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be a TM running in time <img src="https://s0.wp.com/latex.php?latex=t%28n%29%5Cle+o%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%5Cle+o%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%5Cle+o%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)&#92;le o(n&#92;log n)" class="latex" />. Then on every input <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;}^* " class="latex" /> every <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS with <img src="https://s0.wp.com/latex.php?latex=i%5Cle+%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%5Cle+%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%5Cle+%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#92;le |x|" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c_{M}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>For an integer <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b" class="latex" /> let <img src="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x(b)" class="latex" /> be a shortest input such that there exists <img src="https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B0%2C1%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B0%2C1%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B0%2C1%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j&#92;in &#92;{0,1,&#92;ldots ,n&#92;}" class="latex" /> for which the <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j" class="latex" />-CS in the computation of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x(b)" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge b" class="latex" />. Let <img src="https://s0.wp.com/latex.php?latex=n%28b%29%3A%3D%7Cx%28b%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%28b%29%3A%3D%7Cx%28b%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%28b%29%3A%3D%7Cx%28b%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n(b):=|x(b)|" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-6003r5"></a> <b>Exercise</b> 1.5. </span>Prove <img src="https://s0.wp.com/latex.php?latex=n%28b%29%5Cto+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%28b%29%5Cto+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%28b%29%5Cto+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n(b)&#92;to &#92;infty " class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=b%5Cto+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%5Cto+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%5Cto+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b&#92;to &#92;infty " class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">There are <img src="https://s0.wp.com/latex.php?latex=n%28b%29%2B1%5Cge+n%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%28b%29%2B1%5Cge+n%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%28b%29%2B1%5Cge+n%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n(b)+1&#92;ge n(b)" class="latex" /> tape boundaries within or bordering <img src="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x(b)" class="latex" />. If we pick a boundary uniformly at random, the average length of a CS on <img src="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x(b)" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cle+t%28n%28b%29%29%2Fn%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+t%28n%28b%29%29%2Fn%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+t%28n%28b%29%29%2Fn%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le t(n(b))/n(b)" class="latex" />. Hence there are <img src="https://s0.wp.com/latex.php?latex=%5Cge+n%28b%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+n%28b%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+n%28b%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge n(b)/2" class="latex" /> choices for <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> s.t. the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS on <img src="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x(b)" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+2t%28n%28b%29%29%2Fn%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+2t%28n%28b%29%29%2Fn%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+2t%28n%28b%29%29%2Fn%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le 2t(n(b))/n(b)" class="latex" />.</p>
<p style="text-align: justify">The number of such crossing sequences is</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+%28s%2B1%29%5E%7B2t%28n%28b%29%29%2Fn%28b%29%7D%3D%28s%2B1%29%5E%7Bo%28n%28b%29%5Clog+%28n%28b%29%29%2Fn%28b%29%7D%3Dn%28b%29%5E%7Bo%28%5Clog+s%29%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+%28s%2B1%29%5E%7B2t%28n%28b%29%29%2Fn%28b%29%7D%3D%28s%2B1%29%5E%7Bo%28n%28b%29%5Clog+%28n%28b%29%29%2Fn%28b%29%7D%3Dn%28b%29%5E%7Bo%28%5Clog+s%29%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+%28s%2B1%29%5E%7B2t%28n%28b%29%29%2Fn%28b%29%7D%3D%28s%2B1%29%5E%7Bo%28n%28b%29%5Clog+%28n%28b%29%29%2Fn%28b%29%7D%3Dn%28b%29%5E%7Bo%28%5Clog+s%29%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;le (s+1)^{2t(n(b))/n(b)}=(s+1)^{o(n(b)&#92;log (n(b))/n(b)}=n(b)^{o(&#92;log s)}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">Hence, the same crossing sequence occurs at <img src="https://s0.wp.com/latex.php?latex=%5Cge+%28n%28b%29%2F2%29%2Fn%28b%29%5E%7Bo%28%5Clog+s%29%7D%5Cge+4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+%28n%28b%29%2F2%29%2Fn%28b%29%5E%7Bo%28%5Clog+s%29%7D%5Cge+4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+%28n%28b%29%2F2%29%2Fn%28b%29%5E%7Bo%28%5Clog+s%29%7D%5Cge+4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge (n(b)/2)/n(b)^{o(&#92;log s)}&#92;ge 4" class="latex" /> positions <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />, using that <img src="https://s0.wp.com/latex.php?latex=n%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n(b)" class="latex" /> is large enough.</p>
<p style="text-align: justify">Of these four, one could be the CS of length <img src="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge b" class="latex" /> from the definition of <img src="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x(b)" class="latex" />. Of the other three, two are on the same side of <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j" class="latex" />. We can remove the corresponding interval of the input without removing the CS of length <img src="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge b" class="latex" />. Hence we obtained a shorter input with a CS of length <img src="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge b" class="latex" />. Contradiction. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-6004r2"></a> <b>Lemma</b> 1.2. </span>Suppose <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} " class="latex" /> is computable by a TM such that on every input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, every <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS with <img src="https://s0.wp.com/latex.php?latex=i%5Cle+%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%5Cle+%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%5Cle+%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#92;le |x|" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le b" class="latex" />. Then <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is computable in time <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> by a TM with <img src="https://s0.wp.com/latex.php?latex=c_%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{b}" class="latex" /> states that only moves the head in one direction.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-6005r6"></a> <b>Exercise</b> 1.6. </span>Prove this.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">1.4 </span> <a id="x1-70001.4"></a>Circuits</h3>
<p style="text-align: justify">The situation for circuits is similar to that of 2-TMs, and by Theorem ?? we know that proving <img src="https://s0.wp.com/latex.php?latex=%5Comega+%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Comega+%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Comega+%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;omega (n&#92;log n)" class="latex" /> bounds on circuits is harder than for 2-TMs. Even a bound of <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" /> is unknown. The following is a circuit version of Theorem <a href="#x1-4001r2">1.2<!--tex4ht:ref: thm:TM-counting-lower-bound --></a>. Again, the bound is close to what we saw in Theorem ??.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-7001r6"></a> <b>Theorem</b> 1.6. </span><span class="cite">[<a href="#XMR29860">3</a>]</span> There are functions <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} " class="latex" /> that require circuits of size <img src="https://s0.wp.com/latex.php?latex=%5Cge+%281-o%281%29%292%5E%7Bn%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+%281-o%281%29%292%5E%7Bn%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+%281-o%281%29%292%5E%7Bn%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge (1-o(1))2^{n}/n" class="latex" />, for every <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">One can prove a hierarchy for circuit size, by combining Theorem <a href="#x1-7001r6">1.6<!--tex4ht:ref: thm:shannon-hard-function --></a> and Theorem ??. As stated, the results give that circuits of size <img src="https://s0.wp.com/latex.php?latex=cs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cs" class="latex" /> compute more functions than those of size <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />. In fact, the “<img src="https://s0.wp.com/latex.php?latex=o%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=o%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=o%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="o(1)" class="latex" />” in the theorems is small, so one can prove a sharper result. But a stronger and more enjoyable argument exists.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-7002r7"></a> <b>Theorem</b> 1.7. </span>[Hierarchy for circuit size] For every <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=s%5Cle+c2%5E%7Bn%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cle+c2%5E%7Bn%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cle+c2%5E%7Bn%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;le c2^{n}/n" class="latex" /> there is a function <img src="https://s0.wp.com/latex.php?latex=f%3A%5Czonzo+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5Czonzo+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5Czonzo+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;zonzo " class="latex" /> that can be computed by circuits of size <img src="https://s0.wp.com/latex.php?latex=s%2Bcn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%2Bcn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%2Bcn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s+cn" class="latex" /> but not by circuits of size <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>Consider a path from the all-zero function to a function which requires circuits of size <img src="https://s0.wp.com/latex.php?latex=%5Cge+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge s" class="latex" />, guaranteed to exist by Theorem <a href="#x1-7001r6">1.6<!--tex4ht:ref: thm:shannon-hard-function --></a>, changing the output of the function on one input at each step of the path. Let <img src="https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h" class="latex" /> be the first function that requires size <img src="https://s0.wp.com/latex.php?latex=%3Es&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%3Es&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%3Es&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&gt;s" class="latex" />, and let <img src="https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h&#039;" class="latex" /> be the function right before that in the path. Note that <img src="https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h&#039;" class="latex" /> has circuits of size <img src="https://s0.wp.com/latex.php?latex=%5Cle+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le s" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h" class="latex" /> can be computed from <img src="https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h&#039;" class="latex" /> by changing the value on a single input. The latter can be implemented by circuits of size <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" />. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-7003r7"></a> <b>Exercise</b> 1.7. </span>Prove a stronger hierarchy result for alternating circuits, where the “<img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" />” in Theorem <a href="#x1-7002r7">1.7<!--tex4ht:ref: thm:hierarchy-circuits-cn --></a> is replaced with “<img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c" class="latex" />.”</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">In fact, this improvement is possible even for (non aternating) circuits, see Problem <a href="#x1-9002r2">1.2<!--tex4ht:ref: prob:hierarchy-circuits-c --></a>.</p>
<p style="text-align: justify">
<h4 class="subsectionHead"><span class="titlemark">1.4.1 </span> <a id="x1-80001.4.1"></a>The circuit won’t fit in the universe: Non-asymptotic, cosmological results</h4>
<p style="text-align: justify">Most of the results in this book are <em>asymptotic</em>, i.e., we do not explicitly work out the constants because they become irrelevant for larger and larger input lengths. As stated, these results don’t say anything for inputs of a fixed length. For example, any function on <img src="https://s0.wp.com/latex.php?latex=10%5E%7B100%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=10%5E%7B100%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=10%5E%7B100%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="10^{100}" class="latex" /> bits is in Time<img src="https://s0.wp.com/latex.php?latex=%28c%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28c%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28c%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(c)" class="latex" />.</p>
<p style="text-align: justify">However, it is important to note that all the proofs are <em>constructive </em>and one can work out the constants, and produce non-asymptotic results. We state next one representative example when this was done. It is about a problem in logic, an area which often produces very hard problems.</p>
<p style="text-align: justify">On an alphabet of size <img src="https://s0.wp.com/latex.php?latex=63&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=63&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=63&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="63" class="latex" />, the language used to write formulas includes first-order variables that range over <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {N}" class="latex" />, second-order variables that range over finite subsets of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {N}" class="latex" />, the predicates “<img src="https://s0.wp.com/latex.php?latex=y%3Dx%2B1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y%3Dx%2B1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y%3Dx%2B1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y=x+1" class="latex" />” and “<img src="https://s0.wp.com/latex.php?latex=x%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in S" class="latex" />” where <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> denote first-order variables and <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> denotes a set variable, and standard quantifiers, connectives, constants, binary relation symbols on integers, and set equality. For example one can write things like “every finite set has a maximum:” <img src="https://s0.wp.com/latex.php?latex=%5Cforall+S%5Cexists+x%5Cin+S%5Cforall+y%5Cin+S%2Cy%5Cle+x.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cforall+S%5Cexists+x%5Cin+S%5Cforall+y%5Cin+S%2Cy%5Cle+x.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cforall+S%5Cexists+x%5Cin+S%5Cforall+y%5Cin+S%2Cy%5Cle+x.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;forall S&#92;exists x&#92;in S&#92;forall y&#92;in S,y&#92;le x." class="latex" /></p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-8001r8"></a> <b>Theorem</b> 1.8. </span><span class="cite">[<a href="#XMR2145856">4</a>]</span> To decide the truth of logical formulas of length at most <img src="https://s0.wp.com/latex.php?latex=610&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=610&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=610&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="610" class="latex" /> in this language requires a circuit containing at least <img src="https://s0.wp.com/latex.php?latex=10%5E%7B125%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=10%5E%7B125%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=10%5E%7B125%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="10^{125}" class="latex" /> gates. So even if each gate were the size of a proton, the circuit would not fit in the known universe.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Their result applies even to randomized circuits with error <img src="https://s0.wp.com/latex.php?latex=1%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1/3" class="latex" />, if <img src="https://s0.wp.com/latex.php?latex=610&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=610&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=610&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="610" class="latex" /> is replaced with <img src="https://s0.wp.com/latex.php?latex=614&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=614&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=614&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="614" class="latex" />. (We can define randomized circuits analogously to BPTime.)</p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">1.5 </span> <a id="x1-90001.5"></a>Problems</h3>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-9001r1"></a> <b>Problem</b> 1.1. </span>Hierarchy Theorem <a href="#x1-5003r4">1.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a> only gives a function <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> that cannot be computed fast on <em>all </em>large enough input lengths: it is consistent with the theorem that <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> can be computed fast on infinitely many input lengths.</p>
<p style="text-align: justify">Give a function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;}^* " class="latex" /> mapping <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7B%5Clog+%5Clog+%5Clog+%7Cx%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7B%5Clog+%5Clog+%5Clog+%7Cx%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7B%5Clog+%5Clog+%5Clog+%7Cx%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{&#92;log &#92;log &#92;log |x|}" class="latex" /> that is computable in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{c}" class="latex" /> but such that for any TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> running in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}" class="latex" /> the following holds. For every <img src="https://s0.wp.com/latex.php?latex=n%5Cge+c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5Cge+c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Cge+c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#92;ge c_{M}" class="latex" /> and every <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n}" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=M%28x%29%5Cne+f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%29%5Cne+f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%29%5Cne+f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x)&#92;ne f(x)" class="latex" />.</p>
<p style="text-align: justify">Hint: Note the range of <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />. Can this result hold as stated with range <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} " class="latex" />?</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-9002r2"></a> <b>Problem</b> 1.2. </span>Replace “<img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" />” in Theorem <a href="#x1-7002r7">1.7<!--tex4ht:ref: thm:hierarchy-circuits-cn --></a> with “<img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c" class="latex" />.”</p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-9003r3"></a> <b>Problem</b> 1.3. </span>Prove that <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%5E%7Bi%7D1%5E%7Bi%7D%3Ai%5Cge+0%5C%7D%5Cin+%5Ctext+%7BTM-Time%5Censuremath+%7B%28cn%5Clog+n%29%5Csetminus+%5Ctext+%7BTM-Time%7D%28n%29%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%5E%7Bi%7D1%5E%7Bi%7D%3Ai%5Cge+0%5C%7D%5Cin+%5Ctext+%7BTM-Time%5Censuremath+%7B%28cn%5Clog+n%29%5Csetminus+%5Ctext+%7BTM-Time%7D%28n%29%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%5E%7Bi%7D1%5E%7Bi%7D%3Ai%5Cge+0%5C%7D%5Cin+%5Ctext+%7BTM-Time%5Censuremath+%7B%28cn%5Clog+n%29%5Csetminus+%5Ctext+%7BTM-Time%7D%28n%29%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0^{i}1^{i}:i&#92;ge 0&#92;}&#92;in &#92;text {TM-Time&#92;ensuremath {(cn&#92;log n)&#92;setminus &#92;text {TM-Time}(n)}.}" class="latex" /></p>
<p style="text-align: justify">This shows Theorem <a href="#x1-6001r5">1.5<!--tex4ht:ref: thm:TIMEonlogn=00003Dregular --></a> is tight, and gives an explicit problem witnessing the time-hierarchy separation in Theorem <a href="#x1-5003r4">1.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>, for a specific time bound. For the negative result, don’t use pumping lemmas or other characterization results not covered in this book.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-9004r4"></a> <b>Problem</b> 1.4. </span>The following argument contradicts Theorem <a href="#x1-5003r4">1.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>; what is wrong with it?</p>
<p style="text-align: justify">“By Theorem <a href="#x1-6001r5">1.5<!--tex4ht:ref: thm:TIMEonlogn=00003Dregular --></a>, <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B0.9%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B0.9%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B0.9%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(n&#92;log ^{0.9}n)=&#92;text {TM-Time}(n)" class="latex" />. By padding (Theorem <a href="#x1-6001r5">1.5<!--tex4ht:ref: thm:TIMEonlogn=00003Dregular --></a>), <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B1.1%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B0.9%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B1.1%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B0.9%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B1.1%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B0.9%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(n&#92;log ^{1.1}n)=&#92;text {TM-Time}(n&#92;log ^{0.9}n)" class="latex" />. Hence <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B1.1%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B1.1%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B1.1%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(n&#92;log ^{1.1}n)=&#92;text {TM-Time}(n)." class="latex" />”</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<h3 class="likesectionHead"><a id="x1-100001.5"></a>References</h3>
<p style="text-align: justify">
<div class="thebibliography">
<p class="bibitem"><span class="biblabel"> [1]<span class="bibsp">   </span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F. C. Hennie. One-tape, off-line turing machine computations. Information and Control, 8(6):553–578, 1965.</p>
<p class="bibitem"><span class="biblabel"> [2]<span class="bibsp">   </span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi. On the structure of one-tape nondeterministic turing machine time hierarchy. Theor. Comput. Sci., 40:175–193, 1985.</p>
<p class="bibitem"><span class="biblabel"> [3]<span class="bibsp">   </span></span><a id="XMR29860"></a>Claude E. Shannon. The synthesis of two-terminal switching circuits. Bell System Tech. J., 28:59–98, 1949.</p>
<p class="bibitem"><span class="biblabel"> [4]<span class="bibsp">   </span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert R. Meyer. Cosmological lower bound on the circuit complexity of a small problem in logic. J. ACM, 49(6):753–784, 2002.</p>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T13:17:45Z">Thursday, February 02 2023, 13:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/02/professor-in-theoretical-computer-science-at-the-university-of-melbourne-apply-by-february-12-2023/'>Professor in Theoretical Computer Science at The University of Melbourne (apply by February 12, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The University of Melbourne is seeking an outstanding academic with expertise in Theoretical Computer Science to join an internationally recognised group of academics within the School of Computing and Information Systems in the Faculty of Engineering and Information Technology. We are seeking to appoint at the Full Professor level. The University is an equal opportunity [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The University of Melbourne is seeking an outstanding academic with expertise in Theoretical Computer Science to join an internationally recognised group of academics within the School of Computing and Information Systems in the Faculty of Engineering and Information Technology. We are seeking to appoint at the Full Professor level. The University is an equal opportunity employer.</p>
<p>Website: <a href="https://jobs.unimelb.edu.au/en/job/911413/professor-in-theoretical-computing-science">https://jobs.unimelb.edu.au/en/job/911413/professor-in-theoretical-computing-science</a><br />
Email: awirth@unimelb.edu.au</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T06:58:22Z">Thursday, February 02 2023, 06:58</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00273'>Hardness of braided quantum circuit optimization in the surface code</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kunihiro Wasa, Shin Nishio, Koki Suetsugu, Michael Hanks, Ashley Stephens, Yu Yokoi, Kae Nemoto</p><p>Large-scale quantum information processing requires the use of quantum error
correcting codes to mitigate the effects of noise in quantum devices.
Topological error-correcting codes, such as surface codes, are promising
candidates as they can be implemented using only local interactions in a
two-dimensional array of physical qubits. Procedures such as defect braiding
and lattice surgery can then be used to realize a fault-tolerant universal set
of gates on the logical space of such topological codes. However, error
correction also introduces a significant overhead in computation time, the
number of physical qubits, and the number of physical gates. While optimizing
fault-tolerant circuits to minimize this overhead is critical, the
computational complexity of such optimization problems remains unknown. This
ambiguity leaves room for doubt surrounding the most effective methods for
compiling fault-tolerant circuits for a large-scale quantum computer. In this
paper, we show that the optimization of a special subset of braided quantum
circuits is NP-hard by a polynomial-time reduction of the optimization problem
into a specific problem called Planar Rectilinear 3SAT.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Wasa_K/0/1/0/all/0/1">Kunihiro Wasa</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nishio_S/0/1/0/all/0/1">Shin Nishio</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Suetsugu_K/0/1/0/all/0/1">Koki Suetsugu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hanks_M/0/1/0/all/0/1">Michael Hanks</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Stephens_A/0/1/0/all/0/1">Ashley Stephens</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yokoi_Y/0/1/0/all/0/1">Yu Yokoi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nemoto_K/0/1/0/all/0/1">Kae Nemoto</a></p><p>Large-scale quantum information processing requires the use of quantum error
correcting codes to mitigate the effects of noise in quantum devices.
Topological error-correcting codes, such as surface codes, are promising
candidates as they can be implemented using only local interactions in a
two-dimensional array of physical qubits. Procedures such as defect braiding
and lattice surgery can then be used to realize a fault-tolerant universal set
of gates on the logical space of such topological codes. However, error
correction also introduces a significant overhead in computation time, the
number of physical qubits, and the number of physical gates. While optimizing
fault-tolerant circuits to minimize this overhead is critical, the
computational complexity of such optimization problems remains unknown. This
ambiguity leaves room for doubt surrounding the most effective methods for
compiling fault-tolerant circuits for a large-scale quantum computer. In this
paper, we show that the optimization of a special subset of braided quantum
circuits is NP-hard by a polynomial-time reduction of the optimization problem
into a specific problem called Planar Rectilinear 3SAT.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00541'>Parameterized Complexity of Weighted Team Definability</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Juha Kontinen, Yasir Mahmood, Arne Meier, Heribert Vollmer</p><p>In this article, we study the complexity of weighted team definability for
logics with team semantics. This problem is a natural analogue of one of the
most studied problems in parameterized complexity, the notion of weighted
Fagin-definability, which is formulated in terms of satisfaction of first-order
formulas with free relation variables. We focus on the parameterized complexity
of weighted team definability for a fixed formula phi of central team-based
logics. Given a first-order structure A and the parameter value k as input, the
question is to determine whether A,T models phi for some team T of size k. We
show several results on the complexity of this problem for dependence,
independence, and inclusion logic formulas. Moreover, we also relate the
complexity of weighted team definability to the complexity classes in the
well-known W-hierarchy as well as paraNP.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kontinen_J/0/1/0/all/0/1">Juha Kontinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_Y/0/1/0/all/0/1">Yasir Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Meier_A/0/1/0/all/0/1">Arne Meier</a>, <a href="http://arxiv.org/find/cs/1/au:+Vollmer_H/0/1/0/all/0/1">Heribert Vollmer</a></p><p>In this article, we study the complexity of weighted team definability for
logics with team semantics. This problem is a natural analogue of one of the
most studied problems in parameterized complexity, the notion of weighted
Fagin-definability, which is formulated in terms of satisfaction of first-order
formulas with free relation variables. We focus on the parameterized complexity
of weighted team definability for a fixed formula phi of central team-based
logics. Given a first-order structure A and the parameter value k as input, the
question is to determine whether A,T models phi for some team T of size k. We
show several results on the complexity of this problem for dependence,
independence, and inclusion logic formulas. Moreover, we also relate the
complexity of weighted team definability to the complexity classes in the
well-known W-hierarchy as well as paraNP.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00573'>An automated, geometry-based method for the analysis of hippocampal thickness</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kersten Diers, Hannah Baumeister, Frank Jessen, Emrah D&#xfc;zel, David Berron, Martin Reuter</p><p>The hippocampus is one of the most studied neuroanatomical structures due to
its involvement in attention, learning, and memory as well as its atrophy in
ageing, neurological, and psychiatric diseases. Hippocampal shape changes,
however, are complex and cannot be fully characterized by a single summary
metric such as hippocampal volume as determined from MR images. In this work,
we propose an automated, geometry-based approach for the unfolding, point-wise
correspondence, and local analysis of hippocampal shape features such as
thickness and curvature. Starting from an automated segmentation of hippocampal
subfields, we create a 3D tetrahedral mesh model as well as a 3D intrinsic
coordinate system of the hippocampal body. From this coordinate system, we
derive local curvature and thickness estimates as well as a 2D sheet for
hippocampal unfolding. We evaluate the performance of our algorithm with a
series of experiments to quantify neurodegenerative changes in Mild Cognitive
Impairment and Alzheimer's disease dementia. We find that hippocampal thickness
estimates detect known differences between clinical groups and can determine
the location of these effects on the hippocampal sheet. Further, thickness
estimates improve classification of clinical groups and cognitively unimpaired
controls when added as an additional predictor. Comparable results are obtained
with different datasets and segmentation algorithms. Taken together, we
replicate canonical findings on hippocampal volume/shape changes in dementia,
extend them by gaining insight into their spatial localization on the
hippocampal sheet, and provide additional, complementary information beyond
traditional measures. We provide a new set of sensitive processing and analysis
tools for the analysis of hippocampal geometry that allows comparisons across
studies without relying on image registration or requiring manual intervention.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Diers_K/0/1/0/all/0/1">Kersten Diers</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumeister_H/0/1/0/all/0/1">Hannah Baumeister</a>, <a href="http://arxiv.org/find/cs/1/au:+Jessen_F/0/1/0/all/0/1">Frank Jessen</a>, <a href="http://arxiv.org/find/cs/1/au:+Duzel_E/0/1/0/all/0/1">Emrah D&#xfc;zel</a>, <a href="http://arxiv.org/find/cs/1/au:+Berron_D/0/1/0/all/0/1">David Berron</a>, <a href="http://arxiv.org/find/cs/1/au:+Reuter_M/0/1/0/all/0/1">Martin Reuter</a></p><p>The hippocampus is one of the most studied neuroanatomical structures due to
its involvement in attention, learning, and memory as well as its atrophy in
ageing, neurological, and psychiatric diseases. Hippocampal shape changes,
however, are complex and cannot be fully characterized by a single summary
metric such as hippocampal volume as determined from MR images. In this work,
we propose an automated, geometry-based approach for the unfolding, point-wise
correspondence, and local analysis of hippocampal shape features such as
thickness and curvature. Starting from an automated segmentation of hippocampal
subfields, we create a 3D tetrahedral mesh model as well as a 3D intrinsic
coordinate system of the hippocampal body. From this coordinate system, we
derive local curvature and thickness estimates as well as a 2D sheet for
hippocampal unfolding. We evaluate the performance of our algorithm with a
series of experiments to quantify neurodegenerative changes in Mild Cognitive
Impairment and Alzheimer's disease dementia. We find that hippocampal thickness
estimates detect known differences between clinical groups and can determine
the location of these effects on the hippocampal sheet. Further, thickness
estimates improve classification of clinical groups and cognitively unimpaired
controls when added as an additional predictor. Comparable results are obtained
with different datasets and segmentation algorithms. Taken together, we
replicate canonical findings on hippocampal volume/shape changes in dementia,
extend them by gaining insight into their spatial localization on the
hippocampal sheet, and provide additional, complementary information beyond
traditional measures. We provide a new set of sensitive processing and analysis
tools for the analysis of hippocampal geometry that allows comparisons across
studies without relying on image registration or requiring manual intervention.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
