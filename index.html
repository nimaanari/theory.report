<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-02-05T11:30:36Z">Sunday, February 05 2023, 11:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, February 05
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/008'>TR23-008 |  Limits of structures and Total NP Search Problems | 

	Ond?ej Ježil</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          For a class of finite graphs, we define a limit object relative to some computationally restricted class of functions. The properties of the limit object then reflect how a computationally restricted viewer &quot;sees&quot; a generic instance from the class. The construction uses Krají?ek&#39;s forcing with random variables [7]. We prove sufficient conditions for universal and existential sentences to be valid in the limit, provide several examples, and prove that such a limit object can then be expanded to a model of weak arithmetic. We then take the limit of all finite pointed paths to obtain a model of arithmetic where the problem OntoWeakPigeon is total but Leaf (the complete problem for $\textbf{PPA}$) is not. This can be viewed as a logical separation of the oracle classes of total NP search problems, which in our setting implies standard nonreducibility of Leaf to OntoWeakPigeon.
        
        </div>

        <div class='tr-article-summary'>
        
          
          For a class of finite graphs, we define a limit object relative to some computationally restricted class of functions. The properties of the limit object then reflect how a computationally restricted viewer &quot;sees&quot; a generic instance from the class. The construction uses Krají?ek&#39;s forcing with random variables [7]. We prove sufficient conditions for universal and existential sentences to be valid in the limit, provide several examples, and prove that such a limit object can then be expanded to a model of weak arithmetic. We then take the limit of all finite pointed paths to obtain a model of arithmetic where the problem OntoWeakPigeon is total but Leaf (the complete problem for $\textbf{PPA}$) is not. This can be viewed as a logical separation of the oracle classes of total NP search problems, which in our setting implies standard nonreducibility of Leaf to OntoWeakPigeon.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-05T08:30:13Z">Sunday, February 05 2023, 08:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, February 04
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://dstheory.wordpress.com/2023/02/04/thursday-feb-9th-2023-amit-chakrabarti-from-dartmouth-college/'>Thursday, Feb 9th, 2023 — Amit Chakrabarti from Dartmouth College</a></h3>
        <p class='tr-article-feed'>from <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next Foundations of Data Science virtual talk series on recent advances in adversarially robust streaming will take place on Thursday, February 9th at 2:00 PM Pacific Time (17:00 Eastern Time, 23:00 Central European Time, 22:00 UTC). Amit Chakrabarti from Dartmouth College will talk about “How to color your adversary&#8217;s graph” Details of the talkContinue reading "Thursday, Feb 9th, 2023 — Amit Chakrabarti from Dartmouth&#160;College"
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="has-text-align-justify">The next <a rel="noreferrer noopener" href="https://sites.google.com/view/dstheory/home" target="_blank">Foundations of Data Science</a> virtual talk series on recent advances in <em>adversarially robust streaming</em> will take place on <strong>Thursday, February 9th</strong> at <strong>2:00 PM Pacific Time</strong> (17:00 Eastern Time, 23:00 Central European Time, 22:00 UTC). <a href="http://www.cs.dartmouth.edu/~ac">Amit Chakrabarti</a> from<strong> Dartmouth College</strong> will talk about <em>“How to color your adversary&#8217;s graph”</em></p>



<p><a href="https://sites.google.com/view/dstheory">Details of the talk (Zoom link) are available here.</a></p>



<p class="has-text-align-justify">An n-vertex graph with maximum degree D is (D+1)-colorable: an almost trivial combinatorial result, with an equally simple greedy algorithm to produce a (D+1)-coloring. However, given a stream of edges of such a graph, can we maintain a valid (D+1)-coloring as the edges arrive, while using not much more than O(n) space? What if the edges are chosen by an adversary who can look at our current coloring and add additional edges to try to confound us? This is the newly-popular setting of adversarially robust streaming algorithms and this talk is about the coloring problem in this setting.</p>



<p class="has-text-align-justify">We obtain upper and lower bound results for this problem. In O(n polylog n) space, we can maintain an O(D^(5/2))-coloring of such an adversarial graph. On the other hand, every adversarially robust coloring algorithm under the same space limitation must spend Omega(D^2) colors. We in fact prove more general. results that trade off the space usage against the color budget.&nbsp; One interesting by-product of our work is that in combination with the celebrated Assadi-Chen-Khanna algorithm (SODA 2019), it provides the first separation between randomized and deterministic algorithms for the (ordinary, non-robust) streaming graph coloring problem.</p>



<p>Based on joint works [C.-Ghosh-Stoeckl] and [Assadi-C.-Ghosh-Stoeckl].</p>



<p>&nbsp;The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p>
<p class="authors">By dstheory</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-04T19:49:34Z">Saturday, February 04 2023, 19:49</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, February 03
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/03/postdoc-at-ist-austria-apply-by-march-15-2023/'>Postdoc at IST Austria (apply by March 15, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Postdoctorial positions at IST Austria are available funded by the ERC Advanced Grant &#8220;Modern Dynamic Data Structures, led by Prof. Monika Henzinger Website: ist.ac.at/en/job/postdoc-research-group-monika-henzinger/ Email: monika.henzinger@ista.ac.at
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Postdoctorial positions at IST Austria are available funded by the ERC Advanced Grant &#8220;Modern Dynamic Data Structures, led by Prof. Monika Henzinger</p>
<p>Website: <a href="https://ist.ac.at/en/job/postdoc-research-group-monika-henzinger/">https://ist.ac.at/en/job/postdoc-research-group-monika-henzinger/</a><br />
Email: monika.henzinger@ista.ac.at</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T12:26:50Z">Friday, February 03 2023, 12:26</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/007'>TR23-007 |  Extended Nullstellensatz proof systems | 

	Jan  Krajicek</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          For a finite set $\cal F$ of polynomials over a fixed finite prime field of size  $p$ containing all polynomials $x^2 - x$, a Nullstellensatz proof of the unsolvability of the system
$$
	f = 0\ ,\ \mbox{ all } f \in {\cal F}
$$
is a linear combination $\sum_{f \in {\cal F}} \ h_f \cdot f$ that equals to $1$ in the ring of polynomials. The measure of complexity of such a proof is its degree: $\max_f deg(h_f f)$.

We study the problem to establish degree lower bounds for some {\em extended} NS proof systems: these systems prove the unsolvability of $\cal F$ by proving the unsolvability of a bigger set ${\cal F}\cup {\cal E}$, where set $\cal E$ may use more variables $r$ and contains polynomials $r^p - r$ for them, and satisfies the following soundness condition:
 
-- Any $0,1$-assignment ${\overline a}$ to variables ${\overline x}$ can be appended by an assignment ${\overline b}$ to variables $\overline r$ such that for all $g \in {\cal E}$ it holds that $g(\overline a, \overline b) = 0$.

We define a notion of pseudo-solutions of $\cal F$ and prove that the existence of pseudo-solutions with suitable parameters implies lower bounds for two extended NS proof systems ENS and UENS defined in Buss et al. (1996/97). Further we give a combinatorial example of $\cal F$ and candidate pseudo-solutions based on the pigeonhole principle.
        
        </div>

        <div class='tr-article-summary'>
        
          
          For a finite set $\cal F$ of polynomials over a fixed finite prime field of size  $p$ containing all polynomials $x^2 - x$, a Nullstellensatz proof of the unsolvability of the system
$$
	f = 0\ ,\ \mbox{ all } f \in {\cal F}
$$
is a linear combination $\sum_{f \in {\cal F}} \ h_f \cdot f$ that equals to $1$ in the ring of polynomials. The measure of complexity of such a proof is its degree: $\max_f deg(h_f f)$.

We study the problem to establish degree lower bounds for some {\em extended} NS proof systems: these systems prove the unsolvability of $\cal F$ by proving the unsolvability of a bigger set ${\cal F}\cup {\cal E}$, where set $\cal E$ may use more variables $r$ and contains polynomials $r^p - r$ for them, and satisfies the following soundness condition:
 
-- Any $0,1$-assignment ${\overline a}$ to variables ${\overline x}$ can be appended by an assignment ${\overline b}$ to variables $\overline r$ such that for all $g \in {\cal E}$ it holds that $g(\overline a, \overline b) = 0$.

We define a notion of pseudo-solutions of $\cal F$ and prove that the existence of pseudo-solutions with suitable parameters implies lower bounds for two extended NS proof systems ENS and UENS defined in Buss et al. (1996/97). Further we give a combinatorial example of $\cal F$ and candidate pseudo-solutions based on the pigeonhole principle.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T08:33:12Z">Friday, February 03 2023, 08:33</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.01145'>This Game Is Not Going To Analyze Itself</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aviv Adler, Joshua Ani, Lily Chung, Michael Coulombe, Erik D. Demaine, Yevhenii Diomidov, Dylan Hendrickson, Jayson Lynch</p><p>We analyze the puzzle video game This Game Is Not Going To Load Itself, where
the player routes data packets of three different colors from given sources to
given sinks of the correct color. Given the sources, sinks, and some previously
placed arrow tiles, we prove that the game is in Sigma_2^P; in NP for sources
of equal period; NP-complete for three colors and six equal-period sources with
player input; and even without player input, simulating the game is both NP-
and coNP-hard for two colors and many sources with different periods. On the
other hand, we characterize which locations for three data sinks admit a
perfect placement of arrow tiles that guarantee correct routing no matter the
placement of the data sources, effectively solving most instances of the game
as it is normally played.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Adler_A/0/1/0/all/0/1">Aviv Adler</a>, <a href="http://arxiv.org/find/cs/1/au:+Ani_J/0/1/0/all/0/1">Joshua Ani</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_L/0/1/0/all/0/1">Lily Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Coulombe_M/0/1/0/all/0/1">Michael Coulombe</a>, <a href="http://arxiv.org/find/cs/1/au:+Demaine_E/0/1/0/all/0/1">Erik D. Demaine</a>, <a href="http://arxiv.org/find/cs/1/au:+Diomidov_Y/0/1/0/all/0/1">Yevhenii Diomidov</a>, <a href="http://arxiv.org/find/cs/1/au:+Hendrickson_D/0/1/0/all/0/1">Dylan Hendrickson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lynch_J/0/1/0/all/0/1">Jayson Lynch</a></p><p>We analyze the puzzle video game This Game Is Not Going To Load Itself, where
the player routes data packets of three different colors from given sources to
given sinks of the correct color. Given the sources, sinks, and some previously
placed arrow tiles, we prove that the game is in Sigma_2^P; in NP for sources
of equal period; NP-complete for three colors and six equal-period sources with
player input; and even without player input, simulating the game is both NP-
and coNP-hard for two colors and many sources with different periods. On the
other hand, we characterize which locations for three data sinks admit a
perfect placement of arrow tiles that guarantee correct routing no matter the
placement of the data sources, effectively solving most instances of the game
as it is normally played.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T01:30:00Z">Friday, February 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00724'>Order-Preserving Squares in Strings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pawe&#x142; Gawrychowski, Samah Ghazawi, Gad M. Landau</p><p>An order-preserving square in a string is a fragment of the form $uv$ where
$u\neq v$ and $u$ is order-isomorphic to $v$. We show that a string $w$ of
length $n$ over an alphabet of size $\sigma$ contains $\mathcal{O}(\sigma n)$
order-preserving squares that are distinct as words. This improves the upper
bound of $\mathcal{O}(\sigma^{2}n)$ by Kociumaka, Radoszewski, Rytter, and
Wale\'n [TCS 2016]. Further, for every $\sigma$ and $n$ we exhibit a string
with $\Omega(\sigma n)$ order-preserving squares that are distinct as words,
thus establishing that our upper bound is asymptotically tight. Finally, we
design an $\mathcal{O}(\sigma n)$ time algorithm that outputs all
order-preserving squares that occur in a given string and are distinct as
words. By our lower bound, this is optimal in the worst case.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gawrychowski_P/0/1/0/all/0/1">Pawe&#x142; Gawrychowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghazawi_S/0/1/0/all/0/1">Samah Ghazawi</a>, <a href="http://arxiv.org/find/cs/1/au:+Landau_G/0/1/0/all/0/1">Gad M. Landau</a></p><p>An order-preserving square in a string is a fragment of the form $uv$ where
$u\neq v$ and $u$ is order-isomorphic to $v$. We show that a string $w$ of
length $n$ over an alphabet of size $\sigma$ contains $\mathcal{O}(\sigma n)$
order-preserving squares that are distinct as words. This improves the upper
bound of $\mathcal{O}(\sigma^{2}n)$ by Kociumaka, Radoszewski, Rytter, and
Wale\'n [TCS 2016]. Further, for every $\sigma$ and $n$ we exhibit a string
with $\Omega(\sigma n)$ order-preserving squares that are distinct as words,
thus establishing that our upper bound is asymptotically tight. Finally, we
design an $\mathcal{O}(\sigma n)$ time algorithm that outputs all
order-preserving squares that occur in a given string and are distinct as
words. By our lower bound, this is optimal in the worst case.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T01:30:00Z">Friday, February 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00737'>A Universal Technique for Machine-Certified Proofs of Linearizable Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prasad Jayanti, Siddhartha Jayanti, Ugur Y. Yavuz, Lizzie Hernandez</p><p>Linearizability has been the long standing gold standard for consistency in
concurrent data structures. However, proofs of linearizability can be long and
intricate, hard to produce, and extremely time consuming even to verify. In
this work, we address this issue by introducing simple $universal$, $sound$,
and $complete$ proof methods for producing machine-verifiable proofs of
linearizability and its close cousin, strong linearizability. Universality
means that our method works for any object type; soundness means that an
algorithm can be proved correct by our method only if it is linearizable (resp.
strong linearizable); and completeness means that any linearizable (resp.
strong linearizable) implementation can be proved so using our method. We
demonstrate the simplicity and power of our method by producing proofs of
linearizability for the Herlihy-Wing queue and Jayanti's single-scanner
snapshot, as well as a proof of strong linearizability of the Jayanti-Tarjan
union-find object. All three of these proofs are machine-verified by TLAPS (the
Temporal Logic of Actions Proof System).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jayanti_P/0/1/0/all/0/1">Prasad Jayanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayanti_S/0/1/0/all/0/1">Siddhartha Jayanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Yavuz_U/0/1/0/all/0/1">Ugur Y. Yavuz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_L/0/1/0/all/0/1">Lizzie Hernandez</a></p><p>Linearizability has been the long standing gold standard for consistency in
concurrent data structures. However, proofs of linearizability can be long and
intricate, hard to produce, and extremely time consuming even to verify. In
this work, we address this issue by introducing simple $universal$, $sound$,
and $complete$ proof methods for producing machine-verifiable proofs of
linearizability and its close cousin, strong linearizability. Universality
means that our method works for any object type; soundness means that an
algorithm can be proved correct by our method only if it is linearizable (resp.
strong linearizable); and completeness means that any linearizable (resp.
strong linearizable) implementation can be proved so using our method. We
demonstrate the simplicity and power of our method by producing proofs of
linearizability for the Herlihy-Wing queue and Jayanti's single-scanner
snapshot, as well as a proof of strong linearizability of the Jayanti-Tarjan
union-find object. All three of these proofs are machine-verified by TLAPS (the
Temporal Logic of Actions Proof System).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T01:30:00Z">Friday, February 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00748'>Constant RMR Recoverable Mutex under System-wide Crashes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prasad Jayanti, Siddhartha Jayanti, Anup Joshi</p><p>We design two Recoverable Mutual Exclusion (RME) locks for the system-wide
crash model. Our first algorithm requires only $O(1)$ space per process, and
achieves $O(1)$ worst-case RMR complexity in the CC model. Our second algorithm
enhances the first algorithm to achieve (the same) $O(1)$ space per process and
$O(1)$ worst-case RMR complexity in both the CC and DSM models. Furthermore,
both algorithms allow dynamically created threads of arbitrary names to join
the protocol and access the locks. To our knowledge, these are the only RME
locks to achieve worst-case $O(1)$ RMR complexity assuming nothing more than
standard hardware support. In light of Chan and Woelfel's $\Omega(\log n /
\log\log n)$ worst-case RMR lower bound for RME in the individual crash model,
our results show a separation between the system-wide crash and individual
crash models in worst-case RMR complexity in both the CC and DSM models.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jayanti_P/0/1/0/all/0/1">Prasad Jayanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayanti_S/0/1/0/all/0/1">Siddhartha Jayanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1">Anup Joshi</a></p><p>We design two Recoverable Mutual Exclusion (RME) locks for the system-wide
crash model. Our first algorithm requires only $O(1)$ space per process, and
achieves $O(1)$ worst-case RMR complexity in the CC model. Our second algorithm
enhances the first algorithm to achieve (the same) $O(1)$ space per process and
$O(1)$ worst-case RMR complexity in both the CC and DSM models. Furthermore,
both algorithms allow dynamically created threads of arbitrary names to join
the protocol and access the locks. To our knowledge, these are the only RME
locks to achieve worst-case $O(1)$ RMR complexity assuming nothing more than
standard hardware support. In light of Chan and Woelfel's $\Omega(\log n /
\log\log n)$ worst-case RMR lower bound for RME in the individual crash model,
our results show a separation between the system-wide crash and individual
crash models in worst-case RMR complexity in both the CC and DSM models.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T01:30:00Z">Friday, February 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00928'>Rethinking Warm-Starts with Predictions: Learning Predictions Close to Sets of Optimal Solutions for Faster $\text{L}$-/$\text{L}^\natural$-Convex Function Minimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shinsaku Sakaue, Taihei Oki</p><p>An emerging line of work has shown that machine-learned predictions are
useful to warm-start algorithms for discrete optimization problems, such as
bipartite matching. Previous studies have shown time complexity bounds
proportional to some distance between a prediction and an optimal solution,
which we can approximately minimize by learning predictions from past optimal
solutions. However, such guarantees may not be meaningful when multiple optimal
solutions exist. Indeed, the dual problem of bipartite matching and, more
generally, $\text{L}$-/$\text{L}^\natural$-convex function minimization have
arbitrarily many optimal solutions, making such prediction-dependent bounds
arbitrarily large. To resolve this theoretically critical issue, we present a
new warm-start-with-prediction framework for
$\text{L}$-/$\text{L}^\natural$-convex function minimization. Our framework
offers time complexity bounds proportional to the distance between a prediction
and the set of all optimal solutions. The main technical difficulty lies in
learning predictions that are provably close to sets of all optimal solutions,
for which we present an online-gradient-descent-based method. We thus give the
first polynomial-time learnability of predictions that can provably warm-start
algorithms regardless of multiple optimal solutions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sakaue_S/0/1/0/all/0/1">Shinsaku Sakaue</a>, <a href="http://arxiv.org/find/cs/1/au:+Oki_T/0/1/0/all/0/1">Taihei Oki</a></p><p>An emerging line of work has shown that machine-learned predictions are
useful to warm-start algorithms for discrete optimization problems, such as
bipartite matching. Previous studies have shown time complexity bounds
proportional to some distance between a prediction and an optimal solution,
which we can approximately minimize by learning predictions from past optimal
solutions. However, such guarantees may not be meaningful when multiple optimal
solutions exist. Indeed, the dual problem of bipartite matching and, more
generally, $\text{L}$-/$\text{L}^\natural$-convex function minimization have
arbitrarily many optimal solutions, making such prediction-dependent bounds
arbitrarily large. To resolve this theoretically critical issue, we present a
new warm-start-with-prediction framework for
$\text{L}$-/$\text{L}^\natural$-convex function minimization. Our framework
offers time complexity bounds proportional to the distance between a prediction
and the set of all optimal solutions. The main technical difficulty lies in
learning predictions that are provably close to sets of all optimal solutions,
for which we present an online-gradient-descent-based method. We thus give the
first polynomial-time learnability of predictions that can provably warm-start
algorithms regardless of multiple optimal solutions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T01:30:00Z">Friday, February 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00985'>Speed-Oblivious Online Scheduling: Knowing (Precise) Speeds is not Necessary</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Lindermayr, Nicole Megow, Martin Rapp</p><p>We consider online scheduling on unrelated (heterogeneous) machines in a
speed-oblivious setting, where an algorithm is unaware of the exact
job-dependent processing speeds. We show strong impossibility results for
clairvoyant and non-clairvoyant algorithms and overcome them in models inspired
by practical settings: (i) we provide competitive learning-augmented
algorithms, assuming that (possibly erroneous) predictions on the speeds are
given, and (ii) we provide competitive algorithms for the speed-ordered model,
where a single global order of machines according to their unknown
job-dependent speeds is known. We prove strong theoretical guarantees and
evaluate our findings on a representative heterogeneous multi-core processor.
These seem to be the first empirical results for algorithms with predictions
that are performed in a non-synthetic environment on real hardware.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lindermayr_A/0/1/0/all/0/1">Alexander Lindermayr</a>, <a href="http://arxiv.org/find/cs/1/au:+Megow_N/0/1/0/all/0/1">Nicole Megow</a>, <a href="http://arxiv.org/find/cs/1/au:+Rapp_M/0/1/0/all/0/1">Martin Rapp</a></p><p>We consider online scheduling on unrelated (heterogeneous) machines in a
speed-oblivious setting, where an algorithm is unaware of the exact
job-dependent processing speeds. We show strong impossibility results for
clairvoyant and non-clairvoyant algorithms and overcome them in models inspired
by practical settings: (i) we provide competitive learning-augmented
algorithms, assuming that (possibly erroneous) predictions on the speeds are
given, and (ii) we provide competitive algorithms for the speed-ordered model,
where a single global order of machines according to their unknown
job-dependent speeds is known. We prove strong theoretical guarantees and
evaluate our findings on a representative heterogeneous multi-core processor.
These seem to be the first empirical results for algorithms with predictions
that are performed in a non-synthetic environment on real hardware.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-03T01:30:00Z">Friday, February 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, February 02
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/02/postdoc-at-centre-for-quantum-computer-science-university-of-latvia-apply-by-february-20-2023/'>Postdoc at Centre for Quantum Computer Science, University of Latvia (apply by February 20, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Applications are invited for a postdoctoral position at the Centre for Quantum Computer Science, University of Latvia (www.quantum.lu.lv), lead by prof. Andris Ambainis. The Centre is among the strongest European research groups in quantum algorithms and currently consists of 18 researchers (including postdocs and graduate students). Website: quantum.lu.lv/join-us/ Email: andris.ambainis@lu.lv
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Applications are invited for a postdoctoral position at the Centre for Quantum Computer Science, University of Latvia (<a href="https://www.quantum.lu.lv">https://www.quantum.lu.lv</a>), lead by prof. Andris Ambainis. The Centre is among the strongest European research groups in quantum algorithms and currently consists of 18 researchers (including postdocs and graduate students).</p>
<p>Website: <a href="https://quantum.lu.lv/join-us/">https://quantum.lu.lv/join-us/</a><br />
Email: andris.ambainis@lu.lv</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T22:21:11Z">Thursday, February 02 2023, 22:21</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://francisbach.com/non-convex-quadratic-problems/'>Non-convex quadratic optimization problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://francisbach.com'>Francis Bach</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Among continuous optimization problems, convex problems (with convex objectives and convex constraints) define a class that can be solved efficiently with a variety of algorithms and with arbitrary precision. This is not true more generally when the convexity assumption is removed (see this post). This of course does not mean that (1) nobody should attempt...
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="justify-text">Among continuous optimization problems, convex problems (with convex objectives and convex constraints) define a class that can be solved efficiently with a variety of algorithms and with arbitrary precision. This is not true more generally when the convexity assumption is removed (see <a href="https://francisbach.com/optimization-is-as-hard-as-approximation/">this post</a>). This of course does not mean that (1) nobody should attempt to solve high-dimensional non-convex problems (in fact, the spell checker run on this document was trained solving such a problem&#8230;), and that (2) no other problems have efficient solutions.</p>



<p class="justify-text">In this post, we will look at a classical class of continuous optimization problems that can be solved efficiently, namely quadratic optimization problems on the Euclidean sphere or ball. That is, we look at solving $$\tag{1} \min_{ \| x\| \leqslant 1} \ \frac{1}{2} x^\top A x \ &#8211; b^\top x, $$ and $$\tag{2} \min_{ \| x\| = 1} \ \frac{1}{2} x^\top A x \ &#8211; b^\top x,  $$ for \(\|x\|^2 = x^\top x\) the standard squared Euclidean norm.</p>



<p class="justify-text">The matrix \(A \in \mathbb{R}^{n \times n}\) is assumed only symmetric (no need to be positive semi-definite), and \(b \in \mathbb{R}^n\). Therefore, the objective may not be convex, and the constraint set (in the case of the sphere), is not convex either. We could replace the standard squared Euclidean norm \(x^\top x\) by any Mahanalobis squared norm \(x^\top B x\) for \(B\) positive-definite, but to keep it simple, let&#8217;s only consider \(B = I\).</p>



<p class="justify-text">Note that there are other continuous non-convex optimization problems that can be solved efficiently through a convex reformulation, such as the minimization of one-dimensional (trigonometric) polynomials, and more generally sum-of-squares problems (see <a href="https://francisbach.com/sums-of-squares-for-dummies/">this post</a>). If you are aware of many more beyond combinatorial optimization problems, please let me know.</p>



<p class="justify-text"><strong>Special case of eigenvalues.</strong> If \(b=0\) (no linear term), then the solution of Problem \((2)\) is the eigenvector associated with the smallest eigenvalue of \(A\), while the solution of Problem \((1)\) is the same eigenvector if the smallest eigenvalue of \(A\) is negative, and zero otherwise. This has a large number of applications, is the topic of tons of <a href="https://www.google.com/search?q=spectral+relaxation">&#8220;spectral relaxation&#8221; works</a>, and will not be the focus of this post.</p>



<h2>Applications</h2>



<p class="justify-text">Problems \((1)\) and \((2)\) appear in several areas and first appeared in [<a href="https://epubs.siam.org/doi/epdfplus/10.1137/0113073">2</a>] in 1965 (if you know of an earlier reference, please let me know). The three main occurrences that I am aware of are in <a href="https://en.wikipedia.org/wiki/Trust_region">trust-region methods</a>, constrained eigenvalue problems, and relaxation of binary optimization problems.</p>



<p class="justify-text"><strong>Trust-region methods.</strong> When minimizing a differentiable function \(f\) on \(\mathbb{R}^n\), the classical gradient descent iteration $$x^+ = x \, &#8211; \gamma f(x)$$ can be seen as the solution of $$\min_{y \in \mathbb{R}^n} \ f(x) + f'(x)^\top ( y\,  &#8211; x ) \mbox{ such that } \| y\,  &#8211; x\| \leqslant \delta,$$ for \(\delta = \gamma  \| f'(x)\|_2\). This corresponds to minimizing the first-order Taylor expansion in a ball centered at \(x\), and leads to the minimization of an affine function on an Euclidean ball. When using the second order model, we get to solve $$\min_{y \in \mathbb{R}^n} \ f(x) + f'(x)^\top ( y \, &#8211; x ) + \frac{1}{2} ( y\,  -x )^\top f^{\prime \prime}(x) ( y \, -x ) \mbox{ such that } \| y \, &#8211; x\| \leqslant \delta, $$ which can be cast as Problem \((1)\).</p>



<p class="justify-text">The intuitive idea is that the Taylor expansion is only local, so we optimize it locally, instead of globally, like the classical Newton method would do. Moreover, it is well-defined even for singular Hessians. See figure below and [4] for more details.</p>


<div class="wp-block-image justify-text">
<figure class="aligncenter size-full is-resized"><img src="https://francisbach.com/wp-content/uploads/2023/01/tr-2.png" alt="" class="wp-image-8723" width="779" height="280" srcset="https://francisbach.com/wp-content/uploads/2023/01/tr-2.png 2514w, https://francisbach.com/wp-content/uploads/2023/01/tr-2-300x108.png 300w, https://francisbach.com/wp-content/uploads/2023/01/tr-2-1024x369.png 1024w, https://francisbach.com/wp-content/uploads/2023/01/tr-2-768x277.png 768w, https://francisbach.com/wp-content/uploads/2023/01/tr-2-1536x554.png 1536w, https://francisbach.com/wp-content/uploads/2023/01/tr-2-2048x738.png 2048w, https://francisbach.com/wp-content/uploads/2023/01/tr-2-850x306.png 850w" sizes="(max-width: 779px) 100vw, 779px" /><figcaption>We consider two quadratic functions and we compare the minimization of their linear and quadratic Taylor expansions under a ball constraint with increasing radius. Left: convex function (hence the quadratic minimization ends up reaching the global minimum). Right: function with a saddle. Below, only the quadratic minimization path is shown for several starting points.</figcaption></figure></div>

<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img loading="lazy" src="https://francisbach.com/wp-content/uploads/2023/01/video_tr-1.gif" alt="" class="wp-image-8747" width="547" height="353"/></figure></div>


<p class="justify-text"><strong>Constrained eigenvalue problems.</strong> If we aim to minimize \(x^\top A x\) subject to \(x^\top x = 1\) and an affine constraint [<a href="https://www.sciencedirect.com/science/article/pii/0024379589904941/pdf?md5=754201682cef36aa80a3ef681fce6d62&amp;pid=1-s2.0-0024379589904941-main.pdf">3</a>], then, by writing the affine constraint as \(x = Cz+d\), we obtain the minimization of a quadratic-linear function subject to a quadratic-linear constraint, which we can rewrite in a form similar to Problem \((2)\).</p>



<p class="justify-text"><strong>Relaxation of binary optimization problems.</strong> When minimizing a linear-quadratic function on \(\{-1,1\}^n\), we can relax it by replacing the constraint \(x \in \{-1,1\}^n\) by \(x^\top x = n\).</p>



<h2>From local to global optimality conditions</h2>



<p class="justify-text">Let&#8217;s now look at optimality conditions from first principles (see [<a href="http://users.clas.ufl.edu/hager/papers/Regular/sphere.pdf">5</a>, <a href="https://epubs.siam.org/doi/epdf/10.1137/0719026">6</a>] for more details), before relating them to a broader discussion on tight semi-definite relaxations.</p>



<p class="justify-text"><strong>Existence of minimizers.</strong> Minimizers always exists for \(f(x) = \frac{1}{2} x^\top A x \ &#8211; b^\top x\) since the two sets \(\mathbb{S} = \{ x \in \mathbb{R}^n, x^\top x = 1\}\) and \(\mathbb{B} = \{ x \in \mathbb{R}^n, x^\top x \leqslant 1\}\) are compact. Therefore, the problems are well-formulated.</p>



<p class="justify-text"><strong>First-order necessary conditions on the sphere. </strong>We consider an optimal \(x \in \mathbb{S}\). For any \(y \in \mathbb{S}\) which is orthogonal to \(x\), and any \(\theta  \in \mathbb{R}\), we have: $$f( \cos \theta \cdot x + \sin \theta \cdot y) = f(x) + f'(x)^\top y \cdot \theta + o(\theta).$$ Thus, since \(\cos \theta \cdot x + \sin \theta \cdot y\) is always on \(\mathbb{S}\), we must have \(f'(x)^\top y=0\), and this holds for all \(y\) orthogonal to \(x\). Thus \(f'(x)\) has to be proportional to \(x\), that is, there exists \(\mu \in \mathbb{R}\) such that \(f'(x) + \mu x = 0\), that is, \((A + \mu I) x = b\).  </p>



<p class="justify-text"><strong>First-order necessary conditions on the ball.</strong> If \(x \in \mathbb{B}\) is optimal and in the interior, that is, \(x^\top x &lt; 1\), then we directly have \(f'(x) = 0\). If \(x \in \mathbb{S}\), it has to be optimal for the sphere, and thus there exists \(\mu \in \mathbb{R}\) such that \(f'(x) + \mu x = 0\).  By considering that \(g: t \mapsto f(t x)\) has to be minimized on \([0,1]\), for \(t=1\), we must have \(g'(1) \leqslant 0\), i.e., \(\mu = \, &#8211; f'(x) ^\top x \geqslant 0\). </p>



<p class="justify-text">In order to cover the interior case, we need to add the &#8220;complementary slackness&#8221; condition \(\mu ( 1 -x^\top x)=0\).</p>



<p class="justify-text"><strong>Obtaining necessary conditions from Lagrange duality.</strong> We can obtain the same first-order optimality conditions using <a href="https://en.wikipedia.org/wiki/Duality_(optimization)">Lagrange duality</a>, by adding a Lagrange multiplier \(\mu \in \mathbb{R}\) for the equality constraint \(x^\top x = 1\), or \(\mu \in \mathbb{R}_+\) for the inequality constraint \(x^\top x \leqslant 1\), and forming the Lagrangian $$\tag{3} \mathcal{L}(x,\mu) = \frac{1}{2} x^\top A x\, &#8211; b^\top x + \frac{1}{2} \mu ( x^\top x\, &#8211; 1).$$ A necessary condition is thus that the partial derivative with respect to \(x\) is zero for a certain \(\mu\), which is exactly the condition \(f'(x) + \mu x = 0\) above.</p>



<p class="justify-text"><strong>Second-order conditions on the sphere.</strong> Assuming that \(f'(x) + \mu x = 0\), with \(\mu\) potentially negative (i.e., the first-order optimality conditions are satisfied), we then have, for any \(y \in \mathbb{S}\), $$\begin{array}{rcl}f(y) &amp; = &amp; f(x) + f'(x)^\top(y-x) + \frac{1}{2}(x-y)^\top A ( x-y) \\ &amp; = &amp;  f(x) + \frac{1}{2}(x-y)^\top (  A + \mu I) ( x-y) + \frac{\mu}{2} ( x^\top x &#8211; y^\top y). \end{array}$$ Thus, if \(x\) is optimal, we must have \((x-y)^\top (  A + \mu I) ( x-y) \geqslant 0\) for all \(y \in \mathbb{S}\), which implies that \(A+ \mu I \succcurlyeq 0\). Note that our reasoning implies that the optimality condition, that is, existence of \(\mu \in \mathbb{R}\) such that $$\begin{array}{l} ( A+ \mu I) x = b \\ A+ \mu I \succcurlyeq 0 \\ x^\top x = 1 , \end{array} $$ is necessary and sufficient for the optimality of \(x\). The sufficiency can also be obtained through <a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions#:~:text=In%20mathematical%20optimization%2C%20the%20Karush,some%20regularity%20conditions%20are%20satisfied.">Karush-Kuhn-Tucker (KKT) conditions</a>, which apply regardless of convexity. This is one of few problems where strong duality holds for a non-convex optimization problems.</p>



<p class="justify-text"><strong>Second-order necessary condition on the ball.</strong> We also get the following necessary and sufficient condition, that is, the existence of \(\mu \in \mathbb{R}_+\) such that $$\begin{array}{l} ( A+ \mu I) x = b \\ A+ \mu I  \succcurlyeq 0 \\ x^\top x \leqslant 1 \\ \mu \, ( 1 \, &#8211; \, x^\top x) = 0.  \end{array}$$</p>



<p class="justify-text">In both cases, once \(\mu\) is known, we can recover the optimizers \(x\). We now focus on the sphere for simplicity.</p>



<h2>Equivalence to a one-dimensional problem</h2>



<p class="justify-text">We can define the function \((M,u) \mapsto u^\top M^{-1} u\) as the minimal \(t \in \mathbb{R}\) such that the matrix \(\bigg( \begin{array}{cc} \!M\!\! &amp; \!u\! \\[-.1cm] \!u^\top \!\! &amp; \! t \! \end{array} \bigg) \succcurlyeq 0\). It is thus jointly convex in \((M,u)\), is infinite when \(M\) is not positive-semidefinite (PSD). When \(M\) is PSD but not invertible, the function is finite if and only if \(u\) is in the column space of \(M\). We can define similarly \(u^\top M^{-2} u\).</p>



<p class="justify-text">We can now get the dual problem associated to the Lagrangian in \((3)\), by minimizing it with respect to \(x\), leading to $$\max_{\mu \in \mathbb{R}} \  &#8211; \frac{\mu}{2} \, &#8211; \frac{1}{2} b^\top ( A+\mu I)^{-1} b, $$ which is a concave maximization problem in one dimension (with the constraint that \(A + \mu I \succcurlyeq 0\)).</p>



<p class="justify-text">Thus, a simple algorithm for solving the problem is to solve this one-dimensional concave maximization problem. Once an eigenvalue decomposition \(A = \sum_{i=1}^n \! \lambda_i u_i u_i^\top\) has been obtained, we need to minimize $$ \tag{4} &#8211; \frac{\mu}{2} \, &#8211; \frac{1}{2} \sum_{i=1}^n \frac{ (b^\top u_i)^2}{\lambda_i + \mu}. $$</p>



<p class="justify-text">Assuming that \(\lambda_1 \geqslant \lambda_2 \geqslant \cdots \geqslant \lambda_n\), we have the constraint \(\lambda_n + \mu \geqslant 0\). We first need to check if \(\mu = \, &#8211; \lambda_n\) is the solution, which occurs when \(b^\top ( A+ \mu I)^{-2} b \leqslant 1\) (the problem is then called &#8220;degenerate&#8221;, and this can only happen if \(b\) in the eigensubspace of \(A\) associated with eigenvalue \(&#8211; \lambda_n\), which is rather uncommon). Otherwise, the minimum is attained at \(\mu &gt; -\lambda_n\) (note that since we have assumed \(b \neq 0\), the problem is strictly concave and thus has a unique maximizer in \(\mu\)). Moreover, \(\mu\) is characterized by the equation $$ \tag{5}   b^\top ( A+ \mu I)^{-2} b = 1,$$ which can be obtained directly from the optimality conditions.</p>



<p class="justify-text">This one-dimensional problem can be solved using Newton&#8217;s method [<a href="https://epubs.siam.org/doi/epdf/10.1137/0719026">6</a>, <a href="https://epubs.siam.org/doi/epdf/10.1137/S1052623494274374">7</a>] to estimate \(\mu\) given the eigendecomposition of \(A\). There are also cheaper less precise algorithms that do not require a full eigendecomposition. We will also see below a surprising reformulation as a simple eigenvalue problem.</p>



<p class="justify-text"><strong>Other &#8220;secular&#8221; equations.</strong> Equation \((5)\) is often referred to a <a href="https://en.wikipedia.org/wiki/Characteristic_polynomial">secular equation</a>. There are other types of similar equations, in particular for rank-one perturbations of the symmetric eigenvalue problem [<a href="https://link.springer.com/content/pdf/10.1007/BF01396012.pdf?pdf=button">8</a>, <a href="https://epubs.siam.org/doi/epdf/10.1137/S089547989223924X">9</a>].</p>



<h2>Semi-definite relaxations</h2>



<p class="justify-text">We can now give a more modern take on the quadratic maximization problem on the sphere, using <a href="https://en.wikipedia.org/wiki/Semidefinite_programming">semi-definite programming</a>. We can first rewrite the objective function in Equation \((1)\) as $$f(x) = \frac{1}{2}x^\top A x \, &#8211; b^\top x = \frac{1}{2} {\rm tr}(AX) \, &#8211; b^\top x, $$ with \(X = xx^\top\). We now have a linear objective in \((X,x)\). Moreover, the matrix \(X\) satisfies the convex constraints $$ X \succcurlyeq xx^\top \Leftrightarrow \left( \begin{array}{cc} \!X\!\! &amp; \!x\! \\[-.1cm] \!x^\top \!\!&amp;\!  1\!  \end{array} \right) \succcurlyeq 0, $$ and \({\rm tr}(X) = x^\top x = 1\). However the rank-one constraint is not convex. </p>



<p class="justify-text">A classical tool in optimization is to remove the rank-one constraint, and only obtain a lower bound (a so-called &#8220;relaxation&#8221;), with the following optimization problem: $$\tag{6} \min_{ X, x} \frac{1}{2} {\rm tr}(AX)-b^\top x \mbox{ such that } \left( \begin{array}{cc} \!X\!\! &amp; \!x\! \\[-.1cm] \!x^\top \!\!&amp;\!  1\!  \end{array} \right)  \succcurlyeq 0 \mbox{ and } {\rm tr}(X)=1. $$ One can check that the dual problem is exactly Equation \((4)\), and thus the relaxation is here tight. Moreover, the SDP formulation can be used to derive algorithms that do not need a full eigenvalue decomposition [<a href="https://link.springer.com/content/pdf/10.1007/BF02614438.pdf?pdf=button">12</a>].</p>



<p class="justify-text"><strong>Semi-definite relaxation of QCQP&#8217;s.</strong> Problems \((1)\) and \((2)\) are in fact instances of <a href="https://en.wikipedia.org/wiki/Quadratically_constrained_quadratic_program">quadratically constrained quadratic programming</a> problems, and the problem \((6)\) is the usual semi-definite relaxation. It turns out that with a single constraint, such relaxations are always tight, owing to the <a href="https://en.wikipedia.org/wiki/S-procedure">S-lemma</a> [<a href="https://epubs.siam.org/doi/epdf/10.1137/S003614450444614X">10</a>] (see a nice derivation in Boyd and Vandenberghe&#8217;s book [<a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">11</a>, Appendix B.1]).</p>



<p class="justify-text"><strong>Tight <span style="font-size: revert; color: initial; font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen-Sans, Ubuntu, Cantarell, &quot;Helvetica Neue&quot;, sans-serif;">sum-of-squares relaxation.</span></strong> Yet another reformulation is through sum-of-squares (see an earlier <a href="https://francisbach.com/finding-global-minima-with-kernel-approximations/">post</a>), where we consider the feature vector \(\varphi(x) = {x \choose 1}\) and represent non-negative functions as quadratic forms \(x \mapsto \varphi(x)^\top B \varphi(x)\). The problem in \((2)\) can then be relaxed as $$\max_{c \in \mathbb{R}, \ B \succcurlyeq 0} c \ \mbox{ such that } \ f(x) \, &#8211; c = \varphi(x)^\top B \varphi(x),$$ which is exactly the tight SDP relaxation above.</p>



<p class="justify-text"><strong>Having fun with adding affine constraints. </strong>Recently I had to look at Problem \((2)\) with an extra affine constraint, which I will take for simplicity of the form \(c^\top x = 1\) (for a vector \(c \in \mathbb{R}^n\) such that \(\|c\| &gt; 1\) to avoid a trivial problem). By projecting on the subspace orthogonal to \(c \in \mathbb{R}^n\), we obtain again a quadratic minimization problem, this time on a Euclidean sphere embedded in a space of dimension \(n-1\). Therefore, we can apply the above techniques on the reduced problem. However, I did not want to do that and wanted keep the original formulation on \(\mathbb{R}^n\), and then tried to use duality to solve it. Two natural possibilities emerge here.</p>



<p class="justify-text">In order to solve it, we could first imagine using Lagrange duality, with a Lagrange multiplier \(\mu\) for the constraint \(x^\top x = 1\) (this worked exactly without the extra affine constraint), and now an extra Lagrange multiplier \(\nu\) for the constraint \(c^\top x = 1\). This leads to the Lagrangian $$ \mathcal{L}(x,\mu,\nu) = \frac{1}{2} x^\top A x\, &#8211; b^\top x + \frac{1}{2} \mu ( x^\top x\, &#8211; 1) + \nu( c^\top x -1),$$ and thus, after a short calculation, the dual problem $$\max_{\mu,\nu \in \mathbb{R}} \ -\frac{\mu}{2} \, &#8211; \nu   \, &#8211; \frac{1}{2} (b \, &#8211; \nu c)^\top ( A + \mu I)^{-1} (b \, &#8211; \nu c).$$ Another Lagrangian can be obtained with the equivalent constraint \((c^\top x\, &#8211; 1)^2 = 0\), leading to a new Lagrangian $$ \mathcal{L}'(x,\mu,\nu&#8217;) = \frac{1}{2} x^\top A  x\, -b^\top x + \frac{1}{2} \mu ( x^\top x\, &#8211; 1) + \frac{1}{2} \nu&#8217;  (c^\top x \, &#8211; 1)^2,$$ and then the dual problem $$\max_{\mu,\nu&#8217; \in \mathbb{R}} \ -\frac{\mu}{2} \, -\frac{\nu&#8217;}{2} \, &#8211; \frac{1}{2} (b+\nu&#8217; c)^\top ( A +  \nu&#8217; cc^\top  +  \mu I)^{-1} (b+\nu&#8217; c).$$ Are they both tight? Make up your own mind and see the bottom of the post for the answer.</p>



<h2>Amazing eigenvalue reformulations</h2>



<p class="justify-text">The Newton method to solve the one-dimensional problem is efficient, but requires some safeguards to work properly, and a full eigenvalue decomposition. It turns out that one can obtain <em>exact</em> reformulations as eigenvalue problems <em>for a single eigenvalue</em>, for which efficient <a href="https://en.wikipedia.org/wiki/ARPACK">packages</a> exist.</p>



<p class="justify-text">From [<a href="https://reader.elsevier.com/reader/sd/pii/0024379589904941?token=5ED11F6E1B740CDF399B40623394985F3CDDA6BEF749F490CA64773677A63CBDE4C213284E03445941BCF501D0C12336&amp;originRegion=eu-west-1&amp;originCreation=20230128095330">3</a>], for the optimization on the sphere, we can obtain the optimal \(\mu\) from the largest real eigenvalue of the following non symmetric matrix: $$\left( \begin{array}{cc} \!-A\!  &amp; \!\! I\!  \\[-.1cm]   \! bb^\top \!&amp; \!\! -A\!  \end{array} \right).$$ Indeed, one can check that, in the non-degenerate case, given the optimal \((x,\mu)\), then \(y = \left( \begin{array}{c} \!(A+\mu I)^{-1} x \!    \\[-.1cm]  x  \end{array} \right)\) is an eigenvector of the \(2n \times 2n\) matrix above, with eigenvalue \(\mu\).</p>



<p class="justify-text">This leads to two lines of code to solve the problem, at least for the non-degenerate case! See more details in [<a href="https://reader.elsevier.com/reader/sd/pii/0024379589904941?token=5ED11F6E1B740CDF399B40623394985F3CDDA6BEF749F490CA64773677A63CBDE4C213284E03445941BCF501D0C12336&amp;originRegion=eu-west-1&amp;originCreation=20230128095330">3</a>, <a href="https://epubs.siam.org/doi/epdf/10.1137/16M1058200">14</a>], in particular, to deal with the degenerate case, often called the &#8220;hard case&#8221;. See the code snippets in Matlab, Julia, and Python.</p>



<figure class="wp-block-table"><table><tbody><tr><td>Matlab</td><td><code>[y,mu] = eigs([-A, eye(n); b*b', -A],1,'largestreal');&nbsp;<br>x&nbsp;= y(n+1:2*n) / (b'*y(1:n));&nbsp;<br></code>or <code>x = sign(b'*y(1:n)) * y(n+1:2*n) / norm(y(n+1:2*n))</code>;</td></tr><tr><td>Julia</td><td><code>E = eigs([-A I(n) ; b*b' -A ], nev=1 , which=:LR )<br>y, μ = E[2][:, 1], E[1][1]<br>x = y[n+1:2n] ./ (b' * y[1:n])<br></code>or <code>x = sign.(b' * y[1:n]) .* y[n+1:2n] / norm(y[n+1:2*n])</code></td></tr><tr><td>Python</td><td><code>M = np.block([[-A, np.eye(n)], [np.outer(b,b), -A]])<br>mu, y = scipy.sparse.linalg.eigs(M, k=1, which='LR', return_eigenvectors=True)<br>x = y[n:2*n]/(np.dot(b,y[:n]))&nbsp;<br></code>or <code>x&nbsp;= np.sign(np.dot(b,y[:n]))*y[n:2*n]/np.linalg.norm(y[n:2*n])</code></td></tr></tbody></table></figure>



<p class="justify-text"><strong>Symmetric generalized eigenproblems. </strong>If you prefer symmetric matrices, one can obtain a similar result with the generalized eigenvector of the two matrices $$\left( \begin{array}{cc} \!I\!\!  &amp; \!\!-A\! \\ \!-A\!\! &amp; \! bb^\top\! \end{array} \right) \ \mbox{ and }   \  \left( \begin{array}{cc} \! 0  \! &amp; \! \! I \\[-.1cm] I \!\! &amp; \!\! 0   \end{array} \right).$$ If you want to avoid forming a potentially dense matrix \(bb^\top\), you and use instead the matrices $$\left( \begin{array}{ccc}  \!-1\!  &amp; \! 0\! &amp; \! b^\top \! \\[-1.cm] \!0\! &amp;\!  I \!&amp;\! -A \! \\[-.1cm]\! b \!&amp;\! -A \!&amp; \!0\! \end{array} \right) \  \mbox{ and } \  \left( \begin{array}{ccc} \! 0\! &amp;\! 0 \!&amp; \! 0\! \\[-.1cm]\! 0 \! &amp; \! 0 \!&amp;\! I \! \\[-.1cm] \! 0 \! &amp;\! I \! &amp;\! 0 \!  \end{array} \right).$$ See all details in [<a href="https://epubs.siam.org/doi/epdf/10.1137/16M1058200">14</a>]. Note that beyond the two-line code above that lead to precise solutions, more efficient algorithms exist that lead to approximate solutions [<a href="https://link.springer.com/content/pdf/10.1007/s10107-015-0933-y.pdf?pdf=button">14</a>, <a href="https://epubs.siam.org/doi/epdf/10.1137/16M1150281">15</a>].</p>



<h2>Conclusion</h2>



<p class="justify-text">In this blog post, I described one of the few non-convex problems where strong duality holds. There are many other instances within combinatorial optimization (that is, with variables in \(\{0,1\}^n\) or \(\{-1,1\}^n\)), in particular related to <a href="https://en.wikipedia.org/wiki/Submodular_set_function">submodularity</a>. I will hopefully cover these in future posts. </p>



<p class="justify-text"><strong>Acknowledgements.</strong> I would like to thank Alessandro Rudi, Gaspard Beugnot, and ChatGPT for helping with the code snippets.</p>



<h2>References</h2>



<p class="justify-text">[2] George E. Forsythe, and Gene H. Golub. <a href="https://epubs.siam.org/doi/epdfplus/10.1137/0113073">On the stationary values of a second-degree polynomial on the unit sphere</a>.&nbsp;<em>Journal of the Society for Industrial and Applied Mathematics</em>,&nbsp;13(4): 1050-1068, 1965.[3] Walter Gander, Gene H. Golub, and Urs Von Matt. <a href="https://www.sciencedirect.com/science/article/pii/0024379589904941/pdf?md5=754201682cef36aa80a3ef681fce6d62&amp;pid=1-s2.0-0024379589904941-main.pdf">A constrained eigenvalue problem</a>.&nbsp;<em>Linear Algebra and its applications</em>&nbsp;114: 815-839, 1989.<br>[4] Andrew R. Conn, Nicholas I. M. Gould, and Philippe L. Toint.&nbsp;<em>Trust region methods</em>. Society for Industrial and Applied Mathematics, 2000.<br>[5] William W. Hager. <a href="http://users.clas.ufl.edu/hager/papers/Regular/sphere.pdf">Minimizing a quadratic over a sphere</a>.&nbsp;<em>SIAM Journal on Optimization</em>,&nbsp;12(1):188-208, 2001.<br>[6] Danny C. Sorensen. <a href="https://epubs.siam.org/doi/epdf/10.1137/0719026">Newton’s method with a model trust region modification</a>. <em>SIAM Journal on Numerical Analysis</em>,&nbsp;19(2):409-426, 1982.<br>[7] Danny C. Sorensen. <a href="https://epubs.siam.org/doi/epdf/10.1137/S1052623494274374">Minimization of a large-scale quadratic function subject to a spherical constraint</a>.&nbsp;<em>SIAM Journal on Optimization</em>,&nbsp;7(1):141-161, 1997.<br>[8] James R. Bunch, Christopher P. Nielsen, Danny C. Sorensen. <a href="https://link.springer.com/content/pdf/10.1007/BF01396012.pdf?pdf=button">Rank-one modification of the symmetric eigenproblem</a>.&nbsp;<em>Numerische Mathematik</em>,&nbsp;31(1):31-48, 1978.<br>[9] Ming Gu, Stanley C. Eisenstat. <a href="https://epubs.siam.org/doi/epdf/10.1137/S089547989223924X">A stable and efficient algorithm for the rank-one modification of the symmetric eigenproblem</a>.&nbsp;<em>SIAM Journal on Matrix Analysis and Applications</em>&nbsp;,15(4):1266-1276, 1994.<br>[10] Imre Pólik, Tamás Terlaky. <a href="https://epubs.siam.org/doi/epdf/10.1137/S003614450444614X">A survey of the S-lemma</a>.&nbsp;<em>SIAM Review</em>,&nbsp;49(3):371-418, 2007.<br>[11] Stephen P. Boyd, Lieven Vandenberghe.&nbsp;<em><a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">Convex Optimization</a></em>. Cambridge University Press, 2004.<br>[12] Franz Rendl, Henry Wolkowicz. <a href="https://link.springer.com/content/pdf/10.1007/BF02614438.pdf?pdf=button">A semidefinite framework for trust region subproblems with applications to large scale minimization</a>.&nbsp;<em>Mathematical Programming</em>,&nbsp;77(1):273-299, 1997.<br>[13] Satoru Adachi, Satoru Iwata, Yuji Nakatsukasa, Akiko Takeda. <a href="https://epubs.siam.org/doi/epdf/10.1137/16M1058200">Solving the trust-region subproblem by a generalized eigenvalue problem</a>.&nbsp;<em>SIAM Journal on Optimization</em>,&nbsp;<em>27</em>(1):269-291, 2017.<br>[14] Elad Hazan, Tomer Koren. <a href="https://link.springer.com/content/pdf/10.1007/s10107-015-0933-y.pdf?pdf=button">A linear-time algorithm for trust region problems</a>.&nbsp;<em>Mathematical Programming</em>,&nbsp;158(1-2):363-381, 2016.<br>[15] Amir Beck, Yakov Vaisbourd. <a href="https://epubs.siam.org/doi/epdf/10.1137/16M1150281">Globally solving the trust region subproblem using simple first-order methods</a>.&nbsp;<em>SIAM Journal on Optimization</em>,&nbsp;28(3):1951-1967, 2018.</p>



<h2>Having fun with affine constraints</h2>



<p class="justify-text">Let&#8217;s know look at the solution! The second relaxation is tight, while the first is not. To prove that we have a non-tight solution for the first relaxation, we can simply find a counter-example from random matrices in dimension \(n = 2\). For example, for $$A = \left( \begin{array}{cc} \!3\! &amp;\! 0\! \\[-.1cm] \! 0\! &amp; \!-2 \!  \end{array} \right) , \ \ b = \left( \begin{array}{c} \! 0\! \\[-.1cm] \!-1 \! \end{array} \right), \mbox{ and } \ c = \left( \begin{array}{c} \! 0\! \\[-.1cm] \!2 \! \end{array} \right),$$ a minimizer is \( x =  \left( \begin{array}{c}\! \sqrt{3}/2\! \\[-.1cm] \! 1/2 \! \end{array} \right)\), with optimal value \(11/8\), while the non-tight relaxation leads to a value of \(-1/2\). </p>



<p class="justify-text">To show the tightness of the second relaxation, we first notice that the convex problem is equivalent to the following SDP relaxation:  $$\min_{ X, x} \frac{1}{2} {\rm tr}(AX)-b^\top x \mbox{ such that } \left( \begin{array}{cc} \!X\!\! &amp; \!x\! \\[-.1cm] \!x^\top \!\!&amp;\!  1\!  \end{array} \right) \succcurlyeq 0, {\rm tr}(X)=1, \mbox{ and } {\rm tr}(cc^\top X)\,  &#8211; 2 t c^\top x + t^2 = 0. $$ Given the PSD constraint and the fact that $${\rm tr}(cc^\top X)\,  &#8211; 2 t c^\top x + t^2 = {\rm tr} \left( \begin{array}{cc} \!X\!\! &amp; \!x\! \\[-.1cm] \!x^\top \!\!&amp;\!  1\!  \end{array} \right)\left( \begin{array}{cc} \! cc^\top \! &amp; \! -tc \! \\[-.1cm] \!-tc^\top \! &amp; \! t^2 \! \end{array} \right),$$ the new constraint implies that $$ \left( \begin{array}{cc} \!X\!\! &amp; \!x\! \\[-.1cm] \!x^\top \!\!&amp;\!  1\!  \end{array} \right) \left( \begin{array}{c} \!c\!  \\[-.1cm] \!-t \!  \end{array} \right)= 0, $$ that is, \(Xc = t x\) and \(c^\top x = t\). One can then check that these constraints are exactly equivalent to a projection of the problem in to a space of dimension \(n-1\). The incorrect relaxation only has \(c^\top x = t\), which is not enough. It took me a while to realize it&#8230;</p>
<p class="authors">By Francis Bach</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T14:46:35Z">Thursday, February 02 2023, 14:46</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/responsibility.html'>Responsibility</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Nature laid out their ground rules for large language models like ChatGPT including</p><p></p><blockquote><p>No LLM tool will be accepted as a credited author on a research paper. That is because any attribution of authorship carries with it accountability for the work, and AI tools cannot take such responsibility.</p></blockquote><p>Let's focus on the last word "responsibility". What does that mean for an author? It means we can hold an author, or set of authors, responsible for any issues in the paper such as</p><p></p><ul><li>The proofs, calculations, code, formulas, measurements, statistics, and other details of the research.</li><li>Any interpretation or conclusions made in the article</li><li>Properly citing related work, especially work that calls into question the novelty of this research</li><li>The article does not contain text identical or very similar to previous work.</li><li>Anything else described in the article.</li></ul>The authors should take reasonable measures to ensure that a paper is free from any issues above. Nobody is perfect and if you make a mistake in a paper, you should, as with all mistakes, take responsibility and acknowledge the problems, do everything you can to rectify the issues, such as publishing a corrigendum if needed, and work to ensure you won't make similar mistakes in the future.<br>Mistakes can arise outside of an author's actions. Perhaps a computer chip makes faulty calculations, you relied on a faulty theorem in another paper, your main result appeared in a paper fifteen years ago in an obscure journal, a LaTeX package for the journal created some mistakes in the formulas or a student who helped with the research or exposition took a lazy way out, or you put too much trust in AI generative text. Nevertheless the responsibility remains with the authors.&nbsp;<br>Could an AI ever take responsibility for an academic paper? Would a toaster ever take responsibility for burning my breakfast?<br><br>&nbsp;<p></p><p></p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Nature <a href="https://www.nature.com/articles/d41586-023-00191-1">laid out their ground rules</a> for large language models like ChatGPT including</p><p></p><blockquote><p>No LLM tool will be accepted as a credited author on a research paper. That is because any attribution of authorship carries with it accountability for the work, and AI tools cannot take such responsibility.</p></blockquote><p>Let's focus on the last word "responsibility". What does that mean for an author? It means we can hold an author, or set of authors, responsible for any issues in the paper such as</p><p></p><ul style="text-align: left;"><li>The proofs, calculations, code, formulas, measurements, statistics, and other details of the research.</li><li>Any interpretation or conclusions made in the article</li><li>Properly citing related work, especially work that calls into question the novelty of this research</li><li>The article does not contain text identical or very similar to previous work.</li><li>Anything else described in the article.</li></ul><div>The authors should take reasonable measures to ensure that a paper is free from any issues above. Nobody is perfect and if you make a mistake in a paper, you should, as with all mistakes, take responsibility and acknowledge the problems, do everything you can to rectify the issues, such as publishing a corrigendum if needed, and work to ensure you won't make similar mistakes in the future.</div><div><br /></div><div>Mistakes can arise outside of an author's actions. Perhaps a computer chip <a href="https://en.wikipedia.org/wiki/Pentium_FDIV_bug">makes faulty calculations</a>, you relied on a faulty theorem in another paper, your main result appeared in a paper fifteen years ago in an obscure journal, a LaTeX package for the journal created some mistakes in the formulas or a student who helped with the research or exposition took a lazy way out, or you put too much trust in AI generative text. Nevertheless the responsibility remains with the authors.&nbsp;</div><div><br /></div><div>Could an AI ever take responsibility for an academic paper? Would a toaster ever take responsibility for burning my breakfast?</div><div><br /></div><div><br /></div><div>&nbsp;</div><p></p><p></p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T14:39:00Z">Thursday, February 02 2023, 14:39</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/02/assistant-associate-professor-at-ecole-polytechnique-institut-polytechnique-de-paris-apply-by-march-15-2023/'>Assistant/Associate Professor at Ecole polytechnique, Institut Polytechnique de Paris (apply by March 15, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Ecole polytechnique, leading engineering school in France, member of the Institut Polytechnique de Paris, welcomes outstanding applications for one assistant Monge Professor in Computer Science, specialty &#8220;Foundations of Computer Science&#8221;, tenure track teaching/research position. Website: portail.polytechnique.edu/informatique/en/recruitment2023 Email: samuel.mimram@polytechnique.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Ecole polytechnique, leading engineering school in France, member of the<br />
Institut Polytechnique de Paris, welcomes outstanding applications for one assistant Monge Professor in Computer Science, specialty &#8220;Foundations of Computer Science&#8221;, tenure track teaching/research position.</p>
<p>Website: <a href="https://portail.polytechnique.edu/informatique/en/recruitment2023">https://portail.polytechnique.edu/informatique/en/recruitment2023</a><br />
Email: samuel.mimram@polytechnique.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T13:54:05Z">Thursday, February 02 2023, 13:54</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/02/02/mathematics-of-the-impossible-computational-complexity-chapter-3-the-grand-challenge/'>Mathematics of the impossible: Computational Complexity,  Chapter 3: The grand challenge</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          All posts in this series. A PDF version of this post will be published with a delay, but if you&#8217;d like to have it soon let me know. Contents 1 The grand challenge 1.1 Information bottleneck: Palindromes requires quadratic time on TMs 1.2 Counting: impossibility results for non-explicit functions 1.3 Diagonalization: Enumerating machines 1.3.1 1.4 [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><a href="https://emanueleviola.wordpress.com/tag/moti/">All posts in this series.</a><br />
A PDF version of this post will be published with a delay, but if you&#8217;d like to have it soon let me know.</p>
<hr />
<p><!--?xml version="1.0" encoding="iso-8859-1" ?--> <!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd--> <!-- html,xhtml,-css,NoFonts --></p>
<h2 class="likechapterHead"><a id="x1-1000"></a>Contents</h2>
<div class="tableofcontents"><span class="chapterToc">1 <a id="QQ2-1-2" href="#x1-20001">The grand challenge</a></span><br />
<span class="sectionToc">1.1 <a id="QQ2-1-3" href="#x1-30001.1">Information bottleneck: Palindromes requires quadratic time on TMs</a></span><br />
<span class="sectionToc">1.2 <a id="QQ2-1-4" href="#x1-40001.2">Counting: impossibility results for non-explicit functions</a></span><br />
<span class="sectionToc">1.3 <a id="QQ2-1-5" href="#x1-50001.3">Diagonalization: Enumerating machines</a></span><br />
<span class="subsectionToc">1.3.1 <a id="QQ2-1-6" href="#x1-60001.3.1"><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28o%28n+%5Clog+n%29%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28o%28n+%5Clog+n%29%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28o%28n+%5Clog+n%29%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(o(n &#92;log n))=&#92;text {TM-Time}(n)" class="latex" /></a></span><br />
<span class="sectionToc">1.4 <a id="QQ2-1-7" href="#x1-70001.4">Circuits</a></span><br />
<span class="subsectionToc">1.4.1 <a id="QQ2-1-8" href="#x1-80001.4.1">The circuit won’t fit in the universe: Non-asymptotic, cosmological results</a></span><br />
<span class="sectionToc">1.5 <a id="QQ2-1-9" href="#x1-90001.5">Problems</a></span></div>
<div id="verbatim-1" class="verbatim"></div>
<div></div>
<p style="text-align: justify"><img data-attachment-id="1160" data-permalink="https://emanueleviola.wordpress.com/2023/02/02/mathematics-of-the-impossible-computational-complexity-chapter-3-the-grand-challenge/phdcomics/" data-orig-file="https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png" data-orig-size="600,260" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PhDComics" data-image-description="" data-image-caption="" data-medium-file="https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png?w=300" data-large-file="https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png?w=600" class="alignnone size-full wp-image-1160" src="https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png?w=640" alt="PhDComics" srcset="https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png 600w, https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png?w=150 150w, https://emanueleviola.files.wordpress.com/2023/02/phdcomics.png?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"   /></p>
<p style="text-align: justify">As mentioned in Chapter ??, our ability to prove impossibility results related to efficient computation appears very limited. We can now express this situation more precisely with the models we’ve introduced since then.</p>
<div style="text-align: center">
<p style="text-align: justify">
<div class="minipage">It is consistent with our knowledge that any problem in a standard algorithm textbook can be solved</p>
<ol class="enumerate1">
<li id="x1-2002x1" class="enumerate">in Time <img src="https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn^{2}" class="latex" /> on a TM, and</li>
<li id="x1-2004x2" class="enumerate">in Time <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" /> on a 2-TM, and</li>
<li id="x1-2006x3" class="enumerate">by circuits of size <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" />.</li>
</ol>
</div>
</div>
<p style="text-align: justify">Note that 2. implies 1. by Theorem ??.</p>
<p style="text-align: justify">In this chapter we begin to present several impossibility results, covering a variety of techniques which will be used later as well. As hinted above, they appear somewhat weak. However, jumping ahead, there is a flip side to all of this:</p>
<ol class="enumerate1">
<li id="x1-2008x1" class="enumerate">At times, contrary to our intuition, stronger impossibility results are actually <em>false</em>. One example appears in Chapter ??. A list will be given later.</li>
<li id="x1-2010x2" class="enumerate">Many times, the impossibility results that we can prove turn out to be, surprisingly, just “short” of proving major results. Here by “major result” I mean a result that would be phenomenal and that was in focus long before the connection was established. We will see several examples of this (section º??, section º??).</li>
<li id="x1-2012x3" class="enumerate">Yet other times, one can identify broad classes of proof techniques, and argue that impossibility results can’t be proved with them (section º??).</li>
</ol>
<p style="text-align: justify">Given this situation, I don’t subscribe to the general belief that stronger impossibility results are true and we just can’t prove them.</p>
<h3 class="sectionHead"><span class="titlemark">1.1 </span> <a id="x1-30001.1"></a>Information bottleneck: Palindromes requires quadratic time on TMs</h3>
<p style="text-align: justify">Intuitively, the weakness of TMs is the bottleneck of passing information from one end of the tape to the other. We now show how to formalize this and use it show that deciding if a string is a palindrome requires <em>quadratic </em>time on TMs, which is tight and likely matches the time in Exercise ??. The same bound can be shown for other functions; palindromes just happen to be convenient to obtain matching bounds.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-3001r1"></a> <b>Theorem</b> 1.1. </span> <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BPalindromes%7D%5Cnot+%5Cin+%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BPalindromes%7D%5Cnot+%5Cin+%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BPalindromes%7D%5Cnot+%5Cin+%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Palindromes}&#92;not &#92;in &#92;text {TM-Time}(t(n))" class="latex" /> for any <img src="https://s0.wp.com/latex.php?latex=t%28n%29%3Do%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%3Do%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%3Do%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)=o(n^{2})" class="latex" />.</p>
<p style="text-align: justify">More precisely, for every <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />, an <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />-state TM that decides if an <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />-bit input is a palindrome requires time <img src="https://s0.wp.com/latex.php?latex=%5Cge+cn%5E%7B2%7D%2F%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+cn%5E%7B2%7D%2F%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+cn%5E%7B2%7D%2F%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge cn^{2}/&#92;log s" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">The main concept that allows us to formalize the information bottleneck mentioned above is the following.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-3002r1"></a> <b>Definition</b> 1.1. </span>A <em>crossing sequence</em> of a TM <em>M</em> on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and boundary <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />, abbreviated <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS, is the sequence of states that <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is transitioning to when crossing cell boundary <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> (i.e., going from Cell <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=i%2B1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%2B1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%2B1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i+1" class="latex" /> or vice versa) during the computation on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">The idea in the proof is very interesting. If <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> accepts inputs <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> and those two inputs have the same <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS for some <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />, then we can “stitch together” the computation of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> at boundary <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> to create a new input <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> that is still accepted by <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />. The input <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> is formed by picking bits from <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> to the left of cell boundary <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> and bits from <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> to the right of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />:</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+z%3A%3Dx_%7B1%7Dx_%7B2%7D%5Ccdots+x_%7Bi%7Dy_%7Bi%2B1%7Dy_%7Bi%2B2%7D%5Ccdots+y_%7Bn%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+z%3A%3Dx_%7B1%7Dx_%7B2%7D%5Ccdots+x_%7Bi%7Dy_%7Bi%2B1%7Dy_%7Bi%2B2%7D%5Ccdots+y_%7Bn%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+z%3A%3Dx_%7B1%7Dx_%7B2%7D%5Ccdots+x_%7Bi%7Dy_%7Bi%2B1%7Dy_%7Bi%2B2%7D%5Ccdots+y_%7Bn%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} z:=x_{1}x_{2}&#92;cdots x_{i}y_{i+1}y_{i+2}&#92;cdots y_{n}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">The proof that <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> is still accepted is left as an exercise.</p>
<p style="text-align: justify">Now, for many problems, input <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> should <em>not</em> be accepted by <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, and this gives a contradiction. In particular this will be be the case for palindromes. We are going to find two palindromes <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> that have the same <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS for some <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />, but the corresponding <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> is not a palindrome, yet it is still accepted by <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />. We can find these two palindromes if <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> takes too little time. The basic idea is that if <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> runs in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />, because <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CSs for different <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> correspond to different steps of the computation, for every input there is a value of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> such that the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS is short, namely has length at most <img src="https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(|x|)/n" class="latex" />. If <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" /> is much less than <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}" class="latex" />, the length of this CS is much less than <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, from which we can conclude that the number of CSs is much less than the number of inputs, and so we can find two inputs with the same CS.</p>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>Let <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> be divisible by four, without loss of generality, and consider palindromes of the form</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+p%28x%29%3A%3Dx0%5E%7Bn%2F2%7Dx%5E%7BR%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+p%28x%29%3A%3Dx0%5E%7Bn%2F2%7Dx%5E%7BR%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+p%28x%29%3A%3Dx0%5E%7Bn%2F2%7Dx%5E%7BR%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} p(x):=x0^{n/2}x^{R} &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">where <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n/4}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=x%5E%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5E%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5E%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x^{R}" class="latex" /> is the reverse of <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<p style="text-align: justify">Assume there are <img src="https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;ne y" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n/4}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> in the middle part, i.e., <img src="https://s0.wp.com/latex.php?latex=n%2F4%5Cle+i%5Cle+3n%2F4-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2F4%5Cle+i%5Cle+3n%2F4-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2F4%5Cle+i%5Cle+3n%2F4-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n/4&#92;le i&#92;le 3n/4-1" class="latex" />, so that the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(x)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=p%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(y)" class="latex" /> is the same. Then we can define <img src="https://s0.wp.com/latex.php?latex=z%3A%3Dx0%5E%7Bn%2F2%7Dy%5E%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z%3A%3Dx0%5E%7Bn%2F2%7Dy%5E%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z%3A%3Dx0%5E%7Bn%2F2%7Dy%5E%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z:=x0^{n/2}y^{R}" class="latex" /> which is not a palindrome but is still accepted by <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, concluding the proof.</p>
<p style="text-align: justify">There remains to prove that the assumption of Theorem <a href="#x1-3001r1">1.1<!--tex4ht:ref: thm:TM-pal-requires-quadratic --></a> implies the assumption in the previous paragraph. Suppose <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> runs in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />. Since crossing sequences at different boundaries correspond to different steps of the computation, for every <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%2F4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n/4}" class="latex" /> there is a value of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> in the middle part such that the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(x)" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+ct%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+ct%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+ct%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le ct/n" class="latex" />. This implies that there is an <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> in the middle s.t. there are <img src="https://s0.wp.com/latex.php?latex=%5Cge+c2%5E%7Bn%2F4%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c2%5E%7Bn%2F4%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c2%5E%7Bn%2F4%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c2^{n/4}/n" class="latex" /> inputs <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> for which the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+ct%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+ct%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+ct%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le ct/n" class="latex" />.</p>
<p style="text-align: justify">For fixed <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />, the number of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS of length <img src="https://s0.wp.com/latex.php?latex=%5Cle+%5Cell+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+%5Cell+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+%5Cell+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le &#92;ell " class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cle+%28s%2B1%29%5E%7B%5Cell+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+%28s%2B1%29%5E%7B%5Cell+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+%28s%2B1%29%5E%7B%5Cell+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le (s+1)^{&#92;ell }" class="latex" />.</p>
<p style="text-align: justify">Hence there are <img src="https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cne+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;ne y" class="latex" /> for which <img src="https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(x)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=p%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(y)" class="latex" /> have the same <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS whenever <img src="https://s0.wp.com/latex.php?latex=c2%5E%7Bn%2F4%7D%2Fn%5Cge+%28s%2B1%29%5E%7Bct%2Fn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c2%5E%7Bn%2F4%7D%2Fn%5Cge+%28s%2B1%29%5E%7Bct%2Fn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c2%5E%7Bn%2F4%7D%2Fn%5Cge+%28s%2B1%29%5E%7Bct%2Fn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c2^{n/4}/n&#92;ge (s+1)^{ct/n}" class="latex" />. Taking logs one gets <img src="https://s0.wp.com/latex.php?latex=ct%5Clog+%28s%29%2Fn%5Cle+cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=ct%5Clog+%28s%29%2Fn%5Cle+cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=ct%5Clog+%28s%29%2Fn%5Cle+cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="ct&#92;log (s)/n&#92;le cn" class="latex" />. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-3003r1"></a> <b>Exercise</b> 1.1. </span>For every <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> describe an <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />-state TM deciding palindromes in time <img src="https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D%2F%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D%2F%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D%2F%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn^{2}/&#92;log s" class="latex" /> (matching Theorem <a href="#x1-3001r1">1.1<!--tex4ht:ref: thm:TM-pal-requires-quadratic --></a>).</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-3004r2"></a> <b>Exercise</b> 1.2. </span>Let <img src="https://s0.wp.com/latex.php?latex=L%3A%3D%5C%7Bxx%3Ax%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%2A%7D%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%3A%3D%5C%7Bxx%3Ax%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%2A%7D%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%3A%3D%5C%7Bxx%3Ax%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%2A%7D%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L:=&#92;{xx:x&#92;in &#92;{0,1&#92;} ^{*}&#92;}" class="latex" />. Show <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BTM-Time%5Censuremath+%7B%28cn%5E%7B2%7D%29%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BTM-Time%5Censuremath+%7B%28cn%5E%7B2%7D%29%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BTM-Time%5Censuremath+%7B%28cn%5E%7B2%7D%29%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {TM-Time&#92;ensuremath {(cn^{2})}}" class="latex" />, and prove this is tight up to constants.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">One may be tempted to think that it is not hard to prove stronger bounds for similar functions. In fact as mentioned above this has resisted all attempts!</p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">1.2 </span> <a id="x1-40001.2"></a>Counting: impossibility results for non-explicit functions</h3>
<p style="text-align: justify">Proving the <em>existence</em> of hard functions is simple: Just count. If there are more functions than efficient machines, some function is not efficiently computable. This is applicable to any model; next we state it for TMs for concreteness. Later we will state it for circuits.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-4001r2"></a> <b>Theorem</b> 1.2. </span>There exists a function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} " class="latex" /> that cannot be computed by a TM with <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> states unless <img src="https://s0.wp.com/latex.php?latex=cs%5Clog+s%5Cge+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cs%5Clog+s%5Cge+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cs%5Clog+s%5Cge+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cs&#92;log s&#92;ge 2^{n}" class="latex" />, regardless of time.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>The number of TMs with <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> states is <img src="https://s0.wp.com/latex.php?latex=%5Cle+s%7B%7D%5E%7Bcs%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+s%7B%7D%5E%7Bcs%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+s%7B%7D%5E%7Bcs%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le s{}^{cs}," class="latex" /> and each TM computes at most one function (it may compute none, if it does not stop). The number of functions on <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> bits is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{2^{n}}" class="latex" />. Hence if <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%3Ecs%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%3Ecs%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%3Ecs%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{n}&gt;cs&#92;log s" class="latex" /> some function cannot be computed. <b>QED</b></p>
</div>
<p style="text-align: justify">Note this bound is not far from that in Exercise ??.</p>
<p style="text-align: justify">It is instructive to present this basic result as an application of the probabilistic method:</p>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>Let us pick <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> uniformly at random. We want to show that</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7Bf%7D%5B%5Cexists+%5Ctext+%7B+an+%7Ds%5Ctext+%7B-state+TM+%7DM%5Ctext+%7B+such+that+%7DM%28x%29%3Df%28x%29%5Ctext+%7B+for+every+%7Dx%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5D%3C1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7Bf%7D%5B%5Cexists+%5Ctext+%7B+an+%7Ds%5Ctext+%7B-state+TM+%7DM%5Ctext+%7B+such+that+%7DM%28x%29%3Df%28x%29%5Ctext+%7B+for+every+%7Dx%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5D%3C1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7Bf%7D%5B%5Cexists+%5Ctext+%7B+an+%7Ds%5Ctext+%7B-state+TM+%7DM%5Ctext+%7B+such+that+%7DM%28x%29%3Df%28x%29%5Ctext+%7B+for+every+%7Dx%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5D%3C1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;mathbb {P}_{f}[&#92;exists &#92;text { an }s&#92;text {-state TM }M&#92;text { such that }M(x)=f(x)&#92;text { for every }x&#92;in &#92;{0,1&#92;} ^{n}]&lt;1. &#92;end{aligned}" class="latex" /></div>
<p>Indeed, if the probability is less than <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> than some function exists that cannot be computed. By a union bound we can say that this probability is</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+%5Csum+_%7BM%7D%5Cmathbb+%7BP%7D_%7Bf%7D%5BM%28x%29%3Df%28x%29%5Ctext+%7B+for+every+%7Dx%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5D%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+%5Csum+_%7BM%7D%5Cmathbb+%7BP%7D_%7Bf%7D%5BM%28x%29%3Df%28x%29%5Ctext+%7B+for+every+%7Dx%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5D%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+%5Csum+_%7BM%7D%5Cmathbb+%7BP%7D_%7Bf%7D%5BM%28x%29%3Df%28x%29%5Ctext+%7B+for+every+%7Dx%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5D%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;le &#92;sum _{M}&#92;mathbb {P}_{f}[M(x)=f(x)&#92;text { for every }x&#92;in &#92;{0,1&#92;} ^{n}], &#92;end{aligned}" class="latex" /></div>
<p>where the sum is over all <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />-state machines. Each probability in the sum is <img src="https://s0.wp.com/latex.php?latex=%281%2F2%29%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%281%2F2%29%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%281%2F2%29%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(1/2)^{2^{n}}" class="latex" />, since <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is fixed. The number of <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />-state machines is <img src="https://s0.wp.com/latex.php?latex=%5Cle+s%5E%7Bcs%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+s%5E%7Bcs%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+s%5E%7Bcs%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le s^{cs}" class="latex" />. So the sum is <img src="https://s0.wp.com/latex.php?latex=%5Cle+s%5E%7Bcs%7D%281%2F2%29%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+s%5E%7Bcs%7D%281%2F2%29%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+s%5E%7Bcs%7D%281%2F2%29%5E%7B2%5E%7Bn%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le s^{cs}(1/2)^{2^{n}}" class="latex" />, and we can conclude as before taking logs. <b>QED</b></p>
</div>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">1.3 </span> <a id="x1-50001.3"></a>Diagonalization: Enumerating machines</h3>
<p style="text-align: justify">Can you compute more if you have more time? For example, can you write a program that runs in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}" class="latex" /> and computes something that cannot be computed in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1.5%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B1.5%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B1.5%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{1.5}" class="latex" />? The answer is yes for trivial reasons if we allow for non-boolean functions.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-5001r3"></a> <b>Exercise</b> 1.3. </span>Give a function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;}^* " class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29%5Csetminus+%5Ctext+%7BTime%7D%28n%5E%7B1.5%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29%5Csetminus+%5Ctext+%7BTime%7D%28n%5E%7B1.5%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29%5Csetminus+%5Ctext+%7BTime%7D%28n%5E%7B1.5%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(n^{2})&#92;setminus &#92;text {Time}(n^{1.5})" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">The answer is more interesting if the functions are boolean. Such results are known as <em>time hierarchies</em>, and a generic technique for proving them is <em>diagonalization, </em>applicable to any model.</p>
<p style="text-align: justify">We first illustrate the result in the simpler case of partial functions, which contains the main ideas. Later we discuss total functions.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-5002r3"></a> <b>Theorem</b> 1.3. </span>There is a partial function in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(t(n))" class="latex" /> such that any TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> computing it runs in time <img src="https://s0.wp.com/latex.php?latex=%5Cge+c_%7BM%7Dt%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c_%7BM%7Dt%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c_%7BM%7Dt%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c_{M}t(n)" class="latex" />, for any <img src="https://s0.wp.com/latex.php?latex=t%28n%29%3D%5Comega+%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%3D%5Comega+%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%3D%5Comega+%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)=&#92;omega (1)" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">In other words, <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28t%28n%29%29%5Csupsetneq+%5Ctext+%7BTime%7D%28o%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28t%28n%29%29%5Csupsetneq+%5Ctext+%7BTime%7D%28o%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28t%28n%29%29%5Csupsetneq+%5Ctext+%7BTime%7D%28o%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(t(n))&#92;supsetneq &#92;text {Time}(o(t(n))" class="latex" />.</p>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>Consider the TM <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> that on input <img src="https://s0.wp.com/latex.php?latex=x%3D%28M%2C1%5E%7Bn-%7CM%7C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%3D%28M%2C1%5E%7Bn-%7CM%7C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%3D%28M%2C1%5E%7Bn-%7CM%7C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x=(M,1^{n-|M|})" class="latex" /> of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> runs <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> until it stops and then complements the answer. (We can use a simple encoding of these pairs, for example every even-position bit of the description of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is a <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" />.)</p>
<p style="text-align: justify">Now define <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> to be the subset of pairs s.t. <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> runs in time <img src="https://s0.wp.com/latex.php?latex=%5Cle+t%28n%29%2F%7CM%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+t%28n%29%2F%7CM%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+t%28n%29%2F%7CM%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le t(n)/|M|^{c}" class="latex" /> on inputs of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|M|^{c}&#92;le t(n)/2" class="latex" />.</p>
<p style="text-align: justify">On these inputs, <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> runs in time <img src="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%2B%7CM%7C%5E%7Bc%7D%5Ccdot+t%28n%29%2F%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%2B%7CM%7C%5E%7Bc%7D%5Ccdot+t%28n%29%2F%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%2B%7CM%7C%5E%7Bc%7D%5Ccdot+t%28n%29%2F%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|M|^{c}+|M|^{c}&#92;cdot t(n)/|M|^{c}&#92;le t(n)" class="latex" />, as desired. To accomplish this, <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> can begin by making a copy of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> in time <img src="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D%5Cle+t%28n%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|M|^{c}&#92;le t(n)/2" class="latex" />. Then every step of the computation of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> can be simulated by <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CM%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|M|^{c}" class="latex" /> steps, always keeping the description of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> to the left of the head.</p>
<p style="text-align: justify">Now suppose <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N" class="latex" /> computes the same function as <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> in time <img src="https://s0.wp.com/latex.php?latex=t%28n%29%2F%7CN%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%2F%7CN%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%2F%7CN%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)/|N|^{c}" class="latex" />. Note that <img src="https://s0.wp.com/latex.php?latex=x%3A%3D%28N%2C1%5E%7Bn-%7CN%7C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%3A%3D%28N%2C1%5E%7Bn-%7CN%7C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%3A%3D%28N%2C1%5E%7Bn-%7CN%7C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x:=(N,1^{n-|N|})" class="latex" /> falls in the domain <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> of the function, for <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> sufficiently large, using that <img src="https://s0.wp.com/latex.php?latex=t%28n%29%3D%5Comega+%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%3D%5Comega+%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%3D%5Comega+%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)=&#92;omega (1)" class="latex" />. Now consider running <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />. We have <img src="https://s0.wp.com/latex.php?latex=N%28x%29%3DH%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N%28x%29%3DH%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N%28x%29%3DH%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N(x)=H(x)" class="latex" /> by supposition, but <img src="https://s0.wp.com/latex.php?latex=H%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H(x)" class="latex" /> is the complement of <img src="https://s0.wp.com/latex.php?latex=N%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N(x)" class="latex" />, contradiction. <b>QED</b></p>
</div>
<p style="text-align: justify">This proof is somewhat unsatisfactory; in particular we have no control on the running time of <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> on inputs not in <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" />. It is desirable to have a version of this fundamental result for total functions. Such a version is stated next. It requires additional assumptions on <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> and a larger gap between the running times. Perhaps surprisingly, as we shall discuss, both requirements are essential.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-5003r4"></a> <b>Theorem</b> 1.4. </span> Let <img src="https://s0.wp.com/latex.php?latex=t%28n%29%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)&#92;ge n" class="latex" /> be a function. Suppose that <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3A%3Dt%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3A%3Dt%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3A%3Dt%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x):=t(|x|)" class="latex" /> is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%2F%5Clog+%5E%7Bc%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%2F%5Clog+%5E%7Bc%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%2F%5Clog+%5E%7Bc%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(t(n)/&#92;log ^{c}n)" class="latex" />.</p>
<p style="text-align: justify">There is a total function in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28ct%28n%29%5Clog+t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28ct%28n%29%5Clog+t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28ct%28n%29%5Clog+t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(ct(n)&#92;log t(n))" class="latex" /> that cannot be computed by any TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> in time <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}t(n)" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">The assumption about <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is satisfied by all standard functions, including all those in this book. (For example, take <img src="https://s0.wp.com/latex.php?latex=t%28n%29%3A%3Dn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%3A%3Dn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%3A%3Dn%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n):=n^{2}" class="latex" />. The corresponding <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is then <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|^{2}" class="latex" />. To compute <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> bits we can first compute <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|=n" class="latex" /> in time <img src="https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn&#92;log n" class="latex" /> (Exercise ??). This is a number of <img src="https://s0.wp.com/latex.php?latex=b%3A%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%3A%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%3A%3D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b:=&#92;log n" class="latex" /> bits. We can then square this number in time <img src="https://s0.wp.com/latex.php?latex=b%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b^{c}" class="latex" />. Note that the time to compute <img src="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)" class="latex" /> is dominated by the <img src="https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn&#92;log n" class="latex" /> term coming from computing <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|" class="latex" />, which does not depend on <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> and is much less than the <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}/&#92;log ^{c}n" class="latex" /> in the assumption.) The assumption cannot be removed altogether because there exist pathological functions <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> for which the result is false.</p>
<p style="text-align: justify">The proof is similar to that of Theorem <a href="#x1-5002r3">1.3<!--tex4ht:ref: thm:time-hierarchy-TM-Time-partial --></a>. However, to make the function total we need to deal with arbitrary machines, which may not run in the desired time or even stop at all. The solution is to clock <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> in a manner similar to the proof of the universal machine, Lemma ??.</p>
<p style="text-align: justify">Also, we define a slightly different language to give a stronger result – a unary language – and to avoid some minor technical details (the possibility that the computation of <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> erases the input).</p>
<p style="text-align: justify">We define a TM <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> that on input <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" /> obtains a description of a TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, computes <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />, and then simulates <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on input <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" /> steps in a way similar to Lemma ??, and if <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> stops then <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> outputs the complement of the output of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />; and if <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> does not stop then <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> stops and outputs anything. Now <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> computes a function in time about <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />. We argue that this function cannot be computed in much less time as follows. Suppose some TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> computes the function in time somewhat less than <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />. Then we can pick an <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" /> for which <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> obtains the description of this <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, and the simulation always stops. Hence, for that <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" /> we would obtain <img src="https://s0.wp.com/latex.php?latex=M%281%5E%7Bn%7D%29%3DH%281%5E%7Bn%7D%29%3D1-M%281%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%281%5E%7Bn%7D%29%3DH%281%5E%7Bn%7D%29%3D1-M%281%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%281%5E%7Bn%7D%29%3DH%281%5E%7Bn%7D%29%3D1-M%281%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(1^{n})=H(1^{n})=1-M(1^{n})" class="latex" />, which is a contradiction.</p>
<p style="text-align: justify">However, there are interesting differences with the simulation in Lemma ??. In that lemma the universal machine <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> was clocking the steps of the machine <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> being simulated. Now instead we need to clock the steps of <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> itself, even while <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> is parsing the description of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> to compute its transition function. This is necessary to guarantee that <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> does not waste time on big TM descriptions.</p>
<p style="text-align: justify">Whereas in Lemma ?? the tape was arranged as</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2CM%2C%5Cunderline+%7Bi%7D%2Ct%27%2Cy%29%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2CM%2C%5Cunderline+%7Bi%7D%2Ct%27%2Cy%29%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2CM%2C%5Cunderline+%7Bi%7D%2Ct%27%2Cy%29%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} (x,M,&#92;underline {i},t&#039;,y), &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">it will now be arranged as</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2CM%27%2C%5Cunderline+%7Bi%7D%2Ct%27%2CM%27%27%2Cy%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2CM%27%2C%5Cunderline+%7Bi%7D%2Ct%27%2CM%27%27%2Cy%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2CM%27%2C%5Cunderline+%7Bi%7D%2Ct%27%2CM%27%27%2Cy%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} (x,M&#039;,&#92;underline {i},t&#039;,M&#039;&#039;,y) &#92;end{aligned}" class="latex" /></div>
<p>which is parsed as follows. The description of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=M%27M%27%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%27M%27%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%27M%27%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M&#039;M&#039;&#039;" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is in state <img src="https://s0.wp.com/latex.php?latex=%5Cunderline+%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cunderline+%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cunderline+%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;underline {i}" class="latex" />, the tape of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> contains <img src="https://s0.wp.com/latex.php?latex=xy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=xy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=xy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="xy" class="latex" /> and the head is on the left-most symbol of <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />. The integer <img src="https://s0.wp.com/latex.php?latex=t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#039;" class="latex" /> is the counter decreased at every step</p>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>Define TM <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> that on input <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" />:</p>
<ol class="enumerate1">
<li id="x1-5005x1" class="enumerate">Compute <img src="https://s0.wp.com/latex.php?latex=%28n%2Ct%28n%29%2C1%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28n%2Ct%28n%29%2C1%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28n%2Ct%28n%29%2C1%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(n,t(n),1^{n})" class="latex" />.</li>
<li id="x1-5007x2" class="enumerate">Compute <img src="https://s0.wp.com/latex.php?latex=%28M_%7Bn%7D%2Ct%28n%29%2C1%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28M_%7Bn%7D%2Ct%28n%29%2C1%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28M_%7Bn%7D%2Ct%28n%29%2C1%5E%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(M_{n},t(n),1^{n})" class="latex" />. Here <img src="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{n}" class="latex" /> is obtained from <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> by removing all left-most zeroes until the first <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" />. I.e., if <img src="https://s0.wp.com/latex.php?latex=n%3D0%5E%7Bj%7D1x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%3D0%5E%7Bj%7D1x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%3D0%5E%7Bj%7D1x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n=0^{j}1x" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=M_%7Bn%7D%3Dx&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7Bn%7D%3Dx&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7Bn%7D%3Dx&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{n}=x" class="latex" />. This is similar to the fact that a program does not change if you add, say, empty lines at the bottom.</li>
<li id="x1-5009x3" class="enumerate">Simulate <img src="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{n}" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" />, reducing the counter <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" /> at every step, including those parsing <img src="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{n}" class="latex" />, as explained before.</li>
<li id="x1-5011x4" class="enumerate">If <img src="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{n}" class="latex" /> stops before the counter reaches <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" />, output the complement of its output. If the counter reaches <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> stop and output anything.</li>
</ol>
<p style="text-align: justify"><em>Running time of <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" />.</em></p>
<ol class="enumerate1">
<li id="x1-5013x1" class="enumerate">Computing <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> is similar to Exercise ??. By assumption <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" /> is computable in time <img src="https://s0.wp.com/latex.php?latex=t%28n%29%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)/&#92;log ^{c}n" class="latex" />. Our definition of computation allows for erasing the input, but we can keep <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> around spending at most another <img src="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log ^{c}n" class="latex" /> factor. Thus we can compute <img src="https://s0.wp.com/latex.php?latex=%28n%2Ct%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28n%2Ct%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28n%2Ct%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(n,t(n))" class="latex" /> in time <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />. Finally, in case it was erased, we can re-compute <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" /> in time <img src="https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn&#92;log n" class="latex" /> by keeping a counter (initialized to a copy of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />).</li>
<li id="x1-5015x2" class="enumerate">This takes time <img src="https://s0.wp.com/latex.php?latex=c%28n%2Bt%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%28n%2Bt%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%28n%2Bt%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c(n+t(n))" class="latex" />: simply scan the input and remove zeroes.</li>
<li id="x1-5017x3" class="enumerate">Decreasing the counter takes <img src="https://s0.wp.com/latex.php?latex=c%7Ct%28n%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%7Ct%28n%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%7Ct%28n%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c|t(n)|" class="latex" /> steps. Hence this simulation will take <img src="https://s0.wp.com/latex.php?latex=ct%28n%29%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=ct%28n%29%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=ct%28n%29%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="ct(n)&#92;log t(n)" class="latex" /> time.</li>
</ol>
<p style="text-align: justify">Overall the running time is <img src="https://s0.wp.com/latex.php?latex=ct%28n%29%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=ct%28n%29%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=ct%28n%29%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="ct(n)&#92;log t(n)" class="latex" />.</p>
<p style="text-align: justify"><em>Proof that the function computed by <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> requires much time.</em> Suppose some TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> computes the same function as <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" />. Consider inputs <img src="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1^{n}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=n%3D0%5E%7Bj%7D1M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%3D0%5E%7Bj%7D1M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%3D0%5E%7Bj%7D1M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n=0^{j}1M" class="latex" />. Parsing the description of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> to compute its transition function takes time <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}" class="latex" />, a value that depends on <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> only and not on <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j" class="latex" />. Hence <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> will simulate <img src="https://s0.wp.com/latex.php?latex=%5Clfloor+t%28n%29%2Fc_%7BM%7D%5Crfloor+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clfloor+t%28n%29%2Fc_%7BM%7D%5Crfloor+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clfloor+t%28n%29%2Fc_%7BM%7D%5Crfloor+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;lfloor t(n)/c_{M}&#92;rfloor " class="latex" /> steps of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />. If <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> stops within that time (which requires <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" /> to be larger than <img src="https://s0.wp.com/latex.php?latex=b_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b_{M}" class="latex" />, and so <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j" class="latex" /> sufficiently large compared to <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />) then the simulation terminates and we reach a contradiction as explained before. <b>QED</b></p>
</div>
<p style="text-align: justify">The extra <img src="https://s0.wp.com/latex.php?latex=%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log t(n)" class="latex" /> factor cannot be reduced because of the surprising result presented in Theorem <a href="#x1-6001r5">1.5<!--tex4ht:ref: thm:TIMEonlogn=00003Dregular --></a> showing that, on TMs, time <img src="https://s0.wp.com/latex.php?latex=o%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=o%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=o%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="o(n&#92;log n)" class="latex" /> equals time <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> for computing total functions.</p>
<p style="text-align: justify">However, tighter time hierarchies hold for more powerful models, like RAMs. Also, a time hierarchy for total functions for <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPTime}" class="latex" /> is&#8230; an open problem! But a hierarchy is known for partial functions.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-5018r4"></a> <b>Exercise</b> 1.4. </span>(1) State and prove a tighter time hierarchy for Time (which recall corresponds to RAMs) for total functions. You don’t need to address simulation details, but you need to explain why a sharper separation is possible.</p>
<p style="text-align: justify">(2) Explain the difficulty in extending (1) to <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPTime}" class="latex" />.</p>
<p style="text-align: justify">(3) State and prove a time hierarchy for <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPTime}" class="latex" /> for partial functions.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<h4 class="subsectionHead"><span class="titlemark">1.3.1 </span> <a id="x1-60001.3.1"></a><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28o%28n%5Clog+n%29%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28o%28n%5Clog+n%29%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28o%28n%5Clog+n%29%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(o(n&#92;log n))=&#92;text {TM-Time}(n)" class="latex" /></h4>
<p style="text-align: justify">In this subsection we prove the result in the title, which we also mentioned earlier. First let us state the result formally.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-6001r5"></a> <b>Theorem</b> 1.5. </span> <span class="cite">[<a href="journals/iandc/Hennie65">1</a>, <a href="#XKobayashi1985OnTS">2</a>]</span> Let <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} " class="latex" /> be in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(t(n))" class="latex" /> for a <img src="https://s0.wp.com/latex.php?latex=t%28n%29%3Do%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%3Do%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%3Do%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)=o(n&#92;log n)" class="latex" />. Then <img src="https://s0.wp.com/latex.php?latex=f%5Cin+%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%5Cin+%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%5Cin+%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f&#92;in &#92;text {TM-Time}(n)" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Note that time <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> is barely enough to scan the input. Indeed, the corresponding machines in Theorem <a href="#x1-6001r5">1.5<!--tex4ht:ref: thm:TIMEonlogn=00003Dregular --></a> will only move the head in one direction.</p>
<p style="text-align: justify">The rest of this section is devoted to proving the above theorem. Let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be a machine for <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> witnessing the assumption of the theorem. We can assume that <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> stops on every input (even though our definition of time only applies to large enough inputs), possibly by adding <img src="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n" class="latex" /> to the time, which does not change the assumption on <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />. The theorem now follows from the combination of the next two lemmas.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-6002r1"></a> <b>Lemma</b> 1.1. </span>Let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be a TM running in time <img src="https://s0.wp.com/latex.php?latex=t%28n%29%5Cle+o%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%5Cle+o%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%5Cle+o%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)&#92;le o(n&#92;log n)" class="latex" />. Then on every input <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;}^* " class="latex" /> every <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS with <img src="https://s0.wp.com/latex.php?latex=i%5Cle+%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%5Cle+%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%5Cle+%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#92;le |x|" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c_{M}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>For an integer <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b" class="latex" /> let <img src="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x(b)" class="latex" /> be a shortest input such that there exists <img src="https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B0%2C1%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B0%2C1%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B0%2C1%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j&#92;in &#92;{0,1,&#92;ldots ,n&#92;}" class="latex" /> for which the <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j" class="latex" />-CS in the computation of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x(b)" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge b" class="latex" />. Let <img src="https://s0.wp.com/latex.php?latex=n%28b%29%3A%3D%7Cx%28b%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%28b%29%3A%3D%7Cx%28b%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%28b%29%3A%3D%7Cx%28b%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n(b):=|x(b)|" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-6003r5"></a> <b>Exercise</b> 1.5. </span>Prove <img src="https://s0.wp.com/latex.php?latex=n%28b%29%5Cto+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%28b%29%5Cto+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%28b%29%5Cto+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n(b)&#92;to &#92;infty " class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=b%5Cto+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%5Cto+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%5Cto+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b&#92;to &#92;infty " class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">There are <img src="https://s0.wp.com/latex.php?latex=n%28b%29%2B1%5Cge+n%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%28b%29%2B1%5Cge+n%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%28b%29%2B1%5Cge+n%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n(b)+1&#92;ge n(b)" class="latex" /> tape boundaries within or bordering <img src="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x(b)" class="latex" />. If we pick a boundary uniformly at random, the average length of a CS on <img src="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x(b)" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cle+t%28n%28b%29%29%2Fn%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+t%28n%28b%29%29%2Fn%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+t%28n%28b%29%29%2Fn%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le t(n(b))/n(b)" class="latex" />. Hence there are <img src="https://s0.wp.com/latex.php?latex=%5Cge+n%28b%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+n%28b%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+n%28b%29%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge n(b)/2" class="latex" /> choices for <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> s.t. the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS on <img src="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x(b)" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+2t%28n%28b%29%29%2Fn%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+2t%28n%28b%29%29%2Fn%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+2t%28n%28b%29%29%2Fn%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le 2t(n(b))/n(b)" class="latex" />.</p>
<p style="text-align: justify">The number of such crossing sequences is</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+%28s%2B1%29%5E%7B2t%28n%28b%29%29%2Fn%28b%29%7D%3D%28s%2B1%29%5E%7Bo%28n%28b%29%5Clog+%28n%28b%29%29%2Fn%28b%29%7D%3Dn%28b%29%5E%7Bo%28%5Clog+s%29%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+%28s%2B1%29%5E%7B2t%28n%28b%29%29%2Fn%28b%29%7D%3D%28s%2B1%29%5E%7Bo%28n%28b%29%5Clog+%28n%28b%29%29%2Fn%28b%29%7D%3Dn%28b%29%5E%7Bo%28%5Clog+s%29%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+%28s%2B1%29%5E%7B2t%28n%28b%29%29%2Fn%28b%29%7D%3D%28s%2B1%29%5E%7Bo%28n%28b%29%5Clog+%28n%28b%29%29%2Fn%28b%29%7D%3Dn%28b%29%5E%7Bo%28%5Clog+s%29%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;le (s+1)^{2t(n(b))/n(b)}=(s+1)^{o(n(b)&#92;log (n(b))/n(b)}=n(b)^{o(&#92;log s)}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">Hence, the same crossing sequence occurs at <img src="https://s0.wp.com/latex.php?latex=%5Cge+%28n%28b%29%2F2%29%2Fn%28b%29%5E%7Bo%28%5Clog+s%29%7D%5Cge+4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+%28n%28b%29%2F2%29%2Fn%28b%29%5E%7Bo%28%5Clog+s%29%7D%5Cge+4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+%28n%28b%29%2F2%29%2Fn%28b%29%5E%7Bo%28%5Clog+s%29%7D%5Cge+4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge (n(b)/2)/n(b)^{o(&#92;log s)}&#92;ge 4" class="latex" /> positions <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />, using that <img src="https://s0.wp.com/latex.php?latex=n%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n(b)" class="latex" /> is large enough.</p>
<p style="text-align: justify">Of these four, one could be the CS of length <img src="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge b" class="latex" /> from the definition of <img src="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x(b)" class="latex" />. Of the other three, two are on the same side of <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j" class="latex" />. We can remove the corresponding interval of the input without removing the CS of length <img src="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge b" class="latex" />. Hence we obtained a shorter input with a CS of length <img src="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge b" class="latex" />. Contradiction. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-6004r2"></a> <b>Lemma</b> 1.2. </span>Suppose <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} " class="latex" /> is computable by a TM such that on every input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, every <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />-CS with <img src="https://s0.wp.com/latex.php?latex=i%5Cle+%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%5Cle+%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%5Cle+%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#92;le |x|" class="latex" /> has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le b" class="latex" />. Then <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is computable in time <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> by a TM with <img src="https://s0.wp.com/latex.php?latex=c_%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{b}" class="latex" /> states that only moves the head in one direction.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-6005r6"></a> <b>Exercise</b> 1.6. </span>Prove this.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">1.4 </span> <a id="x1-70001.4"></a>Circuits</h3>
<p style="text-align: justify">The situation for circuits is similar to that of 2-TMs, and by Theorem ?? we know that proving <img src="https://s0.wp.com/latex.php?latex=%5Comega+%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Comega+%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Comega+%28n%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;omega (n&#92;log n)" class="latex" /> bounds on circuits is harder than for 2-TMs. Even a bound of <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" /> is unknown. The following is a circuit version of Theorem <a href="#x1-4001r2">1.2<!--tex4ht:ref: thm:TM-counting-lower-bound --></a>. Again, the bound is close to what we saw in Theorem ??.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-7001r6"></a> <b>Theorem</b> 1.6. </span><span class="cite">[<a href="#XMR29860">3</a>]</span> There are functions <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} " class="latex" /> that require circuits of size <img src="https://s0.wp.com/latex.php?latex=%5Cge+%281-o%281%29%292%5E%7Bn%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+%281-o%281%29%292%5E%7Bn%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+%281-o%281%29%292%5E%7Bn%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge (1-o(1))2^{n}/n" class="latex" />, for every <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">One can prove a hierarchy for circuit size, by combining Theorem <a href="#x1-7001r6">1.6<!--tex4ht:ref: thm:shannon-hard-function --></a> and Theorem ??. As stated, the results give that circuits of size <img src="https://s0.wp.com/latex.php?latex=cs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cs" class="latex" /> compute more functions than those of size <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />. In fact, the “<img src="https://s0.wp.com/latex.php?latex=o%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=o%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=o%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="o(1)" class="latex" />” in the theorems is small, so one can prove a sharper result. But a stronger and more enjoyable argument exists.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-7002r7"></a> <b>Theorem</b> 1.7. </span>[Hierarchy for circuit size] For every <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=s%5Cle+c2%5E%7Bn%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cle+c2%5E%7Bn%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cle+c2%5E%7Bn%7D%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;le c2^{n}/n" class="latex" /> there is a function <img src="https://s0.wp.com/latex.php?latex=f%3A%5Czonzo+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5Czonzo+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5Czonzo+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;zonzo " class="latex" /> that can be computed by circuits of size <img src="https://s0.wp.com/latex.php?latex=s%2Bcn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%2Bcn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%2Bcn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s+cn" class="latex" /> but not by circuits of size <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>. </span>Consider a path from the all-zero function to a function which requires circuits of size <img src="https://s0.wp.com/latex.php?latex=%5Cge+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge s" class="latex" />, guaranteed to exist by Theorem <a href="#x1-7001r6">1.6<!--tex4ht:ref: thm:shannon-hard-function --></a>, changing the output of the function on one input at each step of the path. Let <img src="https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h" class="latex" /> be the first function that requires size <img src="https://s0.wp.com/latex.php?latex=%3Es&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%3Es&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%3Es&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&gt;s" class="latex" />, and let <img src="https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h&#039;" class="latex" /> be the function right before that in the path. Note that <img src="https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h&#039;" class="latex" /> has circuits of size <img src="https://s0.wp.com/latex.php?latex=%5Cle+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le s" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h" class="latex" /> can be computed from <img src="https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=h%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="h&#039;" class="latex" /> by changing the value on a single input. The latter can be implemented by circuits of size <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" />. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-7003r7"></a> <b>Exercise</b> 1.7. </span>Prove a stronger hierarchy result for alternating circuits, where the “<img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" />” in Theorem <a href="#x1-7002r7">1.7<!--tex4ht:ref: thm:hierarchy-circuits-cn --></a> is replaced with “<img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c" class="latex" />.”</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">In fact, this improvement is possible even for (non aternating) circuits, see Problem <a href="#x1-9002r2">1.2<!--tex4ht:ref: prob:hierarchy-circuits-c --></a>.</p>
<p style="text-align: justify">
<h4 class="subsectionHead"><span class="titlemark">1.4.1 </span> <a id="x1-80001.4.1"></a>The circuit won’t fit in the universe: Non-asymptotic, cosmological results</h4>
<p style="text-align: justify">Most of the results in this book are <em>asymptotic</em>, i.e., we do not explicitly work out the constants because they become irrelevant for larger and larger input lengths. As stated, these results don’t say anything for inputs of a fixed length. For example, any function on <img src="https://s0.wp.com/latex.php?latex=10%5E%7B100%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=10%5E%7B100%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=10%5E%7B100%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="10^{100}" class="latex" /> bits is in Time<img src="https://s0.wp.com/latex.php?latex=%28c%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28c%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28c%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(c)" class="latex" />.</p>
<p style="text-align: justify">However, it is important to note that all the proofs are <em>constructive </em>and one can work out the constants, and produce non-asymptotic results. We state next one representative example when this was done. It is about a problem in logic, an area which often produces very hard problems.</p>
<p style="text-align: justify">On an alphabet of size <img src="https://s0.wp.com/latex.php?latex=63&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=63&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=63&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="63" class="latex" />, the language used to write formulas includes first-order variables that range over <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {N}" class="latex" />, second-order variables that range over finite subsets of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {N}" class="latex" />, the predicates “<img src="https://s0.wp.com/latex.php?latex=y%3Dx%2B1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y%3Dx%2B1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y%3Dx%2B1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y=x+1" class="latex" />” and “<img src="https://s0.wp.com/latex.php?latex=x%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in S" class="latex" />” where <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> denote first-order variables and <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> denotes a set variable, and standard quantifiers, connectives, constants, binary relation symbols on integers, and set equality. For example one can write things like “every finite set has a maximum:” <img src="https://s0.wp.com/latex.php?latex=%5Cforall+S%5Cexists+x%5Cin+S%5Cforall+y%5Cin+S%2Cy%5Cle+x.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cforall+S%5Cexists+x%5Cin+S%5Cforall+y%5Cin+S%2Cy%5Cle+x.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cforall+S%5Cexists+x%5Cin+S%5Cforall+y%5Cin+S%2Cy%5Cle+x.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;forall S&#92;exists x&#92;in S&#92;forall y&#92;in S,y&#92;le x." class="latex" /></p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-8001r8"></a> <b>Theorem</b> 1.8. </span><span class="cite">[<a href="#XMR2145856">4</a>]</span> To decide the truth of logical formulas of length at most <img src="https://s0.wp.com/latex.php?latex=610&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=610&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=610&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="610" class="latex" /> in this language requires a circuit containing at least <img src="https://s0.wp.com/latex.php?latex=10%5E%7B125%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=10%5E%7B125%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=10%5E%7B125%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="10^{125}" class="latex" /> gates. So even if each gate were the size of a proton, the circuit would not fit in the known universe.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Their result applies even to randomized circuits with error <img src="https://s0.wp.com/latex.php?latex=1%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1/3" class="latex" />, if <img src="https://s0.wp.com/latex.php?latex=610&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=610&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=610&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="610" class="latex" /> is replaced with <img src="https://s0.wp.com/latex.php?latex=614&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=614&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=614&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="614" class="latex" />. (We can define randomized circuits analogously to BPTime.)</p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">1.5 </span> <a id="x1-90001.5"></a>Problems</h3>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-9001r1"></a> <b>Problem</b> 1.1. </span>Hierarchy Theorem <a href="#x1-5003r4">1.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a> only gives a function <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> that cannot be computed fast on <em>all </em>large enough input lengths: it is consistent with the theorem that <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> can be computed fast on infinitely many input lengths.</p>
<p style="text-align: justify">Give a function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;}^* " class="latex" /> mapping <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7B%5Clog+%5Clog+%5Clog+%7Cx%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7B%5Clog+%5Clog+%5Clog+%7Cx%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7B%5Clog+%5Clog+%5Clog+%7Cx%7C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{&#92;log &#92;log &#92;log |x|}" class="latex" /> that is computable in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{c}" class="latex" /> but such that for any TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> running in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}" class="latex" /> the following holds. For every <img src="https://s0.wp.com/latex.php?latex=n%5Cge+c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5Cge+c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Cge+c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#92;ge c_{M}" class="latex" /> and every <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n}" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=M%28x%29%5Cne+f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%29%5Cne+f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%29%5Cne+f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x)&#92;ne f(x)" class="latex" />.</p>
<p style="text-align: justify">Hint: Note the range of <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />. Can this result hold as stated with range <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} " class="latex" />?</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-9002r2"></a> <b>Problem</b> 1.2. </span>Replace “<img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" />” in Theorem <a href="#x1-7002r7">1.7<!--tex4ht:ref: thm:hierarchy-circuits-cn --></a> with “<img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c" class="latex" />.”</p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-9003r3"></a> <b>Problem</b> 1.3. </span>Prove that <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%5E%7Bi%7D1%5E%7Bi%7D%3Ai%5Cge+0%5C%7D%5Cin+%5Ctext+%7BTM-Time%5Censuremath+%7B%28cn%5Clog+n%29%5Csetminus+%5Ctext+%7BTM-Time%7D%28n%29%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%5E%7Bi%7D1%5E%7Bi%7D%3Ai%5Cge+0%5C%7D%5Cin+%5Ctext+%7BTM-Time%5Censuremath+%7B%28cn%5Clog+n%29%5Csetminus+%5Ctext+%7BTM-Time%7D%28n%29%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%5E%7Bi%7D1%5E%7Bi%7D%3Ai%5Cge+0%5C%7D%5Cin+%5Ctext+%7BTM-Time%5Censuremath+%7B%28cn%5Clog+n%29%5Csetminus+%5Ctext+%7BTM-Time%7D%28n%29%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0^{i}1^{i}:i&#92;ge 0&#92;}&#92;in &#92;text {TM-Time&#92;ensuremath {(cn&#92;log n)&#92;setminus &#92;text {TM-Time}(n)}.}" class="latex" /></p>
<p style="text-align: justify">This shows Theorem <a href="#x1-6001r5">1.5<!--tex4ht:ref: thm:TIMEonlogn=00003Dregular --></a> is tight, and gives an explicit problem witnessing the time-hierarchy separation in Theorem <a href="#x1-5003r4">1.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>, for a specific time bound. For the negative result, don’t use pumping lemmas or other characterization results not covered in this book.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-9004r4"></a> <b>Problem</b> 1.4. </span>The following argument contradicts Theorem <a href="#x1-5003r4">1.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>; what is wrong with it?</p>
<p style="text-align: justify">“By Theorem <a href="#x1-6001r5">1.5<!--tex4ht:ref: thm:TIMEonlogn=00003Dregular --></a>, <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B0.9%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B0.9%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B0.9%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(n&#92;log ^{0.9}n)=&#92;text {TM-Time}(n)" class="latex" />. By padding (Theorem <a href="#x1-6001r5">1.5<!--tex4ht:ref: thm:TIMEonlogn=00003Dregular --></a>), <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B1.1%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B0.9%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B1.1%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B0.9%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B1.1%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B0.9%7Dn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(n&#92;log ^{1.1}n)=&#92;text {TM-Time}(n&#92;log ^{0.9}n)" class="latex" />. Hence <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B1.1%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B1.1%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5Clog+%5E%7B1.1%7Dn%29%3D%5Ctext+%7BTM-Time%7D%28n%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(n&#92;log ^{1.1}n)=&#92;text {TM-Time}(n)." class="latex" />”</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<h3 class="likesectionHead"><a id="x1-100001.5"></a>References</h3>
<p style="text-align: justify">
<div class="thebibliography">
<p class="bibitem"><span class="biblabel"> [1]<span class="bibsp">   </span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F. C. Hennie. One-tape, off-line turing machine computations. Information and Control, 8(6):553–578, 1965.</p>
<p class="bibitem"><span class="biblabel"> [2]<span class="bibsp">   </span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi. On the structure of one-tape nondeterministic turing machine time hierarchy. Theor. Comput. Sci., 40:175–193, 1985.</p>
<p class="bibitem"><span class="biblabel"> [3]<span class="bibsp">   </span></span><a id="XMR29860"></a>Claude E. Shannon. The synthesis of two-terminal switching circuits. Bell System Tech. J., 28:59–98, 1949.</p>
<p class="bibitem"><span class="biblabel"> [4]<span class="bibsp">   </span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert R. Meyer. Cosmological lower bound on the circuit complexity of a small problem in logic. J. ACM, 49(6):753–784, 2002.</p>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T13:17:45Z">Thursday, February 02 2023, 13:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/02/professor-in-theoretical-computer-science-at-the-university-of-melbourne-apply-by-february-12-2023/'>Professor in Theoretical Computer Science at The University of Melbourne (apply by February 12, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The University of Melbourne is seeking an outstanding academic with expertise in Theoretical Computer Science to join an internationally recognised group of academics within the School of Computing and Information Systems in the Faculty of Engineering and Information Technology. We are seeking to appoint at the Full Professor level. The University is an equal opportunity [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The University of Melbourne is seeking an outstanding academic with expertise in Theoretical Computer Science to join an internationally recognised group of academics within the School of Computing and Information Systems in the Faculty of Engineering and Information Technology. We are seeking to appoint at the Full Professor level. The University is an equal opportunity employer.</p>
<p>Website: <a href="https://jobs.unimelb.edu.au/en/job/911413/professor-in-theoretical-computing-science">https://jobs.unimelb.edu.au/en/job/911413/professor-in-theoretical-computing-science</a><br />
Email: awirth@unimelb.edu.au</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T06:58:22Z">Thursday, February 02 2023, 06:58</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00273'>Hardness of braided quantum circuit optimization in the surface code</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kunihiro Wasa, Shin Nishio, Koki Suetsugu, Michael Hanks, Ashley Stephens, Yu Yokoi, Kae Nemoto</p><p>Large-scale quantum information processing requires the use of quantum error
correcting codes to mitigate the effects of noise in quantum devices.
Topological error-correcting codes, such as surface codes, are promising
candidates as they can be implemented using only local interactions in a
two-dimensional array of physical qubits. Procedures such as defect braiding
and lattice surgery can then be used to realize a fault-tolerant universal set
of gates on the logical space of such topological codes. However, error
correction also introduces a significant overhead in computation time, the
number of physical qubits, and the number of physical gates. While optimizing
fault-tolerant circuits to minimize this overhead is critical, the
computational complexity of such optimization problems remains unknown. This
ambiguity leaves room for doubt surrounding the most effective methods for
compiling fault-tolerant circuits for a large-scale quantum computer. In this
paper, we show that the optimization of a special subset of braided quantum
circuits is NP-hard by a polynomial-time reduction of the optimization problem
into a specific problem called Planar Rectilinear 3SAT.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Wasa_K/0/1/0/all/0/1">Kunihiro Wasa</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nishio_S/0/1/0/all/0/1">Shin Nishio</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Suetsugu_K/0/1/0/all/0/1">Koki Suetsugu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hanks_M/0/1/0/all/0/1">Michael Hanks</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Stephens_A/0/1/0/all/0/1">Ashley Stephens</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yokoi_Y/0/1/0/all/0/1">Yu Yokoi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nemoto_K/0/1/0/all/0/1">Kae Nemoto</a></p><p>Large-scale quantum information processing requires the use of quantum error
correcting codes to mitigate the effects of noise in quantum devices.
Topological error-correcting codes, such as surface codes, are promising
candidates as they can be implemented using only local interactions in a
two-dimensional array of physical qubits. Procedures such as defect braiding
and lattice surgery can then be used to realize a fault-tolerant universal set
of gates on the logical space of such topological codes. However, error
correction also introduces a significant overhead in computation time, the
number of physical qubits, and the number of physical gates. While optimizing
fault-tolerant circuits to minimize this overhead is critical, the
computational complexity of such optimization problems remains unknown. This
ambiguity leaves room for doubt surrounding the most effective methods for
compiling fault-tolerant circuits for a large-scale quantum computer. In this
paper, we show that the optimization of a special subset of braided quantum
circuits is NP-hard by a polynomial-time reduction of the optimization problem
into a specific problem called Planar Rectilinear 3SAT.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00541'>Parameterized Complexity of Weighted Team Definability</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Juha Kontinen, Yasir Mahmood, Arne Meier, Heribert Vollmer</p><p>In this article, we study the complexity of weighted team definability for
logics with team semantics. This problem is a natural analogue of one of the
most studied problems in parameterized complexity, the notion of weighted
Fagin-definability, which is formulated in terms of satisfaction of first-order
formulas with free relation variables. We focus on the parameterized complexity
of weighted team definability for a fixed formula phi of central team-based
logics. Given a first-order structure A and the parameter value k as input, the
question is to determine whether A,T models phi for some team T of size k. We
show several results on the complexity of this problem for dependence,
independence, and inclusion logic formulas. Moreover, we also relate the
complexity of weighted team definability to the complexity classes in the
well-known W-hierarchy as well as paraNP.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kontinen_J/0/1/0/all/0/1">Juha Kontinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_Y/0/1/0/all/0/1">Yasir Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Meier_A/0/1/0/all/0/1">Arne Meier</a>, <a href="http://arxiv.org/find/cs/1/au:+Vollmer_H/0/1/0/all/0/1">Heribert Vollmer</a></p><p>In this article, we study the complexity of weighted team definability for
logics with team semantics. This problem is a natural analogue of one of the
most studied problems in parameterized complexity, the notion of weighted
Fagin-definability, which is formulated in terms of satisfaction of first-order
formulas with free relation variables. We focus on the parameterized complexity
of weighted team definability for a fixed formula phi of central team-based
logics. Given a first-order structure A and the parameter value k as input, the
question is to determine whether A,T models phi for some team T of size k. We
show several results on the complexity of this problem for dependence,
independence, and inclusion logic formulas. Moreover, we also relate the
complexity of weighted team definability to the complexity classes in the
well-known W-hierarchy as well as paraNP.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00573'>An automated, geometry-based method for the analysis of hippocampal thickness</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kersten Diers, Hannah Baumeister, Frank Jessen, Emrah D&#xfc;zel, David Berron, Martin Reuter</p><p>The hippocampus is one of the most studied neuroanatomical structures due to
its involvement in attention, learning, and memory as well as its atrophy in
ageing, neurological, and psychiatric diseases. Hippocampal shape changes,
however, are complex and cannot be fully characterized by a single summary
metric such as hippocampal volume as determined from MR images. In this work,
we propose an automated, geometry-based approach for the unfolding, point-wise
correspondence, and local analysis of hippocampal shape features such as
thickness and curvature. Starting from an automated segmentation of hippocampal
subfields, we create a 3D tetrahedral mesh model as well as a 3D intrinsic
coordinate system of the hippocampal body. From this coordinate system, we
derive local curvature and thickness estimates as well as a 2D sheet for
hippocampal unfolding. We evaluate the performance of our algorithm with a
series of experiments to quantify neurodegenerative changes in Mild Cognitive
Impairment and Alzheimer's disease dementia. We find that hippocampal thickness
estimates detect known differences between clinical groups and can determine
the location of these effects on the hippocampal sheet. Further, thickness
estimates improve classification of clinical groups and cognitively unimpaired
controls when added as an additional predictor. Comparable results are obtained
with different datasets and segmentation algorithms. Taken together, we
replicate canonical findings on hippocampal volume/shape changes in dementia,
extend them by gaining insight into their spatial localization on the
hippocampal sheet, and provide additional, complementary information beyond
traditional measures. We provide a new set of sensitive processing and analysis
tools for the analysis of hippocampal geometry that allows comparisons across
studies without relying on image registration or requiring manual intervention.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Diers_K/0/1/0/all/0/1">Kersten Diers</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumeister_H/0/1/0/all/0/1">Hannah Baumeister</a>, <a href="http://arxiv.org/find/cs/1/au:+Jessen_F/0/1/0/all/0/1">Frank Jessen</a>, <a href="http://arxiv.org/find/cs/1/au:+Duzel_E/0/1/0/all/0/1">Emrah D&#xfc;zel</a>, <a href="http://arxiv.org/find/cs/1/au:+Berron_D/0/1/0/all/0/1">David Berron</a>, <a href="http://arxiv.org/find/cs/1/au:+Reuter_M/0/1/0/all/0/1">Martin Reuter</a></p><p>The hippocampus is one of the most studied neuroanatomical structures due to
its involvement in attention, learning, and memory as well as its atrophy in
ageing, neurological, and psychiatric diseases. Hippocampal shape changes,
however, are complex and cannot be fully characterized by a single summary
metric such as hippocampal volume as determined from MR images. In this work,
we propose an automated, geometry-based approach for the unfolding, point-wise
correspondence, and local analysis of hippocampal shape features such as
thickness and curvature. Starting from an automated segmentation of hippocampal
subfields, we create a 3D tetrahedral mesh model as well as a 3D intrinsic
coordinate system of the hippocampal body. From this coordinate system, we
derive local curvature and thickness estimates as well as a 2D sheet for
hippocampal unfolding. We evaluate the performance of our algorithm with a
series of experiments to quantify neurodegenerative changes in Mild Cognitive
Impairment and Alzheimer's disease dementia. We find that hippocampal thickness
estimates detect known differences between clinical groups and can determine
the location of these effects on the hippocampal sheet. Further, thickness
estimates improve classification of clinical groups and cognitively unimpaired
controls when added as an additional predictor. Comparable results are obtained
with different datasets and segmentation algorithms. Taken together, we
replicate canonical findings on hippocampal volume/shape changes in dementia,
extend them by gaining insight into their spatial localization on the
hippocampal sheet, and provide additional, complementary information beyond
traditional measures. We provide a new set of sensitive processing and analysis
tools for the analysis of hippocampal geometry that allows comparisons across
studies without relying on image registration or requiring manual intervention.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00360'>Faster maximal clique enumeration in large real-world link streams</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexis Baudin, Cl&#xe9;mence Magnien, Lionel Tabourier</p><p>Link streams offer a good model for representing interactions over time. They
consist of links $(b,e,u,v)$, where $u$ and $v$ are vertices interacting during
the whole time interval $[b,e]$. In this paper, we deal with the problem of
enumerating maximal cliques in link streams. A clique is a pair
$(C,[t_0,t_1])$, where $C$ is a set of vertices that all interact pairwise
during the full interval $[t_0,t_1]$. It is maximal when neither its set of
vertices nor its time interval can be increased. Some of the main works solving
this problem are based on the famous Bron-Kerbosch algorithm for enumerating
maximal cliques in graphs. We take this idea as a starting point to propose a
new algorithm which matches the cliques of the instantaneous graphs formed by
links existing at a given time $t$ to the maximal cliques of the link stream.
We prove its validity and compute its complexity, which is better than the
state-of-the art ones in many cases of interest. We also study the
output-sensitive complexity, which is close to the output size, thereby showing
that our algorithm is efficient. To confirm this, we perform experiments on
link streams used in the state of the art, and on massive link streams, up to
100 million links. In all cases our algorithm is faster, mostly by a factor of
at least 10 and up to a factor of $10^4$. Moreover, it scales to massive link
streams for which the existing algorithms are not able to provide the solution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Baudin_A/0/1/0/all/0/1">Alexis Baudin</a>, <a href="http://arxiv.org/find/cs/1/au:+Magnien_C/0/1/0/all/0/1">Cl&#xe9;mence Magnien</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabourier_L/0/1/0/all/0/1">Lionel Tabourier</a></p><p>Link streams offer a good model for representing interactions over time. They
consist of links $(b,e,u,v)$, where $u$ and $v$ are vertices interacting during
the whole time interval $[b,e]$. In this paper, we deal with the problem of
enumerating maximal cliques in link streams. A clique is a pair
$(C,[t_0,t_1])$, where $C$ is a set of vertices that all interact pairwise
during the full interval $[t_0,t_1]$. It is maximal when neither its set of
vertices nor its time interval can be increased. Some of the main works solving
this problem are based on the famous Bron-Kerbosch algorithm for enumerating
maximal cliques in graphs. We take this idea as a starting point to propose a
new algorithm which matches the cliques of the instantaneous graphs formed by
links existing at a given time $t$ to the maximal cliques of the link stream.
We prove its validity and compute its complexity, which is better than the
state-of-the art ones in many cases of interest. We also study the
output-sensitive complexity, which is close to the output size, thereby showing
that our algorithm is efficient. To confirm this, we perform experiments on
link streams used in the state of the art, and on massive link streams, up to
100 million links. In all cases our algorithm is faster, mostly by a factor of
at least 10 and up to a factor of $10^4$. Moreover, it scales to massive link
streams for which the existing algorithms are not able to provide the solution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00025'>On the Within-Group Discrimination of Screening Classifiers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nastaran Okati, Stratis Tsirtsis, Manuel Gomez Rodriguez</p><p>Screening classifiers are increasingly used to identify qualified candidates
in a variety of selection processes. In this context, it has been recently
shown that, if a classifier is calibrated, one can identify the smallest set of
candidates which contains, in expectation, a desired number of qualified
candidates using a threshold decision rule. This lends support to focusing on
calibration as the only requirement for screening classifiers. In this paper,
we argue that screening policies that use calibrated classifiers may suffer
from an understudied type of within-group discrimination -- they may
discriminate against qualified members within demographic groups of interest.
Further, we argue that this type of discrimination can be avoided if
classifiers satisfy within-group monotonicity, a natural monotonicity property
within each of the groups. Then, we introduce an efficient post-processing
algorithm based on dynamic programming to minimally modify a given calibrated
classifier so that its probability estimates satisfy within-group monotonicity.
We validate our algorithm using US Census survey data and show that
within-group monotonicity can be often achieved at a small cost in terms of
prediction granularity and shortlist size.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Okati_N/0/1/0/all/0/1">Nastaran Okati</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsirtsis_S/0/1/0/all/0/1">Stratis Tsirtsis</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_M/0/1/0/all/0/1">Manuel Gomez Rodriguez</a></p><p>Screening classifiers are increasingly used to identify qualified candidates
in a variety of selection processes. In this context, it has been recently
shown that, if a classifier is calibrated, one can identify the smallest set of
candidates which contains, in expectation, a desired number of qualified
candidates using a threshold decision rule. This lends support to focusing on
calibration as the only requirement for screening classifiers. In this paper,
we argue that screening policies that use calibrated classifiers may suffer
from an understudied type of within-group discrimination -- they may
discriminate against qualified members within demographic groups of interest.
Further, we argue that this type of discrimination can be avoided if
classifiers satisfy within-group monotonicity, a natural monotonicity property
within each of the groups. Then, we introduce an efficient post-processing
algorithm based on dynamic programming to minimally modify a given calibrated
classifier so that its probability estimates satisfy within-group monotonicity.
We validate our algorithm using US Census survey data and show that
within-group monotonicity can be often achieved at a small cost in terms of
prediction granularity and shortlist size.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00037'>Differentially-Private Hierarchical Clustering with Provable Approximation Guarantees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jacob Imola, Alessandro Epasto, Mohammad Mahdian, Vincent Cohen-Addad, Vahab Mirrokni</p><p>Hierarchical Clustering is a popular unsupervised machine learning method
with decades of history and numerous applications. We initiate the study of
differentially private approximation algorithms for hierarchical clustering
under the rigorous framework introduced by (Dasgupta, 2016). We show strong
lower bounds for the problem: that any $\epsilon$-DP algorithm must exhibit
$O(|V|^2/ \epsilon)$-additive error for an input dataset $V$. Then, we exhibit
a polynomial-time approximation algorithm with $O(|V|^{2.5}/
\epsilon)$-additive error, and an exponential-time algorithm that meets the
lower bound. To overcome the lower bound, we focus on the stochastic block
model, a popular model of graphs, and, with a separation assumption on the
blocks, propose a private $1+o(1)$ approximation algorithm which also recovers
the blocks exactly. Finally, we perform an empirical study of our algorithms
and validate their performance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Imola_J/0/1/0/all/0/1">Jacob Imola</a>, <a href="http://arxiv.org/find/cs/1/au:+Epasto_A/0/1/0/all/0/1">Alessandro Epasto</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahdian_M/0/1/0/all/0/1">Mohammad Mahdian</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1">Vincent Cohen-Addad</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a></p><p>Hierarchical Clustering is a popular unsupervised machine learning method
with decades of history and numerous applications. We initiate the study of
differentially private approximation algorithms for hierarchical clustering
under the rigorous framework introduced by (Dasgupta, 2016). We show strong
lower bounds for the problem: that any $\epsilon$-DP algorithm must exhibit
$O(|V|^2/ \epsilon)$-additive error for an input dataset $V$. Then, we exhibit
a polynomial-time approximation algorithm with $O(|V|^{2.5}/
\epsilon)$-additive error, and an exponential-time algorithm that meets the
lower bound. To overcome the lower bound, we focus on the stochastic block
model, a popular model of graphs, and, with a separation assumption on the
blocks, propose a private $1+o(1)$ approximation algorithm which also recovers
the blocks exactly. Finally, we perform an empirical study of our algorithms
and validate their performance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00052'>Exploring Wedges of an Oriented Grid by an Automaton with Pebbles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Subhash Bhagat, Andrzej Pelc</p><p>A mobile agent, modeled as a deterministic finite automaton, navigates in the
infinite anonymous oriented grid $\mathbb{Z} \times \mathbb{Z}$. It has to
explore a given infinite subgraph of the grid by visiting all of its nodes. We
focus on the simplest subgraphs, called {\em wedges}, spanned by all nodes of
the grid located between two half-lines in the plane, with a common origin.
Many wedges turn out to be impossible to explore by an automaton that cannot
mark nodes of the grid. Hence, we study the following question: Given a wedge
$W$, what is the smallest number $p$ of (movable) pebbles for which there
exists an automaton that can explore $W$ using $p$ pebbles? Our main
contribution is a complete solution of this problem. For each wedge $W$ we
determine this minimum number $p$, show an automaton that explores it using $p$
pebbles and show that fewer pebbles are not enough. We show that this smallest
number of pebbles can vary from 0 to 3, depending on the angle between
half-lines limiting the wedge and depending on whether the automaton can cross
these half-lines or not.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhagat_S/0/1/0/all/0/1">Subhash Bhagat</a>, <a href="http://arxiv.org/find/cs/1/au:+Pelc_A/0/1/0/all/0/1">Andrzej Pelc</a></p><p>A mobile agent, modeled as a deterministic finite automaton, navigates in the
infinite anonymous oriented grid $\mathbb{Z} \times \mathbb{Z}$. It has to
explore a given infinite subgraph of the grid by visiting all of its nodes. We
focus on the simplest subgraphs, called {\em wedges}, spanned by all nodes of
the grid located between two half-lines in the plane, with a common origin.
Many wedges turn out to be impossible to explore by an automaton that cannot
mark nodes of the grid. Hence, we study the following question: Given a wedge
$W$, what is the smallest number $p$ of (movable) pebbles for which there
exists an automaton that can explore $W$ using $p$ pebbles? Our main
contribution is a complete solution of this problem. For each wedge $W$ we
determine this minimum number $p$, show an automaton that explores it using $p$
pebbles and show that fewer pebbles are not enough. We show that this smallest
number of pebbles can vary from 0 to 3, depending on the angle between
half-lines limiting the wedge and depending on whether the automaton can cross
these half-lines or not.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00112'>Adding an Edge in a $P_4$-sparse Graph</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anna Mpanti, Stavros D. Nikolopoulos, Leonidas Palios</p><p>The minimum completion (fill-in) problem is defined as follows: Given a graph
family $\mathcal{F}$ (more generally, a property $\Pi$) and a graph $G$, the
completion problem asks for the minimum number of non-edges needed to be added
to $G$ so that the resulting graph belongs to the graph family $\mathcal{F}$
(or has property $\Pi$). This problem is NP-complete for many subclasses of
perfect graphs and polynomial solutions are available only for minimal
completion sets. We study the minimum completion problem of a $P_4$-sparse
graph $G$ with an added edge. For any optimal solution of the problem, we prove
that there is an optimal solution whose form is of one of a small number of
possibilities. This along with the solution of the problem when the added edge
connects two non-adjacent vertices of a spider or connects two vertices in
different connected components of the graph enables us to present a
polynomial-time algorithm for the problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mpanti_A/0/1/0/all/0/1">Anna Mpanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikolopoulos_S/0/1/0/all/0/1">Stavros D. Nikolopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Palios_L/0/1/0/all/0/1">Leonidas Palios</a></p><p>The minimum completion (fill-in) problem is defined as follows: Given a graph
family $\mathcal{F}$ (more generally, a property $\Pi$) and a graph $G$, the
completion problem asks for the minimum number of non-edges needed to be added
to $G$ so that the resulting graph belongs to the graph family $\mathcal{F}$
(or has property $\Pi$). This problem is NP-complete for many subclasses of
perfect graphs and polynomial solutions are available only for minimal
completion sets. We study the minimum completion problem of a $P_4$-sparse
graph $G$ with an added edge. For any optimal solution of the problem, we prove
that there is an optimal solution whose form is of one of a small number of
possibilities. This along with the solution of the problem when the added edge
connects two non-adjacent vertices of a spider or connects two vertices in
different connected components of the graph enables us to present a
polynomial-time algorithm for the problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00133'>Sublinear Approximation Schemes for Scheduling Precedence Graphs of Bounded Depth</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bin Fu, Yumei Huo, Hairong Zhao</p><p>We study the classical scheduling problem on parallel machines %with
precedence constraints where the precedence graph has the bounded depth $h$.
Our goal is to minimize the maximum completion time. We focus on developing
approximation algorithms that use only sublinear space or sublinear time. We
develop the first one-pass streaming approximation schemes using sublinear
space when all jobs' processing times differ no more than a constant factor $c$
and the number of machines $m$ is at most $\tfrac {2n \epsilon}{3 h c }$. This
is so far the best approximation we can have in terms of $m$, since no
polynomial time approximation better than $\tfrac{4}{3}$ exists when $m =
\tfrac{n}{3}$ unless P=NP. %the problem cannot be approximated within a factor
of $\tfrac{4}{3}$ when $m = \tfrac{n}{3}$ even if all jobs have equal
processing time. The algorithms are then extended to the more general problem
where the largest $\alpha n$ jobs have no more than $c$ factor difference. %
for some constant $0 &lt; \alpha \le 1$. We also develop the first sublinear time
algorithms for both problems. For the more general problem, when $ m \le \tfrac
{ \alpha n \epsilon}{20 c^2 \cdot h } $, our algorithm is a randomized
$(1+\epsilon)$-approximation scheme that runs in sublinear time. This work not
only provides an algorithmic solution to the studied problem under big data %
and cloud computing environment, but also gives a methodological framework for
designing sublinear approximation algorithms for other scheduling problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fu_B/0/1/0/all/0/1">Bin Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1">Yumei Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hairong Zhao</a></p><p>We study the classical scheduling problem on parallel machines %with
precedence constraints where the precedence graph has the bounded depth $h$.
Our goal is to minimize the maximum completion time. We focus on developing
approximation algorithms that use only sublinear space or sublinear time. We
develop the first one-pass streaming approximation schemes using sublinear
space when all jobs' processing times differ no more than a constant factor $c$
and the number of machines $m$ is at most $\tfrac {2n \epsilon}{3 h c }$. This
is so far the best approximation we can have in terms of $m$, since no
polynomial time approximation better than $\tfrac{4}{3}$ exists when $m =
\tfrac{n}{3}$ unless P=NP. %the problem cannot be approximated within a factor
of $\tfrac{4}{3}$ when $m = \tfrac{n}{3}$ even if all jobs have equal
processing time. The algorithms are then extended to the more general problem
where the largest $\alpha n$ jobs have no more than $c$ factor difference. %
for some constant $0 &lt; \alpha \le 1$. We also develop the first sublinear time
algorithms for both problems. For the more general problem, when $ m \le \tfrac
{ \alpha n \epsilon}{20 c^2 \cdot h } $, our algorithm is a randomized
$(1+\epsilon)$-approximation scheme that runs in sublinear time. This work not
only provides an algorithmic solution to the studied problem under big data %
and cloud computing environment, but also gives a methodological framework for
designing sublinear approximation algorithms for other scheduling problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00135'>Durable Algorithms for Writable LL/SC and CAS with Dynamic Joining</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prasad Jayanti, Siddhartha Jayanti, Sucharita Jayanti</p><p>We present durable implementations for two well known universal primitives --
CAS (compare-and-swap), and its ABA-free counter-part LLSC (load-linked,
store-conditional). All our implementations are: writable, meaning they support
a Write() operation; have constant time complexity per operation; allow for
dynamic joining, meaning newly created processes (a.k.a. threads) of arbitrary
names can join a protocol and access our implementations; and have adaptive
space complexities, meaning the space use scales in the number of processes $n$
that actually use the objects, as opposed to previous protocols which are
designed for a maximum number of processes $N$. Our durable Writable-CAS
implementation, DuraCAS, requires $O(m + n)$ space to support $m$ objects that
get accessed by $n$ processes, improving on the state-of-the-art $O(m + N^2)$.
By definition, LLSC objects must store "contexts" in addition to object values.
Our Writable-LLSC implementation, DuraLL, requires $O(m + n + C)$ space, where
$C$ is the number of "contexts" stored across all the objects. While LLSC has
an advantage over CAS due to being ABA-free, the object definition seems to
require additional space usage. To address this trade-off, we define an
External Context (EC) variant of LLSC. Our EC Writable-LLSC implementation is
ABA-free and has a space complexity of just $O(m + n)$.
</p>
<p>To our knowledge, we are the first to present durable CAS algorithms that
allow for dynamic joining, and our algorithms are the first to exhibit adaptive
space complexities. To our knowledge, we are the first to implement any type of
durable LLSC objects.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jayanti_P/0/1/0/all/0/1">Prasad Jayanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayanti_S/0/1/0/all/0/1">Siddhartha Jayanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayanti_S/0/1/0/all/0/1">Sucharita Jayanti</a></p><p>We present durable implementations for two well known universal primitives --
CAS (compare-and-swap), and its ABA-free counter-part LLSC (load-linked,
store-conditional). All our implementations are: writable, meaning they support
a Write() operation; have constant time complexity per operation; allow for
dynamic joining, meaning newly created processes (a.k.a. threads) of arbitrary
names can join a protocol and access our implementations; and have adaptive
space complexities, meaning the space use scales in the number of processes $n$
that actually use the objects, as opposed to previous protocols which are
designed for a maximum number of processes $N$. Our durable Writable-CAS
implementation, DuraCAS, requires $O(m + n)$ space to support $m$ objects that
get accessed by $n$ processes, improving on the state-of-the-art $O(m + N^2)$.
By definition, LLSC objects must store "contexts" in addition to object values.
Our Writable-LLSC implementation, DuraLL, requires $O(m + n + C)$ space, where
$C$ is the number of "contexts" stored across all the objects. While LLSC has
an advantage over CAS due to being ABA-free, the object definition seems to
require additional space usage. To address this trade-off, we define an
External Context (EC) variant of LLSC. Our EC Writable-LLSC implementation is
ABA-free and has a space complexity of just $O(m + n)$.
</p>
<p>To our knowledge, we are the first to present durable CAS algorithms that
allow for dynamic joining, and our algorithms are the first to exhibit adaptive
space complexities. To our knowledge, we are the first to implement any type of
durable LLSC objects.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00213'>Approximating Red-Blue Set Cover</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eden Chlamt&#xe1;&#x10d;, Yury Makarychev, Ali Vakilian</p><p>We provide a new approximation algorithm for the Red-Blue Set Cover problem
and give a new hardness result. Our approximation algorithm achieves $\tilde
O(m^{1/3})$-approximation improving on the $\tilde O(m^{1/2})$-approximation
due to Elkin and Peleg (where $m$ is the number of sets). Additionally, we
provide a nearly approximation preserving reduction from Min $k$-Union to
Red-Blue Set Cover that gives an $\tilde\Omega(m^{1/4 - \varepsilon})$ hardness
under the Dense-vs-Random conjecture.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chlamtac_E/0/1/0/all/0/1">Eden Chlamt&#xe1;&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarychev_Y/0/1/0/all/0/1">Yury Makarychev</a>, <a href="http://arxiv.org/find/cs/1/au:+Vakilian_A/0/1/0/all/0/1">Ali Vakilian</a></p><p>We provide a new approximation algorithm for the Red-Blue Set Cover problem
and give a new hardness result. Our approximation algorithm achieves $\tilde
O(m^{1/3})$-approximation improving on the $\tilde O(m^{1/2})$-approximation
due to Elkin and Peleg (where $m$ is the number of sets). Additionally, we
provide a nearly approximation preserving reduction from Min $k$-Union to
Red-Blue Set Cover that gives an $\tilde\Omega(m^{1/4 - \varepsilon})$ hardness
under the Dense-vs-Random conjecture.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00248'>A Nearly-Optimal Bound for Fast Regression with $\ell_\infty$ Guarantee</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhao Song, Mingquan Ye, Junze Yin, Lichen Zhang</p><p>Given a matrix $A\in \mathbb{R}^{n\times d}$ and a vector $b\in
\mathbb{R}^n$, we consider the regression problem with $\ell_\infty$
guarantees: finding a vector $x'\in \mathbb{R}^d$ such that $ \|x'-x^*\|_\infty
\leq \frac{\epsilon}{\sqrt{d}}\cdot \|Ax^*-b\|_2\cdot \|A^\dagger\|$ where
$x^*=\arg\min_{x\in \mathbb{R}^d}\|Ax-b\|_2$. One popular approach for solving
such $\ell_2$ regression problem is via sketching: picking a structured random
matrix $S\in \mathbb{R}^{m\times n}$ with $m\ll n$ and $SA$ can be quickly
computed, solve the ``sketched'' regression problem $\arg\min_{x\in
\mathbb{R}^d} \|SAx-Sb\|_2$. In this paper, we show that in order to obtain
such $\ell_\infty$ guarantee for $\ell_2$ regression, one has to use sketching
matrices that are dense. To the best of our knowledge, this is the first user
case in which dense sketching matrices are necessary. On the algorithmic side,
we prove that there exists a distribution of dense sketching matrices with
$m=\epsilon^{-2}d\log^3(n/\delta)$ such that solving the sketched regression
problem gives the $\ell_\infty$ guarantee, with probability at least
$1-\delta$. Moreover, the matrix $SA$ can be computed in time $O(nd\log n)$.
Our row count is nearly-optimal up to logarithmic factors, and significantly
improves the result in [Price, Song and Woodruff, ICALP'17], in which a
super-linear in $d$ rows, $m=\Omega(\epsilon^{-2}d^{1+\gamma})$ for
$\gamma=\Theta(\sqrt{\frac{\log\log n}{\log d}})$ is required. We also develop
a novel analytical framework for $\ell_\infty$ guarantee regression that
utilizes the Oblivious Coordinate-wise Embedding (OCE) property introduced in
[Song and Yu, ICML'21]. Our analysis is arguably much simpler and more general
than [Price, Song and Woodruff, ICALP'17], and it extends to dense sketches for
tensor product of vectors.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Mingquan Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1">Junze Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lichen Zhang</a></p><p>Given a matrix $A\in \mathbb{R}^{n\times d}$ and a vector $b\in
\mathbb{R}^n$, we consider the regression problem with $\ell_\infty$
guarantees: finding a vector $x'\in \mathbb{R}^d$ such that $ \|x'-x^*\|_\infty
\leq \frac{\epsilon}{\sqrt{d}}\cdot \|Ax^*-b\|_2\cdot \|A^\dagger\|$ where
$x^*=\arg\min_{x\in \mathbb{R}^d}\|Ax-b\|_2$. One popular approach for solving
such $\ell_2$ regression problem is via sketching: picking a structured random
matrix $S\in \mathbb{R}^{m\times n}$ with $m\ll n$ and $SA$ can be quickly
computed, solve the ``sketched'' regression problem $\arg\min_{x\in
\mathbb{R}^d} \|SAx-Sb\|_2$. In this paper, we show that in order to obtain
such $\ell_\infty$ guarantee for $\ell_2$ regression, one has to use sketching
matrices that are dense. To the best of our knowledge, this is the first user
case in which dense sketching matrices are necessary. On the algorithmic side,
we prove that there exists a distribution of dense sketching matrices with
$m=\epsilon^{-2}d\log^3(n/\delta)$ such that solving the sketched regression
problem gives the $\ell_\infty$ guarantee, with probability at least
$1-\delta$. Moreover, the matrix $SA$ can be computed in time $O(nd\log n)$.
Our row count is nearly-optimal up to logarithmic factors, and significantly
improves the result in [Price, Song and Woodruff, ICALP'17], in which a
super-linear in $d$ rows, $m=\Omega(\epsilon^{-2}d^{1+\gamma})$ for
$\gamma=\Theta(\sqrt{\frac{\log\log n}{\log d}})$ is required. We also develop
a novel analytical framework for $\ell_\infty$ guarantee regression that
utilizes the Oblivious Coordinate-wise Embedding (OCE) property introduced in
[Song and Yu, ICML'21]. Our analysis is arguably much simpler and more general
than [Price, Song and Woodruff, ICALP'17], and it extends to dense sketches for
tensor product of vectors.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00352'>Flip-width: Cops and Robber on dense graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Symon Toru&#x144;czyk</p><p>We define new graph parameters that generalize tree-width, degeneracy, and
generalized coloring numbers for sparse graphs, and clique-width and twin-width
for dense graphs. Those parameters are defined using variants of the Cops and
Robber game, in which the robber has speed bounded by a fixed constant
$r\in\mathbb N\cup\{\infty\}$, and the cops perform flips (or perturbations) of
the considered graph. We propose a new notion of tameness of a graph class,
called bounded flip-width, which is a dense counterpart of classes of bounded
expansion of Ne\v{s}et\v{r}il and Ossona de Mendez, and includes classes of
bounded twin-width of Bonnet, Kim, Thomass\'e and Watrigant. We prove that
boundedness of flip-width is preserved by first-order interpretations, or
transductions, generalizing previous results concerning classes of bounded
expansion and bounded twin-width. We provide an algorithm approximating the
flip-width of a given graph, which runs in slicewise polynomial time (XP) in
the size of the graph. We also propose a more general notion of tameness,
called almost bounded flip-width, which is a dense counterpart of nowhere dense
classes, and includes all structurally nowhere dense classes. We conjecture,
and provide evidence, that classes with almost bounded flip-width coincide with
monadically dependent classes, introduced by Shelah in model theory.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Torunczyk_S/0/1/0/all/0/1">Symon Toru&#x144;czyk</a></p><p>We define new graph parameters that generalize tree-width, degeneracy, and
generalized coloring numbers for sparse graphs, and clique-width and twin-width
for dense graphs. Those parameters are defined using variants of the Cops and
Robber game, in which the robber has speed bounded by a fixed constant
$r\in\mathbb N\cup\{\infty\}$, and the cops perform flips (or perturbations) of
the considered graph. We propose a new notion of tameness of a graph class,
called bounded flip-width, which is a dense counterpart of classes of bounded
expansion of Ne\v{s}et\v{r}il and Ossona de Mendez, and includes classes of
bounded twin-width of Bonnet, Kim, Thomass\'e and Watrigant. We prove that
boundedness of flip-width is preserved by first-order interpretations, or
transductions, generalizing previous results concerning classes of bounded
expansion and bounded twin-width. We provide an algorithm approximating the
flip-width of a given graph, which runs in slicewise polynomial time (XP) in
the size of the graph. We also propose a more general notion of tameness,
called almost bounded flip-width, which is a dense counterpart of nowhere dense
classes, and includes all structurally nowhere dense classes. We conjecture,
and provide evidence, that classes with almost bounded flip-width coincide with
monadically dependent classes, introduced by Shelah in model theory.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00458'>Improved Exact and Heuristic Algorithms for Maximum Weight Clique</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Roman Erhardt, Kathrin Hanauer, Nils Kriege, Christian Schulz, Darren Strash</p><p>We propose improved exact and heuristic algorithms for solving the maximum
weight clique problem, a well-known problem in graph theory with many
applications. Our algorithms interleave successful techniques from related work
with novel data reduction rules that use local graph structure to identify and
remove vertices and edges while retaining the optimal solution. We evaluate our
algorithms on a range of synthetic and real-world graphs, and find that they
outperform the current state of the art on most inputs. Our data reductions
always produce smaller reduced graphs than existing data reductions alone. As a
result, our exact algorithm, MWCRedu, finds solutions orders of magnitude
faster on naturally weighted, medium-sized map labeling graphs and random
hyperbolic graphs. Our heuristic algorithm, MWCPeel, outperforms its
competitors on these instances, but is slightly less effective on extremely
dense or large instances.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Erhardt_R/0/1/0/all/0/1">Roman Erhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanauer_K/0/1/0/all/0/1">Kathrin Hanauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kriege_N/0/1/0/all/0/1">Nils Kriege</a>, <a href="http://arxiv.org/find/cs/1/au:+Schulz_C/0/1/0/all/0/1">Christian Schulz</a>, <a href="http://arxiv.org/find/cs/1/au:+Strash_D/0/1/0/all/0/1">Darren Strash</a></p><p>We propose improved exact and heuristic algorithms for solving the maximum
weight clique problem, a well-known problem in graph theory with many
applications. Our algorithms interleave successful techniques from related work
with novel data reduction rules that use local graph structure to identify and
remove vertices and edges while retaining the optimal solution. We evaluate our
algorithms on a range of synthetic and real-world graphs, and find that they
outperform the current state of the art on most inputs. Our data reductions
always produce smaller reduced graphs than existing data reductions alone. As a
result, our exact algorithm, MWCRedu, finds solutions orders of magnitude
faster on naturally weighted, medium-sized map labeling graphs and random
hyperbolic graphs. Our heuristic algorithm, MWCPeel, outperforms its
competitors on these instances, but is slightly less effective on extremely
dense or large instances.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00608'>The Investment Management Game: Extending the Scope of the Notion of Core</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vijay V. Vazirani</p><p>The core is a dominant solution concept in economics and game theory. In this
context, the following question arises, ``How versatile is this solution
concept?'' We note that within game theory, this notion has been used for
profit -- equivalently, cost or utility -- sharing only. In this paper, we show
a completely different use for it: in an {\em investment management game},
under which an agent needs to allocate her money among investment firms in such
a way that {\em in each of exponentially many future scenarios}, sufficient
money is available in the ``right'' firms so she can buy an ``optimal
investment'' for that scenario.
</p>
<p>We study a restriction of this game to {\em perfect graphs} and characterize
its core. Our characterization is analogous to Shapley and Shubik's
characterization of the core of the assignment game. The difference is the
following: whereas their characterization follows from {\em total
unimodularity}, ours follows from {\em total dual integrality}. The latter is
another novelty of our work.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/econ/1/au:+Vazirani_V/0/1/0/all/0/1">Vijay V. Vazirani</a></p><p>The core is a dominant solution concept in economics and game theory. In this
context, the following question arises, ``How versatile is this solution
concept?'' We note that within game theory, this notion has been used for
profit -- equivalently, cost or utility -- sharing only. In this paper, we show
a completely different use for it: in an {\em investment management game},
under which an agent needs to allocate her money among investment firms in such
a way that {\em in each of exponentially many future scenarios}, sufficient
money is available in the ``right'' firms so she can buy an ``optimal
investment'' for that scenario.
</p>
<p>We study a restriction of this game to {\em perfect graphs} and characterize
its core. Our characterization is analogous to Shapley and Shubik's
characterization of the core of the assignment game. The difference is the
following: whereas their characterization follows from {\em total
unimodularity}, ours follows from {\em total dual integrality}. The latter is
another novelty of our work.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00630'>Parameterized Algorithms for Colored Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Leon Kellerhals, Tomohiro Koana, Pascal Kunz, Rolf Niedermeier</p><p>In the Colored Clustering problem, one is asked to cluster edge-colored
(hyper-)graphs whose colors represent interaction types. More specifically, the
goal is to select as many edges as possible without choosing two edges that
share an endpoint and are colored differently. Equivalently, the goal can also
be described as assigning colors to the vertices in a way that fits the
edge-coloring as well as possible. As this problem is NP-hard, we build on
previous work by studying its parameterized complexity. We give a $2^{\mathcal
O(k)} \cdot n^{\mathcal O(1)}$-time algorithm where $k$ is the number of edges
to be selected and $n$ the number of vertices. We also prove the existence of a
problem kernel of size $\mathcal O(k^{5/2} )$, resolving an open problem posed
in the literature. We consider parameters that are smaller than $k$, the number
of edges to be selected, and $r$, the number of edges that can be deleted. Such
smaller parameters are obtained by considering the difference between $k$ or
$r$ and some lower bound on these values. We give both algorithms and lower
bounds for Colored Clustering with such parameterizations. Finally, we settle
the parameterized complexity of Colored Clustering with respect to structural
graph parameters by showing that it is $W[1]$-hard with respect to both vertex
cover number and tree-cut width, but fixed-parameter tractable with respect to
slim tree-cut width.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kellerhals_L/0/1/0/all/0/1">Leon Kellerhals</a>, <a href="http://arxiv.org/find/cs/1/au:+Koana_T/0/1/0/all/0/1">Tomohiro Koana</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunz_P/0/1/0/all/0/1">Pascal Kunz</a>, <a href="http://arxiv.org/find/cs/1/au:+Niedermeier_R/0/1/0/all/0/1">Rolf Niedermeier</a></p><p>In the Colored Clustering problem, one is asked to cluster edge-colored
(hyper-)graphs whose colors represent interaction types. More specifically, the
goal is to select as many edges as possible without choosing two edges that
share an endpoint and are colored differently. Equivalently, the goal can also
be described as assigning colors to the vertices in a way that fits the
edge-coloring as well as possible. As this problem is NP-hard, we build on
previous work by studying its parameterized complexity. We give a $2^{\mathcal
O(k)} \cdot n^{\mathcal O(1)}$-time algorithm where $k$ is the number of edges
to be selected and $n$ the number of vertices. We also prove the existence of a
problem kernel of size $\mathcal O(k^{5/2} )$, resolving an open problem posed
in the literature. We consider parameters that are smaller than $k$, the number
of edges to be selected, and $r$, the number of edges that can be deleted. Such
smaller parameters are obtained by considering the difference between $k$ or
$r$ and some lower bound on these values. We give both algorithms and lower
bounds for Colored Clustering with such parameterizations. Finally, we settle
the parameterized complexity of Colored Clustering with respect to structural
graph parameters by showing that it is $W[1]$-hard with respect to both vertex
cover number and tree-cut width, but fixed-parameter tractable with respect to
slim tree-cut width.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00657'>Adding a Tail in Classes of Perfect Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anna Mpanti, Stavros D. Nikolopoulos, Leonidas Palios</p><p>Consider a graph $G$ which belongs to a graph class ${\cal C}$. We are
interested in connecting a node $w \not\in V(G)$ to $G$ by a single edge $u w$
where $u \in V(G)$; we call such an edge a \emph{tail}. As the graph resulting
from $G$ after the addition of the tail, denoted $G+uw$, need not belong to the
class ${\cal C}$, we want to compute a minimum ${\cal C}$-completion of $G+w$,
i.e., the minimum number of non-edges (excluding the tail $u w$) to be added to
$G+uw$ so that the resulting graph belongs to ${\cal C}$. In this paper, we
study this problem for the classes of split, quasi-threshold, threshold, and
$P_4$-sparse graphs and we present linear-time algorithms by exploiting the
structure of split graphs and the tree representation of quasi-threshold,
threshold, and $P_4$-sparse graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mpanti_A/0/1/0/all/0/1">Anna Mpanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikolopoulos_S/0/1/0/all/0/1">Stavros D. Nikolopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Palios_L/0/1/0/all/0/1">Leonidas Palios</a></p><p>Consider a graph $G$ which belongs to a graph class ${\cal C}$. We are
interested in connecting a node $w \not\in V(G)$ to $G$ by a single edge $u w$
where $u \in V(G)$; we call such an edge a \emph{tail}. As the graph resulting
from $G$ after the addition of the tail, denoted $G+uw$, need not belong to the
class ${\cal C}$, we want to compute a minimum ${\cal C}$-completion of $G+w$,
i.e., the minimum number of non-edges (excluding the tail $u w$) to be added to
$G+uw$ so that the resulting graph belongs to ${\cal C}$. In this paper, we
study this problem for the classes of split, quasi-threshold, threshold, and
$P_4$-sparse graphs and we present linear-time algorithms by exploiting the
structure of split graphs and the tree representation of quasi-threshold,
threshold, and $P_4$-sparse graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, February 01
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13224'>Near-perfect Reachability of Variational Quantum Search with Depth-1 Ansatz</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Junpeng Zhan</p><p>Grover's search algorithm is renowned for its dramatic speedup in solving
many important scientific problems. The recently proposed Variational Quantum
Search (VQS) algorithm has shown an exponential advantage over Grover's
algorithm for up to 26 qubits. However, its advantage for larger numbers of
qubits has not yet been proven. Here we show that the exponentially deep
circuit required by Grover's algorithm can be replaced by a multi-controlled
NOT gate together with either a single layer of Ry gates or two layers of
circuits consisting of Hadamard and NOT gates, which is valid for any number of
qubits greater than five. We prove that the VQS, with a single layer of Ry
gates as its Ansatz, has near-perfect reachability in finding the good element
of an arbitrarily large unstructured data set, and its reachability
exponentially improves with the number of qubits, where the reachability is
defined to quantify the ability of a given Ansatz to generate an optimal
quantum state. Numerical studies further validate the excellent reachability of
the VQS. Proving the near-perfect reachability of the VQS, with a depth-1
Ansatz, for any number of qubits completes an essential step in proving its
exponential advantage over Grover's algorithm for any number of qubits, and the
latter proving is significant as it means that the VQS can efficiently solve
NP-complete problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Zhan_J/0/1/0/all/0/1">Junpeng Zhan</a></p><p>Grover's search algorithm is renowned for its dramatic speedup in solving
many important scientific problems. The recently proposed Variational Quantum
Search (VQS) algorithm has shown an exponential advantage over Grover's
algorithm for up to 26 qubits. However, its advantage for larger numbers of
qubits has not yet been proven. Here we show that the exponentially deep
circuit required by Grover's algorithm can be replaced by a multi-controlled
NOT gate together with either a single layer of Ry gates or two layers of
circuits consisting of Hadamard and NOT gates, which is valid for any number of
qubits greater than five. We prove that the VQS, with a single layer of Ry
gates as its Ansatz, has near-perfect reachability in finding the good element
of an arbitrarily large unstructured data set, and its reachability
exponentially improves with the number of qubits, where the reachability is
defined to quantify the ability of a given Ansatz to generate an optimal
quantum state. Numerical studies further validate the excellent reachability of
the VQS. Proving the near-perfect reachability of the VQS, with a depth-1
Ansatz, for any number of qubits completes an essential step in proving its
exponential advantage over Grover's algorithm for any number of qubits, and the
latter proving is significant as it means that the VQS can efficiently solve
NP-complete problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13329'>A Finer Analysis of Multi-Structural Games and Beyond</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marco Carmosino, Ronald Fagin, Neil Immerman, Phokion Kolaitis, Jonathan Lenchner, Rik Sengupta</p><p>Multi-structural (MS) games are combinatorial games that capture the number
of quantifiers of first-order sentences. On the face of their definition, MS
games differ from Ehrenfeucht-Fraisse (EF) games in two ways: first, MS games
are played on two sets of structures, while EF games are played on a pair of
structures; second, in MS games, Duplicator can make any number of copies of
structures. In the first part of this paper, we perform a finer analysis of MS
games and develop a closer comparison of MS games with EF games. In particular,
we point out that the use of sets of structures is of the essence and that when
MS games are played on pairs of structures, they capture Boolean combinations
of first-order sentences with a fixed number of quantifiers. After this, we
focus on another important difference between MS games and EF games, namely,
the necessity for Spoiler to play on top of a previous move in order to win
some MS games. Via an analysis of the types realized during MS games, we
delineate the expressive power of the variant of MS games in which Spoiler
never plays on top of a previous move. In the second part we focus on
simultaneously capturing number of quantifiers and number of variables in
first-order logic. We show that natural variants of the MS game do not achieve
this. We then introduce a new game, the quantifier-variable tree game, and show
that it simultaneously captures the number of quantifiers and number of
variables.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Carmosino_M/0/1/0/all/0/1">Marco Carmosino</a>, <a href="http://arxiv.org/find/cs/1/au:+Fagin_R/0/1/0/all/0/1">Ronald Fagin</a>, <a href="http://arxiv.org/find/cs/1/au:+Immerman_N/0/1/0/all/0/1">Neil Immerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolaitis_P/0/1/0/all/0/1">Phokion Kolaitis</a>, <a href="http://arxiv.org/find/cs/1/au:+Lenchner_J/0/1/0/all/0/1">Jonathan Lenchner</a>, <a href="http://arxiv.org/find/cs/1/au:+Sengupta_R/0/1/0/all/0/1">Rik Sengupta</a></p><p>Multi-structural (MS) games are combinatorial games that capture the number
of quantifiers of first-order sentences. On the face of their definition, MS
games differ from Ehrenfeucht-Fraisse (EF) games in two ways: first, MS games
are played on two sets of structures, while EF games are played on a pair of
structures; second, in MS games, Duplicator can make any number of copies of
structures. In the first part of this paper, we perform a finer analysis of MS
games and develop a closer comparison of MS games with EF games. In particular,
we point out that the use of sets of structures is of the essence and that when
MS games are played on pairs of structures, they capture Boolean combinations
of first-order sentences with a fixed number of quantifiers. After this, we
focus on another important difference between MS games and EF games, namely,
the necessity for Spoiler to play on top of a previous move in order to win
some MS games. Via an analysis of the types realized during MS games, we
delineate the expressive power of the variant of MS games in which Spoiler
never plays on top of a previous move. In the second part we focus on
simultaneously capturing number of quantifiers and number of variables in
first-order logic. We show that natural variants of the MS game do not achieve
this. We then introduce a new game, the quantifier-variable tree game, and show
that it simultaneously captures the number of quantifiers and number of
variables.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13603'>Limits of structures and Total NP Search Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ond&#x159;ej Je&#x17e;il</p><p>For a class of finite graphs, we define a limit object relative to some
computationally restricted class of functions. The properties of the limit
object then reflect how a computationally restricted viewer "sees" a generic
instance from the class. The construction uses Kraj\'i\v{c}ek's forcing with
random variables [7]. We prove sufficient conditions for universal and
existential sentences to be valid in the limit, provide several examples, and
prove that such a limit object can then be expanded to a model of weak
arithmetic. We then take the limit of all finite pointed paths to obtain a
model of arithmetic where the problem OntoWeakPigeon is total but Leaf (the
complete problem for $\textbf{PPA}$) is not. This can be viewed as a logical
separation of the oracle classes of total NP search problems, which in our
setting implies standard nonreducibility of Leaf to OntoWeakPigeon.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Jezil_O/0/1/0/all/0/1">Ond&#x159;ej Je&#x17e;il</a></p><p>For a class of finite graphs, we define a limit object relative to some
computationally restricted class of functions. The properties of the limit
object then reflect how a computationally restricted viewer "sees" a generic
instance from the class. The construction uses Kraj\'i\v{c}ek's forcing with
random variables [7]. We prove sufficient conditions for universal and
existential sentences to be valid in the limit, provide several examples, and
prove that such a limit object can then be expanded to a model of weak
arithmetic. We then take the limit of all finite pointed paths to obtain a
model of arithmetic where the problem OntoWeakPigeon is total but Leaf (the
complete problem for $\textbf{PPA}$) is not. This can be viewed as a logical
separation of the oracle classes of total NP search problems, which in our
setting implies standard nonreducibility of Leaf to OntoWeakPigeon.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13656'>A Survey and Benchmark of Automatic Surface Reconstruction from Point Clouds</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Raphael Sulzer, Loic Landrieu, Renaud Marlet, Bruno Vallet</p><p>We survey and benchmark traditional and novel learning-based algorithms that
address the problem of surface reconstruction from point clouds. Surface
reconstruction from point clouds is particularly challenging when applied to
real-world acquisitions, due to noise, outliers, non-uniform sampling and
missing data. Traditionally, different handcrafted priors of the input points
or the output surface have been proposed to make the problem more tractable.
However, hyperparameter tuning for adjusting priors to different acquisition
defects can be a tedious task. To this end, the deep learning community has
recently addressed the surface reconstruction problem. In contrast to
traditional approaches, deep surface reconstruction methods can learn priors
directly from a training set of point clouds and corresponding true surfaces.
In our survey, we detail how different handcrafted and learned priors affect
the robustness of methods to defect-laden input and their capability to
generate geometric and topologically accurate reconstructions. In our
benchmark, we evaluate the reconstructions of several traditional and
learning-based methods on the same grounds. We show that learning-based methods
can generalize to unseen shape categories, but their training and test sets
must share the same point cloud characteristics. We also provide the code and
data to compete in our benchmark and to further stimulate the development of
learning-based surface reconstruction
github.com/raphaelsulzer/dsr-benchmark.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sulzer_R/0/1/0/all/0/1">Raphael Sulzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Landrieu_L/0/1/0/all/0/1">Loic Landrieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Marlet_R/0/1/0/all/0/1">Renaud Marlet</a>, <a href="http://arxiv.org/find/cs/1/au:+Vallet_B/0/1/0/all/0/1">Bruno Vallet</a></p><p>We survey and benchmark traditional and novel learning-based algorithms that
address the problem of surface reconstruction from point clouds. Surface
reconstruction from point clouds is particularly challenging when applied to
real-world acquisitions, due to noise, outliers, non-uniform sampling and
missing data. Traditionally, different handcrafted priors of the input points
or the output surface have been proposed to make the problem more tractable.
However, hyperparameter tuning for adjusting priors to different acquisition
defects can be a tedious task. To this end, the deep learning community has
recently addressed the surface reconstruction problem. In contrast to
traditional approaches, deep surface reconstruction methods can learn priors
directly from a training set of point clouds and corresponding true surfaces.
In our survey, we detail how different handcrafted and learned priors affect
the robustness of methods to defect-laden input and their capability to
generate geometric and topologically accurate reconstructions. In our
benchmark, we evaluate the reconstructions of several traditional and
learning-based methods on the same grounds. We show that learning-based methods
can generalize to unseen shape categories, but their training and test sets
must share the same point cloud characteristics. We also provide the code and
data to compete in our benchmark and to further stimulate the development of
learning-based surface reconstruction
https://github.com/raphaelsulzer/dsr-benchmark.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13541'>Singular Value Approximation and Reducing Directed to Undirected Graph Sparsification</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: AmirMahdi Ahmadinejad, John Peebles, Edward Pyne, Aaron Sidford, Salil Vadhan</p><p>In this paper, we introduce a new, spectral notion of approximation between
directed graphs, which we call Singular Value (SV) approximation.
SV-approximation is stronger than previous notions of spectral approximation
considered in the literature, including spectral approximation of Laplacians
for undirected graphs (Spielman Teng STOC 2004), standard approximation for
directed graphs (Cohen et. al. STOC 2007), and unit-circle approximation for
directed graphs (Ahmadinejad et. al. FOCS 2020). Moreover, SV approximation
enjoys several useful properties not known to be possessed by previous notions
of approximation, such as being preserved under products of random-walk
matrices and with matrices of bounded norm.
</p>
<p>Notably, we show that there is a simple black-box reduction from
SV-sparsifying Eulerian directed graphs to SV-sparsifying undirected graphs.
With this reduction in hand, we provide a nearly linear-time algorithm for
SV-sparsifying undirected and hence also Eulerian directed graphs. This also
yields the first nearly linear-time algorithm for unit-circle-sparsifying
Eulerian directed graphs. In addition, we give a nearly linear-time algorithm
for SV-sparsifying (and UC-sparsifying) random-walk polynomials of Eulerian
directed graphs with second normalized singular value bounded away from $1$ by
$1/\text{poly}(n)$.
</p>
<p>Finally, we show that a simple repeated-squaring and sparsification algorithm
for solving Laplacian systems, introduced by (Peng Spielman STOC 2014) for
undirected graphs, also works for Eulerian digraphs whose random-walk matrix is
normal (i.e. unitarily diagonalizable), if we use SV-sparsification at each
step. Prior Laplacian solvers for Eulerian digraphs are significantly more
complicated.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ahmadinejad_A/0/1/0/all/0/1">AmirMahdi Ahmadinejad</a>, <a href="http://arxiv.org/find/cs/1/au:+Peebles_J/0/1/0/all/0/1">John Peebles</a>, <a href="http://arxiv.org/find/cs/1/au:+Pyne_E/0/1/0/all/0/1">Edward Pyne</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidford_A/0/1/0/all/0/1">Aaron Sidford</a>, <a href="http://arxiv.org/find/cs/1/au:+Vadhan_S/0/1/0/all/0/1">Salil Vadhan</a></p><p>In this paper, we introduce a new, spectral notion of approximation between
directed graphs, which we call Singular Value (SV) approximation.
SV-approximation is stronger than previous notions of spectral approximation
considered in the literature, including spectral approximation of Laplacians
for undirected graphs (Spielman Teng STOC 2004), standard approximation for
directed graphs (Cohen et. al. STOC 2007), and unit-circle approximation for
directed graphs (Ahmadinejad et. al. FOCS 2020). Moreover, SV approximation
enjoys several useful properties not known to be possessed by previous notions
of approximation, such as being preserved under products of random-walk
matrices and with matrices of bounded norm.
</p>
<p>Notably, we show that there is a simple black-box reduction from
SV-sparsifying Eulerian directed graphs to SV-sparsifying undirected graphs.
With this reduction in hand, we provide a nearly linear-time algorithm for
SV-sparsifying undirected and hence also Eulerian directed graphs. This also
yields the first nearly linear-time algorithm for unit-circle-sparsifying
Eulerian directed graphs. In addition, we give a nearly linear-time algorithm
for SV-sparsifying (and UC-sparsifying) random-walk polynomials of Eulerian
directed graphs with second normalized singular value bounded away from $1$ by
$1/\text{poly}(n)$.
</p>
<p>Finally, we show that a simple repeated-squaring and sparsification algorithm
for solving Laplacian systems, introduced by (Peng Spielman STOC 2014) for
undirected graphs, also works for Eulerian digraphs whose random-walk matrix is
normal (i.e. unitarily diagonalizable), if we use SV-sparsification at each
step. Prior Laplacian solvers for Eulerian digraphs are significantly more
complicated.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13245'>A Safety Framework for Flow Decomposition Problems via Integer Linear Programming</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fernando H. C. Dias, Manuel Caceres, Lucia Williams, Brendan Mumey, Alexandru I. Tomescu</p><p>Many important problems in Bioinformatics (e.g., assembly or multi-assembly)
admit multiple solutions, while the final objective is to report only one. A
common approach to deal with this uncertainty is finding safe partial solutions
(e.g., contigs) which are common to all solutions. Previous research on safety
has focused on polynomially-time solvable problems, whereas many successful and
natural models are NP-hard to solve, leaving a lack of "safety tools" for such
problems. We propose the first method for computing all safe solutions for an
NP-hard problem, minimum flow decomposition. We obtain our results by
developing a "safety test" for paths based on a general Integer Linear
Programming (ILP) formulation. Moreover, we provide implementations with
practical optimizations aimed to reduce the total ILP time, the most efficient
of these being based on a recursive group-testing procedure.
</p>
<p>Results: Experimental results on the transcriptome datasets of Shao and
Kingsford (TCBB, 2017) show that all safe paths for minimum flow decompositions
correctly recover up to 90% of the full RNA transcripts, which is at least 25%
more than previously known safe paths, such as (Caceres et al. TCBB, 2021),
(Zheng et al., RECOMB 2021), (Khan et al., RECOMB 2022, ESA 2022). Moreover,
despite the NP-hardness of the problem, we can report all safe paths for 99.8%
of the over 27,000 non-trivial graphs of this dataset in only 1.5 hours. Our
results suggest that, on perfect data, there is less ambiguity than thought in
the notoriously hard RNA assembly problem.
</p>
<p>Availability: github.com/algbio/mfd-safety
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dias_F/0/1/0/all/0/1">Fernando H. C. Dias</a>, <a href="http://arxiv.org/find/cs/1/au:+Caceres_M/0/1/0/all/0/1">Manuel Caceres</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_L/0/1/0/all/0/1">Lucia Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Mumey_B/0/1/0/all/0/1">Brendan Mumey</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomescu_A/0/1/0/all/0/1">Alexandru I. Tomescu</a></p><p>Many important problems in Bioinformatics (e.g., assembly or multi-assembly)
admit multiple solutions, while the final objective is to report only one. A
common approach to deal with this uncertainty is finding safe partial solutions
(e.g., contigs) which are common to all solutions. Previous research on safety
has focused on polynomially-time solvable problems, whereas many successful and
natural models are NP-hard to solve, leaving a lack of "safety tools" for such
problems. We propose the first method for computing all safe solutions for an
NP-hard problem, minimum flow decomposition. We obtain our results by
developing a "safety test" for paths based on a general Integer Linear
Programming (ILP) formulation. Moreover, we provide implementations with
practical optimizations aimed to reduce the total ILP time, the most efficient
of these being based on a recursive group-testing procedure.
</p>
<p>Results: Experimental results on the transcriptome datasets of Shao and
Kingsford (TCBB, 2017) show that all safe paths for minimum flow decompositions
correctly recover up to 90% of the full RNA transcripts, which is at least 25%
more than previously known safe paths, such as (Caceres et al. TCBB, 2021),
(Zheng et al., RECOMB 2021), (Khan et al., RECOMB 2022, ESA 2022). Moreover,
despite the NP-hardness of the problem, we can report all safe paths for 99.8%
of the over 27,000 non-trivial graphs of this dataset in only 1.5 hours. Our
results suggest that, on perfect data, there is less ambiguity than thought in
the notoriously hard RNA assembly problem.
</p>
<p>Availability: https://github.com/algbio/mfd-safety
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13307'>Breadth-First Depth-Next: Optimal Collaborative Exploration of Trees with Low Diameter</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Romain Cosson, Laurent Massouli&#xe9;, Laurent Viennot</p><p>We consider the problem of collaborative tree exploration posed by
Fraigniaud, Gasieniec, Kowalski, and Pelc where a team of $k$ agents is tasked
to collectively go through all the edges of an unknown tree as fast as
possible. Denoting by $n$ the total number of nodes and by $D$ the tree depth,
the $\mathcal{O}(n/\log(k)+D)$ algorithm of Fraigniaud et al. achieves the
best-known competitive ratio with respect to the cost of offline exploration
which is $\Theta(\max{\{2n/k,2D\}})$. Brass, Cabrera-Mora, Gasparri, and Xiao
consider an alternative performance criterion, namely the additive overhead
with respect to $2n/k$, and obtain a $2n/k+\mathcal{O}((D+k)^k)$ runtime
guarantee. In this paper, we introduce `Breadth-First Depth-Next' (BFDN), a
novel and simple algorithm that performs collaborative tree exploration in time
$2n/k+\mathcal{O}(D^2\log(k))$, thus outperforming Brass et al. for all values
of $(n,D)$ and being order-optimal for all trees with depth $D=o_k(\sqrt{n})$.
Moreover, a recent result from Disser et al. implies that no exploration
algorithm can achieve a $2n/k+\mathcal{O}(D^{2-\epsilon})$ runtime guarantee.
The dependency in $D^2$ of our bound is in this sense optimal. The proof of our
result crucially relies on the analysis of an associated two-player game. We
extend the guarantees of BFDN to: scenarios with limited memory and
communication, adversarial setups where robots can be blocked, and exploration
of classes of non-tree graphs. Finally, we provide a recursive version of BFDN
with a runtime of $\mathcal{O}_\ell(n/k^{1/\ell}+\log(k) D^{1+1/\ell})$ for
parameter $\ell\ge 1$, thereby improving performance for trees with large
depth.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cosson_R/0/1/0/all/0/1">Romain Cosson</a>, <a href="http://arxiv.org/find/cs/1/au:+Massoulie_L/0/1/0/all/0/1">Laurent Massouli&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Viennot_L/0/1/0/all/0/1">Laurent Viennot</a></p><p>We consider the problem of collaborative tree exploration posed by
Fraigniaud, Gasieniec, Kowalski, and Pelc where a team of $k$ agents is tasked
to collectively go through all the edges of an unknown tree as fast as
possible. Denoting by $n$ the total number of nodes and by $D$ the tree depth,
the $\mathcal{O}(n/\log(k)+D)$ algorithm of Fraigniaud et al. achieves the
best-known competitive ratio with respect to the cost of offline exploration
which is $\Theta(\max{\{2n/k,2D\}})$. Brass, Cabrera-Mora, Gasparri, and Xiao
consider an alternative performance criterion, namely the additive overhead
with respect to $2n/k$, and obtain a $2n/k+\mathcal{O}((D+k)^k)$ runtime
guarantee. In this paper, we introduce `Breadth-First Depth-Next' (BFDN), a
novel and simple algorithm that performs collaborative tree exploration in time
$2n/k+\mathcal{O}(D^2\log(k))$, thus outperforming Brass et al. for all values
of $(n,D)$ and being order-optimal for all trees with depth $D=o_k(\sqrt{n})$.
Moreover, a recent result from Disser et al. implies that no exploration
algorithm can achieve a $2n/k+\mathcal{O}(D^{2-\epsilon})$ runtime guarantee.
The dependency in $D^2$ of our bound is in this sense optimal. The proof of our
result crucially relies on the analysis of an associated two-player game. We
extend the guarantees of BFDN to: scenarios with limited memory and
communication, adversarial setups where robots can be blocked, and exploration
of classes of non-tree graphs. Finally, we provide a recursive version of BFDN
with a runtime of $\mathcal{O}_\ell(n/k^{1/\ell}+\log(k) D^{1+1/\ell})$ for
parameter $\ell\ge 1$, thereby improving performance for trees with large
depth.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13317'>The Iteration Number of the Weisfeiler-Leman Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Martin Grohe, Moritz Lichter, Daniel Neuen</p><p>We prove new upper and lower bounds on the number of iterations the
$k$-dimensional Weisfeiler-Leman algorithm ($k$-WL) requires until
stabilization. For $k \geq 3$, we show that $k$-WL stabilizes after at most
$O(kn^{k-1}\log n)$ iterations (where $n$ denotes the number of vertices of the
input structures), obtaining the first improvement over the trivial upper bound
of $n^{k}-1$ and extending a previous upper bound of $O(n \log n)$ for $k=2$
[Lichter et al., LICS 2019].
</p>
<p>We complement our upper bounds by constructing $k$-ary relational structures
on which $k$-WL requires at least $n^{\Omega(k)}$ iterations to stabilize. This
improves over a previous lower bound of $n^{\Omega(k / \log k)}$ [Berkholz,
Nordstr\"{o}m, LICS 2016].
</p>
<p>We also investigate tradeoffs between the dimension and the iteration number
of WL, and show that $d$-WL, where $d = \lceil\frac{3(k+1)}{2}\rceil$, can
simulate the $k$-WL algorithm using only $O(k^2 \cdot n^{\lfloor k/2\rfloor +
1} \log n)$ many iterations, but still requires at least $n^{\Omega(k)}$
iterations for any $d$ (that is sufficiently smaller than $n$).
</p>
<p>The number of iterations required by $k$-WL to distinguish two structures
corresponds to the quantifier rank of a sentence distinguishing them in the $(k
+ 1)$-variable fragment $C_{k+1}$ of first-order logic with counting
quantifiers. Hence, our results also imply new upper and lower bounds on the
quantifier rank required in the logic $C_{k+1}$, as well as tradeoffs between
variable number and quantifier rank.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1">Martin Grohe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lichter_M/0/1/0/all/0/1">Moritz Lichter</a>, <a href="http://arxiv.org/find/cs/1/au:+Neuen_D/0/1/0/all/0/1">Daniel Neuen</a></p><p>We prove new upper and lower bounds on the number of iterations the
$k$-dimensional Weisfeiler-Leman algorithm ($k$-WL) requires until
stabilization. For $k \geq 3$, we show that $k$-WL stabilizes after at most
$O(kn^{k-1}\log n)$ iterations (where $n$ denotes the number of vertices of the
input structures), obtaining the first improvement over the trivial upper bound
of $n^{k}-1$ and extending a previous upper bound of $O(n \log n)$ for $k=2$
[Lichter et al., LICS 2019].
</p>
<p>We complement our upper bounds by constructing $k$-ary relational structures
on which $k$-WL requires at least $n^{\Omega(k)}$ iterations to stabilize. This
improves over a previous lower bound of $n^{\Omega(k / \log k)}$ [Berkholz,
Nordstr\"{o}m, LICS 2016].
</p>
<p>We also investigate tradeoffs between the dimension and the iteration number
of WL, and show that $d$-WL, where $d = \lceil\frac{3(k+1)}{2}\rceil$, can
simulate the $k$-WL algorithm using only $O(k^2 \cdot n^{\lfloor k/2\rfloor +
1} \log n)$ many iterations, but still requires at least $n^{\Omega(k)}$
iterations for any $d$ (that is sufficiently smaller than $n$).
</p>
<p>The number of iterations required by $k$-WL to distinguish two structures
corresponds to the quantifier rank of a sentence distinguishing them in the $(k
+ 1)$-variable fragment $C_{k+1}$ of first-order logic with counting
quantifiers. Hence, our results also imply new upper and lower bounds on the
quantifier rank required in the logic $C_{k+1}$, as well as tradeoffs between
variable number and quantifier rank.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13326'>A Framework for Adapting Offline Algorithms to Solve Combinatorial Multi-Armed Bandit Problems with Bandit Feedback</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guanyu Nie, Yididiya Y Nadew, Yanhui Zhu, Vaneet Aggarwal, Christopher John Quinn</p><p>We investigate the problem of stochastic, combinatorial multi-armed bandits
where the learner only has access to bandit feedback and the reward function
can be non-linear. We provide a general framework for adapting discrete offline
approximation algorithms into sublinear $\alpha$-regret methods that only
require bandit feedback, achieving
$\mathcal{O}\left(T^\frac{2}{3}\log(T)^\frac{1}{3}\right)$ expected cumulative
$\alpha$-regret dependence on the horizon $T$. The framework only requires the
offline algorithms to be robust to small errors in function evaluation. The
adaptation procedure does not even require explicit knowledge of the offline
approximation algorithm -- the offline algorithm can be used as black box
subroutine.
</p>
<p>To demonstrate the utility of the proposed framework, the proposed framework
is applied to multiple problems in submodular maximization, adapting
approximation algorithms for cardinality and for knapsack constraints. The new
CMAB algorithms for knapsack constraints outperform a full-bandit method
developed for the adversarial setting in experiments with real-world data.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nie_G/0/1/0/all/0/1">Guanyu Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadew_Y/0/1/0/all/0/1">Yididiya Y Nadew</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yanhui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1">Vaneet Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Quinn_C/0/1/0/all/0/1">Christopher John Quinn</a></p><p>We investigate the problem of stochastic, combinatorial multi-armed bandits
where the learner only has access to bandit feedback and the reward function
can be non-linear. We provide a general framework for adapting discrete offline
approximation algorithms into sublinear $\alpha$-regret methods that only
require bandit feedback, achieving
$\mathcal{O}\left(T^\frac{2}{3}\log(T)^\frac{1}{3}\right)$ expected cumulative
$\alpha$-regret dependence on the horizon $T$. The framework only requires the
offline algorithms to be robust to small errors in function evaluation. The
adaptation procedure does not even require explicit knowledge of the offline
approximation algorithm -- the offline algorithm can be used as black box
subroutine.
</p>
<p>To demonstrate the utility of the proposed framework, the proposed framework
is applied to multiple problems in submodular maximization, adapting
approximation algorithms for cardinality and for knapsack constraints. The new
CMAB algorithms for knapsack constraints outperform a full-bandit method
developed for the adversarial setting in experiments with real-world data.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13334'>A Bias-Variance-Privacy Trilemma for Statistical Estimation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gautam Kamath, Argyris Mouzakis, Matthew Regehr, Vikrant Singhal, Thomas Steinke, Jonathan Ullman</p><p>The canonical algorithm for differentially private mean estimation is to
first clip the samples to a bounded range and then add noise to their empirical
mean. Clipping controls the sensitivity and, hence, the variance of the noise
that we add for privacy. But clipping also introduces statistical bias. We
prove that this tradeoff is inherent: no algorithm can simultaneously have low
bias, low variance, and low privacy loss for arbitrary distributions.
</p>
<p>On the positive side, we show that unbiased mean estimation is possible under
approximate differential privacy if we assume that the distribution is
symmetric. Furthermore, we show that, even if we assume that the data is
sampled from a Gaussian, unbiased mean estimation is impossible under pure or
concentrated differential privacy.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Kamath_G/0/1/0/all/0/1">Gautam Kamath</a>, <a href="http://arxiv.org/find/math/1/au:+Mouzakis_A/0/1/0/all/0/1">Argyris Mouzakis</a>, <a href="http://arxiv.org/find/math/1/au:+Regehr_M/0/1/0/all/0/1">Matthew Regehr</a>, <a href="http://arxiv.org/find/math/1/au:+Singhal_V/0/1/0/all/0/1">Vikrant Singhal</a>, <a href="http://arxiv.org/find/math/1/au:+Steinke_T/0/1/0/all/0/1">Thomas Steinke</a>, <a href="http://arxiv.org/find/math/1/au:+Ullman_J/0/1/0/all/0/1">Jonathan Ullman</a></p><p>The canonical algorithm for differentially private mean estimation is to
first clip the samples to a bounded range and then add noise to their empirical
mean. Clipping controls the sensitivity and, hence, the variance of the noise
that we add for privacy. But clipping also introduces statistical bias. We
prove that this tradeoff is inherent: no algorithm can simultaneously have low
bias, low variance, and low privacy loss for arbitrary distributions.
</p>
<p>On the positive side, we show that unbiased mean estimation is possible under
approximate differential privacy if we assume that the distribution is
symmetric. Furthermore, we show that, even if we assume that the data is
sampled from a Gaussian, unbiased mean estimation is impossible under pure or
concentrated differential privacy.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13534'>Weitzman's Rule for Pandora's Box with Correlations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Evangelia Gergatsouli, Christos Tzamos</p><p>Pandora's Box is a central problem in decision making under uncertainty that
can model various real life scenarios. In this problem we are given $n$ boxes,
each with a fixed opening cost, and an unknown value drawn from a known
distribution, only revealed if we pay the opening cost. Our goal is to find a
strategy for opening boxes to minimize the sum of the value selected and the
opening cost paid.
</p>
<p>In this work we revisit Pandora's Box when the value distributions are
correlated, first studied in Chawla et al. (arXiv:1911.01632). We show that the
optimal algorithm for the independent case, given by Weitzman's rule, directly
works for the correlated case. In fact, our algorithm results in significantly
improved approximation guarantees compared to the previous work, while also
being substantially simpler. We finally show how to implement the rule given
only sample access to the correlated distribution of values. Specifically, we
find that a number of samples that is polynomial in the number of boxes is
sufficient for the algorithm to work.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gergatsouli_E/0/1/0/all/0/1">Evangelia Gergatsouli</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1">Christos Tzamos</a></p><p>Pandora's Box is a central problem in decision making under uncertainty that
can model various real life scenarios. In this problem we are given $n$ boxes,
each with a fixed opening cost, and an unknown value drawn from a known
distribution, only revealed if we pay the opening cost. Our goal is to find a
strategy for opening boxes to minimize the sum of the value selected and the
opening cost paid.
</p>
<p>In this work we revisit Pandora's Box when the value distributions are
correlated, first studied in Chawla et al. (<a href="/abs/1911.01632">arXiv:1911.01632</a>). We show that the
optimal algorithm for the independent case, given by Weitzman's rule, directly
works for the correlated case. In fact, our algorithm results in significantly
improved approximation guarantees compared to the previous work, while also
being substantially simpler. We finally show how to implement the rule given
only sample access to the correlated distribution of values. Specifically, we
find that a number of samples that is polynomial in the number of boxes is
sufficient for the algorithm to work.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13723'>p-median location interdiction on trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lena Lei&#xdf;, Till Heller, Luca E. Sch&#xe4;fer, Manuel Streicher, Stefan Ruzika</p><p>In p-median location interdiction the aim is to find a subset of edges in a
graph, such that the objective value of the p-median problem in the same graph
without the selected edges is as large as possible.
</p>
<p>We prove that this problem is NP-hard even on acyclic graphs. Restricting the
problem to trees with unit lengths on the edges, unit interdiction costs, and a
single edge interdiction, we provide an algorithm which solves the problem in
polynomial time. Furthermore, we investigate path graphs with unit and
arbitrary lengths. For the former case, we present an algorithm, where multiple
edges can get interdicted. Furthermore, for the latter case, we present a
method to compute an optimal solution for one interdiction step which can also
be extended to multiple interdicted edges.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Leiss_L/0/1/0/all/0/1">Lena Lei&#xdf;</a>, <a href="http://arxiv.org/find/cs/1/au:+Heller_T/0/1/0/all/0/1">Till Heller</a>, <a href="http://arxiv.org/find/cs/1/au:+Schafer_L/0/1/0/all/0/1">Luca E. Sch&#xe4;fer</a>, <a href="http://arxiv.org/find/cs/1/au:+Streicher_M/0/1/0/all/0/1">Manuel Streicher</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruzika_S/0/1/0/all/0/1">Stefan Ruzika</a></p><p>In p-median location interdiction the aim is to find a subset of edges in a
graph, such that the objective value of the p-median problem in the same graph
without the selected edges is as large as possible.
</p>
<p>We prove that this problem is NP-hard even on acyclic graphs. Restricting the
problem to trees with unit lengths on the edges, unit interdiction costs, and a
single edge interdiction, we provide an algorithm which solves the problem in
polynomial time. Furthermore, we investigate path graphs with unit and
arbitrary lengths. For the former case, we present an algorithm, where multiple
edges can get interdicted. Furthermore, for the latter case, we present a
method to compute an optimal solution for one interdiction step which can also
be extended to multiple interdicted edges.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13735'>Flipper games for monadically stable graph classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jakub Gajarsk&#xfd;, Nikolas M&#xe4;hlmann, Rose McCarty, Pierre Ohlmann, Micha&#x142; Pilipczuk, Wojciech Przybyszewski, Sebastian Siebertz, Marek Soko&#x142;owski, Szymon Toru&#x144;czyk</p><p>A class of graphs $\mathscr{C}$ is monadically stable if for any unary
expansion $\widehat{\mathscr{C}}$ of $\mathscr{C}$, one cannot interpret, in
first-order logic, arbitrarily long linear orders in graphs from
$\widehat{\mathscr{C}}$. It is known that nowhere dense graph classes are
monadically stable; these encompass most of the studied concepts of sparsity in
graphs, including graph classes that exclude a fixed topological minor. On the
other hand, monadic stability is a property expressed in purely model-theoretic
terms and hence it is also suited for capturing structure in dense graphs.
</p>
<p>For several years, it has been suspected that one can create a structure
theory for monadically stable graph classes that mirrors the theory of nowhere
dense graph classes in the dense setting. In this work we provide a step in
this direction by giving a characterization of monadic stability through the
Flipper game: a game on a graph played by Flipper, who in each round can
complement the edge relation between any pair of vertex subsets, and Connector,
who in each round localizes the game to a ball of bounded radius. This is an
analog of the Splitter game, which characterizes nowhere dense classes of
graphs (Grohe, Kreutzer, and Siebertz, J.ACM'17).
</p>
<p>We give two different proofs of our main result. The first proof uses tools
from model theory, and it exposes an additional property of monadically stable
graph classes that is close in spirit to definability of types. Also, as a
byproduct, we give an alternative proof of the recent result of Braunfeld and
Laskowski (arXiv 2209.05120) that monadic stability for graph classes coincides
with existential monadic stability. The second proof relies on the recently
introduced notion of flip-wideness (Dreier, M\"ahlmann, Siebertz, and
Toru\'nczyk, arXiv 2206.13765) and provides an efficient algorithm to compute
Flipper's moves in a winning strategy.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gajarsky_J/0/1/0/all/0/1">Jakub Gajarsk&#xfd;</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahlmann_N/0/1/0/all/0/1">Nikolas M&#xe4;hlmann</a>, <a href="http://arxiv.org/find/cs/1/au:+McCarty_R/0/1/0/all/0/1">Rose McCarty</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohlmann_P/0/1/0/all/0/1">Pierre Ohlmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Micha&#x142; Pilipczuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Przybyszewski_W/0/1/0/all/0/1">Wojciech Przybyszewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Siebertz_S/0/1/0/all/0/1">Sebastian Siebertz</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokolowski_M/0/1/0/all/0/1">Marek Soko&#x142;owski</a>, <a href="http://arxiv.org/find/cs/1/au:+Torunczyk_S/0/1/0/all/0/1">Szymon Toru&#x144;czyk</a></p><p>A class of graphs $\mathscr{C}$ is monadically stable if for any unary
expansion $\widehat{\mathscr{C}}$ of $\mathscr{C}$, one cannot interpret, in
first-order logic, arbitrarily long linear orders in graphs from
$\widehat{\mathscr{C}}$. It is known that nowhere dense graph classes are
monadically stable; these encompass most of the studied concepts of sparsity in
graphs, including graph classes that exclude a fixed topological minor. On the
other hand, monadic stability is a property expressed in purely model-theoretic
terms and hence it is also suited for capturing structure in dense graphs.
</p>
<p>For several years, it has been suspected that one can create a structure
theory for monadically stable graph classes that mirrors the theory of nowhere
dense graph classes in the dense setting. In this work we provide a step in
this direction by giving a characterization of monadic stability through the
Flipper game: a game on a graph played by Flipper, who in each round can
complement the edge relation between any pair of vertex subsets, and Connector,
who in each round localizes the game to a ball of bounded radius. This is an
analog of the Splitter game, which characterizes nowhere dense classes of
graphs (Grohe, Kreutzer, and Siebertz, J.ACM'17).
</p>
<p>We give two different proofs of our main result. The first proof uses tools
from model theory, and it exposes an additional property of monadically stable
graph classes that is close in spirit to definability of types. Also, as a
byproduct, we give an alternative proof of the recent result of Braunfeld and
Laskowski (arXiv <a href="/abs/2209.05120">2209.05120</a>) that monadic stability for graph classes coincides
with existential monadic stability. The second proof relies on the recently
introduced notion of flip-wideness (Dreier, M\"ahlmann, Siebertz, and
Toru\'nczyk, arXiv <a href="/abs/2206.13765">2206.13765</a>) and provides an efficient algorithm to compute
Flipper's moves in a winning strategy.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13767'>Multicalibration as Boosting for Regression</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ira Globus-Harris, Declan Harrison, Michael Kearns, Aaron Roth, Jessica Sorrell</p><p>We study the connection between multicalibration and boosting for squared
error regression. First we prove a useful characterization of multicalibration
in terms of a ``swap regret'' like condition on squared error. Using this
characterization, we give an exceedingly simple algorithm that can be analyzed
both as a boosting algorithm for regression and as a multicalibration algorithm
for a class H that makes use only of a standard squared error regression oracle
for H. We give a weak learning assumption on H that ensures convergence to
Bayes optimality without the need to make any realizability assumptions --
giving us an agnostic boosting algorithm for regression. We then show that our
weak learning assumption on H is both necessary and sufficient for
multicalibration with respect to H to imply Bayes optimality. We also show that
if H satisfies our weak learning condition relative to another class C then
multicalibration with respect to H implies multicalibration with respect to C.
Finally we investigate the empirical performance of our algorithm
experimentally using an open source implementation that we make available. Our
code repository can be found at
github.com/Declancharrison/Level-Set-Boosting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Globus_Harris_I/0/1/0/all/0/1">Ira Globus-Harris</a>, <a href="http://arxiv.org/find/cs/1/au:+Harrison_D/0/1/0/all/0/1">Declan Harrison</a>, <a href="http://arxiv.org/find/cs/1/au:+Kearns_M/0/1/0/all/0/1">Michael Kearns</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1">Aaron Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorrell_J/0/1/0/all/0/1">Jessica Sorrell</a></p><p>We study the connection between multicalibration and boosting for squared
error regression. First we prove a useful characterization of multicalibration
in terms of a ``swap regret'' like condition on squared error. Using this
characterization, we give an exceedingly simple algorithm that can be analyzed
both as a boosting algorithm for regression and as a multicalibration algorithm
for a class H that makes use only of a standard squared error regression oracle
for H. We give a weak learning assumption on H that ensures convergence to
Bayes optimality without the need to make any realizability assumptions --
giving us an agnostic boosting algorithm for regression. We then show that our
weak learning assumption on H is both necessary and sufficient for
multicalibration with respect to H to imply Bayes optimality. We also show that
if H satisfies our weak learning condition relative to another class C then
multicalibration with respect to H implies multicalibration with respect to C.
Finally we investigate the empirical performance of our algorithm
experimentally using an open source implementation that we make available. Our
code repository can be found at
https://github.com/Declancharrison/Level-Set-Boosting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13832'>Bounds for c-Ideal Hashing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fabian Frei, David Wehner</p><p>In this paper, we analyze hashing from a worst-case perspective. To this end,
we study a new property of hash families that is strongly related to d-perfect
hashing, namely c-ideality. On the one hand, this notion generalizes the
definition of perfect hashing, which has been studied extensively; on the other
hand, it provides a direct link to the notion of c-approximativity. We focus on
the usually neglected case where the average load \alpha is at least 1 and
prove upper and lower parametrized bounds on the minimal size of c-ideal hash
families.
</p>
<p>As an aside, we show how c-ideality helps to analyze the advice complexity of
hashing. The concept of advice, introduced a decade ago, lets us measure the
information content of an online problem. We prove hashing's advice complexity
to be linear in the hash table size.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Frei_F/0/1/0/all/0/1">Fabian Frei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wehner_D/0/1/0/all/0/1">David Wehner</a></p><p>In this paper, we analyze hashing from a worst-case perspective. To this end,
we study a new property of hash families that is strongly related to d-perfect
hashing, namely c-ideality. On the one hand, this notion generalizes the
definition of perfect hashing, which has been studied extensively; on the other
hand, it provides a direct link to the notion of c-approximativity. We focus on
the usually neglected case where the average load \alpha is at least 1 and
prove upper and lower parametrized bounds on the minimal size of c-ideal hash
families.
</p>
<p>As an aside, we show how c-ideality helps to analyze the advice complexity of
hashing. The concept of advice, introduced a decade ago, lets us measure the
information content of an online problem. We prove hashing's advice complexity
to be linear in the hash table size.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13850'>Gaussian Noise is Nearly Instance Optimal for Private Unbiased Mean Estimation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aleksandar Nikolov, Haohua Tang</p><p>We investigate unbiased high-dimensional mean estimators in differential
privacy. We consider differentially private mechanisms whose expected output
equals the mean of the input dataset, for every dataset drawn from a fixed
convex domain $K$ in $\mathbb{R}^d$. In the setting of concentrated
differential privacy, we show that, for every input such an unbiased mean
estimator introduces approximately at least as much error as a mechanism that
adds Gaussian noise with a carefully chosen covariance. This is true when the
error is measured with respect to $\ell_p$ error for any $p \ge 2$. We extend
this result to local differential privacy, and to approximate differential
privacy, but for the latter the error lower bound holds either for a dataset or
for a neighboring dataset. We also extend our results to mechanisms that take
i.i.d.~samples from a distribution over $K$ and are unbiased with respect to
the mean of the distribution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Nikolov_A/0/1/0/all/0/1">Aleksandar Nikolov</a>, <a href="http://arxiv.org/find/math/1/au:+Tang_H/0/1/0/all/0/1">Haohua Tang</a></p><p>We investigate unbiased high-dimensional mean estimators in differential
privacy. We consider differentially private mechanisms whose expected output
equals the mean of the input dataset, for every dataset drawn from a fixed
convex domain $K$ in $\mathbb{R}^d$. In the setting of concentrated
differential privacy, we show that, for every input such an unbiased mean
estimator introduces approximately at least as much error as a mechanism that
adds Gaussian noise with a carefully chosen covariance. This is true when the
error is measured with respect to $\ell_p$ error for any $p \ge 2$. We extend
this result to local differential privacy, and to approximate differential
privacy, but for the latter the error lower bound holds either for a dataset or
for a neighboring dataset. We also extend our results to mechanisms that take
i.i.d.~samples from a distribution over $K$ and are unbiased with respect to
the mean of the distribution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13860'>Zero-Memory Graph Exploration with Unknown Inports</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hans-Joachim B&#xf6;ckenhauer, Fabian Frei, Walter Unger, David Wehner</p><p>We study a very restrictive graph exploration problem. In our model, an agent
without persistent memory is placed on a vertex of a graph and only sees the
adjacent vertices. The goal is to visit every vertex of the graph, return to
the start vertex, and terminate. The agent does not know through which edge it
entered a vertex. The agent may color the current vertex and can see the colors
of the neighboring vertices in an arbitrary order. The agent may not recolor a
vertex. We investigate the number of colors necessary and sufficient to explore
all graphs. We prove that n-1 colors are necessary and sufficient for
exploration in general, 3 colors are necessary and sufficient if only trees are
to be explored, and min(2k-3,n-1) colors are necessary and min(2k-1,n-1) colors
are sufficient on graphs of size n and circumference $k$, where the
circumference is the length of a longest cycle. This only holds if an algorithm
has to explore all graphs and not merely certain graph classes. We give an
example for a graph class where each graph can be explored with 4 colors,
although the graphs have maximal circumference. Moreover, we prove that
recoloring vertices is very powerful by designing an algorithm with recoloring
that uses only 7 colors and explores all graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bockenhauer_H/0/1/0/all/0/1">Hans-Joachim B&#xf6;ckenhauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Frei_F/0/1/0/all/0/1">Fabian Frei</a>, <a href="http://arxiv.org/find/cs/1/au:+Unger_W/0/1/0/all/0/1">Walter Unger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wehner_D/0/1/0/all/0/1">David Wehner</a></p><p>We study a very restrictive graph exploration problem. In our model, an agent
without persistent memory is placed on a vertex of a graph and only sees the
adjacent vertices. The goal is to visit every vertex of the graph, return to
the start vertex, and terminate. The agent does not know through which edge it
entered a vertex. The agent may color the current vertex and can see the colors
of the neighboring vertices in an arbitrary order. The agent may not recolor a
vertex. We investigate the number of colors necessary and sufficient to explore
all graphs. We prove that n-1 colors are necessary and sufficient for
exploration in general, 3 colors are necessary and sufficient if only trees are
to be explored, and min(2k-3,n-1) colors are necessary and min(2k-1,n-1) colors
are sufficient on graphs of size n and circumference $k$, where the
circumference is the length of a longest cycle. This only holds if an algorithm
has to explore all graphs and not merely certain graph classes. We give an
example for a graph class where each graph can be explored with 4 colors,
although the graphs have maximal circumference. Moreover, we prove that
recoloring vertices is very powerful by designing an algorithm with recoloring
that uses only 7 colors and explores all graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
