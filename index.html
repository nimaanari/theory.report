<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-03-01T05:32:19Z">Wednesday, March 01 2023, 05:32</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, March 01
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14412'>An Algorithm and Complexity Results for Causal Unit Selection</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Haiying Huang, Adnan Darwiche</p><p>The unit selection problem aims to identify objects, called units, that are
most likely to exhibit a desired mode of behavior when subjected to stimuli
(e.g., customers who are about to churn but would change their mind if
encouraged). Unit selection with counterfactual objective functions was
introduced relatively recently with existing work focusing on bounding a
specific class of objective functions, called the benefit functions, based on
observational and interventional data -- assuming a fully specified model is
not available to evaluate these functions. We complement this line of work by
proposing the first exact algorithm for finding optimal units given a broad
class of causal objective functions and a fully specified structural causal
model (SCM). We show that unit selection under this class of objective
functions is $\text{NP}^\text{PP}$-complete but is $\text{NP}$-complete when
unit variables correspond to all exogenous variables in the SCM. We also
provide treewidth-based complexity bounds on our proposed algorithm while
relating it to a well-known algorithm for Maximum a Posteriori (MAP) inference.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haiying Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Darwiche_A/0/1/0/all/0/1">Adnan Darwiche</a></p><p>The unit selection problem aims to identify objects, called units, that are
most likely to exhibit a desired mode of behavior when subjected to stimuli
(e.g., customers who are about to churn but would change their mind if
encouraged). Unit selection with counterfactual objective functions was
introduced relatively recently with existing work focusing on bounding a
specific class of objective functions, called the benefit functions, based on
observational and interventional data -- assuming a fully specified model is
not available to evaluate these functions. We complement this line of work by
proposing the first exact algorithm for finding optimal units given a broad
class of causal objective functions and a fully specified structural causal
model (SCM). We show that unit selection under this class of objective
functions is $\text{NP}^\text{PP}$-complete but is $\text{NP}$-complete when
unit variables correspond to all exogenous variables in the SCM. We also
provide treewidth-based complexity bounds on our proposed algorithm while
relating it to a well-known algorithm for Maximum a Posteriori (MAP) inference.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14585'>On Degeneracy in the P-Matroid Oriented Matroid Complementarity Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michaela Borzechowski, Simon Weber</p><p>We investigate degeneracy in the P-Matroid Oriented Matroid Complementarity
Problem (P-OMCP) and its impact on the reduction of this problem to
sink-finding in Unique Sink Orientations (USOs). On one hand, this
understanding of degeneracies allows us to prove a linear lower bound for
sink-finding in P-matroid USOs. On the other hand, it allows us to prove a
promise preserving reduction from P-OMCP to USO sink-finding, where we can drop
the assumption that the given P-OMCP is non-degenerate. This places the promise
version of P-OMCP in the complexity class PromiseUEOPL.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Borzechowski_M/0/1/0/all/0/1">Michaela Borzechowski</a>, <a href="http://arxiv.org/find/math/1/au:+Weber_S/0/1/0/all/0/1">Simon Weber</a></p><p>We investigate degeneracy in the P-Matroid Oriented Matroid Complementarity
Problem (P-OMCP) and its impact on the reduction of this problem to
sink-finding in Unique Sink Orientations (USOs). On one hand, this
understanding of degeneracies allows us to prove a linear lower bound for
sink-finding in P-matroid USOs. On the other hand, it allows us to prove a
promise preserving reduction from P-OMCP to USO sink-finding, where we can drop
the assumption that the given P-OMCP is non-degenerate. This places the promise
version of P-OMCP in the complexity class PromiseUEOPL.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14755'>Local Hamiltonians with no low-energy stabilizer states</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nolan J. Coble, Matthew Coudron, Jon Nelson, Seyed Sajjad Nezhadi</p><p>The recently-defined No Low-energy Sampleable States (NLSS) conjecture of
Gharibian and Le Gall [GL22] posits the existence of a family of local
Hamiltonians where all states of low-enough constant energy do not have
succinct representations allowing perfect sampling access. States that can be
prepared using only Clifford gates (i.e. stabilizer states) are an example of
sampleable states, so the NLSS conjecture implies the existence of local
Hamiltonians whose low-energy space contains no stabilizer states. We describe
families that exhibit this requisite property via a simple alteration to local
Hamiltonians corresponding to CSS codes. Our method can also be applied to the
recent NLTS Hamiltonians of Anshu, Breuckmann, and Nirkhe [ABN22], resulting in
a family of local Hamiltonians whose low-energy space contains neither
stabilizer states nor trivial states. We hope that our techniques will
eventually be helpful for constructing Hamiltonians which simultaneously
satisfy NLSS and NLTS.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Coble_N/0/1/0/all/0/1">Nolan J. Coble</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Coudron_M/0/1/0/all/0/1">Matthew Coudron</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nelson_J/0/1/0/all/0/1">Jon Nelson</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nezhadi_S/0/1/0/all/0/1">Seyed Sajjad Nezhadi</a></p><p>The recently-defined No Low-energy Sampleable States (NLSS) conjecture of
Gharibian and Le Gall [GL22] posits the existence of a family of local
Hamiltonians where all states of low-enough constant energy do not have
succinct representations allowing perfect sampling access. States that can be
prepared using only Clifford gates (i.e. stabilizer states) are an example of
sampleable states, so the NLSS conjecture implies the existence of local
Hamiltonians whose low-energy space contains no stabilizer states. We describe
families that exhibit this requisite property via a simple alteration to local
Hamiltonians corresponding to CSS codes. Our method can also be applied to the
recent NLTS Hamiltonians of Anshu, Breuckmann, and Nirkhe [ABN22], resulting in
a family of local Hamiltonians whose low-energy space contains neither
stabilizer states nor trivial states. We hope that our techniques will
eventually be helpful for constructing Hamiltonians which simultaneously
satisfy NLSS and NLTS.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14125'>A Note on the Faces of the Dual Koch Arrangement</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bernd G&#xe4;rtner, Manuel Wettstein</p><p>We analyze the faces of the dual Koch arrangement, which is the arrangement
of $2^s + 1$ lines obtained by projective duality from the Koch chain $K_s$. In
particular, we show that this line arrangement does not contain any $k$-gons
for $k &gt; 5$, and that the number of pentagons is $3 \cdot 2^{s-1} - 3$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gartner_B/0/1/0/all/0/1">Bernd G&#xe4;rtner</a>, <a href="http://arxiv.org/find/cs/1/au:+Wettstein_M/0/1/0/all/0/1">Manuel Wettstein</a></p><p>We analyze the faces of the dual Koch arrangement, which is the arrangement
of $2^s + 1$ lines obtained by projective duality from the Koch chain $K_s$. In
particular, we show that this line arrangement does not contain any $k$-gons
for $k &gt; 5$, and that the number of pentagons is $3 \cdot 2^{s-1} - 3$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14213'>Crossing Minimization in Time Interval Storylines</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Dobler, Martin N&#xf6;llenburg, Daniel Stojanovic, Ana&#xef;s Villedieu, Jules Wulms</p><p>Storyline visualizations are a popular way of visualizing characters and
their interactions over time: Characters are drawn as x-monotone curves and
interactions are visualized through close proximity of the corresponding
character curves in a vertical strip. Existing methods to generate storylines
assume a total ordering of the interactions, although real-world data often do
not contain such a total order. Instead, multiple interactions are often
grouped into coarser time intervals such as years. We exploit this grouping
property by introducing a new model called storylines with time intervals and
present two methods to minimize the number of crossings and horizontal space
usage. We then evaluate these algorithms on a small benchmark set to show their
effectiveness.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dobler_A/0/1/0/all/0/1">Alexander Dobler</a>, <a href="http://arxiv.org/find/cs/1/au:+Nollenburg_M/0/1/0/all/0/1">Martin N&#xf6;llenburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Stojanovic_D/0/1/0/all/0/1">Daniel Stojanovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Villedieu_A/0/1/0/all/0/1">Ana&#xef;s Villedieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wulms_J/0/1/0/all/0/1">Jules Wulms</a></p><p>Storyline visualizations are a popular way of visualizing characters and
their interactions over time: Characters are drawn as x-monotone curves and
interactions are visualized through close proximity of the corresponding
character curves in a vertical strip. Existing methods to generate storylines
assume a total ordering of the interactions, although real-world data often do
not contain such a total order. Instead, multiple interactions are often
grouped into coarser time intervals such as years. We exploit this grouping
property by introducing a new model called storylines with time intervals and
present two methods to minimize the number of crossings and horizontal space
usage. We then evaluate these algorithms on a small benchmark set to show their
effectiveness.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14251'>LaplacianFusion: Detailed 3D Clothed-Human Body Reconstruction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hyomin Kim, Hyeonseo Nam, Jungeon Kim, Jaesik Park, Seungyong Lee</p><p>We propose LaplacianFusion, a novel approach that reconstructs detailed and
controllable 3D clothed-human body shapes from an input depth or 3D point cloud
sequence. The key idea of our approach is to use Laplacian coordinates,
well-known differential coordinates that have been used for mesh editing, for
representing the local structures contained in the input scans, instead of
implicit 3D functions or vertex displacements used previously. Our approach
reconstructs a controllable base mesh using SMPL, and learns a surface function
that predicts Laplacian coordinates representing surface details on the base
mesh. For a given pose, we first build and subdivide a base mesh, which is a
deformed SMPL template, and then estimate Laplacian coordinates for the mesh
vertices using the surface function. The final reconstruction for the pose is
obtained by integrating the estimated Laplacian coordinates as a whole.
Experimental results show that our approach based on Laplacian coordinates
successfully reconstructs more visually pleasing shape details than previous
methods. The approach also enables various surface detail manipulations, such
as detail transfer and enhancement.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyomin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Nam_H/0/1/0/all/0/1">Hyeonseo Nam</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jungeon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jaesik Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seungyong Lee</a></p><p>We propose LaplacianFusion, a novel approach that reconstructs detailed and
controllable 3D clothed-human body shapes from an input depth or 3D point cloud
sequence. The key idea of our approach is to use Laplacian coordinates,
well-known differential coordinates that have been used for mesh editing, for
representing the local structures contained in the input scans, instead of
implicit 3D functions or vertex displacements used previously. Our approach
reconstructs a controllable base mesh using SMPL, and learns a surface function
that predicts Laplacian coordinates representing surface details on the base
mesh. For a given pose, we first build and subdivide a base mesh, which is a
deformed SMPL template, and then estimate Laplacian coordinates for the mesh
vertices using the surface function. The final reconstruction for the pose is
obtained by integrating the estimated Laplacian coordinates as a whole.
Experimental results show that our approach based on Laplacian coordinates
successfully reconstructs more visually pleasing shape details than previous
methods. The approach also enables various surface detail manipulations, such
as detail transfer and enhancement.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14721'>On the geometric thickness of 2-degenerate graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rahul Jain, Marco Ricci, Jonathan Rollin, Andr&#xe9; Schulz</p><p>A graph is 2-degenerate if every subgraph contains a vertex of degree at most
2. We show that every 2-degenerate graph can be drawn with straight lines such
that the drawing decomposes into 4 plane forests. Therefore, the geometric
arboricity, and hence the geometric thickness, of 2-degenerate graphs is at
most 4. On the other hand, we show that there are 2-degenerate graphs that do
not admit any straight-line drawing with a decomposition of the edge set into 2
plane graphs. That is, there are 2-degenerate graphs with geometric thickness,
and hence geometric arboricity, at least 3. This answers two questions posed by
Eppstein [Separating thickness from geometric thickness. In Towards a Theory of
Geometric Graphs, vol. 342 of Contemp. Math., AMS, 2004].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Jain_R/0/1/0/all/0/1">Rahul Jain</a>, <a href="http://arxiv.org/find/math/1/au:+Ricci_M/0/1/0/all/0/1">Marco Ricci</a>, <a href="http://arxiv.org/find/math/1/au:+Rollin_J/0/1/0/all/0/1">Jonathan Rollin</a>, <a href="http://arxiv.org/find/math/1/au:+Schulz_A/0/1/0/all/0/1">Andr&#xe9; Schulz</a></p><p>A graph is 2-degenerate if every subgraph contains a vertex of degree at most
2. We show that every 2-degenerate graph can be drawn with straight lines such
that the drawing decomposes into 4 plane forests. Therefore, the geometric
arboricity, and hence the geometric thickness, of 2-degenerate graphs is at
most 4. On the other hand, we show that there are 2-degenerate graphs that do
not admit any straight-line drawing with a decomposition of the edge set into 2
plane graphs. That is, there are 2-degenerate graphs with geometric thickness,
and hence geometric arboricity, at least 3. This answers two questions posed by
Eppstein [Separating thickness from geometric thickness. In Towards a Theory of
Geometric Graphs, vol. 342 of Contemp. Math., AMS, 2004].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14066'>Query-optimal estimation of unitary channels in diamond distance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jeongwan Haah, Robin Kothari, Ryan O&#x27;Donnell, Ewin Tang</p><p>We consider process tomography for unitary quantum channels. Given access to
an unknown unitary channel acting on a $\textsf{d}$-dimensional qudit, we aim
to output a classical description of a unitary that is $\varepsilon$-close to
the unknown unitary in diamond norm. We design an algorithm achieving error
$\varepsilon$ using $O(\textsf{d}^2/\varepsilon)$ applications of the unknown
channel and only one qudit. This improves over prior results, which use
$O(\textsf{d}^3/\varepsilon^2)$ [via standard process tomography] or
$O(\textsf{d}^{2.5}/\varepsilon)$ [Yang, Renner, and Chiribella, PRL 2020]
applications. To show this result, we introduce a simple technique to
"bootstrap" an algorithm that can produce constant-error estimates to one that
can produce $\varepsilon$-error estimates with the Heisenberg scaling. Finally,
we prove a complementary lower bound showing that estimation requires
$\Omega(\textsf{d}^2/\varepsilon)$ applications, even with access to the
inverse or controlled versions of the unknown unitary. This shows that our
algorithm has both optimal query complexity and optimal space complexity.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Haah_J/0/1/0/all/0/1">Jeongwan Haah</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kothari_R/0/1/0/all/0/1">Robin Kothari</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+ODonnell_R/0/1/0/all/0/1">Ryan O&#x27;Donnell</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tang_E/0/1/0/all/0/1">Ewin Tang</a></p><p>We consider process tomography for unitary quantum channels. Given access to
an unknown unitary channel acting on a $\textsf{d}$-dimensional qudit, we aim
to output a classical description of a unitary that is $\varepsilon$-close to
the unknown unitary in diamond norm. We design an algorithm achieving error
$\varepsilon$ using $O(\textsf{d}^2/\varepsilon)$ applications of the unknown
channel and only one qudit. This improves over prior results, which use
$O(\textsf{d}^3/\varepsilon^2)$ [via standard process tomography] or
$O(\textsf{d}^{2.5}/\varepsilon)$ [Yang, Renner, and Chiribella, PRL 2020]
applications. To show this result, we introduce a simple technique to
"bootstrap" an algorithm that can produce constant-error estimates to one that
can produce $\varepsilon$-error estimates with the Heisenberg scaling. Finally,
we prove a complementary lower bound showing that estimation requires
$\Omega(\textsf{d}^2/\varepsilon)$ applications, even with access to the
inverse or controlled versions of the unknown unitary. This shows that our
algorithm has both optimal query complexity and optimal space complexity.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14099'>On Differentially Private Online Predictions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Haim Kaplan, Yishay Mansour, Shay Moran, Kobbi Nissim, Uri Stemmer</p><p>In this work we introduce an interactive variant of joint differential
privacy towards handling online processes in which existing privacy definitions
seem too restrictive. We study basic properties of this definition and
demonstrate that it satisfies (suitable variants) of group privacy,
composition, and post processing. We then study the cost of interactive joint
privacy in the basic setting of online classification. We show that any
(possibly non-private) learning rule can be effectively transformed to a
private learning rule with only a polynomial overhead in the mistake bound.
This demonstrates a stark difference with more restrictive notions of privacy
such as the one studied by Golowich and Livni (2021), where only a double
exponential overhead on the mistake bound is known (via an information
theoretic upper bound).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kaplan_H/0/1/0/all/0/1">Haim Kaplan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1">Yishay Mansour</a>, <a href="http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1">Shay Moran</a>, <a href="http://arxiv.org/find/cs/1/au:+Nissim_K/0/1/0/all/0/1">Kobbi Nissim</a>, <a href="http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1">Uri Stemmer</a></p><p>In this work we introduce an interactive variant of joint differential
privacy towards handling online processes in which existing privacy definitions
seem too restrictive. We study basic properties of this definition and
demonstrate that it satisfies (suitable variants) of group privacy,
composition, and post processing. We then study the cost of interactive joint
privacy in the basic setting of online classification. We show that any
(possibly non-private) learning rule can be effectively transformed to a
private learning rule with only a polynomial overhead in the mistake bound.
This demonstrates a stark difference with more restrictive notions of privacy
such as the one studied by Golowich and Livni (2021), where only a double
exponential overhead on the mistake bound is known (via an information
theoretic upper bound).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14128'>Tight Algorithms for Connectivity Problems Parameterized by Modular-Treewidth</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Falko Hegerfeld, Stefan Kratsch</p><p>We study connectivity problems from a fine-grained parameterized perspective.
Cygan et al. (TALG 2022) obtained algorithms with single-exponential running
time $\alpha^{tw} n^{O(1)}$ for connectivity problems parameterized by
treewidth ($tw$) by introducing the cut-and-count-technique, which reduces
connectivity problems to locally checkable counting problems. In addition, the
bases $\alpha$ were proven to be optimal assuming the Strong Exponential-Time
Hypothesis (SETH).
</p>
<p>As only sparse graphs may admit small treewidth, these results do not apply
to graphs with dense structure. A well-known tool to capture dense structure is
the modular decomposition, which recursively partitions the graph into modules
whose members have the same neighborhood outside of the module. Contracting the
modules yields a quotient graph describing the adjacencies between modules.
Measuring the treewidth of the quotient graph yields the parameter
modular-treewidth, a natural intermediate step between treewidth and
clique-width.
</p>
<p>We obtain the first tight running times for connectivity problems
parameterized by modular-treewidth. For some problems the obtained bounds are
the same as relative to treewidth, showing that we can deal with a greater
generality in input structure at no cost in complexity. We obtain the following
randomized algorithms for graphs of modular-treewidth $k$, given an appropriate
decomposition: Steiner Tree can be solved in time $3^k n^{O(1)}$, Connected
Dominating Set can be solved in time $4^k n^{O(1)}$, Connected Vertex Cover can
be solved in time $5^k n^{O(1)}$, Feedback Vertex Set can be solved in time
$5^k n^{O(1)}$.
</p>
<p>The first two algorithms are tight due to known results and the last two
algorithms are complemented by new tight lower bounds under SETH.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hegerfeld_F/0/1/0/all/0/1">Falko Hegerfeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Kratsch_S/0/1/0/all/0/1">Stefan Kratsch</a></p><p>We study connectivity problems from a fine-grained parameterized perspective.
Cygan et al. (TALG 2022) obtained algorithms with single-exponential running
time $\alpha^{tw} n^{O(1)}$ for connectivity problems parameterized by
treewidth ($tw$) by introducing the cut-and-count-technique, which reduces
connectivity problems to locally checkable counting problems. In addition, the
bases $\alpha$ were proven to be optimal assuming the Strong Exponential-Time
Hypothesis (SETH).
</p>
<p>As only sparse graphs may admit small treewidth, these results do not apply
to graphs with dense structure. A well-known tool to capture dense structure is
the modular decomposition, which recursively partitions the graph into modules
whose members have the same neighborhood outside of the module. Contracting the
modules yields a quotient graph describing the adjacencies between modules.
Measuring the treewidth of the quotient graph yields the parameter
modular-treewidth, a natural intermediate step between treewidth and
clique-width.
</p>
<p>We obtain the first tight running times for connectivity problems
parameterized by modular-treewidth. For some problems the obtained bounds are
the same as relative to treewidth, showing that we can deal with a greater
generality in input structure at no cost in complexity. We obtain the following
randomized algorithms for graphs of modular-treewidth $k$, given an appropriate
decomposition: Steiner Tree can be solved in time $3^k n^{O(1)}$, Connected
Dominating Set can be solved in time $4^k n^{O(1)}$, Connected Vertex Cover can
be solved in time $5^k n^{O(1)}$, Feedback Vertex Set can be solved in time
$5^k n^{O(1)}$.
</p>
<p>The first two algorithms are tight due to known results and the last two
algorithms are complemented by new tight lower bounds under SETH.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14168'>Signal Propagation in Double Edged Relays</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adam Boucher</p><p>A discrete signal propagation model blending characteristics of linear wave
propagation and finite state automata is developed. We show this model obeys a
limited form of superposition and is capable of displaying a wide variety of
interesting behaviors. We show how the model's superposition properties permit
information to be encoded and retained by signals that pass through discrete
networks. We outline a SPIDER model replacement for Dijkstra's algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Boucher_A/0/1/0/all/0/1">Adam Boucher</a></p><p>A discrete signal propagation model blending characteristics of linear wave
propagation and finite state automata is developed. We show this model obeys a
limited form of superposition and is capable of displaying a wide variety of
interesting behaviors. We show how the model's superposition properties permit
information to be encoded and retained by signals that pass through discrete
networks. We outline a SPIDER model replacement for Dijkstra's algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14324'>A CS guide to the quantum singular value transformation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ewin Tang, Kevin Tian</p><p>We present a simplified exposition of some pieces of [Gily\'en, Su, Low, and
Wiebe, STOC'19, arXiv:1806.01838], who introduced a quantum singular value
transformation (QSVT) framework for applying polynomial functions to
block-encoded matrices. The QSVT framework has garnered substantial recent
interest from the quantum algorithms community, as it was demonstrated by
[GSLW19] to encapsulate many existing algorithms naturally phrased as an
application of a matrix function. First, we posit that the lifting of quantum
singular processing (QSP) to QSVT is better viewed not through Jordan's lemma
(as was suggested by [GSLW19]) but as an application of the cosine-sine
decomposition, which can be thought of as a more explicit and stronger version
of Jordan's lemma. Second, we demonstrate that the constructions of bounded
polynomial approximations given in [GSLW19], which use a variety of ad hoc
approaches drawing from Fourier analysis, Chebyshev series, and Taylor series,
can be unified under the framework of truncation of Chebyshev series, and
indeed, can in large part be matched via a bounded variant of a standard
meta-theorem from [Trefethen, 2013]. We hope this work finds use to the
community as a companion guide for understanding and applying the powerful
framework of [GSLW19].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Tang_E/0/1/0/all/0/1">Ewin Tang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tian_K/0/1/0/all/0/1">Kevin Tian</a></p><p>We present a simplified exposition of some pieces of [Gily\'en, Su, Low, and
Wiebe, STOC'19, <a href="/abs/1806.01838">arXiv:1806.01838</a>], who introduced a quantum singular value
transformation (QSVT) framework for applying polynomial functions to
block-encoded matrices. The QSVT framework has garnered substantial recent
interest from the quantum algorithms community, as it was demonstrated by
[GSLW19] to encapsulate many existing algorithms naturally phrased as an
application of a matrix function. First, we posit that the lifting of quantum
singular processing (QSP) to QSVT is better viewed not through Jordan's lemma
(as was suggested by [GSLW19]) but as an application of the cosine-sine
decomposition, which can be thought of as a more explicit and stronger version
of Jordan's lemma. Second, we demonstrate that the constructions of bounded
polynomial approximations given in [GSLW19], which use a variety of ad hoc
approaches drawing from Fourier analysis, Chebyshev series, and Taylor series,
can be unified under the framework of truncation of Chebyshev series, and
indeed, can in large part be matched via a bounded variant of a standard
meta-theorem from [Trefethen, 2013]. We hope this work finds use to the
community as a companion guide for understanding and applying the powerful
framework of [GSLW19].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14386'>Practical Algorithms for Orientations of Partially Directed Graphical Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Malte Luttermann, Marcel Wien&#xf6;bst, Maciej Li&#x15b;kiewicz</p><p>In observational studies, the true causal model is typically unknown and
needs to be estimated from available observational and limited experimental
data. In such cases, the learned causal model is commonly represented as a
partially directed acyclic graph (PDAG), which contains both directed and
undirected edges indicating uncertainty of causal relations between random
variables. The main focus of this paper is on the maximal orientation task,
which, for a given PDAG, aims to orient the undirected edges maximally such
that the resulting graph represents the same Markov equivalent DAGs as the
input PDAG. This task is a subroutine used frequently in causal discovery, e.
g., as the final step of the celebrated PC algorithm. Utilizing connections to
the problem of finding a consistent DAG extension of a PDAG, we derive faster
algorithms for computing the maximal orientation by proposing two novel
approaches for extending PDAGs, both constructed with an emphasis on simplicity
and practical effectiveness.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Luttermann_M/0/1/0/all/0/1">Malte Luttermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Wienobst_M/0/1/0/all/0/1">Marcel Wien&#xf6;bst</a>, <a href="http://arxiv.org/find/cs/1/au:+Liskiewicz_M/0/1/0/all/0/1">Maciej Li&#x15b;kiewicz</a></p><p>In observational studies, the true causal model is typically unknown and
needs to be estimated from available observational and limited experimental
data. In such cases, the learned causal model is commonly represented as a
partially directed acyclic graph (PDAG), which contains both directed and
undirected edges indicating uncertainty of causal relations between random
variables. The main focus of this paper is on the maximal orientation task,
which, for a given PDAG, aims to orient the undirected edges maximally such
that the resulting graph represents the same Markov equivalent DAGs as the
input PDAG. This task is a subroutine used frequently in causal discovery, e.
g., as the final step of the celebrated PC algorithm. Utilizing connections to
the problem of finding a consistent DAG extension of a PDAG, we derive faster
algorithms for computing the maximal orientation by proposing two novel
approaches for extending PDAGs, both constructed with an emphasis on simplicity
and practical effectiveness.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14421'>Publicly verifiable delegative democracy with secret voting power</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dimitrios Karoukis</p><p>We use a commitment scheme to track every individual's voting power on a
public ledger with the ability to validate transfers and transitive, reversible
delegations of it between them without sacrificing their privacy. Every unit of
voting power is represented by the Merkle root of a tree consisting of its
latest owner's public key, a random nonce and the Merkle root of the tree of
its previous owner's public key and random nonce and so on. Transfers and
delegations mention the input units, their owner's public keys, the hashes of
their nonces and the output units, which are the Merkle roots of the new
owners' public keys, new random nonces and the previous units' identifiers. In
case of a delegation, the receiver provides the sender with the hashed random
nonces and the hashed public keys whose secret keys they control. In case of a
transfer, only the hashes of these hashes' concatenations are provided. To
reverse a delegation, a historical owner reveals the individual hashes that
resulted the subsequent units. In voting, the owner reveals the actual nonces
and public keys of the units.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Karoukis_D/0/1/0/all/0/1">Dimitrios Karoukis</a></p><p>We use a commitment scheme to track every individual's voting power on a
public ledger with the ability to validate transfers and transitive, reversible
delegations of it between them without sacrificing their privacy. Every unit of
voting power is represented by the Merkle root of a tree consisting of its
latest owner's public key, a random nonce and the Merkle root of the tree of
its previous owner's public key and random nonce and so on. Transfers and
delegations mention the input units, their owner's public keys, the hashes of
their nonces and the output units, which are the Merkle roots of the new
owners' public keys, new random nonces and the previous units' identifiers. In
case of a delegation, the receiver provides the sender with the hashed random
nonces and the hashed public keys whose secret keys they control. In case of a
transfer, only the hashes of these hashes' concatenations are provided. To
reverse a delegation, a historical owner reveals the individual hashes that
resulted the subsequent units. In voting, the owner reveals the actual nonces
and public keys of the units.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14692'>Massively Parallel Computation in a Heterogeneous Regime</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Orr Fischer, Adi Horowitz, Rotem Oshman</p><p>Massively-parallel graph algorithms have received extensive attention over
the past decade, with research focusing on three memory regimes: the
superlinear regime, the near-linear regime, and the sublinear regime. The
sublinear regime is the most desirable in practice, but conditional hardness
results point towards its limitations.
</p>
<p>In this work we study a \emph{heterogeneous} model, where the memory of the
machines varies in size. We focus mostly on the heterogeneous setting created
by adding a single near-linear machine to the sublinear MPC regime, and show
that even a single large machine suffices to circumvent most of the conditional
hardness results for the sublinear regime: for graphs with $n$ vertices and $m$
edges, we give (a) an MST algorithm that runs in $O(\log\log(m/n))$ rounds; (b)
an algorithm that constructs an $O(k)$-spanner of size $O(n^{1+1/k})$ in $O(1)$
rounds; and (c) a maximal-matching algorithm that runs in
$O(\sqrt{\log(m/n)}\log\log(m/n))$ rounds.
</p>
<p>We also observe that the best known near-linear MPC algorithms for several
other graph problems which are conjectured to be hard in the sublinear regime
(minimum cut, maximal independent set, and vertex coloring) can easily be
transformed to work in the heterogeneous MPC model with a single near-linear
machine, while retaining their original round complexity in the near-linear
regime. If the large machine is allowed to have \emph{superlinear} memory, all
of the problems above can be solved in $O(1)$ rounds.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fischer_O/0/1/0/all/0/1">Orr Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Horowitz_A/0/1/0/all/0/1">Adi Horowitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Oshman_R/0/1/0/all/0/1">Rotem Oshman</a></p><p>Massively-parallel graph algorithms have received extensive attention over
the past decade, with research focusing on three memory regimes: the
superlinear regime, the near-linear regime, and the sublinear regime. The
sublinear regime is the most desirable in practice, but conditional hardness
results point towards its limitations.
</p>
<p>In this work we study a \emph{heterogeneous} model, where the memory of the
machines varies in size. We focus mostly on the heterogeneous setting created
by adding a single near-linear machine to the sublinear MPC regime, and show
that even a single large machine suffices to circumvent most of the conditional
hardness results for the sublinear regime: for graphs with $n$ vertices and $m$
edges, we give (a) an MST algorithm that runs in $O(\log\log(m/n))$ rounds; (b)
an algorithm that constructs an $O(k)$-spanner of size $O(n^{1+1/k})$ in $O(1)$
rounds; and (c) a maximal-matching algorithm that runs in
$O(\sqrt{\log(m/n)}\log\log(m/n))$ rounds.
</p>
<p>We also observe that the best known near-linear MPC algorithms for several
other graph problems which are conjectured to be hard in the sublinear regime
(minimum cut, maximal independent set, and vertex coloring) can easily be
transformed to work in the heterogeneous MPC model with a single near-linear
machine, while retaining their original round complexity in the near-linear
regime. If the large machine is allowed to have \emph{superlinear} memory, all
of the problems above can be solved in $O(1)$ rounds.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14698'>Heuristic Modularity Maximization Algorithms for Community Detection Rarely Return an Optimal Partition or Anything Similar</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samin Aref, Mahdi Mostajabdaveh, Hriday Chheda</p><p>Community detection is a classic problem in network science with extensive
applications in various fields. The most commonly used methods are the
algorithms designed to maximize modularity over different partitions of the
network nodes into communities. Using 80 real and random networks from a wide
range of contexts, we investigate the extent to which current heuristic
modularity maximization algorithms succeed in returning modularity-maximum
(optimal) partitions. We evaluate (1) the ratio of their output modularity to
the maximum modularity for each input graph and (2) the maximum similarity
between their output partition and any optimal partition of that graph. Our
computational experiments involve eight existing heuristic algorithms which we
compare against an exact integer programming method that globally maximizes
modularity. The average modularity-based heuristic algorithm returns optimal
partitions for only 16.9% of the 80 graphs considered. Results on adjusted
mutual information show considerable dissimilarity between the sub-optimal
partitions and any optimal partitions of the graphs in our experiments. More
importantly, our results show that near-optimal partitions tend to be
disproportionally dissimilar to any optimal partition. Taken together, our
analysis points to a crucial limitation of commonly used modularity-based
algorithms for discovering communities: they rarely return an optimal partition
or a partition resembling an optimal partition. Given this finding, developing
an exact or approximate algorithm for modularity maximization is recommendable
for a more methodologically sound usage of modularity in community detection.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aref_S/0/1/0/all/0/1">Samin Aref</a>, <a href="http://arxiv.org/find/cs/1/au:+Mostajabdaveh_M/0/1/0/all/0/1">Mahdi Mostajabdaveh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chheda_H/0/1/0/all/0/1">Hriday Chheda</a></p><p>Community detection is a classic problem in network science with extensive
applications in various fields. The most commonly used methods are the
algorithms designed to maximize modularity over different partitions of the
network nodes into communities. Using 80 real and random networks from a wide
range of contexts, we investigate the extent to which current heuristic
modularity maximization algorithms succeed in returning modularity-maximum
(optimal) partitions. We evaluate (1) the ratio of their output modularity to
the maximum modularity for each input graph and (2) the maximum similarity
between their output partition and any optimal partition of that graph. Our
computational experiments involve eight existing heuristic algorithms which we
compare against an exact integer programming method that globally maximizes
modularity. The average modularity-based heuristic algorithm returns optimal
partitions for only 16.9% of the 80 graphs considered. Results on adjusted
mutual information show considerable dissimilarity between the sub-optimal
partitions and any optimal partitions of the graphs in our experiments. More
importantly, our results show that near-optimal partitions tend to be
disproportionally dissimilar to any optimal partition. Taken together, our
analysis points to a crucial limitation of commonly used modularity-based
algorithms for discovering communities: they rarely return an optimal partition
or a partition resembling an optimal partition. Given this finding, developing
an exact or approximate algorithm for modularity maximization is recommendable
for a more methodologically sound usage of modularity in community detection.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14725'>Parameterized Complexity of Vertex Splitting to Pathwidth at most 1</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jakob Baumann, Matthias Pfretzschner, Ignaz Rutter</p><p>Motivated by the planarization of 2-layered straight-line drawings, we
consider the problem of modifying a graph such that the resulting graph has
pathwidth at most 1. The problem Pathwidth-One Vertex Explosion (POVE) asks
whether such a graph can be obtained using at most $k$ vertex explosions, where
a vertex explosion replaces a vertex $v$ by deg$(v)$ degree-1 vertices, each
incident to exactly one edge that was originally incident to $v$. For POVE, we
give an FPT algorithm with running time $O(4^k \cdot m)$ and a quadratic
kernel, thereby improving over the $O(k^6)$-kernel by Ahmed et al. [GD 22] in a
more general setting. Similarly, a vertex split replaces a vertex $v$ by two
distinct vertices $v_1$ and $v_2$ and distributes the edges originally incident
to $v$ arbitrarily to $v_1$ and $v_2$. Analogously to POVE, we define the
problem variant Pathwidth-One Vertex Splitting (POVS) that uses the split
operation instead of vertex explosions. Here we obtain a linear kernel and an
algorithm with running time $O((6k+12)^k \cdot m)$. This answers an open
question by Ahmed et al. [GD22].
</p>
<p>Finally, we consider the problem $\Pi$ Vertex Splitting ($\Pi$-VS), which
generalizes the problem POVS and asks whether a given graph can be turned into
a graph of a specific graph class $\Pi$ using at most $k$ vertex splits. For
graph classes $\Pi$ that can be tested in monadic second-order graph logic
(MSO$_2$), we show that the problem $\Pi$-VS can be expressed as an MSO$_2$
formula, resulting in an FPT algorithm for $\Pi$-VS parameterized by $k$ if
$\Pi$ additionally has bounded treewidth. We obtain the same result for the
problem variant using vertex explosions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Baumann_J/0/1/0/all/0/1">Jakob Baumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfretzschner_M/0/1/0/all/0/1">Matthias Pfretzschner</a>, <a href="http://arxiv.org/find/cs/1/au:+Rutter_I/0/1/0/all/0/1">Ignaz Rutter</a></p><p>Motivated by the planarization of 2-layered straight-line drawings, we
consider the problem of modifying a graph such that the resulting graph has
pathwidth at most 1. The problem Pathwidth-One Vertex Explosion (POVE) asks
whether such a graph can be obtained using at most $k$ vertex explosions, where
a vertex explosion replaces a vertex $v$ by deg$(v)$ degree-1 vertices, each
incident to exactly one edge that was originally incident to $v$. For POVE, we
give an FPT algorithm with running time $O(4^k \cdot m)$ and a quadratic
kernel, thereby improving over the $O(k^6)$-kernel by Ahmed et al. [GD 22] in a
more general setting. Similarly, a vertex split replaces a vertex $v$ by two
distinct vertices $v_1$ and $v_2$ and distributes the edges originally incident
to $v$ arbitrarily to $v_1$ and $v_2$. Analogously to POVE, we define the
problem variant Pathwidth-One Vertex Splitting (POVS) that uses the split
operation instead of vertex explosions. Here we obtain a linear kernel and an
algorithm with running time $O((6k+12)^k \cdot m)$. This answers an open
question by Ahmed et al. [GD22].
</p>
<p>Finally, we consider the problem $\Pi$ Vertex Splitting ($\Pi$-VS), which
generalizes the problem POVS and asks whether a given graph can be turned into
a graph of a specific graph class $\Pi$ using at most $k$ vertex splits. For
graph classes $\Pi$ that can be tested in monadic second-order graph logic
(MSO$_2$), we show that the problem $\Pi$-VS can be expressed as an MSO$_2$
formula, resulting in an FPT algorithm for $\Pi$-VS parameterized by $k$ if
$\Pi$ additionally has bounded treewidth. We obtain the same result for the
problem variant using vertex explosions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, February 28
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/02/28/linkage-200k-edits.html'>Linkage for 200,000 edits to Wikipedia</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government (\(\mathbb{M}\)), including guidelines for equitable use of AI and automated systems through a new Blueprint for an AI Bill of Rights (that is, rights for people to be protected against unfair uses of AI, not rights for artificial intelligences).
        
        </div>

        <div class='tr-article-summary'>
        
          
          <ul>
  <li>
    <p><a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/02/16/executive-order-on-further-advancing-racial-equity-and-support-for-underserved-communities-through-the-federal-government/">Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@sorelle@mastodon.social/109875326202971711">\(\mathbb{M}\)</a>),</span> including guidelines for equitable use of AI and automated systems through a new <a href="https://www.whitehouse.gov/ostp/ai-bill-of-rights/">Blueprint for an AI Bill of Rights</a> (that is, rights for people to be protected against unfair uses of AI, not rights for artificial intelligences).</p>
  </li>
  <li>
    <p><a href="https://press.princeton.edu/ideas/why-prove-it">Why prove it?</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@highergeometer/109854745668334423">\(\mathbb{M}\)</a>,</span> <a href="https://www.math.columbia.edu/~woit/wordpress/?p=13288">via</a>). John Stillwell on human-written vs machine-checkable proofs, with reference to the abc conjecture.</p>
  </li>
  <li>
    <p><a href="https://www.ics.uci.edu/~eppstein/pix/ltcc/index.html">Low tide at Crystal Cove State Park</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109894403539276698">\(\mathbb{M}\)</a>).</span></p>

    <p style="text-align:center"><img src="https://www.ics.uci.edu/~eppstein/pix/ltcc/Seagrass2-m.jpg" alt="Low tide at Crystal Cove State Park, California" style="border-style:solid;border-color:black" /></p>
  </li>
  <li>
    <p>Another newly promoted Wikipedia Good Article: <a href="https://en.wikipedia.org/wiki/Polygonalization">Polygonalization</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109906715996859674">\(\mathbb{M}\)</a>),</span> about finding a polygon that uses all of a given set of points as vertices. The usual definitions allow it to go straight through some of the vertices, rather than always turning, though, and the illustration below shows why: for some point sets, including 3x3 grids, a polygon that turns everywhere might not exist.</p>

    <p style="text-align:center"><img src="/blog/assets/2023/3x3_grid_polygonalizations.svg" alt="Eight ways of polygonalizing a 3x3 grid" /></p>
  </li>
  <li>
    <p><a href="https://terrytao.wordpress.com/2023/02/18/would-it-be-possible-to-create-a-tool-to-automatically-diagram-papers/">Would it be possible to create a tool to automatically diagram papers?</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@tao/109887019658810502">\(\mathbb{M}\)</a>),</span> by Terry Tao, inspired by the diagrams the proof-assistant people have been using to guide their work.</p>
  </li>
  <li>
    <p>People who indulge in the fringe belief in the reality of certain folklore beasts are sad that <a href="https://boingboing.net/2023/02/22/the-cryptid-complications-of-wikipedias-editing-policies.html">Wikipedia now focuses on the folklore of these beasts without going into much detail about the fringe belief in their reality</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109918360457067075">\(\mathbb{M}\)</a>).</span> (Based on a both-sides-ist <em>Slate</em> article that Iâm not going to link.)</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=MDhT6-6Yr_I">Origami actuators</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@logicalelegance@mastodon.online/109920746034435458">\(\mathbb{M}\)</a>),</span> for simple repetitive motions of origami models, by attaching flat-printed electromagnets to them.</p>
  </li>
  <li>
    <p>Gasarch writes: <a href="https://blog.computationalcomplexity.org/2023/02/it-is-more-important-than-ever-to-teach.html">It is more important than ever to teach your students probability (even non-stem students)</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109935523877122235">\(\mathbb{M}\)</a>).</span> Why: because your university may be making deals promoting online gambling to the same students, as the linked copy of a New York Times article details.</p>
  </li>
  <li>
    <p><a href="https://xtools.wmflabs.org/ec/en.wikipedia.org/David_Eppstein">Sometime in the last month (not exactly sure when) I passed the milestone of 200,000 edits (all non-automated) to Wikipedia</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109941265893054592">\(\mathbb{M}\)</a>).</span> Thatâsâ¦a lot of edits. Although, as of earlier in the month when it was below 200,000, it only places me at 260 on the <a href="https://en.wikipedia.org/w/index.php?title=Wikipedia:List_of_Wikipedians_by_number_of_edits&amp;oldid=1138516223">list of all-time prolific editors</a>. And a couple of the top ten are now blocked, so itâs not exactly always a place of pride.</p>
  </li>
  <li>
    <p><a href="https://www.thisiscolossal.com/2023/02/zai-divecha-phase-shift/">Mesmerizing paper sculptures and animations by Zai Divecha convey the subtlety of change</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@colossal@mastodon.art/109937307601608046">\(\mathbb{M}\)</a>,</span> <a href="https://zaidivecha.com/">see also</a>). Basically a 3d papercraft zoetrope.</p>
  </li>
</ul><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T17:40:00Z">Tuesday, February 28 2023, 17:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.simons.berkeley.edu/2023/02/theory-at-the-institute-and-beyond-february-2023/'>Theory at the Institute and Beyond, February 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          by Venkatesan Guruswami (Simons Institute) This semester at the Simons Institute, the Meta-Complexity program is buzzing along with intense activity in the form of multiple reading groups and a weekly seminar, on top of the usual three workshops and boot &#8230; Continue reading &#8594;<p>By Simons Institute Editor</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          by Venkatesan Guruswami (Simons Institute) This semester at the Simons Institute, the Meta-Complexity program is buzzing along with intense activity in the form of multiple reading groups and a weekly seminar, on top of the usual three workshops and boot &#8230; <a href="https://blog.simons.berkeley.edu/2023/02/theory-at-the-institute-and-beyond-february-2023/">Continue reading <span class="meta-nav">&#8594;</span></a><p class="authors">By Simons Institute Editor</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T17:00:08Z">Tuesday, February 28 2023, 17:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/02/28/alefs-corner-democracy-israel-2023/'>Alefâs Corner: Democracy (Israel, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Democracy in Hebrew is ××××§×¨××× represented by the letter &#8220;dalet&#8221; × Â 
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p></p>


<h2><img loading="lazy" data-attachment-id="23916" data-permalink="https://gilkalai.wordpress.com/2023/02/28/alefs-corner-democracy-israel-2023/dem1/" data-orig-file="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg" data-orig-size="684,701" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Dem1" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg?w=293" data-large-file="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg?w=640" class="alignnone size-full wp-image-23916" src="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg" alt="Dem1" width="684" height="701" srcset="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg 684w, https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg?w=146&amp;h=150 146w, https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg?w=293&amp;h=300 293w" sizes="(max-width: 684px) 100vw, 684px" /><img loading="lazy" data-attachment-id="23918" data-permalink="https://gilkalai.wordpress.com/2023/02/28/alefs-corner-democracy-israel-2023/dem2/" data-orig-file="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg" data-orig-size="1000,1000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Dem2" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=640" class="alignnone size-full wp-image-23918" src="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg" alt="Dem2" width="1000" height="1000" srcset="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg 1000w, https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=150&amp;h=150 150w, https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=300&amp;h=300 300w, https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=768&amp;h=768 768w" sizes="(max-width: 1000px) 100vw, 1000px" /></h2>
<h2>Democracy in Hebrew is ××××§×¨××× represented by the letter &#8220;dalet&#8221; <strong><span style="color: #ff0000">×</span></strong></h2>
<p>Â </p><p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T16:27:04Z">Tuesday, February 28 2023, 16:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12937'>Constraint Optimization over Semirings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: A. Pavan, Kuldeep S. Meel, N. V. Vinodchandran, Arnab Bhattacharyya</p><p>Interpretations of logical formulas over semirings have applications in
various areas of computer science including logic, AI, databases, and security.
Such interpretations provide richer information beyond the truth or falsity of
a statement. Examples of such semirings include Viterbi semiring, min-max or
access control semiring, tropical semiring, and fuzzy semiring.
</p>
<p>The present work investigates the complexity of constraint optimization
problems over semirings. The generic optimization problem we study is the
following: Given a propositional formula $\varphi$ over $n$ variable and a
semiring $(K,+,\cdot,0,1)$, find the maximum value over all possible
interpretations of $\varphi$ over $K$. This can be seen as a generalization of
the well-known satisfiability problem. A related problem is to find an
interpretation that achieves the maximum value. In this work, we first focus on
these optimization problems over the Viterbi semiring, which we call optConfVal
and optConf.
</p>
<p>We show that for general propositional formulas in negation normal form,
optConfVal and optConf are in ${\mathrm{FP}}^{\mathrm{NP}}$. We investigate
optConf when the input formula $\varphi$ is represented as a CNF. For CNF
formulae, we first derive an upper bound on optConfVal as a function of the
number of maximum satisfiable clauses. In particular, we show that if $r$ is
the maximum number of satisfiable clauses in a CNF formula with $m$ clauses,
then its optConfVal is at most $1/4^{m-r}$. Building on this we establish that
optConfVal for CNF formulae is hard for the complexity class
${\mathrm{FP}}^{\mathrm{NP}[\log]}$. We also design polynomial-time
approximation algorithms and establish an inapproximability for optConfVal. We
establish similar complexity results for these optimization problems over other
semirings including tropical, fuzzy, and access control semirings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pavan_A/0/1/0/all/0/1">A. Pavan</a>, <a href="http://arxiv.org/find/cs/1/au:+Meel_K/0/1/0/all/0/1">Kuldeep S. Meel</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinodchandran_N/0/1/0/all/0/1">N. V. Vinodchandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_A/0/1/0/all/0/1">Arnab Bhattacharyya</a></p><p>Interpretations of logical formulas over semirings have applications in
various areas of computer science including logic, AI, databases, and security.
Such interpretations provide richer information beyond the truth or falsity of
a statement. Examples of such semirings include Viterbi semiring, min-max or
access control semiring, tropical semiring, and fuzzy semiring.
</p>
<p>The present work investigates the complexity of constraint optimization
problems over semirings. The generic optimization problem we study is the
following: Given a propositional formula $\varphi$ over $n$ variable and a
semiring $(K,+,\cdot,0,1)$, find the maximum value over all possible
interpretations of $\varphi$ over $K$. This can be seen as a generalization of
the well-known satisfiability problem. A related problem is to find an
interpretation that achieves the maximum value. In this work, we first focus on
these optimization problems over the Viterbi semiring, which we call optConfVal
and optConf.
</p>
<p>We show that for general propositional formulas in negation normal form,
optConfVal and optConf are in ${\mathrm{FP}}^{\mathrm{NP}}$. We investigate
optConf when the input formula $\varphi$ is represented as a CNF. For CNF
formulae, we first derive an upper bound on optConfVal as a function of the
number of maximum satisfiable clauses. In particular, we show that if $r$ is
the maximum number of satisfiable clauses in a CNF formula with $m$ clauses,
then its optConfVal is at most $1/4^{m-r}$. Building on this we establish that
optConfVal for CNF formulae is hard for the complexity class
${\mathrm{FP}}^{\mathrm{NP}[\log]}$. We also design polynomial-time
approximation algorithms and establish an inapproximability for optConfVal. We
establish similar complexity results for these optimization problems over other
semirings including tropical, fuzzy, and access control semirings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12940'>Exponential Hardness of Reinforcement Learning with Linear Function Approximation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Kane, Sihan Liu, Shachar Lovett, Gaurav Mahajan, Csaba Szepesv&#xe1;ri, Gell&#xe9;rt Weisz</p><p>A fundamental question in reinforcement learning theory is: suppose the
optimal value functions are linear in given features, can we learn them
efficiently? This problem's counterpart in supervised learning, linear
regression, can be solved both statistically and computationally efficiently.
Therefore, it was quite surprising when a recent work
\cite{kane2022computational} showed a computational-statistical gap for linear
reinforcement learning: even though there are polynomial sample-complexity
algorithms, unless NP = RP, there are no polynomial time algorithms for this
setting.
</p>
<p>In this work, we build on their result to show a computational lower bound,
which is exponential in feature dimension and horizon, for linear reinforcement
learning under the Randomized Exponential Time Hypothesis. To prove this we
build a round-based game where in each round the learner is searching for an
unknown vector in a unit hypercube. The rewards in this game are chosen such
that if the learner achieves large reward, then the learner's actions can be
used to simulate solving a variant of 3-SAT, where (a) each variable shows up
in a bounded number of clauses (b) if an instance has no solutions then it also
has no solutions that satisfy more than (1-$\epsilon$)-fraction of clauses. We
use standard reductions to show this 3-SAT variant is approximately as hard as
3-SAT. Finally, we also show a lower bound optimized for horizon dependence
that almost matches the best known upper bound of $\exp(\sqrt{H})$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1">Daniel Kane</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sihan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lovett_S/0/1/0/all/0/1">Shachar Lovett</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_G/0/1/0/all/0/1">Gaurav Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1">Csaba Szepesv&#xe1;ri</a>, <a href="http://arxiv.org/find/cs/1/au:+Weisz_G/0/1/0/all/0/1">Gell&#xe9;rt Weisz</a></p><p>A fundamental question in reinforcement learning theory is: suppose the
optimal value functions are linear in given features, can we learn them
efficiently? This problem's counterpart in supervised learning, linear
regression, can be solved both statistically and computationally efficiently.
Therefore, it was quite surprising when a recent work
\cite{kane2022computational} showed a computational-statistical gap for linear
reinforcement learning: even though there are polynomial sample-complexity
algorithms, unless NP = RP, there are no polynomial time algorithms for this
setting.
</p>
<p>In this work, we build on their result to show a computational lower bound,
which is exponential in feature dimension and horizon, for linear reinforcement
learning under the Randomized Exponential Time Hypothesis. To prove this we
build a round-based game where in each round the learner is searching for an
unknown vector in a unit hypercube. The rewards in this game are chosen such
that if the learner achieves large reward, then the learner's actions can be
used to simulate solving a variant of 3-SAT, where (a) each variable shows up
in a bounded number of clauses (b) if an instance has no solutions then it also
has no solutions that satisfy more than (1-$\epsilon$)-fraction of clauses. We
use standard reductions to show this 3-SAT variant is approximately as hard as
3-SAT. Finally, we also show a lower bound optimized for horizon dependence
that almost matches the best known upper bound of $\exp(\sqrt{H})$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12953'>Optimization Problems on The Weighted Massively Parallel Computation Model: Hardness and Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hengzhao Ma, Jianzhong Li, Xiangyu Gao</p><p>The topology-aware Massively Parallel Computation (MPC) model is proposed and
studied recently, which enhances the classical MPC model by the awareness of
network topology. The work of Hu et. al. on topology-aware MPC model considers
only the tree topology. In this paper a more general case is considered, where
the underlying network is a weighted complete graph. We then call this model as
Weighted Massively Parallel Computation (WMPC) model, and study the problem of
minimizing communication cost under it. Three communication cost minimization
problems are defined based on different pattern of communication, which are the
Data Redistribution Problem, Data Allocation Problem on Continuous data, and
Data Allocation Problem on Categorized data. We also define four kinds of
objective functions for communication cost, which consider the total cost,
bottleneck cost, maximum of send and receive cost, and summation of send and
receive cost, respectively. Combining the three problems in different
communication pattern with the four kinds of objective cost functions, 12
problems are obtained. The hardness results and algorithms of the 12 problems
make up the content of this paper. With rigorous proof, we prove that some of
the 12 problems are in P, some FPT, some NP-complete, and some W[1]-complete.
Approximate algorithms are proposed for several selected problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1">Hengzhao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianzhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiangyu Gao</a></p><p>The topology-aware Massively Parallel Computation (MPC) model is proposed and
studied recently, which enhances the classical MPC model by the awareness of
network topology. The work of Hu et. al. on topology-aware MPC model considers
only the tree topology. In this paper a more general case is considered, where
the underlying network is a weighted complete graph. We then call this model as
Weighted Massively Parallel Computation (WMPC) model, and study the problem of
minimizing communication cost under it. Three communication cost minimization
problems are defined based on different pattern of communication, which are the
Data Redistribution Problem, Data Allocation Problem on Continuous data, and
Data Allocation Problem on Categorized data. We also define four kinds of
objective functions for communication cost, which consider the total cost,
bottleneck cost, maximum of send and receive cost, and summation of send and
receive cost, respectively. Combining the three problems in different
communication pattern with the four kinds of objective cost functions, 12
problems are obtained. The hardness results and algorithms of the 12 problems
make up the content of this paper. With rigorous proof, we prove that some of
the 12 problems are in P, some FPT, some NP-complete, and some W[1]-complete.
Approximate algorithms are proposed for several selected problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13031'>Cosecure Domination: Hardness Results and Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kusum, Arti Pandey</p><p>For a simple graph $G=(V,E)$ without any isolated vertex, a cosecure
dominating set $D$ of $G$ satisfies the following two properties (i) $S$ is a
dominating set of $G$, (ii) for every vertex $v \in S$ there exists a vertex $u
\in V \setminus S$ such that $uv \in E$ and $(S \setminus \{v\}) \cup \{u\}$ is
a dominating set of $G$. The minimum cardinality of a cosecure dominating set
of $G$ is called cosecure domination number of $G$ and is denoted by
$\gamma_{cs}(G)$. The Minimum Cosecure Domination problem is to find a cosecure
dominating set of a graph $G$ of cardinality $\gamma_{cs}(G)$. The decision
version of the problem is known to be NP-complete for bipartite, planar, and
split graphs. Also, it is known that the Minimum Cosecure Domination problem is
efficiently solvable for proper interval graphs and cographs.
</p>
<p>In this paper, we work on various important graph classes in an effort to
reduce the complexity gap of the Minimum Cosecure Domination problem. We show
that the decision version of the problem remains NP-complete for circle graphs,
doubly chordal graphs, chordal bipartite graphs, star-convex bipartite graphs
and comb-convex bipartite graphs. On the positive side, we give an efficient
algorithm to compute the cosecure domination number of chain graphs, which is
an important subclass of bipartite graphs. In addition, we show that the
problem is linear-time solvable for bounded tree-width graphs. Further, we
prove that the computational complexity of this problem varies from the
domination problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kusum/0/1/0/all/0/1">Kusum</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1">Arti Pandey</a></p><p>For a simple graph $G=(V,E)$ without any isolated vertex, a cosecure
dominating set $D$ of $G$ satisfies the following two properties (i) $S$ is a
dominating set of $G$, (ii) for every vertex $v \in S$ there exists a vertex $u
\in V \setminus S$ such that $uv \in E$ and $(S \setminus \{v\}) \cup \{u\}$ is
a dominating set of $G$. The minimum cardinality of a cosecure dominating set
of $G$ is called cosecure domination number of $G$ and is denoted by
$\gamma_{cs}(G)$. The Minimum Cosecure Domination problem is to find a cosecure
dominating set of a graph $G$ of cardinality $\gamma_{cs}(G)$. The decision
version of the problem is known to be NP-complete for bipartite, planar, and
split graphs. Also, it is known that the Minimum Cosecure Domination problem is
efficiently solvable for proper interval graphs and cographs.
</p>
<p>In this paper, we work on various important graph classes in an effort to
reduce the complexity gap of the Minimum Cosecure Domination problem. We show
that the decision version of the problem remains NP-complete for circle graphs,
doubly chordal graphs, chordal bipartite graphs, star-convex bipartite graphs
and comb-convex bipartite graphs. On the positive side, we give an efficient
algorithm to compute the cosecure domination number of chain graphs, which is
an important subclass of bipartite graphs. In addition, we show that the
problem is linear-time solvable for bounded tree-width graphs. Further, we
prove that the computational complexity of this problem varies from the
domination problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13116'>The $\mathsf{AC}^0$-Complexity Of Visibly Pushdown Languages</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Stefan G&#xf6;ller, Nathan Grosshans</p><p>We concern ourselves with the question which visibly pushdown languages are
in the complexity class $\mathsf{AC}^0$.
</p>
<p>We provide a conjectural characterization that isolates a stubborn subclass
of particular one-turn visibly pushdown languages (that we call intermediate
VPLs) all of which our community seems to lack tools for determining
containment in $\mathsf{AC}^0$.
</p>
<p>Our main result states that there is an algorithm that, given a visibly
pushdown automaton, correctly outputs if its language is in $\mathsf{AC}^0$,
some $m\geq 2$ such that $\text{MOD}_m\leq_{\text{cd}} L$ (implying that $L$ is
not in $\mathsf{AC}^0$), or a finite disjoint union of intermediate languages
$L$ is constant-depth equivalent to. In the latter case one can moreover
effectively compute $k,l&gt;0$ with $k\not=l$ such that the visibly pushdown
language is hard for the more concrete intermediate language $L(S\rightarrow
\varepsilon\mid a c^{k-1} S b_1\mid ac^{l-1}Sb_2)$.
</p>
<p>For our proofs we revisit so-called Ext-algebras, introduced by Czarnetzki,
Krebs and Lange, which in turn are closely related to forest algebras
introduced by Boja\'nczyk and Walukiewicz, and Green's relations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goller_S/0/1/0/all/0/1">Stefan G&#xf6;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Grosshans_N/0/1/0/all/0/1">Nathan Grosshans</a></p><p>We concern ourselves with the question which visibly pushdown languages are
in the complexity class $\mathsf{AC}^0$.
</p>
<p>We provide a conjectural characterization that isolates a stubborn subclass
of particular one-turn visibly pushdown languages (that we call intermediate
VPLs) all of which our community seems to lack tools for determining
containment in $\mathsf{AC}^0$.
</p>
<p>Our main result states that there is an algorithm that, given a visibly
pushdown automaton, correctly outputs if its language is in $\mathsf{AC}^0$,
some $m\geq 2$ such that $\text{MOD}_m\leq_{\text{cd}} L$ (implying that $L$ is
not in $\mathsf{AC}^0$), or a finite disjoint union of intermediate languages
$L$ is constant-depth equivalent to. In the latter case one can moreover
effectively compute $k,l&gt;0$ with $k\not=l$ such that the visibly pushdown
language is hard for the more concrete intermediate language $L(S\rightarrow
\varepsilon\mid a c^{k-1} S b_1\mid ac^{l-1}Sb_2)$.
</p>
<p>For our proofs we revisit so-called Ext-algebras, introduced by Czarnetzki,
Krebs and Lange, which in turn are closely related to forest algebras
introduced by Boja\'nczyk and Walukiewicz, and Green's relations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12950'>Two-Disk Compound Symmetry Groups</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Robert A. Hearn, William Kretschmer, Tomas Rokicki, Benjamin Streeter, Eric Vergo</p><p>Symmetry is at the heart of much of mathematics, physics, and art.
Traditional geometric symmetry groups are defined in terms of isometries of the
ambient space of a shape or pattern. If we slightly generalize this notion to
allow the isometries to operate on overlapping but non-identical metric spaces,
we obtain what we call compound symmetry groups. A natural example is that of
the groups generated by discrete rotations of overlapping disks in the plane.
Investigation of these groups reveals a new family of fractals, as well as a
rich structure that is intriguing both mathematically and artistically. We
report on our initial investigations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Hearn_R/0/1/0/all/0/1">Robert A. Hearn</a>, <a href="http://arxiv.org/find/math/1/au:+Kretschmer_W/0/1/0/all/0/1">William Kretschmer</a>, <a href="http://arxiv.org/find/math/1/au:+Rokicki_T/0/1/0/all/0/1">Tomas Rokicki</a>, <a href="http://arxiv.org/find/math/1/au:+Streeter_B/0/1/0/all/0/1">Benjamin Streeter</a>, <a href="http://arxiv.org/find/math/1/au:+Vergo_E/0/1/0/all/0/1">Eric Vergo</a></p><p>Symmetry is at the heart of much of mathematics, physics, and art.
Traditional geometric symmetry groups are defined in terms of isometries of the
ambient space of a shape or pattern. If we slightly generalize this notion to
allow the isometries to operate on overlapping but non-identical metric spaces,
we obtain what we call compound symmetry groups. A natural example is that of
the groups generated by discrete rotations of overlapping disks in the plane.
Investigation of these groups reveals a new family of fractals, as well as a
rich structure that is intriguing both mathematically and artistically. We
report on our initial investigations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13036'>Limited Query Graph Connectivity Test</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mingyu Guo, Jialiang Li, Aneta Neumann, Frank Neumann, Hung Nguyen</p><p>We propose a combinatorial optimisation model called Limited Query Graph
Connectivity Test. We consider a graph whose edges have two possible states
(on/off). The edges' states are hidden initially. We could query an edge to
reveal its state. Given a source s and a destination t, we aim to test s-t
connectivity by identifying either a path (consisting of only on edges) or a
cut (consisting of only off edges). We are limited to B queries, after which we
stop regardless of whether graph connectivity is established. We aim to design
a query policy that minimizes the expected number of queries.
</p>
<p>If we remove the query limit B (i.e., by setting B to the total number of
edges), then our problem becomes a special case of (monotone) Stochastic
Boolean Function Evaluation (SBFE). There are two existing exact algorithms
that are prohibitively expensive. They have best known upper bounds of O(3^m)
and O(2^{2^k}) respectively, where m is the number of edges and k is the number
of paths/cuts. These algorithms do not scale well in practice.
</p>
<p>We propose a significantly more scalable exact algorithm. Our exact algorithm
works by iteratively improving the performance lower bound until the lower
bound becomes achievable. Even when our exact algorithm does not scale, it can
be used as an anytime algorithm for calculating lower bound.
</p>
<p>We experiment on a wide range of practical graphs. We observe that even for
large graphs (i.e., tens of thousands of edges), it mostly takes only a few
queries to reach conclusion, which is the practical motivation behind the query
limit B. B is also an algorithm parameter that controls scalability. For small
B, our exact algorithm scales well. For large B, our exact algorithm can be
converted to a heuristic (i.e., always pretend that there are only 5 queries
left). Our heuristic outperforms all existing heuristics ported from SBFE and
related literature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Mingyu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jialiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_A/0/1/0/all/0/1">Aneta Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_F/0/1/0/all/0/1">Frank Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Hung Nguyen</a></p><p>We propose a combinatorial optimisation model called Limited Query Graph
Connectivity Test. We consider a graph whose edges have two possible states
(on/off). The edges' states are hidden initially. We could query an edge to
reveal its state. Given a source s and a destination t, we aim to test s-t
connectivity by identifying either a path (consisting of only on edges) or a
cut (consisting of only off edges). We are limited to B queries, after which we
stop regardless of whether graph connectivity is established. We aim to design
a query policy that minimizes the expected number of queries.
</p>
<p>If we remove the query limit B (i.e., by setting B to the total number of
edges), then our problem becomes a special case of (monotone) Stochastic
Boolean Function Evaluation (SBFE). There are two existing exact algorithms
that are prohibitively expensive. They have best known upper bounds of O(3^m)
and O(2^{2^k}) respectively, where m is the number of edges and k is the number
of paths/cuts. These algorithms do not scale well in practice.
</p>
<p>We propose a significantly more scalable exact algorithm. Our exact algorithm
works by iteratively improving the performance lower bound until the lower
bound becomes achievable. Even when our exact algorithm does not scale, it can
be used as an anytime algorithm for calculating lower bound.
</p>
<p>We experiment on a wide range of practical graphs. We observe that even for
large graphs (i.e., tens of thousands of edges), it mostly takes only a few
queries to reach conclusion, which is the practical motivation behind the query
limit B. B is also an algorithm parameter that controls scalability. For small
B, our exact algorithm scales well. For large B, our exact algorithm can be
converted to a heuristic (i.e., always pretend that there are only 5 queries
left). Our heuristic outperforms all existing heuristics ported from SBFE and
related literature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13110'>On the Cost of Demographic Parity in Influence Maximization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ruben Becker, Gianlorenzo D&#x27;Angelo, Sajjad Ghobadi</p><p>Modeling and shaping how information spreads through a network is a major
research topic in network analysis. While initially the focus has been mostly
on efficiency, recently fairness criteria have been taken into account in this
setting. Most work has focused on the maximin criteria however, and thus still
different groups can receive very different shares of information. In this work
we propose to consider fairness as a notion to be guaranteed by an algorithm
rather than as a criterion to be maximized. To this end, we propose three
optimization problems that aim at maximizing the overall spread while enforcing
strict levels of demographic parity fairness via constraints (either ex-post or
ex-ante). The level of fairness hence becomes a user choice rather than a
property to be observed upon output. We study this setting from various
perspectives. First, we prove that the cost of introducing demographic parity
can be high in terms of both overall spread and computational complexity, i.e.,
the price of fairness may be unbounded for all three problems and optimal
solutions are hard to compute, in some case even approximately or when fairness
constraints may be violated. For one of our problems, we still design an
algorithm with both constant approximation factor and fairness violation. We
also give two heuristics that allow the user to choose the tolerated fairness
violation. By means of an extensive experimental study, we show that our
algorithms perform well in practice, that is, they achieve the best demographic
parity fairness values. For certain instances we additionally even obtain an
overall spread comparable to the most efficient algorithms that come without
any fairness guarantee, indicating that the empirical price of fairness may
actually be small when using our algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Becker_R/0/1/0/all/0/1">Ruben Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+DAngelo_G/0/1/0/all/0/1">Gianlorenzo D&#x27;Angelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghobadi_S/0/1/0/all/0/1">Sajjad Ghobadi</a></p><p>Modeling and shaping how information spreads through a network is a major
research topic in network analysis. While initially the focus has been mostly
on efficiency, recently fairness criteria have been taken into account in this
setting. Most work has focused on the maximin criteria however, and thus still
different groups can receive very different shares of information. In this work
we propose to consider fairness as a notion to be guaranteed by an algorithm
rather than as a criterion to be maximized. To this end, we propose three
optimization problems that aim at maximizing the overall spread while enforcing
strict levels of demographic parity fairness via constraints (either ex-post or
ex-ante). The level of fairness hence becomes a user choice rather than a
property to be observed upon output. We study this setting from various
perspectives. First, we prove that the cost of introducing demographic parity
can be high in terms of both overall spread and computational complexity, i.e.,
the price of fairness may be unbounded for all three problems and optimal
solutions are hard to compute, in some case even approximately or when fairness
constraints may be violated. For one of our problems, we still design an
algorithm with both constant approximation factor and fairness violation. We
also give two heuristics that allow the user to choose the tolerated fairness
violation. By means of an extensive experimental study, we show that our
algorithms perform well in practice, that is, they achieve the best demographic
parity fairness values. For certain instances we additionally even obtain an
overall spread comparable to the most efficient algorithms that come without
any fairness guarantee, indicating that the empirical price of fairness may
actually be small when using our algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13112'>Improving Fairness in Information Exposure by Adding Links</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ruben Becker, Gianlorenzo D&#x27;Angelo, Sajjad Ghobadi</p><p>Fairness in influence maximization has been a very active research topic
recently. Most works in this context study the question of how to find seeding
strategies (deterministic or probabilistic) such that nodes or communities in
the network get their fair share of coverage. Different fairness criteria have
been used in this context. All these works assume that the entity that is
spreading the information has an inherent interest in spreading the information
fairly, otherwise why would they want to use the developed fair algorithms?
This assumption may however be flawed in reality -- the spreading entity may be
purely \emph{efficiency-oriented}. In this paper we propose to study two
optimization problems with the goal to modify the network structure by adding
links in such a way that efficiency-oriented information spreading becomes
\emph{automatically fair}. We study the proposed optimization problems both
from a theoretical and experimental perspective, that is, we give several
hardness and hardness of approximation results, provide efficient algorithms
for some special cases, and more importantly provide heuristics for solving one
of the problems in practice. In our experimental study we then first compare
the proposed heuristics against each other and establish the most successful
one. In a second experiment, we then show that our approach can be very
successful in practice. That is, we show that already after adding a few edges
to the networks the greedy algorithm that purely maximizes spread surpasses all
fairness-tailored algorithms in terms of ex-post fairness. Maybe surprisingly,
we even show that our approach achieves ex-post fairness values that are
comparable or even better than the ex-ante fairness values of the currently
most efficient algorithms that optimize ex-ante fairness.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Becker_R/0/1/0/all/0/1">Ruben Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+DAngelo_G/0/1/0/all/0/1">Gianlorenzo D&#x27;Angelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghobadi_S/0/1/0/all/0/1">Sajjad Ghobadi</a></p><p>Fairness in influence maximization has been a very active research topic
recently. Most works in this context study the question of how to find seeding
strategies (deterministic or probabilistic) such that nodes or communities in
the network get their fair share of coverage. Different fairness criteria have
been used in this context. All these works assume that the entity that is
spreading the information has an inherent interest in spreading the information
fairly, otherwise why would they want to use the developed fair algorithms?
This assumption may however be flawed in reality -- the spreading entity may be
purely \emph{efficiency-oriented}. In this paper we propose to study two
optimization problems with the goal to modify the network structure by adding
links in such a way that efficiency-oriented information spreading becomes
\emph{automatically fair}. We study the proposed optimization problems both
from a theoretical and experimental perspective, that is, we give several
hardness and hardness of approximation results, provide efficient algorithms
for some special cases, and more importantly provide heuristics for solving one
of the problems in practice. In our experimental study we then first compare
the proposed heuristics against each other and establish the most successful
one. In a second experiment, we then show that our approach can be very
successful in practice. That is, we show that already after adding a few edges
to the networks the greedy algorithm that purely maximizes spread surpasses all
fairness-tailored algorithms in terms of ex-post fairness. Maybe surprisingly,
we even show that our approach achieves ex-post fairness values that are
comparable or even better than the ex-ante fairness values of the currently
most efficient algorithms that optimize ex-ante fairness.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13113'>Toward Self-Adjusting k-ary Search Tree Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Evgenii Feder, Anton Paramonov, Iosif Salem, Stefan Schmid, Vitaly Aksenov</p><p>Datacenter networks are becoming increasingly flexible with the incorporation
of new networking technologies, such as optical circuit switches. These
technologies allow for programmable network topologies that can be reconfigured
to better serve network traffic, thus enabling a trade-off between the benefits
(i.e., shorter routes) and costs of reconfigurations (i.e., overhead).
Self-Adjusting Networks (SANs) aim at addressing this trade-off by exploiting
patterns in network traffic, both when it is revealed piecewise (online dynamic
topologies) or known in advance (offline static topologies). In this paper, we
take the first steps toward Self-Adjusting k-ary tree networks. These are more
powerful generalizations of existing binary search tree networks (like
SplayNets), which have been at the core of SAN designs. k-ary search tree
networks are a natural generalization offering nodes of higher degrees, reduced
route lengths for a fixed number of nodes, and local routing in spite of
reconfigurations. We first compute an offline (optimal) static network for
arbitrary traffic patterns in $O(n^3 \cdot k)$ time via dynamic programming,
and also improve the bound to $O(n^2 \cdot k)$ for the special case of
uniformly distributed traffic. Then, we present a centroid-based topology of
the network that can be used both in the offline static and the online setting.
In the offline uniform-workload case, we construct this quasi-optimal network
in linear time $O(n)$ and, finally, we present online self-adjusting k-ary
search tree versions of SplayNet. We evaluate experimentally our new structure
for $k=2$ (allowing for a comparison with existing SplayNets) on real and
synthetic network traces. Our results show that this approach works better than
SplayNet in most of the real network traces and in average to low locality
synthetic traces, and is only little inferior to SplayNet in all remaining
traces.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Feder_E/0/1/0/all/0/1">Evgenii Feder</a>, <a href="http://arxiv.org/find/cs/1/au:+Paramonov_A/0/1/0/all/0/1">Anton Paramonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Salem_I/0/1/0/all/0/1">Iosif Salem</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Aksenov_V/0/1/0/all/0/1">Vitaly Aksenov</a></p><p>Datacenter networks are becoming increasingly flexible with the incorporation
of new networking technologies, such as optical circuit switches. These
technologies allow for programmable network topologies that can be reconfigured
to better serve network traffic, thus enabling a trade-off between the benefits
(i.e., shorter routes) and costs of reconfigurations (i.e., overhead).
Self-Adjusting Networks (SANs) aim at addressing this trade-off by exploiting
patterns in network traffic, both when it is revealed piecewise (online dynamic
topologies) or known in advance (offline static topologies). In this paper, we
take the first steps toward Self-Adjusting k-ary tree networks. These are more
powerful generalizations of existing binary search tree networks (like
SplayNets), which have been at the core of SAN designs. k-ary search tree
networks are a natural generalization offering nodes of higher degrees, reduced
route lengths for a fixed number of nodes, and local routing in spite of
reconfigurations. We first compute an offline (optimal) static network for
arbitrary traffic patterns in $O(n^3 \cdot k)$ time via dynamic programming,
and also improve the bound to $O(n^2 \cdot k)$ for the special case of
uniformly distributed traffic. Then, we present a centroid-based topology of
the network that can be used both in the offline static and the online setting.
In the offline uniform-workload case, we construct this quasi-optimal network
in linear time $O(n)$ and, finally, we present online self-adjusting k-ary
search tree versions of SplayNet. We evaluate experimentally our new structure
for $k=2$ (allowing for a comparison with existing SplayNets) on real and
synthetic network traces. Our results show that this approach works better than
SplayNet in most of the real network traces and in average to low locality
synthetic traces, and is only little inferior to SplayNet in all remaining
traces.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13160'>The Effect of Points Dispersion on the $k$-nn Search in Random Projection Forests</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mashaan Alshammari, John Stavrakakis, Adel F. Ahmed, Masahiro Takatsuka</p><p>Partitioning trees are efficient data structures for $k$-nearest neighbor
search. Machine learning libraries commonly use a special type of partitioning
trees called $k$d-trees to perform $k$-nn search. Unfortunately, $k$d-trees can
be ineffective in high dimensions because they need more tree levels to
decrease the vector quantization (VQ) error. Random projection trees rpTrees
solve this scalability problem by using random directions to split the data. A
collection of rpTrees is called rpForest. $k$-nn search in an rpForest is
influenced by two factors: 1) the dispersion of points along the random
direction and 2) the number of rpTrees in the rpForest. In this study, we
investigate how these two factors affect the $k$-nn search with varying $k$
values and different datasets. We found that with larger number of trees, the
dispersion of points has a very limited effect on the $k$-nn search. One should
use the original rpTree algorithm by picking a random direction regardless of
the dispersion of points.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alshammari_M/0/1/0/all/0/1">Mashaan Alshammari</a>, <a href="http://arxiv.org/find/cs/1/au:+Stavrakakis_J/0/1/0/all/0/1">John Stavrakakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1">Adel F. Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Takatsuka_M/0/1/0/all/0/1">Masahiro Takatsuka</a></p><p>Partitioning trees are efficient data structures for $k$-nearest neighbor
search. Machine learning libraries commonly use a special type of partitioning
trees called $k$d-trees to perform $k$-nn search. Unfortunately, $k$d-trees can
be ineffective in high dimensions because they need more tree levels to
decrease the vector quantization (VQ) error. Random projection trees rpTrees
solve this scalability problem by using random directions to split the data. A
collection of rpTrees is called rpForest. $k$-nn search in an rpForest is
influenced by two factors: 1) the dispersion of points along the random
direction and 2) the number of rpTrees in the rpForest. In this study, we
investigate how these two factors affect the $k$-nn search with varying $k$
values and different datasets. We found that with larger number of trees, the
dispersion of points has a very limited effect on the $k$-nn search. One should
use the original rpTree algorithm by picking a random direction regardless of
the dispersion of points.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, February 27
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/i-wish-we-had-less-students-in-class.html'>I wish we had less students in a Class. Demographics says I may get my wish.</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;According to&nbsp;this&nbsp;article, in the near future LESS people will be going to college. There is even a name for this upcoming shift: The Enrollment Cliff. Why?</p><p>Is it Covid-related?&nbsp; Is it that College has gotten to expensive? To liberal? To much cancel culture?&nbsp; To many dead white males in the core? The core is to multicultural? Online learning is stealing our students?&nbsp;</p><p>No. The reason is actually very boring and does not serve anyone's political agenda. (thats not quite right).&nbsp; Or any agenda. And you can probably guess the cause from the title of this blog post.</p><p>For some years up until 2007 the birth rate was slowly dropping. Then there was a large drop in the birth rate after the recession of 2007, and the birth rate has never really recovered. And the recession might not have that much to do with it-- the long term move from an agricultural society (where kids are an economic gain) to an industrial one (where, after child labor laws and the expense of college, kids are an economic loss- though that can be debated) has resulted in a very long term decline in births.&nbsp;</p><p>And from personal experience, I know (a) very few people who have 4 or more kids, (b) there is NO stigma about having 0 kids as there once was.&nbsp; Of course the sample size of people I know may be skewed.&nbsp;</p><p>ANYWAY, what will this mean for colleges?&nbsp;</p><p>a) Harvard, Yale, etc will not be affected. Plenty of people will still apply. Note that they draw from all of American and also internationally.&nbsp;</p><p>b) Colleges that draw from a local area may be affected a lot since they depend on locals, and that population may be shrinking.&nbsp;</p><p>c) Schools in between Harvard and Small colleges- hard to say.&nbsp;</p><p>d) The sports betting places paying schools to allow them to promote on campus (and in some cases helping them promote it) may find far less students to sucker into this loser's game. See my blog on this topic&nbsp;here</p><p>Univ of MD has around 4000 Computer Science majors (depending on who tells you this its either a brag or a complaint). In the Spring of 2023 there are three lectures of Discrete math of sizes 240, 270, and 90. Each of those also has recitations of&nbsp; 30 (or so) each. If the decline is gradual (either from demographics or from the CS majors bubble finally bursting, or from the other reasons above) then I am sure we can handle it. If it declines very suddenly we may have a problem adjusting.&nbsp;</p><p>One caveat to this that I've heard is that immigration will save us. Maybe. But America is politically going in the opposite direction. The counterargument of without immigration there will be less students going to college is not that compelling to most Americans. There are other more intelligent and compelling pro-immigration arguments. However, American politics is no longer interested in compelling and logical arguments. (The notion that it once was may be nostalgia for a time that never was.)&nbsp;</p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;According to&nbsp;<a href="https://www.vox.com/the-highlight/23428166/college-enrollment-population-education-crash">this</a>&nbsp;article, in the near future LESS people will be going to college. There is even a name for this upcoming shift: <i>The Enrollment Cliff. </i>Why?</p><p>Is it Covid-related?&nbsp; Is it that College has gotten to expensive? To liberal? To much cancel culture?&nbsp; To many dead white males in the core? The core is to multicultural? Online learning is stealing our students?&nbsp;</p><p>No. The reason is actually very boring and does not serve anyone's political agenda. (thats not quite right).&nbsp; Or any agenda. And you can probably guess the cause from the title of this blog post.</p><p>For some years up until 2007 the birth rate was slowly dropping. Then there was a large drop in the birth rate after the recession of 2007, and the birth rate has never really recovered. And the recession might not have that much to do with it-- the long term move from an agricultural society (where kids are an economic gain) to an industrial one (where, after child labor laws and the expense of college, kids are an economic loss- though that can be debated) has resulted in a very long term decline in births.&nbsp;</p><p>And from personal experience, I know (a) very few people who have 4 or more kids, (b) there is NO stigma about having 0 kids as there once was.&nbsp; Of course the sample size of people I know may be skewed.&nbsp;</p><p>ANYWAY, what will this mean for colleges?&nbsp;</p><p>a) Harvard, Yale, etc will not be affected. Plenty of people will still apply. Note that they draw from all of American and also internationally.&nbsp;</p><p>b) Colleges that draw from a local area may be affected a lot since they depend on locals, and that population may be shrinking.&nbsp;</p><p>c) Schools in between Harvard and Small colleges- hard to say.&nbsp;</p><p>d) The sports betting places paying schools to allow them to promote on campus (and in some cases helping them promote it) may find far less students to sucker into this loser's game. See my blog on this topic&nbsp;<a href="https://blog.computationalcomplexity.org/2023/02/it-is-more-important-than-ever-to-teach.html">here</a></p><p>Univ of MD has around 4000 Computer Science majors (depending on who tells you this its either a brag or a complaint). In the Spring of 2023 there are three lectures of Discrete math of sizes 240, 270, and 90. Each of those also has recitations of&nbsp; 30 (or so) each. If the decline is gradual (either from demographics or from the CS majors bubble finally bursting, or from the other reasons above) then I am sure we can handle it. If it declines very suddenly we may have a problem adjusting.&nbsp;</p><p>One caveat to this that I've heard is that immigration will save us. Maybe. But America is politically going in the opposite direction. The counterargument of <i>without immigration there will be less students</i> <i>going to college </i>is not that compelling to most Americans. There are other more intelligent and compelling pro-immigration arguments. However, American politics is no longer interested in compelling and logical arguments. (The notion that it once was may be nostalgia for a time that never was.)&nbsp;</p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T15:10:00Z">Monday, February 27 2023, 15:10</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/017'>TR23-017 |  Near-Optimal Set-Multilinear Formula Lower Bounds | 

	Deepanshu Kush, 

	Shubhangi Saraf</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The seminal work of Raz (J. ACM 2013) as well as the recent breakthrough results by Limaye, Srinivasan, and Tavenas (FOCS 2021, STOC 2022) have demonstrated a potential avenue for obtaining lower bounds for general algebraic formulas, via strong enough lower bounds for set-multilinear formulas.

In this paper, we make progress along this direction by proving near-optimal lower bounds against low-depth as well
as unbounded-depth set-multilinear formulas.
More precisely, we show that over any field of characteristic zero, there is a polynomial $f$ computed by a polynomial-sized set-multilinear branching program (i.e., $f$ is in set-multilinear VBP) defined over $\Theta(n^2)$ variables and of degree $\Theta(n)$, such that any product-depth $\Delta$ set-multilinear formula computing $f$ has size at
least $n^{\Omega( n^{1/\Delta}/\Delta)}$. Moreover, we show that any unbounded-depth set-multilinear formula computing $f$ has size at least $n^{\Omega(\log n)}$.


If such strong lower bounds are proven for the iterated matrix multiplication (IMM) polynomial or rather, any polynomial
that is computed by an ordered set-multilinear branching program (i.e., a further restriction of set-multilinear VBP), then this would have dramatic consequences as it would imply super-polynomial lower bounds 
for general algebraic formulas (Raz, J. ACM 2013; Tavenas, Limaye, and Srinivasan, STOC 2022).

Prior to our work, either only weaker lower bounds were known for the IMM polynomial (Tavenas, Limaye, and Srinivasan, STOC 2022), or similar strong lower bounds were known but for a
hard polynomial not known to be even in set-multilinear VP (Kush and Saraf, CCC 2022; Raz, J. ACM 2009).

By known depth-reduction results, our lower bounds are essentially tight
for $f$ and in general, for any hard polynomial that is in set-multilinear VBP or set-multilinear VP.
Any asymptotic improvement in the lower bound (for a hard polynomial, say, in VNP) would imply super-polynomial lower bounds for general set-multilinear circuits.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The seminal work of Raz (J. ACM 2013) as well as the recent breakthrough results by Limaye, Srinivasan, and Tavenas (FOCS 2021, STOC 2022) have demonstrated a potential avenue for obtaining lower bounds for general algebraic formulas, via strong enough lower bounds for set-multilinear formulas.

In this paper, we make progress along this direction by proving near-optimal lower bounds against low-depth as well
as unbounded-depth set-multilinear formulas.
More precisely, we show that over any field of characteristic zero, there is a polynomial $f$ computed by a polynomial-sized set-multilinear branching program (i.e., $f$ is in set-multilinear VBP) defined over $\Theta(n^2)$ variables and of degree $\Theta(n)$, such that any product-depth $\Delta$ set-multilinear formula computing $f$ has size at
least $n^{\Omega( n^{1/\Delta}/\Delta)}$. Moreover, we show that any unbounded-depth set-multilinear formula computing $f$ has size at least $n^{\Omega(\log n)}$.


If such strong lower bounds are proven for the iterated matrix multiplication (IMM) polynomial or rather, any polynomial
that is computed by an ordered set-multilinear branching program (i.e., a further restriction of set-multilinear VBP), then this would have dramatic consequences as it would imply super-polynomial lower bounds 
for general algebraic formulas (Raz, J. ACM 2013; Tavenas, Limaye, and Srinivasan, STOC 2022).

Prior to our work, either only weaker lower bounds were known for the IMM polynomial (Tavenas, Limaye, and Srinivasan, STOC 2022), or similar strong lower bounds were known but for a
hard polynomial not known to be even in set-multilinear VP (Kush and Saraf, CCC 2022; Raz, J. ACM 2009).

By known depth-reduction results, our lower bounds are essentially tight
for $f$ and in general, for any hard polynomial that is in set-multilinear VBP or set-multilinear VP.
Any asymptotic improvement in the lower bound (for a hard polynomial, say, in VNP) would imply super-polynomial lower bounds for general set-multilinear circuits.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T15:04:14Z">Monday, February 27 2023, 15:04</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12796'>Revisiting Graph Persistence for Updates and Efficiency</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tamal K. Dey, Tao Hou</p><p>It is well known that ordinary persistence on graphs can be computed more
efficiently than the general persistence. Recently, it has also been shown that
zigzag persistence on graphs also exhibits similar behavior. Motivated by these
results, we revisit graph persistence and propose efficient algorithms
especially for local updates on filtrations, similar to what is done in
ordinary persistence for computing the vineyard. We show that, for a filtration
of length $m$ (i) switches (transpositions) in ordinary graph persistence can
be done in $O(\log^4 m)$ amortized time; (ii) zigzag persistence on graphs can
be computed in $O(m\log m)$ time, which improves a recent $O(m\log^4n)$ time
algorithm assuming $n$, the size of the union of all graphs in the filtration,
satisfies $n\in\Omega({m^\varepsilon})$ for any fixed $0&lt;\varepsilon&lt;1$; (iii)
open-closed, closed-open, and closed-closed bars in dimension $0$ for graph
zigzag persistence can be updated in $O(\log^4m)$ amortized time, whereas the
open-open bars in dimension $0$ and closed-closed bars in dimension $1$ can be
done in $O(m)$ time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dey_T/0/1/0/all/0/1">Tamal K. Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_T/0/1/0/all/0/1">Tao Hou</a></p><p>It is well known that ordinary persistence on graphs can be computed more
efficiently than the general persistence. Recently, it has also been shown that
zigzag persistence on graphs also exhibits similar behavior. Motivated by these
results, we revisit graph persistence and propose efficient algorithms
especially for local updates on filtrations, similar to what is done in
ordinary persistence for computing the vineyard. We show that, for a filtration
of length $m$ (i) switches (transpositions) in ordinary graph persistence can
be done in $O(\log^4 m)$ amortized time; (ii) zigzag persistence on graphs can
be computed in $O(m\log m)$ time, which improves a recent $O(m\log^4n)$ time
algorithm assuming $n$, the size of the union of all graphs in the filtration,
satisfies $n\in\Omega({m^\varepsilon})$ for any fixed $0&lt;\varepsilon&lt;1$; (iii)
open-closed, closed-open, and closed-closed bars in dimension $0$ for graph
zigzag persistence can be updated in $O(\log^4m)$ amortized time, whereas the
open-open bars in dimension $0$ and closed-closed bars in dimension $1$ can be
done in $O(m)$ time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T01:30:00Z">Monday, February 27 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12823'>Generative Models of Huge Objects</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lunjia Hu, Inbal Livni-Navon, Omer Reingold</p><p>This work initiates the systematic study of explicit distributions that are
indistinguishable from a single exponential-size combinatorial object. In this
we extend the work of Goldreich, Goldwasser and Nussboim (SICOMP 2010) that
focused on the implementation of huge objects that are indistinguishable from
the uniform distribution, satisfying some global properties (which they coined
truthfulness). Indistinguishability from a single object is motivated by the
study of generative models in learning theory and regularity lemmas in graph
theory. Problems that are well understood in the setting of pseudorandomness
present significant challenges and at times are impossible when considering
generative models of huge objects.
</p>
<p>We demonstrate the versatility of this study by providing a learning
algorithm for huge indistinguishable objects in several natural settings
including: dense functions and graphs with a truthfulness requirement on the
number of ones in the function or edges in the graphs, and a version of the
weak regularity lemma for sparse graphs that satisfy some global properties.
These and other results generalize basic pseudorandom objects as well as
notions introduced in algorithmic fairness. The results rely on notions and
techniques from a variety of areas including learning theory, complexity
theory, cryptography, and game theory.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Lunjia Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Livni_Navon_I/0/1/0/all/0/1">Inbal Livni-Navon</a>, <a href="http://arxiv.org/find/cs/1/au:+Reingold_O/0/1/0/all/0/1">Omer Reingold</a></p><p>This work initiates the systematic study of explicit distributions that are
indistinguishable from a single exponential-size combinatorial object. In this
we extend the work of Goldreich, Goldwasser and Nussboim (SICOMP 2010) that
focused on the implementation of huge objects that are indistinguishable from
the uniform distribution, satisfying some global properties (which they coined
truthfulness). Indistinguishability from a single object is motivated by the
study of generative models in learning theory and regularity lemmas in graph
theory. Problems that are well understood in the setting of pseudorandomness
present significant challenges and at times are impossible when considering
generative models of huge objects.
</p>
<p>We demonstrate the versatility of this study by providing a learning
algorithm for huge indistinguishable objects in several natural settings
including: dense functions and graphs with a truthfulness requirement on the
number of ones in the function or edges in the graphs, and a version of the
weak regularity lemma for sparse graphs that satisfy some global properties.
These and other results generalize basic pseudorandom objects as well as
notions introduced in algorithmic fairness. The results rely on notions and
techniques from a variety of areas including learning theory, complexity
theory, cryptography, and game theory.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T01:30:00Z">Monday, February 27 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12811'>$k$-Center Clustering with Outliers in the MPC and Streaming Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mark de Berg, Leyla Biabani, Morteza Monemizadeh</p><p>Given a point set $P \subseteq X$ of size $n$ in a metric space $(X,dist)$ of
doubling dimension $d$ and two parameters $k \in N$ and $z \in N$, the
$k$-center problem with $z$ outliers asks to return a set $C^\ast \subseteq X$
of $k$ centers such that the maximum distance of all but $z$ points of $P$ to
their nearest center in $C^\ast$ is minimized. An $(\epsilon,k,z)$-coreset for
this problem is a weighted point set $P^*$ such that an optimal solution for
the $k$-center problem with $z$ outliers on $P^*$ gives a
$(1\pm\epsilon)$-approximation for the $k$-center problem with $z$ outliers on
$P$. We study the construction of such coresets in the Massively Parallel
Computing (MPC) model, and in the insertion-only as well as the fully dynamic
streaming model. We obtain the following results, for any given $0 &lt; \epsilon
\le 1$: In all cases, the size of the computed coreset is $O(k/\epsilon^d+z)$.
</p>
<p>- In the MPC model, we present a deterministic $2$-round and a randomized
$1$-round algorithm. Additionally, we provide a deterministic algorithm that
obtains a trade-off between the number of rounds, $R$, and the storage per
machine.
</p>
<p>- For the insertion-only streaming model, we present an algorithm and a tight
lower bound to support it.
</p>
<p>- We also discuss the dynamic streaming model, which allows both insertions
and deletions in the data stream. In this model, we present the first algorithm
and a lower bound.
</p>
<p>- Finally, we consider the sliding window model, where we are interested in
maintaining an $(\epsilon,k,z)$-coreset for the last $W$ points in the stream,
we present a tight lower bound that confirms the optimality of the previous
work by De Berg, Monemizadeh, and Zhong (ESA2020).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berg_M/0/1/0/all/0/1">Mark de Berg</a>, <a href="http://arxiv.org/find/cs/1/au:+Biabani_L/0/1/0/all/0/1">Leyla Biabani</a>, <a href="http://arxiv.org/find/cs/1/au:+Monemizadeh_M/0/1/0/all/0/1">Morteza Monemizadeh</a></p><p>Given a point set $P \subseteq X$ of size $n$ in a metric space $(X,dist)$ of
doubling dimension $d$ and two parameters $k \in N$ and $z \in N$, the
$k$-center problem with $z$ outliers asks to return a set $C^\ast \subseteq X$
of $k$ centers such that the maximum distance of all but $z$ points of $P$ to
their nearest center in $C^\ast$ is minimized. An $(\epsilon,k,z)$-coreset for
this problem is a weighted point set $P^*$ such that an optimal solution for
the $k$-center problem with $z$ outliers on $P^*$ gives a
$(1\pm\epsilon)$-approximation for the $k$-center problem with $z$ outliers on
$P$. We study the construction of such coresets in the Massively Parallel
Computing (MPC) model, and in the insertion-only as well as the fully dynamic
streaming model. We obtain the following results, for any given $0 &lt; \epsilon
\le 1$: In all cases, the size of the computed coreset is $O(k/\epsilon^d+z)$.
</p>
<p>- In the MPC model, we present a deterministic $2$-round and a randomized
$1$-round algorithm. Additionally, we provide a deterministic algorithm that
obtains a trade-off between the number of rounds, $R$, and the storage per
machine.
</p>
<p>- For the insertion-only streaming model, we present an algorithm and a tight
lower bound to support it.
</p>
<p>- We also discuss the dynamic streaming model, which allows both insertions
and deletions in the data stream. In this model, we present the first algorithm
and a lower bound.
</p>
<p>- Finally, we consider the sliding window model, where we are interested in
maintaining an $(\epsilon,k,z)$-coreset for the last $W$ points in the stream,
we present a tight lower bound that confirms the optimality of the previous
work by De Berg, Monemizadeh, and Zhong (ESA2020).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T01:30:00Z">Monday, February 27 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12289'>Beyond Moments: Robustly Learning Affine Transformations with Asymptotically Optimal Error</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: He Jia, Pravesh K . Kothari, Santosh S. Vempala</p><p>We present a polynomial-time algorithm for robustly learning an unknown
affine transformation of the standard hypercube from samples, an important and
well-studied setting for independent component analysis (ICA). Specifically,
given an $\epsilon$-corrupted sample from a distribution $D$ obtained by
applying an unknown affine transformation $x \rightarrow Ax+s$ to the uniform
distribution on a $d$-dimensional hypercube $[-1,1]^d$, our algorithm
constructs $\hat{A}, \hat{s}$ such that the total variation distance of the
distribution $\hat{D}$ from $D$ is $O(\epsilon)$ using poly$(d)$ time and
samples. Total variation distance is the information-theoretically strongest
possible notion of distance in our setting and our recovery guarantees in this
distance are optimal up to the absolute constant factor multiplying $\epsilon$.
In particular, if the columns of $A$ are normalized to be unit length, our
total variation distance guarantee implies a bound on the sum of the $\ell_2$
distances between the column vectors of $A$ and $A'$, $\sum_{i =1}^d
\|a_i-\hat{a}_i\|_2 = O(\epsilon)$. In contrast, the strongest known prior
results only yield a $\epsilon^{O(1)}$ (relative) bound on the distance between
individual $a_i$'s and their estimates and translate into an $O(d\epsilon)$
bound on the total variation distance. Our key innovation is a new approach to
ICA (even to outlier-free ICA) that circumvents the difficulties in the
classical method of moments and instead relies on a new geometric certificate
of correctness of an affine transformation. Our algorithm is based on a new
method that iteratively improves an estimate of the unknown affine
transformation whenever the requirements of the certificate are not met.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1">He Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1">Pravesh K . Kothari</a>, <a href="http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1">Santosh S. Vempala</a></p><p>We present a polynomial-time algorithm for robustly learning an unknown
affine transformation of the standard hypercube from samples, an important and
well-studied setting for independent component analysis (ICA). Specifically,
given an $\epsilon$-corrupted sample from a distribution $D$ obtained by
applying an unknown affine transformation $x \rightarrow Ax+s$ to the uniform
distribution on a $d$-dimensional hypercube $[-1,1]^d$, our algorithm
constructs $\hat{A}, \hat{s}$ such that the total variation distance of the
distribution $\hat{D}$ from $D$ is $O(\epsilon)$ using poly$(d)$ time and
samples. Total variation distance is the information-theoretically strongest
possible notion of distance in our setting and our recovery guarantees in this
distance are optimal up to the absolute constant factor multiplying $\epsilon$.
In particular, if the columns of $A$ are normalized to be unit length, our
total variation distance guarantee implies a bound on the sum of the $\ell_2$
distances between the column vectors of $A$ and $A'$, $\sum_{i =1}^d
\|a_i-\hat{a}_i\|_2 = O(\epsilon)$. In contrast, the strongest known prior
results only yield a $\epsilon^{O(1)}$ (relative) bound on the distance between
individual $a_i$'s and their estimates and translate into an $O(d\epsilon)$
bound on the total variation distance. Our key innovation is a new approach to
ICA (even to outlier-free ICA) that circumvents the difficulties in the
classical method of moments and instead relies on a new geometric certificate
of correctness of an affine transformation. Our algorithm is based on a new
method that iteratively improves an estimate of the unknown affine
transformation whenever the requirements of the certificate are not met.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T01:30:00Z">Monday, February 27 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12440'>Optimal Bounds for Noisy Sorting</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuzhou Gu, Yinzhan Xu</p><p>Sorting is a fundamental problem in computer science. In the classical
setting, it is well-known that $(1\pm o(1)) n\log_2 n$ comparisons are both
necessary and sufficient to sort a list of $n$ elements. In this paper, we
study the Noisy Sorting problem, where each comparison result is flipped
independently with probability $p$ for some fixed $p\in (0, \frac 12)$. As our
main result, we show that $$(1\pm o(1)) \left( \frac{1}{I(p)} + \frac{1}{(1-2p)
\log_2 \left(\frac{1-p}p\right)} \right) n\log_2 n$$ noisy comparisons are both
necessary and sufficient to sort $n$ elements with error probability $o(1)$
using noisy comparisons, where $I(p)=1 + p\log_2 p+(1-p)\log_2 (1-p)$ is
capacity of BSC channel with crossover probability $p$. This simultaneously
improves the previous best lower and upper bounds (Wang, Ghaddar and Wang, ISIT
2022) for this problem.
</p>
<p>For the related Noisy Binary Search problem, we show that $$
</p>
<p>(1\pm o(1)) \left((1-\delta)\frac{\log_2(n)}{I(p)} + \frac{2 \log_2
\left(\frac 1\delta\right)}{(1-2p)\log_2\left(\frac {1-p}p\right)}\right) $$
noisy comparisons are both necessary and sufficient to find the predecessor of
an element among $n$ sorted elements with error probability $\delta$. This
extends the previous bounds of (Burnashev and Zigangirov, 1974), which are only
tight for $\delta = 1/n^{o(1)}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yuzhou Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinzhan Xu</a></p><p>Sorting is a fundamental problem in computer science. In the classical
setting, it is well-known that $(1\pm o(1)) n\log_2 n$ comparisons are both
necessary and sufficient to sort a list of $n$ elements. In this paper, we
study the Noisy Sorting problem, where each comparison result is flipped
independently with probability $p$ for some fixed $p\in (0, \frac 12)$. As our
main result, we show that $$(1\pm o(1)) \left( \frac{1}{I(p)} + \frac{1}{(1-2p)
\log_2 \left(\frac{1-p}p\right)} \right) n\log_2 n$$ noisy comparisons are both
necessary and sufficient to sort $n$ elements with error probability $o(1)$
using noisy comparisons, where $I(p)=1 + p\log_2 p+(1-p)\log_2 (1-p)$ is
capacity of BSC channel with crossover probability $p$. This simultaneously
improves the previous best lower and upper bounds (Wang, Ghaddar and Wang, ISIT
2022) for this problem.
</p>
<p>For the related Noisy Binary Search problem, we show that $$
</p>
<p>(1\pm o(1)) \left((1-\delta)\frac{\log_2(n)}{I(p)} + \frac{2 \log_2
\left(\frac 1\delta\right)}{(1-2p)\log_2\left(\frac {1-p}p\right)}\right) $$
noisy comparisons are both necessary and sufficient to find the predecessor of
an element among $n$ sorted elements with error probability $\delta$. This
extends the previous bounds of (Burnashev and Zigangirov, 1974), which are only
tight for $\delta = 1/n^{o(1)}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T01:30:00Z">Monday, February 27 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12467'>The number of descendants in a random directed acyclic graph</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Svante Janson</p><p>We consider a well known model of random directed acyclic graphs of order
$n$, obtained by recursively adding vertices, where each new vertex has a fixed
outdegree $d\ge2$ and the endpoints of the $d$ edges from it are chosen
uniformly at random among previously existing vertices.
</p>
<p>Our main results concern the number $X$ of vertices that are descendants of
$n$. We show that $X/\sqrt n$ converges in distribution; the limit distribution
is, up to a constant factor, given by the $d$th root of a Gamma distributed
variable. $\Gamma(d/(d-1))$. When $d=2$, the limit distribution can also be
described as a chi distribution $\chi(4)$. We also show convergence of moments,
and find thus the asymptotics of the mean and higher moments.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Janson_S/0/1/0/all/0/1">Svante Janson</a></p><p>We consider a well known model of random directed acyclic graphs of order
$n$, obtained by recursively adding vertices, where each new vertex has a fixed
outdegree $d\ge2$ and the endpoints of the $d$ edges from it are chosen
uniformly at random among previously existing vertices.
</p>
<p>Our main results concern the number $X$ of vertices that are descendants of
$n$. We show that $X/\sqrt n$ converges in distribution; the limit distribution
is, up to a constant factor, given by the $d$th root of a Gamma distributed
variable. $\Gamma(d/(d-1))$. When $d=2$, the limit distribution can also be
described as a chi distribution $\chi(4)$. We also show convergence of moments,
and find thus the asymptotics of the mean and higher moments.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T01:30:00Z">Monday, February 27 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, February 26
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://minorfree.github.io/hz-spanner/'>Halperin-Zwick Algorithm for Spanners</a></h3>
        <p class='tr-article-feed'>from <a href='https://minorfree.github.io'>Hung Le</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This post describes a simple linear time algorithm by Halperin-Zwick [6] for constructing a \((2k-1)\)-spanner of unweighted graphs for any given integer \(k\geq 1\). The spanner has \(O(n^{1+1/k})\) edges and hence is sparse. When \(k = \log n\), it only has \(O(n)\) edges. This sparsity makes spanners an important object in many applications. This post was inspired by my past attempt to track down the detail of the Halperin-Zwick algorithm. Halperin and Zwick never published their algorithm, and all papers I am aware of cite their unpublished manuscript [6]. The algorithm by Halperin-Zwick is a simple modification of an earlier algorithm by Pelege and SchÃ¤ffer [8], which, according to Uri Zwick, is the reason why they did not publish their result. The spanner by Pelege and SchÃ¤ffer [8] has stretch \(4k-3\) for the same sparsity. The idea of Halperin-Zwick algorithm was given as Exercise 3 in Chapter 16 of the book by Peleg [7]. First, letâs define spanners. Graphs in this post are connected. \(t\)-Spanner: Given a graph \(G\), a \(t\)-spanner is a subgraph of \(G\), denoted by \(H\), such that for every two vertices \(u,v\in V(G)\): \[d_H(u,v)\leq t\cdot d_G(u,v)\] Here \(d_H\) and \(d_G\) denote the graph distances in \(H\) and in \(G\), respectively. Graph \(G\) could be weighted or unweighted; we only consider unweighted graphs in this post. The distance constraint on \(H\) implies that \(H\) is connected and spanning. Parameter \(t\) is called the stretch of the spanner. We often construct a spanner with an odd stretch: \(t = 2k-1\) for some integer \(k\geq 1\). Why not even stretches? Short answer: there is no gain in terms of the worst case bounds for even stretch [1].
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>This post describes a simple linear time algorithm by Halperin-Zwick [6] for constructing a \((2k-1)\)-spanner of unweighted graphs for any given integer \(k\geq 1\). The spanner  has \(O(n^{1+1/k})\) edges and hence is sparse. When \(k = \log n\), it only has \(O(n)\) edges.  This sparsity makes spanners an important object in many applications.</p>

<p>This post was inspired by my past attempt to track down the detail of the Halperin-Zwick algorithm. Halperin and Zwick never published their algorithm, and all papers I am aware of cite their unpublished manuscript [6]. The algorithm by Halperin-Zwick is a simple modification of an earlier algorithm by Pelege and SchÃ¤ffer [8], which, according to Uri Zwick, is the reason why they did not publish their result. The spanner by Pelege and SchÃ¤ffer [8] has stretch \(4k-3\) for the same sparsity. The idea of Halperin-Zwick algorithm was given as Exercise 3 in Chapter 16 of  the book by Peleg [7].</p>

<p>First, letâs define spanners. Graphs in this post are connected.</p>

<hr />
<p><strong>\(t\)-Spanner</strong>: Given a graph \(G\), a \(t\)-spanner is a subgraph of \(G\), denoted by \(H\),  such that for every two vertices \(u,v\in V(G)\):</p>

\[d_H(u,v)\leq t\cdot d_G(u,v)\]

<hr />

<p>Here \(d_H\) and \(d_G\) denote the graph distances in \(H\) and in \(G\), respectively. Graph \(G\) could be weighted or unweighted; we only consider unweighted graphs in this post. The distance constraint on \(H\) implies that \(H\) is connected and spanning.</p>

<p>Parameter \(t\) is called the <em>stretch</em> of the spanner. We often construct a spanner with an odd stretch: \(t = 2k-1\) for some integer \(k\geq 1\). Why not even stretches? Short answer: there is no gain in terms of the worst case bounds for even stretch [1].</p>

<hr />
<p><strong>Theorem</strong> (Halperin-Zwick): Let \(G\) be an unweighted graph with \(n\) vertices and \(m\) edges. Let \(k\geq 1\) be any given integer. There is an algorithm that runs in time \(O(m)\) and constructs a \((2k-1)\)-spanner of \(G\) with \(O(n^{1+1/k})\) edges.</p>

<hr />

<p>It is often instructive to think about \(k=2\), i.e, constructing a \(3\)-spanner. And this is where we start.</p>

<h1 id="stretch-3">Stretch 3</h1>

<p>Here we seek a \(3\)-spanner with \(O(n^{3/2})\) edges. There are two steps: clustering and connecting the clusters. Letâs focus on clustering first. The idea is to: construct a set of radius-1 clusters (a set of stars) that have at least \(\sqrt{n}\) vertices each. This implies that the number of clusters is \(O(\sqrt{n})\) and hence we can afford to add one edge from each vertex to each cluster. The remaining vertices induce a graph of at most \(O(n^{3/2})\); we can add all the edges.</p>

<p>The cluster can be constructed greedily; the pseudocode of the algorithm is given below. We use \(N_G(v)\) to denote neighbors of \(v\) in a graph \(G\).</p>

<hr />
<p><span style="font-variant: small-caps">Clustering</span>\((G)\)</p>
<blockquote>
  <p>\(1.\) \({\mathcal C} \leftarrow \emptyset, \quad G_1\leftarrow G\)<br />
\(2.\) while \(G_i \not= \emptyset\)<br />
\(3.\) Â Â Â Â  \(x\leftarrow\) an arbitrary vertex in \(G_i\)<br />
\(4.\) Â Â Â Â  \(C_x\leftarrow {x}\)<br />
\(5.\) Â Â Â Â  if \(\lvert N_{G_i}(x)\rvert  \geq \sqrt{n}\)<br />
\(6.\) Â Â Â Â  Â Â Â Â   \(C_v\leftarrow C_v\cup N_{G_i}(x)\)<br />
\(7.\) Â Â Â Â  \({\mathcal C} \leftarrow {\mathcal C}\cup {C_x}\) <br />
\(8.\) Â Â Â Â   \(G_{i+1}\leftarrow G_i\setminus C_v, \quad i\leftarrow i+1\)<br />
\(9.\) return \({\mathcal C}\)</p>
</blockquote>

<hr />
<p>We call the vertex \(v\) in the cluster \(C_v\) in line 4 the <em>center</em> of the cluster. We use \(E(C_v)\) to the edges of \(G\) connecting \(v\) to other vertices in \(C_v\).</p>

<p>Observe  that every cluster \(C\in {\mathcal C}\) has radius at most \(1\) and it has either at least \(\sqrt{n}\) vertices or  exactly one vertex. We call \(C\) a <em>heavy cluster</em> if \(\lvert C \rvert\geq \sqrt{n}\), and a <em>light cluster</em> otherwise.</p>

<hr />
<p><strong>Observation 1</strong>: The number of heavy clusters in \({\mathcal C}\) is at most \(\sqrt{n}\).</p>

<hr />

<p>To get a 3-spanner of \(G\), we simply add an edge from every vertex to each heavy cluster of \({\mathcal C}\), and an edge between every pair of light clusters. (Light clusters are singletons.) 
***
 <span style="font-variant: small-caps">3Spanner</span>\((G)\)</p>
<blockquote>
  <p>\(1.\) \({\mathcal C} \leftarrow\)<span style="font-variant: small-caps">Clustering</span>\((G)\)<br />
\(2.\) \(H\leftarrow (V,\emptyset)\)<br />
\(3.\) for each heavy cluster \(C\in {\mathcal C}\)<br />
\(4.\) Â Â Â Â  add \(E(C)\) to \(H\)<br />
\(5\). Â Â Â Â  for each vertex \(v \in N_G(C)\)<br />
\(6.\) Â Â Â Â   Â Â Â Â  \((v,u)\leftarrow\) an arbitrary edge from \(v\) to \(C\)<br />
\(7.\) Â Â Â Â   Â Â Â Â  add \((u,v)\) to \(H\)<br />
\(8.\) add to \(H\) all edges between light clusters<br />
\(9.\) return \(H\)</p>
</blockquote>

<hr />

<p>In line 5, we use \(N_G(C)\) to denote the set of neighbors of \(C\), which are vertices are not in \(C\) and having at least one edge to \(C\).  The running time is clearly \(O(m)\).</p>

<p><strong>Sparsity analysis.</strong> Note that \(E(C)\leq \lvert C \rvert-1\). Thus, the total number of edges added to \(H\) in line 4 over all iterations is at most \(n-1\). Furthermore, the number of edges added to \(H\) in the loop in line 5 is at most \(n\) and hence by Observation 1, the total number of edges added in lines 3-7 is \(O(n\sqrt{n}) = O(n^{3/2})\).</p>

<p>To bound the number of edges added in line 8, observe that, if we order light clusters by the order it is added to \({\mathcal C}\) in line 7 of algorithm <span style="font-variant: small-caps">Clustering</span>, then each light cluster is incident to at most \(\sqrt{n}\) light clusters following it in the order. It follows that the total number of edges added in line 8 is \(O(n\sqrt{n}) = O(n^{3/2})\).</p>

<p><strong>Stretch analysis.</strong> We show that \(d_G(u,v)\leq 3 d_H(u,v)\). By the triangle inequality, it suffices to show the inequality for every edge \((u,v)\) of \(G\). This means we have to show that \(d_H(u,v)\leq 3\).  This inequality holds if \((u,v)\in E(H)\), and hence we only need to consider the case where at least one of \(u\) and \(v\) is in a heavy cluster.</p>

<p><img src="/assets/figs/clusters.svg" alt="" /></p>

<p><em>Figure 1: (a) stretch-3 path for edge \((u,v)\) and (b) stretch-\((2k-1)\) path for edge \((u,v)\)</em></p>

<p>If \(u\) and \(v\) are in the same heavy cluster \(C\), then \(d_H(u,v)\leq 2\) and the stretch guarantee holds. Otherwise, let \(C_x\) be the heavy cluster centered at \(x\) containing \(v\), say. As \((u,v)\not\in H\), there must be another vertex \(w\in C_x\) such that \((u,w)\in H\) by the construction in line 6. Thus, the path \(u\rightarrow w\rightarrow x\rightarrow v\) is a path of length 3 in \(H\) between \(u\) and \(v\), as desired. See Figure 1(a).</p>

<h1 id="larger-stretches">Larger Stretches</h1>

<p>The algorithm for constructing a \((2k-1)\)-spanner with \(O(n^{1+1/k})\) edges is somewhat similar to the stretch-3 case, but we will need a finer analysis. A key observation, which we also use in the 3-spanner construction, is that if we have a cluster, say \(C\), of radius \(k\), and a vertex \(v\in N_G(C)\), it suffices to keep only one edge from \(v\) to \(C\). Thus, as long as \(N_G(C)\) has at most \(n^{1/k}\lvert C \rvert\) vertices, we can add an edge from \(v\) to \(C\) for each \(v\in N_G(C)\); the <em>average number of edges added per vertex</em> of \(C\) is \(n^{1/k}\).</p>

<p>What if \(\lvert N_G(C) \rvert \geq n^{1/k}\lvert C \rvert\)? In this case, we simply grow \(C\) by adding all of its neighbors. How many times will it grow? At most \(k-1\) times, as every time \(C\) grows, its size increases by a factor of strictly larger than \(n^{1/k}\), and there are only \(n\) vertices in the graph.</p>

<p>The pseudocode of the algorithm is given below. The set \(A\) holds the edges between \(C\) and its neighbors described above. The rest is essentially the same as the clustering for stretch 3.</p>

<hr />
<p><span style="font-variant: small-caps">Clustering</span>\((G,k)\)</p>
<blockquote>
  <p>\(1.\) \({\mathcal C} \leftarrow \emptyset, \quad A\leftarrow \emptyset, \quad G_1\leftarrow G\)<br />
\(2.\) while \(G_i \not= \emptyset\)<br />
\(3.\) Â Â Â Â  \(x\leftarrow\) an arbitrary vertex in \(G_i\)<br />
\(4.\) Â Â Â Â  \(C_x\leftarrow {x}\)<br />
\(5.\) Â Â Â Â  while \(\lvert N_{G_i}(C_x)\rvert \geq n^{1/k} \lvert C_{x} \rvert\)<br />
\(6.\) Â Â Â Â  Â Â Â Â   \(C_v\leftarrow C_x\cup N_{G_i}(C_x)\)<br />
\(7.\) Â Â Â Â  for each \(v \in N_{G_i}(C_x)\)<br />
\(8.\) Â Â Â Â   Â Â Â Â  \((v,u)\leftarrow\) an arbitrary edge from \(v\) to \(C\)<br />
\(9.\) Â Â Â Â   Â Â Â Â  add \((v,u)\) to \(A\)<br />
\(10.\) Â Â Â Â  \({\mathcal C} \leftarrow {\mathcal C}\cup {C_v}\) <br />
\(11.\) Â Â Â Â   \(G_{i+1}\leftarrow G_i\setminus C_v, \quad i\leftarrow i+1\)<br />
\(12.\) return \(({\mathcal C},A)\)</p>
</blockquote>

<hr />

<p>Once we perform clustering, we only need to add the set \(A\) and the edges inside each cluster to the spanner.</p>

<hr />
<p><span style="font-variant: small-caps">Spanner</span>\((G,k)\)</p>
<blockquote>
  <p>\(1.\) \(H\leftarrow (V,\emptyset)\)<br />
\(2.\) \(({\mathcal C},A) \leftarrow\)<span style="font-variant: small-caps">Clustering</span>\((G,k)\)<br />
\(3.\) add \(A\) to \(H\)<br />
\(4.\) for each cluster \(C\in {\mathcal C}\)<br />
\(5.\) Â Â Â Â  add \(E(C)\) to \(H\)<br />
\(6.\) return \(H\)</p>
</blockquote>

<hr />

<p><strong>Sparsity analysis.</strong> The number of edges added in the loop in line 4 is at most \(n-1\). Observe that for each cluster \(C_x\) added to \({\mathcal C}\) in line 6 of <span style="font-variant: small-caps">Clustering</span>, the number of edges added to \(A\) in the loop in line 7 is at most \(n^{1/k}\lvert C_{x} \rvert\). Thus, \(\lvert A \rvert\leq n^{1/k}\sum_{C}\lvert C \rvert \leq n^{1+1/k}\). This implies that \(\lvert E(H) \rvert = O(n^{1+1/k})\).</p>

<p><strong>Stretch analysis.</strong> Let \((u,v)\) be any edge of \(G\) such that \((u,v)\not\in H\). We need to show that \(d_H(u,v)\leq 2k-1\). Observe that:</p>

<hr />
<p><strong>Observation 2</strong>: Every cluster \(C_x\in {\mathcal C}\) has radius at most \(k-1\).</p>

<hr />
<p>Proof: Every time the radius of \(C_x\) increases by \(1\), the size of \(C_x\) increases by a factor of strictly larger than \(n^{1/k}\) by the construction. Thus, after \(t\) rounds, \(n\geq \lvert C_{x} \rvert &gt; n^{t/k}\), which gives \(t\leq k-1\).</p>

<hr />

<p>Let \(C_x\) be the cluster containing \(v\). If \(u\in C_x\), then \(d_G(u,v)\leq 2\cdot (k-1)\). Otherwise, suppose w.l.o.g, that \(v\) is clustered before \(u\). Observe that \(u\in N_{G_{i}}(C_x)\) and hence an edge \((u,w)\) is added to \(A\), which is eventually added to \(H\). See Figure 1(b). Thus, the path consisting of an edge \((u,w)\), the shortest path from \(w\) to \(x\), and the shortest path from \(x\) to \(v\), is a path of length at most \(2(k-1)+1 = 2k-1\) between \(u\) and \(v\) in \(H\), as desired.</p>

<h1 id="optimality-the-girth-conjecture">Optimality: The Girth Conjecture</h1>

<p>It is not hard to construct a class of graphs such that for any graph \(G\) of size \(n\) in the class, the Halperin-Zwick algorithm produces a \((2k-1)\)-spanner for \(G\) that has \(\Omega(n^{1+1/k})\) edges. Could we go below the bound \(\Theta(n^{1+1/k})\) on the number of edges (by a different algorithm, say)? The consensus seems to be no, though currently we do not have a definite answer.</p>

<p>Spanners have a tight connection to the girth of graphs; a graph has girth \(g\) if the shortest simple cycle in the graph has length \(g\).</p>

<hr />
<p><strong>Observation 3</strong>: Let \(H\) be a graph of girth \(2k+1\). Then any \((2k-1)\)-spanner of \(H\) must contain every edge of \(H\).</p>

<hr />

<p>Observation 3 essentially says that any \((2k-1)\)-spanner of \(H\) must be itself. Thus, the question of the optimality of spanners reduces to: is there any graph with \(o(n^{1+1/k})\) edges and girth \((2k+1)\)? The ErdÅsâ Girth Conjecture implies that the answer is no.</p>

<hr />
<p><strong>ErdÅsâ Girth Conjecture [5]</strong>: For any \(n \geq 1\) and \(k\geq 1\), there exists a graph with \(n\) vertices of girth \((2k+1)\) that has \(\Omega(n^{1+1/k})\) edges.</p>

<hr />

<p>ErdÅs stated a lower bound \(c_k\cdot n^{1+1/k}\) on the number of edges in the conjecture [5]; that is, the constant is allowed to degrade as \(k\) increases.  The spanner literature often cites the stronger version above, where the constant remains the same for every \(k\). The ErdÅsâ Girth Conjecture is known to hold for a few small values of \(k\).</p>

<p>While ErdÅsâ Girth Conjecture remains wide open, we could ask: is it possible to construct a \((2k-1)\)-spanner that has girth at least \(2k+1\)? If yes, then the output spanner is (existentially) optimal regardless of the truth of ErdÅsâ Girth Conjecture.</p>

<p>It turns out that the following simple greedy algorithm, formally described in [2] and attributed to Marshall Bern, does the job: consider edges in increasing weight order and add an edge \(e\) to the current spanner if the distance between its endpoints in the spanner is larger than \((2k-1)w(e)\). The algorithm works for weighted graphs as well. It is an instructive exercise to show that the output graph is a \((2k-1)\)-spanner and has girth at least \(2k+1\).</p>

<p>The major downsize of the greedy algorithm is its running time: the current best known implemtation takes \(O(mn^{1+1/k})\) time. Even in unweighted graphs, to the best of my knowledge, the following problem remains open:</p>

<hr />
<p><strong>Open Problem</strong>: Construct a maximal subgraph of girth at least \((2k+1)\) in nearly linear time.</p>

<hr />

<p>For an unweighted graph, a maximal subgraph of girth at least \((2k+1)\) is a \((2k-1)\)-spanner.</p>

<h1 id="conclusion">Conclusion</h1>

<p>We have mentioned two algorithms for constructing a spanner. Another beautiful algorithm that I hope to cover in a future post is the randomized construction by Baswana and Sen [4]. A notable feature of the Baswana-Sen algorithm is that it can be implemented efficiently in both parallel and distributed models. The recent survey paper [1] contains almost all known algorithms for spanners and its sibling problems.</p>

<h1 id="bibliographical-notes">Bibliographical Notes</h1>

<p>The concept of a spanner was formally introduced by Peleg and Schaffer [8], though its conception was much earlier. Peleg and Schaffer constructed a \((4k-3)\)-spanner with \(O(n^{1+1/k})\) edges by connecting every pair of clusters in the output of <span style="font-variant: small-caps">Clustering</span>\((G,k)\) by an edge. This clustering procedure was due to Awerbuch [2].</p>

<h1 id="references">References</h1>

<p>[1] Ahmed, R., Bodwin, G., Sahneh, F. D., Hamm, K., Jebelli, M. J. L., Kobourov, S., and Spence, R. (2020). Graph spanners: A tutorial review. Computer Science Review, 37, 100253.</p>

<p>[2] AlthÃ¶fer, I., Das, G., Dobkin, D., Joseph, D., and Soares, J. (1993). On sparse spanners of weighted graphs. Discrete \&amp; Computational Geometry, 9(1), 81-100.</p>

<p>[3] Awerbuch, B. (1985). Complexity of network synchronization. Journal of the ACM (JACM), 32(4), 804-823.</p>

<p>[4] Baswana, S., and Sen, S. (2007). A simple and linear time randomized algorithm for computing sparse spanners in weighted graphs. Random Structures &amp; Algorithms, 30(4), 532-563.</p>

<p>[5] ErdÅs, P. (1965). Extremal problems in graph theory. In Proceedings of the Symposium on Theory of Graphs and its Applications, page 29-36, 1963.</p>

<p>[6] Halperin, S., and Zwick, U. (1996). Unpublished manuscript.</p>

<p>[7] Peleg, D. (2000). Distributed computing: a locality-sensitive approach. Society for Industrial and Applied Mathematics.</p>

<p>[8] Peleg, D., and SchÃ¤ffer, A. A. (1989). Graph spanners. Journal of graph theory, 13(1), 99-116.</p><p class="authors">By Hung Le</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-26T00:00:00Z">Sunday, February 26 2023, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, February 25
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/'>STOC 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          STOC 2023 is the 55th Annual ACM Symposium on Theory of Computing. It will be held on June 20-23, 2023 in Orlando, Florida. Perhaps the best paper ever at STOC was by Stephen Cook. His 1971 STOC paper The Complexity of Theorem Proving Procedures formalized the notions of polynomial-time and started the search to prove [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<a href="http://acm-stoc.org/stoc2023/">STOC 2023</a> is the 55th Annual ACM Symposium on Theory of Computing. It will be held on June 20-23, 2023 in Orlando, Florida. </p>
<p>
Perhaps the best paper ever at STOC was by Stephen Cook. His 1971 STOC paper <a href="https://dl.acm.org/doi/10.1145/800157.805047">The Complexity of Theorem Proving Procedures</a> formalized the notions of polynomial-time and started the search to prove <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" /> is not equal to <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BNP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{NP}" class="latex" />. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/cook/" rel="attachment wp-att-21168"><img data-attachment-id="21168" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/cook/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?fit=290%2C174&amp;ssl=1" data-orig-size="290,174" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cook" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?fit=290%2C174&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?fit=290%2C174&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?resize=290%2C174&#038;ssl=1" alt="" width="290" height="174" class="aligncenter size-full wp-image-21168" data-recalc-dims="1" /></a></p>
<p>
See <a href="https://en.wikipedia.org/wiki/Symposium_on_Theory_of_Computing">this</a> for more. </p>
<p>
<p><H2> Papers with Pointers </H2></p>
<p><p>
Many web sites on STOC 2023 list the accepted papers but not with pointers. We planned to create these links ourself but we discovered this site that already has them:</p>
<p>
<a href="https://www.conference-publishing.com/list.php?Event=STOC23">List of papers</a> with pointers. </p>
<p>
This saved us having to create the pointers. Try them&#8212;fun to see the accepted papers.</p>
<p>
<p><H2> The Program Committee </H2></p>
<p><p>
Thanks to the program committee for working so hard on putting together such a terrific program. </p>
<ul>
<li>
Amir Abboud (Weizmann Institute of Science) </p>
<li>
Josh Alman (Columbia University) </p>
<li>
Andris Ambainis (University of Latvia) </p>
<li>
Nima Anari (Stanford University) </p>
<li>
Srinivasan Arunachalam (IBM Thomas J. Watson Research Center) </p>
<li>
Petra Berenbrink (Universitat Hamburg) </p>
<li>
Aaron Bernstein (Rutgers University) </p>
<li>
Aditya Bhaskara (University of Utah) </p>
<li>
Sayan Bhattacharya (University of Warwick) </p>
<li>
Eric Blais (University of Waterloo) </p>
<li>
Hans Bodlaender (Utrecht University) </p>
<li>
Adam Bouland (Stanford University) </p>
<li>
Anne Broadbent (University of Ottawa) </p>
<li>
Mark Bun (Boston University) </p>
<li>
Keren Censor-Hillel (Technion) </p>
<li>
Timothy Chan (University of Illinois at Urbana-Champaign) </p>
<li>
Arkadev Chattopadhyay (Tata Institute of Fundamental Research) </p>
<li>
Chandra Chekuri (University of Illinois at Urbana-Champaign) </p>
<li>
Xue Chen (University of Science and Technology of China) </p>
<li>
Gil Cohen (Tel Aviv University) </p>
<li>
Dana Dachman-Soled (University of Maryland College Park) </p>
<li>
Anindya De (University of Pennsylvania) </p>
<li>
Shahar Dobzhinski (Weizmann Institute of Science) </p>
<li>
Shaddin Dughmi (University of Southern California) </p>
<li>
Vida Dujmovic (University of Ottawa) </p>
<li>
Yuval Filmus (Technion) </p>
<li>
Sumegha Garg (Stanford University) </p>
<li>
Rong Ge (Duke University) </p>
<li>
Elena Grigorescu (Purdue University) </p>
<li>
Shuichi Hirahara (National Institute of Informatics, Japan) </p>
<li>
Zhiyi Huang (University of Hong Kong) </p>
<li>
Sungjin Im (University of California, Merced) </p>
<li>
Giuseppe Italiano (LUISS University) </p>
<li>
Ken-ichi Kawarabayashi (National Institute of Informatics, Japan) </p>
<li>
Sanjeev Khanna (University of Pennsylvania) </p>
<li>
Robin Kothari (Google Research) </p>
<li>
Marvin Kunnemann (TU Kaiserslautern) </p>
<li>
Rasmus Kyng (ETH Zurich) </p>
<li>
Sophie Laplante (Universite Paris Cite) </p>
<li>
Hung Le (University of Massachusetts, Amherst) </p>
<li>
Daniel Lokshtanov (University of California, Santa Barbara) </p>
<li>
Sepideh Mahabadi (Microsoft Research) </p>
<li>
Nicole Megow (Universitat Bremen) </p>
<li>
Slobodan Mitrovic (University of California, Davis) </p>
<li>
Ankur Moitra (Massachusetts Institute of Technology) </p>
<li>
Shay Moran (Technion and Google Research) </p>
<li>
Christopher Musco (New York University) </p>
<li>
Krzysztof Onak (Boston University) </p>
<li>
Rotem Oshman (Tel Aviv University) </p>
<li>
Prasad Raghavendra (University of California, Berkeley) </p>
<li>
Susanna Rezende (Lund University) </p>
<li>
Robert Robere (McGill University) </p>
<li>
Alon Rosen (Bocconi University and Reichman University) </p>
<li>
Ron Rothblum (Technion) </p>
<li>
Alex Russell (University of Connecticut) </p>
<li>
Laura Sanita (Bocconi University) </p>
<li>
Thatchaphol Saranurak (University of Michigan) </p>
<li>
Tselil Schramm (Stanford University) </p>
<li>
Rocco Servedio (Columbia University), Chair </p>
<li>
Tasos Sidiropoulos (University of Illinois at Chicago) </p>
<li>
Alex Slivkins (Microsoft Research) </p>
<li>
Srikanth Srinivasan (Aarhus University) </p>
<li>
David Steurer (ETH Zurich) </p>
<li>
Ola Svensson (EPFL) </p>
<li>
Chaitanya Swamy (University of Waterloo) </p>
<li>
Madhur Tulsiani (Toyota Technological Institute at Chicago) </p>
<li>
Christos Tzamos (University of Wisconsin-Madison) </p>
<li>
Muthu Venkitasubramaniam (Georgetown University) </p>
<li>
Ben Lee Volk (Reichman University) </p>
<li>
Andreas Wiese (Technical University of Munich) </p>
<li>
Mary Wootters (Stanford University) </p>
<li>
Yuichi Yoshida (National Institute of Informatics, Japan) </p>
<li>
Huacheng Yu (Princeton University)
</ul>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
I hope having the list of accepted papers with links is of some value. Cook&#8217;s paper might be the best ever, but it did not get the award for best paper at the time. Here are some of the more recent <a href="https://www.sigact.org/prizes/best_paper.html">best papers</a>:</p>
<p>
2020	<a href="https://arxiv.org/abs/1908.08483">Improved Bounds for The Sunflower Lemma</a> <br />
2019	<a href="https://arxiv.org/abs/1809.07115">The Reachability Problem for Petri Nets is Not Elementary</a> </p>
<p>
I like the second one above for personal reasons that I expounded long ago <a href="https://rjlipton.wpcomstaging.com/2009/04/08/an-expspace-lower-bound/">here</a>, and which Ken expanded on <a href="https://rjlipton.wpcomstaging.com/2015/07/12/the-long-reach-of-reachability/">here</a>. </p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-25T23:40:51Z">Saturday, February 25 2023, 23:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/02/25/isohedral-delaunay-complexes.html'>Isohedral Delaunay complexes</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Delaunay complex of a set of points in the Euclidean plane partitions the convex hull of the points into polygonal cells. Each cell is the convex hull of a co-circular subset of the points whose circle does not contain any more points. Itâs often called a Delaunay triangulation, because for points in general position the cells are all triangles, but I do not want to assume general position here. It is isohedral when all of the cells are symmetric to each other (maybe a little more strong than asking for them all to have the same shape). For example, the familiar tilings of the plane by squares or regular hexagons are both isohedral and Delaunay. Another example is a tiling of the plane by 60Â°â90Â°â120Â° kites:
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Delaunay complex of a set of points in the Euclidean plane partitions the convex hull of the points into polygonal cells. Each cell is the convex hull of a co-circular subset of the points whose circle does not contain any more points. Itâs often called a <a href="https://en.wikipedia.org/wiki/Delaunay_triangulation">Delaunay triangulation</a>, because for points in <a href="General position">general position</a> the cells are all triangles, but I do not want to assume general position here. It is <a href="https://en.wikipedia.org/wiki/Isohedral_figure">isohedral</a> when all of the cells are symmetric to each other (maybe a little more strong than asking for them all to have the same shape). For example, the familiar tilings of the plane by squares or regular hexagons are both isohedral and Delaunay. Another example is a <a href="https://en.wikipedia.org/wiki/Deltoidal_trihexagonal_tiling">tiling of the plane by 60Â°â90Â°â120Â° kites</a>:</p>

<p style="text-align:center"><img src="/blog/assets/2023/tetrille-delaunay.svg" alt="Tiling of the plane by 60Â°â90Â°â120Â° kites, with shading showing that the circumcircles of each site are empty of other tiling vertices" style="width:100%;max-width:720px" /></p>

<p>Some other tilings, even very symmetric ones, might not be Delaunay. For instance, it is impossible to make a Delaunay version of the <a href="https://en.wikipedia.org/wiki/Cairo_pentagonal_tiling">Cairo pentagonal tiling</a> because its tiles have two complementary angles or two right angles, impossible for a co-circular pentagon.</p>

<p>In these cases, the symmetries are of the familiar kind, translations and rotations of the plane. But translation symmetry forces us to use infinitely many points. Can finite Delaunay complexes be isohedral? Sort of, maybe, but with a different kind of symmetry.
You can translate between Delaunay complexes on the plane and on a sphere by <a href="https://en.wikipedia.org/wiki/Stereographic_projection">stereographic projection</a>, and translations, rotations, and scaling in the plane become MÃ¶bius transformations on the sphere. So the projection onto the sphere of a square grid becomes a spherical Delaunay complex that is symmetric under MÃ¶bius transformations.</p>

<p style="text-align:center"><img src="/blog/assets/2023/stereographic-square-tiling.svg" alt="Stereographic projection of a square grid from the plane to a sphere" title="CC-BY-SA 4.0 image https://commons.wikimedia.org/wiki/File:Stereogr-proj-netz.svg by Ag2gaeh from Wikimedia commons" style="width:100%;max-width:720px" /></p>

<p>Rotations of the sphere are also a very special case of MÃ¶bius transformations, so we can look for Delaunay complexes with rotational symmetries. Suppose you have a polyhedron all of whose vertices lie on a sphere, and all of whose faces are symmetric to each other by rotations of the sphere. Then the intersection of the sphere with any face plane of the polyhedron is a circle through the vertices of a face that does not contain any other vertices, the defining property of a Delaunay cell. So these polyhedra are isohedral spherical Delaunay complexes. This is true, for instance, for the Platonic solids and for the two infinite families of <a href="https://en.wikipedia.org/wiki/Bipyramid">bipyramids</a> and the <a href="https://en.wikipedia.org/wiki/Trapezohedron">trapezohedra</a> but false for some other isohedral polyhedra like the <a href="https://en.wikipedia.org/wiki/Rhombic_dodecahedron">rhombic dodecahedron</a> and <a href="https://en.wikipedia.org/wiki/Triakis_tetrahedron">triakis tetrahedron</a> whose vertices cannot all be placed on a sphere.</p>

<p>You can map these spherical Delaunay complexes back onto the plane by stereographic projection again. You might think that the result is always a planar Delaunay complex in which all faces are symmetric to each other under MÃ¶bius transformation, but thereâs a catch. The projection preserves circles, but it turns inside out the ones that contain the pole of the projection. If they were empty on the sphere, they instead turn into circles in the plane that contain every other point. These inside-out circles correspond to Delaunay cells on the sphere that do not map to Delaunay cells in the plane. For instance, projecting the cube vertices back down to the plane with the pole at the midpoint of a cube edge produces a Delaunay complex with only four quadrilaterals; the other two faces of the cube come from inside-out circles and do not become Delaunay cells.</p>

<p style="text-align:center"><img src="/blog/assets/2023/cube-edge-projection.svg" alt="Delaunay complex of a cube, stereographically projected onto the plane with its pole at an edge midpoint" style="width:100%;max-width:720px" /></p>

<p>All of this generalizes directly to 3d Delaunay triangulations, and to isohedral 4d polytopes with cospherical vertices, but less is known about what shapes are possible. The regular 4-polytopes, certainly, have symmetric facets and cospherical vertices, but there are other possibilities as well. The <a href="http://www.polytope.net/hedrondude/dice4.htm">isohedral 4-polytopes with up to 20 sides</a> have been classified, but I donât know which of these can have cospherical vertices.</p>

<p>There are, at least, three different infinite families of isohedral 4d polytopes with cospherical vertices, analogous to the bipyramids and trapezohedra. To describe this, it helps to think of four-dimensional Euclidean space as having two complex numbers \(\alpha\) and \(\beta\) as coordinates, and the unit sphere as the points for which \(\vert\alpha\vert^2+\vert\beta\vert^2=1\). These are the state vectors of a <a href="https://en.wikipedia.org/wiki/Qubit">qubit</a>, so we can write these points on the sphere using <a href="https://en.wikipedia.org/wiki/Bra%E2%80%93ket_notation">quantum notation</a> as \(\alpha\,\vert0\rangle+\beta\,\vert1\rangle\), where \(\vert0\rangle\) and \(\vert1\rangle\) are just the two basis vectors for the two-complex-number coordinate system. In this notation, consider the following three sets of points, all on the unit sphere, for integer parameters \(n\) and \(m\):</p>

<ul>
  <li>
    <p>Let \(X\) be the set of \(n\) points \(e^{2\pi i/n}\,\vert0\rangle\), for the integers \(i\) with \(0\le i\lt n\). These form a regular \(n\)-gon in the plane \(\beta=0\).</p>
  </li>
  <li>
    <p>Let \(Y\) be the set of \(m\) points \(e^{2\pi j/m}\,\vert1\rangle\), for the integers \(j\) with \(0\le j\lt n\). These form a regular \(m\)-gon, in the perpendicular plane \(\alpha=0\).</p>
  </li>
  <li>
    <p>Let \(Z\) be the set of \(mn\) points</p>

\[\frac{1}{\sqrt 2}e^{2\pi i/n}\,\vert0\rangle + \frac{1}{\sqrt 2}e^{2\pi j/m}\,\vert1\rangle,\]

    <p>for the same ranges of \(i\) and \(j\). These lie on a <a href="https://en.wikipedia.org/wiki/Flat_torus">flat torus</a>, the Cartesian product of two circles, and form the vertices of a tiling of the torus by rectangles.</p>
  </li>
</ul>

<p>Then the convex hull of \(X\cup Y\) has as its facets \(mn\) congruent tetrahedra, each formed as the convex hull of an edge of the \(X\)-polygon and an edge of the \(Y\)-polygon. The convex hull of \(Z\) is a <a href="https://en.wikipedia.org/wiki/Duoprism">duoprism</a> whose facets are two kinds of prisms: the Cartesian product of an edge of the \(X\)-polygon with the whole \(Y\)-polygon, and vice versa. When \(n=m\) these two prisms are congruent and the resulting duoprism is isohedral, and dual to the convex hull of \(X\cup Y\). Here is a stereographic projection for \(n=m=18\), taken from the <a href="https://www.math.cmu.edu/~fho/jenn/polytopes/index.html">Jenn 3d website</a>:</p>

<p style="text-align:center"><img src="/blog/assets/2023/18x18-torus.png" alt="Stereographic projection into 3d of a 4-dimensional polytope, the (18,18)-duoprism, appearing as a torus tiled with squares" title="Public domain image https://www.math.cmu.edu/~fho/jenn/polytopes/18x18-torus.png" style="width:100%;max-width:720px" /></p>

<p>In this image, the most prominent feature is the tiling by squares of the torus containing \(Z\). If you follow sequences of edges of this square grid, through opposite edges at each vertex, you will also see many 18-gons. Some of the 18-gons slice the âinsideâ of the torus radially into distorted prisms; these are Delaunay cells. Many of the perpendicular 18-gons slice across the âdonut holeâ of the torus, forming more Delaunay cells. But some of the remaining 18-gons lie on the convex hull of the shape, and cannot be used as slices for the projected set. The missing slices cause the Delaunay triangulation of the stereographic projection to miss some cells, and that can only happen because the spheres for these cells were inverted by the projection.</p>

<p>You can also take the convex hull of \(X\cup Y\cup Z\). This has two triangular-prism facets for each tetrahedron of \(X\cup Y\), meeting at one of the squares of \(Z\). The reason Iâm interested in this example comes from <a href="/blog/2023/02/20/geometric-graphs-unbounded.html">my most recent post, on flip-width of geometric graphs</a>. If you take an induced subgraph of this polytope, consisting only of the points in \(X\cup Y\cup Z\) whose coefficients \(i\) and \(j\) are both even, the result is a subdivided complete bipartite graph \(K_{n,n}\), where by âsubdividedâ I mean that each edge of \(K_{n,n}\) has been replaced by a two-edge path. This isnât an interchange, in the sense of the previous post, but it has unbounded flip-width, because it is a sparse graph that does not have bounded expansion.</p>

<p>What I really want, though, is a 3d Euclidean Delaunay triangulation with unbounded flip-width, not a non-triangulation complex and not a 4-polytope (I already had one of those in my previous post). To get this, use a stereographic projection whose pole is on the central torus, in the middle of one of the squares (or really on the corresponding point of the unit sphere), and note that the Delaunay spheres of the polytope faces will intersect this torus in Delaunay circles of the squares. But for a square grid, the center of each square belongs only to the circumcircle of that square, not to any of the other circumcircles. So the pole of the projection will only belong to two of the Delaunay spheres, the two sharing the chosen square. The two prisms for these two spheres will be missing from the Delaunay complex (instead, their union, some sort of <a href="https://en.wikipedia.org/wiki/Gyrobifastigium">gyrobifastifium</a>, will form the convex hull of the points), but all the other prisms will still be present. They contain all the edges of the graph, so it still contains a large induced subdivided biclique. Perturbing the points slightly to get a triangulation rather than a complex doesnât change this.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/109926574982696332">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-25T09:19:00Z">Saturday, February 25 2023, 09:19</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, February 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/24/postdoc-at-tu-eindhoven-university-of-amsterdam-leiden-university-cwi-apply-by-march-31-2023/'>postdoc at TU Eindhoven, University of Amsterdam, Leiden University, CWI (apply by March 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Postdoc Positions in Algorithmics and Stochastics, in the NETWORKS project (the Netherlands). The NETWORKS project is a collaboration of researchers from four institutions in The Netherlands: TU Eindhoven, University of Amsterdam, Leiden University and the Centrum Wiskunde &#38; Informatica (CWI). NETWORKS has openings for postdocs working on algorithmics or stochastics for network problems. Website: www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND- [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Postdoc Positions in Algorithmics and Stochastics, in the NETWORKS project (the Netherlands).</p>
<p>The NETWORKS project is a collaboration of researchers from four institutions in The Netherlands: TU Eindhoven, University of Amsterdam, Leiden University and the Centrum Wiskunde &amp; Informatica (CWI). NETWORKS has openings for postdocs working on algorithmics or stochastics for network problems.</p>
<p>Website: <a href="https://www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND-">https://www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND-</a><br />
Email: info@thenetworkcenter.nl</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T12:53:26Z">Friday, February 24 2023, 12:53</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11578'>Guidable Local Hamiltonian Problems with Implications to Heuristic Ans\"atze State Preparation and the Quantum PCP Conjecture</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jordi Weggemans, Marten Folkertsma, Chris Cade</p><p>We introduce 'Merlinized' versions of the recently defined Guided Local
Hamiltonian problem, which we call 'Guidable Local Hamiltonian' problems.
Unlike their guided counterparts, these problems do not have a guiding state
provided as a part of the input, but merely come with the promise that one
exists and that it satisfies certain constraints. We consider in particular two
classes of guiding states: those that can be prepared efficiently by a quantum
circuit; and those belonging to a class of quantum states we call classically
evaluatable, which have a short classical description from which it is possible
to efficiently compute expectation values of local observables classically. We
show that guidable local Hamiltonian problems for both classes of guiding
states are $\mathsf{QCMA}$-complete in the inverse-polynomial precision
setting, but lie within $\mathsf{NP}$ (or $\mathsf{NqP}$) in certain parameter
regimes when the guiding state is classically evaluatable.
</p>
<p>We discuss the implications of these results to heuristic ans\"atze state
preparation and the quantum PCP conjecture. Our completeness results show that,
from a complexity-theoretic perspective, classical ans\"atze prepared by
classical heuristics are just as powerful as quantum ans\"atze prepared by
quantum heuristics, so long as one has access to quantum phase estimation. In
relation to the quantum PCP conjecture, we (i) define a PCP for $\mathsf{QCMA}$
and show that it is equal to $\mathsf{NP}$ under quantum reductions; (ii) show
several no-go results for the existence of quantum gap amplification procedures
that preserve certain ground state properties; and (iii) propose two
conjectures that can be viewed as stronger versions of the NLTS theorem.
Finally, we show that many of our results can be directly modified to obtain
similar results for the class $\mathsf{MA}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Weggemans_J/0/1/0/all/0/1">Jordi Weggemans</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Folkertsma_M/0/1/0/all/0/1">Marten Folkertsma</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Cade_C/0/1/0/all/0/1">Chris Cade</a></p><p>We introduce 'Merlinized' versions of the recently defined Guided Local
Hamiltonian problem, which we call 'Guidable Local Hamiltonian' problems.
Unlike their guided counterparts, these problems do not have a guiding state
provided as a part of the input, but merely come with the promise that one
exists and that it satisfies certain constraints. We consider in particular two
classes of guiding states: those that can be prepared efficiently by a quantum
circuit; and those belonging to a class of quantum states we call classically
evaluatable, which have a short classical description from which it is possible
to efficiently compute expectation values of local observables classically. We
show that guidable local Hamiltonian problems for both classes of guiding
states are $\mathsf{QCMA}$-complete in the inverse-polynomial precision
setting, but lie within $\mathsf{NP}$ (or $\mathsf{NqP}$) in certain parameter
regimes when the guiding state is classically evaluatable.
</p>
<p>We discuss the implications of these results to heuristic ans\"atze state
preparation and the quantum PCP conjecture. Our completeness results show that,
from a complexity-theoretic perspective, classical ans\"atze prepared by
classical heuristics are just as powerful as quantum ans\"atze prepared by
quantum heuristics, so long as one has access to quantum phase estimation. In
relation to the quantum PCP conjecture, we (i) define a PCP for $\mathsf{QCMA}$
and show that it is equal to $\mathsf{NP}$ under quantum reductions; (ii) show
several no-go results for the existence of quantum gap amplification procedures
that preserve certain ground state properties; and (iii) propose two
conjectures that can be viewed as stronger versions of the NLTS theorem.
Finally, we show that many of our results can be directly modified to obtain
similar results for the class $\mathsf{MA}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11667'>Cutting Barnette graphs perfectly is hard</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: &#xc9;douard Bonnet, Dibyayan Chakraborty, Julien Duron</p><p>A perfect matching cut is a perfect matching that is also a cutset, or
equivalently a perfect matching containing an even number of edges on every
cycle. The corresponding algorithmic problem, Perfect Matching Cut, is known to
be NP-complete in subcubic bipartite graphs [Le &amp; Telle, TCS '22] but its
complexity was open in planar graphs and in cubic graphs. We settle both
questions at once by showing that Perfect Matching Cut is NP-complete in
3-connected cubic bipartite planar graphs or Barnette graphs. Prior to our
work, among problems whose input is solely an undirected graph, only Distance-2
4-Coloring was known NP-complete in Barnette graphs. Notably, Hamiltonian Cycle
would only join this private club if Barnette's conjecture were refuted.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bonnet_E/0/1/0/all/0/1">&#xc9;douard Bonnet</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1">Dibyayan Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Duron_J/0/1/0/all/0/1">Julien Duron</a></p><p>A perfect matching cut is a perfect matching that is also a cutset, or
equivalently a perfect matching containing an even number of edges on every
cycle. The corresponding algorithmic problem, Perfect Matching Cut, is known to
be NP-complete in subcubic bipartite graphs [Le &amp; Telle, TCS '22] but its
complexity was open in planar graphs and in cubic graphs. We settle both
questions at once by showing that Perfect Matching Cut is NP-complete in
3-connected cubic bipartite planar graphs or Barnette graphs. Prior to our
work, among problems whose input is solely an undirected graph, only Distance-2
4-Coloring was known NP-complete in Barnette graphs. Notably, Hamiltonian Cycle
would only join this private club if Barnette's conjecture were refuted.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11637'>Hitting Sets when the Shallow Cell Complexity is Small</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sander Aarts, David B. Shmoys</p><p>The hitting set problem is a well-known NP-hard optimization problem in
which, given a set of elements and a collection of subsets, the goal is to find
the smallest selection of elements, such that each subset contains at least one
element in the selection. Many geometric set systems enjoy improved
approximation ratios, which have recently been shown to be tight with respect
to the shallow cell complexity of the set system. The algorithms that exploit
the cell complexity, however, tend to be involved and computationally
intensive. This paper shows that comparable approximation ratios for the
hitting set problem can be attained using a much simpler algorithm: solve the
linear programming relaxation, take one initial random sample from the set of
elements with probabilities proportional to the LP-solution, and, while there
is an unhit set, take an additional sample from it proportional to the
LP-solution. Our algorithm is based on a generalization of the elegant
net-finder algorithm of Nabil Mustafa. To analyze this algorithm for the
hitting set problem, we generalize the classic Packing Lemma, and the more
recent Shallow-Packing Lemma, to the setting of weighted epsilon nets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aarts_S/0/1/0/all/0/1">Sander Aarts</a>, <a href="http://arxiv.org/find/cs/1/au:+Shmoys_D/0/1/0/all/0/1">David B. Shmoys</a></p><p>The hitting set problem is a well-known NP-hard optimization problem in
which, given a set of elements and a collection of subsets, the goal is to find
the smallest selection of elements, such that each subset contains at least one
element in the selection. Many geometric set systems enjoy improved
approximation ratios, which have recently been shown to be tight with respect
to the shallow cell complexity of the set system. The algorithms that exploit
the cell complexity, however, tend to be involved and computationally
intensive. This paper shows that comparable approximation ratios for the
hitting set problem can be attained using a much simpler algorithm: solve the
linear programming relaxation, take one initial random sample from the set of
elements with probabilities proportional to the LP-solution, and, while there
is an unhit set, take an additional sample from it proportional to the
LP-solution. Our algorithm is based on a generalization of the elegant
net-finder algorithm of Nabil Mustafa. To analyze this algorithm for the
hitting set problem, we generalize the classic Packing Lemma, and the more
recent Shallow-Packing Lemma, to the setting of weighted epsilon nets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11767'>Adaptive Approximate Implicitization of Planar Parametric Curves via Weak Gradient Constraints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Minghao Guo, Yan Gao, Zheng Pan</p><p>Converting a parametric curve into the implicit form, which is called
implicitization, has always been a popular but challenging problem in geometric
modeling and related applications. However, the existing methods mostly suffer
from the problems of maintaining geometric features and choosing a reasonable
implicit degree. The present paper has two contributions. We first introduce a
new regularization constraint(called the weak gradient constraint) for both
polynomial and non-polynomial curves, which efficiently possesses shape
preserving. We then propose two adaptive algorithms of approximate
implicitization for polynomial and non-polynomial curves respectively, which
find the ``optimal'' implicit degree based on the behavior of the weak gradient
constraint. More precisely, the idea is gradually increasing the implicit
degree, until there is no obvious improvement in the weak gradient loss of the
outputs. Experimental results have shown the effectiveness and high quality of
our proposed methods.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Minghao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1">Zheng Pan</a></p><p>Converting a parametric curve into the implicit form, which is called
implicitization, has always been a popular but challenging problem in geometric
modeling and related applications. However, the existing methods mostly suffer
from the problems of maintaining geometric features and choosing a reasonable
implicit degree. The present paper has two contributions. We first introduce a
new regularization constraint(called the weak gradient constraint) for both
polynomial and non-polynomial curves, which efficiently possesses shape
preserving. We then propose two adaptive algorithms of approximate
implicitization for polynomial and non-polynomial curves respectively, which
find the ``optimal'' implicit degree based on the behavior of the weak gradient
constraint. More precisely, the idea is gradually increasing the implicit
degree, until there is no obvious improvement in the weak gradient loss of the
outputs. Experimental results have shown the effectiveness and high quality of
our proposed methods.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11922'>Translation of "Simplizialzerlegungen von Beschrankter Flachheit'' by Hans Freudenthal, Annals of Mathematics, Second Series, Volume 43, Number 3, July 1942, Pages 580-583</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mathijs Wintraecken (translator)</p><p>Translation of the paper ``Simplizialzerlegungen von Beschrankter Flachheit''
by Hans Freudenthal (doi.org/10.2307/1968813), in which Freudenthal
answers ``a question by Brouwer about the construction of an infinite series of
subdivisions of a polytope, such that the next element in the sequence is a
subdivision of the previous one and such that the subsimplices that arise do
not become arbitrarily flat.''
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Wintraecken_M/0/1/0/all/0/1">Mathijs Wintraecken</a> (translator)</p><p>Translation of the paper ``Simplizialzerlegungen von Beschrankter Flachheit''
by Hans Freudenthal (https://doi.org/10.2307/1968813), in which Freudenthal
answers ``a question by Brouwer about the construction of an infinite series of
subdivisions of a polytope, such that the next element in the sequence is a
subdivision of the previous one and such that the subsimplices that arise do
not become arbitrarily flat.''
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12219'>Certified Polyhedral Decompositions of Collision-Free Configuration Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hongkai Dai, Alexandre Amice, Peter Werner, Annan Zhang, Russ Tedrake</p><p>Understanding the geometry of collision-free configuration space (C-free) in
the presence of task-space obstacles is an essential ingredient for
collision-free motion planning. While it is possible to check for collisions at
a point using standard algorithms, to date no practical method exists for
computing C-free regions with rigorous certificates due to the complexity of
mapping task-space obstacles through the kinematics. In this work, we present
the first to our knowledge rigorous method for approximately decomposing a
rational parametrization of C-free into certified polyhedral regions. Our
method, called C-IRIS (C-space Iterative Regional Inflation by Semidefinite
programming), generates large, convex polytopes in a rational parameterization
of the configuration space which are rigorously certified to be collision-free.
Such regions have been shown to be useful for both optimization-based and
randomized motion planning. Based on convex optimization, our method works in
arbitrary dimensions, only makes assumptions about the convexity of the
obstacles in the task space, and is fast enough to scale to realistic problems
in manipulation. We demonstrate our algorithm's ability to fill a non-trivial
amount of collision-free C-space in several 2-DOF examples where the C-space
can be visualized, as well as the scalability of our algorithm on a 7-DOF KUKA
iiwa, a 6-DOF UR3e and 12-DOF bimanual manipulators. An implementation of our
algorithm is open-sourced in Drake. We furthermore provide examples of our
algorithm in interactive Python notebooks.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hongkai Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Amice_A/0/1/0/all/0/1">Alexandre Amice</a>, <a href="http://arxiv.org/find/cs/1/au:+Werner_P/0/1/0/all/0/1">Peter Werner</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Annan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tedrake_R/0/1/0/all/0/1">Russ Tedrake</a></p><p>Understanding the geometry of collision-free configuration space (C-free) in
the presence of task-space obstacles is an essential ingredient for
collision-free motion planning. While it is possible to check for collisions at
a point using standard algorithms, to date no practical method exists for
computing C-free regions with rigorous certificates due to the complexity of
mapping task-space obstacles through the kinematics. In this work, we present
the first to our knowledge rigorous method for approximately decomposing a
rational parametrization of C-free into certified polyhedral regions. Our
method, called C-IRIS (C-space Iterative Regional Inflation by Semidefinite
programming), generates large, convex polytopes in a rational parameterization
of the configuration space which are rigorously certified to be collision-free.
Such regions have been shown to be useful for both optimization-based and
randomized motion planning. Based on convex optimization, our method works in
arbitrary dimensions, only makes assumptions about the convexity of the
obstacles in the task space, and is fast enough to scale to realistic problems
in manipulation. We demonstrate our algorithm's ability to fill a non-trivial
amount of collision-free C-space in several 2-DOF examples where the C-space
can be visualized, as well as the scalability of our algorithm on a 7-DOF KUKA
iiwa, a 6-DOF UR3e and 12-DOF bimanual manipulators. An implementation of our
algorithm is open-sourced in Drake. We furthermore provide examples of our
algorithm in interactive Python notebooks.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11821'>Storage in Computational Geometry</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yijie Han, Sanjeev Saxena</p><p>We show that $n$ real numbers can be stored in a constant number of real
numbers such that each original real number can be fetched in $O(\log n)$ time.
</p>
<p>Although our result has implications for many computational geometry
problems, we show here, combined with Han's $O(n\sqrt{\log n})$ time real
number sorting algorithm [3, arXiv:1801.00776], we can improve the complexity
of Kirkpatrick's point location algorithm [8] to $O(n\sqrt{\log n})$
preprocessing time, a constant number of real numbers for storage and $O(\log
n)$ point location time. Kirkpatrick's algorithm uses $O(n\log n)$
preprocessing time, $O(n)$ storage and $O(\log n)$ point location time. The
complexity results in Kirkpatrick's algorithm was the previous best result.
Although Lipton and Tarjan's algorithm [10] predates Kirkpatrick's algorithm
and has the same complexity, Kirkpatrick's algorithm is simpler and has a
better structure.
</p>
<p>This paper can be viewed as a companion paper of paper [3, arXiv:1801.00776].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yijie Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1">Sanjeev Saxena</a></p><p>We show that $n$ real numbers can be stored in a constant number of real
numbers such that each original real number can be fetched in $O(\log n)$ time.
</p>
<p>Although our result has implications for many computational geometry
problems, we show here, combined with Han's $O(n\sqrt{\log n})$ time real
number sorting algorithm [3, <a href="/abs/1801.00776">arXiv:1801.00776</a>], we can improve the complexity
of Kirkpatrick's point location algorithm [8] to $O(n\sqrt{\log n})$
preprocessing time, a constant number of real numbers for storage and $O(\log
n)$ point location time. Kirkpatrick's algorithm uses $O(n\log n)$
preprocessing time, $O(n)$ storage and $O(\log n)$ point location time. The
complexity results in Kirkpatrick's algorithm was the previous best result.
Although Lipton and Tarjan's algorithm [10] predates Kirkpatrick's algorithm
and has the same complexity, Kirkpatrick's algorithm is simpler and has a
better structure.
</p>
<p>This paper can be viewed as a companion paper of paper [3, <a href="/abs/1801.00776">arXiv:1801.00776</a>].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
