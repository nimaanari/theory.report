<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-01-12T02:00:23Z">Thursday, January 12 2023, 02:00</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, January 12
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.04350'>Maximum Centre-Disjoint Mergeable Disks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ali Gholami Rudi</p><p>Given a set of disks on the plane, the goal of the problem studied in this
paper is to choose a subset of these disks such that none of its members
contains the centre of any other. Each disk not in this subset must be merged
with one of its nearby disks that is, increasing the latter's radius. We prove
that this problem is NP-hard. We also present polynomial-time algorithms for
the special case in which the centres of all disks are on a line.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rudi_A/0/1/0/all/0/1">Ali Gholami Rudi</a></p><p>Given a set of disks on the plane, the goal of the problem studied in this
paper is to choose a subset of these disks such that none of its members
contains the centre of any other. Each disk not in this subset must be merged
with one of its nearby disks that is, increasing the latter's radius. We prove
that this problem is NP-hard. We also present polynomial-time algorithms for
the special case in which the centres of all disks are on a line.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-12T01:30:00Z">Thursday, January 12 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.04147'>The Basis of Design Tools for Quantum Computing: Arrays, Decision Diagrams, Tensor Networks, and ZX-Calculus</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Robert Wille, Lukas Burgholzer, Stefan Hillmich, Thomas Grurl, Alexander Ploier, Tom Peham</p><p>Quantum computers promise to efficiently solve important problems classical
computers never will. However, in order to capitalize on these prospects, a
fully automated quantum software stack needs to be developed. This involves a
multitude of complex tasks from the classical simulation of quantum circuits,
over their compilation to specific devices, to the verification of the circuits
to be executed as well as the obtained results. All of these tasks are highly
non-trivial and necessitate efficient data structures to tackle the inherent
complexity. Starting from rather straight-forward arrays over decision diagrams
(inspired by the design automation community) to tensor networks and the
ZX-calculus, various complementary approaches have been proposed. This work
provides a look "under the hood" of today's tools and showcases how these means
are utilized in them, e.g., for simulation, compilation, and verification of
quantum circuits.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Wille_R/0/1/0/all/0/1">Robert Wille</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Burgholzer_L/0/1/0/all/0/1">Lukas Burgholzer</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hillmich_S/0/1/0/all/0/1">Stefan Hillmich</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Grurl_T/0/1/0/all/0/1">Thomas Grurl</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ploier_A/0/1/0/all/0/1">Alexander Ploier</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Peham_T/0/1/0/all/0/1">Tom Peham</a></p><p>Quantum computers promise to efficiently solve important problems classical
computers never will. However, in order to capitalize on these prospects, a
fully automated quantum software stack needs to be developed. This involves a
multitude of complex tasks from the classical simulation of quantum circuits,
over their compilation to specific devices, to the verification of the circuits
to be executed as well as the obtained results. All of these tasks are highly
non-trivial and necessitate efficient data structures to tackle the inherent
complexity. Starting from rather straight-forward arrays over decision diagrams
(inspired by the design automation community) to tensor networks and the
ZX-calculus, various complementary approaches have been proposed. This work
provides a look "under the hood" of today's tools and showcases how these means
are utilized in them, e.g., for simulation, compilation, and verification of
quantum circuits.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-12T01:30:00Z">Thursday, January 12 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.04295'>Linear Time Online Algorithms for Constructing Linear-size Suffix Trie</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Diptarama Hendrian, Takuya Takagi, Shunsuke Inenaga, Keisuke Goto, Mitsuru Funakoshi</p><p>The suffix trees are fundamental data structures for various kinds of string
processing. The suffix tree of a text string $T$ of length $n$ has $O(n)$ nodes
and edges, and the string label of each edge is encoded by a pair of positions
in $T$. Thus, even after the tree is built, the input string $T$ needs to be
kept stored and random access to $T$ is still needed. The \emph{linear-size
suffix tries} (\emph{LSTs}), proposed by Crochemore et al. [Linear-size suffix
tries, TCS 638:171-178, 2016], are a "stand-alone" alternative to the suffix
trees. Namely, the LST of an input text string $T$ of length $n$ occupies
$O(n)$ total space, and supports pattern matching and other tasks with the same
efficiency as the suffix tree without the need to store the input text string
$T$. Crochemore et al. proposed an \emph{offline} algorithm which transforms
the suffix tree of $T$ into the LST of $T$ in $O(n \log \sigma)$ time and
$O(n)$ space, where $\sigma$ is the alphabet size. In this paper, we present
two types of \emph{online} algorithms which "directly" construct the LST, from
right to left, and from left to right, without constructing the suffix tree as
an intermediate structure. Both algorithms construct the LST incrementally when
a new symbol is read, and do not access the previously read symbols. Both of
the right-to-left construction algorithm and the left-to-right construction
algorithm work in $O(n \log \sigma)$ time and $O(n)$ space. The main feature of
our algorithms is that the input text string does not need to be stored.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hendrian_D/0/1/0/all/0/1">Diptarama Hendrian</a>, <a href="http://arxiv.org/find/cs/1/au:+Takagi_T/0/1/0/all/0/1">Takuya Takagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Inenaga_S/0/1/0/all/0/1">Shunsuke Inenaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Goto_K/0/1/0/all/0/1">Keisuke Goto</a>, <a href="http://arxiv.org/find/cs/1/au:+Funakoshi_M/0/1/0/all/0/1">Mitsuru Funakoshi</a></p><p>The suffix trees are fundamental data structures for various kinds of string
processing. The suffix tree of a text string $T$ of length $n$ has $O(n)$ nodes
and edges, and the string label of each edge is encoded by a pair of positions
in $T$. Thus, even after the tree is built, the input string $T$ needs to be
kept stored and random access to $T$ is still needed. The \emph{linear-size
suffix tries} (\emph{LSTs}), proposed by Crochemore et al. [Linear-size suffix
tries, TCS 638:171-178, 2016], are a "stand-alone" alternative to the suffix
trees. Namely, the LST of an input text string $T$ of length $n$ occupies
$O(n)$ total space, and supports pattern matching and other tasks with the same
efficiency as the suffix tree without the need to store the input text string
$T$. Crochemore et al. proposed an \emph{offline} algorithm which transforms
the suffix tree of $T$ into the LST of $T$ in $O(n \log \sigma)$ time and
$O(n)$ space, where $\sigma$ is the alphabet size. In this paper, we present
two types of \emph{online} algorithms which "directly" construct the LST, from
right to left, and from left to right, without constructing the suffix tree as
an intermediate structure. Both algorithms construct the LST incrementally when
a new symbol is read, and do not access the previously read symbols. Both of
the right-to-left construction algorithm and the left-to-right construction
algorithm work in $O(n \log \sigma)$ time and $O(n)$ space. The main feature of
our algorithms is that the input text string does not need to be stored.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-12T01:30:00Z">Thursday, January 12 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.04406'>A Note on Property Testing of the Binary Rank</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nader H. Bshouty</p><p>Let $M$ be a $n\times m$ $(0,1)$-matrix. We define the $s$-binary rank,
$br_s(M)$, of $M$ to be the minimal integer $d$ such that there are $d$
monochromatic rectangles that cover all the $1$-entries in the matrix, and each
$1$-entry is covered by at most $s$ rectangles. When $s=1$, this is the binary
rank,~$br(M)$, known from the literature. Let $R(M)$ and $C(M)$ be the set of
rows and columns of~$M$, respectively. We use the result of Sgall (Comb. 1999)
to prove that if $M$ has $s$-binary rank at most~$d$, then $|R(M)|\cdot
|C(M)|\le {d\choose \le s}2^{d}$ where ${d\choose \le s}=\sum_{i=0}^s{d\choose
i}$. This bound is tight; that is, there exists a matrix $M'$ of $s$-binary
rank $d$ such that $|R(M')|\cdot |C(M')|= {d\choose \le s}2^{d}$. Using this
result, we give a new one-sided adaptive and non-adaptive testers for
$(0,1)$-matrices of $s$-binary rank at most $d$ (and exactly $d$) that makes
$\tilde O\left({d\choose \le s}2^d/\epsilon\right)$ and $\tilde
O\left({d\choose \le s}2^d/\epsilon^2\right)$ queries, respectively. For a
fixed $s$, this improves the query complexity of the tester of Parnas et al.
(Theory Comput. Syst. 2021) by a factor of $\tilde \Theta (2^d)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bshouty_N/0/1/0/all/0/1">Nader H. Bshouty</a></p><p>Let $M$ be a $n\times m$ $(0,1)$-matrix. We define the $s$-binary rank,
$br_s(M)$, of $M$ to be the minimal integer $d$ such that there are $d$
monochromatic rectangles that cover all the $1$-entries in the matrix, and each
$1$-entry is covered by at most $s$ rectangles. When $s=1$, this is the binary
rank,~$br(M)$, known from the literature. Let $R(M)$ and $C(M)$ be the set of
rows and columns of~$M$, respectively. We use the result of Sgall (Comb. 1999)
to prove that if $M$ has $s$-binary rank at most~$d$, then $|R(M)|\cdot
|C(M)|\le {d\choose \le s}2^{d}$ where ${d\choose \le s}=\sum_{i=0}^s{d\choose
i}$. This bound is tight; that is, there exists a matrix $M'$ of $s$-binary
rank $d$ such that $|R(M')|\cdot |C(M')|= {d\choose \le s}2^{d}$. Using this
result, we give a new one-sided adaptive and non-adaptive testers for
$(0,1)$-matrices of $s$-binary rank at most $d$ (and exactly $d$) that makes
$\tilde O\left({d\choose \le s}2^d/\epsilon\right)$ and $\tilde
O\left({d\choose \le s}2^d/\epsilon^2\right)$ queries, respectively. For a
fixed $s$, this improves the query complexity of the tester of Parnas et al.
(Theory Comput. Syst. 2021) by a factor of $\tilde \Theta (2^d)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-12T01:30:00Z">Thursday, January 12 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, January 11
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03598'>Stream-K: Work-centric Parallel Decomposition for Dense Matrix-Matrix Multiplication on the GPU</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Muhammad Osama, Duane Merrill, Cris Cecka, Michael Garland, John D. Owens</p><p>We introduce Stream-K, a work-centric parallelization of matrix
multiplication (GEMM) and related computations in dense linear algebra. Whereas
contemporary decompositions are primarily tile-based, our method operates by
partitioning an even share of the aggregate inner loop iterations among
physical processing elements. This provides a near-perfect utilization of
computing resources, regardless of how efficiently the output tiling for any
given problem quantizes across the underlying processing elements.
</p>
<p>On GPU processors, our Stream-K parallelization of GEMM produces a peak
speedup of up to 14$\times$ and 6.7$\times$, and an average performance
response that is both higher and more consistent across 32,824 GEMM problem
geometries than state-of-the-art math libraries such as CUTLASS and cuBLAS.
Furthermore, we achieve this performance from a single tile size configuration
per floating-point precision, whereas today's math libraries employ complex
kernel-selection heuristics to select from a large ensemble of kernel variants.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Osama_M/0/1/0/all/0/1">Muhammad Osama</a>, <a href="http://arxiv.org/find/cs/1/au:+Merrill_D/0/1/0/all/0/1">Duane Merrill</a>, <a href="http://arxiv.org/find/cs/1/au:+Cecka_C/0/1/0/all/0/1">Cris Cecka</a>, <a href="http://arxiv.org/find/cs/1/au:+Garland_M/0/1/0/all/0/1">Michael Garland</a>, <a href="http://arxiv.org/find/cs/1/au:+Owens_J/0/1/0/all/0/1">John D. Owens</a></p><p>We introduce Stream-K, a work-centric parallelization of matrix
multiplication (GEMM) and related computations in dense linear algebra. Whereas
contemporary decompositions are primarily tile-based, our method operates by
partitioning an even share of the aggregate inner loop iterations among
physical processing elements. This provides a near-perfect utilization of
computing resources, regardless of how efficiently the output tiling for any
given problem quantizes across the underlying processing elements.
</p>
<p>On GPU processors, our Stream-K parallelization of GEMM produces a peak
speedup of up to 14$\times$ and 6.7$\times$, and an average performance
response that is both higher and more consistent across 32,824 GEMM problem
geometries than state-of-the-art math libraries such as CUTLASS and cuBLAS.
Furthermore, we achieve this performance from a single tile size configuration
per floating-point precision, whereas today's math libraries employ complex
kernel-selection heuristics to select from a large ensemble of kernel variants.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-11T01:30:00Z">Wednesday, January 11 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03638'>Improved Approximation Algorithms for the Expanding Search Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Svenja M. Griesbach, Felix Hommelsheim, Max Klimm, Kevin Schewior</p><p>A searcher faces a graph with edge lengths and vertex weights, initially
having explored only a given starting vertex. In each step, the searcher adds
an edge to the solution that connects an unexplored vertex to an explored
vertex. This requires an amount of time equal to the edge length. The goal is
to minimize the vertex-weighted sum of the exploration times over all vertices.
We show that this problem is hard to approximate and provide algorithms with
improved approximation guarantees. For the case that all vertices have unit
weight, we provide a $2e$-approximation. For the general case, we give a
$(5e/2+\varepsilon)$-approximation for any $\varepsilon &gt; 0$. Previously, for
both cases only an $8$-approximation was known. Finally, we provide a PTAS for
the case of a Euclidean graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Griesbach_S/0/1/0/all/0/1">Svenja M. Griesbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Hommelsheim_F/0/1/0/all/0/1">Felix Hommelsheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Klimm_M/0/1/0/all/0/1">Max Klimm</a>, <a href="http://arxiv.org/find/cs/1/au:+Schewior_K/0/1/0/all/0/1">Kevin Schewior</a></p><p>A searcher faces a graph with edge lengths and vertex weights, initially
having explored only a given starting vertex. In each step, the searcher adds
an edge to the solution that connects an unexplored vertex to an explored
vertex. This requires an amount of time equal to the edge length. The goal is
to minimize the vertex-weighted sum of the exploration times over all vertices.
We show that this problem is hard to approximate and provide algorithms with
improved approximation guarantees. For the case that all vertices have unit
weight, we provide a $2e$-approximation. For the general case, we give a
$(5e/2+\varepsilon)$-approximation for any $\varepsilon &gt; 0$. Previously, for
both cases only an $8$-approximation was known. Finally, we provide a PTAS for
the case of a Euclidean graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-11T01:30:00Z">Wednesday, January 11 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03763'>Quantum Speedups for Zero-Sum Games via Improved Dynamic Gibbs Sampling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adam Bouland, Yosheb Getachew, Yujia Jin, Aaron Sidford, Kevin Tian</p><p>We give a quantum algorithm for computing an $\epsilon$-approximate Nash
equilibrium of a zero-sum game in a $m \times n$ payoff matrix with bounded
entries. Given a standard quantum oracle for accessing the payoff matrix our
algorithm runs in time $\widetilde{O}(\sqrt{m + n}\cdot \epsilon^{-2.5} +
\epsilon^{-3})$ and outputs a classical representation of the
$\epsilon$-approximate Nash equilibrium. This improves upon the best prior
quantum runtime of $\widetilde{O}(\sqrt{m + n} \cdot \epsilon^{-3})$ obtained
by [vAG19] and the classic $\widetilde{O}((m + n) \cdot \epsilon^{-2})$ runtime
due to [GK95] whenever $\epsilon = \Omega((m +n)^{-1})$. We obtain this result
by designing new quantum data structures for efficiently sampling from a
slowly-changing Gibbs distribution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Bouland_A/0/1/0/all/0/1">Adam Bouland</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Getachew_Y/0/1/0/all/0/1">Yosheb Getachew</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Jin_Y/0/1/0/all/0/1">Yujia Jin</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sidford_A/0/1/0/all/0/1">Aaron Sidford</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tian_K/0/1/0/all/0/1">Kevin Tian</a></p><p>We give a quantum algorithm for computing an $\epsilon$-approximate Nash
equilibrium of a zero-sum game in a $m \times n$ payoff matrix with bounded
entries. Given a standard quantum oracle for accessing the payoff matrix our
algorithm runs in time $\widetilde{O}(\sqrt{m + n}\cdot \epsilon^{-2.5} +
\epsilon^{-3})$ and outputs a classical representation of the
$\epsilon$-approximate Nash equilibrium. This improves upon the best prior
quantum runtime of $\widetilde{O}(\sqrt{m + n} \cdot \epsilon^{-3})$ obtained
by [vAG19] and the classic $\widetilde{O}((m + n) \cdot \epsilon^{-2})$ runtime
due to [GK95] whenever $\epsilon = \Omega((m +n)^{-1})$. We obtain this result
by designing new quantum data structures for efficiently sampling from a
slowly-changing Gibbs distribution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-11T01:30:00Z">Wednesday, January 11 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03862'>Proportionally Fair Matching with Multiple Groups</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sayan Bandyapadhyay, Fedor V. Fomin, Tanmay Inamdar, Kirill Simonov</p><p>The study of fair algorithms has become mainstream in machine learning and
artificial intelligence due to its increasing demand in dealing with biases and
discrimination. Along this line, researchers have considered fair versions of
traditional optimization problems including clustering, regression, ranking and
voting. However, most of the efforts have been channeled into designing
heuristic algorithms, which often do not provide any guarantees on the quality
of the solution. In this work, we study matching problems with the notion of
proportional fairness. Proportional fairness is one of the most popular notions
of group fairness where every group is represented up to an extent proportional
to the final selection size. Matching with proportional fairness or more
commonly, proportionally fair matching, was introduced in [Chierichetti et al.,
AISTATS, 2019], where the problem was studied with only two groups. However, in
many practical applications, the number of groups -- although often a small
constant -- is larger than two. In this work, we make the first step towards
understanding the computational complexity of proportionally fair matching with
more than two groups. We design exact and approximation algorithms achieving
reasonable guarantees on the quality of the matching as well as on the time
complexity. Our algorithms are also supported by suitable hardness bounds.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bandyapadhyay_S/0/1/0/all/0/1">Sayan Bandyapadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Fomin_F/0/1/0/all/0/1">Fedor V. Fomin</a>, <a href="http://arxiv.org/find/cs/1/au:+Inamdar_T/0/1/0/all/0/1">Tanmay Inamdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Simonov_K/0/1/0/all/0/1">Kirill Simonov</a></p><p>The study of fair algorithms has become mainstream in machine learning and
artificial intelligence due to its increasing demand in dealing with biases and
discrimination. Along this line, researchers have considered fair versions of
traditional optimization problems including clustering, regression, ranking and
voting. However, most of the efforts have been channeled into designing
heuristic algorithms, which often do not provide any guarantees on the quality
of the solution. In this work, we study matching problems with the notion of
proportional fairness. Proportional fairness is one of the most popular notions
of group fairness where every group is represented up to an extent proportional
to the final selection size. Matching with proportional fairness or more
commonly, proportionally fair matching, was introduced in [Chierichetti et al.,
AISTATS, 2019], where the problem was studied with only two groups. However, in
many practical applications, the number of groups -- although often a small
constant -- is larger than two. In this work, we make the first step towards
understanding the computational complexity of proportionally fair matching with
more than two groups. We design exact and approximation algorithms achieving
reasonable guarantees on the quality of the matching as well as on the time
complexity. Our algorithms are also supported by suitable hardness bounds.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-11T01:30:00Z">Wednesday, January 11 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03972'>Maintaining Triconnected Components under Node Expansion</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Simon D. Fink, Ignaz Rutter</p><p>SPQR-trees are a central component of graph drawing and are also important in
many further areas of computer science. From their inception onwards, they have
always had a strong relation to dynamic algorithms maintaining information,
e.g., on planarity and triconnectivity, under edge insertion and, later on,
also deletion. In this paper, we focus on a special kind of dynamic update, the
expansion of vertices into arbitrary biconnected graphs, while maintaining the
SPQR-tree and further information. This will also allow us to efficiently merge
two SPQR-trees by identifying the edges incident to two vertices with each
other. We do this working along an axiomatic definition lifting the SPQR-tree
to a stand-alone data structure that can be modified independently from the
graph it might have been derived from. Making changes to this structure, we can
now observe how the graph represented by the SPQR-tree changes, instead of
having to reason which updates to the SPQR-tree are necessary after a change to
the represented graph.
</p>
<p>Using efficient expansions and merges allows us to improve the runtime of the
Synchronized Planarity algorithm by Bl\"asius et al. [ESA 2021] from $O(m^2)$
to $O(m\cdot \Delta)$, where $\Delta$ is the maximum pipe degree. This also
reduces the time for solving several constrained planarity problems, e.g. for
Clustered Planarity from $O((n+d)^2)$ to $O(n+d\cdot \Delta)$, where $d$ is the
total number of crossings between cluster borders and edges and $\Delta$ is the
maximum number of edge crossings on a single cluster border.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fink_S/0/1/0/all/0/1">Simon D. Fink</a>, <a href="http://arxiv.org/find/cs/1/au:+Rutter_I/0/1/0/all/0/1">Ignaz Rutter</a></p><p>SPQR-trees are a central component of graph drawing and are also important in
many further areas of computer science. From their inception onwards, they have
always had a strong relation to dynamic algorithms maintaining information,
e.g., on planarity and triconnectivity, under edge insertion and, later on,
also deletion. In this paper, we focus on a special kind of dynamic update, the
expansion of vertices into arbitrary biconnected graphs, while maintaining the
SPQR-tree and further information. This will also allow us to efficiently merge
two SPQR-trees by identifying the edges incident to two vertices with each
other. We do this working along an axiomatic definition lifting the SPQR-tree
to a stand-alone data structure that can be modified independently from the
graph it might have been derived from. Making changes to this structure, we can
now observe how the graph represented by the SPQR-tree changes, instead of
having to reason which updates to the SPQR-tree are necessary after a change to
the represented graph.
</p>
<p>Using efficient expansions and merges allows us to improve the runtime of the
Synchronized Planarity algorithm by Bl\"asius et al. [ESA 2021] from $O(m^2)$
to $O(m\cdot \Delta)$, where $\Delta$ is the maximum pipe degree. This also
reduces the time for solving several constrained planarity problems, e.g. for
Clustered Planarity from $O((n+d)^2)$ to $O(n+d\cdot \Delta)$, where $d$ is the
total number of crossings between cluster borders and edges and $\Delta$ is the
maximum number of edge crossings on a single cluster border.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-11T01:30:00Z">Wednesday, January 11 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.04003'>Change Propagation Without Joins</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Qichen Wang, Xiao Hu, Binyang Dai, Ke Yi</p><p>We revisit the classical change propagation framework for query evaluation
under updates. The standard framework takes a query plan and materializes the
intermediate views, which incurs high polynomial costs in both space and time,
with the join operator being the culprit. In this paper, we propose a new
change propagation framework without joins, thus naturally avoiding this
polynomial blowup. Meanwhile, we show that the new framework still supports
constant-delay enumeration of both the deltas and the full query results, the
same as in the standard framework. Furthermore, we provide a quantitative
analysis of its update cost, which not only recovers many recent theoretical
results on the problem, but also yields an effective approach to optimizing the
query plan. The new framework is also easy to be integrated into an existing
streaming database system. Experimental results show that our system prototype,
implemented using Flink DataStream API, significantly outperforms other systems
in terms of space, time, and latency.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qichen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1">Binyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_K/0/1/0/all/0/1">Ke Yi</a></p><p>We revisit the classical change propagation framework for query evaluation
under updates. The standard framework takes a query plan and materializes the
intermediate views, which incurs high polynomial costs in both space and time,
with the join operator being the culprit. In this paper, we propose a new
change propagation framework without joins, thus naturally avoiding this
polynomial blowup. Meanwhile, we show that the new framework still supports
constant-delay enumeration of both the deltas and the full query results, the
same as in the standard framework. Furthermore, we provide a quantitative
analysis of its update cost, which not only recovers many recent theoretical
results on the problem, but also yields an effective approach to optimizing the
query plan. The new framework is also easy to be integrated into an existing
streaming database system. Experimental results show that our system prototype,
implemented using Flink DataStream API, significantly outperforms other systems
in terms of space, time, and latency.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-11T01:30:00Z">Wednesday, January 11 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.04009'>On the Complexity of the Two-Stage Majority Rule</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yongjie Yang</p><p>Sequential voting rules have been extensively used in parliamentary and
legislative decision making. After observing that the prevalent successive and
the amendment rules fail several fundamental axioms, Horan and Sprumont [2021]
proposed very recently a two-stage sequential rule which satisfies a variety of
desirable properties. This paper examines this rule by investigating the
complexity of Agenda Control, Coalition Manipulation, Possible Winner,
Necessary Winner, and eight standard election control problems. Our study
offers a comprehensive understanding of the complexity landscape of these
problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yongjie Yang</a></p><p>Sequential voting rules have been extensively used in parliamentary and
legislative decision making. After observing that the prevalent successive and
the amendment rules fail several fundamental axioms, Horan and Sprumont [2021]
proposed very recently a two-stage sequential rule which satisfies a variety of
desirable properties. This paper examines this rule by investigating the
complexity of Agenda Control, Coalition Manipulation, Possible Winner,
Necessary Winner, and eight standard election control problems. Our study
offers a comprehensive understanding of the complexity landscape of these
problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-11T01:30:00Z">Wednesday, January 11 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.04131'>On Knuth's conjecture for back and forward arcs in Depth First Search in a random digraph with geometric outdegree distribution</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Svante Janson</p><p>Donald Knuth, in a draft of a coming volume of The Art of Computer
Programming, has recently conjectured that in Depth-First Search of a random
digraph with geometric outdegree distribution, the numbers of back and forward
arcs have the same distribution.
</p>
<p>We show that this conjecture is equivalent to an equality between two
generating functions defined by different recursions.
</p>
<p>Unfortunately, we have not been able so use this to prove the conjecture,
which still is open, but we hope that this note will inspire others to succeed
with the conjecture.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Janson_S/0/1/0/all/0/1">Svante Janson</a></p><p>Donald Knuth, in a draft of a coming volume of The Art of Computer
Programming, has recently conjectured that in Depth-First Search of a random
digraph with geometric outdegree distribution, the numbers of back and forward
arcs have the same distribution.
</p>
<p>We show that this conjecture is equivalent to an equality between two
generating functions defined by different recursions.
</p>
<p>Unfortunately, we have not been able so use this to prove the conjecture,
which still is open, but we hope that this note will inspire others to succeed
with the conjecture.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-11T01:30:00Z">Wednesday, January 11 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, January 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03221'>Representing Matroids over the Reals is $\exists \mathbb R$-complete</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eunjung Kim, Arnaud de Mesmay, Tillmann Miltzow</p><p>A matroid $M$ is an ordered pair $(E,I)$, where $E$ is a finite set called
the ground set and a collection $I\subset 2^{E}$ called the independent sets
which satisfy the conditions: (I1) $\emptyset \in I$, (I2) $I'\subset I \in I$
implies $I'\in I$, and (I3) $I_1,I_2 \in I$ and $|I_1| &lt; |I_2|$ implies that
there is an $e\in I_2$ such that $I_1\cup \{e\} \in I$. The rank $rank(M)$ of a
matroid $M$ is the maximum size of an independent set. We say that a matroid
$M=(E,I)$ is representable over the reals if there is a map $\varphi : E
\rightarrow \mathbb{R}^{rank(M)}$ such that $I\in I$ if and only if
$\varphi(I)$ forms a linearly independent set.
</p>
<p>We study the problem of matroid realizability over the reals. Given a matroid
$M$, we ask whether there is a set of points in the Euclidean space
representing $M$. We show that matroid realizability is $\exists \mathbb
R$-complete, already for matroids of rank 3. The complexity class $\exists
\mathbb R$ can be defined as the family of algorithmic problems that is
polynomial-time is equivalent to determining if a multivariate polynomial with
integers coefficients has a real root.
</p>
<p>Our methods are similar to previous methods from the literature. Yet, the
result itself was never pointed out and there is no proof readily available in
the language of computer science.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1">Eunjung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Mesmay_A/0/1/0/all/0/1">Arnaud de Mesmay</a>, <a href="http://arxiv.org/find/cs/1/au:+Miltzow_T/0/1/0/all/0/1">Tillmann Miltzow</a></p><p>A matroid $M$ is an ordered pair $(E,I)$, where $E$ is a finite set called
the ground set and a collection $I\subset 2^{E}$ called the independent sets
which satisfy the conditions: (I1) $\emptyset \in I$, (I2) $I'\subset I \in I$
implies $I'\in I$, and (I3) $I_1,I_2 \in I$ and $|I_1| &lt; |I_2|$ implies that
there is an $e\in I_2$ such that $I_1\cup \{e\} \in I$. The rank $rank(M)$ of a
matroid $M$ is the maximum size of an independent set. We say that a matroid
$M=(E,I)$ is representable over the reals if there is a map $\varphi : E
\rightarrow \mathbb{R}^{rank(M)}$ such that $I\in I$ if and only if
$\varphi(I)$ forms a linearly independent set.
</p>
<p>We study the problem of matroid realizability over the reals. Given a matroid
$M$, we ask whether there is a set of points in the Euclidean space
representing $M$. We show that matroid realizability is $\exists \mathbb
R$-complete, already for matroids of rank 3. The complexity class $\exists
\mathbb R$ can be defined as the family of algorithmic problems that is
polynomial-time is equivalent to determining if a multivariate polynomial with
integers coefficients has a real root.
</p>
<p>Our methods are similar to previous methods from the literature. Yet, the
result itself was never pointed out and there is no proof readily available in
the language of computer science.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03384'>Exceeding Computational Complexity Trial-and-Error Dynamic Action and Intelligence</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chuyu Xiong</p><p>Computational complexity is a core theory of computer science, which dictates
the degree of difficulty of computation. There are many problems with high
complexity that we have to deal, which is especially true for AI. This raises a
big question: Is there a better way to deal with these highly complex problems
other than bounded by computational complexity? We believe that ideas and
methods from intelligence science can be applied to these problems and help us
to exceed computational complexity. In this paper, we try to clarify concepts,
and we propose definitions such as unparticularized computing, particularized
computing, computing agents, and dynamic search. We also propose and discuss a
framework, i.e., trial-and-error + dynamic search. Number Partition Problem is
a well-known NP-complete problem, and we use this problem as an example to
illustrate the ideas discussed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Chuyu Xiong</a></p><p>Computational complexity is a core theory of computer science, which dictates
the degree of difficulty of computation. There are many problems with high
complexity that we have to deal, which is especially true for AI. This raises a
big question: Is there a better way to deal with these highly complex problems
other than bounded by computational complexity? We believe that ideas and
methods from intelligence science can be applied to these problems and help us
to exceed computational complexity. In this paper, we try to clarify concepts,
and we propose definitions such as unparticularized computing, particularized
computing, computing agents, and dynamic search. We also propose and discuss a
framework, i.e., trial-and-error + dynamic search. Number Partition Problem is
a well-known NP-complete problem, and we use this problem as an example to
illustrate the ideas discussed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03487'>A Critique of Sopin's "${\rm PH} = {\rm PSPACE}$"</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael C. Chavrimootoo, Ian Clingerman, Quan Luu</p><p>We critique Valerii Sopin's paper "${\rm PH} = {\rm PSPACE}$" [Sop14]. The
paper claims to resolve one of the major open problems of theoretical computer
science by leveraging the Skolemization of existential quantifiers of
quantified boolean formulas to show that ${\rm QBF}$ (a well-known ${\rm
PSPACE}$-complete problem) is in $\Pi_4^p$, and thus ${\rm PH} = {\rm PSPACE}$.
In this critique, we highlight problems in that paper and conclude that it
fails to establish that ${\rm PH} = {\rm PSPACE}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chavrimootoo_M/0/1/0/all/0/1">Michael C. Chavrimootoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Clingerman_I/0/1/0/all/0/1">Ian Clingerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Luu_Q/0/1/0/all/0/1">Quan Luu</a></p><p>We critique Valerii Sopin's paper "${\rm PH} = {\rm PSPACE}$" [Sop14]. The
paper claims to resolve one of the major open problems of theoretical computer
science by leveraging the Skolemization of existential quantifiers of
quantified boolean formulas to show that ${\rm QBF}$ (a well-known ${\rm
PSPACE}$-complete problem) is in $\Pi_4^p$, and thus ${\rm PH} = {\rm PSPACE}$.
In this critique, we highlight problems in that paper and conclude that it
fails to establish that ${\rm PH} = {\rm PSPACE}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02949'>Maximum overlap area of a convex polyhedron and a convex polygon under translation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hyuk Jun Kweon, Honglin Zhu</p><p>Let $P$ be a convex polyhedron and $Q$ be a convex polygon with $n$ vertices
in total in three-dimensional space. We present a deterministic algorithm that
finds a translation vector $v \in \mathbb{R}^3$ maximizing the overlap area $|P
\cap (Q + v)|$ in $O(n \log^2 n)$ time. We then apply our algorithm to solve
two related problems. We give an $O(n \log^3 n)$ time algorithm that finds the
maximum overlap area of three convex polygons with $n$ vertices in total. We
also give an $O(n \log^2 n)$ time algorithm that minimizes the symmetric
difference of two convex polygons under scaling and translation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kweon_H/0/1/0/all/0/1">Hyuk Jun Kweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Honglin Zhu</a></p><p>Let $P$ be a convex polyhedron and $Q$ be a convex polygon with $n$ vertices
in total in three-dimensional space. We present a deterministic algorithm that
finds a translation vector $v \in \mathbb{R}^3$ maximizing the overlap area $|P
\cap (Q + v)|$ in $O(n \log^2 n)$ time. We then apply our algorithm to solve
two related problems. We give an $O(n \log^3 n)$ time algorithm that finds the
maximum overlap area of three convex polygons with $n$ vertices in total. We
also give an $O(n \log^2 n)$ time algorithm that minimizes the symmetric
difference of two convex polygons under scaling and translation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02999'>Variational Direct Modeling: A framework towards integration of parametric modeling and direct modeling in CAD</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Qiang Zou, Hsi-Yung Feng, Shuming Gao</p><p>Feature-based parametric modeling is the de facto standard in CAD. Boundary
representation-based direct modeling is another CAD paradigm developed
recently. They have complementary advantages and limitations, thereby offering
huge potential for improvement towards an integrated CAD modeling scheme. Most
existing integration methods are developed by industry and typically treat
direct edits as pseudo-features, where little can be said about seamless
integration. This paper presents an alternative method for seamless
parametric/direct integration, which allows parametric and direct edits to work
in a unified way. The fundamental issues and challenges of parametric/direct
integration are first explained. A framework is then proposed to handle those
information inconsistencies, based on a detection-then-resolution strategy.
Algorithms that can systematically detect and resolve all possible types of
information inconsistencies are also given to implement the framework. With
them, model validity can be maintained during the whole model editing process,
and then the discrepancy between direct edits and parametric edits can be
resolved. The effectiveness of the proposed approach has been shown with a
series of case studies and comparisons, based on a preliminary prototype.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zou_Q/0/1/0/all/0/1">Qiang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1">Hsi-Yung Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Shuming Gao</a></p><p>Feature-based parametric modeling is the de facto standard in CAD. Boundary
representation-based direct modeling is another CAD paradigm developed
recently. They have complementary advantages and limitations, thereby offering
huge potential for improvement towards an integrated CAD modeling scheme. Most
existing integration methods are developed by industry and typically treat
direct edits as pseudo-features, where little can be said about seamless
integration. This paper presents an alternative method for seamless
parametric/direct integration, which allows parametric and direct edits to work
in a unified way. The fundamental issues and challenges of parametric/direct
integration are first explained. A framework is then proposed to handle those
information inconsistencies, based on a detection-then-resolution strategy.
Algorithms that can systematically detect and resolve all possible types of
information inconsistencies are also given to implement the framework. With
them, model validity can be maintained during the whole model editing process,
and then the discrepancy between direct edits and parametric edits can be
resolved. The effectiveness of the proposed approach has been shown with a
series of case studies and comparisons, based on a preliminary prototype.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03167'>Machining feature recognition using descriptors with range constraints for mechanical 3D models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Seungeun Lim, Changmo Yeo, Fazhi He, Jinwon Lee, Duhwan Mun</p><p>In machining feature recognition, geometric elements generated in a
three-dimensional computer-aided design model are identified. This technique is
used in manufacturability evaluation, process planning, and tool path
generation. Here, we propose a method of recognizing 16 types of machining
features using descriptors, often used in shape-based part retrieval studies.
The base face is selected for each feature type, and descriptors express the
base face's minimum, maximum, and equal conditions. Furthermore, the similarity
in the three conditions between the descriptors extracted from the target face
and those from the base face is calculated. If the similarity is greater than
or equal to the threshold, the target face is determined as the base face of
the feature. Machining feature recognition tests were conducted for two test
cases using the proposed method, and all machining features included in the
test cases were successfully recognized. Also, it was confirmed through an
additional test that the proposed method in this study showed better feature
recognition performance than the latest artificial neural network.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1">Seungeun Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_C/0/1/0/all/0/1">Changmo Yeo</a>, <a href="http://arxiv.org/find/cs/1/au:+He_F/0/1/0/all/0/1">Fazhi He</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jinwon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Mun_D/0/1/0/all/0/1">Duhwan Mun</a></p><p>In machining feature recognition, geometric elements generated in a
three-dimensional computer-aided design model are identified. This technique is
used in manufacturability evaluation, process planning, and tool path
generation. Here, we propose a method of recognizing 16 types of machining
features using descriptors, often used in shape-based part retrieval studies.
The base face is selected for each feature type, and descriptors express the
base face's minimum, maximum, and equal conditions. Furthermore, the similarity
in the three conditions between the descriptors extracted from the target face
and those from the base face is calculated. If the similarity is greater than
or equal to the threshold, the target face is determined as the base face of
the feature. Machining feature recognition tests were conducted for two test
cases using the proposed method, and all machining features included in the
test cases were successfully recognized. Also, it was confirmed through an
additional test that the proposed method in this study showed better feature
recognition performance than the latest artificial neural network.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03230'>Combinatorial Properties for a Class of Simplicial Complexes Extended from Pseudo-fractal Scale-free Web</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zixuan Xie, Yucheng Wang, Wanyue Xu, Liwang Zhu, Wei Li, Zhongzhi Zhang</p><p>Simplicial complexes are a popular tool used to model higher-order
interactions between elements of complex social and biological systems. In this
paper, we study some combinatorial aspects of a class of simplicial complexes
created by a graph product, which is an extension of the pseudo-fractal
scale-free web. We determine explicitly the independence number, the domination
number, and the chromatic number. Moreover, we derive closed-form expressions
for the number of acyclic orientations, the number of root-connected acyclic
orientations, the number of spanning trees, as well as the number of perfect
matchings for some particular cases.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Xie_Z/0/1/0/all/0/1">Zixuan Xie</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_Y/0/1/0/all/0/1">Yucheng Wang</a>, <a href="http://arxiv.org/find/math/1/au:+Xu_W/0/1/0/all/0/1">Wanyue Xu</a>, <a href="http://arxiv.org/find/math/1/au:+Zhu_L/0/1/0/all/0/1">Liwang Zhu</a>, <a href="http://arxiv.org/find/math/1/au:+Li_W/0/1/0/all/0/1">Wei Li</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_Z/0/1/0/all/0/1">Zhongzhi Zhang</a></p><p>Simplicial complexes are a popular tool used to model higher-order
interactions between elements of complex social and biological systems. In this
paper, we study some combinatorial aspects of a class of simplicial complexes
created by a graph product, which is an extension of the pseudo-fractal
scale-free web. We determine explicitly the independence number, the domination
number, and the chromatic number. Moreover, we derive closed-form expressions
for the number of acyclic orientations, the number of root-connected acyclic
orientations, the number of spanning trees, as well as the number of perfect
matchings for some particular cases.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03321'>Dimensionality Reduction for Persistent Homology with Gaussian Kernels</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jean-Daniel Boissonnat, Kunal Dutta</p><p>Computing persistent homology using Gaussian kernels is useful in the domains
of topological data analysis and machine learning as shown by Phillips, Wang
and Zheng [SoCG 2015]. However, contrary to the case of computing persistent
homology using the Euclidean distance or even the $k$-distance, it is not known
how to compute the persistent homology of high dimensional data using Gaussian
kernels. In this paper, we consider a power distance version of the Gaussian
kernel distance (GKPD) given by Phillips, Wang and Zheng, and show that the
persistent homology of the \v{C}ech filtration of $P$ computed using the GKPD
is approximately preserved. For datasets in $d$-dimensional Euclidean space,
under a relative error bound of $\varepsilon \in [0,1]$, we obtain a
dimensionality of $(i)$ $O(\varepsilon^{-2}\log^2 n)$ for $n$-point datasets
and $(ii)$ $O(D\varepsilon^{-2}\log (Dr/\varepsilon))$ for datasets having
diameter $r$ (up to a scaling factor).
</p>
<p>We use two main ingredients. The first one is a new decomposition of the
squared radii of \v{C}ech simplices using the kernel power distance, in terms
of the pairwise GKPDs between the vertices, which we state and prove. The
second one is the Random Fourier Features (RFF) map of Rahimi and Recht
[NeurIPS 2007], as used by Chen and Phillips [ALT 2017].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Boissonnat_J/0/1/0/all/0/1">Jean-Daniel Boissonnat</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_K/0/1/0/all/0/1">Kunal Dutta</a></p><p>Computing persistent homology using Gaussian kernels is useful in the domains
of topological data analysis and machine learning as shown by Phillips, Wang
and Zheng [SoCG 2015]. However, contrary to the case of computing persistent
homology using the Euclidean distance or even the $k$-distance, it is not known
how to compute the persistent homology of high dimensional data using Gaussian
kernels. In this paper, we consider a power distance version of the Gaussian
kernel distance (GKPD) given by Phillips, Wang and Zheng, and show that the
persistent homology of the \v{C}ech filtration of $P$ computed using the GKPD
is approximately preserved. For datasets in $d$-dimensional Euclidean space,
under a relative error bound of $\varepsilon \in [0,1]$, we obtain a
dimensionality of $(i)$ $O(\varepsilon^{-2}\log^2 n)$ for $n$-point datasets
and $(ii)$ $O(D\varepsilon^{-2}\log (Dr/\varepsilon))$ for datasets having
diameter $r$ (up to a scaling factor).
</p>
<p>We use two main ingredients. The first one is a new decomposition of the
squared radii of \v{C}ech simplices using the kernel power distance, in terms
of the pairwise GKPDs between the vertices, which we state and prove. The
second one is the Random Fourier Features (RFF) map of Rahimi and Recht
[NeurIPS 2007], as used by Chen and Phillips [ALT 2017].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03329'>Sparse Geometric Set Systems and the Beck-Fiala Conjecture</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kunal Dutta, Arijit Ghosh</p><p>We investigate the combinatorial discrepancy of geometric set systems having
bounded shallow cell complexity in the \emph{Beck-Fiala} setting, where each
point belongs to at most $t$ ranges. For set systems with shallow cell
complexity $\psi(m,k)=g(m)k^{c}$, where $(i)$ $g(m) = o(m^{\varepsilon})$ for
any $\varepsilon\in (0,1],$ $(ii)$ $\psi$ is non-decreasing in $m$, and $(iii)$
$c&gt;0$ is independent of $m$ and $k$, we get a discrepancy bound of
</p>
<p>\[ O\left(\sqrt{\left(\log
n+\left(t^{c}g(n)\right)^{\frac{1}{1+c}}\right)\log n}\right).\]
</p>
<p>For $t=\omega(\log^2 n)$, in several cases, such as for set systems of points
and half-planes / disks / pseudo-disks in $\mathbb{R}^2$, points and orthants
in $\mathbb{R}^3$ etc., these bounds are $o(\sqrt{t})$, which verifies (and
improves upon) the conjectured bound of Beck and Fiala~\emph{(Disc. Appl.
Math., 1981)}.
</p>
<p>Our bounds are obtained by showing the existence of \emph{matchings with low
crossing number}, using the multiplicative weights update method of Welzl
\emph{(SoCG, 1988)}, together with the recent bound of Mustafa \emph{(Disc.
Comp. Geom., 2015)} on \emph{shallow packings} of set systems in terms of their
shallow cell complexity. For set systems of shallow cell complexity
$\psi(m,k)=m^{c_1}g(m)k^{c}$, we obtain matchings with crossing number at most
</p>
<p>\[ O\left(\left(n^{c_1}g(n)t^{c}\right)^{\frac{1}{1+c_1+c}}\right).\]
</p>
<p>These are of independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dutta_K/0/1/0/all/0/1">Kunal Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Arijit Ghosh</a></p><p>We investigate the combinatorial discrepancy of geometric set systems having
bounded shallow cell complexity in the \emph{Beck-Fiala} setting, where each
point belongs to at most $t$ ranges. For set systems with shallow cell
complexity $\psi(m,k)=g(m)k^{c}$, where $(i)$ $g(m) = o(m^{\varepsilon})$ for
any $\varepsilon\in (0,1],$ $(ii)$ $\psi$ is non-decreasing in $m$, and $(iii)$
$c&gt;0$ is independent of $m$ and $k$, we get a discrepancy bound of
</p>
<p>\[ O\left(\sqrt{\left(\log
n+\left(t^{c}g(n)\right)^{\frac{1}{1+c}}\right)\log n}\right).\]
</p>
<p>For $t=\omega(\log^2 n)$, in several cases, such as for set systems of points
and half-planes / disks / pseudo-disks in $\mathbb{R}^2$, points and orthants
in $\mathbb{R}^3$ etc., these bounds are $o(\sqrt{t})$, which verifies (and
improves upon) the conjectured bound of Beck and Fiala~\emph{(Disc. Appl.
Math., 1981)}.
</p>
<p>Our bounds are obtained by showing the existence of \emph{matchings with low
crossing number}, using the multiplicative weights update method of Welzl
\emph{(SoCG, 1988)}, together with the recent bound of Mustafa \emph{(Disc.
Comp. Geom., 2015)} on \emph{shallow packings} of set systems in terms of their
shallow cell complexity. For set systems of shallow cell complexity
$\psi(m,k)=m^{c_1}g(m)k^{c}$, we obtain matchings with crossing number at most
</p>
<p>\[ O\left(\left(n^{c_1}g(n)t^{c}\right)^{\frac{1}{1+c_1+c}}\right).\]
</p>
<p>These are of independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03514'>Strong Collapse of Random Simplicial Complexes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jean-Daniel Boissonnat, Kunal Dutta, Soumik Dutta, Siddharth Pritam</p><p>The \emph{strong collapse} of a simplicial complex, proposed by Barmak and
Minian (\emph{Disc. Comp. Geom. 2012}), is a combinatorial collapse of a
complex onto its sub-complex. Recently, it has received attention from
computational topology researchers, owing to its empirically observed
usefulness in simplification and size-reduction
</p>
<p>of the size of simplicial complexes while preserving the homotopy class. We
consider the strong collapse process on random simplicial complexes. For the
</p>
<p>Erd\H{o}s-R\'enyi random clique complex $X(n,c/n)$ on $n$ vertices with edge
probability $c/n$ with $c&gt;1$, we show that after any maximal sequence of strong
collapses
</p>
<p>the remaining subcomplex, or \emph{core} must have $(1-\gamma)(1-c\gamma)
n+o(n)$ vertices asymptotically almost surely (a.a.s.), where $\gamma$ is the
least non-negative fixed
</p>
<p>point of the function $f(x) = \exp\left(-c(1-x)\right)$ in the range $(0,1)$.
</p>
<p>These are the first theoretical results proved for strong collapses on random
(or non-random) simplicial complexes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Boissonnat_J/0/1/0/all/0/1">Jean-Daniel Boissonnat</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_K/0/1/0/all/0/1">Kunal Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Soumik Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Pritam_S/0/1/0/all/0/1">Siddharth Pritam</a></p><p>The \emph{strong collapse} of a simplicial complex, proposed by Barmak and
Minian (\emph{Disc. Comp. Geom. 2012}), is a combinatorial collapse of a
complex onto its sub-complex. Recently, it has received attention from
computational topology researchers, owing to its empirically observed
usefulness in simplification and size-reduction
</p>
<p>of the size of simplicial complexes while preserving the homotopy class. We
consider the strong collapse process on random simplicial complexes. For the
</p>
<p>Erd\H{o}s-R\'enyi random clique complex $X(n,c/n)$ on $n$ vertices with edge
probability $c/n$ with $c&gt;1$, we show that after any maximal sequence of strong
collapses
</p>
<p>the remaining subcomplex, or \emph{core} must have $(1-\gamma)(1-c\gamma)
n+o(n)$ vertices asymptotically almost surely (a.a.s.), where $\gamma$ is the
least non-negative fixed
</p>
<p>point of the function $f(x) = \exp\left(-c(1-x)\right)$ in the range $(0,1)$.
</p>
<p>These are the first theoretical results proved for strong collapses on random
(or non-random) simplicial complexes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02870'>Sublinear Time Algorithms for Several Geometric Optimization (With Outliers) Problems In Machine Learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hu Ding</p><p>In this paper, we study several important geometric optimization problems
arising in machine learning. First, we revisit the Minimum Enclosing Ball (MEB)
problem in Euclidean space $\mathbb{R}^d$. The problem has been extensively
studied before, but real-world machine learning tasks often need to handle
large-scale datasets so that we cannot even afford linear time algorithms.
Motivated by the recent studies on {\em beyond worst-case analysis}, we
introduce the notion of stability for MEB, which is natural and easy to
understand. Roughly speaking, an instance of MEB is stable, if the radius of
the resulting ball cannot be significantly reduced by removing a small fraction
of the input points. Under the stability assumption, we present two sampling
algorithms for computing radius-approximate MEB with sample complexities
independent of the number of input points $n$. In particular, the second
algorithm has the sample complexity even independent of the dimensionality $d$.
We also consider the general case without the stability assumption. We present
a hybrid algorithm that can output either a radius-approximate MEB or a
covering-approximate MEB. Our algorithm improves the running time and the
number of passes for the previous sublinear MEB algorithms. Our method relies
on two novel techniques, the Uniform-Adaptive Sampling method and Sandwich
Lemma. Furthermore, we observe that these two techniques can be generalized to
design sublinear time algorithms for a broader range of geometric optimization
problems with outliers in high dimensions, including MEB with outliers,
one-class and two-class linear SVMs with outliers, $k$-center clustering with
outliers, and flat fitting with outliers. Our proposed algorithms also work
fine for kernels.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Hu Ding</a></p><p>In this paper, we study several important geometric optimization problems
arising in machine learning. First, we revisit the Minimum Enclosing Ball (MEB)
problem in Euclidean space $\mathbb{R}^d$. The problem has been extensively
studied before, but real-world machine learning tasks often need to handle
large-scale datasets so that we cannot even afford linear time algorithms.
Motivated by the recent studies on {\em beyond worst-case analysis}, we
introduce the notion of stability for MEB, which is natural and easy to
understand. Roughly speaking, an instance of MEB is stable, if the radius of
the resulting ball cannot be significantly reduced by removing a small fraction
of the input points. Under the stability assumption, we present two sampling
algorithms for computing radius-approximate MEB with sample complexities
independent of the number of input points $n$. In particular, the second
algorithm has the sample complexity even independent of the dimensionality $d$.
We also consider the general case without the stability assumption. We present
a hybrid algorithm that can output either a radius-approximate MEB or a
covering-approximate MEB. Our algorithm improves the running time and the
number of passes for the previous sublinear MEB algorithms. Our method relies
on two novel techniques, the Uniform-Adaptive Sampling method and Sandwich
Lemma. Furthermore, we observe that these two techniques can be generalized to
design sublinear time algorithms for a broader range of geometric optimization
problems with outliers in high dimensions, including MEB with outliers,
one-class and two-class linear SVMs with outliers, $k$-center clustering with
outliers, and flat fitting with outliers. Our proposed algorithms also work
fine for kernels.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02814'>Randomized Greedy Algorithms and Composable Coreset for k-Center Clustering with Outliers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hu Ding, Ruomin Huang, Kai Liu, Haikuo Yu, Zixiu Wang</p><p>In this paper, we study the problem of {\em $k$-center clustering with
outliers}. The problem has many important applications in real world, but the
presence of outliers can significantly increase the computational complexity.
Though a number of methods have been developed in the past decades, it is still
quite challenging to design quality guaranteed algorithm with low complexity
for this problem. Our idea is inspired by the greedy method, Gonzalez's
algorithm, that was developed for solving the ordinary $k$-center clustering
problem. Based on some novel observations, we show that a simple randomized
version of this greedy strategy actually can handle outliers efficiently. We
further show that this randomized greedy approach also yields small coreset for
the problem in doubling metrics (even if the doubling dimension is not given),
which can greatly reduce the computational complexity. Moreover, together with
the partial clustering framework proposed in arXiv:1703.01539 , we prove that
our coreset method can be applied to distributed data with a low communication
complexity. The experimental results suggest that our algorithms can achieve
near optimal solutions and yield lower complexities comparing with the existing
methods.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Hu Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1">Ruomin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kai Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Haikuo Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zixiu Wang</a></p><p>In this paper, we study the problem of {\em $k$-center clustering with
outliers}. The problem has many important applications in real world, but the
presence of outliers can significantly increase the computational complexity.
Though a number of methods have been developed in the past decades, it is still
quite challenging to design quality guaranteed algorithm with low complexity
for this problem. Our idea is inspired by the greedy method, Gonzalez's
algorithm, that was developed for solving the ordinary $k$-center clustering
problem. Based on some novel observations, we show that a simple randomized
version of this greedy strategy actually can handle outliers efficiently. We
further show that this randomized greedy approach also yields small coreset for
the problem in doubling metrics (even if the doubling dimension is not given),
which can greatly reduce the computational complexity. Moreover, together with
the partial clustering framework proposed in <a href="/abs/1703.01539">arXiv:1703.01539</a> , we prove that
our coreset method can be applied to distributed data with a low communication
complexity. The experimental results suggest that our algorithms can achieve
near optimal solutions and yield lower complexities comparing with the existing
methods.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02876'>Assigning Agents to Increase Network-Based Neighborhood Diversity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zirou Qiu, Andrew Yuan, Chen Chen, Madhav V. Marathe, S. S. Ravi, Daniel J. Rosenkrantz, Richard E. Stearns, Anil Vullikanti</p><p>Social segregation is a persistent problem in society. Despite of the
existing strategic plans to advance diversity, we continue to witness spatial
segregation of people by demographic features. Motivated by real-world
applications, such as public-housing allocation for low-income individuals, we
examine the problem of assigning a group of agents to vertices in a graph that
represents spatial locations. Agents are of two types (subgroups) characterized
by certain sensitive features. The goal is to construct an assignment that
maximizes the level of diversity. Specifically, we quantify the diversity by
the number of well-integrated agents, that is, the agents who have at least one
neighbor of a different type in the network. Given the intractable nature of
this maximization problem, we focus on developing approximation algorithms with
provable performance guarantees. We first propose a local-improvement algorithm
for general graphs with a constant factor 1/2 approximation. Further, for a
special case where the sizes of two subgroups are similar, we present a
semidefinite programming approach that yields an approximation factor better
than 1/2. We also show that the problem can be solved efficiently when the
underlying graph is treewidth-bounded, and then use this result to obtain a
polynomial time approximation scheme (PTAS) for the problem on planar graphs.
Lastly, we conduct experiments to evaluate the performance of the proposed
algorithms on realistic networks.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Qiu_Z/0/1/0/all/0/1">Zirou Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_A/0/1/0/all/0/1">Andrew Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Marathe_M/0/1/0/all/0/1">Madhav V. Marathe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_S/0/1/0/all/0/1">S. S. Ravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenkrantz_D/0/1/0/all/0/1">Daniel J. Rosenkrantz</a>, <a href="http://arxiv.org/find/cs/1/au:+Stearns_R/0/1/0/all/0/1">Richard E. Stearns</a>, <a href="http://arxiv.org/find/cs/1/au:+Vullikanti_A/0/1/0/all/0/1">Anil Vullikanti</a></p><p>Social segregation is a persistent problem in society. Despite of the
existing strategic plans to advance diversity, we continue to witness spatial
segregation of people by demographic features. Motivated by real-world
applications, such as public-housing allocation for low-income individuals, we
examine the problem of assigning a group of agents to vertices in a graph that
represents spatial locations. Agents are of two types (subgroups) characterized
by certain sensitive features. The goal is to construct an assignment that
maximizes the level of diversity. Specifically, we quantify the diversity by
the number of well-integrated agents, that is, the agents who have at least one
neighbor of a different type in the network. Given the intractable nature of
this maximization problem, we focus on developing approximation algorithms with
provable performance guarantees. We first propose a local-improvement algorithm
for general graphs with a constant factor 1/2 approximation. Further, for a
special case where the sizes of two subgroups are similar, we present a
semidefinite programming approach that yields an approximation factor better
than 1/2. We also show that the problem can be solved efficiently when the
underlying graph is treewidth-bounded, and then use this result to obtain a
polynomial time approximation scheme (PTAS) for the problem on planar graphs.
Lastly, we conduct experiments to evaluate the performance of the proposed
algorithms on realistic networks.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02878'>Abstract Huffman Coding and PIFO Tree Embeddings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Keri D&#x27;Angelo, Dexter Kozen</p><p>Algorithms for deriving Huffman codes and the recently developed algorithm
for compiling PIFO trees to trees of fixed shape (Mohan et al. 2022) are
similar, but work with different underlying algebraic operations. In this
paper, we exploit the monadic structure of prefix codes to create a generalized
Huffman algorithm that has these two applications as special cases.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+DAngelo_K/0/1/0/all/0/1">Keri D&#x27;Angelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozen_D/0/1/0/all/0/1">Dexter Kozen</a></p><p>Algorithms for deriving Huffman codes and the recently developed algorithm
for compiling PIFO trees to trees of fixed shape (Mohan et al. 2022) are
similar, but work with different underlying algebraic operations. In this
paper, we exploit the monadic structure of prefix codes to create a generalized
Huffman algorithm that has these two applications as special cases.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02944'>Quantum Honest Byzantine Agreement as a Distributed Quantum Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marcus Edwards</p><p>Blockchain technology has three main components: the network, consensus
algorithm and distributed data structure. Each of these brings with it
particular issues of scalability and efficiency. By recasting the network and
consensus algorithm components of blockchain to a quantum algorithm, we show
that the efficiency and scalability of blockchain technology can be improved in
the near-term without requiring powerful quantum computers to be available.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Edwards_M/0/1/0/all/0/1">Marcus Edwards</a></p><p>Blockchain technology has three main components: the network, consensus
algorithm and distributed data structure. Each of these brings with it
particular issues of scalability and efficiency. By recasting the network and
consensus algorithm components of blockchain to a quantum algorithm, we show
that the efficiency and scalability of blockchain technology can be improved in
the near-term without requiring powerful quantum computers to be available.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03074'>SeedTree: A Dynamically Optimal and Local Self-Adjusting Tree</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arash Pourdamghani, Chen Avin, Robert Sama, Stefan Schmid</p><p>We consider the fundamental problem of designing a self-adjusting tree, which
efficiently and locally adapts itself towards the demand it serves (namely
accesses to the items stored by the tree nodes), striking a balance between the
benefits of such adjustments (enabling faster access) and their costs
(reconfigurations). This problem finds applications, among others, in the
context of emerging demand-aware and reconfigurable datacenter networks and
features connections to self-adjusting data structures. Our main contribution
is SeedTree, a dynamically optimal self-adjusting tree which supports local
(i.e., greedy) routing, which is particularly attractive under highly dynamic
demands. SeedTree relies on an innovative approach which defines a set of
unique paths based on randomized item addresses, and uses a small constant
number of items per node. We complement our analytical results by showing the
benefits of SeedTree empirically, evaluating it on various synthetic and
real-world communication traces.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pourdamghani_A/0/1/0/all/0/1">Arash Pourdamghani</a>, <a href="http://arxiv.org/find/cs/1/au:+Avin_C/0/1/0/all/0/1">Chen Avin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sama_R/0/1/0/all/0/1">Robert Sama</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a></p><p>We consider the fundamental problem of designing a self-adjusting tree, which
efficiently and locally adapts itself towards the demand it serves (namely
accesses to the items stored by the tree nodes), striking a balance between the
benefits of such adjustments (enabling faster access) and their costs
(reconfigurations). This problem finds applications, among others, in the
context of emerging demand-aware and reconfigurable datacenter networks and
features connections to self-adjusting data structures. Our main contribution
is SeedTree, a dynamically optimal self-adjusting tree which supports local
(i.e., greedy) routing, which is particularly attractive under highly dynamic
demands. SeedTree relies on an innovative approach which defines a set of
unique paths based on randomized item addresses, and uses a small constant
number of items per node. We complement our analytical results by showing the
benefits of SeedTree empirically, evaluating it on various synthetic and
real-world communication traces.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03084'>Dynamic Binary Search Trees: Improved Lower Bounds for the Greedy-Future Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yaniv Sadeh, Haim Kaplan</p><p>Binary search trees (BSTs) are one of the most basic and widely used data
structures. The best static tree for serving a sequence of queries (searches)
can be computed by dynamic programming. In contrast, when the BSTs are allowed
to be dynamic (i.e. change by rotations between searches), we still do not know
how to compute the optimal algorithm (OPT) for a given sequence. One of the
candidate algorithms whose serving cost is suspected to be optimal up-to a
(multiplicative) constant factor is known by the name Greedy Future (GF). In an
equivalent geometric way of representing queries on BSTs, GF is in fact
equivalent to another algorithm called Geometric Greedy (GG). Most of the
results on GF are obtained using the geometric model and the study of GG.
Despite this intensive recent fruitful research, the best lower bound we have
on the competitive ratio of GF is $\frac{4}{3}$. Furthermore, it has been
conjectured that the additive gap between the cost of GF and OPT is only linear
in the number of queries. In this paper we prove a lower bound of $2$ on the
competitive ratio of GF, and we prove that the additive gap between the cost of
GF and OPT can be $\Omega(m \cdot \log\log n)$ where $n$ is the number of items
in the tree and $m$ is the number of queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sadeh_Y/0/1/0/all/0/1">Yaniv Sadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaplan_H/0/1/0/all/0/1">Haim Kaplan</a></p><p>Binary search trees (BSTs) are one of the most basic and widely used data
structures. The best static tree for serving a sequence of queries (searches)
can be computed by dynamic programming. In contrast, when the BSTs are allowed
to be dynamic (i.e. change by rotations between searches), we still do not know
how to compute the optimal algorithm (OPT) for a given sequence. One of the
candidate algorithms whose serving cost is suspected to be optimal up-to a
(multiplicative) constant factor is known by the name Greedy Future (GF). In an
equivalent geometric way of representing queries on BSTs, GF is in fact
equivalent to another algorithm called Geometric Greedy (GG). Most of the
results on GF are obtained using the geometric model and the study of GG.
Despite this intensive recent fruitful research, the best lower bound we have
on the competitive ratio of GF is $\frac{4}{3}$. Furthermore, it has been
conjectured that the additive gap between the cost of GF and OPT is only linear
in the number of queries. In this paper we prove a lower bound of $2$ on the
competitive ratio of GF, and we prove that the additive gap between the cost of
GF and OPT can be $\Omega(m \cdot \log\log n)$ where $n$ is the number of items
in the tree and $m$ is the number of queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03161'>Structural Equivalence in Subgraph Matching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dominic Yang, Yurun Ge, Thien Nguyen, Jacob Moorman, Denali Molitor, Andrea Bertozzi</p><p>Symmetry plays a major role in subgraph matching both in the description of
the graphs in question and in how it confounds the search process. This work
addresses how to quantify these effects and how to use symmetries to increase
the efficiency of subgraph isomorphism algorithms. We introduce rigorous
definitions of structural equivalence and establish conditions for when it can
be safely used to generate more solutions. We illustrate how to adapt standard
search routines to utilize these symmetries to accelerate search and compactly
describe the solution space. We then adapt a state-of-the-art solver and
perform a comprehensive series of tests to demonstrate these methods' efficacy
on a standard benchmark set. We extend these methods to multiplex graphs and
present results on large multiplex networks drawn from transportation systems,
social media, adversarial attacks, and knowledge graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Dominic Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yurun Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thien Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Moorman_J/0/1/0/all/0/1">Jacob Moorman</a>, <a href="http://arxiv.org/find/cs/1/au:+Molitor_D/0/1/0/all/0/1">Denali Molitor</a>, <a href="http://arxiv.org/find/cs/1/au:+Bertozzi_A/0/1/0/all/0/1">Andrea Bertozzi</a></p><p>Symmetry plays a major role in subgraph matching both in the description of
the graphs in question and in how it confounds the search process. This work
addresses how to quantify these effects and how to use symmetries to increase
the efficiency of subgraph isomorphism algorithms. We introduce rigorous
definitions of structural equivalence and establish conditions for when it can
be safely used to generate more solutions. We illustrate how to adapt standard
search routines to utilize these symmetries to accelerate search and compactly
describe the solution space. We then adapt a state-of-the-art solver and
perform a comprehensive series of tests to demonstrate these methods' efficacy
on a standard benchmark set. We extend these methods to multiplex graphs and
present results on large multiplex networks drawn from transportation systems,
social media, adversarial attacks, and knowledge graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03180'>Subset verification and search algorithms for causal DAGs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Davin Choo, Kirankumar Shiragur</p><p>Learning causal relationships between variables is a fundamental task in
causal inference and directed acyclic graphs (DAGs) are a popular choice to
represent the causal relationships. As one can recover a causal graph only up
to its Markov equivalence class from observations, interventions are often used
for the recovery task. Interventions are costly in general and it is important
to design algorithms that minimize the number of interventions performed.
</p>
<p>In this work, we study the problem of learning the causal relationships of a
subset of edges (target edges) in a graph with as few interventions as
possible. Under the assumptions of faithfulness, causal sufficiency, and ideal
interventions, we study this problem in two settings: when the underlying
ground truth causal graph is known (subset verification) and when it is unknown
(subset search).
</p>
<p>For the subset verification problem, we provide an efficient algorithm to
compute a minimum sized interventional set; we further extend these results to
bounded size non-atomic interventions and node-dependent interventional costs.
For the subset search problem, in the worst case, we show that no algorithm
(even with adaptivity or randomization) can achieve an approximation ratio that
is asymptotically better than the vertex cover of the target edges when
compared with the subset verification number. This result is surprising as
there exists a logarithmic approximation algorithm for the search problem when
we wish to recover the whole causal graph. To obtain our results, we prove
several interesting structural properties of interventional causal graphs that
we believe have applications beyond the subset verification/search problems
studied here.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Choo_D/0/1/0/all/0/1">Davin Choo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shiragur_K/0/1/0/all/0/1">Kirankumar Shiragur</a></p><p>Learning causal relationships between variables is a fundamental task in
causal inference and directed acyclic graphs (DAGs) are a popular choice to
represent the causal relationships. As one can recover a causal graph only up
to its Markov equivalence class from observations, interventions are often used
for the recovery task. Interventions are costly in general and it is important
to design algorithms that minimize the number of interventions performed.
</p>
<p>In this work, we study the problem of learning the causal relationships of a
subset of edges (target edges) in a graph with as few interventions as
possible. Under the assumptions of faithfulness, causal sufficiency, and ideal
interventions, we study this problem in two settings: when the underlying
ground truth causal graph is known (subset verification) and when it is unknown
(subset search).
</p>
<p>For the subset verification problem, we provide an efficient algorithm to
compute a minimum sized interventional set; we further extend these results to
bounded size non-atomic interventions and node-dependent interventional costs.
For the subset search problem, in the worst case, we show that no algorithm
(even with adaptivity or randomization) can achieve an approximation ratio that
is asymptotically better than the vertex cover of the target edges when
compared with the subset verification number. This result is surprising as
there exists a logarithmic approximation algorithm for the search problem when
we wish to recover the whole causal graph. To obtain our results, we prove
several interesting structural properties of interventional causal graphs that
we believe have applications beyond the subset verification/search problems
studied here.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03390'>Space-Query Tradeoffs in Range Subgraph Counting and Listing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shiyuan Deng, Shangqi Lu, Yufei Tao</p><p>This paper initializes the study of {\em range subgraph counting} and {\em
range subgraph listing}, both of which are motivated by the significant demands
in practice to perform graph analytics on subgraphs pertinent to only selected,
as opposed to all, vertices. In the first problem, there is an undirected graph
$G$ where each vertex carries a real-valued attribute. Given an interval $q$
and a pattern $Q$, a query counts the number of occurrences of $Q$ in the
subgraph of $G$ induced by the vertices whose attributes fall in $q$. The
second problem has the same setup except that a query needs to enumerate
(rather than count) those occurrences with a small delay. In both problems, our
goal is to understand the tradeoff between {\em space usage} and {\em query
cost}, or more specifically: (i) given a target on query efficiency, how much
pre-computed information about $G$ must we store? (ii) Or conversely, given a
budget on space usage, what is the best query time we can hope for? We
establish a suite of upper- and lower-bound results on such tradeoffs for
various query patterns.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shiyuan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shangqi Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1">Yufei Tao</a></p><p>This paper initializes the study of {\em range subgraph counting} and {\em
range subgraph listing}, both of which are motivated by the significant demands
in practice to perform graph analytics on subgraphs pertinent to only selected,
as opposed to all, vertices. In the first problem, there is an undirected graph
$G$ where each vertex carries a real-valued attribute. Given an interval $q$
and a pattern $Q$, a query counts the number of occurrences of $Q$ in the
subgraph of $G$ induced by the vertices whose attributes fall in $q$. The
second problem has the same setup except that a query needs to enumerate
(rather than count) those occurrences with a small delay. In both problems, our
goal is to understand the tradeoff between {\em space usage} and {\em query
cost}, or more specifically: (i) given a target on query efficiency, how much
pre-computed information about $G$ must we store? (ii) Or conversely, given a
budget on space usage, what is the best query time we can hope for? We
establish a suite of upper- and lower-bound results on such tradeoffs for
various query patterns.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.03566'>Simple Binary Hypothesis Testing under Local Differential Privacy and Communication Constraints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ankit Pensia, Amir R. Asadi, Varun Jog, Po-Ling Loh</p><p>We study simple binary hypothesis testing under both local differential
privacy (LDP) and communication constraints. We qualify our results as either
minimax optimal or instance optimal: the former hold for the set of
distribution pairs with prescribed Hellinger divergence and total variation
distance, whereas the latter hold for specific distribution pairs. For the
sample complexity of simple hypothesis testing under pure LDP constraints, we
establish instance-optimal bounds for distributions with binary support;
minimax-optimal bounds for general distributions; and (approximately)
instance-optimal, computationally efficient algorithms for general
distributions. When both privacy and communication constraints are present, we
develop instance-optimal, computationally efficient algorithms that achieve the
minimum possible sample complexity (up to universal constants). Our results on
instance-optimal algorithms hinge on identifying the extreme points of the
joint range set $\mathcal A$ of two distributions $p$ and $q$, defined as
$\mathcal A := \{(\mathbf T p, \mathbf T q) | \mathbf T \in \mathcal C\}$,
where $\mathcal C$ is the set of channels characterizing the constraints.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Pensia_A/0/1/0/all/0/1">Ankit Pensia</a>, <a href="http://arxiv.org/find/math/1/au:+Asadi_A/0/1/0/all/0/1">Amir R. Asadi</a>, <a href="http://arxiv.org/find/math/1/au:+Jog_V/0/1/0/all/0/1">Varun Jog</a>, <a href="http://arxiv.org/find/math/1/au:+Loh_P/0/1/0/all/0/1">Po-Ling Loh</a></p><p>We study simple binary hypothesis testing under both local differential
privacy (LDP) and communication constraints. We qualify our results as either
minimax optimal or instance optimal: the former hold for the set of
distribution pairs with prescribed Hellinger divergence and total variation
distance, whereas the latter hold for specific distribution pairs. For the
sample complexity of simple hypothesis testing under pure LDP constraints, we
establish instance-optimal bounds for distributions with binary support;
minimax-optimal bounds for general distributions; and (approximately)
instance-optimal, computationally efficient algorithms for general
distributions. When both privacy and communication constraints are present, we
develop instance-optimal, computationally efficient algorithms that achieve the
minimum possible sample complexity (up to universal constants). Our results on
instance-optimal algorithms hinge on identifying the extreme points of the
joint range set $\mathcal A$ of two distributions $p$ and $q$, defined as
$\mathcal A := \{(\mathbf T p, \mathbf T q) | \mathbf T \in \mathcal C\}$,
where $\mathcal C$ is the set of channels characterizing the constraints.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-10T01:30:00Z">Tuesday, January 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, January 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/01/09/art-as-math-that-meets-crochet/'>Art as Math that Meets Crochet</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Gabriele Meyer is a Senior Lecturer Emerita in the Department of Mathematics, at the University of Wisconsin. She creates beautiful art by crocheting mathematical shapes. In a recent article on a crocheting website, quoting an earlier statement, Gabi explained the connection this way: &#8220;In math, if you want to prove something really beautiful, you have [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
Gabriele Meyer is a Senior Lecturer Emerita in the Department of Mathematics, at the University of Wisconsin. She creates beautiful art by crocheting mathematical shapes. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/01/09/art-as-math-that-meets-crochet/gabiwearingsurface/" rel="attachment wp-att-20882"><img data-attachment-id="20882" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/09/art-as-math-that-meets-crochet/gabiwearingsurface/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/GabiWearingSurface.jpg?fit=408%2C449&amp;ssl=1" data-orig-size="408,449" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1673206169&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="GabiWearingSurface" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/GabiWearingSurface.jpg?fit=273%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/GabiWearingSurface.jpg?fit=408%2C449&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/GabiWearingSurface.jpg?resize=273%2C300&#038;ssl=1" alt="" width="273" height="300" class="aligncenter size-medium wp-image-20882" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/GabiWearingSurface.jpg?resize=273%2C300&amp;ssl=1 273w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/GabiWearingSurface.jpg?w=408&amp;ssl=1 408w" sizes="(max-width: 273px) 100vw, 273px" data-recalc-dims="1" /></a></p>
<p>
In a recent <a href="https://www.crochetconcupiscence.com/hyperbolic-crochet-artist-gabriele-meyer/">article</a> on a crocheting website, quoting an earlier <a href="https://theworld.org/stories/2012-02-03/beauty-truth-math-art">statement</a>, Gabi explained the connection this way:  </p>
<blockquote><p>
&#8220;In math, if you want to prove something really beautiful, you have to understand the structure. And the structure means you understand the beauty of an object and with that knowledge you oftentimes can make a very important and deep proof. That&#8217;s why beauty matters tremendously in mathematics.&#8221;
</p></blockquote>
<p>
Today I want to share some of Gabi&#8217;s work of crocheting shapes that follow hyperbolic geometry.  This includes crocheted algae, flowers, sea anemones, and other organic shapes. </p>
<p>
<p><b> Some of Her Art </b></p>
<p>
<p align=center> <a href="https://rjlipton.wpcomstaging.com/2023/01/09/art-as-math-that-meets-crochet/attachment/4/" rel="attachment wp-att-20824"><img data-attachment-id="20824" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/09/art-as-math-that-meets-crochet/attachment/4/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/4.jpg?fit=397%2C1013&amp;ssl=1" data-orig-size="397,1013" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS REBEL T3i&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1488814602&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;28&quot;,&quot;iso&quot;:&quot;640&quot;,&quot;shutter_speed&quot;:&quot;0.02&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/4.jpg?fit=118%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/4.jpg?fit=397%2C1013&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/4.jpg?resize=300%2C500&#038;ssl=1" alt="" width="300" height="500" class="aligncenter size-full wp-image-20824"</a data-recalc-dims="1"></p>
<p align=center><a href="https://rjlipton.wpcomstaging.com/2023/01/09/art-as-math-that-meets-crochet/attachment/3/" rel="attachment wp-att-20823"><img data-attachment-id="20823" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/09/art-as-math-that-meets-crochet/attachment/3/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/3.jpg?fit=558%2C1494&amp;ssl=1" data-orig-size="558,1494" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 6s&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1550871742&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;320&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/3.jpg?fit=112%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/3.jpg?fit=382%2C1024&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/3.jpg?resize=300%2C500&#038;ssl=1" alt="" width="300" height="500" class="aligncenter size-full wp-image-20823" data-recalc-dims="1" /></a></p>
<p align=center><a href="https://rjlipton.wpcomstaging.com/2023/01/09/art-as-math-that-meets-crochet/attachment/2/" rel="attachment wp-att-20822"><img data-attachment-id="20822" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/09/art-as-math-that-meets-crochet/attachment/2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/2.jpg?fit=1060%2C1588&amp;ssl=1" data-orig-size="1060,1588" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 6s&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1587898278&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;32&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/2.jpg?fit=200%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/2.jpg?fit=600%2C898&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/2.jpg?resize=300%2C500&#038;ssl=1" alt="" width="300" height="500" class="aligncenter size-full wp-image-20822" data-recalc-dims="1" /></a></p>
<p align=center>
<a href="https://rjlipton.wpcomstaging.com/2023/01/09/art-as-math-that-meets-crochet/attachment/1/" rel="attachment wp-att-20821"><img data-attachment-id="20821" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/09/art-as-math-that-meets-crochet/attachment/1/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/1.jpg?fit=692%2C1037&amp;ssl=1" data-orig-size="692,1037" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS REBEL T3i&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1556141637&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;25&quot;,&quot;iso&quot;:&quot;3200&quot;,&quot;shutter_speed&quot;:&quot;0.125&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/1.jpg?fit=200%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/1.jpg?fit=600%2C900&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/1.jpg?resize=300%2C500&#038;ssl=1" alt="" width="300" height="500" class="aligncenter size-full wp-image-20821" data-recalc-dims="1" /></a> </p>
<p>
The crocheting article relates that Gabi is &#8220;happy to give a new spin to a traditional European women&#8217;s craft while also connecting it to mathematics.&#8221; Besides the sea anemones, flower blossoms, and algae, she draws inspiration from abstract forms in topology.  One could say she <a href="https://www.bridgesmathart.org/about/">bridges</a> between what is structurally ideal and what is biologically real, as well as from mathematics to art and culture more generally.</p>
<p>
Gabi’s work was featured in the Bridges 2013 <a href="http://gallery.bridgesmathart.org/exhibitions/2013-bridges-conference/gabriele_meyer">conference</a> on mathematical connections in art, music, architecture, and culture.  This began <a href="http://gallery.bridgesmathart.org/exhibitions/2013-bridges-conference/gabriele_meyer">a</a> <a href="http://gallery.bridgesmathart.org/exhibitions/2014-bridges-conference/gabriele_meyer">streak</a> <a href="http://gallery.bridgesmathart.org/exhibitions/2015-bridges-conference/gabriele_meyer">of</a> <a href="http://gallery.bridgesmathart.org/exhibitions/2016-bridges-conference/gabriele_meyer">nine</a> <a href="http://gallery.bridgesmathart.org/exhibitions/2017-bridges-conference/gabriele_meyer">consecutive</a> <a href="http://gallery.bridgesmathart.org/exhibitions/2018-bridges-conference/gabriele_meyer">appearances</a> <a href="http://gallery.bridgesmathart.org/exhibitions/2019-bridges-conference/gabriele_meyer">at</a> <a href="http://gallery.bridgesmathart.org/exhibitions/2020-bridges-conference/gabriele_meyer">Bridges</a> <a href="http://gallery.bridgesmathart.org/exhibitions/2021-bridges-conference/gabriele_meyer">conferences</a>, and in <a href="http://gallery.bridgesmathart.org/exhibitions/2022-joint-mathematics-meetings/gabriele_meyer">2022</a> at the Joint Mathematics Meetings.  Some more of her hyperbolic art is on her own <a href="http://www.math.wisc.edu/~meyer/airsculpt/hyperbolic2.html">site</a>. </p>
<p>
Her pieces are made by creating hyperbolic crochet around an original shaping line, giving it structure in three dimensions.  One principle noted in her <a href="https://drive.google.com/file/d/189l484eJrwe-9Liof-lxHRle1PJ2Cihp/view">talk slides</a> for Bridges 2019 is that neighborhoods of any point in hyperbolic geometry have more stuff than in flat Euclidean geometry or spherical geometry, forcing a local saddle structure having negative curvature. Crochet enables embodying this locality more robustly than weaving or knitting would.  The effect of increasing the local stitch count is explained in greater detail in a nice 2016 <a href="https://chalkdustmagazine.com/blog/wonders-mathematical-crochet/">article</a> by Anna Lambert.  That crocheting is friendlier than William Thurston&#8217;s paper models for hyperbolic surfaces was <a href="https://www.theiff.org/oexhibits/oe1e.html">discovered</a> in 1997 by Cornell&#8217;s <a href="https://math.cornell.edu/daina-taimina">Daina Taimina</a>, who has also exhibited at <a href="http://gallery.bridgesmathart.org/exhibitions/2022-bridges-conference/daina">Bridges</a> and <a href="https://www.liepajniekiem.lv/zinas/sabiedriba/viesojas-matematike-un-maksliniece-daina-taimina/">elsewhere</a>. </p>
<p><b> Open Problems </b></p>
<p>
My dear wife, Kathryn Farley and I, have had one of her artworks in our house for years.  We knew her first through her husband, Jin-Yi Cai, and Ken has also known both as colleagues in Buffalo.  We have also just purchased some more of her art work for our new condo.  Gabi also has a separate line of <a href="https://people.math.wisc.edu/~gemeyer/prints/prints11.html">linoleum prints</a>.   </p>
<p>
John Conway famously kept myriad models of polyhedra and networks in his office for inspiration.  The polyhedra illustrate positive curvature.  What kind of mathematical creativity is best inspired by surfaces of negative curvature?</p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T19:06:12Z">Monday, January 09 2023, 19:06</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://ptreview.sublinear.info/2023/01/news-for-december-2022/'>News for December 2022</a></h3>
        <p class='tr-article-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Happy New Year! Apologies for the late post; I was stuck for far too long in holiday mode. We haven&#8217;t missed much. There were only two papers in the month of December, since, I&#8217;m assuming, many of us were entering holiday mode. Testing in the bounded-degree graph model with degree bound two by Oded Goldreich [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Happy New Year! Apologies for the late post; I was stuck for far too long in holiday mode. We haven&#8217;t missed much. There were only two papers in the month of December, since, I&#8217;m assuming, many of us were entering holiday mode.</p>



<p><strong>Testing in the bounded-degree graph model with degree bound two</strong> by Oded Goldreich and Laliv Tauber (<a href="https://eccc.weizmann.ac.il/report/2022/184/">ECCC</a>). One of great, central results in graph property testing is that all monotone properties are testable (with query complexity independent on graph size) on dense graphs. The sparse graph universe is far, far, more complicated and interesting. Even for graphs with degree bound 3, natural graph properties can have anywhere from constant to linear (in \(n\)) query complexity. This note shows that when considering graphs with degree bound at most 2, the landscape is quite plain. The paper shows that all properties are testable in \(poly(\varepsilon^{-1})\). Any graph with degree at most 2 is a collection of paths and cycles. In \(poly(\varepsilon^{-1})\) queries, one can approximately learn the graph. (After which the testing problem is trivial.) The paper gives a simple \(O(\varepsilon^{-4})\) query algorithm, which is improved to the nearly optimal \(\widetilde{O}(\varepsilon^{-2})\) bound.</p>



<p><strong>On the power of nonstandard quantum oracles</strong> by Roozbeh Bassirian, Bill Fefferman, and Kunal Marwaha (<a href="https://arxiv.org/pdf/2212.00098.pdf">arXiv</a>). This paper is on the power of oracles in quantum computation. An important question in quantum complexity theory is whether \(QCMA\) is a strict subset of \(QMA\). The former consists of languages decided by Merlin-Arthur quantum protocols with a classical witness (the string that Merlin provides). The latter class allows Merlin to be a quantum witness. This paper shows a property testing problem where such a separation is shown. The property is essentially graph non-expansion (does there exist a set of low conductance?). The input graph should be thought of as an even (bounded) degree with &#8220;exponentially many&#8221; vertices. So it has \(N = 2^n\) vertices. The graph is represented through a special &#8220;graph-coded&#8221; function. The paper shows that there is a \(poly(n)\)-sized quantum witness for non-expansion that can be verified in \(poly(n)\) time, which includes queries to the graph-coded function. On the other hand, there is no classic \(poly(n)\)-sized witness that can be verified in \(poly(n)\) queries to the graph-coded function. (Informally speaking, any \(QCMA\) protocol needs exponentially many queries to the graph.)</p>
<p class="authors">By Seshadhri</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T18:51:55Z">Monday, January 09 2023, 18:51</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/01/09/assistant-or-associate-professor-at-new-york-university-tandon-school-of-engineering-apply-by-march-1-2023/'>Assistant or Associate Professor at New York University, Tandon School of Engineering (apply by March 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          NYU&#8217;s Computer Science and Engineering Dept. is hiring and &#8220;Theory + X&#8221; is a priority area (e.g. Theory + Responsible Computing, Theory + Data Management, Theory + Scientific Computing). This is a late search, so applications are accepted on a rolling basis. Reach out to Chris Musco (cmusco@nyu.edu) with any questions about the search, position, [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>NYU&#8217;s Computer Science and Engineering Dept. is hiring and &#8220;Theory + X&#8221; is a priority area (e.g. Theory + Responsible Computing, Theory + Data Management, Theory + Scientific Computing). This is a late search, so applications are accepted on a rolling basis. Reach out to Chris Musco (cmusco@nyu.edu) with any questions about the search, position, and dept.</p>
<p>Website: <a href="https://apply.interfolio.com/119179">https://apply.interfolio.com/119179</a><br />
Email: cmusco@nyu.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T16:42:47Z">Monday, January 09 2023, 16:42</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2023/01/martin-davis-passed-away-on-jan-1-2023.html'>Martin Davis Passed Away on Jan 1, 2023</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p><br></p><p>As you probably already know from other sources, Martin Davis passed away on Jan 1, 2023, at the age of 94. His wife Virginia died a few hours later.</p><p>He majored in math at Brooklyn College and graduated in 1948.</p><p>He got his PhD under Alonzo Church at the Princeton in 1950.</p><p>Two years for a PhD seems fast!</p><p><br></p><p>His Phd was on Recursion theory.</p><p>In it he conjectured that Hilbert's tenth problem (below) is undecidable.</p><p>He is known for the following (if you know more, please leave a comment).</p><p>1) Hilbert's Tenth Problem.</p><p>Hilbert posed 23 problems in the year 1900 for mathematicians to work on</p><p>over the next 100 years. Hilbert's tenth problem, in modern terminology, was</p><p><br></p><p>Find an algorithm that will, given a polynomial p \in Z[x_1,...,x_n],</p><p>determine it has a Diophantine solution (that is, a_1,...,a_n\in Z</p><p>such that&nbsp; p(a_1,...,a_n)=0).</p><br><p>&nbsp;In Hilbert's article he did say in a preface to all of the problems. Here is the exact quote:</p><p><br></p><p>Occasionally it happens that we seek the solution under insufficient hypotheses or in an incorrect sense, and for this reason do not succeed. The problem then arises: to show the impossibility of the solution under the given hypotheses or in the sense contemplated.</p><p><br></p><p>Hilbert had hoped that this problem would lead to deep results in number theory. And it has to some extend. However this went from being a problem in number theory to a problem in logic. That might not be quite right: the result did use number theory.</p><p><br></p><p>In 1961 Davis-Putnam-Robinson showed that the problem is undecidable IF you also allow exponentials.&nbsp; This may have been a turning point for the conventional wisdom to shift from `Probably Solvable' to `Probably Unsolvable.'</p><p>Martin Davis predicted that the H10 would be shown undecidable by a young Russian by the end of the decade. He was correct. Yuri Matiyasevich did indeed prove H10 undecidable in 1970. By all account Davis was delighted. When the result is cited usually all four people are credited which is as it should be.&nbsp; He wrote an excellent exposition of the complete proof from soup to nuts in:&nbsp;</p><p>Hilbert's tenth problem is unsolvable, American Math Monthly, Volume 80, No 4, 233-269.</p><p>When I first heard of this result I assumed that the number of variables and the degree to get undecidability was huge. I was wrong.&nbsp; I wrote a survey of H10 emphasizing what happens if you bound the degree and the number of variables, see&nbsp;here</p><p>2) SAT Solvers. Davis-Putnam-Logemann-Loveland outlined a SAT Solver, or really a class os SAT Solvers. While I doubt it was the first SAT Solver, it was an early one that tried to cut down on the time needed.</p><p>3) He wrote the following books:</p><p>Computability and Unsolvability (1958, reprinted 1982)</p><p>Applied Non-Standard Analysis (1977, reprinted 2014)</p><p>Computability, Complexity, and Languages: Fundamentals of Theoretical Computer Science (1994 (with Elaine Weyuker)</p><p>The Universal Computer: The Road from Leibniz to Turing (2000, reprinted as</p><p>Engines of Logic: Mathematicians and the origin of the computer)</p><p>The Undecidable: Basic Paper on undecidable propositions, unsolvable problems and computable functions (2004)</p><p>4) He was a recursion theorist who could actually program a Turing Machine to really do things. There are still some people who do that- getting the UTM down to a small number of states, and the work (the Wolfram Challenge), and the Busy Beaver Function (see Scott Aaronson's open problems column&nbsp;here,</p><p>but I think this is done less by academic recursion theorists than it used to be. I do not have my students in Automata Theory write any TM code. Clyde Kruskal, who had that same course from Martin Davis, thinks that I should.&nbsp;</p><p>4) For more on Martin Davis see this obit&nbsp;here&nbsp;and/or his Wikipedia page&nbsp;here</p><p><br></p><br><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><br /></p><p>As you probably already know from other sources, Martin Davis passed away on Jan 1, 2023, at the age of 94. His wife Virginia died a few hours later.</p><p>He majored in math at Brooklyn College and graduated in 1948.</p><p>He got his PhD under Alonzo Church at the Princeton in 1950.</p><p>Two years for a PhD seems fast!</p><p><br /></p><p>His Phd was on Recursion theory.</p><p>In it he conjectured that Hilbert's tenth problem (below) is undecidable.</p><p>He is known for the following (if you know more, please leave a comment).</p><p>1) Hilbert's Tenth Problem.</p><p>Hilbert posed 23 problems in the year 1900 for mathematicians to work on</p><p>over the next 100 years. Hilbert's tenth problem, in modern terminology, was</p><p><br /></p><p>Find an algorithm that will, given a polynomial p \in Z[x_1,...,x_n],</p><p>determine it has a Diophantine solution (that is, a_1,...,a_n\in Z</p><p>such that&nbsp; p(a_1,...,a_n)=0).</p><div><br /></div><p>&nbsp;In Hilbert's article he did say in a preface to all of the problems. Here is the exact quote:</p><p><br /></p><p><i>Occasionally it happens that we seek the solution under insufficient hypotheses or in an incorrect sense, and for this reason do not succeed. The problem then arises: to show the impossibility of the solution under the given hypotheses or in the sense contemplated.</i></p><p><br /></p><p>Hilbert had hoped that this problem would lead to deep results in number theory. And it has to some extend. However this went from being a problem in number theory to a problem in logic. That might not be quite right: the result did use number theory.</p><p><br /></p><p>In 1961 Davis-Putnam-Robinson showed that the problem is undecidable IF you also allow exponentials.&nbsp; This may have been a turning point for the conventional wisdom to shift from `Probably Solvable' to `Probably Unsolvable.'</p><p>Martin Davis predicted that the H10 would be shown undecidable by a young Russian by the end of the decade. He was correct. Yuri Matiyasevich did indeed prove H10 undecidable in 1970. By all account Davis was delighted. When the result is cited usually all four people are credited which is as it should be.&nbsp; He wrote an excellent exposition of the complete proof from soup to nuts in:&nbsp;</p><p><i>Hilbert's tenth problem is unsolvable, American Math Monthly, Volume 80, No 4, 233-269.</i></p><p>When I first heard of this result I assumed that the number of variables and the degree to get undecidability was huge. I was wrong.&nbsp; I wrote a survey of H10 emphasizing what happens if you bound the degree and the number of variables, see&nbsp;<a href="https://arxiv.org/abs/2104.07220">here</a></p><p>2) SAT Solvers. Davis-Putnam-Logemann-Loveland outlined a SAT Solver, or really a class os SAT Solvers. While I doubt it was the first SAT Solver, it was an early one that tried to cut down on the time needed.</p><p>3) He wrote the following books:</p><p>Computability and Unsolvability (1958, reprinted 1982)</p><p>Applied Non-Standard Analysis (1977, reprinted 2014)</p><p>Computability, Complexity, and Languages: Fundamentals of Theoretical Computer Science (1994 (with Elaine Weyuker)</p><p>The Universal Computer: The Road from Leibniz to Turing (2000, reprinted as</p><p>Engines of Logic: Mathematicians and the origin of the computer)</p><p>The Undecidable: Basic Paper on undecidable propositions, unsolvable problems and computable functions (2004)</p><p>4) He was a recursion theorist who could actually program a Turing Machine to really do things. There are still some people who do that- getting the UTM down to a small number of states, and the work (the Wolfram Challenge), and the Busy Beaver Function (see Scott Aaronson's open problems column&nbsp;<a href="https://www.cs.umd.edu/~gasarch/open/busybeaver.pdf">here</a>,</p><p>but I think this is done less by academic recursion theorists than it used to be. I do not have my students in Automata Theory write any TM code. Clyde Kruskal, who had that same course from Martin Davis, thinks that I should.&nbsp;</p><p>4) For more on Martin Davis see this obit&nbsp;<a href="https://logicprogramming.org/2023/01/in-memoriam-martin-davis/?fbclid=IwAR3v_3E7eRIszv-A3ZFqXQdr7PX36SrwnDFMo5uk0liqEBhEUgxYNZ8g2zM">here</a>&nbsp;and/or his Wikipedia page&nbsp;<a href="https://en.wikipedia.org/wiki/Martin_Davis_(mathematician)">here</a></p><p><br /></p><div><br /></div><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T16:11:00Z">Monday, January 09 2023, 16:11</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/01/09/phd-position-at-university-of-edinburgh-apply-by-january-27-2023/'>PhD position at University of Edinburgh (apply by January 27, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Applications are invited for a PhD position in Algorithms and Incentives for Blockchains and Digital Coins at the University of Edinburgh, to be supervised by Aris Filos-Ratsikas and co-supervised by Aggelos Kiayias on fundamental topics related to algorithms and incentive mechanisms for blockchain-related applications. Website: www.ed.ac.uk/informatics/postgraduate/fees/research-scholarships/research-grant-funding/phd-studentship-in-incentives-for-blockchain-coins Email: Aris.Filos-Ratsikas@ed.ac.uk
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Applications are invited for a PhD position in Algorithms and Incentives for Blockchains and Digital Coins at the University of Edinburgh, to be supervised by Aris Filos-Ratsikas and co-supervised by Aggelos Kiayias on fundamental topics related to algorithms and incentive mechanisms for blockchain-related applications.</p>
<p>Website: <a href="https://www.ed.ac.uk/informatics/postgraduate/fees/research-scholarships/research-grant-funding/phd-studentship-in-incentives-for-blockchain-coins">https://www.ed.ac.uk/informatics/postgraduate/fees/research-scholarships/research-grant-funding/phd-studentship-in-incentives-for-blockchain-coins</a><br />
Email: Aris.Filos-Ratsikas@ed.ac.uk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T14:35:48Z">Monday, January 09 2023, 14:35</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02462'>Measuring a Priori Voting Power -- Taking Delegations Seriously</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rachael Colley, Th&#xe9;o Delemazure, Hugo Gilbert</p><p>In this paper, we introduce new power indices to measure the criticality of
voters involved in different elections where delegations play a key role,
namely, two variants of the proxy voting setting and a liquid democracy
setting. First, we argue that our power indices are natural extensions of the
Penrose-Banzhaf index in classic simple voting games, illustrating their
intuitions. We show that recursive formulas can compute these indices for
weighted voting games in pseudo-polynomial time. Last, we highlight theoretical
properties and provide numerical results to illustrate how introducing
delegation options modifies the voting power of voters.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Colley_R/0/1/0/all/0/1">Rachael Colley</a>, <a href="http://arxiv.org/find/cs/1/au:+Delemazure_T/0/1/0/all/0/1">Th&#xe9;o Delemazure</a>, <a href="http://arxiv.org/find/cs/1/au:+Gilbert_H/0/1/0/all/0/1">Hugo Gilbert</a></p><p>In this paper, we introduce new power indices to measure the criticality of
voters involved in different elections where delegations play a key role,
namely, two variants of the proxy voting setting and a liquid democracy
setting. First, we argue that our power indices are natural extensions of the
Penrose-Banzhaf index in classic simple voting games, illustrating their
intuitions. We show that recursive formulas can compute these indices for
weighted voting games in pseudo-polynomial time. Last, we highlight theoretical
properties and provide numerical results to illustrate how introducing
delegation options modifies the voting power of voters.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T01:30:00Z">Monday, January 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02616'>On the Width of the Regular $n$-Simplex</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sariel Har-Peled, Eliot W. Robson</p><p>Consider the regular $n$-simplex $\Delta_n$ - it is formed by the convex-hull
of $n+1$ points in Euclidean space, with each pair of points being in distance
exactly one from each other. We prove an exact bound on the width of $\Delta_n$
which is $\approx \sqrt{2/n}$. Specifically, $ \mathrm{width}(\Delta_n) =
\sqrt{\frac{2}{n + 1}}$ if $n$ is odd, and $ \mathrm{width}(\Delta_n) =
\sqrt{\frac{2(n+1)}{n(n+2)}} $ if $n$ is even. While this bound is well known
[GK92, Ale77], we provide a self-contained elementary proof that might (or
might not) be of interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Har_Peled_S/0/1/0/all/0/1">Sariel Har-Peled</a>, <a href="http://arxiv.org/find/cs/1/au:+Robson_E/0/1/0/all/0/1">Eliot W. Robson</a></p><p>Consider the regular $n$-simplex $\Delta_n$ - it is formed by the convex-hull
of $n+1$ points in Euclidean space, with each pair of points being in distance
exactly one from each other. We prove an exact bound on the width of $\Delta_n$
which is $\approx \sqrt{2/n}$. Specifically, $ \mathrm{width}(\Delta_n) =
\sqrt{\frac{2}{n + 1}}$ if $n$ is odd, and $ \mathrm{width}(\Delta_n) =
\sqrt{\frac{2(n+1)}{n(n+2)}} $ if $n$ is even. While this bound is well known
[GK92, Ale77], we provide a self-contained elementary proof that might (or
might not) be of interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T01:30:00Z">Monday, January 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02569'>Finding and Counting Patterns in Sparse Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Balagopal Komarath, Anant Kumar, Suchismita Mishra, Aditi Sethia</p><p>We consider algorithms for finding and counting small, fixed graphs in sparse
host graphs. In the non-sparse setting, the parameters treedepth and treewidth
play a crucial role in fast, constant-space and polynomial-space algorithms
respectively. We discover two new parameters that we call matched treedepth and
matched treewidth. We show that finding and counting patterns with low matched
treedepth and low matched treewidth can be done asymptotically faster than the
existing algorithms when the host graphs are sparse for many patterns. As an
application to finding and counting fixed-size patterns, we discover
$\otilde(m^3)$-time \footnote{$\otilde$ hides factors that are logarithmic in
the input size.}, constant-space algorithms for cycles of length at most $11$
and $\otilde(m^2)$-time, polynomial-space algorithms for paths of length at
most $10$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Komarath_B/0/1/0/all/0/1">Balagopal Komarath</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Anant Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Suchismita Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethia_A/0/1/0/all/0/1">Aditi Sethia</a></p><p>We consider algorithms for finding and counting small, fixed graphs in sparse
host graphs. In the non-sparse setting, the parameters treedepth and treewidth
play a crucial role in fast, constant-space and polynomial-space algorithms
respectively. We discover two new parameters that we call matched treedepth and
matched treewidth. We show that finding and counting patterns with low matched
treedepth and low matched treewidth can be done asymptotically faster than the
existing algorithms when the host graphs are sparse for many patterns. As an
application to finding and counting fixed-size patterns, we discover
$\otilde(m^3)$-time \footnote{$\otilde$ hides factors that are logarithmic in
the input size.}, constant-space algorithms for cycles of length at most $11$
and $\otilde(m^2)$-time, polynomial-space algorithms for paths of length at
most $10$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T01:30:00Z">Monday, January 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02457'>Better Differentially Private Approximate Histograms and Heavy Hitters using the Misra-Gries Sketch</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Christian Janos Lebeda, Jakub T&#x11b;tek</p><p>We consider the problem of computing differentially private approximate
histograms and heavy hitters in a stream of elements. In the non-private
setting, this is often done using the sketch of Misra and Gries [Science of
Computer Programming, 1982]. Chan, Li, Shi, and Xu [PETS 2012] describe a
differentially private version of the Misra-Gries sketch, but the amount of
noise it adds can be large and scales linearly with the size of the sketch: the
more accurate the sketch is, the more noise this approach has to add. We
present a better mechanism for releasing Misra-Gries sketch under
$(\varepsilon,\delta)$-differential privacy. It adds noise with magnitude
independent of the size of the sketch size, in fact, the maximum error coming
from the noise is the same as the best known in the private non-streaming
setting, up to a constant factor. Our mechanism is simple and likely to be
practical. We also give a simple post-processing step of the Misra-Gries sketch
that does not increase the worst-case error guarantee. It is sufficient to add
noise to this new sketch with less than twice the magnitude of the
non-streaming setting. This improves on the previous result for
$\varepsilon$-differential privacy where the noise scales linearly to the size
of the sketch.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lebeda_C/0/1/0/all/0/1">Christian Janos Lebeda</a>, <a href="http://arxiv.org/find/cs/1/au:+Tetek_J/0/1/0/all/0/1">Jakub T&#x11b;tek</a></p><p>We consider the problem of computing differentially private approximate
histograms and heavy hitters in a stream of elements. In the non-private
setting, this is often done using the sketch of Misra and Gries [Science of
Computer Programming, 1982]. Chan, Li, Shi, and Xu [PETS 2012] describe a
differentially private version of the Misra-Gries sketch, but the amount of
noise it adds can be large and scales linearly with the size of the sketch: the
more accurate the sketch is, the more noise this approach has to add. We
present a better mechanism for releasing Misra-Gries sketch under
$(\varepsilon,\delta)$-differential privacy. It adds noise with magnitude
independent of the size of the sketch size, in fact, the maximum error coming
from the noise is the same as the best known in the private non-streaming
setting, up to a constant factor. Our mechanism is simple and likely to be
practical. We also give a simple post-processing step of the Misra-Gries sketch
that does not increase the worst-case error guarantee. It is sufficient to add
noise to this new sketch with less than twice the magnitude of the
non-streaming setting. This improves on the previous result for
$\varepsilon$-differential privacy where the noise scales linearly to the size
of the sketch.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T01:30:00Z">Monday, January 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02507'>Perturbation results for distance-edge-monitoring numbers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chenxu Yang, Ralf Klasing, Changxiang He, Yaping Mao</p><p>Foucaud et al. recently introduced and initiated the study of a new
graph-theoretic concept in the area of network monitoring. Let $G=(V, E)$ be a
graph. A set of vertices $M \subseteq V(G)$ is a distance-edge-monitoring set
of $G$ if any edges in $G$ can be monitored by a vertex in $M$. The
distance-edge-monitoring number $\operatorname{dem}(G)$ is the minimum
cardinality of a distance-edge-monitoring set of $G$. In this paper, we first
show that $\operatorname{dem}(G\setminus e)- \operatorname{dem}(G)\leq 2$ for
any graph $G$ and edge $e \in E(G)$. Moreover, the bound is sharp. Next, we
construct two graphs $G$ and $H$ to show that
$\operatorname{dem}(G)-\operatorname{dem}(G-u)$ and
$\operatorname{dem}(H-v)-\operatorname{dem}(H)$ can be arbitrarily large, where
$u \in V(G)$ and $v \in V(H)$. We also study the relationship between
$\operatorname{dem}(H)$ and $\operatorname{dem}(G)$ for $H\subset G$. In the
end, we give an algorithm to judge whether the distance-edge-monitoring set
still remain in the resulting graph when any edge of a graph $G$ is deleted.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chenxu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Klasing_R/0/1/0/all/0/1">Ralf Klasing</a>, <a href="http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1">Changxiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yaping Mao</a></p><p>Foucaud et al. recently introduced and initiated the study of a new
graph-theoretic concept in the area of network monitoring. Let $G=(V, E)$ be a
graph. A set of vertices $M \subseteq V(G)$ is a distance-edge-monitoring set
of $G$ if any edges in $G$ can be monitored by a vertex in $M$. The
distance-edge-monitoring number $\operatorname{dem}(G)$ is the minimum
cardinality of a distance-edge-monitoring set of $G$. In this paper, we first
show that $\operatorname{dem}(G\setminus e)- \operatorname{dem}(G)\leq 2$ for
any graph $G$ and edge $e \in E(G)$. Moreover, the bound is sharp. Next, we
construct two graphs $G$ and $H$ to show that
$\operatorname{dem}(G)-\operatorname{dem}(G-u)$ and
$\operatorname{dem}(H-v)-\operatorname{dem}(H)$ can be arbitrarily large, where
$u \in V(G)$ and $v \in V(H)$. We also study the relationship between
$\operatorname{dem}(H)$ and $\operatorname{dem}(G)$ for $H\subset G$. In the
end, we give an algorithm to judge whether the distance-edge-monitoring set
still remain in the resulting graph when any edge of a graph $G$ is deleted.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-09T01:30:00Z">Monday, January 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, January 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/01/08/teaching-faculty-at-university-of-michigan-apply-by-january-22-2023/'>Teaching faculty at University of Michigan (apply by January 22, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Michigan CSE is hiring for multiple long-term, career-oriented teaching faculty positions. We are seeking passionate individuals to join our community of teaching-focused faculty, and who will support our teaching mission and further our goal of creating a diverse, inclusive, and representative Computer Science community within our department and in the field at large. Website: cse.umich.edu/cse/jobs/ [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Michigan CSE is hiring for multiple long-term, career-oriented teaching faculty positions. We are seeking passionate individuals to join our community of teaching-focused faculty, and who will support our teaching mission and further our goal of creating a diverse, inclusive, and representative Computer Science community within our department and in the field at large.</p>
<p>Website: <a href="https://cse.umich.edu/cse/jobs/">https://cse.umich.edu/cse/jobs/</a><br />
Email: awdeorio@umich.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-08T17:17:00Z">Sunday, January 08 2023, 17:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://decentralizedthoughts.github.io/2023-01-08-re-rand-cred/'>Pairing-based Anonymous Credentials and the Power of Re-randomization</a></h3>
        <p class='tr-article-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          David Chaum wrote in 1985: Large-scale automated transaction systems are imminent. The architecture chosen for these systems may have a long-term impact on the centralization of our economic system, on some of our basic liberties, and even on our democracy. The initial choice of direction will gather economic and societal...
        
        </div>

        <div class='tr-article-summary'>
        
          
          David Chaum wrote in 1985: Large-scale automated transaction systems are imminent. The architecture chosen for these systems may have a long-term impact on the centralization of our economic system, on some of our basic liberties, and even on our democracy. The initial choice of direction will gather economic and societal...
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-08T09:00:00Z">Sunday, January 08 2023, 09:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/002'>TR23-002 |  Diagonalization Games | 

	Noga Alon, 

	Olivier Bousquet, 

	Kasper Green Larsen, 

	Shay Moran, 

	Shlomo Moran</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study several variants of a combinatorial game which is based on Cantor&#39;s diagonal argument. The game is between two players called Kronecker and Cantor. The names of the players are motivated by the known fact  that Leopold Kronecker did not appreciate Georg Cantor&#39;s arguments about the infinite, and even referred to him as a ``scientific charlatan&#39;&#39;. 

In the game Kronecker maintains a list of m binary vectors, 
each of length n, and Cantor&#39;s goal is to produce a new binary vector which is different from each of Kronecker&#39;s vectors, or prove that no such vector exists. Cantor does not see Kronecker&#39;s vectors but he is allowed to ask queries of the form  ``What is bit number j of vector number i? What is the minimal number of queries with which Cantor can achieve his goal? How much better can Cantor do if he is allowed to pick his queries \emph{adaptively}, based on Kronecker&#39;s previous replies?

The case when m=n is solved by diagonalization using n (non-adaptive) queries. We study this game more generally, and prove an optimal bound in the adaptive case and nearly tight upper and lower bounds in the non-adaptive case.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study several variants of a combinatorial game which is based on Cantor&#39;s diagonal argument. The game is between two players called Kronecker and Cantor. The names of the players are motivated by the known fact  that Leopold Kronecker did not appreciate Georg Cantor&#39;s arguments about the infinite, and even referred to him as a ``scientific charlatan&#39;&#39;. 

In the game Kronecker maintains a list of m binary vectors, 
each of length n, and Cantor&#39;s goal is to produce a new binary vector which is different from each of Kronecker&#39;s vectors, or prove that no such vector exists. Cantor does not see Kronecker&#39;s vectors but he is allowed to ask queries of the form  ``What is bit number j of vector number i? What is the minimal number of queries with which Cantor can achieve his goal? How much better can Cantor do if he is allowed to pick his queries \emph{adaptively}, based on Kronecker&#39;s previous replies?

The case when m=n is solved by diagonalization using n (non-adaptive) queries. We study this game more generally, and prove an optimal bound in the adaptive case and nearly tight upper and lower bounds in the non-adaptive case.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-08T02:36:41Z">Sunday, January 08 2023, 02:36</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://minorfree.github.io/tree-shortcutting/'>Shortcutting Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://minorfree.github.io'>Hung Le</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Over the past two years or so, I have been thinking about a cute problem, which turned out to be much more useful to my research than I initially thought. Here it is: Tree Shortcutting Problem: Given an edge-weighted tree \(T\), add (weighted) edges to \(T\), called shortcuts, to get a graph \(K\) such that: \(d_K(u,v) = d_T(u,v)~\quad \forall u,v\in V(T)\). That is, \(K\) preserves distances in \(T\). For every \(u,v\in V(T)\), there exists a shortest path from \(u\) to \(v\) in \(K\) containing at most \(k\) edges for some \(k\geq 2\). The goal is to minimize the product \(k \cdot \mathrm{tw}(K)\), where \(\mathrm{tw}(K)\) is the treewidth of \(K\).
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Over the past two years or so, I have been thinking about a cute problem, which turned out to be much more useful to my research than I initially thought. Here it is:</p>

<hr />
<p><strong>Tree Shortcutting Problem</strong>: Given an edge-weighted tree \(T\), add (weighted) edges to \(T\), called <em>shortcuts</em>, to get a graph \(K\) such that:</p>
<ol>
  <li>\(d_K(u,v) = d_T(u,v)~\quad \forall u,v\in V(T)\). That is, \(K\) preserves distances in \(T\).</li>
  <li>For every \(u,v\in V(T)\), there exists a shortest path from \(u\) to \(v\) in \(K\) containing at most \(k\) edges for some \(k\geq 2\).</li>
</ol>

<p>The goal is to minimize the product \(k \cdot \mathrm{tw}(K)\), where \(\mathrm{tw}(K)\) is the treewidth of \(K\).</p>

<hr />

<p><img src="/assets/figs/shortcut.svg" alt="" /></p>

<p><em>Figure 1: An emulator \(K\) obtained by adding one edge to the tree \(T\) has hop bound \(3\) and treewidth \(2\). Compared to \(T\), the hop bound decreases by 1 while the treewidth increases by 1.</em></p>

<p>Such a graph \(K\) is called a <em>low-hop and low-treewidth emulator</em> of the tree \(T\).  The parameter \(k\) is called the <em>hop bound</em> of \(K\). It is expected that there will be some trade-off between the hop bound and the treewidth. We are interested in minimizing \(k \cdot \mathrm{tw}(K)\). This product directly affects parameters in our application; see the conclusion section for more details.</p>

<p>For readers who are not familar with treeewidth, see  <a href="https://en.wikipedia.org/wiki/Treewidth">here</a> and <a href="https://www.win.tue.nl/~nikhil/courses/2015/2WO08/treewidth-erickson.pdf">here</a> for an excellent introduction, and why treewidth is an interesting graph parameter.</p>

<blockquote>
  <p><strong>Remark 1:</strong> The tree shortcutting problem is already non-trivial for unweighted trees; the shortcuts must be weighted though. Furthermore, for each edge \((u,v)\) added to \(K\), the weight of the edge will be \(d_T(u,v)\). Thus, in the construction below, we do not explicitly assign weights to the added edges.</p>
</blockquote>

<p>A version of a tree shortcutting problem where one seeks to minimize <em>the number of edges of \(K\)</em>, given a hop bound \(k\), was studied extensively (see <a href="http://www.math.tau.ac.il/~haimk/adv-ds-2008/Alon-Schieber.ps">1</a>,<a href="https://dl.acm.org/doi/abs/10.5555/640186.640193">2</a>,<a href="https://arxiv.org/abs/1005.4155">3</a>,<a href="https://dl.acm.org/doi/10.1145/800070.802185">4</a>, including my own work <a href="https://arxiv.org/abs/2107.14221">with</a> <a href="https://arxiv.org/abs/2112.09124">others</a>), arising in the context of spanners and minimum spanning tree problem. What is interesting there IMO is that we see all kinds of crazy slowly growing functions in computer science: for \(k = 2\), the number of edges of \(K\) is \(\Theta(n \log n)\);  for \(k = 3\), the number of edges of \(K\) is \(\Theta(n \log\log n)\); for \(k = 4\), the number of edges is \(\Theta(n \log^* n)\); \(\ldots\) [too difficult to describe]; and for \(k = \alpha(n)\), the number of edges is   \(\Theta(n)\). Here, as you might guess, \(\alpha(\cdot)\) is the notorious (one parameter) inverse Ackermann function. (The \(\Theta\) notation in the number of edges means there exist matching lower bounds.) I hope to cover this problem in a future blog post.</p>

<p>Now back to our tree shortcutting problem. Let \(n = \lvert V(T) \rvert\). There are two extreme regimes that I am aware of:</p>

<ol>
  <li>Hop bound \(k=2\) and treewidth \(\mathrm{tw}(K) = O(\log n)\). This is a relatively simple exercise.</li>
  <li>Hop bound \(k=O(\log n)\) and treewidth \(\mathrm{tw}(K) = O(1)\). This regime is harder to prove; trying to show this for a path graph will be an insightful exercise. It follows from a well-known fact [1] that any tree decomposition of width \(t\) can be turned into a tree decomposition of width \(O(t)\) and depth \(O(\log n)\).</li>
</ol>

<p>The two regimes might suggest that a lower bound \(k\cdot \mathrm{tw}(K) = \Omega(\log n)\) for any \(k\). In our recent paper [2], we show that this is not the case:</p>

<hr />
<p><strong>Theorem 1</strong>: There exists an emulator \(K\) for any \(n\)-vertex tree \(T\) such that \(h(K) = O(\log  \log n)\) and \(\mathrm{tw}(K) = O(\log \log n)\).</p>

<hr />

<p>Theorem 1 implies that one can get an emulator with \(k\cdot \mathrm{tw}(K) = O((\log \log n)^2)\), which is exponentially smaller than \(O(\log(n))\). The goal of this post is to discuss the proof of Theorem 1. See the conclusion section for a more thorough discussion on other aspects of Theorem 1, in particular, the construction time and application.</p>

<p>For the tree shortcutting problem, it is often insightful to look into the <strong>path graph with \(n\) vertices</strong>, which is a special case. Once we solve the path graph, extending the ideas to trees is not that difficult.</p>

<h1 id="1-the-path-graph">1. The Path Graph</h1>

<p>The (unweighted )path graph \(P_n\) is a path of \(n\) vertices. To simplify the presentation, assume that \(\sqrt{n}\) is an integer. The construction is recursive and described in the pseudo-code below.  First we divide \(P_n\) into \(\sqrt{n}\) sub paths of size \(\sqrt{n}\) each. Denote the endpoints of these subpaths by \(b_i = i\sqrt{n}\) for \(1\leq i\leq\sqrt{n}\). We call \({b_i}_{i}\) boundary vertices.  We have two types of recursions: (1) top level recursion – lines 2 and 3 – and (2) subpath recursion – lines 5 to 9. The intuition of the top level recursion is a bit tricky and we will get to that later. See Figure 2.</p>

<p><img src="/assets/figs/recursion.svg" alt="" /></p>

<p><em>Figure 2: (a) The recursive construction applied to the path \(P_n\). (b) Gluing \(\mathcal T_B\) and all \(\{\mathcal T_i\}\) to obtain a tree decomposition \(\mathcal{T}\) of \(K\) via red edges.</em></p>

<p>The subpath recursion is natural: recursively shortcut each subpath \(P[b_i,b_{i+1}]\) (line 6). The subpath recursion returns the shortcut graph \(K_i\) and its tree decomposition \(\mathcal T_i\).  Next, we add edges from each boundary vertex \(b_i, b_{i+1}\) of the subpath to all other vertices on the subpath (lines 7 and 8). This step guarantees that each vertex of the subpath can “jump” to the boundary vertices using only <strong>one edge</strong>. In terms of tree decomposition, it means that we add both \(b_i\) and \(b_{i+1}\) to every bag of \(\mathcal T_i\) (line 9).</p>

<p>The top level recursion serves two purposes: (i) creating a low hop emulator  for boundary vertices (recall that each vertex can jump to a boundary vertex in the same subpath using one edge) and  (ii) gluing \({\mathcal T_i}\) together. More precisely, let \(P_{\sqrt{n}}\) be a path of boundary vertices, i.e., \(b_i\) is adjacent to \(b_{i+1}\) in  \(P_{\sqrt{n}}\). We shortcut \(P_{\sqrt{n}}\) recursively, getting the shortcut graph \(K_B\) and its tree decomposition \(\mathcal T_B\) (line 3). Since \((b_i,b_{i+1})\) is an edge in \(P_{\sqrt{n}}\), there must be a bag in \(\mathcal T_B\) containing both \(b_i,b_{i+1}\); that is, the bag \(X\) in line 11 exists. See Figure 2(b). Recall that in line 9, every bag in \(\mathcal T_i\) contains both \(b_i,b_{i+1}\), and that \(K_B\) and \(K_i\) only share two boundary vertices \(b_i,b_{i+1}\). Thus, we can connect \(X\) to an arbitrary bag of \(\mathcal T_i\) as done in line 12. This completes the shortcutting algorithm.</p>

<hr />
<p><span style="font-variant: small-caps">PathShortcutting</span>\((P_n)\)</p>
<blockquote>
  <p>\(1.\) \(B \leftarrow {0,\sqrt{n}, 2\sqrt{n}, \ldots, n}\) and \(b_i \leftarrow i\sqrt{n}\) for every \(0\leq i \leq \sqrt{n}\)<br />
\(2.\) \(P_{\sqrt{n}} \leftarrow\) unweighted path graph with vertex set \(B\).<br />
\(3.\) \((K_B,\mathcal T_B) \leftarrow\)<span style="font-variant: small-caps">PathShortcutting</span>\((P_{\sqrt{n}})\)<br />
\(4.\) \(K\leftarrow K_B,\quad \mathcal{T}\leftarrow \mathcal T_B\)<br />
\(5.\) for \(i\leftarrow 0\) to \(\sqrt{n}-1\)<br />
\(6.\)     \((K_i,\mathcal T_i) \leftarrow\)<span style="font-variant: small-caps">PathShortcutting</span>\((P_{n}[b_i, b_{i+1}])\)<br />
\(7.\)      for each \(v\in P_{n}[b_i, b_{i+1}]\)<br />
\(8.\)           \(E(K_i)\leftarrow {(v,b_i), (v,b_{i+1})}\) <br />
\(9.\)            add both \({v_i,v_{i+1}}\) to every bag of \(\mathcal T_i\)<br />
\(10.\)     \(K\leftarrow K \cup K_i\) <br />
\(11.\)     Let \(X\) be a bag in \(\mathcal{T}\) containing both \(b_i,b_{i+1}\)<br />
\(12.\)     Add \(\mathcal T_i\) to \(\mathcal{T}\) by connecting \(X\) to an arbitrary bag of \(\mathcal T_i\) <br />
\(13.\) return \((K,\mathcal{T})\)</p>
</blockquote>

<hr />

<p>It is not difficult to show that \(\mathcal{T}\) indeed is a tree decomposition of \(K\). Thus, we focus on analyzing the hop bound and the treewidth.</p>

<blockquote>
  <p><strong>Remark 2:</strong> For notational convenience, we include \(0\) in the set \(B\) though \(0\not\in P_n\). When calling the recursion, one could simply drop 0.</p>
</blockquote>

<p><img src="/assets/figs/hopbound.svg" alt="" /></p>

<p><em>Figure 3: A low-hop path from \(u\) to \(v\).</em></p>

<p><strong>Analyzing the hop bound \(h(K)\).</strong>   Let \(u\) and \(v\) be any two vertices of \(P_{n}\); w.l.o.g, assume that \(u \leq v\), and \(h(n)\) be the hop bound. Let \(b_{u}\) and \(b_v\) be two boundary vertices of the subpaths containing \(u\) and \(v\), respectively, such that \(b_u,b_v \in P[u,v]\). See Figure 3. As mentioned above, line 8 of the algorithms guarantees that there are two edges \((u,b_u)\) and \((b_v,v)\) in \(K\), and the top level recursion (line 3) guarantees that there is a shortest path of hop length  \(h(\sqrt{n})\) between \(b_u\) and \(b_v\) in \(K_B\). Thus we have:</p>

\[h(n) \leq h(\sqrt{n}) + 2\]

<p>which solves to \(h(n)= O(\log\log n)\).</p>

<p><strong>Analyzing the treewidth \(\mathrm{tw}(K)\).</strong> Note that the treewidth of   \(\mathcal T_B\) and all \({\mathcal{T_i}}\) (before adding boundary vertices in line 9) is bounded by \(\mathrm{tw}(\sqrt{n})\). Line 9 increases the treewidth of  \({\mathcal{T_i}}\) by at most \(2\). Since the treewidth of \(K\) is the maximum treewidth \(\mathcal T_B\) and all \({\mathcal{T_i}}\), we have:</p>

\[\mathrm{tw}(n) \leq \mathrm{tw}(\sqrt{n}) + 2\]

<p>which solves to \(\mathrm{tw}(n)= O(\log\log n)\).</p>

<p>This completes the proof of Theorem 1 for the path graph \(P_n\).</p>

<h1 id="2-trees">2. Trees</h1>

<p>What is needed to extend the construction of a path graph to a general tree? Two properties we exploited in the construction of \(P_n\):</p>

<ol>
  <li>\(P_n\) can be decomposed into \(\sqrt{n}\) (connected) subpaths.</li>
  <li>Each subpath in the decomposition has at most two boundary vertices.</li>
</ol>

<p>Property 2 implies that the total number of boundary vertices is about \(\sqrt{n}\), which plays a key role in analyzing the top level recursion.</p>

<p>It is well known that we can obtain a somewhat similar but weaker decomposition for trees: one can decompose a tree of \(n\) vertices to roughly \(\sqrt{n}\) connected subtrees such that the number of boundary vertices is \(\sqrt{n}\). (A vertex is a boundary vertex of a subtree if it is incident to an edge not in the subtree.) This decomposition is weaker in the sense that a subtree could have more than 2, and indeed up to \(\Omega(\sqrt{n})\), boundary vertices.  Is this enough?</p>

<p>Not quite. To glue the tree decomposition \(\mathcal T_i\) to \(\mathcal{T}\) (and effectively to \(\mathcal T_B\)), we rely on the fact that there is a bag \(X\in \mathcal T_B\) containing both boundary vertices in line 11. The  analogy for trees would be: there exists a bag \(X\) containing all boundary vertices of each subtree. This is problematic if a subtree has \(\Omega(\sqrt{n})\) boundary vertices.</p>

<p>Then how abound guaranteeing that each subtree has \(O(1)\) vertices, say 3 vertices. Will this be enough? The answer is pathetically no. To guarantee 3 vertices in the same bag, one has to add a clique of size 3 between the boundary vertices in the top level recursion. What it means is that, the graph between boundary vertices on which we recursively call the shortcuting procedure is <em>no longer a tree</em>. Thus, we really need a decomposition where every subtree has <strong>at most 2 boundary vertices</strong>.</p>

<hr />
<p><strong>Lemma 1:</strong> Let \(T\) be any tree of \(n\) vertices, one can decompose \(T\) into a collection \(\mathcal{D}\) of \(O(\sqrt{n})\) subtrees such that every tree \(T’\in \mathcal{D}\) has \(\lvert V(T’)\rvert \leq \sqrt{n}\) and at most 2 boundary vertices.</p>

<hr />

<p>Lemma 1 is all we need to prove Theorem 1, following exactly the same construction for the path graph \(P_n\); the details are left to readers.</p>

<blockquote>
  <p><strong>Remark 3:</strong> In developing our shortcutting tree result, we were unaware that Lemma 1 was already known in the literature. A reviewer later pointed out that one can get Lemma 1 from a weaker decomposition using <em>least common ancestor closure</em> [3], which I reproduce below.</p>
</blockquote>

<p><strong>Proof of Lemma 1:</strong> First, decompose \(T\) into a collection \(\mathcal{D}’\) of \(O(\sqrt{n})\) subtrees such that each tree in \(\mathcal{D}’\) has size at most \(\sqrt{n}\) and that the total number of boundary vertices is \(O(\sqrt{n})\). As mentioned above, this decomposition is well known; see Claim 1 in our paper [2] for a proof.</p>

<p>Let \(A_1\) be the set of boundary vertices; \(\lvert A_1\rvert = O(\sqrt{n})\). Root \(T\) at an arbitrary vertex. Let \(A_2\) be the set containing the ancestor of every pair of vertices in \(A_1\). Let \(B = A_1\cup A_2\).</p>

<p>It is not hard to see that \(\lvert A_2\rvert  \leq \lvert A_1\rvert - 1  = O(\sqrt{n})\). Thus, \(\lvert B\rvert = O(\sqrt{n})\). Furthermore, every connected component of \(T\setminus B\) has at most \(\sqrt{n}\) vertices and has edges to at most 2 vertices in \(B\). The set \(B\) induces a decomposition \(\mathcal{D}\) of \(T\) claimed in Lemma 1.</p>

<h1 id="3-conclusion">3. Conclusion</h1>

<p>The emulator in Theorem 1 can be constructed in time \(O(n \log \log n)\); see Theorem 10 our paper [2] for more details. The major open problem is:</p>

<p><strong>Open problem:</strong> Is \(O((\log \log n)^2)\) the best possible bound for the product \(\mathrm{tw}(K)\cdot h(K)\)?</p>

<p>This open problem is intimately connected to another problem: embedding  planar graphs of diameter \(D\) into low treewidth graphs with additive distortion at most \(+\epsilon D\) for any \(\epsilon \in (0,1)\). More precisely, though not explicitly stated [2], one of our main results is:</p>

<hr />
<p><strong>Theorem 2:</strong> If one can construct an emulator \(K\) of treewidth \(\mathrm{tw}(n)\) and hop bound \(h(n)\) for any tree of \(n\) vertices, then one can embed any planar graphs with \(n\) vertices and diameter \(D\) into  a graph of treewidth \(O(h(n)\cdot \mathrm{tw}(n)/\epsilon)\) and additive distortion \(+\epsilon D\) for any given \(\epsilon \in (0,1)\).</p>

<hr />

<p>That is, the product of treewdith and hop bound directly bounds the treewdith of the embedding. Theorem 1 give us an embedding with treewidth \(O((\log\log n)^2/\epsilon)\), which has various algorithmic applications [2]. My belief is that the bound \(O((\log \log n)^2)\) is the best possible.</p>

<h1 id="4-references">4. References</h1>

<p>[1] Bodlaender, H.L. and Hagerup, T. (1995). Parallel algorithms with optimal speedup for bounded treewidth. In ICALP ‘95, 268-279.</p>

<p>[2] Filtser, A. and Hung, L. (2022). Low Treewidth Embeddings of Planar and Minor-Free Metrics. ArXiv preprint <a href="https://arxiv.org/abs/2203.15627">arXiv:2203.15627</a>.</p>

<p>[3] Fomin, F.V., Lokshtanov, D., Saurabh, S. and Zehavi, M. (2019). Kernelization: theory of parameterized preprocessing. Cambridge University Press.</p><p class="authors">By Hung Le</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-08T00:00:00Z">Sunday, January 08 2023, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, January 06
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/'>Cargo Cult Redo</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Richard Feynman during his 1974 commencement address at the California Institute of Technology coined the term cargo cult science. The term was just used over at the blog of Scott Aaronson at Shtetl-Optimized. Read his post and skip the rest here if you will. Or read the rest here and then his post. As Wikipedia&#8217;s [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
Richard Feynman during his 1974 commencement address at the California Institute of Technology coined the term <a href="https://en.wikipedia.org/wiki/Cargo_cult_science">cargo cult science</a>. The term was just used over at the blog of Scott Aaronson at <a href="https://scottaaronson.blog">Shtetl-Optimized</a>. Read his post and skip the rest here if you will. Or read the rest here and then his post.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/rf/" rel="attachment wp-att-20780"><img data-attachment-id="20780" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/rf/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?fit=220%2C311&amp;ssl=1" data-orig-size="220,311" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rf" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?fit=212%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?fit=220%2C311&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?resize=169%2C169&#038;ssl=1" alt="" width="169" height="169" class="aligncenter size-full wp-image-20780" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 169px) 100vw, 169px" data-recalc-dims="1" /></a></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/sa/" rel="attachment wp-att-20786"><img data-attachment-id="20786" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/sa/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?fit=169%2C169&amp;ssl=1" data-orig-size="169,169" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sa" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?fit=169%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?fit=169%2C169&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?resize=169%2C169&#038;ssl=1" alt="" width="169" height="169" class="aligncenter size-full wp-image-20786" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?w=169&amp;ssl=1 169w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 169px) 100vw, 169px" data-recalc-dims="1" /></a><br />
<span id="more-20776"></span></p>
<p><P></p>
<p>
As Wikipedia&#8217;s page says, cargo cults are religious practices that have appeared in many traditional tribal societies&#8212;often caused by interactions with technologically advanced cultures. Cargo cult <em>science</em>, as explained more pithily on <a href="https://coffeeandjunk.com/cargo-cult-science/">this page</a>, means following others&#8217; procedures uncritically and expecting the same results without having ascertained whether the needed conditions apply in your particular setting.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/plane-4/" rel="attachment wp-att-20800"><img data-attachment-id="20800" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/plane-4/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/plane-3.jpeg?fit=%2C&amp;ssl=1" data-orig-size="" data-comments-opened="1" data-image-meta="[]" data-image-title="plane" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/plane-3.jpeg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/plane-3.jpeg?fit=1024%2C1024&amp;ssl=1" decoding="async" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/plane-3.jpeg?w=600&#038;ssl=1" alt="" class="aligncenter size-full wp-image-20800" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Factoring is Hard? </H2></p>
<p><p>
Factoring large numbers is the key to the security of the famous <a href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)">RSA</a> method. The 2048-bit RSA system is a real encryption method that is used in practice&#8212;2048 is the size of the numbers that must be hard to factor.</p>
<p>
An obvious idea is to try and use quantum computers to factor these numbers. The trouble is that the known methods do not seem to work on 2048-bit numbers. The quantum computers that we can build in the near future are way too small for running these quantum algorithms. </p>
<p>
<p><H2> Factoring is Easy? </H2></p>
<p><p>
However a group of Chinese researchers have just published a <a href="https://arxiv.org/pdf/2212.12372.pdf">paper</a> claiming that they can&#8212;although they have not yet done so&#8212;break 2048-bit RSA. </p>
<blockquote><p><b> </b> <em> Bao Yan, Ziqi Tan, Shijie Wei, Haocong Jiang, Weilong Wang, Hong Wang, Lan Luo, Qianheng Duan, Yiting Liu, Wenhao Shi, Yangyang Fei, Xiangdong Meng, Yu Han, Zheng Shan, Jiachen Chen, Xuhao Zhu, Chuanyu Zhang, Feitong Jin, Hekang Li, Chao Song, Zhen Wang, Zhi Ma, H. Wang, and Gui-Lu Long </em>
</p></blockquote>
<p><p>
This is something to take seriously. It might not be correct, but it&#8217;s not obviously wrong. This would break a real encryption method since 2048-bit RSA is used in practice. </p>
<p>
Scott <a href="https://scottaaronson.blog">factoring</a> says:</p>
<blockquote><p><b> </b> <em> The paper claims <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;dots}" class="latex" /> well, it&#8217;s hard to pin down what it claims, but it&#8217;s certainly given many people the impression that there&#8217;s been a decisive advance on how to factor huge integers, and thereby break the RSA cryptosystem, using a near-term quantum computer. Not by using Shor&#8217;s Algorithm, mind you, but by using the deceptively similarly named Schnorr&#8217;s Algorithm. The latter is a classical algorithm based on lattices, which the authors then &#8220;enhance&#8221; using the heuristic quantum optimization method called QAOA.</p>
<p>
All told, this is one of the most actively misleading quantum computing papers I&#8217;ve seen in 25 years, and I&#8217;ve seen <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;dots}" class="latex" /> many. Having said that, this actually isn&#8217;t the first time I&#8217;ve encountered the strange idea that the exponential quantum speedup for factoring integers, which we know about from Shor&#8217;s algorithm, should somehow &#8220;rub off&#8221; onto quantum optimization heuristics that embody none of the actual insights of Shor&#8217;s algorithm, as if by sympathetic magic. Since this idea needs a name, I&#8217;d hereby like to propose:</em><br />
<font color="#0044cc"><br />
<em>Cargo Cult Quantum Factoring</em><br />
<font color="#000000"></p>
</blockquote>
<p><p>
An interesting question is: Why would China allow this paper to be public given the huge importance of RSA? Could this be a sign that it is not real?</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
There it is&#8212;&#8220;Cargo Cult&#8221; in quantum algorithmic science&#8212;used by Scott. No doubt that it would have been approved by Feynman. </p>
<p><P><br />
[fixed &#8220;cargo cult&#8221;&#8211;>cargo cult <em>science</em>]</p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T16:39:51Z">Friday, January 06 2023, 16:39</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01924'>Diagonalization Games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Noga Alon, Olivier Bousquet, Kasper Green Larsen, Shay Moran, Shlomo Moran</p><p>We study several variants of a combinatorial game which is based on Cantor's
diagonal argument.
</p>
<p>The game is between two players called Kronecker and Cantor. The names of the
players are motivated by the known fact that Leopold Kronecker did not
appreciate Georg Cantor's arguments about the infinite, and even referred to
him as a "scientific charlatan". In the game Kronecker maintains a list of m
binary vectors, each of length n, and Cantor's goal is to produce a new binary
vector which is different from each of Kronecker's vectors, or prove that no
such vector exists. Cantor does not see Kronecker's vectors but he is allowed
to ask queries of the form"What is bit number j of vector number i?" What is
the minimal number of queries with which Cantor can achieve his goal? How much
better can Cantor do if he is allowed to pick his queries \emph{adaptively},
based on Kronecker's previous replies? The case when m=n is solved by
diagonalization using n (non-adaptive) queries. We study this game more
generally, and prove an optimal bound in the adaptive case and nearly tight
upper and lower bounds in the non-adaptive case.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Alon_N/0/1/0/all/0/1">Noga Alon</a>, <a href="http://arxiv.org/find/math/1/au:+Bousquet_O/0/1/0/all/0/1">Olivier Bousquet</a>, <a href="http://arxiv.org/find/math/1/au:+Larsen_K/0/1/0/all/0/1">Kasper Green Larsen</a>, <a href="http://arxiv.org/find/math/1/au:+Moran_S/0/1/0/all/0/1">Shay Moran</a>, <a href="http://arxiv.org/find/math/1/au:+Moran_S/0/1/0/all/0/1">Shlomo Moran</a></p><p>We study several variants of a combinatorial game which is based on Cantor's
diagonal argument.
</p>
<p>The game is between two players called Kronecker and Cantor. The names of the
players are motivated by the known fact that Leopold Kronecker did not
appreciate Georg Cantor's arguments about the infinite, and even referred to
him as a "scientific charlatan". In the game Kronecker maintains a list of m
binary vectors, each of length n, and Cantor's goal is to produce a new binary
vector which is different from each of Kronecker's vectors, or prove that no
such vector exists. Cantor does not see Kronecker's vectors but he is allowed
to ask queries of the form"What is bit number j of vector number i?" What is
the minimal number of queries with which Cantor can achieve his goal? How much
better can Cantor do if he is allowed to pick his queries \emph{adaptively},
based on Kronecker's previous replies? The case when m=n is solved by
diagonalization using n (non-adaptive) queries. We study this game more
generally, and prove an optimal bound in the adaptive case and nearly tight
upper and lower bounds in the non-adaptive case.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02161'>Streaming Zero-Knowledge Proofs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Graham Cormode, Marcel Dall&#x27;Agnol, Tom Gur, Chris Hickey</p><p>We initiate the study of zero-knowledge proofs for data streams. Streaming
interactive proofs (SIPs) are well-studied protocols whereby a space-bounded
algorithm with one-pass access to a massive stream of data communicates with a
powerful but untrusted prover to verify a computation that requires large
space.
</p>
<p>We define the notion of zero-knowledge in the streaming setting and construct
zero-knowledge SIPs for the two main building blocks in the streaming
interactive proofs literature: the sumcheck and polynomial evaluation
protocols. To the best of our knowledge all known streaming interactive proofs
are based on either of these tools, and indeed, this allows us to obtain
zero-knowledge SIPs for central streaming problems such as index, frequency
moments, and inner product. Our protocols are efficient in terms of time and
space, as well as communication: the space complexity is $\mathrm{polylog}(n)$
and, after a non-interactive setup that uses a random string of near-linear
length, the remaining parameters are $n^{o(1)}$.
</p>
<p>En route, we develop a toolkit for designing zero-knowledge data stream
protocols, consisting of an algebraic streaming commitment protocol and a
temporal commitment protocol. The analysis of our protocols relies on delicate
algebraic and information-theoretic arguments and reductions from average-case
communication complexity.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cormode_G/0/1/0/all/0/1">Graham Cormode</a>, <a href="http://arxiv.org/find/cs/1/au:+DallAgnol_M/0/1/0/all/0/1">Marcel Dall&#x27;Agnol</a>, <a href="http://arxiv.org/find/cs/1/au:+Gur_T/0/1/0/all/0/1">Tom Gur</a>, <a href="http://arxiv.org/find/cs/1/au:+Hickey_C/0/1/0/all/0/1">Chris Hickey</a></p><p>We initiate the study of zero-knowledge proofs for data streams. Streaming
interactive proofs (SIPs) are well-studied protocols whereby a space-bounded
algorithm with one-pass access to a massive stream of data communicates with a
powerful but untrusted prover to verify a computation that requires large
space.
</p>
<p>We define the notion of zero-knowledge in the streaming setting and construct
zero-knowledge SIPs for the two main building blocks in the streaming
interactive proofs literature: the sumcheck and polynomial evaluation
protocols. To the best of our knowledge all known streaming interactive proofs
are based on either of these tools, and indeed, this allows us to obtain
zero-knowledge SIPs for central streaming problems such as index, frequency
moments, and inner product. Our protocols are efficient in terms of time and
space, as well as communication: the space complexity is $\mathrm{polylog}(n)$
and, after a non-interactive setup that uses a random string of near-linear
length, the remaining parameters are $n^{o(1)}$.
</p>
<p>En route, we develop a toolkit for designing zero-knowledge data stream
protocols, consisting of an algebraic streaming commitment protocol and a
temporal commitment protocol. The analysis of our protocols relies on delicate
algebraic and information-theoretic arguments and reductions from average-case
communication complexity.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
