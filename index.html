<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-01-06T20:30:45Z">Friday, January 06 2023, 20:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, January 06
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/'>Cargo Cult Redo</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Richard Feynman during his 1974 commencement address at the California Institute of Technology coined the term cargo cult science. The term was just used over at the blog of Scott Aaronson at Shtetl-Optimized. Read his post and skip the rest here if you will. Or read the rest here and then his post. As Wikipedia&#8217;s [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
Richard Feynman during his 1974 commencement address at the California Institute of Technology coined the term <a href="https://en.wikipedia.org/wiki/Cargo_cult_science">cargo cult science</a>. The term was just used over at the blog of Scott Aaronson at <a href="https://scottaaronson.blog">Shtetl-Optimized</a>. Read his post and skip the rest here if you will. Or read the rest here and then his post.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/rf/" rel="attachment wp-att-20780"><img data-attachment-id="20780" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/rf/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?fit=220%2C311&amp;ssl=1" data-orig-size="220,311" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rf" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?fit=212%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?fit=220%2C311&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?resize=169%2C169&#038;ssl=1" alt="" width="169" height="169" class="aligncenter size-full wp-image-20780" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/rf.jpg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 169px) 100vw, 169px" data-recalc-dims="1" /></a></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/sa/" rel="attachment wp-att-20786"><img data-attachment-id="20786" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/sa/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?fit=169%2C169&amp;ssl=1" data-orig-size="169,169" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sa" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?fit=169%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?fit=169%2C169&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?resize=169%2C169&#038;ssl=1" alt="" width="169" height="169" class="aligncenter size-full wp-image-20786" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?w=169&amp;ssl=1 169w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/sa.jpeg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 169px) 100vw, 169px" data-recalc-dims="1" /></a></p>
<p><P></p>
<p>
As Wikipedia&#8217;s page says, cargo cults are religious practices that have appeared in many traditional tribal societies&#8212;often caused by interactions with technologically advanced cultures. Cargo cult <em>science</em>, as explained more pithily on <a href="https://coffeeandjunk.com/cargo-cult-science/">this page</a>, means following others&#8217; procedures uncritically and expecting the same results without having ascertained whether the needed conditions apply in your particular setting.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/plane-4/" rel="attachment wp-att-20800"><img data-attachment-id="20800" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/06/cargo-cult-redo/plane-4/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/plane-3.jpeg?fit=%2C&amp;ssl=1" data-orig-size="" data-comments-opened="1" data-image-meta="[]" data-image-title="plane" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/plane-3.jpeg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/plane-3.jpeg?fit=1024%2C1024&amp;ssl=1" decoding="async" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/plane-3.jpeg?w=600&#038;ssl=1" alt="" class="aligncenter size-full wp-image-20800" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Factoring is Hard? </H2></p>
<p><p>
Factoring large numbers is the key to the security of the famous <a href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)">RSA</a> method. The 2048-bit RSA system is a real encryption method that is used in practice&#8212;2048 is the size of the numbers that must be hard to factor.</p>
<p>
An obvious idea is to try and use quantum computers to factor these numbers. The trouble is that the known methods do not seem to work on 2048-bit numbers. The quantum computers that we can build in the near future are way too small for running these quantum algorithms. </p>
<p>
<p><H2> Factoring is Easy? </H2></p>
<p><p>
However a group of Chinese researchers have just published a <a href="https://arxiv.org/pdf/2212.12372.pdf">paper</a> claiming that they can&#8212;although they have not yet done so&#8212;break 2048-bit RSA. </p>
<blockquote><p><b> </b> <em> Bao Yan, Ziqi Tan, Shijie Wei, Haocong Jiang, Weilong Wang, Hong Wang, Lan Luo, Qianheng Duan, Yiting Liu, Wenhao Shi, Yangyang Fei, Xiangdong Meng, Yu Han, Zheng Shan, Jiachen Chen, Xuhao Zhu, Chuanyu Zhang, Feitong Jin, Hekang Li, Chao Song, Zhen Wang, Zhi Ma, H. Wang, and Gui-Lu Long </em>
</p></blockquote>
<p><p>
This is something to take seriously. It might not be correct, but it&#8217;s not obviously wrong. This would break a real encryption method since 2048-bit RSA is used in practice. </p>
<p>
Scott <a href="https://scottaaronson.blog">factoring</a> says:</p>
<blockquote><p><b> </b> <em> The paper claims <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;dots}" class="latex" /> well, it&#8217;s hard to pin down what it claims, but it&#8217;s certainly given many people the impression that there&#8217;s been a decisive advance on how to factor huge integers, and thereby break the RSA cryptosystem, using a near-term quantum computer. Not by using Shor&#8217;s Algorithm, mind you, but by using the deceptively similarly named Schnorr&#8217;s Algorithm. The latter is a classical algorithm based on lattices, which the authors then &#8220;enhance&#8221; using the heuristic quantum optimization method called QAOA.</p>
<p>
All told, this is one of the most actively misleading quantum computing papers I&#8217;ve seen in 25 years, and I&#8217;ve seen <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;dots}" class="latex" /> many. Having said that, this actually isn&#8217;t the first time I&#8217;ve encountered the strange idea that the exponential quantum speedup for factoring integers, which we know about from Shor&#8217;s algorithm, should somehow &#8220;rub off&#8221; onto quantum optimization heuristics that embody none of the actual insights of Shor&#8217;s algorithm, as if by sympathetic magic. Since this idea needs a name, I&#8217;d hereby like to propose:</em><br />
<font color="#0044cc"><br />
<em>Cargo Cult Quantum Factoring</em><br />
<font color="#000000"></p>
</blockquote>
<p><p>
An interesting question is: Why would China allow this paper to be public given the huge importance of RSA? Could this be a sign that it is not real?</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
There it is&#8212;&#8220;Cargo Cult&#8221; in quantum algorithmic science&#8212;used by Scott. No doubt that it would have been approved by Feynman. </p>
<p><P><br />
[fixed &#8220;cargo cult&#8221;&#8211;>cargo cult <em>science</em>]</p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T16:39:51Z">Friday, January 06 2023, 16:39</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01924'>Diagonalization Games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Noga Alon, Olivier Bousquet, Kasper Green Larsen, Shay Moran, Shlomo Moran</p><p>We study several variants of a combinatorial game which is based on Cantor's
diagonal argument.
</p>
<p>The game is between two players called Kronecker and Cantor. The names of the
players are motivated by the known fact that Leopold Kronecker did not
appreciate Georg Cantor's arguments about the infinite, and even referred to
him as a "scientific charlatan". In the game Kronecker maintains a list of m
binary vectors, each of length n, and Cantor's goal is to produce a new binary
vector which is different from each of Kronecker's vectors, or prove that no
such vector exists. Cantor does not see Kronecker's vectors but he is allowed
to ask queries of the form"What is bit number j of vector number i?" What is
the minimal number of queries with which Cantor can achieve his goal? How much
better can Cantor do if he is allowed to pick his queries \emph{adaptively},
based on Kronecker's previous replies? The case when m=n is solved by
diagonalization using n (non-adaptive) queries. We study this game more
generally, and prove an optimal bound in the adaptive case and nearly tight
upper and lower bounds in the non-adaptive case.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Alon_N/0/1/0/all/0/1">Noga Alon</a>, <a href="http://arxiv.org/find/math/1/au:+Bousquet_O/0/1/0/all/0/1">Olivier Bousquet</a>, <a href="http://arxiv.org/find/math/1/au:+Larsen_K/0/1/0/all/0/1">Kasper Green Larsen</a>, <a href="http://arxiv.org/find/math/1/au:+Moran_S/0/1/0/all/0/1">Shay Moran</a>, <a href="http://arxiv.org/find/math/1/au:+Moran_S/0/1/0/all/0/1">Shlomo Moran</a></p><p>We study several variants of a combinatorial game which is based on Cantor's
diagonal argument.
</p>
<p>The game is between two players called Kronecker and Cantor. The names of the
players are motivated by the known fact that Leopold Kronecker did not
appreciate Georg Cantor's arguments about the infinite, and even referred to
him as a "scientific charlatan". In the game Kronecker maintains a list of m
binary vectors, each of length n, and Cantor's goal is to produce a new binary
vector which is different from each of Kronecker's vectors, or prove that no
such vector exists. Cantor does not see Kronecker's vectors but he is allowed
to ask queries of the form"What is bit number j of vector number i?" What is
the minimal number of queries with which Cantor can achieve his goal? How much
better can Cantor do if he is allowed to pick his queries \emph{adaptively},
based on Kronecker's previous replies? The case when m=n is solved by
diagonalization using n (non-adaptive) queries. We study this game more
generally, and prove an optimal bound in the adaptive case and nearly tight
upper and lower bounds in the non-adaptive case.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02161'>Streaming Zero-Knowledge Proofs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Graham Cormode, Marcel Dall&#x27;Agnol, Tom Gur, Chris Hickey</p><p>We initiate the study of zero-knowledge proofs for data streams. Streaming
interactive proofs (SIPs) are well-studied protocols whereby a space-bounded
algorithm with one-pass access to a massive stream of data communicates with a
powerful but untrusted prover to verify a computation that requires large
space.
</p>
<p>We define the notion of zero-knowledge in the streaming setting and construct
zero-knowledge SIPs for the two main building blocks in the streaming
interactive proofs literature: the sumcheck and polynomial evaluation
protocols. To the best of our knowledge all known streaming interactive proofs
are based on either of these tools, and indeed, this allows us to obtain
zero-knowledge SIPs for central streaming problems such as index, frequency
moments, and inner product. Our protocols are efficient in terms of time and
space, as well as communication: the space complexity is $\mathrm{polylog}(n)$
and, after a non-interactive setup that uses a random string of near-linear
length, the remaining parameters are $n^{o(1)}$.
</p>
<p>En route, we develop a toolkit for designing zero-knowledge data stream
protocols, consisting of an algebraic streaming commitment protocol and a
temporal commitment protocol. The analysis of our protocols relies on delicate
algebraic and information-theoretic arguments and reductions from average-case
communication complexity.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cormode_G/0/1/0/all/0/1">Graham Cormode</a>, <a href="http://arxiv.org/find/cs/1/au:+DallAgnol_M/0/1/0/all/0/1">Marcel Dall&#x27;Agnol</a>, <a href="http://arxiv.org/find/cs/1/au:+Gur_T/0/1/0/all/0/1">Tom Gur</a>, <a href="http://arxiv.org/find/cs/1/au:+Hickey_C/0/1/0/all/0/1">Chris Hickey</a></p><p>We initiate the study of zero-knowledge proofs for data streams. Streaming
interactive proofs (SIPs) are well-studied protocols whereby a space-bounded
algorithm with one-pass access to a massive stream of data communicates with a
powerful but untrusted prover to verify a computation that requires large
space.
</p>
<p>We define the notion of zero-knowledge in the streaming setting and construct
zero-knowledge SIPs for the two main building blocks in the streaming
interactive proofs literature: the sumcheck and polynomial evaluation
protocols. To the best of our knowledge all known streaming interactive proofs
are based on either of these tools, and indeed, this allows us to obtain
zero-knowledge SIPs for central streaming problems such as index, frequency
moments, and inner product. Our protocols are efficient in terms of time and
space, as well as communication: the space complexity is $\mathrm{polylog}(n)$
and, after a non-interactive setup that uses a random string of near-linear
length, the remaining parameters are $n^{o(1)}$.
</p>
<p>En route, we develop a toolkit for designing zero-knowledge data stream
protocols, consisting of an algebraic streaming commitment protocol and a
temporal commitment protocol. The analysis of our protocols relies on delicate
algebraic and information-theoretic arguments and reductions from average-case
communication complexity.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02227'>Optimal lower bounds for Quantum Learning via Information Theory</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shima Bab Hadiashar, Ashwin Nayak, Pulkit Sinha</p><p>Although a concept class may be learnt more efficiently using quantum samples
as compared with classical samples in certain scenarios, Arunachalam and de
Wolf (JMLR, 2018) proved that quantum learners are asymptotically no more
efficient than classical ones in the quantum PAC and Agnostic learning models.
They established lower bounds on sample complexity via quantum state
identification and Fourier analysis. In this paper, we derive optimal lower
bounds for quantum sample complexity in both the PAC and agnostic models via an
information-theoretic approach. The proofs are arguably simpler, and the same
ideas can potentially be used to derive optimal bounds for other problems in
quantum learning theory.
</p>
<p>We then turn to a quantum analogue of the Coupon Collector problem, a classic
problem from probability theory also of importance in the study of PAC
learning. Arunachalam, Belovs, Childs, Kothari, Rosmanis, and de Wolf (TQC,
2020) characterized the quantum sample complexity of this problem up to
constant factors. First, we show that the information-theoretic approach
mentioned above provably does not yield the optimal lower bound. As a
by-product, we get a natural ensemble of pure states in arbitrarily high
dimensions which are not easily (simultaneously) distinguishable, while the
ensemble has close to maximal Holevo information. Second, we discover that the
information-theoretic approach yields an asymptotically optimal bound for an
approximation variant of the problem. Finally, we derive a sharp lower bound
for the Quantum Coupon Collector problem, with the exact leading order term,
via the Holevo-Curlander bounds on the distinguishability of an ensemble. All
the aspects of the Quantum Coupon Collector problem we study rest on properties
of the spectrum of the associated Gram matrix, which may be of independent
interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Hadiashar_S/0/1/0/all/0/1">Shima Bab Hadiashar</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nayak_A/0/1/0/all/0/1">Ashwin Nayak</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sinha_P/0/1/0/all/0/1">Pulkit Sinha</a></p><p>Although a concept class may be learnt more efficiently using quantum samples
as compared with classical samples in certain scenarios, Arunachalam and de
Wolf (JMLR, 2018) proved that quantum learners are asymptotically no more
efficient than classical ones in the quantum PAC and Agnostic learning models.
They established lower bounds on sample complexity via quantum state
identification and Fourier analysis. In this paper, we derive optimal lower
bounds for quantum sample complexity in both the PAC and agnostic models via an
information-theoretic approach. The proofs are arguably simpler, and the same
ideas can potentially be used to derive optimal bounds for other problems in
quantum learning theory.
</p>
<p>We then turn to a quantum analogue of the Coupon Collector problem, a classic
problem from probability theory also of importance in the study of PAC
learning. Arunachalam, Belovs, Childs, Kothari, Rosmanis, and de Wolf (TQC,
2020) characterized the quantum sample complexity of this problem up to
constant factors. First, we show that the information-theoretic approach
mentioned above provably does not yield the optimal lower bound. As a
by-product, we get a natural ensemble of pure states in arbitrarily high
dimensions which are not easily (simultaneously) distinguishable, while the
ensemble has close to maximal Holevo information. Second, we discover that the
information-theoretic approach yields an asymptotically optimal bound for an
approximation variant of the problem. Finally, we derive a sharp lower bound
for the Quantum Coupon Collector problem, with the exact leading order term,
via the Holevo-Curlander bounds on the distinguishability of an ensemble. All
the aspects of the Quantum Coupon Collector problem we study rest on properties
of the spectrum of the associated Gram matrix, which may be of independent
interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02051'>A Distance-Geometric Method for Recovering Robot Joint Angles From an RGB Image</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ivan Bili&#x107;, Filip Mari&#x107;, Ivan Markovi&#x107;, Ivan Petrovi&#x107;</p><p>Autonomous manipulation systems operating in domains where human intervention
is difficult or impossible (e.g., underwater, extraterrestrial or hazardous
environments) require a high degree of robustness to sensing and communication
failures. Crucially, motion planning and control algorithms require a stream of
accurate joint angle data provided by joint encoders, the failure of which may
result in an unrecoverable loss of functionality. In this paper, we present a
novel method for retrieving the joint angles of a robot manipulator using only
a single RGB image of its current configuration, opening up an avenue for
recovering system functionality when conventional proprioceptive sensing is
unavailable. Our approach, based on a distance-geometric representation of the
configuration space, exploits the knowledge of a robot's kinematic model with
the goal of training a shallow neural network that performs a 2D-to-3D
regression of distances associated with detected structural keypoints. It is
shown that the resulting Euclidean distance matrix uniquely corresponds to the
observed configuration, where joint angles can be recovered via
multidimensional scaling and a simple inverse kinematics procedure. We evaluate
the performance of our approach on real RGB images of a Franka Emika Panda
manipulator, showing that the proposed method is efficient and exhibits solid
generalization ability. Furthermore, we show that our method can be easily
combined with a dense refinement technique to obtain superior results.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bilic_I/0/1/0/all/0/1">Ivan Bili&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Maric_F/0/1/0/all/0/1">Filip Mari&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Markovic_I/0/1/0/all/0/1">Ivan Markovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrovic_I/0/1/0/all/0/1">Ivan Petrovi&#x107;</a></p><p>Autonomous manipulation systems operating in domains where human intervention
is difficult or impossible (e.g., underwater, extraterrestrial or hazardous
environments) require a high degree of robustness to sensing and communication
failures. Crucially, motion planning and control algorithms require a stream of
accurate joint angle data provided by joint encoders, the failure of which may
result in an unrecoverable loss of functionality. In this paper, we present a
novel method for retrieving the joint angles of a robot manipulator using only
a single RGB image of its current configuration, opening up an avenue for
recovering system functionality when conventional proprioceptive sensing is
unavailable. Our approach, based on a distance-geometric representation of the
configuration space, exploits the knowledge of a robot's kinematic model with
the goal of training a shallow neural network that performs a 2D-to-3D
regression of distances associated with detected structural keypoints. It is
shown that the resulting Euclidean distance matrix uniquely corresponds to the
observed configuration, where joint angles can be recovered via
multidimensional scaling and a simple inverse kinematics procedure. We evaluate
the performance of our approach on real RGB images of a Franka Emika Panda
manipulator, showing that the proposed method is efficient and exhibits solid
generalization ability. Furthermore, we show that our method can be easily
combined with a dense refinement technique to obtain superior results.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02129'>Algorithms and Complexity for Computing Nash Equilibria in Adversarial Team Games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ioannis Anagnostides, Fivos Kalogiannis, Ioannis Panageas, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Stephen McAleer</p><p>Adversarial team games model multiplayer strategic interactions in which a
team of identically-interested players is competing against an adversarial
player in a zero-sum game. Such games capture many well-studied settings in
game theory, such as congestion games, but go well-beyond to environments
wherein the cooperation of one team -- in the absence of explicit communication
-- is obstructed by competing entities; the latter setting remains poorly
understood despite its numerous applications. Since the seminal work of Von
Stengel and Koller (GEB `97), different solution concepts have received
attention from an algorithmic standpoint. Yet, the complexity of the standard
Nash equilibrium has remained open.
</p>
<p>In this paper, we settle this question by showing that computing a Nash
equilibrium in adversarial team games belongs to the class continuous local
search (CLS), thereby establishing CLS-completeness by virtue of the recent
CLS-hardness result of Rubinstein and Babichenko (STOC `21) in potential games.
To do so, we leverage linear programming duality to prove that any
$\epsilon$-approximate stationary strategy for the team can be extended in
polynomial time to an $O(\epsilon)$-approximate Nash equilibrium, where the
$O(\cdot)$ notation suppresses polynomial factors in the description of the
game. As a consequence, we show that the Moreau envelop of a suitable best
response function acts as a potential under certain natural gradient-based
dynamics.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Anagnostides_I/0/1/0/all/0/1">Ioannis Anagnostides</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalogiannis_F/0/1/0/all/0/1">Fivos Kalogiannis</a>, <a href="http://arxiv.org/find/cs/1/au:+Panageas_I/0/1/0/all/0/1">Ioannis Panageas</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlatakis_Gkaragkounis_E/0/1/0/all/0/1">Emmanouil-Vasileios Vlatakis-Gkaragkounis</a>, <a href="http://arxiv.org/find/cs/1/au:+McAleer_S/0/1/0/all/0/1">Stephen McAleer</a></p><p>Adversarial team games model multiplayer strategic interactions in which a
team of identically-interested players is competing against an adversarial
player in a zero-sum game. Such games capture many well-studied settings in
game theory, such as congestion games, but go well-beyond to environments
wherein the cooperation of one team -- in the absence of explicit communication
-- is obstructed by competing entities; the latter setting remains poorly
understood despite its numerous applications. Since the seminal work of Von
Stengel and Koller (GEB `97), different solution concepts have received
attention from an algorithmic standpoint. Yet, the complexity of the standard
Nash equilibrium has remained open.
</p>
<p>In this paper, we settle this question by showing that computing a Nash
equilibrium in adversarial team games belongs to the class continuous local
search (CLS), thereby establishing CLS-completeness by virtue of the recent
CLS-hardness result of Rubinstein and Babichenko (STOC `21) in potential games.
To do so, we leverage linear programming duality to prove that any
$\epsilon$-approximate stationary strategy for the team can be extended in
polynomial time to an $O(\epsilon)$-approximate Nash equilibrium, where the
$O(\cdot)$ notation suppresses polynomial factors in the description of the
game. As a consequence, we show that the Moreau envelop of a suitable best
response function acts as a potential under certain natural gradient-based
dynamics.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02178'>Sum Labelling Graphs of Maximum Degree Two</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Henning Fernau, Kshitij Gajjar</p><p>The concept of sum labelling was introduced in 1990 by Harary. A graph is a
sum graph if its vertices can be labelled by distinct positive integers in such
a way that two vertices are connected by an edge if and only if the sum of
their labels is the label of another vertex in the graph. It is easy to see
that every sum graph has at least one isolated vertex, and every graph can be
made a sum graph by adding at most $n^2$ isolated vertices to it. The minimum
number of isolated vertices that need to be added to a graph to make it a sum
graph is called the sum number of the graph.
</p>
<p>The sum number of several prominent graph classes (e.g., cycles, trees,
complete graphs) is already well known. We examine the effect of taking the
disjoint union of graphs on the sum number. In particular, we provide a
complete characterization of the sum number of graphs of maximum degree two,
since every such graph is the disjoint union of paths and cycles.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Fernau_H/0/1/0/all/0/1">Henning Fernau</a>, <a href="http://arxiv.org/find/math/1/au:+Gajjar_K/0/1/0/all/0/1">Kshitij Gajjar</a></p><p>The concept of sum labelling was introduced in 1990 by Harary. A graph is a
sum graph if its vertices can be labelled by distinct positive integers in such
a way that two vertices are connected by an edge if and only if the sum of
their labels is the label of another vertex in the graph. It is easy to see
that every sum graph has at least one isolated vertex, and every graph can be
made a sum graph by adding at most $n^2$ isolated vertices to it. The minimum
number of isolated vertices that need to be added to a graph to make it a sum
graph is called the sum number of the graph.
</p>
<p>The sum number of several prominent graph classes (e.g., cycles, trees,
complete graphs) is already well known. We examine the effect of taking the
disjoint union of graphs on the sum number. In particular, we provide a
complete characterization of the sum number of graphs of maximum degree two,
since every such graph is the disjoint union of paths and cycles.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01778'>Quantum relaxation for quadratic programs over orthogonal matrices</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andrew Zhao, Nicholas C. Rubin</p><p>Quadratic programming over the (special) orthogonal group encompasses a broad
class of optimization problems such as group synchronization, point-set
registration, and simultaneous localization and mapping. Such problems are
instances of the little noncommutative Grothendieck problem (LNCG), a natural
generalization of quadratic combinatorial optimization where, instead of binary
decision variables, one optimizes over orthogonal matrices. In this work, we
establish an embedding of this class of LNCG problems over the orthogonal group
onto a quantum Hamiltonian. This embedding is accomplished by identifying
orthogonal matrices with their double cover (Pin and Spin group) elements,
which we represent as quantum states. We connect this construction to the
theory of free fermions, which provides a physical interpretation of the
derived LNCG Hamiltonian as a two-body interacting-fermion model due to the
quadratic nature of the problem. Determining extremal states of this
Hamiltonian provides an outer approximation to the original problem, analogous
to classical relaxations of the problem via semidefinite programming. When
optimizing over the special orthogonal group, our quantum relaxation naturally
obeys additional, powerful constraints based on the convex hull of rotation
matrices. The classical size of this convex-hull representation is exponential
in matrix dimension, whereas the quantum representation requires only a linear
number of qubits. Finally, to project the relaxed solution into the feasible
space, we employ rounding procedures which return orthogonal matrices from
appropriate measurements of the quantum state. Through numerical experiments we
provide evidence that this quantum relaxation can produce high-quality
approximations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Zhao_A/0/1/0/all/0/1">Andrew Zhao</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Rubin_N/0/1/0/all/0/1">Nicholas C. Rubin</a></p><p>Quadratic programming over the (special) orthogonal group encompasses a broad
class of optimization problems such as group synchronization, point-set
registration, and simultaneous localization and mapping. Such problems are
instances of the little noncommutative Grothendieck problem (LNCG), a natural
generalization of quadratic combinatorial optimization where, instead of binary
decision variables, one optimizes over orthogonal matrices. In this work, we
establish an embedding of this class of LNCG problems over the orthogonal group
onto a quantum Hamiltonian. This embedding is accomplished by identifying
orthogonal matrices with their double cover (Pin and Spin group) elements,
which we represent as quantum states. We connect this construction to the
theory of free fermions, which provides a physical interpretation of the
derived LNCG Hamiltonian as a two-body interacting-fermion model due to the
quadratic nature of the problem. Determining extremal states of this
Hamiltonian provides an outer approximation to the original problem, analogous
to classical relaxations of the problem via semidefinite programming. When
optimizing over the special orthogonal group, our quantum relaxation naturally
obeys additional, powerful constraints based on the convex hull of rotation
matrices. The classical size of this convex-hull representation is exponential
in matrix dimension, whereas the quantum representation requires only a linear
number of qubits. Finally, to project the relaxed solution into the feasible
space, we employ rounding procedures which return orthogonal matrices from
appropriate measurements of the quantum state. Through numerical experiments we
provide evidence that this quantum relaxation can produce high-quality
approximations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01977'>Exact and Heuristic Approaches to Speeding Up the MSM Time Series Distance Computation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jana Holznigenkemper, Christian Komusiewicz, Bernhard Seeger</p><p>The computation of a distance of two time series is time-consuming for any
elastic distance function that accounts for misalignments. Among those
functions, DTW is the most prominent. However, a recent extensive evaluation
has shown that the move-split merge (MSM) metric is superior to DTW regarding
the analytical accuracy of 1-NN classifier. Unfortunately, the runtime of the
standard dynamic programming algorithm for MSM distance computation is
$\Omega(n^2)$, where $n$ is the length of the longest time series. In this
paper, we provide approaches to reducing the cost of MSM distance computations
by using lower and upper bounds for early pruning paths in the underlying
dynamic programming table. For the case of one time series being a constant, we
present a linear-time algorithm. In addition, we propose new linear-time
heuristics and adapt heuristics known from DTW to computing the MSM distance.
One heuristic employs the metric property of MSM and the previously introduced
linear-time algorithm. Our experimental studies achieve substantial speed-ups
in our approaches compared to previous MSM algorithms. In particular, the
running time for MSM is faster for a majority of data sets than a
state-of-the-art DTW distance computation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Holznigenkemper_J/0/1/0/all/0/1">Jana Holznigenkemper</a>, <a href="http://arxiv.org/find/cs/1/au:+Komusiewicz_C/0/1/0/all/0/1">Christian Komusiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Seeger_B/0/1/0/all/0/1">Bernhard Seeger</a></p><p>The computation of a distance of two time series is time-consuming for any
elastic distance function that accounts for misalignments. Among those
functions, DTW is the most prominent. However, a recent extensive evaluation
has shown that the move-split merge (MSM) metric is superior to DTW regarding
the analytical accuracy of 1-NN classifier. Unfortunately, the runtime of the
standard dynamic programming algorithm for MSM distance computation is
$\Omega(n^2)$, where $n$ is the length of the longest time series. In this
paper, we provide approaches to reducing the cost of MSM distance computations
by using lower and upper bounds for early pruning paths in the underlying
dynamic programming table. For the case of one time series being a constant, we
present a linear-time algorithm. In addition, we propose new linear-time
heuristics and adapt heuristics known from DTW to computing the MSM distance.
One heuristic employs the metric property of MSM and the previously introduced
linear-time algorithm. Our experimental studies achieve substantial speed-ups
in our approaches compared to previous MSM algorithms. In particular, the
running time for MSM is faster for a majority of data sets than a
state-of-the-art DTW distance computation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.02053'>Max-Min Diversification with Fairness Constraints: Exact and Approximation Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yanhao Wang, Michael Mathioudakis, Jia Li, Francesco Fabbri</p><p>Diversity maximization aims to select a diverse and representative subset of
items from a large dataset. It is a fundamental optimization task that finds
applications in data summarization, feature selection, web search, recommender
systems, and elsewhere. However, in a setting where data items are associated
with different groups according to sensitive attributes like sex or race, it is
possible that algorithmic solutions for this task, if left unchecked, will
under- or over-represent some of the groups. Therefore, we are motivated to
address the problem of \emph{max-min diversification with fairness
constraints}, aiming to select $k$ items to maximize the minimum distance
between any pair of selected items while ensuring that the number of items
selected from each group falls within predefined lower and upper bounds. In
this work, we propose an exact algorithm based on integer linear programming
that is suitable for small datasets as well as a
$\frac{1-\varepsilon}{5}$-approximation algorithm for any $\varepsilon \in (0,
1)$ that scales to large datasets. Extensive experiments on real-world datasets
demonstrate the superior performance of our proposed algorithms over existing
ones.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathioudakis_M/0/1/0/all/0/1">Michael Mathioudakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fabbri_F/0/1/0/all/0/1">Francesco Fabbri</a></p><p>Diversity maximization aims to select a diverse and representative subset of
items from a large dataset. It is a fundamental optimization task that finds
applications in data summarization, feature selection, web search, recommender
systems, and elsewhere. However, in a setting where data items are associated
with different groups according to sensitive attributes like sex or race, it is
possible that algorithmic solutions for this task, if left unchecked, will
under- or over-represent some of the groups. Therefore, we are motivated to
address the problem of \emph{max-min diversification with fairness
constraints}, aiming to select $k$ items to maximize the minimum distance
between any pair of selected items while ensuring that the number of items
selected from each group falls within predefined lower and upper bounds. In
this work, we propose an exact algorithm based on integer linear programming
that is suitable for small datasets as well as a
$\frac{1-\varepsilon}{5}$-approximation algorithm for any $\varepsilon \in (0,
1)$ that scales to large datasets. Extensive experiments on real-world datasets
demonstrate the superior performance of our proposed algorithms over existing
ones.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-06T01:30:00Z">Friday, January 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, January 05
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/001'>TR23-001 |  New Lower Bounds against Homogeneous Non-Commutative Circuits | 

	Prerona Chatterjee, 

	Pavel Hrubes</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We give several new lower bounds on size of homogeneous non-commutative circuits. We present an explicit homogeneous bivariate polynomial of degree $d$ which requires homogeneous non-commutative circuit of size $\Omega(d/\log d)$. For an $n$-variate polynomial with $n&gt;1$, the result can be improved to $\Omega(nd)$, if $d\leq n$,  or $\Omega(nd \frac{\log n}{\log d})$, if $d\geq n$.
  Under the same assumptions, we also give a quadratic lower bound for the ordered version of the central symmetric polynomial.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We give several new lower bounds on size of homogeneous non-commutative circuits. We present an explicit homogeneous bivariate polynomial of degree $d$ which requires homogeneous non-commutative circuit of size $\Omega(d/\log d)$. For an $n$-variate polynomial with $n&gt;1$, the result can be improved to $\Omega(nd)$, if $d\leq n$,  or $\Omega(nd \frac{\log n}{\log d})$, if $d\geq n$.
  Under the same assumptions, we also give a quadratic lower bound for the ordered version of the central symmetric polynomial.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T12:43:37Z">Thursday, January 05 2023, 12:43</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/01/05/greatest-hits-2015-2022-part-ii/'>Greatest Hits 2015-2022, Part II</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This is the second part of Greatest Hits 2015-2022, Part I. Here are popular and favorite posts published in 2019-2022. 2019 Supremacy and Sensitivity (and Sunflowers) Test your intuition 38 was contributed in March 2019 by my youngest son Lior. &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>This is the second part of <a href="https://gilkalai.wordpress.com/2023/01/01/greatest-hits-2015-2022-part-i/">Greatest Hits 2015-2022</a>, Part I. Here are popular and favorite posts published in 2019-2022.</p>
<h2>2019 Supremacy and Sensitivity (and Sunflowers)</h2>
<p>Test your intuition 38 was contributed in March 2019 by my youngest son Lior. <a href="https://gilkalai.wordpress.com/2019/03/18/tyi38-lior-kalai-monty-hall-meets-survivor/" rel="bookmark">TYI38 Lior Kalai: Monty Hall MeetsÂ Survivor</a>. Aside from the problem itself, the post contained beautiful pictures of my family, and, two days after the post was published, I added the startling breaking news about Karen Uhlenbeck being awarded the Abel Prize.</p>
<p>Also in March 2019, the post <a href="https://gilkalai.wordpress.com/2019/03/26/10-milestones-in-the-history-of-mathematics-according-to-nati-and-me/" rel="bookmark">10 Milestones in the History of Mathematics according to Nati andÂ Me</a> drew many views and many comments. And in April 2019 I made an unusual invitation:Â  <a href="https://gilkalai.wordpress.com/2019/04/23/an-invitation-to-a-conference-visions-in-mathematics-towards-2000/" rel="bookmark">An Invitation to a Conference: Visions in Mathematics towards 2000,</a> with links to videos and many pictures of us 20 years younger.Â  This followed by a post discussing a bold statement made at the conference by Misha Gromov <a href="https://gilkalai.wordpress.com/2019/04/25/are-natural-mathematical-problems-bad-problems/" rel="bookmark">Are Natural Mathematical Problems Bad Problems?</a></p>
<h3>Quantum supremacy</h3>
<p>In August 2019 I presented a new paper and a CERN colloquium:Â  <a href="https://gilkalai.wordpress.com/2019/08/21/the-argument-against-quantum-computers-a-cern-colloquium-and-a-new-paper/" rel="bookmark">The Argument against Quantum Computers â a CERN Colloquium and a New Paper</a>, a month later on September 22, 2019, a paper by a team from Google was leaked with a demonstration of quantum supremacy, which, if true, would refute my argument. I found the leaked paper rather unconvincing and raised some concerns about it in this post: <a href="https://gilkalai.wordpress.com/2019/09/23/quantum-computers-amazing-progress-google-ibm-and-extraordinary-but-probably-false-supremacy-claims-google/" rel="bookmark">Quantum computers: amazing progress (Google &amp; IBM), and extraordinary but probably false supremacy claimsÂ (Google).</a></p>
<p>Two weeks later I wrote <a href="https://gilkalai.wordpress.com/2019/10/13/the-story-of-poincare-and-his-friend-the-baker/" rel="bookmark">The story of PoincarÃ© and his friend the baker,</a> where I raised another concern regarding the calibration process of the paper, and this concern was amply discussed in the comment section.Â  Following the appearance of the Google paper itself on October 21, 2019, and some responses from the Google team,Â  I wrote on November 11, 2019 a new post <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/" rel="bookmark">Gilâs Collegial Quantum Supremacy Skepticism FAQ.</a> Some further updates and discussion can be found in the Dec. 27 post <a href="https://gilkalai.wordpress.com/2019/12/27/the-google-quantum-supremacy-demo/" rel="bookmark">The Google Quantum Supremacy Demo and the Jerusalem HQCAÂ debate</a>.</p>
<h3>2019 mathematical news</h3>
<p>The mathematical news that was most exciting to me in 2019 was reported in August. <a href="https://gilkalai.wordpress.com/2019/08/23/amazing-ryan-alweiss-shachar-lovett-kewen-wu-jiapeng-zhang-made-dramatic-progress-on-the-sunflower-conjecture/" rel="bookmark">Amazing: Ryan Alweiss, Shachar Lovett, Kewen Wu, Jiapeng Zhang made dramatic progress on the Sunflower Conjecture.</a> This was a problem I had first heard about as an undergraduate, I thought about it over the years, and we ran polymath 10 for attacking it. I also was excited about other possible applications, but did not imagine it would be related to Jeff Kahn and mine expectation threshold conjecture. But indeed it was related: <a href="https://gilkalai.wordpress.com/2019/10/30/amazing-keith-frankston-jeff-kahn-bhargav-narayanan-jinyoung-park-thresholds-versus-fractional-expectation-thresholds/" rel="bookmark">Amazing! Keith Frankston, Jeff Kahn, Bhargav Narayanan, Jinyoung Park: Thresholds versus fractional expectation-thresholds</a>;</p>
<p>Other great results were: <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/" rel="bookmark">Amazing: Hao Huang Proved the SensitivityÂ Conjecture!</a> (July);Â  <a href="https://gilkalai.wordpress.com/2019/05/10/sansation-in-the-morning-news-yaroslav-shitov-counterexamples-to-hedetniemis-conjecture/" rel="bookmark">A sensation in the morning news â Yaroslav Shitov: Counterexamples to Hedetniemiâs conjecture</a> (May); <a href="https://gilkalai.wordpress.com/2019/06/28/another-sensation-annika-heckel-non-concentration-of-the-chromatic-number-of-a-random-graph/" rel="bookmark">Another sensation â Annika Heckel: Non-concentration of the chromatic number of a randomÂ graph</a> (June); <a href="https://gilkalai.wordpress.com/2019/02/02/konstantin-tikhomrov-the-probability-that-a-bernoulli-matrix-is-singular/" rel="bookmark">Konstantin Tikhomirov: The Probability that a Bernoulli Matrix isÂ Singular</a> (February); <a href="https://gilkalai.wordpress.com/2019/09/22/jeff-kahn-and-jinyoung-park-maximal-independent-sets-and-a-new-isoperimetric-inequality-for-the-hamming-cube/" rel="bookmark">Jeff Kahn and Jinyoung Park: Maximal independent sets and a new isoperimetric inequality for the Hamming cube; </a><a href="https://gilkalai.wordpress.com/2019/07/23/matan-harel-frank-mousset-and-wojciech-samotij-and-the-the-infamous-upper-tail-problem/" rel="bookmark">Matan Harel, Frank Mousset, and Wojciech Samotij and the âthe infamous upper tailâ problem; </a><a href="https://gilkalai.wordpress.com/2019/02/16/attila-pors-universality-result-for-tverberg-partitions/" rel="bookmark">Attila Porâs Universality Result for Tverberg Partitions; </a><a href="https://gilkalai.wordpress.com/2019/07/20/isabella-novik-and-hailun-zheng-neighborly-centrally-symmetric-spheres-exist-in-all-dimensions/" rel="bookmark">Isabella Novik and Hailun Zheng: Neighborly centrally symmetric spheres exist in all dimensions!</a>; <a href="https://gilkalai.wordpress.com/2019/03/22/danny-nguyen-and-igor-pak-presburger-arithmetic-problem-solved/" rel="bookmark">Danny Nguyen and Igor Pak: Presburger Arithmetic ProblemÂ Solved!</a> And in number theory <a href="https://gilkalai.wordpress.com/2019/03/09/8866128975287528%c2%b3-8778405442862239%c2%b3-2736111468807040%c2%b3/" rel="bookmark">8866128975287528Â³+(-8778405442862239)Â³+(-2736111468807040)Â³</a>;</p>
<p>We had two great guest posts: <a href="https://gilkalai.wordpress.com/2019/07/17/dan-romik-on-the-riemann-zeta-function/" rel="bookmark">Dan Romik on the Riemann zeta function</a>, and <a href="https://gilkalai.wordpress.com/2019/07/09/imre-barany-limit-shape/" rel="bookmark">Imre BÃ¡rÃ¡ny: Limit shape.</a></p>
<p>In 2019 I also wrote about <a href="https://gilkalai.wordpress.com/2019/01/02/jean/">Jean Bourgain</a> and about <a href="https://gilkalai.wordpress.com/2019/05/01/the-last-paper-of-catherine-renyi-and-alfred-renyi-counting-k-trees/" rel="bookmark">The last paper of Catherine RÃ©nyi and AlfrÃ©d RÃ©nyi: Counting k-Trees.</a></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/talab.png"><img loading="lazy" data-attachment-id="16899" data-permalink="https://gilkalai.wordpress.com/2019/02/16/attila-pors-universality-result-for-tverberg-partitions/rainbow-2/" data-orig-file="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png" data-orig-size="983,711" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rainbow" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=640" class="alignnone  wp-image-16899" src="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=274&#038;h=198" alt="rainbow" width="274" height="198" srcset="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=274&amp;h=198 274w, https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=548&amp;h=396 548w, https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=150&amp;h=108 150w, https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=300&amp;h=217 300w" sizes="(max-width: 274px) 100vw, 274px" /></a></p>
<p><span style="color: #ff0000">A drawing explaining Attila Por&#8217;s construction</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png"><img loading="lazy" data-attachment-id="16725" data-permalink="https://gilkalai.wordpress.com/2019/01/02/jean/jean-joram/" data-orig-file="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png" data-orig-size="1586,1238" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Jean-Joram" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=640" class="alignnone  wp-image-16725" src="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=217&#038;h=169" alt="Jean-Joram" width="217" height="169" srcset="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=217&amp;h=169 217w, https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=434&amp;h=338 434w, https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=150&amp;h=117 150w, https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=300&amp;h=234 300w" sizes="(max-width: 217px) 100vw, 217px" /></a></p>
<p><span style="color: #ff0000">Jean Bourgain and Joram Lindenstrauss</span></p>
<h2>2020 To cheer you up in difficult times</h2>
<h3>Mathematical news</h3>
<p>The post about mathematical news that excited both the readers and me the most appeared in January: <a href="https://gilkalai.wordpress.com/2020/01/17/amazing-zhengfeng-ji-anand-natarajan-thomas-vidick-john-wright-and-henry-yuen-proved-that-mip-re-and-thus-disproved-connes-1976-embedding-conjecture-and-provided-a-negative-answer-to-tsirelso/" rel="bookmark">Amazing: Zhengfeng Ji, Anand Natarajan, Thomas Vidick, John Wright, and Henry Yuen proved that MIP* = RE and thus disproved Connes 1976 Embedding Conjecture, and provided a negative answer to Tsirelsonâs problem.Â </a>My final correspondence with Boris Tsirelson was about this breakthrough and I wrote about him in this post <a href="https://gilkalai.wordpress.com/2020/04/03/trees-not-cubes-memories-of-boris-tsirelson/" rel="bookmark">Trees not Cubes! Memories of BorisÂ Tsirelson</a>.</p>
<p>Two other exciting and popular posts with 2020 major mathematical news came in July and December. The July post was <a href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/" rel="bookmark">To cheer you up in difficult times 7: Bloom and Sisask just broke the logarithm barrier for Rothâs theorem!;</a> And in December <a href="https://gilkalai.wordpress.com/2020/12/21/to-cheer-you-up-in-difficult-times-15-yuansi-chen-achieved-a-major-breakthrough-on-bourgains-slicing-problem-and-the-kannan-lovasz-and-simonovits-conjecture/" rel="bookmark">To Cheer You Up in Difficult Times 15: Yuansi Chen Achieved a Major Breakthrough on Bourgainâs Slicing Problem and the Kannan, LovÃ¡sz and SimonovitsÂ Conjecture</a></p>
<h3>To cheer you up in difficult times (Math news, and fun)</h3>
<p><a href="https://gilkalai.wordpress.com/2020/05/08/to-cheer-you-up-in-difficult-times-3-a-guest-post-by-noam-lifshitz-on-the-new-hypercontractivity-inequality-of-peter-keevash-noam-lifshitz-eoin-long-and-dor-minzer/" rel="bookmark">To cheer you up in difficult times 3: A guest post by Noam Lifshitz on the new hypercontractivity inequality of Peter Keevash, Noam Lifshitz, Eoin Long and Dor Minzer</a>; <a href="https://gilkalai.wordpress.com/2020/05/30/to-cheer-you-up-in-difficult-times-5-a-new-elementary-proof-of-the-prime-number-theorem-by-florian-k-richter/" rel="bookmark">To cheer you up in difficult times 5: A New Elementary Proof of the Prime Number Theorem by Florian K. Richter;</a> <a href="https://gilkalai.wordpress.com/2020/06/26/to-cheer-you-up-in-difficult-times-6-play-rani-sharims-two-player-games-of-life-read-maya-bar-hillel-presentation-on-catching-lies-with-statistics-and-more/" rel="bookmark">To cheer you up in difficult times 6: Play Rani Sharimâs two-player games of life, read Maya Bar-Hillel presentation on catching lies with statistics, andÂ more.</a><a href="https://gilkalai.wordpress.com/2020/08/01/to-cheer-you-up-in-difficult-times-8-nathan-keller-and-ohad-klein-proved-tomaszewskis-conjecture-on-randomly-signed-sums/" rel="bookmark">;To Cheer you up in Difficult Times 8: Nathan Keller and Ohad Klein Proved Tomaszewskiâs Conjecture on Randomly Signed Sums</a>;Â  <a href="https://gilkalai.wordpress.com/2020/08/14/to-cheer-you-up-in-difficult-times-9-alexey-pokrovskiy-proved-that-rotas-basis-conjecture-holds-asymptotically/" rel="bookmark">To cheer you up in difficult times 9: Alexey Pokrovskiy proved that Rotaâs Basis Conjecture holdsÂ asymptotically</a>; <a href="https://gilkalai.wordpress.com/2020/09/23/to-cheer-you-up-in-difficult-times-12-asaf-ferber-and-david-conlon-found-new-lower-bounds-for-diagonal-ramsey-numbers/" rel="bookmark">To cheer you up in difficult times 12: Asaf Ferber and David Conlon found new lower bounds for diagonal Ramsey numbers</a>; <a href="https://gilkalai.wordpress.com/2020/10/11/three-games-to-cheer-you-up/" rel="bookmark">Three games to cheer youÂ up.</a></p>
<p>The first post which explicitly aimed cheering up our readers was from mid-March when it had become clear that the Corvid outbreak is going to overshadow our lives. <a href="https://gilkalai.wordpress.com/2020/03/14/to-cheer-you-up-in-complicated-times-a-book-proof-by-rom-pinchasi-and-alexandr-polyanskii-for-a-1978-conjecture-by-erdos-and-purdy/" rel="bookmark">To cheer you up in complicated times â A book proof by Rom Pinchasi and Alexandr Polyanskii for a 1978 Conjecture by ErdÅs andÂ Purdy!</a></p>
<p>Other mathematical news from 2019 were <a href="https://gilkalai.wordpress.com/2020/01/27/ringel-conjecture-solved-congratulations-to-richard-montgomery-alexey-pokrovskiy-and-benny-sudakov/" rel="bookmark">Ringel Conjecture, Solved! Congratulations to Richard Montgomery, Alexey Pokrovskiy, and Benny Sudakov;</a> In February <a href="https://gilkalai.wordpress.com/2020/02/28/remarkable-new-stochastic-methods-in-abf-ronen-eldan-and-renan-gross-found-a-new-proof-for-kkl-and-settled-a-conjecture-by-talagrand/" rel="bookmark">Remarkable New Stochastic Methods in ABF: Ronen Eldan and Renan Gross Found a New Proof for KKL and Settled a Conjecture by Talagrand;</a> <a href="https://gilkalai.wordpress.com/2020/03/22/kelman-kindler-lifshitz-minzer-and-safra-towards-the-entropy-influence-conjecture/" rel="bookmark">Kelman, Kindler, Lifshitz, Minzer, and Safra: Towards the Entropy-Influence Conjecture</a>; <a href="https://gilkalai.wordpress.com/2020/07/24/noam-lifshitz-a-new-hypercontractivity-inequality-the-proof/" rel="bookmark">Noam Lifshitz: A new hypercontractivity inequality â TheÂ proof!</a></p>
<h3>Quantum news and matters</h3>
<p>In December 2020 I wrote about an attempt to establish quantum supremacy using a photonic device: <a href="https://gilkalai.wordpress.com/2020/12/06/photonic-huge-quantum-advantage/" rel="bookmark">Photonic Huge Quantum AdvantageÂ ???</a>, This time, an algorithm from a 2014 paper by Guy Kindler and me sufficed to refute the fantastic claims. A few days later I wrote <a href="https://gilkalai.wordpress.com/2020/12/29/the-argument-against-quantum-computers-a-very-short-introduction/" rel="bookmark">The Argument Against Quantum Computers â A Very ShortÂ Introduction</a>, which has become one of the blog&#8217;s blockbusters.</p>
<h2>2021 ErdÅs-Faber-LovÃ¡sz and Diverse Matters</h2>
<p><strong>Discussion about Diversity:</strong> the post <a href="https://gilkalai.wordpress.com/2021/09/22/to-cheer-you-up-in-difficult-times-31-federico-ardilas-four-axioms-for-cultivating-diversity/" rel="bookmark">To Cheer You Up in Difficult Times 31: Federico Ardilaâs Four Axioms for Cultivating Diversity</a>, led to heated discussions mainly on Facebook.</p>
<p><strong>Celebrations and discussions:</strong> The post <a href="https://gilkalai.wordpress.com/2021/03/17/cheerful-news-in-difficult-times-the-abel-prize-is-awarded-to-laszlo-lovasz-and-avi-wigderson/" rel="bookmark">Cheerful News in Difficult Times: The Abel Prize is Awarded to LÃ¡szlÃ³ LovÃ¡sz and Avi Wigderson,</a> contains a lot of pictures of Avi and Laci and their families (and in a few cases of my family), and it was followed by the most viewed 2021 post presenting a debate between Avi Wigderson and me, which goes deeply into the connection between (computer science) theory, practice, and mathematics: <a href="https://gilkalai.wordpress.com/2021/04/22/the-probabilistic-proof-that-2400-593-is-a-prime-a-revolutionary-new-type-of-mathematical-proof-or-not-a-proof-at-all/" rel="bookmark">The probabilistic proof that 2^400-593 is a prime: a revolutionary new type of mathematical proof, or not a proof at all?</a></p>
<p><strong>Mathematical news from 2021:</strong> <a href="https://gilkalai.wordpress.com/2021/01/14/to-cheer-you-up-in-difficult-times-17-amazing-the-erdos-faber-lovasz-conjecture-for-large-n-was-proved-by-dong-yeap-kang-tom-kelly-daniela-kuhn-abhishek-methuku-and-deryk-osthus/" rel="bookmark">To cheer you up in difficult times 17: Amazing! The ErdÅs-Faber-LovÃ¡sz conjecture (for large n) was proved by Dong Yeap Kang, Tom Kelly, Daniela KÃ¼hn, Abhishek Methuku, and Deryk Osthus!</a>; <a href="https://gilkalai.wordpress.com/2021/02/08/to-cheer-you-up-in-difficult-times-20-ben-green-presents-super-polynomial-lower-bounds-for-off-diagonal-van-der-waerden-numbers-w3k/" rel="bookmark">To cheer you up in difficult times 20: Ben Green presents super-polynomial lower bounds for off-diagonal van der Waerden numbers W(3,k)</a><a href="https://gilkalai.wordpress.com/2021/02/25/to-cheer-you-up-in-difficult-times-21-giles-gardam-lecture-and-new-result-on-kaplanskys-conjectures/" rel="bookmark">;To cheer you up in difficult times 21: Giles Gardam lecture and new result on Kaplanskyâs conjectures</a>; <a href="https://gilkalai.wordpress.com/2021/09/17/to-cheer-you-up-in-difficult-times-30-irit-dinur-shai-evra-ron-livne-alex-lubotzky-and-shahar-mozes-constructed-locally-testable-codes-with-constant-rate-distance-and-locality/" rel="bookmark">To Cheer you up in difficult times 30: Irit Dinur, Shai Evra, Ron Livne, Alex Lubotzky, and Shahar Mozes Constructed Locally Testable Codes with Constant Rate, Distance, and Locality.</a> <a href="https://gilkalai.wordpress.com/2021/12/11/to-cheer-you-up-in-difficult-times-34-ringel-circle-problem-solved-by-james-davies-chaya-keller-linda-kleist-shakhar-smorodinsky-and-bartosz-walczak/" rel="bookmark">To cheer you up in difficult times 34: Ringel Circle Problem solved by James Davies, Chaya Keller, Linda Kleist, Shakhar Smorodinsky, and Bartosz Walczak;</a> <a href="https://gilkalai.wordpress.com/2021/01/21/amazing-simpler-and-more-general-proofs-for-the-g-theorem-by-stavros-argyrios-papadakis-and-vasiliki-petrotou-and-by-karim-adiprasito-stavros-argyrios-papadakis-and-vasiliki-petrotou/" rel="bookmark">Amazing: Simpler and more general proofs for the g-theorem by Stavros Argyrios Papadakis and Vasiliki Petrotou, and by Karim Adiprasito, Stavros Argyrios Papadakis, and VasilikiÂ Petrotou.</a></p>
<p><strong>Two collections of startling mathematical news:</strong> <a href="https://gilkalai.wordpress.com/2021/05/20/to-cheer-you-up-in-difficult-times-25-some-mathematical-news-part-2/" rel="bookmark">To cheer you up in difficult times 25: some mathematical news! (PartÂ 2)</a> and <a href="https://gilkalai.wordpress.com/2021/03/23/to-cheer-you-up-in-difficult-times-22-some-mathematical-news-part-1/" rel="bookmark">To cheer you up in difficult times 22: some mathematical news! (PartÂ 1)</a></p>
<p><strong>Memorabilia</strong>: <a href="https://gilkalai.wordpress.com/2021/02/19/nostalgia-corner-john-riordans-referee-report-of-my-first-paper/" rel="bookmark">Nostalgia corner: John Riordanâs referee report of my firstÂ paper</a>; Â <a href="https://gilkalai.wordpress.com/2021/05/14/to-cheer-you-up-in-difficult-times-23-the-original-hand-written-slides-of-terry-taos-2015-einstein-lecture-in-jerusalem/" rel="bookmark">To cheer you up in difficult times 23: the original hand-written slides of Terry Taoâs 2015 Einstein Lecture inÂ Jerusalem</a></p>
<p><strong>Quantum matters: Â </strong><a href="https://gilkalai.wordpress.com/2021/03/10/amazing-feng-pan-and-pan-zhang-announced-a-way-to-spoof-classically-simulate-the-googles-quantum-supremacy-circuit/" rel="bookmark">Amazing: Feng Pan and Pan Zhang Announced a Way to âSpoofâ (Classically Simulate) the Googleâs Quantum Supremacy Circuit!;</a> This work and several related works largely (but not fully) refutedÂ  Google&#8217;s 2019 quantum supremacy claim.</p>
<p><strong>Free will:</strong> <a href="https://gilkalai.wordpress.com/2021/08/18/to-cheer-you-up-in-difficult-times-29-free-will-predictability-and-quantum-computers/" rel="bookmark">To cheer you up in difficult times 29: Free will, predictability and quantumÂ computers</a></p>
<p><strong>A post about my papers</strong>:Â  <a href="https://gilkalai.wordpress.com/2021/08/05/let-me-tell-you-about-three-of-my-recent-papers/" rel="bookmark">Let me tell you about three of my recent papers;</a></p>
<p><strong>Open problems:</strong> <a href="https://gilkalai.wordpress.com/2021/01/10/open-problem-session-of-huji-combsem-problem-5-gil-kalai-the-3%e1%b5%88-problem/" rel="bookmark">The 3áµ problem</a>; <a href="https://gilkalai.wordpress.com/2020/11/25/open-problem-session-of-huji-combsem-problem-1-nati-linial-turan-type-theorems-for-simplicial-complexes/" rel="bookmark">Turan type theorems for simplicial complexes.</a></p>
<p><strong>Are we up for a new polymath project?</strong>: <a href="https://gilkalai.wordpress.com/2021/01/29/possible-future-polymath-projects-2009-2021/" rel="bookmark">Possible future Polymath projects (2009,Â 2021)</a></p>
<h2>2022 The expectation threshold conjecture</h2>
<p><strong>Blogging from ICM 2022:</strong>Â  I <a href="https://gilkalai.wordpress.com/category/icm2022/">slowly blogged about various events</a> and lectures from ICM 2022. The most popular post about ICM2022 was about verifying mathematical proofs using computers and especially LEAN: <a href="https://gilkalai.wordpress.com/2022/07/17/icm-2022-kevin-buzzard-the-rise-of-formalism-in-mathematics/" rel="bookmark">ICM 2022. Kevin Buzzard: The Rise of Formalism in Mathematics.</a> I attempted to report on <a href="https://gilkalai.wordpress.com/2022/07/13/icm-2022-langlands-day/" rel="bookmark">ICM 2022: LanglandsÂ Day</a> which I followed on Zoom, and I gave a live report from Helsinki on <a href="https://gilkalai.wordpress.com/2022/07/06/icm-2022-awarding-ceremonies-1/" rel="bookmark">ICM 2022 awarding ceremonies (1)</a>.</p>
<p>Because of Russia&#8217;s invasion of Ukraine, the ICM originally planned for St. Petersburg turned into a virtual event, but the opening ceremonies and lectures of the medalists took place with live audience in Helsinki.</p>
<p><a href="https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png"><img loading="lazy" data-attachment-id="23796" data-permalink="https://gilkalai.wordpress.com/2023/01/05/greatest-hits-2015-2022-part-ii/israeli-del2/" data-orig-file="https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png" data-orig-size="1024,637" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="israeli-del2" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=640" class="alignnone  wp-image-23796" src="https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=389&#038;h=242" alt="israeli-del2" width="389" height="242" srcset="https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=389&amp;h=242 389w, https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=778&amp;h=484 778w, https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=150&amp;h=93 150w, https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=300&amp;h=187 300w, https://gilkalai.files.wordpress.com/2022/12/israeli-del2.png?w=768&amp;h=478 768w" sizes="(max-width: 389px) 100vw, 389px" /></a></p>
<p><span style="color: #ff0000">The Israeli delegation to the 2022 general assembly of the IMU. With Tammy Ziegler and Mina Teicher. </span></p>
<p><strong>The mathematical news that caught most attention:</strong>Â  A conjecture of Jeff Kahn and me is now fully resolved: <a href="https://gilkalai.wordpress.com/2022/04/02/amazing-jinyoung-park-and-huy-tuan-pham-settled-the-expectation-threshold-conjecture/" rel="bookmark">Amazing: Jinyoung Park and Huy Tuan Pham settled the expectation thresholdÂ conjecture!</a>Â  &#8230; and major progress on Frankl&#8217;s conjecture: <a href="https://gilkalai.wordpress.com/2022/11/17/amazing-justin-gilmer-gave-a-constant-lower-bound-for-the-union-closed-sets-conjecture/" rel="bookmark">Amazing: Justin Gilmer gave a constant lower bound for the union-closed sets conjecture</a></p>
<p><strong>Other news</strong>: Â <a href="https://gilkalai.wordpress.com/2022/05/20/oliver-janzer-and-benny-sudakov-settled-the-erdos-sauer-problem/" rel="bookmark">Oliver Janzer and Benny Sudakov Settled the ErdÅs-Sauer Problem; </a> <a href="https://gilkalai.wordpress.com/2022/10/15/boaz-klartag-and-joseph-lehec-the-slice-conjecture-up-to-polylogarithmic-factor/" rel="bookmark">Boâaz Klartag and Joseph Lehec: The Slice Conjecture Up to PolylogarithmicÂ Factor! </a>;</p>
<p><strong>News about polytopes and combinatorial geometry:</strong> <a href="https://gilkalai.wordpress.com/2022/04/29/joshua-hinman-proved-baranys-conjecture-on-face-numbers-of-polytopes-and-lei-xue-proved-a-lower-bound-conjecture-by-grunbaum/" rel="bookmark">Joshua Hinman proved BÃ¡rÃ¡nyâs conjecture on face numbers of polytopes, and Lei Xue proved a lower bound conjecture by GrÃ¼nbaum; </a><a href="https://gilkalai.wordpress.com/2022/10/19/james-davies-every-finite-colouring-of-the-plane-contains-a-monochromatic-pair-of-points-at-an-odd-distance-from-each-other/" rel="bookmark">James Davies: Every finite colouring of the plane contains a monochromatic pair of points at an odd distance from eachÂ other.</a>;Â <a href="https://gilkalai.wordpress.com/2022/03/05/chaim-even-zohar-tsviqa-lakrec-and-ran-tessler-present-the-amplituhedron-bcfw-triangulation/" rel="bookmark">Chaim Even-Zohar, Tsviqa Lakrec, and Ran Tessler present: The Amplituhedron BCFWÂ Triangulation</a>; <a href="https://gilkalai.wordpress.com/2022/08/19/alexander-a-gaifullin-many-27-vertex-triangulations-of-manifolds-like-the-octonionic-projective-plane-not-even-one-was-known-before/" rel="bookmark">Alexander A. Gaifullin: Many 27-vertex Triangulations of Manifolds Like the Octonionic Projective Plane (Not Even One Was KnownÂ Before).</a></p>
<p><strong>Quantum matters:</strong> Â <a href="https://gilkalai.wordpress.com/2022/11/05/inaugural-address-at-the-hungarian-academy-of-science-the-quantum-computer-a-miracle-or-mirage/" rel="bookmark">Inaugural address at the Hungarian Academy of Science: The Quantum Computer â A Miracle orÂ Mirage</a>;</p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T11:01:54Z">Thursday, January 05 2023, 11:01</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=6957'>Cargo Cult Quantum Factoring</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Just days after we celebrated my wife&#8217;s 40th birthday, she came down with COVID, meaning she&#8217;s been isolating and I&#8217;ve been spending almost all my time dealing with our kids. But if experience has taught me anything, it&#8217;s that the quantum hype train never slows down. In the past 24 hours, at least four people [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Just days after we celebrated <a href="https://scottaaronson.blog/?p=6946">my wife&#8217;s 40th birthday</a>, she came down with COVID, meaning she&#8217;s been isolating and I&#8217;ve been spending almost all my time dealing with our kids.</p>



<p>But if experience has taught me anything, it&#8217;s that the quantum hype train never slows down.  In the past 24 hours, at least four people have emailed to ask me about a <a href="https://arxiv.org/abs/2212.12372">new paper</a> entitled &#8220;Factoring integers with sublinear resources on a superconducting quantum processor.&#8221;  Even the security expert Bruce Schneier, while skeptical, took the paper <a href="https://www.schneier.com/blog/archives/2023/01/breaking-rsa-with-a-quantum-computer.html">surprisingly seriously</a>.</p>



<p>The paper claims &#8230; well, it&#8217;s hard to pin down what it claims, but it&#8217;s certainly <em>given many people the impression</em> that there&#8217;s been a decisive advance on how to factor huge integers, and thereby break the RSA cryptosystem, using a near-term quantum computer.  <em>Not</em> by using <a href="https://en.wikipedia.org/wiki/Shor%27s_algorithm">Shor&#8217;s Algorithm</a>, mind you, but by using the deceptively similarly named <a href="https://link.springer.com/chapter/10.1007/3-540-46416-6_24">Schnorr&#8217;s Algorithm</a>.  The latter is a classical algorithm based on lattices, which the authors then &#8220;enhance&#8221; using the heuristic quantum optimization method called <a href="https://arxiv.org/abs/1411.4028">QAOA</a>.</p>



<p>For those who don&#8217;t care to read further, here is my 3-word review:</p>



<h2>No.  Just No.</h2>



<p>And here&#8217;s my slightly longer review:</p>



<p><em>Schnorr â  Shor</em>.  Yes, even when Schnorr&#8217;s algorithm is dubiously âenhancedâ using QAOA&#8212;a quantum algorithm that, incredibly, for all the hundreds of papers written about it, has not yet been convincingly argued to yield any speedup for any problem whatsoever (besides, as it were, the problem of <a href="https://arxiv.org/abs/1602.07674">reproducing its own pattern of errors</a>) (<a href="https://arxiv.org/abs/2208.06909">one possible recent exception</a> from Sami Boulebnane and Ashley Montanaro).</p>



<p>In the new paper, the authors spend page after page saying-without-saying that it <em>might</em> soon become possible to break RSA-2048, using a NISQ (i.e., non-fault-tolerant) quantum computer.  They do so via two time-tested strategems:</p>



<ol>
<li>the detailed exploration of irrelevancies (mostly, optimization of the number of <em>qubits</em>, while ignoring the number of <em>gates</em>), and</li>



<li>complete silence about the <strong>one crucial point</strong>.</li>
</ol>



<p>Then, finally, they come clean about the one crucial point in a single sentence of the Conclusion section:</p>



<blockquote class="wp-block-quote">
<p>It should be pointed out that the quantum speedup of the algorithm is unclear due to the ambiguous convergence of QAOA.</p>
</blockquote>



<p>âUnclearâ is an understatement here.  It seems to me that a miracle would be required for the approach here to yield any benefit at all, compared to just running the classical Schnorr&#8217;s algorithm on your laptop.  And if the latter were able to break RSA, it would&#8217;ve already done so.</p>



<p>All told, this is one of the most actively misleading quantum computing papers Iâve seen in 25 years, and Iâve seen &#8230; many.  Having said that, this actually <em>isn&#8217;t</em> the first time I&#8217;ve encountered the strange idea that the exponential quantum speedup for factoring integers, which we know about from Shorâs algorithm, should somehow ârub offâ onto quantum optimization heuristics that embody none of the actual insights of Shor&#8217;s algorithm, as if by sympathetic magic.  Since this idea needs a name, I&#8217;d hereby like to propose <strong>Cargo Cult Quantum Factoring</strong>.</p>



<p>And with that, I feel I&#8217;ve adequately discharged my duties here to sanity and truth.  If I&#8217;m slow to answer comments, it&#8217;ll be because I&#8217;m dealing with two screaming kids.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T05:06:20Z">Thursday, January 05 2023, 05:06</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01589'>Quantum Feasibility Labeling for NP-complete Vertex Coloring Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Junpeng Zhan</p><p>Many important science and engineering problems can be converted into
NP-complete problems which are of significant importance in computer science
and mathematics. Currently, neither existing classical nor quantum algorithms
can solve these problems in polynomial time. To overcome this difficulty, this
paper proposes a quantum feasibility labeling (QFL) algorithm to label all
possible solutions to the vertex coloring problem, which is a well-known
NP-complete problem. The variational quantum search (VQS) algorithm proposed in
my previous work has been demonstrated, up to 26 qubits, to achieve an
exponential speedup in finding good element(s) from an unstructured database.
Using the labels and the associated possible solutions as input, the VQS can
find all feasible solutions to the vertex coloring problem. The number of
qubits and the circuit depth required by the QFL each is a polynomial function
of the number of vertices, the number of edges, and the number of colors of a
vertex coloring problem. The QFL together with the VQS could be the first
algorithm to solve an NP-complete problem in polynomial time, provided that the
VQS is proved to be efficient for any number of qubits.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Zhan_J/0/1/0/all/0/1">Junpeng Zhan</a></p><p>Many important science and engineering problems can be converted into
NP-complete problems which are of significant importance in computer science
and mathematics. Currently, neither existing classical nor quantum algorithms
can solve these problems in polynomial time. To overcome this difficulty, this
paper proposes a quantum feasibility labeling (QFL) algorithm to label all
possible solutions to the vertex coloring problem, which is a well-known
NP-complete problem. The variational quantum search (VQS) algorithm proposed in
my previous work has been demonstrated, up to 26 qubits, to achieve an
exponential speedup in finding good element(s) from an unstructured database.
Using the labels and the associated possible solutions as input, the VQS can
find all feasible solutions to the vertex coloring problem. The number of
qubits and the circuit depth required by the QFL each is a polynomial function
of the number of vertices, the number of edges, and the number of colors of a
vertex coloring problem. The QFL together with the VQS could be the first
algorithm to solve an NP-complete problem in polynomial time, provided that the
VQS is proved to be efficient for any number of qubits.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01676'>New Lower Bounds against Homogeneous Non-Commutative Circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prerona Chatterjee, Pavel Hrube&#x161;</p><p>We give several new lower bounds on size of homogeneous non-commutative
circuits. We present an explicit homogeneous bivariate polynomial of degree $d$
which requires homogeneous non-commutative circuit of size $\Omega(d/\log d)$.
For an $n$-variate polynomial with $n&gt;1$, the result can be improved to
$\Omega(nd)$, if $d\leq n$, or $\Omega(nd \frac{\log n}{\log d})$, if $d\geq
n$.
</p>
<p>Under the same assumptions, we also give a quadratic lower bound for the
ordered version of the central symmetric polynomial.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_P/0/1/0/all/0/1">Prerona Chatterjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hrubes_P/0/1/0/all/0/1">Pavel Hrube&#x161;</a></p><p>We give several new lower bounds on size of homogeneous non-commutative
circuits. We present an explicit homogeneous bivariate polynomial of degree $d$
which requires homogeneous non-commutative circuit of size $\Omega(d/\log d)$.
For an $n$-variate polynomial with $n&gt;1$, the result can be improved to
$\Omega(nd)$, if $d\leq n$, or $\Omega(nd \frac{\log n}{\log d})$, if $d\geq
n$.
</p>
<p>Under the same assumptions, we also give a quadratic lower bound for the
ordered version of the central symmetric polynomial.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01696'>Parameterised and Fine-grained Subgraph Counting, modulo $2$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Leslie Ann Goldberg, Marc Roth</p><p>Given a class of graphs $\mathcal{H}$, the problem
$\oplus\mathsf{Sub}(\mathcal{H})$ is defined as follows. The input is a graph
$H\in \mathcal{H}$ together with an arbitrary graph $G$. The problem is to
compute, modulo $2$, the number of subgraphs of $G$ that are isomorphic to $H$.
The goal of this research is to determine for which classes $\mathcal{H}$ the
problem $\oplus\mathsf{Sub}(\mathcal{H})$ is fixed-parameter tractable (FPT),
i.e., solvable in time $f(|H|)\cdot |G|^{O(1)}$.
</p>
<p>Curticapean, Dell, and Husfeldt (ESA 2021) conjectured that
$\oplus\mathsf{Sub}(\mathcal{H})$ is FPT if and only if the class of allowed
patterns $\mathcal{H}$ is "matching splittable", which means that for some
fixed $B$, every $H \in \mathcal{H}$ can be turned into a matching (a graph in
which every vertex has degree at most $1$) by removing at most $B$ vertices.
</p>
<p>Assuming the randomised Exponential Time Hypothesis, we prove their
conjecture for (I) all hereditary pattern classes $\mathcal{H}$, and (II) all
tree pattern classes, i.e., all classes $\mathcal{H}$ such that every $H\in
\mathcal{H}$ is a tree.
</p>
<p>We also establish almost tight fine-grained upper and lower bounds for the
case of hereditary patterns (I).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goldberg_L/0/1/0/all/0/1">Leslie Ann Goldberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_M/0/1/0/all/0/1">Marc Roth</a></p><p>Given a class of graphs $\mathcal{H}$, the problem
$\oplus\mathsf{Sub}(\mathcal{H})$ is defined as follows. The input is a graph
$H\in \mathcal{H}$ together with an arbitrary graph $G$. The problem is to
compute, modulo $2$, the number of subgraphs of $G$ that are isomorphic to $H$.
The goal of this research is to determine for which classes $\mathcal{H}$ the
problem $\oplus\mathsf{Sub}(\mathcal{H})$ is fixed-parameter tractable (FPT),
i.e., solvable in time $f(|H|)\cdot |G|^{O(1)}$.
</p>
<p>Curticapean, Dell, and Husfeldt (ESA 2021) conjectured that
$\oplus\mathsf{Sub}(\mathcal{H})$ is FPT if and only if the class of allowed
patterns $\mathcal{H}$ is "matching splittable", which means that for some
fixed $B$, every $H \in \mathcal{H}$ can be turned into a matching (a graph in
which every vertex has degree at most $1$) by removing at most $B$ vertices.
</p>
<p>Assuming the randomised Exponential Time Hypothesis, we prove their
conjecture for (I) all hereditary pattern classes $\mathcal{H}$, and (II) all
tree pattern classes, i.e., all classes $\mathcal{H}$ such that every $H\in
\mathcal{H}$ is a tree.
</p>
<p>We also establish almost tight fine-grained upper and lower bounds for the
case of hereditary patterns (I).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01318'>Implicitization of Biquadratic B\'ezier Triangle and Quadrilateral Surfaces</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jackson Borchardt, Saul Kato</p><p>We produce implicit equations for general biquadratic (order 2x2) B\'ezier
triangle and quadrilateral surface patches and provide function evaluation
code, using modern computing resources to exploit old algebraic construction
techniques.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Borchardt_J/0/1/0/all/0/1">Jackson Borchardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Kato_S/0/1/0/all/0/1">Saul Kato</a></p><p>We produce implicit equations for general biquadratic (order 2x2) B\'ezier
triangle and quadrilateral surface patches and provide function evaluation
code, using modern computing resources to exploit old algebraic construction
techniques.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01394'>Large Matchings in Maximal 1-planar graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Therese Biedl, John Wittnebel</p><p>It is well-known that every maximal planar graph has a matching of size at
least $\tfrac{n+8}{3}$ if $n\geq 14$. In this paper, we investigate similar
matching-bounds for maximal \emph{1-planar} graphs, i.e., graphs that can be
drawn such that every edge has at most one crossing. In particular we show that
every 3-connected simple-maximal 1-planar graph has a matching of size at least
$\tfrac{2n+6}{5}$; the bound decreases to $\tfrac{3n+14}{10}$ if the graph need
not be 3-connected. We also give (weaker) bounds when the graph comes with a
fixed 1-planar drawing or is not simple. All our bounds are tight in the sense
that some graph that satisfies the restrictions has no bigger matching.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Biedl_T/0/1/0/all/0/1">Therese Biedl</a>, <a href="http://arxiv.org/find/math/1/au:+Wittnebel_J/0/1/0/all/0/1">John Wittnebel</a></p><p>It is well-known that every maximal planar graph has a matching of size at
least $\tfrac{n+8}{3}$ if $n\geq 14$. In this paper, we investigate similar
matching-bounds for maximal \emph{1-planar} graphs, i.e., graphs that can be
drawn such that every edge has at most one crossing. In particular we show that
every 3-connected simple-maximal 1-planar graph has a matching of size at least
$\tfrac{2n+6}{5}$; the bound decreases to $\tfrac{3n+14}{10}$ if the graph need
not be 3-connected. We also give (weaker) bounds when the graph comes with a
fixed 1-planar drawing or is not simple. All our bounds are tight in the sense
that some graph that satisfies the restrictions has no bigger matching.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01471'>Freeform Islamic Geometric Patterns</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rebecca Lin, Craig S. Kaplan</p><p>Islamic geometric patterns are a rich and venerable ornamental tradition.
Many classic designs feature periodic arrangements of rosettes: star shapes
surrounded by rings of hexagonal petals. We present a new technique for
generating 'freeform' compositions of rosettes: finite designs that freely mix
rosettes of unusual sizes while retaining the aesthetics of traditional
patterns. We use a circle packing as a scaffolding for developing a patch of
polygons and fill each polygon with a motif based on established constructions
from Islamic art.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1">Rebecca Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaplan_C/0/1/0/all/0/1">Craig S. Kaplan</a></p><p>Islamic geometric patterns are a rich and venerable ornamental tradition.
Many classic designs feature periodic arrangements of rosettes: star shapes
surrounded by rings of hexagonal petals. We present a new technique for
generating 'freeform' compositions of rosettes: finite designs that freely mix
rosettes of unusual sizes while retaining the aesthetics of traditional
patterns. We use a circle packing as a scaffolding for developing a patch of
polygons and fill each polygon with a motif based on established constructions
from Islamic art.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01356'>Provably Fast and Space-Efficient Parallel Biconnectivity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiaojun Dong, Letong Wang, Yan Gu, Yihan Sun</p><p>Biconnectivity is one of the most fundamental graph problems. The canonical
parallel biconnectivity algorithm is the Tarjan-Vishkin algorithm, which has
$O(n+m)$ optimal work (number of operations) and polylogarithmic span (longest
dependent operations) on a graph with $n$ vertices and $m$ edges. However,
Tarjan-Vishkin is not widely used in practice. We believe the reason is the
space-inefficiency (it generates an auxiliary graph with $O(m)$ edges). In
practice, existing parallel implementations are based on breath-first search
(BFS). Since BFS has span proportional to the diameter of the graph, existing
parallel BCC implementations suffer from poor performance on large-diameter
graphs and can be even slower than the sequential algorithm on many real-world
graphs.
</p>
<p>We propose the first parallel biconnectivity algorithm (FAST-BCC) that has
optimal work, polylogarithmic span, and is space-efficient. Our algorithm first
generates a skeleton graph based on any spanning tree of the input graph. Then
we use the connectivity information of the skeleton to compute the
biconnectivity of the original input. All the steps in our algorithm are
highly-parallel. We carefully analyze the correctness of our algorithm, which
is highly non-trivial.
</p>
<p>We implemented FAST-BCC and compared it with existing implementations,
including GBBS, Slota and Madduri's algorithm, and the sequential
Hopcroft-Tarjan algorithm. We ran them on a 96-core machine on 27 graphs,
including social, web, road, $k$-NN, and synthetic graphs, with significantly
varying sizes and edge distributions. FAST-BCC is the fastest on all 27 graphs.
On average (geometric means), FAST-BCC is 5.1$\times$ faster than GBBS, and
3.1$\times$ faster than the best existing baseline on each graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaojun Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Letong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yihan Sun</a></p><p>Biconnectivity is one of the most fundamental graph problems. The canonical
parallel biconnectivity algorithm is the Tarjan-Vishkin algorithm, which has
$O(n+m)$ optimal work (number of operations) and polylogarithmic span (longest
dependent operations) on a graph with $n$ vertices and $m$ edges. However,
Tarjan-Vishkin is not widely used in practice. We believe the reason is the
space-inefficiency (it generates an auxiliary graph with $O(m)$ edges). In
practice, existing parallel implementations are based on breath-first search
(BFS). Since BFS has span proportional to the diameter of the graph, existing
parallel BCC implementations suffer from poor performance on large-diameter
graphs and can be even slower than the sequential algorithm on many real-world
graphs.
</p>
<p>We propose the first parallel biconnectivity algorithm (FAST-BCC) that has
optimal work, polylogarithmic span, and is space-efficient. Our algorithm first
generates a skeleton graph based on any spanning tree of the input graph. Then
we use the connectivity information of the skeleton to compute the
biconnectivity of the original input. All the steps in our algorithm are
highly-parallel. We carefully analyze the correctness of our algorithm, which
is highly non-trivial.
</p>
<p>We implemented FAST-BCC and compared it with existing implementations,
including GBBS, Slota and Madduri's algorithm, and the sequential
Hopcroft-Tarjan algorithm. We ran them on a 96-core machine on 27 graphs,
including social, web, road, $k$-NN, and synthetic graphs, with significantly
varying sizes and edge distributions. FAST-BCC is the fastest on all 27 graphs.
On average (geometric means), FAST-BCC is 5.1$\times$ faster than GBBS, and
3.1$\times$ faster than the best existing baseline on each graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01549'>Matching Using Sufficient Dimension Reduction for Heterogeneity Causal Effect Estimation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Haoran Zhao, Yinghao Zhang, Debo Cheng, Chen Li, Zaiwen Feng</p><p>Causal inference plays an important role in under standing the underlying
mechanisation of the data generation process across various domains. It is
challenging to estimate the average causal effect and individual causal effects
from observational data with high-dimensional covariates due to the curse of
dimension and the problem of data sufficiency. The existing matching methods
can not effectively estimate individual causal effect or solve the problem of
dimension curse in causal inference. To address this challenge, in this work,
we prove that the reduced set by sufficient dimension reduction (SDR) is a
balance score for confounding adjustment. Under the theorem, we propose to use
an SDR method to obtain a reduced representation set of the original covariates
and then the reduced set is used for the matching method. In detail, a
non-parametric model is used to learn such a reduced set and to avoid model
specification errors. The experimental results on real-world datasets show that
the proposed method outperforms the compared matching methods. Moreover, we
conduct an experiment analysis and the results demonstrate that the reduced
representation is enough to balance the imbalance between the treatment group
and control group individuals.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haoran Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinghao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1">Debo Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zaiwen Feng</a></p><p>Causal inference plays an important role in under standing the underlying
mechanisation of the data generation process across various domains. It is
challenging to estimate the average causal effect and individual causal effects
from observational data with high-dimensional covariates due to the curse of
dimension and the problem of data sufficiency. The existing matching methods
can not effectively estimate individual causal effect or solve the problem of
dimension curse in causal inference. To address this challenge, in this work,
we prove that the reduced set by sufficient dimension reduction (SDR) is a
balance score for confounding adjustment. Under the theorem, we propose to use
an SDR method to obtain a reduced representation set of the original covariates
and then the reduced set is used for the matching method. In detail, a
non-parametric model is used to learn such a reduced set and to avoid model
specification errors. The experimental results on real-world datasets show that
the proposed method outperforms the compared matching methods. Moreover, we
conduct an experiment analysis and the results demonstrate that the reduced
representation is enough to balance the imbalance between the treatment group
and control group individuals.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01631'>R\'enyi-Ulam Games and Online Computation with Imperfect Advice</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Spyros Angelopoulos, Shahin Kamali</p><p>We study the nascent setting of online computation with imperfect advice, in
which the online algorithm is enhanced by some prediction encoded in the form
of a possibly erroneous binary string. The algorithm is oblivious to the advice
error, but defines a desired tolerance, namely an upper bound on the number of
erroneous advice bits it can tolerate. This is a model that generalizes the
untrusted advice model [Angelopoulos et al. ITCS 2020], in which the
performance of the algorithm is only evaluated at the extreme values of error
(namely, if the advice has either no errors, or if it is generated
adversarially).
</p>
<p>In this work, we establish connections between games with a lying responder,
also known as R\'enyi-Ulam games, and the design and analysis of online
algorithms with imperfect advice. Specifically, we demonstrate how to obtain
upper and lower bounds on the competitive ratio for well-studied online
problems such as time-series search, online bidding, and fractional knapsack.
Our techniques provide the first lower bounds for online problems in this
model. We also highlight and exploit connections between competitive analysis
with imperfect advice and fault-tolerance in multiprocessor systems. Last, we
show how to waive the dependence on the tolerance parameter, by means of
resource augmentation and robustification.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Angelopoulos_S/0/1/0/all/0/1">Spyros Angelopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamali_S/0/1/0/all/0/1">Shahin Kamali</a></p><p>We study the nascent setting of online computation with imperfect advice, in
which the online algorithm is enhanced by some prediction encoded in the form
of a possibly erroneous binary string. The algorithm is oblivious to the advice
error, but defines a desired tolerance, namely an upper bound on the number of
erroneous advice bits it can tolerate. This is a model that generalizes the
untrusted advice model [Angelopoulos et al. ITCS 2020], in which the
performance of the algorithm is only evaluated at the extreme values of error
(namely, if the advice has either no errors, or if it is generated
adversarially).
</p>
<p>In this work, we establish connections between games with a lying responder,
also known as R\'enyi-Ulam games, and the design and analysis of online
algorithms with imperfect advice. Specifically, we demonstrate how to obtain
upper and lower bounds on the competitive ratio for well-studied online
problems such as time-series search, online bidding, and fractional knapsack.
Our techniques provide the first lower bounds for online problems in this
model. We also highlight and exploit connections between competitive analysis
with imperfect advice and fault-tolerance in multiprocessor systems. Last, we
show how to waive the dependence on the tolerance parameter, by means of
resource augmentation and robustification.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01744'>Dynamic Maintenance of Monotone Dynamic Programs and Applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Monika Henzinger, Stefan Neumann, Harald R&#xe4;cke, Stefan Schmid</p><p>Dynamic programming (DP) is one of the fundamental paradigms in algorithm
design. However, many DP algorithms have to fill in large DP tables,
represented by two-dimensional arrays, which causes at least quadratic running
times and space usages. This has led to the development of improved algorithms
for special cases when the DPs satisfy additional properties like, e.g., the
Monge property or total monotonicity.
</p>
<p>In this paper, we consider a new condition which assumes (among some other
technical assumptions) that the rows of the DP table are monotone. Under this
assumption, we introduce a novel data structure for computing
$(1+\varepsilon)$-approximate DP solutions in near-linear time and space in the
static setting, and with polylogarithmic update times when the DP entries
change dynamically. To the best of our knowledge, our new condition is
incomparable to previous conditions and is the first which allows to derive
dynamic algorithms based on existing DPs. Instead of using two-dimensional
arrays to store the DP tables, we store the rows of the DP tables using
monotone piecewise constant functions. This allows us to store length-$n$ DP
table rows with entries in $[0,W]$ using only polylog$(n,W)$ bits, and to
perform operations, such as $(\min,+)$-convolution or rounding, on these
functions in polylogarithmic time.
</p>
<p>We further present several applications of our data structure. For bicriteria
versions of $k$-balanced graph partitioning and simultaneous source location,
we obtain the first dynamic algorithms with subpolynomial update times, as well
as the first static algorithms using only near-linear time and space.
Additionally, we obtain the currently fastest algorithm for fully dynamic
knapsack.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1">Monika Henzinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_S/0/1/0/all/0/1">Stefan Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Racke_H/0/1/0/all/0/1">Harald R&#xe4;cke</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a></p><p>Dynamic programming (DP) is one of the fundamental paradigms in algorithm
design. However, many DP algorithms have to fill in large DP tables,
represented by two-dimensional arrays, which causes at least quadratic running
times and space usages. This has led to the development of improved algorithms
for special cases when the DPs satisfy additional properties like, e.g., the
Monge property or total monotonicity.
</p>
<p>In this paper, we consider a new condition which assumes (among some other
technical assumptions) that the rows of the DP table are monotone. Under this
assumption, we introduce a novel data structure for computing
$(1+\varepsilon)$-approximate DP solutions in near-linear time and space in the
static setting, and with polylogarithmic update times when the DP entries
change dynamically. To the best of our knowledge, our new condition is
incomparable to previous conditions and is the first which allows to derive
dynamic algorithms based on existing DPs. Instead of using two-dimensional
arrays to store the DP tables, we store the rows of the DP tables using
monotone piecewise constant functions. This allows us to store length-$n$ DP
table rows with entries in $[0,W]$ using only polylog$(n,W)$ bits, and to
perform operations, such as $(\min,+)$-convolution or rounding, on these
functions in polylogarithmic time.
</p>
<p>We further present several applications of our data structure. For bicriteria
versions of $k$-balanced graph partitioning and simultaneous source location,
we obtain the first dynamic algorithms with subpolynomial update times, as well
as the first static algorithms using only near-linear time and space.
Additionally, we obtain the currently fastest algorithm for fully dynamic
knapsack.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-05T01:30:00Z">Thursday, January 05 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, January 04
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/'>Logicians are Everywhere</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          So where were they between 1720 and 1820? Helena Rasiowa was a famous logician from Poland. She visited Case Western Reserve University when I was an undergraduate a million years ago&#8212;in the 1960s. I have always loved mathematical logic. I took undergraduate courses with two famous logicians. Richard Vesley taught me my first logic course [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>So where were they between 1720 and 1820?</em><br />
<font color="#000000"></p>
<p>
Helena Rasiowa was a famous <a href="https://en.wikipedia.org/wiki/Helena_Rasiowa">logician</a> from Poland. She visited Case Western Reserve University when I was an undergraduate a million years ago&#8212;in the 1960s. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/helen/" rel="attachment wp-att-20741"><img data-attachment-id="20741" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/helen/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/helen.jpg?fit=220%2C294&amp;ssl=1" data-orig-size="220,294" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="helen" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/helen.jpg?fit=220%2C294&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/helen.jpg?fit=220%2C294&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/helen.jpg?resize=150%2C200&#038;ssl=1" alt="" width="150" height="200" class="aligncenter wp-image-20741" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/helen.jpg?w=220&amp;ssl=1 220w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/helen.jpg?resize=150%2C200&amp;ssl=1 150w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1" /></a></p>
<p>
I have always loved mathematical logic. I took undergraduate courses with two famous logicians. Richard Vesley taught me my first logic course at Case. I later took an advanced course there, also as an undergraduate, from Rasiowa. Vesley became a Professor in the University at Buffalo mathematics department, where Ken also knew him before he passed away in 2016.</p>
<p>
One of my memories from her class is about a statement. One day in class we were stuck on a tricky insight and we as a class were asking lots of questions. Perhaps too many. She finally said:</p>
<blockquote><p><b> </b> <em> <i>&#8220;You will understand.&#8221;</i> </em>
</p></blockquote>
<p><p>
I still recall this like it happened yesterday. She was eventually right. But at the time we were scared that we might have trouble getting it.</p>
<p>
<p><H2> Logicians Named Lewis Are Everywhere </H2></p>
<p><p>
Rasiowa&#8217;s dissertation was titled <i>Algebraic Treatment of the Functional Calculus of Lewis and Heyting</i>. The names are <a href="https://en.wikipedia.org/wiki/C._I._Lewis">Clarence Lewis</a> and Arend Heyting. Although Lewis was American, he adopted the British habit of going by his initials as C.I. Lewis. This made him confusable with C.S. Lewis, the writer Clive Lewis in this blog&#8217;s style. </p>
<p>
An unrelated Lewis is Harry Lewis, who is an American computer scientist known for his research in logic&#8212;and for books on theoretical computer science, computing, higher education, and technology. He is the Gordon McKay Professor of Computer Science at Harvard University, and was Dean of Harvard College from 1995 to 2003. </p>
<p>
Another logician named Lewis whom I could have known at Princeton was <a href="https://en.wikipedia.org/wiki/David_Lewis_(philosopher)">David Lewis</a>. He is best known in logic for rigorizing <em>counterfactual conditionals</em>. An example he <a href="https://en.wikipedia.org/wiki/David_Lewis_(philosopher)#Counterfactuals_and_modal_realism">gave</a> is, &#8220;if kangaroos had no tails, they would topple over.&#8221; In complexity theory, many results are like, &#8220;if pigs could whistle then horses could fly.&#8221; Scott Aaronson wrote about one such result <a href="https://books.google.com/books?id=pYggAwAAQBAJ&#038;pg=PA86&#038;lpg=PA86&#038;dq=if+donkeys+could+whistle,+then+pigs+could+fly+complexity&#038;source=bl&#038;ots=OcEzjHP2XX&#038;sig=ACfU3U0mWxqt8ShA90_Ni5lSIWhmWAeOMQ&#038;hl=en&#038;sa=X&#038;ved=2ahUKEwiisbbunar8AhVcEGIAHccLCtEQ6AF6BAgtEAM]">here</a>. Maybe we could have used Lewis to organize the logic of these results. </p>
<p>
Lewis is also famous for actuating the condition of the implication &#8220;if a cat could get a published paper then &#8230;&#8221; His pet named Bruce Le Catt was credited for <a href="https://www.tandfonline.com/doi/abs/10.1080/00048408212340581">this article</a> until the journal <a href="https://www.science.org/content/article/philosophy-journal-corrects-35-year-old-article-written-cat">recently</a> corrected it. The Cheshire Cat&#8212;</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/cat/" rel="attachment wp-att-20746"><img data-attachment-id="20746" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/cat/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?fit=224%2C225&amp;ssl=1" data-orig-size="224,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cat" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?fit=224%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?fit=224%2C225&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?resize=150%2C150&#038;ssl=1" alt="" width="150" height="150" class="aligncenter wp-image-20746" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?w=224&amp;ssl=1 224w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/cat.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">Wikipedia <a href="https://en.wikipedia.org/wiki/Cheshire_Cat">src</a></FONT>
</td>
</tr>
</table>
<p>
&#8212;brings up another logical Lewis: Lewis Carroll. Well, in this blog&#8217;s style he is Charles Dodgson. By whichever name, his work in mathematical logic was <a href="https://iep.utm.edu/lewis-carroll-logic/">substantial</a>.</p>
<p>
Our point is, there have been so many logicians in the past century-plus that we can point to several with the same name. But that was not always the case. There is a previous century-plus when we can find hardly any logicians at all. To explain why this surprises us, we need to go back further, to Gottfried <a href="https://en.wikipedia.org/wiki/Gottfried_Wilhelm_Leibniz">Leibniz</a>.</p>
<p>
<p><H2> Leibniz </H2></p>
<p><p>
Leibniz was of course one of the great mathematicians of all time. He published nothing on formal logic in his lifetime&#8212;he wrote only working drafts. Bertrand Russell claimed that Leibniz had developed logic in his drafts to a level which was reached only two centuries later.</p>
<p>
Harry Lewis wrote a <a href="https://www.amazon.com/Leibniz-Binary-Invention-Computer-Arithmetic-ebook/dp/B09R717JLY">book</a> with Lloyd Strickland titled <i>Leibniz on Binary: The Invention of Computer Arithmetic</i>. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/lewisandstrickland/" rel="attachment wp-att-20744"><img data-attachment-id="20744" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/lewisandstrickland/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/LewisAndStrickland.png?fit=374%2C203&amp;ssl=1" data-orig-size="374,203" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="LewisAndStrickland" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/LewisAndStrickland.png?fit=300%2C163&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/LewisAndStrickland.png?fit=374%2C203&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/LewisAndStrickland.png?resize=226%2C120&#038;ssl=1" alt="" width="226" height="120" class="aligncenter wp-image-20744" data-recalc-dims="1" /></a></p>
<p>
Harry&#8217;s <a href="https://lewis.seas.harvard.edu/">website</a> says about it:</p>
<blockquote><p><b> </b> <em> The definitive edition and translation of 32 of Leibniz&#8217;s works on binary arithmetic. He works out all the arithmetic operations, and realizes that base-16 would be a more usable notation, so invents several different notations for what we now call the hexadecimal digits.</p>
<p>
Leibniz may have been the first computer scientist and information theorist. Early in life, he documented the binary numeral system (base 2), then revisited that system throughout his career. </em>
</p></blockquote>
<p><p>
<a href="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/lei/" rel="attachment wp-att-20743"><img data-attachment-id="20743" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/lei/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/lei.jpg?fit=350%2C500&amp;ssl=1" data-orig-size="350,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lei" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/lei.jpg?fit=210%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/lei.jpg?fit=350%2C500&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/lei.jpg?resize=175%2C250&#038;ssl=1" alt="" width="175" height="250" class="aligncenter wp-image-20743" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/lei.jpg?w=350&amp;ssl=1 350w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/lei.jpg?resize=210%2C300&amp;ssl=1 210w" sizes="(max-width: 175px) 100vw, 175px" data-recalc-dims="1" /></a></p>
<p>
Among testimonials on the book&#8217;s MIT Press <a href="https://mitpress.mit.edu/9780262544344/leibniz-on-binary/">page</a> is this by Donald Knuth:</p>
<blockquote><p><b> </b> <em> &#8220;This book is a model of how the history of computer science and mathematics should be written. Leibniz pointed out the importance of putting ourselves into the place of others, and here we get to put ourselves into the shoes of Leibniz himself, as we&#8217;re treated to dozens of his private notes, carefully translated into idiomatic English and thoroughly explained.&#8221; </em>
</p></blockquote>
<p><p>
The publisher&#8217;s description, echoed on the book&#8217;s Amazon <a href="https://www.amazon.com/Leibniz-Binary-Invention-Computer-Arithmetic/dp/0262544342/">page</a>, chimes in about readability:</p>
<blockquote><p><b> </b> <em> The [translated] texts are prefaced by a lengthy and detailed introductory essay, in which Strickland and Lewis trace Leibniz&#8217;s development of binary, place it in its historical context, and chart its posthumous influence, most notably on shaping our own computer age. </em>
</p></blockquote>
<p>
<p><H2> A Historical Logic Gap? </H2></p>
<p><p>
The &#8220;shaping of the computer age&#8221; seems to have started no earlier than the work of Charles Babbage on mechanical computation beginning in the 1820s. Even so, Babbage&#8217;s <a href="https://en.wikipedia.org/wiki/Difference_engine">Difference Engine</a> dealt only with numerical calculations. It took his later <a href="https://en.wikipedia.org/wiki/Analytical_Engine">Analytical Engine</a> to involve programming logic as we conceive it. </p>
<p>
Ken has had several thoughts along these lines, going back to his graduate student days at Merton College, Oxford University:</p>
<ul>
<li>
The Merton College Library had one half-height stack of mathematics books. Shelved right alongside modern texts&#8212;this was the early 1980s&#8212;was an 1854 first edition of George Boole&#8217;s book <a href="https://en.wikipedia.org/wiki/The_Laws_of_Thought">The Laws of Thought</a>. We refer to <em>Boolean logic</em> and <em>Boolean algebra</em> because of this book. These terms came from a book placed with the moderns, not from the centuries-older books growing out of Aristotle and other Classical-era works that Ken could find in the grand <a href="https://en.wikipedia.org/wiki/Merton_College_Library">Upper Library</a>. This struck Ken as a warp of time. </p>
<li>
Ken says that the watershed for <em>doing computational logic</em> is realizing that NAND and NOR are universal gates. The older name for NAND is the <a href="https://en.wikipedia.org/wiki/Sheffer_stroke">Sheffer stroke</a>, after the American logician Henry Sheffer. But that wasn&#8217;t until <b>1913</b>, when Russell and Alfred Whitehead picked it up. The polymath Charles Peirce had discovered this about NAND and NOR in the 1880s, so NOR is also called the <em>Peirce Arrow</em>. He also conceived electrical implemenation of AND and OR:
</ul>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/peircedrawing1886/" rel="attachment wp-att-20742"><img data-attachment-id="20742" data-permalink="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/peircedrawing1886/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/PeirceDrawing1886.png?fit=537%2C267&amp;ssl=1" data-orig-size="537,267" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PeirceDrawing1886" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/PeirceDrawing1886.png?fit=300%2C149&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/PeirceDrawing1886.png?fit=537%2C267&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/PeirceDrawing1886.png?resize=400%2C200&#038;ssl=1" alt="" width="400" height="200" class="aligncenter wp-image-20742" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/PeirceDrawing1886.png?w=537&amp;ssl=1 537w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/PeirceDrawing1886.png?resize=300%2C149&amp;ssl=1 300w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">Advent of Computers <a href="http://adventofcomputers.weebly.com/boolean-logic-the-core-of-computer-science.html">source</a></FONT>
</td>
</tr>
</table>
<p>The century-plus between Leibniz and Babbage had Leonhard Euler. It had Carl Gauss. It had all the Bernoullis. It had Joseph-Louis Lagrange, Augustin-Louis Cauchy, Adrien-Marie Legendre, Jean-Baptiste Fourier, and Marie-Sophie Germain. But where are the logicians? As we quoted Russell above, Leibniz&#8217;s preliminary work connects only to two centuries later. </p>
<p>
So why the gap? That is the puzzle. One further question is how close Leibniz came to perceiving the universality of NAND and its significance. Harry, who also drew the Peirce drawing to our attention, tells us that Leibniz invented XOR and also wrote bitwise AND for binary strings. Another is how far back the ideas of <a href="https://en.wikipedia.org/wiki/Polish_notation">Polish notation</a> go. Gottlob Frege anticipated it, but that was still in the late 1800s. Polish notation and its reverse form have had enduring value in programming and compilation since <a href="https://en.wikipedia.org/wiki/Jan_Lukasiewicz">Jan &#321;ukasiewicz</a> invented the notation in 1924. Being taught by Rasiowa in the 1960s brought me closer to the origins of these logical fundamentals than I might expect, on historical reflection.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Are you puzzled by the gap? Can you explain it? </p>
<p>
How might history have changed if the French greats had developed Boolean logic? For some jokes, spelling Louis in their names as Lewis might have helped. There are no US Senators named Lewis, though the introducer at Monday&#8217;s Rose Bowl tried to <a href="https://www.msn.com/en-us/sports/ncaafb/football-world-reacts-to-embarrassing-rose-bowl-mistake/">create</a> one. Not jokes: both Leibniz and C.I. Lewis figure in <a href="https://en.wikipedia.org/wiki/David_Lewis_(philosopher)#Realism_about_possible_worlds">this section</a> of Wikipedia&#8217;s bio of David Lewis. Maybe now the rapper <a href="https://en.wikipedia.org/wiki/Louis_Logic">Louis Logic</a> will help people named Louis catch up&#8212;to the logician <a href="https://homepages.math.uic.edu/lhls/">Louise Hay</a>, whom Ken knew when she visited <a href="https://rjlipton.wpcomstaging.com/2021/01/01/peter-m-neumann-1940-2020/">Peter Neumann</a> and others at Oxford.</p>
<p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-04T05:27:13Z">Wednesday, January 04 2023, 05:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00995'>Unconditional Quantum Advantage for Sampling with Shallow Circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adam Bene Watts, Natalie Parham</p><p>Recent work by Bravyi, Gosset, and Koenig showed that there exists a search
problem that a constant-depth quantum circuit can solve, but that any
constant-depth classical circuit with bounded fan-in cannot. They also pose the
question: can we achieve a similar proof of separation for an input-independent
sampling task? In this paper, we show that the answer to this question is yes.
</p>
<p>We introduce a distribution $D_{n}$ and give a constant-depth, $n$ qubit,
quantum circuit that samples from a distribution close to $D_{n}$ in total
variation distance. For any $\delta &lt; 1$ we also prove, unconditionally, that
any classical circuit with bounded fan-in gates that takes as input $n +
n^\delta$ uniformly random bits and produces output close to $D_{n}$ in total
variation distance has depth $\Omega(\log \log n)$. This gives an unconditional
proof that constant-depth quantum circuits can sample from distributions which
can't be reproduced by constant-depth bounded fan-in classical circuits, even
up to additive error.
</p>
<p>The distribution $D_n$ and classical circuit lower bounds are based on work
of Viola, in which he shows a different (but related) distribution cannot be
sampled from approximately by constant-depth bounded fan-in classical circuits.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Watts_A/0/1/0/all/0/1">Adam Bene Watts</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Parham_N/0/1/0/all/0/1">Natalie Parham</a></p><p>Recent work by Bravyi, Gosset, and Koenig showed that there exists a search
problem that a constant-depth quantum circuit can solve, but that any
constant-depth classical circuit with bounded fan-in cannot. They also pose the
question: can we achieve a similar proof of separation for an input-independent
sampling task? In this paper, we show that the answer to this question is yes.
</p>
<p>We introduce a distribution $D_{n}$ and give a constant-depth, $n$ qubit,
quantum circuit that samples from a distribution close to $D_{n}$ in total
variation distance. For any $\delta &lt; 1$ we also prove, unconditionally, that
any classical circuit with bounded fan-in gates that takes as input $n +
n^\delta$ uniformly random bits and produces output close to $D_{n}$ in total
variation distance has depth $\Omega(\log \log n)$. This gives an unconditional
proof that constant-depth quantum circuits can sample from distributions which
can't be reproduced by constant-depth bounded fan-in classical circuits, even
up to additive error.
</p>
<p>The distribution $D_n$ and classical circuit lower bounds are based on work
of Viola, in which he shows a different (but related) distribution cannot be
sampled from approximately by constant-depth bounded fan-in classical circuits.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-04T01:30:00Z">Wednesday, January 04 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00849'>Small-World Formation via Local Information</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Soroush Alamdari</p><p>It is observed that in a society almost anyone is acquainted with almost
anyone else through only a few intermediary links. This is known as the
small-world phenomenon. In this paper we investigate this observation from a
theoretical stand-point by imagining each individual as a greedy agent
satisfying a drive for knowledge by acquiring links that cost to maintain. We
show that in such a setting small-world properties emerge naturally.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alamdari_S/0/1/0/all/0/1">Soroush Alamdari</a></p><p>It is observed that in a society almost anyone is acquainted with almost
anyone else through only a few intermediary links. This is known as the
small-world phenomenon. In this paper we investigate this observation from a
theoretical stand-point by imagining each individual as a greedy agent
satisfying a drive for knowledge by acquiring links that cost to maintain. We
show that in such a setting small-world properties emerge naturally.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-04T01:30:00Z">Wednesday, January 04 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00996'>Transactional Composition of Nonblocking Data Structures</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Wentao Cai, Haosen Wen, Michael L. Scott</p><p>This paper introduces nonblocking transaction composition (NBTC), a new
methodology for atomic composition of nonblocking operations on concurrent data
structures. Unlike previous software transactional memory (STM) approaches,
NBTC leverages the linearizability of existing nonblocking structures, reducing
the number of memory accesses that must be executed together, atomically, to
only one per operation in most cases (these are typically the linearizing
instructions of the constituent operations).
</p>
<p>Our obstruction-free implementation of NBTC, which we call Medley, makes it
easy to transform most nonblocking data structures into transactional
counterparts while preserving their nonblocking liveness and high concurrency.
In our experiments, Medley outperforms Lock-Free Transactional Transform
(LFTT), the fastest prior competing methodology, by 40--170%. The marginal
overhead of Medley's transactional composition, relative to separate operations
performed in succession, is roughly 2.2$\times$.
</p>
<p>For persistent data structures, we observe that failure atomicity for
transactions can be achieved "almost for free" with epoch-based periodic
persistence. Toward that end, we integrate Medley with nbMontage, a general
system for periodically persistent data structures. The resulting txMontage
provides ACID transactions and achieves throughput up to two orders of
magnitude higher than that of the OneFile persistent STM system.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1">Wentao Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1">Haosen Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Scott_M/0/1/0/all/0/1">Michael L. Scott</a></p><p>This paper introduces nonblocking transaction composition (NBTC), a new
methodology for atomic composition of nonblocking operations on concurrent data
structures. Unlike previous software transactional memory (STM) approaches,
NBTC leverages the linearizability of existing nonblocking structures, reducing
the number of memory accesses that must be executed together, atomically, to
only one per operation in most cases (these are typically the linearizing
instructions of the constituent operations).
</p>
<p>Our obstruction-free implementation of NBTC, which we call Medley, makes it
easy to transform most nonblocking data structures into transactional
counterparts while preserving their nonblocking liveness and high concurrency.
In our experiments, Medley outperforms Lock-Free Transactional Transform
(LFTT), the fastest prior competing methodology, by 40--170%. The marginal
overhead of Medley's transactional composition, relative to separate operations
performed in succession, is roughly 2.2$\times$.
</p>
<p>For persistent data structures, we observe that failure atomicity for
transactions can be achieved "almost for free" with epoch-based periodic
persistence. Toward that end, we integrate Medley with nbMontage, a general
system for periodically persistent data structures. The resulting txMontage
provides ACID transactions and achieves throughput up to two orders of
magnitude higher than that of the OneFile persistent STM system.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-04T01:30:00Z">Wednesday, January 04 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01068'>Fast Parallel Algorithms for Enumeration of Simple, Temporal, and Hop-Constrained Cycles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jovan Blanu&#x161;a (1 and 2), Kubilay Atasu (1), Paolo Ienne (2) ((1) IBM Research Europe - Zurich, (2) &#xc9;cole Polytechnique F&#xe9;d&#xe9;rale de Lausanne)</p><p>Finding cycles in directed graphs enables important applications in various
domains such as finance, biology, chemistry, and network science. However, as
the size of graph datasets continues to grow, it becomes increasingly difficult
to discover cycles within them, which necessitates more efficient algorithms
and their parallel implementations. In this work, we propose scalable
parallelisation of state-of-the-art sequential algorithms for enumerating
simple, temporal, and hop-constrained cycles. First, we focus on the simple
cycle enumeration problem and parallelise the algorithms by Johnson and by Read
and Tarjan in a fine-grained manner. We theoretically show that our resulting
fine-grained parallel algorithms are scalable, with the fine-grained parallel
Read-Tarjan algorithm being strongly scalable. In contrast, we show that
straightforward coarse-grained parallel versions of these simple cycle
enumeration algorithms that exploit edge- or vertex-level parallelism are not
scalable. Next, we adapt our fine-grained approach to enable scalable
parallelisation of state-of-the-art algorithms for temporal and hop-constrained
cycle enumeration. Our evaluation on a cluster with 256 physical cores
demonstrates a near-linear scalability of our fine-grained parallel algorithms
when enumerating all the aforementioned types of cycles. On the same cluster,
our fine-grained parallel algorithms achieve, on average, one order of
magnitude speedup compared to the respective coarse-grained parallel versions
of the state-of-the-art algorithms for cycle enumeration. The performance gap
between the fine-grained and the coarse-grained parallel algorithms increases
as we use more CPU cores.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blanusa_J/0/1/0/all/0/1">Jovan Blanu&#x161;a</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Atasu_K/0/1/0/all/0/1">Kubilay Atasu</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Ienne_P/0/1/0/all/0/1">Paolo Ienne</a> (2) ((1) IBM Research Europe - Zurich, (2) &#xc9;cole Polytechnique F&#xe9;d&#xe9;rale de Lausanne)</p><p>Finding cycles in directed graphs enables important applications in various
domains such as finance, biology, chemistry, and network science. However, as
the size of graph datasets continues to grow, it becomes increasingly difficult
to discover cycles within them, which necessitates more efficient algorithms
and their parallel implementations. In this work, we propose scalable
parallelisation of state-of-the-art sequential algorithms for enumerating
simple, temporal, and hop-constrained cycles. First, we focus on the simple
cycle enumeration problem and parallelise the algorithms by Johnson and by Read
and Tarjan in a fine-grained manner. We theoretically show that our resulting
fine-grained parallel algorithms are scalable, with the fine-grained parallel
Read-Tarjan algorithm being strongly scalable. In contrast, we show that
straightforward coarse-grained parallel versions of these simple cycle
enumeration algorithms that exploit edge- or vertex-level parallelism are not
scalable. Next, we adapt our fine-grained approach to enable scalable
parallelisation of state-of-the-art algorithms for temporal and hop-constrained
cycle enumeration. Our evaluation on a cluster with 256 physical cores
demonstrates a near-linear scalability of our fine-grained parallel algorithms
when enumerating all the aforementioned types of cycles. On the same cluster,
our fine-grained parallel algorithms achieve, on average, one order of
magnitude speedup compared to the respective coarse-grained parallel versions
of the state-of-the-art algorithms for cycle enumeration. The performance gap
between the fine-grained and the coarse-grained parallel algorithms increases
as we use more CPU cores.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-04T01:30:00Z">Wednesday, January 04 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.01084'>Reducing Maximum Weighted Matching to the Largest Cardinality Matching in CONGEST</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vahan Mkrtchyan</p><p>In this paper, we reduce the maximum weighted matching problem to the largest
cardinality matching in {\bf CONGEST}. The paper presents two technical
contributions. The first of them is a simple $poly(\log n,
\frac{1}{\varepsilon}, t, \ln w_t)$-round {\bf CONGEST} algorithm for reducing
the maximum weighted matching problem to the largest cardinality matching
problem. This is achieved under the assumption that all vertices know all
edge-weights $\{w_1,....,w_t\}$ (in particular, they know $t$, the number of
different edge-weights), though a particular vertex may not know the weight of
a particular edge. Our second ingredient is a simple rounding algorithm
(similar to approximation algorithms for the bin packing problem) allowing to
reduce general instances of the maximum weighted matching problem to ones
satisfying the assumptions of the first ingredient, in which $t\leq poly'(\log
n, \frac{1}{\varepsilon})$. We end the paper with a brief discussion of
implementing our algorithms in {\bf CONGEST}. Our main conclusion is that we
just need constant rounds for the reduction.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mkrtchyan_V/0/1/0/all/0/1">Vahan Mkrtchyan</a></p><p>In this paper, we reduce the maximum weighted matching problem to the largest
cardinality matching in {\bf CONGEST}. The paper presents two technical
contributions. The first of them is a simple $poly(\log n,
\frac{1}{\varepsilon}, t, \ln w_t)$-round {\bf CONGEST} algorithm for reducing
the maximum weighted matching problem to the largest cardinality matching
problem. This is achieved under the assumption that all vertices know all
edge-weights $\{w_1,....,w_t\}$ (in particular, they know $t$, the number of
different edge-weights), though a particular vertex may not know the weight of
a particular edge. Our second ingredient is a simple rounding algorithm
(similar to approximation algorithms for the bin packing problem) allowing to
reduce general instances of the maximum weighted matching problem to ones
satisfying the assumptions of the first ingredient, in which $t\leq poly'(\log
n, \frac{1}{\varepsilon})$. We end the paper with a brief discussion of
implementing our algorithms in {\bf CONGEST}. Our main conclusion is that we
just need constant rounds for the reduction.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-04T01:30:00Z">Wednesday, January 04 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, January 03
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/01/03/memento-and-large-language-models/'>Memento and Large Language Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          [Mild spoilers for the 2000 film Memento. See this doc for the full ChatGPT transcripts. &#8211;Boaz] Leonard Shelbey, the protagonist of Christopher Nolan&#8217;s film &#8220;Memento&#8220;, suffers from anterograde amnesia. He remembers everything up to the time in which he was the victim of a violent attack, but cannot form new memories after that. He uses &#8230; Continue reading Memento and Large Language&#160;Models
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><em>[Mild spoilers for the 2000 film <a href="https://en.wikipedia.org/wiki/Memento_(film)">Memento</a>. See <a href="https://docs.google.com/document/d/1-yNQgFiEjY_Q0llmN9LUt4HKD_Ag5xHTFWqb-Idqyiw/edit?usp=sharing">this doc</a> for the full ChatGPT transcripts. &#8211;Boaz]</em></p>



<p>Leonard Shelbey, the protagonist of Christopher Nolan&#8217;s film &#8220;<a href="https://www.imdb.com/title/tt0209144/">Memento</a>&#8220;, suffers from <a href="https://en.wikipedia.org/wiki/Anterograde_amnesia">anterograde amnesia</a>. He remembers everything up to the time in which he was the victim of a violent attack, but cannot form new memories after that. He uses notes, polaroid photos, and tattoos to communicate the most important facts to his future self. (See also Suzanne Corkin&#8217;s book <a href="https://www.amazon.com/Permanent-Present-Tense-Unforgettable-Amnesic/dp/0465031595">&#8220;Permanent Present Tense&#8221;</a> for the real-life story of &#8220;Patient H.M.&#8221; &#8211; Henry Molaison &#8211; who suffered from anterograde and retrograde amnesia.)</p>



<p>Large language models such as the one powering <a href="https://openai.com/blog/chatgpt/">ChatGPT</a> can be thought of as suffering from a similar affliction. They remember everything up to the point at which their training stopped. After that, in inference, they can get X tokens (which roughly correspond to 0.75X words) and produce Y tokens as output, with X+Y â¤ 2048. In particular, this means that they can only remember a very short context of less than 2000 words, and cannot recall it after it&#8217;s done.</p>



<p>For example, if we ask ChatGPT to describe an event that happened after its training ended in 2021, it will either refuse or simply &#8220;fib&#8221;, as it does when given the query:</p>



<blockquote class="wp-block-quote">
<p><strong>Q: </strong>Write a poem about the World Cup final game in Qatar</p>
</blockquote>



<blockquote class="wp-block-quote">
<p><strong>ChatGPT: </strong> <br>In Qatar, the final game<br>Of the World Cup takes place<br>The best teams from around the world<br>Come face to face</p>



<p>The heat is on, the tension high<br>As players take the field<br>A nation&#8217;s pride is on the line<br>Their fate, to be revealed</p>



<p>The crowd is wild, the atmosphere electric<br>As the ball is kicked to start<br>Two teams, determined to emerge victorious<br>With all their skill and heart</p>



<p>The game is fast, the play intense<br>As goals are scored, and missed<br>But in the end, there can be only one<br>The victor&#8217;s flag, is kissed</p>



<p>The World Cup final, a momentous occasion<br>A spectacle for all to see<br>A celebration of the beautiful game<br>In Qatar, so grand and grandiose</p>
</blockquote>



<p>ChatGPT has no clue what happened in the game, and so just makes it up. However, if we search &#8220;World Cup final game in Qatar&#8221; on Google, the first result is the <a href="https://en.wikipedia.org/wiki/2022_FIFA_World_Cup_final">Wikipedia page</a>. If we ask ChatGPT to summarize it, then it provides us with the following summary:</p>



<blockquote class="wp-block-quote">
<p><strong>ChatGPT:</strong> The 2022 FIFA World Cup final was a football match played on 18 December 2022 at the Lusail Stadium in Lusail, Qatar, between Argentina and France. Argentina won the match 4-2 in a penalty shootout after the match ended 3-3 after extra time. The match was refereed by Szymon Marciniak from Poland and was attended by 88,966 spectators. Argentina and France had both progressed to the final by finishing first in their respective groups, and then defeating Australia, the Netherlands, Croatia, Poland, England, and Morocco in the subsequent knockout rounds. The final was marked by goals from Lionel Messi and Ãngel Di MarÃ­a for Argentina, and a hat-trick from Kylian MbappÃ© for France.</p>
</blockquote>



<p>We can now use this summary as a &#8220;memento&#8221; for the model, making the query: &#8220;<strong>Background: (the summary above) Task:  Write a poem about the World Cup final game in Qatar</strong>&#8220;. </p>



<p>Now the response is much more informative</p>



<blockquote class="wp-block-quote">
<p><strong>ChatGPT:</strong><br>The World Cup final in Qatar,<br>A match that will surely inspire.<br>Argentina and France,<br>Two nations that dance,<br>On the pitch they&#8217;ll set the world on fire.<br><br>The Lusail Stadium is the stage,<br>Where the best from across the globe convene.<br>The tension is high,<br>As the teams take to the sky,<br>In search of the ultimate dream.</p>



<p>Lionel Messi and Ãngel Di MarÃ­a,<br>For Argentina they shine.<br>Kylian MbappÃ© for France,<br>A hat-trick he&#8217;ll advance,<br>In a game that will forever entwine.</p>



<p>The final goes to extra time,<br>As the two teams battle neck and neck.<br>But in the end, it&#8217;s Argentina who prevails,<br>In a penalty shootout they won&#8217;t fail,<br>As they lift the trophy, the ultimate check.</p>



<p>The World Cup final in Qatar,<br>A memory that will last forever.<br>Argentina the champions,<br>Their talent and their valor,<br>A victory they&#8217;ll always treasure.</p>
</blockquote>



<p>The &#8220;amnesia&#8221; suffered by large language models is also manifested by their propensity to output responses that <em>look<strong> </strong></em>correct but are actually wrong.  For example, if we ask ChatGPT the following &#8220;unfair&#8221; question:</p>



<blockquote class="wp-block-quote">
<p><strong>Q: </strong>Prove that there is a finite number of prime numbers</p>
</blockquote>



<p>Then it dutifully responds as follows:</p>



<blockquote class="wp-block-quote">
<p><strong>ChatGPT: </strong>There is no known way to prove that there is a finite number of prime numbers, but it is generally believed to be true. This is because the number of prime numbers is not infinite, and in fact, it is thought to be quite small compared to the total number of integers. For example, there are only about 50 prime numbers less than 1000.</p>



<p>One reason that it is believed that there are only a finite number of prime numbers is the fact that the prime numbers thin out as you go further along the number line. In other words, the proportion of prime numbers to total numbers decreases as the numbers get larger. For example, there are 25 prime numbers less than 100, but only 21 prime numbers between 100 and 200. This suggests that the number of prime numbers may become negligible as the numbers get very large, and thus there may be only a finite number of prime numbers.</p>



<p>Another reason that it is believed that there are only a finite number of prime numbers is the fact that there are many different types of numbers that are not prime, such as composite numbers and perfect numbers. These types of numbers are formed by the multiplication of smaller numbers, and thus it is thought that there must be a point beyond which no more prime numbers can exist.</p>



<p>Overall, while it is not possible to prove that there are only a finite number of prime numbers, it is widely believed to be true based on the observed patterns in the distribution of prime numbers and the existence of other types of numbers that are not prime.</p>
</blockquote>



<p>Even though it&#8217;s completely wrong, the paragraph above might look reasonable to an average person with no knowledge about the prime numbers. This is not an isolated incident. Stackoverflow had to <a href="https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned">ban ChatGPT-produced answers</a> because &#8220;answers which ChatGPT produces have a high rate of being incorrect, [but] they typically look like they might be good.&#8221;</p>



<p>However, large language models have one huge advantage over Leonard Shelbey: they can time travel. Specificially, ChatGPT can figure out the questions that are supposedly answered by its response. It can then query these questions to a search engine (e.g. Google) and use the information to come up with better responses. Specifically, in the context of the &#8220;number of primes&#8221; interaction, if we ask ChatGPT to <strong><em>&#8220;List the questions answered by your response above&#8221;</em></strong> then it responds with the following:</p>



<blockquote class="wp-block-quote">
<p><strong>ChatGPT:</strong><br>1. Is there a finite number of prime numbers?<br>2. What evidence suggests that there may be a finite number of prime numbers?<br>3. Why is it believed that there are only a finite number of prime numbers?</p>
</blockquote>



<p>We now plug the three questions into Google, click on the first links (<a href="https://towardsdatascience.com/proving-the-infinity-of-primes-using-elementary-calculus-3386699801f4#:~:text=The%20number%20of%20primes%20is,is%20known%20as%20Euclid's%20theorem.">this</a>, <a href="https://www.askamathematician.com/2009/10/q-are-there-an-infinite-amount-of-prime-numbers/">this</a>, and <a href="https://math.stackexchange.com/questions/382736/are-all-prime-numbers-finite#:~:text=Every%20prime%20number%20(in%20the,are%20infinitely%20many%20natural%20numbers.">this</a>) and ask ChatGPT to summarize the (first ~1000 words of) these web pages. </p>



<figure class="wp-block-image size-large is-resized"><a href="https://windowsontheory.files.wordpress.com/2023/01/image-2.png"><img loading="lazy" data-attachment-id="8508" data-permalink="https://windowsontheory.org/2023/01/03/memento-and-large-language-models/image-2-3/" data-orig-file="https://windowsontheory.files.wordpress.com/2023/01/image-2.png" data-orig-size="1224,772" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-image-caption="" data-medium-file="https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=300" data-large-file="https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=656" src="https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=1024" alt="" class="wp-image-8508" width="708" height="446" srcset="https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=1024 1024w, https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=708 708w, https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=150 150w, https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=300 300w, https://windowsontheory.files.wordpress.com/2023/01/image-2.png?w=768 768w, https://windowsontheory.files.wordpress.com/2023/01/image-2.png 1224w" sizes="(max-width: 708px) 100vw, 708px" /></a></figure>



<p>We then make the following query:</p>



<blockquote class="wp-block-quote">
<p><strong>Q: </strong>Background:</p>



<ol>
<li>The article discusses the concept of prime numbers, which are defined as positive integers that are only divisible by 1 and themselves. The article then presents a proof by Leonhard Euler, using basic calculus, that the number of prime numbers is infinite. The proof involves considering the prime-counting function, which is the number of prime numbers smaller than or equal to a certain value, and comparing the area under a curve representing this function to the area under a step function. The article then goes on to describe the steps of the proof in detail.</li>



<li>The web page discusses the question of whether there are an infinite number of prime numbers. The physicist provides a proof that there are an infinite number of prime numbers by assuming there are a finite number of primes, multiplying them all together and adding 1, and demonstrating that this new number must be a new prime or be divisible by at least one new prime. This means that no matter how many primes exist, there must be at least one more, leading to an infinite number of primes. The physicist notes that there are many other proofs of the infinitude of primes, but this one is likely the simplest.</li>



<li>The webpage discusses the concept of prime numbers and whether they are finite or infinite. Some people believe that there must be a greatest prime number, while others believe that there must be an infinite prime number. It is pointed out that both of these beliefs lead to contradictions, and the idea is raised that the set of all prime numbers may contain all finite elements with no greatest element. The concept of hyperreal numbers and infinite hypernatural numbers is also mentioned as a possible solution to this problem. It is ultimately concluded that every prime number is finite, despite there being an infinite number of them.</li>
</ol>



<p>Task: Prove that there is a finite number of prime numbers</p>
</blockquote>



<p>Given this background, ChatGPT no longer takes the bait:</p>



<blockquote class="wp-block-quote">
<p><strong>ChatGPT: </strong>I&#8217;m sorry, but it is actually not possible to prove that there is a finite number of prime numbers. In fact, the opposite has been proven to be true &#8211; there are an infinite number of prime numbers. This was first demonstrated by Euclid over 2,000 years ago, and many other proofs have been developed since then. One such proof, as mentioned in the given information, is the proof by Leonhard Euler using basic calculus. This proof involves considering the prime-counting function and comparing the area under a curve representing this function to the area under a step function, which ultimately shows that the number of primes is infinite.</p>



<p>It is worth noting that while every prime number is indeed finite, as it is a positive integer, there is an infinite number of them. This means that there is no largest prime number, and there will always be another prime number after any given prime number.</p>
</blockquote>



<p>The above raises a more general question: <em>is &#8220;memento&#8221;-like reasoning sufficient?</em>  Can you perform an arbitrarily complex computation by splitting it up into pieces that only require finite context? Decades of theoretical computer science research say that the answer is &#8220;yes&#8221;. Indeed, this is precisely what is done by a Turing Machine: at a given step, it only processes information based on a finite state and the contents of the memory address that it reads. A more challenging question is whether we can also do this even when there is some chance for error. This is indeed more challenging. However, tools such as error-correcting codes, interactive proofs, probabilistically-checkable proofs, and succinct arguments, can provide reliable computation even under a variety of challenging error models.  Hence at least this is not a fundamental barrier for arbitrarily complex computation.</p>



<p></p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T18:00:13Z">Tuesday, January 03 2023, 18:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2023/01/positional-encoding.html'>Positional Encoding</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Given the excitement over ChatGPT, I spent part of the winter recess trying to understand the underlying technology of Transformers. After trying various tutorials, I found the best explanation comes in the original 2017 paper, Attention is All you Need. This is my attempt to figure out positional encoding in transformers with some naive questions. Let me know if I'm completely off base.</p><p>Earlier models like Recurrent Neural Nets and Convolutional NNs worked under the assumption that information close by was more likely to be correlated. Machine learning seems to improve as the models make fewer and fewer assumptions about the data and transformers use positional data with no predisposed favoritism to nearby inputs.</p><p>The attention paper uses the following encoding for positions. Let Î±(j) = 10000-j/d where d is the dimension of the input embedding, i.e. the number of numbers used to represent each word of the input. We encode position p as d/2 pairs of numbers cos(p Î±(j)) and sin(p Î±(j)), for j ranging from 1 to d/2. They chose this function because relative positions are easy to address. We can address a relative position of a fixed k by a linear combination of cos(p Î±(j)) and sin(p Î±(j)) using the addition rules of cos and sin.</p><p>cos ((p+k) Î±(j)) = cos(k Î±(j)) cos(p Î±(j))&nbsp; - sin(k Î±(j)) sin(p Î±(j))&nbsp;</p><p>sin ((p+k) Î±(j)) = cos(k Î±(j)) sin(p Î±(j))&nbsp; + sin(k Î±(j)) cos(p Î±(j))&nbsp;</p><p>The d-dimensional vector of position encodings is added to the input embedding.</p><p>Why is the position encodings added to the input embedding?</p><p>I scoured the Internet and can't seem to find a good reason for this, other than it seems to work. Wouldn't the linear combinations to handle relative positions muddle up the input embedding? Since the input embedding is learned, perhaps some parts of the embedding are made zero or very small so the positional embedding stands out. Why not concatenate the two, have separate inputs for the input embedding and the positions? You wouldn't need to fully double the dimension since you would no longer need to match the dimension of the input encoding.</p><p>Why not use complex numbers?</p><p>I see cos(p Î±(j)) and sin(p Î±(j)) and immediately think of them as the real and imaginary parts of ep Î±(j) i. So why not just do the positional encodings as complex numbers? This paper&nbsp;suggests multiplying ep Î±(j) i with the input embedding, i.e., the input is embedding into the amplitude and the position by the phase. That makes more sense. You can now multiply by ep Î±(k) i to get the relative position j+k without effecting the input embedding.</p><p>I don't see a good reason not to use complex numbers for transformers, given that most learning packages and GPUs can handle complex numbers just fine. Even if you don't want to use complex numbers you could multiply the sin and cos versions of the positional encoding instead of adding to achieve a similar effect.</p><p>How about positional encoding for outputs?</p><p>Transformers output words in order but that makes it harder to relate outputs that are far apart. So why not give positional encoding to the outputs. A post-processor could then put the outputs in the correct order. More generally, how about outputting a program that produces the real output? We know transformers can generate code, and this way can handle operations that transformers normally struggle with, like multiplication or sorting.</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Given the excitement over <a href="https://chat.openai.com/chat">ChatGPT</a>, I spent part of the winter recess trying to understand the underlying technology of Transformers. After trying various tutorials, I found the best explanation comes in the original 2017 paper, <a href="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html">Attention is All you Need</a>. This is my attempt to figure out positional encoding in transformers with some naive questions. Let me know if I'm completely off base.</p><p>Earlier models like Recurrent Neural Nets and Convolutional NNs worked under the assumption that information close by was more likely to be correlated. Machine learning seems to improve as the models make fewer and fewer assumptions about the data and transformers use positional data with no predisposed favoritism to nearby inputs.</p><p>The attention paper uses the following encoding for positions. Let Î±(j) = 10000<sup>-j/d</sup> where d is the dimension of the input embedding, i.e. the number of numbers used to represent each word of the input. We encode position p as d/2 pairs of numbers cos(p Î±(j)) and sin(p Î±(j)), for j ranging from 1 to d/2. They chose this function because relative positions are easy to address. We can address a relative position of a fixed k by a linear combination of cos(p Î±(j)) and sin(p Î±(j)) using the addition rules of cos and sin.</p><p>cos ((p+k) Î±(j)) = cos(k Î±(j)) cos(p Î±(j))&nbsp; - sin(k Î±(j)) sin(p Î±(j))&nbsp;</p><p>sin ((p+k) Î±(j)) = cos(k Î±(j)) sin(p Î±(j))&nbsp; + sin(k Î±(j)) cos(p Î±(j))&nbsp;</p><p>The d-dimensional vector of position encodings is added to the input embedding.</p><p><b>Why is the position encodings added to the input embedding?</b></p><p>I scoured the Internet and can't seem to find a good reason for this, other than it seems to work. Wouldn't the linear combinations to handle relative positions muddle up the input embedding? Since the input embedding is learned, perhaps some parts of the embedding are made zero or very small so the positional embedding stands out. Why not concatenate the two, have separate inputs for the input embedding and the positions? You wouldn't need to fully double the dimension since you would no longer need to match the dimension of the input encoding.</p><p><b>Why not use complex numbers?</b></p><p>I see cos(p Î±(j)) and sin(p Î±(j)) and immediately think of them as the real and imaginary parts of e<sup>p Î±(j) i</sup>. So why not just do the positional encodings as complex numbers? <a href="https://arxiv.org/abs/1912.12333">This paper</a>&nbsp;suggests multiplying e<sup>p Î±(j) i</sup> with the input embedding, i.e., the input is embedding into the amplitude and the position by the phase. That makes more sense. You can now multiply by e<sup>p Î±(k) i</sup> to get the relative position j+k without effecting the input embedding.</p><p>I don't see a good reason not to use complex numbers for transformers, given that most learning packages and GPUs can handle complex numbers just fine. Even if you don't want to use complex numbers you could multiply the sin and cos versions of the positional encoding instead of adding to achieve a similar effect.</p><p><b>How about positional encoding for outputs?</b></p><p>Transformers output words in order but that makes it harder to relate outputs that are far apart. So why not give positional encoding to the outputs. A post-processor could then put the outputs in the correct order. More generally, how about outputting a program that produces the real output? We know transformers can generate code, and this way can handle operations that transformers normally struggle with, like multiplication or sorting.</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T14:58:00Z">Tuesday, January 03 2023, 14:58</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://thmatters.wordpress.com/2023/01/02/nsf-program-director-opening-in-algorithmic-foundations-2/'>NSF Program Director opening in Algorithmic Foundations</a></h3>
        <p class='tr-article-feed'>from <a href='https://thmatters.wordpress.com'>Theory Matters</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Serving as a program director at the NSF is one of the most impactful ways of serving the TCS community. Â The Algorithmic Foundations Program in NSF/CISE/CCF is currently accepting applications for a permanent Program Director position. Â Please consider applying! Apply hereÂ by January 12. Â Feel free and encouraged to contact the AF group (TracyÂ Kimbrel, Peter Brass, [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Serving as a program director at the NSF is one of the most impactful ways of serving the TCS community. Â The Algorithmic Foundations Program in NSF/CISE/CCF is currently accepting applications for a permanent Program Director position. Â Please consider applying!</p>



<p><a rel="noreferrer noopener" href="https://www.usajobs.gov/job/694200200" target="_blank">Apply here</a>Â by January 12. Â Feel free and encouraged to contact the AF group (TracyÂ Kimbrel, Peter Brass, Funda Ergun) for information.</p>
<p class="authors">By shuchic</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T02:18:42Z">Tuesday, January 03 2023, 02:18</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00104'>Separating Computational and Statistical Differential Privacy (Under Plausible Assumptions)</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Badih Ghazi, Rahul Ilango, Pritish Kamath, Ravi Kumar, Pasin Manurangsi</p><p>Computational differential privacy (CDP) is a natural relaxation of the
standard notion of (statistical) differential privacy (SDP) proposed by Beimel,
Nissim, and Omri (CRYPTO 2008) and Mironov, Pandey, Reingold, and Vadhan
(CRYPTO 2009). In contrast to SDP, CDP only requires privacy guarantees to hold
against computationally-bounded adversaries rather than
computationally-unbounded statistical adversaries. Despite the question being
raised explicitly in several works (e.g., Bun, Chen, and Vadhan, TCC 2016), it
has remained tantalizingly open whether there is any task achievable with the
CDP notion but not the SDP notion. Even a candidate such task is unknown.
Indeed, it is even unclear what the truth could be!
</p>
<p>In this work, we give the first construction of a task achievable with the
CDP notion but not the SDP notion. More specifically, under strong but
plausible cryptographic assumptions, we construct a task for which there exists
an $\varepsilon$-CDP mechanism with $\varepsilon = O(1)$ achieving $1-o(1)$
utility, but any $(\varepsilon, \delta)$-SDP mechanism, including
computationally unbounded ones, that achieves a constant utility must use
either a super-constant $\varepsilon$ or a non-negligible $\delta$. To prove
this, we introduce a new approach for showing that a mechanism satisfies CDP:
first we show that a mechanism is "private" against a certain class of decision
tree adversaries, and then we use cryptographic constructions to "lift" this
into privacy against computational adversaries. We believe this approach could
be useful to devise further tasks separating CDP from SDP.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghazi_B/0/1/0/all/0/1">Badih Ghazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilango_R/0/1/0/all/0/1">Rahul Ilango</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamath_P/0/1/0/all/0/1">Pritish Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Ravi Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1">Pasin Manurangsi</a></p><p>Computational differential privacy (CDP) is a natural relaxation of the
standard notion of (statistical) differential privacy (SDP) proposed by Beimel,
Nissim, and Omri (CRYPTO 2008) and Mironov, Pandey, Reingold, and Vadhan
(CRYPTO 2009). In contrast to SDP, CDP only requires privacy guarantees to hold
against computationally-bounded adversaries rather than
computationally-unbounded statistical adversaries. Despite the question being
raised explicitly in several works (e.g., Bun, Chen, and Vadhan, TCC 2016), it
has remained tantalizingly open whether there is any task achievable with the
CDP notion but not the SDP notion. Even a candidate such task is unknown.
Indeed, it is even unclear what the truth could be!
</p>
<p>In this work, we give the first construction of a task achievable with the
CDP notion but not the SDP notion. More specifically, under strong but
plausible cryptographic assumptions, we construct a task for which there exists
an $\varepsilon$-CDP mechanism with $\varepsilon = O(1)$ achieving $1-o(1)$
utility, but any $(\varepsilon, \delta)$-SDP mechanism, including
computationally unbounded ones, that achieves a constant utility must use
either a super-constant $\varepsilon$ or a non-negligible $\delta$. To prove
this, we introduce a new approach for showing that a mechanism satisfies CDP:
first we show that a mechanism is "private" against a certain class of decision
tree adversaries, and then we use cryptographic constructions to "lift" this
into privacy against computational adversaries. We believe this approach could
be useful to devise further tasks separating CDP from SDP.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00136'>Power of Decision Trees with Monotone Queries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prashanth Amireddy, Sai Jayasurya, Jayalal Sarma</p><p>In this paper, we initiate study of the computational power of adaptive and
non-adaptive monotone decision trees - decision trees where each query is a
monotone function on the input bits. In the most general setting, the monotone
decision tree height (or size) can be viewed as a measure of non-monotonicity
of a given Boolean function. We also study the restriction of the model by
restricting (in terms of circuit complexity) the monotone functions that can be
queried at each node. This naturally leads to complexity classes of the form
DT(mon-C) for any circuit complexity class C, where the height of the tree is
O(log n), and the query functions can be computed by monotone circuits in the
class C. In the above context, we prove the following characterizations and
bounds.
</p>
<p>For any Boolean function f, we show that the minimum monotone decision tree
height can be exactly characterized (both in the adaptive and non-adaptive
versions of the model) in terms of its alternation (alt(f) is defined as the
maximum number of times that the function value changes, in any chain in the
Boolean lattice). We also characterize the non-adaptive decision tree height
with a natural generalization of certification complexity of a function.
Similarly, we determine the complexity of non-deterministic and randomized
variants of monotone decision trees in terms of alt(f).
</p>
<p>We show that DT(mon-C) = C when C contains monotone circuits for the
threshold functions (for e.g., if C = TC0). For C = AC0, we are able to show
that any function in AC0 can be computed by a sub-linear height monotone
decision tree with queries having monotone AC0 circuits. To understand the
logarithmic height case in case of AC0 i.e., DT(mon-AC0), we show that
functions in DT(mon-AC0) have AC0 circuits with few negation gates.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Amireddy_P/0/1/0/all/0/1">Prashanth Amireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayasurya_S/0/1/0/all/0/1">Sai Jayasurya</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarma_J/0/1/0/all/0/1">Jayalal Sarma</a></p><p>In this paper, we initiate study of the computational power of adaptive and
non-adaptive monotone decision trees - decision trees where each query is a
monotone function on the input bits. In the most general setting, the monotone
decision tree height (or size) can be viewed as a measure of non-monotonicity
of a given Boolean function. We also study the restriction of the model by
restricting (in terms of circuit complexity) the monotone functions that can be
queried at each node. This naturally leads to complexity classes of the form
DT(mon-C) for any circuit complexity class C, where the height of the tree is
O(log n), and the query functions can be computed by monotone circuits in the
class C. In the above context, we prove the following characterizations and
bounds.
</p>
<p>For any Boolean function f, we show that the minimum monotone decision tree
height can be exactly characterized (both in the adaptive and non-adaptive
versions of the model) in terms of its alternation (alt(f) is defined as the
maximum number of times that the function value changes, in any chain in the
Boolean lattice). We also characterize the non-adaptive decision tree height
with a natural generalization of certification complexity of a function.
Similarly, we determine the complexity of non-deterministic and randomized
variants of monotone decision trees in terms of alt(f).
</p>
<p>We show that DT(mon-C) = C when C contains monotone circuits for the
threshold functions (for e.g., if C = TC0). For C = AC0, we are able to show
that any function in AC0 can be computed by a sub-linear height monotone
decision tree with queries having monotone AC0 circuits. To understand the
logarithmic height case in case of AC0 i.e., DT(mon-AC0), we show that
functions in DT(mon-AC0) have AC0 circuits with few negation gates.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00370'>Matching upper bounds on symmetric predicates in quantum communication complexity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daiki Suruga</p><p>In this paper, we focus on the quantum communication complexity of functions
of the form $f \circ G = f(G(X_1, Y_1), \ldots, G(X_n, Y_n))$ where $f: \{0,
1\}^n \to \{0, 1\}$ is a symmetric function, $G: \{0, 1\}^j \times \{0, 1\}^k
\to \{0, 1\}$ is any function and Alice (resp. Bob) is given $(X_i)_{i \leq n}$
(resp. $(Y_i)_{i \leq n}$). Recently, Chakraborty et al. [STACS 2022] showed
that the quantum communication complexity of $f \circ G$ is
$O(Q(f)\mathrm{QCC}_\mathrm{E}(G))$ when the parties are allowed to use shared
entanglement, where $Q(f)$ is the query complexity of $f$ and
$\mathrm{QCC}_\mathrm{E}(G)$ is the exact communication complexity of $G$. In
this paper, we first show that the same statement holds \emph{without shared
entanglement}, which generalizes their result. Based on the improved result, we
next show tight upper bounds on $f \circ \mathrm{AND}_2$ for any symmetric
function $f$ (where $\textrm{AND}_2 : \{0, 1\} \times \{0, 1\} \to \{0, 1\}$
denotes the 2-bit AND function) in both models: with shared entanglement and
without shared entanglement. This matches the well-known lower bound by
Razborov~[Izv. Math. 67(1) 145, 2003] when shared entanglement is allowed and
improves Razborov's bound when shared entanglement is not allowed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Suruga_D/0/1/0/all/0/1">Daiki Suruga</a></p><p>In this paper, we focus on the quantum communication complexity of functions
of the form $f \circ G = f(G(X_1, Y_1), \ldots, G(X_n, Y_n))$ where $f: \{0,
1\}^n \to \{0, 1\}$ is a symmetric function, $G: \{0, 1\}^j \times \{0, 1\}^k
\to \{0, 1\}$ is any function and Alice (resp. Bob) is given $(X_i)_{i \leq n}$
(resp. $(Y_i)_{i \leq n}$). Recently, Chakraborty et al. [STACS 2022] showed
that the quantum communication complexity of $f \circ G$ is
$O(Q(f)\mathrm{QCC}_\mathrm{E}(G))$ when the parties are allowed to use shared
entanglement, where $Q(f)$ is the query complexity of $f$ and
$\mathrm{QCC}_\mathrm{E}(G)$ is the exact communication complexity of $G$. In
this paper, we first show that the same statement holds \emph{without shared
entanglement}, which generalizes their result. Based on the improved result, we
next show tight upper bounds on $f \circ \mathrm{AND}_2$ for any symmetric
function $f$ (where $\textrm{AND}_2 : \{0, 1\} \times \{0, 1\} \to \{0, 1\}$
denotes the 2-bit AND function) in both models: with shared entanglement and
without shared entanglement. This matches the well-known lower bound by
Razborov~[Izv. Math. 67(1) 145, 2003] when shared entanglement is allowed and
improves Razborov's bound when shared entanglement is not allowed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00732'>Improved NP-Hardness of Approximation for Orthogonality Dimension and Minrank</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dror Chawin, Ishay Haviv</p><p>The orthogonality dimension of a graph $G$ over $\mathbb{R}$ is the smallest
integer $k$ for which one can assign a nonzero $k$-dimensional real vector to
each vertex of $G$, such that every two adjacent vertices receive orthogonal
vectors. We prove that for every sufficiently large integer $k$, it is
$\mathsf{NP}$-hard to decide whether the orthogonality dimension of a given
graph over $\mathbb{R}$ is at most $k$ or at least $2^{(1-o(1)) \cdot k/2}$. We
further prove such hardness results for the orthogonality dimension over finite
fields as well as for the closely related minrank parameter, which is motivated
by the index coding problem in information theory. This in particular implies
that it is $\mathsf{NP}$-hard to approximate these graph quantities to within
any constant factor. Previously, the hardness of approximation was known to
hold either assuming certain variants of the Unique Games Conjecture or for
approximation factors smaller than $3/2$. The proofs involve the concept of
line digraphs and bounds on their orthogonality dimension and on the minrank of
their complement.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chawin_D/0/1/0/all/0/1">Dror Chawin</a>, <a href="http://arxiv.org/find/cs/1/au:+Haviv_I/0/1/0/all/0/1">Ishay Haviv</a></p><p>The orthogonality dimension of a graph $G$ over $\mathbb{R}$ is the smallest
integer $k$ for which one can assign a nonzero $k$-dimensional real vector to
each vertex of $G$, such that every two adjacent vertices receive orthogonal
vectors. We prove that for every sufficiently large integer $k$, it is
$\mathsf{NP}$-hard to decide whether the orthogonality dimension of a given
graph over $\mathbb{R}$ is at most $k$ or at least $2^{(1-o(1)) \cdot k/2}$. We
further prove such hardness results for the orthogonality dimension over finite
fields as well as for the closely related minrank parameter, which is motivated
by the index coding problem in information theory. This in particular implies
that it is $\mathsf{NP}$-hard to approximate these graph quantities to within
any constant factor. Previously, the hardness of approximation was known to
hold either assuming certain variants of the Unique Games Conjecture or for
approximation factors smaller than $3/2$. The proofs involve the concept of
line digraphs and bounds on their orthogonality dimension and on the minrank of
their complement.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00739'>On the Complexity of Sub-Tree Scheduling for Wireless Sensor Networks with Partial Coverage</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michele Barbato, Nicola Bianchessi</p><p>Given an undirected graph $G$ whose edge weights change over $s$ time slots,
the sub-tree scheduling for wireless sensor networks with partial coverage asks
to partition the vertices of $G$ in $s$ non-empty trees such that the total
weight of the trees is minimized. In this note we show that the problem is
NP-hard in both the cases where $s$ $(i)$ is part of the input and $(ii)$ is a
fixed instance parameter. In both our proofs we reduce from the cardinality
Steiner tree problem. We additionally give polynomial-time algorithms for
structured inputs of the problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Barbato_M/0/1/0/all/0/1">Michele Barbato</a>, <a href="http://arxiv.org/find/cs/1/au:+Bianchessi_N/0/1/0/all/0/1">Nicola Bianchessi</a></p><p>Given an undirected graph $G$ whose edge weights change over $s$ time slots,
the sub-tree scheduling for wireless sensor networks with partial coverage asks
to partition the vertices of $G$ in $s$ non-empty trees such that the total
weight of the trees is minimized. In this note we show that the problem is
NP-hard in both the cases where $s$ $(i)$ is part of the input and $(ii)$ is a
fixed instance parameter. In both our proofs we reduce from the cardinality
Steiner tree problem. We additionally give polynomial-time algorithms for
structured inputs of the problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00806'>The characterization of $\mathbf{(n-1)}$-spheres with $\mathbf{n+4}$ vertices having maximal Buchstaber number</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Suyoung Choi, Hyeontae Jang, Mathieu Vall&#xe9;e</p><p>We provide a GPU-friendly algorithm for obtaining all weak pseudo-manifolds
whose facets are all in an input set of facets satisfying given conditions. We
use it here to completely list up toric colorable seed PL-spheres with a few
vertices implying the complete characterization of PL-spheres of dimension
$n-1$ with $n+4$ vertices having maximal Buchstaber numbers.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Choi_S/0/1/0/all/0/1">Suyoung Choi</a>, <a href="http://arxiv.org/find/math/1/au:+Jang_H/0/1/0/all/0/1">Hyeontae Jang</a>, <a href="http://arxiv.org/find/math/1/au:+Vallee_M/0/1/0/all/0/1">Mathieu Vall&#xe9;e</a></p><p>We provide a GPU-friendly algorithm for obtaining all weak pseudo-manifolds
whose facets are all in an input set of facets satisfying given conditions. We
use it here to completely list up toric colorable seed PL-spheres with a few
vertices implying the complete characterization of PL-spheres of dimension
$n-1$ with $n+4$ vertices having maximal Buchstaber numbers.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00074'>Matrix Multiplication: Verifying Strong Uniquely Solvable Puzzles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Matthew Anderson, Zongliang Ji, Anthony Yang Xu</p><p>Cohn and Umans proposed a framework for developing fast matrix multiplication
algorithms based on the embedding computation in certain groups algebras. In
subsequent work with Kleinberg and Szegedy, they connected this to the search
for combinatorial objects called strong uniquely solvable puzzles (strong
USPs). We begin a systematic computer-aided search for these objects. We
develop and implement constraint-based algorithms build on reductions to
$\mathrm{SAT}$ and $\mathrm{IP}$ to verify that puzzles are strong USPs, and to
search for large strong USPs. We produce tight bounds on the maximum size of a
strong USP for width $k \le 5$, construct puzzles of small width that are
larger than previous work, and improve the upper bounds on strong USP size for
$k \le 12$. Although our work only deals with puzzles of small-constant width,
the strong USPs we find imply matrix multiplication algorithms that run in
$O(n^\omega)$ time with exponent $\omega \le 2.66$. While our algorithms do not
beat the fastest algorithms, our work provides evidence and, perhaps, a path to
finding families of strong USPs that imply matrix multiplication algorithms
that are more efficient than those currently known.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Anderson_M/0/1/0/all/0/1">Matthew Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1">Zongliang Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_A/0/1/0/all/0/1">Anthony Yang Xu</a></p><p>Cohn and Umans proposed a framework for developing fast matrix multiplication
algorithms based on the embedding computation in certain groups algebras. In
subsequent work with Kleinberg and Szegedy, they connected this to the search
for combinatorial objects called strong uniquely solvable puzzles (strong
USPs). We begin a systematic computer-aided search for these objects. We
develop and implement constraint-based algorithms build on reductions to
$\mathrm{SAT}$ and $\mathrm{IP}$ to verify that puzzles are strong USPs, and to
search for large strong USPs. We produce tight bounds on the maximum size of a
strong USP for width $k \le 5$, construct puzzles of small width that are
larger than previous work, and improve the upper bounds on strong USP size for
$k \le 12$. Although our work only deals with puzzles of small-constant width,
the strong USPs we find imply matrix multiplication algorithms that run in
$O(n^\omega)$ time with exponent $\omega \le 2.66$. While our algorithms do not
beat the fastest algorithms, our work provides evidence and, perhaps, a path to
finding families of strong USPs that imply matrix multiplication algorithms
that are more efficient than those currently known.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00278'>Isometric path antichain covers: beyond hyperbolic graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dibyayan Chakraborty, Florent Foucaud</p><p>The \emph{isometric path antichain cover number} of a graph $G$, denoted by
$ipacc(G)$, is a graph parameter that was recently introduced to provide a
constant factor approximation algorithm for \textsc{Isometric Path Cover},
whose objective is to cover all vertices of a graph with a minimum number of
isometric paths (i.e. shortest paths between their end-vertices). This
parameter was previously shown to be bounded for chordal graphs and, more
generally, for graphs of bounded \emph{chordality} and bounded
\emph{treelength}. In this paper, we show that the isometric path antichain
cover number remains bounded for graphs in three seemingly unrelated graph
classes, namely, \emph{hyperbolic graphs}, \emph{(theta, prism, pyramid)-free
graphs}, and \emph{outerstring graphs}. Hyperbolic graphs are extensively
studied in \emph{Metric Graph Theory}. The class of (theta, prism,
pyramid)-free graphs are extensively studied in \emph{Structural Graph Theory},
\textit{e.g.} in the context of the \emph{Strong Perfect Graph Theorem}. The
class of outerstring graphs is studied in \emph{Geometric Graph Theory} and
\emph{Computational Geometry}. Our results imply a constant factor
approximation algorithm for \textsc{Isometric Path Cover} on all the above
graph classes. Our results also show that the distance functions of these
(structurally) different graph classes are more similar than previously
thought.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Chakraborty_D/0/1/0/all/0/1">Dibyayan Chakraborty</a>, <a href="http://arxiv.org/find/math/1/au:+Foucaud_F/0/1/0/all/0/1">Florent Foucaud</a></p><p>The \emph{isometric path antichain cover number} of a graph $G$, denoted by
$ipacc(G)$, is a graph parameter that was recently introduced to provide a
constant factor approximation algorithm for \textsc{Isometric Path Cover},
whose objective is to cover all vertices of a graph with a minimum number of
isometric paths (i.e. shortest paths between their end-vertices). This
parameter was previously shown to be bounded for chordal graphs and, more
generally, for graphs of bounded \emph{chordality} and bounded
\emph{treelength}. In this paper, we show that the isometric path antichain
cover number remains bounded for graphs in three seemingly unrelated graph
classes, namely, \emph{hyperbolic graphs}, \emph{(theta, prism, pyramid)-free
graphs}, and \emph{outerstring graphs}. Hyperbolic graphs are extensively
studied in \emph{Metric Graph Theory}. The class of (theta, prism,
pyramid)-free graphs are extensively studied in \emph{Structural Graph Theory},
\textit{e.g.} in the context of the \emph{Strong Perfect Graph Theorem}. The
class of outerstring graphs is studied in \emph{Geometric Graph Theory} and
\emph{Computational Geometry}. Our results imply a constant factor
approximation algorithm for \textsc{Isometric Path Cover} on all the above
graph classes. Our results also show that the distance functions of these
(structurally) different graph classes are more similar than previously
thought.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00108'>Targeted k-node Collapse Problem: Towards Understanding the Robustness of Local k-core Structure</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuqian Lv, Bo Zhou, Jinhuan Wang, Qi Xuan</p><p>The concept of k-core, which indicates the largest induced subgraph where
each node has k or more neighbors, plays a significant role in measuring the
cohesiveness and the engagement of a network, and it is exploited in diverse
applications, e.g., network analysis, anomaly detection, community detection,
etc. Recent works have demonstrated the vulnerability of k-core under malicious
perturbations which focuses on removing the minimal number of edges to make a
whole k-core structure collapse. However, to the best of our knowledge, there
is no existing research concentrating on how many edges should be removed at
least to make an arbitrary node in k-core collapse. Therefore, in this paper,
we make the first attempt to study the Targeted k-node Collapse Problem (TNCP)
with four novel contributions. Firstly, we offer the general definition of TNCP
problem with the proof of its NP-hardness. Secondly, in order to address the
TNCP problem, we propose a heuristic algorithm named TNC and its improved
version named ATNC for implementations on large-scale networks. After that, the
experiments on 16 real-world networks across various domains verify the
superiority of our proposed algorithms over 4 baseline methods along with
detailed comparisons and analyses. Finally, the significance of TNCP problem
for precisely evaluating the resilience of k-core structures in networks is
validated.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1">Yuqian Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jinhuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xuan_Q/0/1/0/all/0/1">Qi Xuan</a></p><p>The concept of k-core, which indicates the largest induced subgraph where
each node has k or more neighbors, plays a significant role in measuring the
cohesiveness and the engagement of a network, and it is exploited in diverse
applications, e.g., network analysis, anomaly detection, community detection,
etc. Recent works have demonstrated the vulnerability of k-core under malicious
perturbations which focuses on removing the minimal number of edges to make a
whole k-core structure collapse. However, to the best of our knowledge, there
is no existing research concentrating on how many edges should be removed at
least to make an arbitrary node in k-core collapse. Therefore, in this paper,
we make the first attempt to study the Targeted k-node Collapse Problem (TNCP)
with four novel contributions. Firstly, we offer the general definition of TNCP
problem with the proof of its NP-hardness. Secondly, in order to address the
TNCP problem, we propose a heuristic algorithm named TNC and its improved
version named ATNC for implementations on large-scale networks. After that, the
experiments on 16 real-world networks across various domains verify the
superiority of our proposed algorithms over 4 baseline methods along with
detailed comparisons and analyses. Finally, the significance of TNCP problem
for precisely evaluating the resilience of k-core structures in networks is
validated.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00316'>Optimization Perspectives on Shellsort</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Oscar Skean, Richard Ehrenborg, Jerzy W. Jaromczyk</p><p>Shellsort is a sorting method that is attractive due to its simplicity, yet
it takes effort to analyze its efficiency. The heart of the algorithm is the
gap sequence chosen a priori and used during sorting. The selection of this gap
sequence affects the efficiency of Shellsort, and thus drives both its
theoretical and experimental analysis. We contribute to Shellsort by
identifying efficient gap sequences based on new parameterized functions.
Specifically, a parameter grid-search identifies optimal parameters for
different input sizes for sorting by observing minimal overhead in three
categories: number of comparisons, number of exchanges, and running time. We
report that our method finds sequences that outperform state-of-the-art gap
sequences concerning the number of comparisons for chosen small array sizes.
Additionally, our function-based sequences outperform the running time of the
Tokuda sequence for chosen large array sizes. However, no substantial
improvements were observed when minimizing the number of exchanges.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Skean_O/0/1/0/all/0/1">Oscar Skean</a>, <a href="http://arxiv.org/find/cs/1/au:+Ehrenborg_R/0/1/0/all/0/1">Richard Ehrenborg</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaromczyk_J/0/1/0/all/0/1">Jerzy W. Jaromczyk</a></p><p>Shellsort is a sorting method that is attractive due to its simplicity, yet
it takes effort to analyze its efficiency. The heart of the algorithm is the
gap sequence chosen a priori and used during sorting. The selection of this gap
sequence affects the efficiency of Shellsort, and thus drives both its
theoretical and experimental analysis. We contribute to Shellsort by
identifying efficient gap sequences based on new parameterized functions.
Specifically, a parameter grid-search identifies optimal parameters for
different input sizes for sorting by observing minimal overhead in three
categories: number of comparisons, number of exchanges, and running time. We
report that our method finds sequences that outperform state-of-the-art gap
sequences concerning the number of comparisons for chosen small array sizes.
Additionally, our function-based sequences outperform the running time of the
Tokuda sequence for chosen large array sizes. However, no substantial
improvements were observed when minimizing the number of exchanges.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00384'>Correlation Clustering Algorithm for Dynamic Complete Signed Graphs: An Index-based Approach</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ali Shakiba</p><p>In this paper, we reduce the complexity of approximating the correlation
clustering problem from $O(m\times\left( 2+ \alpha (G) \right)+n)$ to $O(m+n)$
for any given value of $\varepsilon$ for a complete signed graph with $n$
vertices and $m$ positive edges where $\alpha(G)$ is the arboricity of the
graph. Our approach gives the same output as the original algorithm and makes
it possible to implement the algorithm in a full dynamic setting where edge
sign flipping and vertex addition/removal are allowed. Constructing this index
costs $O(m)$ memory and $O(m\times\alpha(G))$ time. We also studied the
structural properties of the non-agreement measure used in the approximation
algorithm. The theoretical results are accompanied by a full set of experiments
concerning seven real-world graphs. These results shows superiority of our
index-based algorithm to the non-index one by a decrease of %34 in time on
average.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Shakiba_A/0/1/0/all/0/1">Ali Shakiba</a></p><p>In this paper, we reduce the complexity of approximating the correlation
clustering problem from $O(m\times\left( 2+ \alpha (G) \right)+n)$ to $O(m+n)$
for any given value of $\varepsilon$ for a complete signed graph with $n$
vertices and $m$ positive edges where $\alpha(G)$ is the arboricity of the
graph. Our approach gives the same output as the original algorithm and makes
it possible to implement the algorithm in a full dynamic setting where edge
sign flipping and vertex addition/removal are allowed. Constructing this index
costs $O(m)$ memory and $O(m\times\alpha(G))$ time. We also studied the
structural properties of the non-agreement measure used in the approximation
algorithm. The theoretical results are accompanied by a full set of experiments
concerning seven real-world graphs. These results shows superiority of our
index-based algorithm to the non-index one by a decrease of %34 in time on
average.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00387'>Exactly Hittable Interval Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: S.M. Dhannya, N.S. Narayanaswamy, K.K. Nisha</p><p>Given a set system $\mathcal{X} = \{\mathcal{U},\mathcal{S}\}$, where
$\mathcal{U}$ is a set of elements and $\mathcal{S}$ is a set of subsets of
$\mathcal{U}$, an exact hitting set $\mathcal{U}'$ is a subset of $\mathcal{U}$
such that each subset in $\mathcal{S}$ contains exactly one element in
$\mathcal{U}'$. We refer to a set system as exactly hittable if it has an exact
hitting set. In this paper, we study interval graphs which have intersection
models that are exactly hittable. We refer to these interval graphs as exactly
hittable interval graphs (EHIG). We present a forbidden structure
characterization for EHIG. We also show that the class of proper interval
graphs is a strict subclass of EHIG. Finally, we give an algorithm that runs in
polynomial time to recognize graphs belonging to the class of EHIG.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dhannya_S/0/1/0/all/0/1">S.M. Dhannya</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanaswamy_N/0/1/0/all/0/1">N.S. Narayanaswamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Nisha_K/0/1/0/all/0/1">K.K. Nisha</a></p><p>Given a set system $\mathcal{X} = \{\mathcal{U},\mathcal{S}\}$, where
$\mathcal{U}$ is a set of elements and $\mathcal{S}$ is a set of subsets of
$\mathcal{U}$, an exact hitting set $\mathcal{U}'$ is a subset of $\mathcal{U}$
such that each subset in $\mathcal{S}$ contains exactly one element in
$\mathcal{U}'$. We refer to a set system as exactly hittable if it has an exact
hitting set. In this paper, we study interval graphs which have intersection
models that are exactly hittable. We refer to these interval graphs as exactly
hittable interval graphs (EHIG). We present a forbidden structure
characterization for EHIG. We also show that the class of proper interval
graphs is a strict subclass of EHIG. Finally, we give an algorithm that runs in
polynomial time to recognize graphs belonging to the class of EHIG.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00457'>ReSQueing Parallel and Private Stochastic Convex Optimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yair Carmon, Arun Jambulapati, Yujia Jin, Yin Tat Lee, Daogao Liu, Aaron Sidford, Kevin Tian</p><p>We introduce a new tool for stochastic convex optimization (SCO): a
Reweighted Stochastic Query (ReSQue) estimator for the gradient of a function
convolved with a (Gaussian) probability density. Combining ReSQue with recent
advances in ball oracle acceleration [CJJJLST20, ACJJS21], we develop
algorithms achieving state-of-the-art complexities for SCO in parallel and
private settings. For a SCO objective constrained to the unit ball in
$\mathbb{R}^d$, we obtain the following results (up to polylogarithmic
factors). We give a parallel algorithm obtaining optimization error
$\epsilon_{\text{opt}}$ with $d^{1/3}\epsilon_{\text{opt}}^{-2/3}$ gradient
oracle query depth and $d^{1/3}\epsilon_{\text{opt}}^{-2/3} +
\epsilon_{\text{opt}}^{-2}$ gradient queries in total, assuming access to a
bounded-variance stochastic gradient estimator. For $\epsilon_{\text{opt}} \in
[d^{-1}, d^{-1/4}]$, our algorithm matches the state-of-the-art oracle depth of
[BJLLS19] while maintaining the optimal total work of stochastic gradient
descent. We give an $(\epsilon_{\text{dp}}, \delta)$-differentially private
algorithm which, given $n$ samples of Lipschitz loss functions, obtains
near-optimal optimization error and makes $\min(n, n^2\epsilon_{\text{dp}}^2
d^{-1}) + \min(n^{4/3}\epsilon_{\text{dp}}^{1/3},
(nd)^{2/3}\epsilon_{\text{dp}}^{-1})$ queries to the gradients of these
functions. In the regime $d \le n \epsilon_{\text{dp}}^{2}$, where privacy
comes at no cost in terms of the optimal loss up to constants, our algorithm
uses $n + (nd)^{2/3}\epsilon_{\text{dp}}^{-1}$ queries and improves recent
advancements of [KLL21, AFKT21]. In the moderately low-dimensional setting $d
\le \sqrt n \epsilon_{\text{dp}}^{3/2}$, our query complexity is near-linear.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Carmon_Y/0/1/0/all/0/1">Yair Carmon</a>, <a href="http://arxiv.org/find/math/1/au:+Jambulapati_A/0/1/0/all/0/1">Arun Jambulapati</a>, <a href="http://arxiv.org/find/math/1/au:+Jin_Y/0/1/0/all/0/1">Yujia Jin</a>, <a href="http://arxiv.org/find/math/1/au:+Lee_Y/0/1/0/all/0/1">Yin Tat Lee</a>, <a href="http://arxiv.org/find/math/1/au:+Liu_D/0/1/0/all/0/1">Daogao Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Sidford_A/0/1/0/all/0/1">Aaron Sidford</a>, <a href="http://arxiv.org/find/math/1/au:+Tian_K/0/1/0/all/0/1">Kevin Tian</a></p><p>We introduce a new tool for stochastic convex optimization (SCO): a
Reweighted Stochastic Query (ReSQue) estimator for the gradient of a function
convolved with a (Gaussian) probability density. Combining ReSQue with recent
advances in ball oracle acceleration [CJJJLST20, ACJJS21], we develop
algorithms achieving state-of-the-art complexities for SCO in parallel and
private settings. For a SCO objective constrained to the unit ball in
$\mathbb{R}^d$, we obtain the following results (up to polylogarithmic
factors). We give a parallel algorithm obtaining optimization error
$\epsilon_{\text{opt}}$ with $d^{1/3}\epsilon_{\text{opt}}^{-2/3}$ gradient
oracle query depth and $d^{1/3}\epsilon_{\text{opt}}^{-2/3} +
\epsilon_{\text{opt}}^{-2}$ gradient queries in total, assuming access to a
bounded-variance stochastic gradient estimator. For $\epsilon_{\text{opt}} \in
[d^{-1}, d^{-1/4}]$, our algorithm matches the state-of-the-art oracle depth of
[BJLLS19] while maintaining the optimal total work of stochastic gradient
descent. We give an $(\epsilon_{\text{dp}}, \delta)$-differentially private
algorithm which, given $n$ samples of Lipschitz loss functions, obtains
near-optimal optimization error and makes $\min(n, n^2\epsilon_{\text{dp}}^2
d^{-1}) + \min(n^{4/3}\epsilon_{\text{dp}}^{1/3},
(nd)^{2/3}\epsilon_{\text{dp}}^{-1})$ queries to the gradients of these
functions. In the regime $d \le n \epsilon_{\text{dp}}^{2}$, where privacy
comes at no cost in terms of the optimal loss up to constants, our algorithm
uses $n + (nd)^{2/3}\epsilon_{\text{dp}}^{-1}$ queries and improves recent
advancements of [KLL21, AFKT21]. In the moderately low-dimensional setting $d
\le \sqrt n \epsilon_{\text{dp}}^{3/2}$, our query complexity is near-linear.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00483'>Inferring multiple consensus trees and supertrees using clustering: a review</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vladimir Makarenkov, Gayane S. Barseghyan, Nadia Tahiri</p><p>Phylogenetic trees (i.e. evolutionary trees, additive trees or X-trees) play
a key role in the processes of modeling and representing species evolution.
Genome evolution of a given group of species is usually modeled by a species
phylogenetic tree that represents the main patterns of vertical descent.
However, the evolution of each gene is unique. It can be represented by its own
gene tree which can differ substantially from a general species tree
representation. Consensus trees and supertrees have been widely used in
evolutionary studies to combine phylogenetic information contained in
individual gene trees. Nevertheless, if the available gene trees are quite
different from each other, then the resulting consensus tree or supertree can
either include many unresolved subtrees corresponding to internal nodes of high
degree or can simply be a star tree. This may happen if the available gene
trees have been affected by different reticulate evolutionary events, such as
horizontal gene transfer, hybridization or genetic recombination. Thus, the
problem of inferring multiple alternative consensus trees or supertrees, using
clustering, becomes relevant since it allows one to regroup in different
clusters gene trees having similar evolutionary patterns (e.g. gene trees
representing genes that have undergone the same horizontal gene transfer or
recombination events). We critically review recent advances and methods in the
field of phylogenetic tree clustering, discuss the methods' mathematical
properties, and describe the main advantages and limitations of multiple
consensus tree and supertree approaches. In the application section, we show
how the multiple supertree clustering approach can be used to cluster aaRS gene
trees according to their evolutionary patterns.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/q-bio/1/au:+Makarenkov_V/0/1/0/all/0/1">Vladimir Makarenkov</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Barseghyan_G/0/1/0/all/0/1">Gayane S. Barseghyan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Tahiri_N/0/1/0/all/0/1">Nadia Tahiri</a></p><p>Phylogenetic trees (i.e. evolutionary trees, additive trees or X-trees) play
a key role in the processes of modeling and representing species evolution.
Genome evolution of a given group of species is usually modeled by a species
phylogenetic tree that represents the main patterns of vertical descent.
However, the evolution of each gene is unique. It can be represented by its own
gene tree which can differ substantially from a general species tree
representation. Consensus trees and supertrees have been widely used in
evolutionary studies to combine phylogenetic information contained in
individual gene trees. Nevertheless, if the available gene trees are quite
different from each other, then the resulting consensus tree or supertree can
either include many unresolved subtrees corresponding to internal nodes of high
degree or can simply be a star tree. This may happen if the available gene
trees have been affected by different reticulate evolutionary events, such as
horizontal gene transfer, hybridization or genetic recombination. Thus, the
problem of inferring multiple alternative consensus trees or supertrees, using
clustering, becomes relevant since it allows one to regroup in different
clusters gene trees having similar evolutionary patterns (e.g. gene trees
representing genes that have undergone the same horizontal gene transfer or
recombination events). We critically review recent advances and methods in the
field of phylogenetic tree clustering, discuss the methods' mathematical
properties, and describe the main advantages and limitations of multiple
consensus tree and supertree approaches. In the application section, we show
how the multiple supertree clustering approach can be used to cluster aaRS gene
trees according to their evolutionary patterns.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00754'>Algorithms for Massive Data -- Lecture Notes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicola Prezza</p><p>These are the lecture notes for the course CM0622 - Algorithms for Massive
Data, Ca' Foscari University of Venice. The goal of this course is to introduce
algorithmic techniques for dealing with massive data: data so large that it
does not fit in the computer's memory. Broadly speaking, there are two main
solutions to deal with massive data: (lossless) compressed data structures and
(lossy) data sketches. These notes cover the latter topic: probabilistic
filters, sketching under various metrics, Locality Sensitive Hashing, nearest
neighbour search, algorithms on streams (pattern matching, counting).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1">Nicola Prezza</a></p><p>These are the lecture notes for the course CM0622 - Algorithms for Massive
Data, Ca' Foscari University of Venice. The goal of this course is to introduce
algorithmic techniques for dealing with massive data: data so large that it
does not fit in the computer's memory. Broadly speaking, there are two main
solutions to deal with massive data: (lossless) compressed data structures and
(lossy) data sketches. These notes cover the latter topic: probabilistic
filters, sketching under various metrics, Locality Sensitive Hashing, nearest
neighbour search, algorithms on streams (pattern matching, counting).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.00797'>Parameterized Lower Bounds for Problems in P via Fine-Grained Cross-Compositions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Klaus Heeger, Andr&#xe9; Nichterlein, Rolf Niedermeier</p><p>We provide a general framework to exclude parameterized running times of the
form $O(\ell^\beta+ n^\gamma)$ for problems that have polynomial running time
lower bounds under hypotheses from fine-grained complexity. Our framework is
based on cross-compositions from parameterized complexity. We (conditionally)
exclude running times of the form $O(\ell^{{\gamma}/{(\gamma-1)} - \epsilon} +
n^\gamma)$ for any $1&lt;\gamma&lt;2$ and $\epsilon&gt;0$ for the following problems:
</p>
<p>- Longest Common Subsequence: Given two length-$n$ strings and
$\ell\in\mathbb{N}$, is there a common subsequence of length $\ell$?
</p>
<p>- Discrete Fr\'echet Distance: Given two lists of $n$ points each and $k\in
\mathbb{N}$, is the Fr\'echet distance of the lists at most $k$? Here $\ell$ is
the maximum number of points which one list is ahead of the other list in an
optimum traversal.
</p>
<p>Moreover, we exclude running times $O(\ell^{{2\gamma}/{(\gamma -1)}-\epsilon}
+ n^\gamma)$ for any $1&lt;\gamma&lt;3$ and $\epsilon&gt;0$ for:
</p>
<p>- Negative Triangle: Given an edge-weighted graph with $n$ vertices, is there
a triangle whose sum of edge-weights is negative? Here $\ell$ is the order of a
maximum connected component.
</p>
<p>- Triangle Collection: Given a vertex-colored graph with $n$ vertices, is
there for each triple of colors a triangle whose vertices have these three
colors? Here $\ell$ is the order of a maximum connected component.
</p>
<p>- 2nd Shortest Path: Given an $n$-vertex edge-weighted directed graph, two
vertices $s$ and $t$, and $k \in \mathbb{N}$, has the second longest
$s$-$t$-path length at most $k$? Here $\ell$ is the directed feedback vertex
set.
</p>
<p>Except for 2nd Shortest Path all these running time bounds are tight, that
is, algorithms with running time $O(\ell^{{\gamma}/{(\gamma-1)}} + n^\gamma )$
for any $1 &lt; \gamma &lt; 2$ and $O(\ell^{{2\gamma}/{(\gamma -1)}} + n^\gamma)$ for
any $1 &lt; \gamma &lt; 3$, respectively, are known.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Heeger_K/0/1/0/all/0/1">Klaus Heeger</a>, <a href="http://arxiv.org/find/cs/1/au:+Nichterlein_A/0/1/0/all/0/1">Andr&#xe9; Nichterlein</a>, <a href="http://arxiv.org/find/cs/1/au:+Niedermeier_R/0/1/0/all/0/1">Rolf Niedermeier</a></p><p>We provide a general framework to exclude parameterized running times of the
form $O(\ell^\beta+ n^\gamma)$ for problems that have polynomial running time
lower bounds under hypotheses from fine-grained complexity. Our framework is
based on cross-compositions from parameterized complexity. We (conditionally)
exclude running times of the form $O(\ell^{{\gamma}/{(\gamma-1)} - \epsilon} +
n^\gamma)$ for any $1&lt;\gamma&lt;2$ and $\epsilon&gt;0$ for the following problems:
</p>
<p>- Longest Common Subsequence: Given two length-$n$ strings and
$\ell\in\mathbb{N}$, is there a common subsequence of length $\ell$?
</p>
<p>- Discrete Fr\'echet Distance: Given two lists of $n$ points each and $k\in
\mathbb{N}$, is the Fr\'echet distance of the lists at most $k$? Here $\ell$ is
the maximum number of points which one list is ahead of the other list in an
optimum traversal.
</p>
<p>Moreover, we exclude running times $O(\ell^{{2\gamma}/{(\gamma -1)}-\epsilon}
+ n^\gamma)$ for any $1&lt;\gamma&lt;3$ and $\epsilon&gt;0$ for:
</p>
<p>- Negative Triangle: Given an edge-weighted graph with $n$ vertices, is there
a triangle whose sum of edge-weights is negative? Here $\ell$ is the order of a
maximum connected component.
</p>
<p>- Triangle Collection: Given a vertex-colored graph with $n$ vertices, is
there for each triple of colors a triangle whose vertices have these three
colors? Here $\ell$ is the order of a maximum connected component.
</p>
<p>- 2nd Shortest Path: Given an $n$-vertex edge-weighted directed graph, two
vertices $s$ and $t$, and $k \in \mathbb{N}$, has the second longest
$s$-$t$-path length at most $k$? Here $\ell$ is the directed feedback vertex
set.
</p>
<p>Except for 2nd Shortest Path all these running time bounds are tight, that
is, algorithms with running time $O(\ell^{{\gamma}/{(\gamma-1)}} + n^\gamma )$
for any $1 &lt; \gamma &lt; 2$ and $O(\ell^{{2\gamma}/{(\gamma -1)}} + n^\gamma)$ for
any $1 &lt; \gamma &lt; 3$, respectively, are known.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-03T01:30:00Z">Tuesday, January 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, January 02
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.14095'>Partial Degeneration of Tensors</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Matthias Christandl, Fulvio Gesmundo, Vladimir Lysikov, Vincent Steffan</p><p>Tensors are often studied by introducing preorders such as restriction and
degeneration: the former describes transformations of the tensors by local
linear maps on its tensor factors; the latter describes transformations where
the local linear maps may vary along a curve, and the resulting tensor is
expressed as a limit along this curve. In this work we introduce and study
partial degeneration, a special version of degeneration where one of the local
linear maps is constant whereas the others vary along a curve. Motivated by
algebraic complexity, quantum entanglement and tensor networks, we present
constructions based on matrix multiplication tensors and find examples by
making a connection to the theory of prehomogenous tensor spaces. We highlight
the subtleties of this new notion by showing obstruction and classification
results for the unit tensor. To this end, we study the notion of aided rank, a
natural generalization of tensor rank. The existence of partial degenerations
gives strong upper bounds on the aided rank of the tensor, which in turn allows
one to turn degenerations into restrictions. In particular, we present several
examples, based on the W-tensor and the Coppersmith-Winograd tensors, where
lower bounds on aided rank provide obstructions to the existence of certain
partial degenerations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Christandl_M/0/1/0/all/0/1">Matthias Christandl</a>, <a href="http://arxiv.org/find/math/1/au:+Gesmundo_F/0/1/0/all/0/1">Fulvio Gesmundo</a>, <a href="http://arxiv.org/find/math/1/au:+Lysikov_V/0/1/0/all/0/1">Vladimir Lysikov</a>, <a href="http://arxiv.org/find/math/1/au:+Steffan_V/0/1/0/all/0/1">Vincent Steffan</a></p><p>Tensors are often studied by introducing preorders such as restriction and
degeneration: the former describes transformations of the tensors by local
linear maps on its tensor factors; the latter describes transformations where
the local linear maps may vary along a curve, and the resulting tensor is
expressed as a limit along this curve. In this work we introduce and study
partial degeneration, a special version of degeneration where one of the local
linear maps is constant whereas the others vary along a curve. Motivated by
algebraic complexity, quantum entanglement and tensor networks, we present
constructions based on matrix multiplication tensors and find examples by
making a connection to the theory of prehomogenous tensor spaces. We highlight
the subtleties of this new notion by showing obstruction and classification
results for the unit tensor. To this end, we study the notion of aided rank, a
natural generalization of tensor rank. The existence of partial degenerations
gives strong upper bounds on the aided rank of the tensor, which in turn allows
one to turn degenerations into restrictions. In particular, we present several
examples, based on the W-tensor and the Coppersmith-Winograd tensors, where
lower bounds on aided rank provide obstructions to the existence of certain
partial degenerations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-02T01:30:00Z">Monday, January 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.14091'>Heterochromatic Higher Order Transversals for Convex Sets</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arijit Ghosh, Soumi Nandi</p><p>For $0\leq k\leq d-1$, a $k$-flat in $\mathbb{R}^d$ is a $k$-dimensional
affine subspace in $\mathbb{R}^d$. A set $T$ of $k$-flats in $\mathbb{R}^d$ is
a {\em $k$-transversal} of a family $\mathcal{F}$ of subsets of $\mathbb{R}^d$
if every member of $\mathcal{F}$ intersects some $k$-flat in $T$. A family
$\mathcal{F}$ of sets is said to satisfy $(p,q)$-property with respect to a set
$T$ of $k$-flats if among every $p$ members of $\mathcal{F}$ at least $q$ of
them can be hit by a single $k$-flat in $T$. Keller and Perles (SoCG 2022)
proved an $(\aleph_0,k+2)$-theorem for $k$-transversals for families of
$(r,R)$-fat convex sets in $\mathbb{R}^d$. They proved that any family
$\mathcal{F}$ of $(r,R)$-fat sets in $\mathbb{R}^d$ satisfying
$(\aleph_{0},k+2)$-property with respect to $k$-transversals can be hit by a
finite number of $k$-flats. In this paper, we have extended the
$(\aleph_0,k+2)$-theorem for $k$-transversals without the fatness assumption by
introducing a notion, called \emph{$k$-growing sequence}. Moreover, we have
proved a heterochromatic version of $(\aleph_0,k+2)$-theorem for
$k$-transversals for families of both $(r,R)$-fat sets and more general convex
sets. We have also proved a colorful generalization of the \emph{Helly-type}
theorem for $k$-transversals of convex sets due to Aronov, Goodman and Pollack.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Ghosh_A/0/1/0/all/0/1">Arijit Ghosh</a>, <a href="http://arxiv.org/find/math/1/au:+Nandi_S/0/1/0/all/0/1">Soumi Nandi</a></p><p>For $0\leq k\leq d-1$, a $k$-flat in $\mathbb{R}^d$ is a $k$-dimensional
affine subspace in $\mathbb{R}^d$. A set $T$ of $k$-flats in $\mathbb{R}^d$ is
a {\em $k$-transversal} of a family $\mathcal{F}$ of subsets of $\mathbb{R}^d$
if every member of $\mathcal{F}$ intersects some $k$-flat in $T$. A family
$\mathcal{F}$ of sets is said to satisfy $(p,q)$-property with respect to a set
$T$ of $k$-flats if among every $p$ members of $\mathcal{F}$ at least $q$ of
them can be hit by a single $k$-flat in $T$. Keller and Perles (SoCG 2022)
proved an $(\aleph_0,k+2)$-theorem for $k$-transversals for families of
$(r,R)$-fat convex sets in $\mathbb{R}^d$. They proved that any family
$\mathcal{F}$ of $(r,R)$-fat sets in $\mathbb{R}^d$ satisfying
$(\aleph_{0},k+2)$-property with respect to $k$-transversals can be hit by a
finite number of $k$-flats. In this paper, we have extended the
$(\aleph_0,k+2)$-theorem for $k$-transversals without the fatness assumption by
introducing a notion, called \emph{$k$-growing sequence}. Moreover, we have
proved a heterochromatic version of $(\aleph_0,k+2)$-theorem for
$k$-transversals for families of both $(r,R)$-fat sets and more general convex
sets. We have also proved a colorful generalization of the \emph{Helly-type}
theorem for $k$-transversals of convex sets due to Aronov, Goodman and Pollack.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-02T01:30:00Z">Monday, January 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
