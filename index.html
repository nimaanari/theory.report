<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-02-14T14:31:58Z">Tuesday, February 14 2023, 14:31</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, February 14
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/02/14/absolutely-sensational-morning-news-zander-kelley-and-raghua-meka-proved-behrend-type-bounds-for-3aps/'>Absolutely Sensational Morning News – Zander Kelley and Raghu Meka proved Behrend-type bounds for 3APs</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          What is the density of a subset of that guarantees that contains a 3-term arithmetic progression? And, more generally, if the density of is what is the minimum number of 3-terms AP that contains? These problems and the more general &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><img data-attachment-id="23891" data-permalink="https://gilkalai.wordpress.com/2023/02/14/absolutely-sensational-morning-news-zander-kelley-and-raghua-meka-proved-behrend-type-bounds-for-3aps/ultimate-roth-3/" data-orig-file="https://gilkalai.files.wordpress.com/2023/02/ultimate-roth-2.jpg" data-orig-size="770,372" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="ultimate-roth" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/02/ultimate-roth-2.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/02/ultimate-roth-2.jpg?w=640" class="alignnone size-full wp-image-23891" src="https://gilkalai.files.wordpress.com/2023/02/ultimate-roth-2.jpg?w=640" alt="ultimate-roth" srcset="https://gilkalai.files.wordpress.com/2023/02/ultimate-roth-2.jpg?w=640 640w, https://gilkalai.files.wordpress.com/2023/02/ultimate-roth-2.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2023/02/ultimate-roth-2.jpg?w=300 300w, https://gilkalai.files.wordpress.com/2023/02/ultimate-roth-2.jpg?w=768 768w, https://gilkalai.files.wordpress.com/2023/02/ultimate-roth-2.jpg 770w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p>What is the density of a subset <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots+%2C+n+%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots+%2C+n+%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots+%2C+n+%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{1,2,&#92;dots , n &#92;}" class="latex" /> that guarantees that <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> contains a 3-term arithmetic progression? And, more generally, if the density of <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;delta" class="latex" /> what is the minimum number of 3-terms AP that <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> contains?</p>
<p>These problems and the more general problems for <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-term AP, are very exciting and mathematicians worked on them extensively in the last century. (We devoted <a href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/">several</a>  posts to earlier breakthroughs.)</p>
<p>This morning. a striking new paper by Zander Kelley and Raghu Meka appeared on the arXiv describing an absolutely amazing breakthrough. (I am thankful to <span class="gI"><span class="qu" role="gridcell"><span class="gD">Ryan Alweiss for telling me about it.) Here is the link to the paper<br />
</span></span></span></p>
<h3 class="title mathjax"><a href="https://arxiv.org/abs/2302.05537">Strong Bounds for 3-Progressions</a>, by Zander Kelley and Raghu Meka</h3>
<p><strong>Abstract:</strong> We show that for some constant <span id="MathJax-Element-1-Frame" class="MathJax"><span id="MathJax-Span-1" class="math"><span id="MathJax-Span-2" class="mrow"><span id="MathJax-Span-3" class="mi">β</span><span id="MathJax-Span-4" class="mo">&gt;</span><span id="MathJax-Span-5" class="mn">0</span></span></span></span>, any subset <span id="MathJax-Element-2-Frame" class="MathJax"><span id="MathJax-Span-6" class="math"><span id="MathJax-Span-7" class="mrow"><span id="MathJax-Span-8" class="mi">A</span></span></span></span> of integers <span id="MathJax-Element-3-Frame" class="MathJax"><span id="MathJax-Span-9" class="math"><span id="MathJax-Span-10" class="mrow"><span id="MathJax-Span-11" class="mo">{</span><span id="MathJax-Span-12" class="mn">1</span><span id="MathJax-Span-13" class="mo">,</span><span id="MathJax-Span-14" class="mo">…</span><span id="MathJax-Span-15" class="mo">,</span><span id="MathJax-Span-16" class="mi">N</span><span id="MathJax-Span-17" class="mo">}</span></span></span></span> of size at least</p>
<p><img src="https://s0.wp.com/latex.php?latex=2%5E%7B-O%28%28%5Clog+N%29%5E%5Cbeta%29%7D+%5Ccdot+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7B-O%28%28%5Clog+N%29%5E%5Cbeta%29%7D+%5Ccdot+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7B-O%28%28%5Clog+N%29%5E%5Cbeta%29%7D+%5Ccdot+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{-O((&#92;log N)^&#92;beta)} &#92;cdot N" class="latex" /></p>
<p>contains a non-trivial three-term arithmetic progression. Previously, three-term arithmetic progressions were known to exist only for sets of size at least <img src="https://s0.wp.com/latex.php?latex=N%2F%28%5Clog+N%29%5E%7B1+%2B+c%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N%2F%28%5Clog+N%29%5E%7B1+%2B+c%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N%2F%28%5Clog+N%29%5E%7B1+%2B+c%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N/(&#92;log N)^{1 + c}" class="latex" /> for a constant <img src="https://s0.wp.com/latex.php?latex=c%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&gt;0" class="latex" />.</p>
<p>Our approach is first to develop new analytic techniques for addressing some related questions in the finite-field setting and then to apply some analogous variants of these same techniques, suitably adapted for the more complicated setting of integers.</p>
<p>Huge congratulations to Zander Kelley and Raghu Meka, and to the mathematical community.</p>
<p><img loading="lazy" data-attachment-id="23875" data-permalink="https://gilkalai.wordpress.com/2023/02/14/absolutely-sensational-morning-news-zander-kelley-and-raghua-meka-proved-behrend-type-bounds-for-3aps/3-term-ap-2/" data-orig-file="https://gilkalai.files.wordpress.com/2023/02/3-term-ap-1.jpg" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="3-term AP" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/02/3-term-ap-1.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/02/3-term-ap-1.jpg?w=640" class="alignnone  wp-image-23875" src="https://gilkalai.files.wordpress.com/2023/02/3-term-ap-1.jpg?w=463&#038;h=463" alt="3-term AP" width="463" height="463" srcset="https://gilkalai.files.wordpress.com/2023/02/3-term-ap-1.jpg?w=463&amp;h=463 463w, https://gilkalai.files.wordpress.com/2023/02/3-term-ap-1.jpg?w=926&amp;h=926 926w, https://gilkalai.files.wordpress.com/2023/02/3-term-ap-1.jpg?w=150&amp;h=150 150w, https://gilkalai.files.wordpress.com/2023/02/3-term-ap-1.jpg?w=300&amp;h=300 300w, https://gilkalai.files.wordpress.com/2023/02/3-term-ap-1.jpg?w=768&amp;h=768 768w" sizes="(max-width: 463px) 100vw, 463px" /></p>
<p>AI generated image showing arithmetic progression by shutterstock.</p>
<p>An earlier 2020 post on 3-term AP and related problems with much bacground on the problem: <a href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/" rel="bookmark">To cheer you up in difficult times 7: Bloom and Sisask just broke the logarithm barrier for Roth’s theorem!;</a></p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T07:42:46Z">Tuesday, February 14 2023, 07:42</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/02/13/novel-proofs-of-the-infinitude-of-primes/'>Novel Proofs of the Infinitude of Primes</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Can they inform computational complexity theory? Bill Gasarch and Christian Elsholtz both like primes and jokes and graphs and ways of sharing baked goods. Bill is a Professor of Computer Science at the University of Maryland; Elsholtz is an Associate Professor of Mathematics at T.U. Graz in Austria. They recently independently came up with a [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>Can they inform computational complexity theory?</em><br />
<font color="#000000"></p>
<p>
Bill Gasarch and Christian Elsholtz both like primes and jokes and graphs and ways of sharing baked goods. Bill is a Professor of Computer Science at the University of Maryland; Elsholtz is an Associate Professor of Mathematics at T.U. Graz in Austria. They recently independently came up with a new proof of the infinitude of the primes.</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/02/13/novel-proofs-of-the-infinitude-of-primes/gasarchelsholtz/" rel="attachment wp-att-21110"><img data-attachment-id="21110" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/13/novel-proofs-of-the-infinitude-of-primes/gasarchelsholtz/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/GasarchElsholtz.png?fit=571%2C457&amp;ssl=1" data-orig-size="571,457" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GasarchElsholtz" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/GasarchElsholtz.png?fit=300%2C240&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/GasarchElsholtz.png?fit=571%2C457&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/GasarchElsholtz.png?resize=300%2C240&#038;ssl=1" alt="" width="300" height="240" class="aligncenter size-medium wp-image-21110" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/GasarchElsholtz.png?resize=300%2C240&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/GasarchElsholtz.png?w=571&amp;ssl=1 571w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">Composite crop of <a href="https://www.facebook.com/wspcphysicsmaths/photos/william-gasarch-problems-with-a-point-exploring-math-and-computer-science-httpsd/2600013870048218/?locale=zh_CN">src1</a>, <a href="https://www.tugraz.at/en/tu-graz/services/news-stories/planet-research/singleview/article/primzahlen-die-atome-der-mathematik0/">src2</a></FONT>
</td>
</tr>
</table>
<p>
Today we discuss reasons for being interested in such new proofs.</p>
<p>
Bill&#8217;s <a href="https://www.cs.umd.edu/~gasarch/">website</a> features his co-written book on the problem of equitably dividing muffins in ways that avoid cutting small pieces, which we covered <a href="https://rjlipton.wpcomstaging.com/2018/06/21/muffins-and-integers/">here</a>. Elsholtz&#8217;s <a href="https://www.math.tugraz.at/~elsholtz/">website</a> reveals that the final oral component of his <em>Habilitation</em>&#8212;the successor to PhD in Germany&#8212;was on &#8220;fair division of sandwiches and cakes.&#8221; We trust that his examiners did not go hungry. </p>
<p>
Bill co-writes the blog <a href="https://blog.computationalcomplexity.org">blog</a> <em>Computational Complexity</em>, which was started by Lance Fortnow in 2002. He <a href="https://blog.computationalcomplexity.org/2023/02/after-you-are-notified-that-article-is.html">posted</a> last week about his new <a href="https://www.sciencedirect.com/science/article/pii/S0012365X23000225?dgcid=author">paper</a> titled, &#8220;Fermat&#8217;s Last Theorem, Schur&#8217;s Theorem (in Ramsey Theory), and the Infinitude of the Primes.&#8221; Elsholtz&#8217;s <a href="https://www.tandfonline.com/doi/epdf/10.1080/00029890.2021.1856544?src=getftr">paper</a> is titled, &#8220;Fermat’s Last Theorem Implies Euclid’s Infinitude of Primes&#8221; and is discussed in this sprightly <a href="https://www.tugraz.at/en/tu-graz/services/news-stories/planet-research/singleview/article/primzahlen-die-atome-der-mathematik0/">interview</a>.</p>
<p>
<p><H2> New Proofs </H2></p>
<p><p>
The issue is: <i>How many ways can we prove that there are an infinite number of primes?</i> We have known this fact since Euclid proved it in his <a href="https://en.wikipedia.org/wiki/Euclid&#37;27s_Elements">Elements</a>&#8212;a few years ago in 300 BCE. </p>
<p>
There are now many proofs known. A relatively recent cool proof came from Filip Saidak. </p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/02/13/novel-proofs-of-the-infinitude-of-primes/fs/" rel="attachment wp-att-21112"><img data-attachment-id="21112" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/13/novel-proofs-of-the-infinitude-of-primes/fs/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/fs.jpeg?fit=172%2C222&amp;ssl=1" data-orig-size="172,222" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fs" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/fs.jpeg?fit=172%2C222&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/fs.jpeg?fit=172%2C222&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/fs.jpeg?resize=172%2C222&#038;ssl=1" alt="" width="172" height="222" class="aligncenter size-full wp-image-21112" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">UNC Greensboro <a href="https://mathstats.uncg.edu/people/directory/saidak/">homepage</a></FONT>
</td>
</tr>
</table>
<p>It can be viewed in PDF <a href="https://mathstats.uncg.edu/wp-content/uploads/2018/08/infinitude-of-primes.pdf">here</a>. Briefly:</p>
<blockquote><p><b> </b> <em> Let <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5C%23%28n%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;#(n)}" class="latex" /> be the number of distinct primes that divide <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />. A key property is: Let <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn+%3E+1%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n &gt; 1}" class="latex" /> be a positive integer. Since <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%2B1%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n+1}" class="latex" /> are consecutive integers, they must be coprime, and hence the number <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+n%28n+%2B+1%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N = n(n + 1)}" class="latex" /> must have <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5C%23%28N%29+%5Cge+%5C%23%28n%29+%2B+1%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;#(N) &#92;ge &#92;#(n) + 1}" class="latex" />. This shows that <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5C%23%28N%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;#(N)}" class="latex" /> must be unbounded. </em>
</p></blockquote>
<p><p>
The site <a href="https://brilliant.org">Brilliant.org</a> maintains a <a href="https://brilliant.org/wiki/infinitely-many-primes/">wiki</a> of proofs. There is also a nice 2013 <a href="https://www.gcsu.edu/sites/files/page-assets/node-808/attachments/harrison.pdf">survey</a> by Lindsey Harrison. </p>
<p>
Bill&#8217;s paper begins with reference to two other recent proofs: a <a href="https://people.math.harvard.edu/~alpoge/papers/monthly&#37;20note.pdf">note</a> by Levent Alpoge and a <a href="https://arxiv.org/pdf/1708.06951.pdf">paper</a> by Andrew Granville. Working separately, they gave novel proofs that the primes are infinite that use Ramsey Theory. Bill&#8217;s abstract continues:</p>
<blockquote><p><b> </b> <em> In particular, they use Van der Waerden&#8217;s Theorem and some number theory. We prove the primes are infinite using an easier theorem from Ramsey Theory, namely Schur&#8217;s Theorem, and some number theory. </em>
</p></blockquote>
<p><p>
Alpoge&#8217;s paper has had several <a href="https://www.semanticscholar.org/paper/van-der-Waerden-and-the-Primes-Alpoge/3b1e75a55465470b0009f35b01a2cfee38bf3603">followups</a>, including a <a href="https://www.semanticscholar.org/paper/A-panopoly-of-proofs-that-there-are-infinitely-many-Granville/ce23103812dd271226b7b47124e008e2932505d4">survey</a> by Granville titled, &#8220;A panoply of proofs that there are infinitely many primes.&#8221; But where does Schur come in?</p>
<p>
<p><H2> A Schur Way To Do It </H2></p>
<p><p>
Issai Schur was a giant in Berlin and Bonn for the first four decades of the 20th century. We once did a <a href="https://rjlipton.wpcomstaging.com/2011/04/08/why-is-everything-named-after-gauss/">post</a> titled on, why is everything named after Carl Gauss?  Schur is no slouch in that department:</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/02/13/novel-proofs-of-the-infinitude-of-primes/schurlist/" rel="attachment wp-att-21114"><img data-attachment-id="21114" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/13/novel-proofs-of-the-infinitude-of-primes/schurlist/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/SchurList.jpg?fit=1129%2C247&amp;ssl=1" data-orig-size="1129,247" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1676224069&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SchurList" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/SchurList.jpg?fit=300%2C66&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/SchurList.jpg?fit=600%2C131&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/SchurList.jpg?resize=565%2C124&#038;ssl=1" alt="" width="565" height="124" class="aligncenter wp-image-21114" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/SchurList.jpg?w=1129&amp;ssl=1 1129w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/SchurList.jpg?resize=300%2C66&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/SchurList.jpg?resize=1024%2C224&amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/SchurList.jpg?resize=768%2C168&amp;ssl=1 768w" sizes="(max-width: 565px) 100vw, 565px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">Wikipedia <a href="https://en.wikipedia.org/wiki/Issai_Schur#Concepts_named_after_Schur">source</a></FONT>
</td>
</tr>
</table>
<p><p>
There&#8217;s more: the highlighted link on &#8220;Schur&#8217;s theorem&#8221; goes to a page of several theorems named for Schur, hence Bill felt the need to disambiguate the one in Ramsey theory. This is simple to state:</p>
<blockquote><p><b>Theorem 1</b> <em> For every partition of the positive integers into finitely many subsets, at least one subset contains integers <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x,y,z}" class="latex" /> such that <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx+%2B+y+%3D+z%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x + y = z}" class="latex" />. </em>
</p></blockquote>
<p><p>
The &#8220;some number theory&#8221; used in both proofs involves cases of Fermat&#8217;s Last Theorem (FLT) for particular <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cgeq+3%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n &#92;geq 3}" class="latex" />. But wait&#8212;aren&#8217;t Schur&#8217;s Theorem and cases of FLT stronger theorems than the infinitude of primes? The relevant facts are:</p>
<ul>
<li>
Schur&#8217;s Theorem follows from Ramsey&#8217;s Theorem in a way that employs no multiplicative properties of the integers. Namely, let <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BK%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{K}" class="latex" /> be the number of subsets. Ramsey gives a number <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N}" class="latex" /> such that any <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BK%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{K}" class="latex" />-coloring of the edges of the complete graph of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{G}" class="latex" /> on <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BN%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{N}" class="latex" /> nodes has a monochrome triangle. &#8220;Color&#8221; each edge <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{(i,j)}" class="latex" /> of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{G}" class="latex" /> by the label of the subset <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bj+-+i%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{j - i}" class="latex" /> belongs to. The triangle gives numbers <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bj+-+i%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{j - i}" class="latex" />, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk+-+j%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k - j}" class="latex" />, and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk+-+i%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k - i}" class="latex" /> in the same subset, and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%28j+-+i%29+%2B+%28k+-+j%29+%3D+%28k+-+i%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{(j - i) + (k - j) = (k - i)}" class="latex" />. </p>
<li>
As remarked directly by Elsholtz, the cases <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%3D3%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n=3}" class="latex" />, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%3D4%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n=4}" class="latex" />, and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%3D5%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n=5}" class="latex" /> of FLT do not rely on having infinitely many primes. </p>
<li>
Known proofs of the full FLT use the infinitude of primes. This leads to open problems about which other cases, besides multiples of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B3%2C4%2C5%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{3,4,5}" class="latex" /> and other known <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />, have proofs that do not require the infinitude of primes.
</ul>
<p>
<p><H2> Their Theorem and Proof </H2></p>
<p><p>
An informal statement of their theorem is:</p>
<blockquote><p><b>Theorem 2</b> <em> In any mathematical structure that models certain simple properties of the integers, if any case <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /> of FLT holds then the structure has infinitely many irreducible elements. </em>
</p></blockquote>
<p><p>
For an integral domain, that is equivalent to having infinitely many primes. The main property needed, which Bill calls &#8220;atomic,&#8221; is that all nonzero elements <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> can be formed by multiplying together powers of irreducible elements (and a unit like <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{-1}" class="latex" /> if needed), that is, </p>
<p align=center><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+p_1%5E%7Be_1%7D+p_2%5E%7Be_2%7D+%5Ccdots+p_k%5E%7Be_k%7D+&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle  x = p_1^{e_1} p_2^{e_2} &#92;cdots p_k^{e_k} " class="latex" /></p>
<p>with each <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Be_i+%5Cgeq+0%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{e_i &#92;geq 0}" class="latex" />. Such a representation need not be unique like it is in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathbb{Z}}" class="latex" />, and the concept does not presuppose having infinitely many irreducibles. Our informal rendition of their proof is lighter on notation but still complete.</p>
<p>
<em>Proof:</em>  Given <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />, suppose there are only finitely many irreducibles <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp_1%2C%5Cdots%2Cp_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p_1,&#92;dots,p_k}" class="latex" />. Every integer <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> can be decomposed as an <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />-th power <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bq_x%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{q_x}" class="latex" /> times a number <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Br%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{r}" class="latex" /> that has no <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />-th power as a divisor. By the &#8220;atomic&#8221; hypothesis, the <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Br%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{r}" class="latex" /> part can always be written as a product of powers of the <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p_i}" class="latex" />. Those powers must all be less than <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />. That leaves <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n^k}" class="latex" /> possible patterns for <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Br%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{r}" class="latex" />, and the integers produced by each pattern becomes the partition into <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n^k}" class="latex" /> subsets. Schur then gives a subset <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Br%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{r}" class="latex" /> containing a triple <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx+%2B+y+%3D+z%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x + y = z}" class="latex" />. This means </p>
<p align=center><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++q_x+r+%2B+q_y+r+%3D+q_z+r%2C+%5Cqquad%5Ctext%7Bso%7D%5Cqquad+q_x+%2B+q_r+%2B+q_z.+&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle  q_x r + q_y r = q_z r, &#92;qquad&#92;text{so}&#92;qquad q_x + q_r + q_z. " class="latex" /></p>
<p>But since <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bq_x%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{q_x}" class="latex" />, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bq_y%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{q_y}" class="latex" />, and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bq_z%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{q_z}" class="latex" /> are all <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />-th powers, this contradicts the case <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /> of FLT. <img decoding="async" src="https://s0.wp.com/latex.php?latex=%5CBox&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;Box" class="latex" /></p>
<p>
Both papers have much additional content. Bill&#8217;s focuses on the relationships of axioms and logical models resembling the integers. Elsholtz&#8217;s has more number theory. This speaks to the lineage of their PhD advisors. Bill was co-advised by Harry Lewis, whom we <a href="https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/">mentioned</a> recently, and Albert Meyer, a top theorist known for deep connections between machine computations and arithmetical structures. Elsholtz&#8217;s PhD advisor, Wolfgang Schwarz, was a student of Carl Siegel, a giant of analytic number theory, whose work on the Riemann Hypothesis has been in <a href="https://arxiv.org/abs/2211.02515">recent</a> <a href="https://science.thewire.in/the-sciences/yitang-zhang-landau-siegel-zeroes-riemann-hypothesis/">news</a> that we have not yet had time to appraise. </p>
<p>
<p><H2> More New Proofs? </H2></p>
<p><p>
That their theorem shows certain other structures besides the integers must have infinitely many irreducibles is a further reason to care about it. To quote Elsholtz, its flip side informs what must happen in &#8220;worlds with only finitely many primes.&#8221; In complexity theory we also consider different &#8220;<a href="https://blog.computationalcomplexity.org/2004/06/impagliazzos-five-worlds.html">worlds</a>,&#8221; some in which <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{P = NP}}" class="latex" /> and other important unknown assertions go one way, others the opposite. We wonder if there is any meeting of worlds to eb found here.</p>
<p>
In particular, we wonder: are there are proofs of the infinitude of primes that use complexity theory rather than number theory? The best we can do is unfortunately weak. We can prove for example:</p>
<p>
<b>Theorem</b>: <i>If RSA is not breakable in linear time, then the primes are infinite</i>.</p>
<p>
This shows that <a href="https://www.geeksforgeeks.org/rsa-algorithm-cryptography/">RSA</a> being hard to crack implies that there must be infinitely many primes. But this is a &#8220;swiz&#8221; in that the notion of linear time is asymptotic in a way that makes this mostly presuppose what it purports to prove.</p>
<p>
<i>Wait a minute.</i> We can do a little better. Here is a proof of the infinitude of primes that is more concrete in complexity terms. Look at the numbers that have at most <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />-bit binary representation&#8212;denote them by <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{A}" class="latex" />. The relevant abstract properties we need, besides &#8220;atomic,&#8221; are that all members of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{A}" class="latex" /> are <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%3C+2%5E%7Bn%2B1%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&lt; 2^{n+1}}" class="latex" /> and there are exponentially many of them. Suppose that there are at most <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> primes: <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bp_1%2C%5Cdots%2Cp_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{p_1,&#92;dots,p_k}" class="latex" />. The members of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{A}" class="latex" /> have representations </p>
<p align=center><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7Bp_1%7D%5E%7Be_1%7D+%7Bp_2%7D%5E%7Be_2%7D+%5Ccdots+%7Bp_k%7D%5E%7Be_k%7D+%3C+2%5E%7Bn%2B1%7D.+&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle  {p_1}^{e_1} {p_2}^{e_2} &#92;cdots {p_k}^{e_k} &lt; 2^{n+1}. " class="latex" /></p>
<p>This shows that each <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Be_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{e_k}" class="latex" /> is at most <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />. (Or, if we have an abstract structure in which <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B1+%3C+%7Cp_i%7C+%3C+2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{1 &lt; |p_i| &lt; 2}" class="latex" /> is allowed, there must be a minimum magnitude <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B1%2B%5Cepsilon%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{1+&#92;epsilon}" class="latex" />, and then each <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Be_k%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{e_k}" class="latex" /> is at most <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /> times <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B%5Clog%281%2B%5Cepsilon%29%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;frac{1}{&#92;log(1+&#92;epsilon)}}" class="latex" />, for which the argument easily adjusts.) So the cardinality of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{A}" class="latex" /> can be at most </p>
<p align=center><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cunderbrace%7Bn+%5Ctimes+%5Ccdots+%5Ctimes+n%7D_%7Bk%5Crm%5C+times%7D+%3D+n%5Ek.+&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle  &#92;underbrace{n &#92;times &#92;cdots &#92;times n}_{k&#92;rm&#92; times} = n^k. " class="latex" /></p>
<p>This means that <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> must be unbounded, since <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{A}" class="latex" /> has exponential size. This actually proves a stronger lower bound on the density of primes than Euclid&#8217;s proof and some of the others. </p>
<p>
In fact, this is much the same as Axel Thue&#8217;s <a href="https://www.cut-the-knot.org/proofs/ThueInfinitudeOfPrimes.shtml">proof</a>, and the &#8220;proof by information theory&#8221; on the Brilliant.org wiki linked above. </p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Can we get other complexity based proofs? Note it is interesting that the above proof uses the concept of <a href="https://en.wikipedia.org/wiki/Binary_number">binary numbers</a> to get a proof. That concept was discovered long after Euclid, in the 16th and 17th centuries by Thomas Harriot, Juan Lobkowitz, and Gottfried Leibniz among Europeans. </p>
<p>
Schur&#8217;s Theorem has a version for Pythagorean triples <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Ba%5E2+%2B+b%5E2+%3D+c%5E2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{a^2 + b^2 = c^2}" class="latex" /> rather than sums. We <a href="https://rjlipton.wpcomstaging.com/2016/09/04/how-hard-really-is-sat/">covered</a> the prodigious instances of SAT that accompany the search for exact bounds on cases of these theorems.</p>
<p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T04:09:43Z">Tuesday, February 14 2023, 04:09</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05575'>Compositional Algorithms on Compositional Data: Deciding Sheaves on Presheaves</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ernst Althaus, Benjamin Merlin Bumpus, James Fairbanks, Daniel Rosiak</p><p>Algorithmicists are well-aware that fast dynamic programming algorithms are
very often the correct choice when computing on compositional (or even
recursive) graphs. Here we initiate the study of how to generalize this
folklore intuition to mathematical structures writ large. We achieve this
horizontal generality by adopting a categorial perspective which allows us to
show that: (1) structured decompositions (a recent, abstract generalization of
many graph decompositions) define Grothendieck topologies on categories of data
(adhesive categories) and that (2) any computational problem which can be
represented as a sheaf with respect to these topologies can be decided in
linear time on classes of inputs which admit decompositions of bounded width
and whose decomposition shapes have bounded feedback vertex number. This
immediately leads to algorithms on objects of any C-set category; these include
-- to name but a few examples -- structures such as: symmetric graphs, directed
graphs, directed multigraphs, hypergraphs, directed hypergraphs, databases,
simplicial complexes, circular port graphs and half-edge graphs.
</p>
<p>Thus we initiate the bridging of tools from sheaf theory, structural graph
theory and parameterized complexity theory; we believe this to be a very
fruitful approach for a general, algebraic theory of dynamic programming
algorithms. Finally we pair our theoretical results with concrete
implementations of our main algorithmic contribution in the AlgebraicJulia
ecosystem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Althaus_E/0/1/0/all/0/1">Ernst Althaus</a>, <a href="http://arxiv.org/find/cs/1/au:+Bumpus_B/0/1/0/all/0/1">Benjamin Merlin Bumpus</a>, <a href="http://arxiv.org/find/cs/1/au:+Fairbanks_J/0/1/0/all/0/1">James Fairbanks</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosiak_D/0/1/0/all/0/1">Daniel Rosiak</a></p><p>Algorithmicists are well-aware that fast dynamic programming algorithms are
very often the correct choice when computing on compositional (or even
recursive) graphs. Here we initiate the study of how to generalize this
folklore intuition to mathematical structures writ large. We achieve this
horizontal generality by adopting a categorial perspective which allows us to
show that: (1) structured decompositions (a recent, abstract generalization of
many graph decompositions) define Grothendieck topologies on categories of data
(adhesive categories) and that (2) any computational problem which can be
represented as a sheaf with respect to these topologies can be decided in
linear time on classes of inputs which admit decompositions of bounded width
and whose decomposition shapes have bounded feedback vertex number. This
immediately leads to algorithms on objects of any C-set category; these include
-- to name but a few examples -- structures such as: symmetric graphs, directed
graphs, directed multigraphs, hypergraphs, directed hypergraphs, databases,
simplicial complexes, circular port graphs and half-edge graphs.
</p>
<p>Thus we initiate the bridging of tools from sheaf theory, structural graph
theory and parameterized complexity theory; we believe this to be a very
fruitful approach for a general, algebraic theory of dynamic programming
algorithms. Finally we pair our theoretical results with concrete
implementations of our main algorithmic contribution in the AlgebraicJulia
ecosystem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05972'>On the Existence of Anomalies</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samuel Epstein</p><p>The Independence Postulate (IP) is a finitary Church-Turing Thesis, saying
mathematical sequences are independent from physical ones. IP implies the
existence of anomalies.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1">Samuel Epstein</a></p><p>The Independence Postulate (IP) is a finitary Church-Turing Thesis, saying
mathematical sequences are independent from physical ones. IP implies the
existence of anomalies.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05644'>Partial k-means to avoid outliers, mathematical programming formulations, complexity results</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicolas Dupin, Frank Nielsen</p><p>A known bottleneck of Min-Sum-of-Square Clustering (MSSC, also denoted
k-means problem) is to tackle the perturbation implied by outliers. This paper
proposes a partial clustering variant, denoted PMSSC, considering a fixed
number of outliers to remove. Integer Programming formulations are proposed.
Complexity results extending the ones from MSSC are studied. PMSSC is NP-hard
in a general Euclidean space, and also when dimension or the number of clusters
is upper than 2. Lastly, one dimensional case are studied. Unweighted PMSSC is
polynomial in theses cases with a dynamic programming algorithm, extending the
optimality property of MSSC with interval clustering. A weaker optimality
property holds for weighted PMSSC, NP-hardness remains still an open question
in dimension one.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dupin_N/0/1/0/all/0/1">Nicolas Dupin</a>, <a href="http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1">Frank Nielsen</a></p><p>A known bottleneck of Min-Sum-of-Square Clustering (MSSC, also denoted
k-means problem) is to tackle the perturbation implied by outliers. This paper
proposes a partial clustering variant, denoted PMSSC, considering a fixed
number of outliers to remove. Integer Programming formulations are proposed.
Complexity results extending the ones from MSSC are studied. PMSSC is NP-hard
in a general Euclidean space, and also when dimension or the number of clusters
is upper than 2. Lastly, one dimensional case are studied. Unweighted PMSSC is
polynomial in theses cases with a dynamic programming algorithm, extending the
optimality property of MSSC with interval clustering. A weaker optimality
property holds for weighted PMSSC, NP-hardness remains still an open question
in dimension one.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05510'>Support Generation for Robot-Assisted 3D Printing with Curved Layers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tianyu Zhang, Yuming Huang, Piotr Kukulski, Neelotpal Dutta, Guoxin Fang, Charlie C.L. Wang</p><p>Robot-assisted 3D printing has drawn a lot of attention by its capability to
fabricate curved layers that are optimized according to different objectives.
However, the support generation algorithm based on a fixed printing direction
for planar layers cannot be directly applied for curved layers as the
orientation of material accumulation is dynamically varied. In this paper, we
propose a skeleton-based support generation method for robot-assisted 3D
printing with curved layers. The support is represented as an implicit solid so
that the problems of numerical robustness can be effectively avoided. The
effectiveness of our algorithm is verified on a dual-material printing platform
that consists of a robotic arm and a newly designed dual-material extruder.
Experiments have been successfully conducted on our system to fabricate a
variety of freeform models.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yuming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kukulski_P/0/1/0/all/0/1">Piotr Kukulski</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_N/0/1/0/all/0/1">Neelotpal Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_G/0/1/0/all/0/1">Guoxin Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Charlie C.L. Wang</a></p><p>Robot-assisted 3D printing has drawn a lot of attention by its capability to
fabricate curved layers that are optimized according to different objectives.
However, the support generation algorithm based on a fixed printing direction
for planar layers cannot be directly applied for curved layers as the
orientation of material accumulation is dynamically varied. In this paper, we
propose a skeleton-based support generation method for robot-assisted 3D
printing with curved layers. The support is represented as an implicit solid so
that the problems of numerical robustness can be effectively avoided. The
effectiveness of our algorithm is verified on a dual-material printing platform
that consists of a robotic arm and a newly designed dual-material extruder.
Experiments have been successfully conducted on our system to fabricate a
variety of freeform models.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05937'>The Two-Squirrel Problem and Its Relatives</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sergey Bereg, Yuya Higashikawa, Naoki Katoh, Manuel Lafond, Yuki Tokuni, Binhai Zhu</p><p>In this paper, we start with a variation of the star cover problem called the
Two-Squirrel problem. Given a set $P$ of $2n$ points in the plane, and two
sites $c_1$ and $c_2$, compute two $n$-stars $S_1$ and $S_2$ centered at $c_1$
and $c_2$ respectively such that the maximum weight of $S_1$ and $S_2$ is
minimized. This problem is strongly NP-hard by a reduction from Equal-size
Set-Partition with Rationals. Then we consider two variations of the
Two-Squirrel problem, namely the Two-MST and Two-TSP problem, which are both
NP-hard. The NP-hardness for the latter is obvious while the former needs a
non-trivial reduction from Equal-size Set-Partition with Rationals. In terms of
approximation algorithms, for Two-MST and Two-TSP we give factor 3.6402 and
$4+\varepsilon$ approximations respectively. Finally, we also show some
interesting polynomial-time solvable cases for Two-MST.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bereg_S/0/1/0/all/0/1">Sergey Bereg</a>, <a href="http://arxiv.org/find/cs/1/au:+Higashikawa_Y/0/1/0/all/0/1">Yuya Higashikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Katoh_N/0/1/0/all/0/1">Naoki Katoh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lafond_M/0/1/0/all/0/1">Manuel Lafond</a>, <a href="http://arxiv.org/find/cs/1/au:+Tokuni_Y/0/1/0/all/0/1">Yuki Tokuni</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1">Binhai Zhu</a></p><p>In this paper, we start with a variation of the star cover problem called the
Two-Squirrel problem. Given a set $P$ of $2n$ points in the plane, and two
sites $c_1$ and $c_2$, compute two $n$-stars $S_1$ and $S_2$ centered at $c_1$
and $c_2$ respectively such that the maximum weight of $S_1$ and $S_2$ is
minimized. This problem is strongly NP-hard by a reduction from Equal-size
Set-Partition with Rationals. Then we consider two variations of the
Two-Squirrel problem, namely the Two-MST and Two-TSP problem, which are both
NP-hard. The NP-hardness for the latter is obvious while the former needs a
non-trivial reduction from Equal-size Set-Partition with Rationals. In terms of
approximation algorithms, for Two-MST and Two-TSP we give factor 3.6402 and
$4+\varepsilon$ approximations respectively. Finally, we also show some
interesting polynomial-time solvable cases for Two-MST.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.06012'>Computation with Large Advice</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hiroki Morizumi</p><p>In this paper, we consider a new direction of computation, which we call
computation with large advice. We mainly consider constant space computation
with large advice in Turing machines, and prove the following facts.
\begin{itemize} \item The class of decision problems solvable by a constant
space Turing machine with polynomial-size advice includes nonuniform-{\sf
NC}$^1$. \item The class of decision problems solvable by a constant space
Turing machine with quasipolynomial-size advice equals nonuniform-{\sf polyL}.
\end{itemize} The facts mean constant space computation with large advice has
an unexpected computational power. On the other hand, we attempt to propose a
concept of ``algorithms with large advice''. In the proposal, advice is
precomputed data for a problem and a fixed instance size, and we expect
efficient algorithms by large or huge advice.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Morizumi_H/0/1/0/all/0/1">Hiroki Morizumi</a></p><p>In this paper, we consider a new direction of computation, which we call
computation with large advice. We mainly consider constant space computation
with large advice in Turing machines, and prove the following facts.
\begin{itemize} \item The class of decision problems solvable by a constant
space Turing machine with polynomial-size advice includes nonuniform-{\sf
NC}$^1$. \item The class of decision problems solvable by a constant space
Turing machine with quasipolynomial-size advice equals nonuniform-{\sf polyL}.
\end{itemize} The facts mean constant space computation with large advice has
an unexpected computational power. On the other hand, we attempt to propose a
concept of ``algorithms with large advice''. In the proposal, advice is
precomputed data for a problem and a fixed instance size, and we expect
efficient algorithms by large or huge advice.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05505'>Characterization of Simplicial Complexes by Counting Simplets Beyond Four Nodes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hyunju Kim, Jihoon Ko, Fanchen Bu, Kijung Shin</p><p>Simplicial complexes are higher-order combinatorial structures which have
been used to represent real-world complex systems. In this paper, we
concentrate on the local patterns in simplicial complexes called
\textit{simplets}, a generalization of graphlets. We formulate the problem of
counting simplets of a given size in a given simplicial complex. For this
problem, we extend a sampling algorithm based on color coding from graphs to
simplicial complexes, with essential technical novelty. We theoretically
analyze our proposed algorithm named SC3, showing its correctness,
unbiasedness, convergence, and time/space complexity. Through the extensive
experiments on sixteen real-world datasets, we show the superiority of SC3 in
terms of accuracy, speed, and scalability, compared to the baseline methods.
Finally, we use the counts given by SC3 for simplicial complex analysis,
especially for characterization, which is further used for simplicial complex
clustering, where SC3 shows a strong ability of characterization with
domain-based similarity.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyunju Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1">Jihoon Ko</a>, <a href="http://arxiv.org/find/cs/1/au:+Bu_F/0/1/0/all/0/1">Fanchen Bu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1">Kijung Shin</a></p><p>Simplicial complexes are higher-order combinatorial structures which have
been used to represent real-world complex systems. In this paper, we
concentrate on the local patterns in simplicial complexes called
\textit{simplets}, a generalization of graphlets. We formulate the problem of
counting simplets of a given size in a given simplicial complex. For this
problem, we extend a sampling algorithm based on color coding from graphs to
simplicial complexes, with essential technical novelty. We theoretically
analyze our proposed algorithm named SC3, showing its correctness,
unbiasedness, convergence, and time/space complexity. Through the extensive
experiments on sixteen real-world datasets, we show the superiority of SC3 in
terms of accuracy, speed, and scalability, compared to the baseline methods.
Finally, we use the counts given by SC3 for simplicial complex analysis,
especially for characterization, which is further used for simplicial complex
clustering, where SC3 shows a strong ability of characterization with
domain-based similarity.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05520'>Synchrony/Asynchrony vs. Stationary/Mobile? The Latter is Superior...in Theory</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eli Gafni, Vasileios Zikas</p><p>Like Asynchrony, Mobility of faults precludes consensus. Yet, a model M in
which Consensus is solvable, has an analogue relaxed model in which Consensus
is not solvable and for which we can ask, whether Consensus is solvable if the
system initially behaves like the relaxed analogue model, but eventually morphs
into M. We consider two relaxed analogues of M. The first is the traditional
Asynchronous model, and the second to be defined, the Mobile analogue. While
for some M we show that Consensus is not solvable in the Asynchronous analogue,
it is solvable in all the Mobile analogues. Hence, from this perspective
Mobility is superior to Asynchrony.
</p>
<p>The pie in the sky relationship we envision is: Consensus is solvable in M,
if and only if binary Commit-Adopt is solvable in the mobile analogue.
</p>
<p>The ``only if'' is easy. Here we show case by case that the ``if'' holds for
all the common faults types.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gafni_E/0/1/0/all/0/1">Eli Gafni</a>, <a href="http://arxiv.org/find/cs/1/au:+Zikas_V/0/1/0/all/0/1">Vasileios Zikas</a></p><p>Like Asynchrony, Mobility of faults precludes consensus. Yet, a model M in
which Consensus is solvable, has an analogue relaxed model in which Consensus
is not solvable and for which we can ask, whether Consensus is solvable if the
system initially behaves like the relaxed analogue model, but eventually morphs
into M. We consider two relaxed analogues of M. The first is the traditional
Asynchronous model, and the second to be defined, the Mobile analogue. While
for some M we show that Consensus is not solvable in the Asynchronous analogue,
it is solvable in all the Mobile analogues. Hence, from this perspective
Mobility is superior to Asynchrony.
</p>
<p>The pie in the sky relationship we envision is: Consensus is solvable in M,
if and only if binary Commit-Adopt is solvable in the mobile analogue.
</p>
<p>The ``only if'' is easy. Here we show case by case that the ``if'' holds for
all the common faults types.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05526'>A Linear Delay Algorithm for Enumeration of 2-Edge/Vertex-connected Induced Subgraphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Takumi Tada, Kazuya Haraguchi</p><p>For a set system $(V,{\mathcal C}\subseteq 2^V)$, we call a subset
$C\in{\mathcal C}$ a component. A nonempty subset $Y\subseteq C$ is a minimal
removable set (MRS) of $C$ if $C\setminus Y\in{\mathcal C}$ and no proper
nonempty subset $Z\subsetneq Y$ satisfies $C\setminus Z\in{\mathcal C}$. In
this paper, we consider the problem of enumerating all components in a set
system such that, for every two components $C,C'\in{\mathcal C}$ with
$C'\subsetneq C$, every MRS $X$ of $C$ satisfies either $X\subseteq C'$ or
$X\cap C'=\emptyset$. We provide a partition-based algorithm for this problem,
which yields the first linear delay algorithms to enumerate all
2-edge-connected induced subgraphs, and to enumerate all 2-vertex-connected
induced subgraphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tada_T/0/1/0/all/0/1">Takumi Tada</a>, <a href="http://arxiv.org/find/cs/1/au:+Haraguchi_K/0/1/0/all/0/1">Kazuya Haraguchi</a></p><p>For a set system $(V,{\mathcal C}\subseteq 2^V)$, we call a subset
$C\in{\mathcal C}$ a component. A nonempty subset $Y\subseteq C$ is a minimal
removable set (MRS) of $C$ if $C\setminus Y\in{\mathcal C}$ and no proper
nonempty subset $Z\subsetneq Y$ satisfies $C\setminus Z\in{\mathcal C}$. In
this paper, we consider the problem of enumerating all components in a set
system such that, for every two components $C,C'\in{\mathcal C}$ with
$C'\subsetneq C$, every MRS $X$ of $C$ satisfies either $X\subseteq C'$ or
$X\cap C'=\emptyset$. We provide a partition-based algorithm for this problem,
which yields the first linear delay algorithms to enumerate all
2-edge-connected induced subgraphs, and to enumerate all 2-vertex-connected
induced subgraphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05552'>Algorithmically Effective Differentially Private Synthetic Data</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yiyun He, Roman Vershynin, Yizhe Zhu</p><p>We present a highly effective algorithmic approach for generating
$\varepsilon$-differentially private synthetic data in a bounded metric space
with near-optimal utility guarantees under the 1-Wasserstein distance. In
particular, for a dataset $\mathcal X$ in the hypercube $[0,1]^d$, our
algorithm generates synthetic dataset $\mathcal Y$ such that the expected
1-Wasserstein distance between the empirical measure of $\mathcal X$ and
$\mathcal Y$ is $O((\varepsilon n)^{-1/d})$ for $d\geq 2$, and is
$O(\log^2(\varepsilon n)(\varepsilon n)^{-1})$ for $d=1$. The accuracy
guarantee is optimal up to a constant factor for $d\geq 2$, and up to a
logarithmic factor for $d=1$. Our algorithm has a fast running time of
$O(\varepsilon n)$ for all $d\geq 1$ and demonstrates improved accuracy
compared to the method in (Boedihardjo et al., 2022) for $d\geq 2$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yiyun He</a>, <a href="http://arxiv.org/find/cs/1/au:+Vershynin_R/0/1/0/all/0/1">Roman Vershynin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yizhe Zhu</a></p><p>We present a highly effective algorithmic approach for generating
$\varepsilon$-differentially private synthetic data in a bounded metric space
with near-optimal utility guarantees under the 1-Wasserstein distance. In
particular, for a dataset $\mathcal X$ in the hypercube $[0,1]^d$, our
algorithm generates synthetic dataset $\mathcal Y$ such that the expected
1-Wasserstein distance between the empirical measure of $\mathcal X$ and
$\mathcal Y$ is $O((\varepsilon n)^{-1/d})$ for $d\geq 2$, and is
$O(\log^2(\varepsilon n)(\varepsilon n)^{-1})$ for $d=1$. The accuracy
guarantee is optimal up to a constant factor for $d\geq 2$, and up to a
logarithmic factor for $d=1$. Our algorithm has a fast running time of
$O(\varepsilon n)$ for all $d\geq 1$ and demonstrates improved accuracy
compared to the method in (Boedihardjo et al., 2022) for $d\geq 2$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05633'>Improved Competitive Ratio for Edge-Weighted Online Stochastic Matching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yilong Feng, Guoliang Qiu, Xiaowei Wu, Shengwei Zhou</p><p>We consider the edge-weighted online stochastic matching problem, in which an
edge-weighted bipartite graph G=(I\cup J, E) with offline vertices J and online
vertex types I is given. The online vertices have types sampled from I with
probability proportional to the arrival rates of online vertex types. The
online algorithm must make immediate and irrevocable matching decisions with
the objective of maximizing the total weight of the matching. For the problem
with general arrival rates, Feldman et al. (FOCS 2009) proposed the Suggested
Matching algorithm and showed that it achieves a competitive ratio of 1-1/e
\approx 0.632. The ratio has recently been improved to 0.645 by Yan (2022), who
proposed the Multistage Suggested Matching (MSM) algorithm. In this paper, we
propose the Evolving Suggested Matching (ESM) algorithm, and show that it
achieves a competitive ratio of 0.650.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yilong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_G/0/1/0/all/0/1">Guoliang Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiaowei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shengwei Zhou</a></p><p>We consider the edge-weighted online stochastic matching problem, in which an
edge-weighted bipartite graph G=(I\cup J, E) with offline vertices J and online
vertex types I is given. The online vertices have types sampled from I with
probability proportional to the arrival rates of online vertex types. The
online algorithm must make immediate and irrevocable matching decisions with
the objective of maximizing the total weight of the matching. For the problem
with general arrival rates, Feldman et al. (FOCS 2009) proposed the Suggested
Matching algorithm and showed that it achieves a competitive ratio of 1-1/e
\approx 0.632. The ratio has recently been improved to 0.645 by Yan (2022), who
proposed the Multistage Suggested Matching (MSM) algorithm. In this paper, we
propose the Evolving Suggested Matching (ESM) algorithm, and show that it
achieves a competitive ratio of 0.650.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05681'>An EPTAS for Budgeted Matching and Budgeted Matroid Intersection</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ilan Doron-Arad, Ariel Kulik, Hadas Shachnai</p><p>We study the budgeted versions of the well known matching and matroid
intersection problems. While both problems admit a polynomial-time
approximation scheme (PTAS) [Berger et al. (Math. Programming, 2011), Chekuri,
Vondrak and Zenklusen (SODA 2011)], it has been an intriguing open question
whether these problems admit a fully PTAS (FPTAS), or even an efficient PTAS
(EPTAS).
</p>
<p>In this paper we answer the second part of this question affirmatively, by
presenting an EPTAS for budgeted matching and budgeted matroid intersection. A
main component of our scheme is a novel construction of representative sets for
desired solutions, whose cardinality depends only on $\varepsilon$, the
accuracy parameter. Thus, enumerating over solutions within a representative
set leads to an EPTAS. This crucially distinguishes our algorithms from
previous approaches, which rely on exhaustive enumeration over the solution
set. Our ideas for constructing representative sets may find use in tackling
other budgeted optimization problems, and are thus of independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Doron_Arad_I/0/1/0/all/0/1">Ilan Doron-Arad</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulik_A/0/1/0/all/0/1">Ariel Kulik</a>, <a href="http://arxiv.org/find/cs/1/au:+Shachnai_H/0/1/0/all/0/1">Hadas Shachnai</a></p><p>We study the budgeted versions of the well known matching and matroid
intersection problems. While both problems admit a polynomial-time
approximation scheme (PTAS) [Berger et al. (Math. Programming, 2011), Chekuri,
Vondrak and Zenklusen (SODA 2011)], it has been an intriguing open question
whether these problems admit a fully PTAS (FPTAS), or even an efficient PTAS
(EPTAS).
</p>
<p>In this paper we answer the second part of this question affirmatively, by
presenting an EPTAS for budgeted matching and budgeted matroid intersection. A
main component of our scheme is a novel construction of representative sets for
desired solutions, whose cardinality depends only on $\varepsilon$, the
accuracy parameter. Thus, enumerating over solutions within a representative
set leads to an EPTAS. This crucially distinguishes our algorithms from
previous approaches, which rely on exhaustive enumeration over the solution
set. Our ideas for constructing representative sets may find use in tackling
other budgeted optimization problems, and are thus of independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05682'>A Simple Data Structure for Maintaining a Discrete Probability Distribution</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Allendorf</p><p>We revisit the following problem: given a set of indices $S = \{1, \dots,
n\}$ and weights $w_1, \dots, w_n \in \mathbb{R}_{&gt; 0}$, provide samples from
$S$ with distribution $p(i) = w_i / W$ where $W = \sum_j w_j$ gives the proper
normalization. In the static setting, there is a simple data structure due to
Walker called Alias Table that allows for samples to be drawn in constant time.
A more challenging task is to maintain the distribution in a dynamic setting,
where elements may be added or removed, or weights may change over time; here,
existing solutions restrict the permissible weights, require rebuilding of the
associated data structure after a number of updates, or are rather complex.
</p>
<p>In this paper, we describe, analyze, and engineer a simple data structure for
maintaining a discrete probability distribution in the dynamic setting.
Construction of the data structure for an arbitrary distribution takes time
$O(n)$, sampling takes expected time $O(1)$, and updates of size $\Delta = O(W
/ n)$ can be processed in time $O(1)$. To evaluate the efficiency of the data
structure we conduct an experimental study. The results suggest that the
dynamic sampling performance is comparable to the static Alias Table with a
minor slowdown.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Allendorf_D/0/1/0/all/0/1">Daniel Allendorf</a></p><p>We revisit the following problem: given a set of indices $S = \{1, \dots,
n\}$ and weights $w_1, \dots, w_n \in \mathbb{R}_{&gt; 0}$, provide samples from
$S$ with distribution $p(i) = w_i / W$ where $W = \sum_j w_j$ gives the proper
normalization. In the static setting, there is a simple data structure due to
Walker called Alias Table that allows for samples to be drawn in constant time.
A more challenging task is to maintain the distribution in a dynamic setting,
where elements may be added or removed, or weights may change over time; here,
existing solutions restrict the permissible weights, require rebuilding of the
associated data structure after a number of updates, or are rather complex.
</p>
<p>In this paper, we describe, analyze, and engineer a simple data structure for
maintaining a discrete probability distribution in the dynamic setting.
Construction of the data structure for an arbitrary distribution takes time
$O(n)$, sampling takes expected time $O(1)$, and updates of size $\Delta = O(W
/ n)$ can be processed in time $O(1)$. To evaluate the efficiency of the data
structure we conduct an experimental study. The results suggest that the
dynamic sampling performance is comparable to the static Alias Table with a
minor slowdown.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05707'>On Differential Privacy and Adaptive Data Analysis with Bounded Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Itai Dinur, Uri Stemmer, David P. Woodruff, Samson Zhou</p><p>We study the space complexity of the two related fields of differential
privacy and adaptive data analysis. Specifically,
</p>
<p>(1) Under standard cryptographic assumptions, we show that there exists a
problem P that requires exponentially more space to be solved efficiently with
differential privacy, compared to the space needed without privacy. To the best
of our knowledge, this is the first separation between the space complexity of
private and non-private algorithms.
</p>
<p>(2) The line of work on adaptive data analysis focuses on understanding the
number of samples needed for answering a sequence of adaptive queries. We
revisit previous lower bounds at a foundational level, and show that they are a
consequence of a space bottleneck rather than a sampling bottleneck.
</p>
<p>To obtain our results, we define and construct an encryption scheme with
multiple keys that is built to withstand a limited amount of key leakage in a
very particular way.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dinur_I/0/1/0/all/0/1">Itai Dinur</a>, <a href="http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1">Uri Stemmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Samson Zhou</a></p><p>We study the space complexity of the two related fields of differential
privacy and adaptive data analysis. Specifically,
</p>
<p>(1) Under standard cryptographic assumptions, we show that there exists a
problem P that requires exponentially more space to be solved efficiently with
differential privacy, compared to the space needed without privacy. To the best
of our knowledge, this is the first separation between the space complexity of
private and non-private algorithms.
</p>
<p>(2) The line of work on adaptive data analysis focuses on understanding the
number of samples needed for answering a sequence of adaptive queries. We
revisit previous lower bounds at a foundational level, and show that they are a
consequence of a space bottleneck rather than a sampling bottleneck.
</p>
<p>To obtain our results, we define and construct an encryption scheme with
multiple keys that is built to withstand a limited amount of key leakage in a
very particular way.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05951'>Fully Dynamic Exact Edge Connectivity in Sublinear Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gramoz Goranci, Monika Henzinger, Danupon Nanongkai, Thatchaphol Saranurak, Mikkel Thorup, Christian Wulff-Nilsen</p><p>Given a simple $n$-vertex, $m$-edge graph $G$ undergoing edge insertions and
deletions, we give two new fully dynamic algorithms for exactly maintaining the
edge connectivity of $G$ in $\tilde{O}(n)$ worst-case update time and
$\tilde{O}(m^{1-1/16})$ amortized update time, respectively. Prior to our work,
all dynamic edge connectivity algorithms assumed bounded edge connectivity,
guaranteed approximate solutions, or were restricted to edge insertions only.
Our results answer in the affirmative an open question posed by Thorup
[Combinatorica'07].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goranci_G/0/1/0/all/0/1">Gramoz Goranci</a>, <a href="http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1">Monika Henzinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Nanongkai_D/0/1/0/all/0/1">Danupon Nanongkai</a>, <a href="http://arxiv.org/find/cs/1/au:+Saranurak_T/0/1/0/all/0/1">Thatchaphol Saranurak</a>, <a href="http://arxiv.org/find/cs/1/au:+Thorup_M/0/1/0/all/0/1">Mikkel Thorup</a>, <a href="http://arxiv.org/find/cs/1/au:+Wulff_Nilsen_C/0/1/0/all/0/1">Christian Wulff-Nilsen</a></p><p>Given a simple $n$-vertex, $m$-edge graph $G$ undergoing edge insertions and
deletions, we give two new fully dynamic algorithms for exactly maintaining the
edge connectivity of $G$ in $\tilde{O}(n)$ worst-case update time and
$\tilde{O}(m^{1-1/16})$ amortized update time, respectively. Prior to our work,
all dynamic edge connectivity algorithms assumed bounded edge connectivity,
guaranteed approximate solutions, or were restricted to edge insertions only.
Our results answer in the affirmative an open question posed by Thorup
[Combinatorica'07].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05960'>Computing Truncated Metric Dimension of Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Paul Gutkovich, Zi Song Yeoh</p><p>Let $G=(V,E)$ be a simple, unweighted, connected graph. Let $d(u,v)$ denote
the distance between vertices $u,v$. A resolving set of $G$ is a subset $S$ of
$V$ such that knowing the distance from a vertex $v$ to every vertex in $S$
uniquely identifies $v$. The metric dimension of $G$ is defined as the size of
the smallest resolving set of $G$. We define the $k$-truncated resolving set
and $k$-truncated metric dimension of a graph similarly, but with the notion of
distance replaced with $d_k(u,v) := \min(d(u,v),k+1)$.
</p>
<p>In this paper, we demonstrate that computing $k$-truncated dimension of trees
is NP-Hard for general $k$. We then present a polynomial-time algorithm to
compute $k$-truncated dimension of trees when $k$ is a fixed constant.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gutkovich_P/0/1/0/all/0/1">Paul Gutkovich</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeoh_Z/0/1/0/all/0/1">Zi Song Yeoh</a></p><p>Let $G=(V,E)$ be a simple, unweighted, connected graph. Let $d(u,v)$ denote
the distance between vertices $u,v$. A resolving set of $G$ is a subset $S$ of
$V$ such that knowing the distance from a vertex $v$ to every vertex in $S$
uniquely identifies $v$. The metric dimension of $G$ is defined as the size of
the smallest resolving set of $G$. We define the $k$-truncated resolving set
and $k$-truncated metric dimension of a graph similarly, but with the notion of
distance replaced with $d_k(u,v) := \min(d(u,v),k+1)$.
</p>
<p>In this paper, we demonstrate that computing $k$-truncated dimension of trees
is NP-Hard for general $k$. We then present a polynomial-time algorithm to
compute $k$-truncated dimension of trees when $k$ is a fixed constant.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05966'>Infinite Lewis Weights in Spectral Graph Theory</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Amit Suliman, Omri Weinstein</p><p>We study the spectral implications of re-weighting a graph by the
$\ell_\infty$-Lewis weights of its edges. Our main motivation is the
ER-Minimization problem (Saberi et al., SIAM'08): Given an undirected graph
$G$, the goal is to find positive normalized edge-weights $w\in \mathbb{R}_+^m$
which minimize the sum of pairwise \emph{effective-resistances} of $G_w$
(Kirchhoff's index). By contrast, $\ell_\infty$-Lewis weights minimize the
\emph{maximum} effective-resistance of \emph{edges}, but are much cheaper to
approximate, especially for Laplacians. With this algorithmic motivation, we
study the ER-approximation ratio obtained by Lewis weights.
</p>
<p>Our first main result is that $\ell_\infty$-Lewis weights provide a constant
($\approx 3.12$) approximation for ER-minimization on \emph{trees}. The proof
introduces a new technique, a local polarization process for
effective-resistances ($\ell_2$-congestion) on trees, which is of independent
interest in electrical network analysis. For general graphs, we prove an upper
bound $\alpha(G)$ on the approximation ratio obtained by Lewis weights, which
is always $\leq \min\{ \text{diam}(G), \kappa(L_{w_\infty})\}$, where $\kappa$
is the condition number of the weighted Laplacian. All our approximation
algorithms run in \emph{input-sparsity} time $\tilde{O}(m)$, a major
improvement over Saberi et al.'s $O(m^{3.5})$ SDP for exact ER-minimization.
</p>
<p>Finally, we demonstrate the favorable effects of $\ell_\infty$-LW reweighting
on the \emph{spectral-gap} of graphs and on their \emph{spectral-thinness}
(Anari and Gharan, 2015). En-route to our results, we prove a weighted analogue
of Mohar's classical bound on $\lambda_2(G)$, and provide a new
characterization of leverage-scores of a matrix, as the gradient (w.r.t
weights) of the volume of the enclosing ellipsoid.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Suliman_A/0/1/0/all/0/1">Amit Suliman</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinstein_O/0/1/0/all/0/1">Omri Weinstein</a></p><p>We study the spectral implications of re-weighting a graph by the
$\ell_\infty$-Lewis weights of its edges. Our main motivation is the
ER-Minimization problem (Saberi et al., SIAM'08): Given an undirected graph
$G$, the goal is to find positive normalized edge-weights $w\in \mathbb{R}_+^m$
which minimize the sum of pairwise \emph{effective-resistances} of $G_w$
(Kirchhoff's index). By contrast, $\ell_\infty$-Lewis weights minimize the
\emph{maximum} effective-resistance of \emph{edges}, but are much cheaper to
approximate, especially for Laplacians. With this algorithmic motivation, we
study the ER-approximation ratio obtained by Lewis weights.
</p>
<p>Our first main result is that $\ell_\infty$-Lewis weights provide a constant
($\approx 3.12$) approximation for ER-minimization on \emph{trees}. The proof
introduces a new technique, a local polarization process for
effective-resistances ($\ell_2$-congestion) on trees, which is of independent
interest in electrical network analysis. For general graphs, we prove an upper
bound $\alpha(G)$ on the approximation ratio obtained by Lewis weights, which
is always $\leq \min\{ \text{diam}(G), \kappa(L_{w_\infty})\}$, where $\kappa$
is the condition number of the weighted Laplacian. All our approximation
algorithms run in \emph{input-sparsity} time $\tilde{O}(m)$, a major
improvement over Saberi et al.'s $O(m^{3.5})$ SDP for exact ER-minimization.
</p>
<p>Finally, we demonstrate the favorable effects of $\ell_\infty$-LW reweighting
on the \emph{spectral-gap} of graphs and on their \emph{spectral-thinness}
(Anari and Gharan, 2015). En-route to our results, we prove a weighted analogue
of Mohar's classical bound on $\lambda_2(G)$, and provide a new
characterization of leverage-scores of a matrix, as the gradient (w.r.t
weights) of the volume of the enclosing ellipsoid.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T01:30:00Z">Tuesday, February 14 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, February 13
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/02/13/eric-allenders-day/'>Eric Allender’s day</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          is unfolding at Simons institute (and tomorrow is Valentine&#8217;s day, joke by Rahul).  The speakers are praising Eric&#8217;s many contributions to the field, so I thought I&#8217;d add my praise, since over the years I interacted with Eric in many different capacities, excluding coauthor, but there&#8217;s time to fix that, Eric.  I met him the [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><a href="https://simons.berkeley.edu/workshops/lower-bounds-learning-average-case-complexity/schedule#simons-tabs">is unfolding at Simons institute</a> (and tomorrow is Valentine&#8217;s day, joke by Rahul).  The speakers are praising Eric&#8217;s many contributions to the field, so I thought I&#8217;d add my praise, since over the years I interacted with Eric in many different capacities, excluding coauthor, but there&#8217;s time to fix that, Eric.  I met him the first time 20 years ago in Denmark.  I had already read some of his surveys, and I remember being somewhat surprised that the mental image I had subconsciously created of him didn&#8217;t match the way he looked.  Turns out even he was expecting something different from the emails we had exchanged &#8212; pictures weren&#8217;t online back then.  Anyway, back to more scientific matters, I told him that his surveys were one of the first things I read, and I think he said it was good that they had had an effect.</p>
<p>Indeed, they have, his works and surveys have had a significant impact on my research.  Especially his surveys on low-level complexity classes, a topic dear to my heart.  Counting hierarchies, arithmetic circuits, and the division breakthroughs are some of the many things his surveys exposed me to.  Eric has a unique angle about these topics, and I often go back to his surveys and papers for knowledge and inspiration.  More in line with the topic of the workshop, people are emphasizing how Eric anticipated recent trends, such as &#8220;meta complexity,&#8221; before they were a thing.  Way to go.</p>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T23:10:18Z">Monday, February 13 2023, 23:10</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/13/postdoc-at-institute-of-mathematics-czech-academy-of-sciences-apply-by-march-31-2023/'>postdoc at Institute of Mathematics, Czech Academy of Sciences (apply by March 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Institute of Mathematics of the Czech Academy of Sciences is seeking a researcher for the project “Logic and unsatisfiability”. Applications are invited from candidates who have completed their PhD within the last 5 years (or will have completed it before the time of hiring), and who have a strong background in proof complexity or [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Institute of Mathematics of the Czech Academy of Sciences is seeking a researcher for the project “Logic and unsatisfiability”. Applications are invited from candidates who have completed their PhD within the last 5 years (or will have completed it before the time of hiring), and who have a strong background in proof complexity or bounded arithmetic.</p>
<p>Website: <a href="http://www.math.cas.cz/recrutements/postes.php">http://www.math.cas.cz/recrutements/postes.php</a><br />
Email: thapen@math.cas.cz</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T10:19:11Z">Monday, February 13 2023, 10:19</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05426'>Lower bounds for Choiceless Polynomial Time via Symmetric XOR-circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Benedikt Pago</p><p>Choiceless Polynomial Time (CPT) is one of the few remaining candidate logics
for capturing PTIME. In this paper, we make progress towards separating CPT
from polynomial time by firstly establishing a connection between the
expressive power of CPT and the existence of certain symmetric circuit
families, and secondly, proving lower bounds against these circuits. We focus
on the isomorphism problem of unordered Cai-F\"urer-Immerman-graphs (the
CFI-query) as a potential candidate for separating CPT from P. Results by
Dawar, Richerby and Rossman, and subsequently by Pakusa, Schalth\"ofer and
Selman show that the CFI-query is CPT-definable on linearly ordered and
preordered base graphs with small colour classes. We define a class of
CPT-algorithms, that we call "CFI-symmetric algorithms", which generalises all
the known ones, and show that such algorithms can only define the CFI-query on
a given class of base graphs if there exists a family of symmetric XOR-circuits
with certain properties. These properties include that the circuits have the
same symmetries as the base graphs, are of polynomial size, and satisfy certain
fan-in restrictions. Then we prove that such circuits with slightly
strengthened requirements (i.e. stronger symmetry and fan-in and fan-out
restrictions) do not exist for the n-dimensional hypercubes as base graphs.
This almost separates the CFI-symmetric algorithms from polynomial time - up to
the gap that remains between the circuits whose existence we can currently
disprove and the circuits whose existence is necessary for the definability of
the CFI-query by a CFI-symmetric algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pago_B/0/1/0/all/0/1">Benedikt Pago</a></p><p>Choiceless Polynomial Time (CPT) is one of the few remaining candidate logics
for capturing PTIME. In this paper, we make progress towards separating CPT
from polynomial time by firstly establishing a connection between the
expressive power of CPT and the existence of certain symmetric circuit
families, and secondly, proving lower bounds against these circuits. We focus
on the isomorphism problem of unordered Cai-F\"urer-Immerman-graphs (the
CFI-query) as a potential candidate for separating CPT from P. Results by
Dawar, Richerby and Rossman, and subsequently by Pakusa, Schalth\"ofer and
Selman show that the CFI-query is CPT-definable on linearly ordered and
preordered base graphs with small colour classes. We define a class of
CPT-algorithms, that we call "CFI-symmetric algorithms", which generalises all
the known ones, and show that such algorithms can only define the CFI-query on
a given class of base graphs if there exists a family of symmetric XOR-circuits
with certain properties. These properties include that the circuits have the
same symmetries as the base graphs, are of polynomial size, and satisfy certain
fan-in restrictions. Then we prove that such circuits with slightly
strengthened requirements (i.e. stronger symmetry and fan-in and fan-out
restrictions) do not exist for the n-dimensional hypercubes as base graphs.
This almost separates the CFI-symmetric algorithms from polynomial time - up to
the gap that remains between the circuits whose existence we can currently
disprove and the circuits whose existence is necessary for the definability of
the CFI-query by a CFI-symmetric algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T01:30:00Z">Monday, February 13 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04908'>Certified simultaneous isotopic approximation of pairs of curves via subdivision</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Burr, Michael Byrd</p><p>We present a certified algorithm based on subdivision for computing an
isotopic approximation to a pair of curves in the plane. Our algorithm is based
on the certified curve approximation algorithm of Plantinga and Vegter. The
main challenge in this computation is to correctly and efficiently compute the
intersections of the curves. To address this issue, we introduce a new, but
simple test that guarantees the global correctness of our output.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Burr_M/0/1/0/all/0/1">Michael Burr</a>, <a href="http://arxiv.org/find/cs/1/au:+Byrd_M/0/1/0/all/0/1">Michael Byrd</a></p><p>We present a certified algorithm based on subdivision for computing an
isotopic approximation to a pair of curves in the plane. Our algorithm is based
on the certified curve approximation algorithm of Plantinga and Vegter. The
main challenge in this computation is to correctly and efficiently compute the
intersections of the curves. To address this issue, we introduce a new, but
simple test that guarantees the global correctness of our output.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T01:30:00Z">Monday, February 13 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04963'>Quadratic Memory is Necessary for Optimal Query Complexity in Convex Optimization: Center-of-Mass is Pareto-Optimal</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mo&#xef;se Blanchard, Junhui Zhang, Patrick Jaillet</p><p>We give query complexity lower bounds for convex optimization and the related
feasibility problem. We show that quadratic memory is necessary to achieve the
optimal oracle complexity for first-order convex optimization. In particular,
this shows that center-of-mass cutting-planes algorithms in dimension $d$ which
use $\tilde O(d^2)$ memory and $\tilde O(d)$ queries are Pareto-optimal for
both convex optimization and the feasibility problem, up to logarithmic
factors. Precisely, we prove that to minimize $1$-Lipschitz convex functions
over the unit ball to $1/d^4$ accuracy, any deterministic first-order
algorithms using at most $d^{2-\delta}$ bits of memory must make
$\tilde\Omega(d^{1+\delta/3})$ queries, for any $\delta\in[0,1]$. For the
feasibility problem, in which an algorithm only has access to a separation
oracle, we show a stronger trade-off: for at most $d^{2-\delta}$ memory, the
number of queries required is $\tilde\Omega(d^{1+\delta})$. This resolves a
COLT 2019 open problem of Woodworth and Srebro.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blanchard_M/0/1/0/all/0/1">Mo&#xef;se Blanchard</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junhui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaillet_P/0/1/0/all/0/1">Patrick Jaillet</a></p><p>We give query complexity lower bounds for convex optimization and the related
feasibility problem. We show that quadratic memory is necessary to achieve the
optimal oracle complexity for first-order convex optimization. In particular,
this shows that center-of-mass cutting-planes algorithms in dimension $d$ which
use $\tilde O(d^2)$ memory and $\tilde O(d)$ queries are Pareto-optimal for
both convex optimization and the feasibility problem, up to logarithmic
factors. Precisely, we prove that to minimize $1$-Lipschitz convex functions
over the unit ball to $1/d^4$ accuracy, any deterministic first-order
algorithms using at most $d^{2-\delta}$ bits of memory must make
$\tilde\Omega(d^{1+\delta/3})$ queries, for any $\delta\in[0,1]$. For the
feasibility problem, in which an algorithm only has access to a separation
oracle, we show a stronger trade-off: for at most $d^{2-\delta}$ memory, the
number of queries required is $\tilde\Omega(d^{1+\delta})$. This resolves a
COLT 2019 open problem of Woodworth and Srebro.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T01:30:00Z">Monday, February 13 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05030'>Dynamic $(1+\epsilon)$-Approximate Matching Size in Truly Sublinear Update Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sayan Bhattacharya, Peter Kiss, Thatchaphol Saranurak</p><p>We show a fully dynamic algorithm for maintaining $(1+\epsilon)$-approximate
\emph{size} of maximum matching of the graph with $n$ vertices and $m$ edges
using $m^{0.5-\Omega_{\epsilon}(1)}$ update time. This is the first polynomial
improvement over the long-standing $O(n)$ update time, which can be trivially
obtained by periodic recomputation. Thus, we resolve the value version of a
major open question of the dynamic graph algorithms literature (see, e.g.,
[Gupta and Peng FOCS'13], [Bernstein and Stein SODA'16],[Behnezhad and Khanna
SODA'22]).
</p>
<p>Our key technical component is the first sublinear algorithm for $(1,\epsilon
n)$-approximate maximum matching with sublinear running time on dense graphs.
All previous algorithms suffered a multiplicative approximation factor of at
least $1.499$ or assumed that the graph has a very small maximum degree.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1">Sayan Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiss_P/0/1/0/all/0/1">Peter Kiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Saranurak_T/0/1/0/all/0/1">Thatchaphol Saranurak</a></p><p>We show a fully dynamic algorithm for maintaining $(1+\epsilon)$-approximate
\emph{size} of maximum matching of the graph with $n$ vertices and $m$ edges
using $m^{0.5-\Omega_{\epsilon}(1)}$ update time. This is the first polynomial
improvement over the long-standing $O(n)$ update time, which can be trivially
obtained by periodic recomputation. Thus, we resolve the value version of a
major open question of the dynamic graph algorithms literature (see, e.g.,
[Gupta and Peng FOCS'13], [Bernstein and Stein SODA'16],[Behnezhad and Khanna
SODA'22]).
</p>
<p>Our key technical component is the first sublinear algorithm for $(1,\epsilon
n)$-approximate maximum matching with sublinear running time on dense graphs.
All previous algorithms suffered a multiplicative approximation factor of at
least $1.499$ or assumed that the graph has a very small maximum degree.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T01:30:00Z">Monday, February 13 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05245'>Count-min sketch with variable number of hash functions: an experimental study</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: &#xc9;ric Fusy, Gregory Kucherov</p><p>Conservative Count-Min, an improved version of Count-Min sketch [Cormode,
Muthukrishnan 2005], is an online-maintained hashing-based data structure
summarizing element frequency information without storing elements themselves.
Although several works attempted to analyze the error that can be made by
Count-Min, the behavior of this data structure remains poorly understood. In
[Fusy, Kucherov 2022], we demonstrated that under the uniform distribution of
input elements, the error of conservative Count-Min follows two distinct
regimes depending on its load factor.
</p>
<p>In this work, we provide a series of experimental results providing new
insights into the behavior of conservative Count-Min. Our contributions can be
seen as twofold. On one hand, we provide a detailed experimental analysis of
the behavior of Count-Min sketch in different regimes and under several
representative probability distributions of input elements. On the other hand,
we demonstrate improvements that can be made by assigning a variable number of
hash functions to different elements. This includes, in particular, reduced
space of the data structure while still supporting a small error.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fusy_E/0/1/0/all/0/1">&#xc9;ric Fusy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kucherov_G/0/1/0/all/0/1">Gregory Kucherov</a></p><p>Conservative Count-Min, an improved version of Count-Min sketch [Cormode,
Muthukrishnan 2005], is an online-maintained hashing-based data structure
summarizing element frequency information without storing elements themselves.
Although several works attempted to analyze the error that can be made by
Count-Min, the behavior of this data structure remains poorly understood. In
[Fusy, Kucherov 2022], we demonstrated that under the uniform distribution of
input elements, the error of conservative Count-Min follows two distinct
regimes depending on its load factor.
</p>
<p>In this work, we provide a series of experimental results providing new
insights into the behavior of conservative Count-Min. Our contributions can be
seen as twofold. On one hand, we provide a detailed experimental analysis of
the behavior of Count-Min sketch in different regimes and under several
representative probability distributions of input elements. On the other hand,
we demonstrate improvements that can be made by assigning a variable number of
hash functions to different elements. This includes, in particular, reduced
space of the data structure while still supporting a small error.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T01:30:00Z">Monday, February 13 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.05366'>Online Algorithms with Randomly Infused Advice</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuval Emek, Yuval Gil, Maciej Pacut, Stefan Schmid</p><p>We introduce a novel method for the rigorous quantitative evaluation of
online algorithms that relaxes the "radical worst-case" perspective of classic
competitive analysis. In contrast to prior work, our method, referred to as
randomly infused advice (RIA), does not make any probabilistic assumptions
about the input sequence and does not rely on the development of designated
online algorithms. Rather, it can be applied to existing online randomized
algorithms, introducing a means to evaluate their performance in scenarios that
lie outside the radical worst-case regime. More concretely, an online algorithm
ALG with RIA benefits from pieces of advice generated by an omniscient but not
entirely reliable oracle. The crux of the new method is that the advice is
provided to ALG by writing it into the buffer B from which ALG normally reads
its random bits, hence allowing us to augment it through a very simple and
non-intrusive interface. The (un)reliability of the oracle is captured via a
parameter 0 {\le} {\alpha} {\le} 1 that determines the probability (per round)
that the advice is successfully infused by the oracle; if the advice is not
infused, which occurs with probability 1 - {\alpha}, then the buffer B contains
fresh random bits (as in the classic online setting).
</p>
<p>The applicability of the new RIA method is demonstrated by applying it to
three extensively studied online problems: paging, uniform metrical task
systems, and online set cover. For these problems, we establish new upper
bounds on the competitive ratio of classic online algorithms that improve as
the infusion parameter {\alpha} increases. These are complemented with (often
tight) lower bounds on the competitive ratio of online algorithms with RIA for
the three problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Emek_Y/0/1/0/all/0/1">Yuval Emek</a>, <a href="http://arxiv.org/find/cs/1/au:+Gil_Y/0/1/0/all/0/1">Yuval Gil</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacut_M/0/1/0/all/0/1">Maciej Pacut</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a></p><p>We introduce a novel method for the rigorous quantitative evaluation of
online algorithms that relaxes the "radical worst-case" perspective of classic
competitive analysis. In contrast to prior work, our method, referred to as
randomly infused advice (RIA), does not make any probabilistic assumptions
about the input sequence and does not rely on the development of designated
online algorithms. Rather, it can be applied to existing online randomized
algorithms, introducing a means to evaluate their performance in scenarios that
lie outside the radical worst-case regime. More concretely, an online algorithm
ALG with RIA benefits from pieces of advice generated by an omniscient but not
entirely reliable oracle. The crux of the new method is that the advice is
provided to ALG by writing it into the buffer B from which ALG normally reads
its random bits, hence allowing us to augment it through a very simple and
non-intrusive interface. The (un)reliability of the oracle is captured via a
parameter 0 {\le} {\alpha} {\le} 1 that determines the probability (per round)
that the advice is successfully infused by the oracle; if the advice is not
infused, which occurs with probability 1 - {\alpha}, then the buffer B contains
fresh random bits (as in the classic online setting).
</p>
<p>The applicability of the new RIA method is demonstrated by applying it to
three extensively studied online problems: paging, uniform metrical task
systems, and online set cover. For these problems, we establish new upper
bounds on the competitive ratio of classic online algorithms that improve as
the infusion parameter {\alpha} increases. These are complemented with (often
tight) lower bounds on the competitive ratio of online algorithms with RIA for
the three problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-13T01:30:00Z">Monday, February 13 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, February 12
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/when-is-paper-easily-available.html'>When is a paper `Easily Available' ?</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>I was looking at the paper&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PSPACE-Completeness of reversible deterministic systems</p><p>by Erik Demaine, Robert Hearn,&nbsp; Dylan Hendrickson, and Jayson Lynch (see&nbsp;here) and came across the following fascinating result which I paraphrase:</p><p>The problem of, given balls on a pool table (though it can be one you devise which is not the standard one) and each balls initial position and velocity, and a particular ball and place, it is PSPACE complete to determine if that ball ever gets to that place.&nbsp;</p><p>Demaine et al. stated that this was proven by&nbsp;Edward Fredkin and Tommaso Toffoli in 1982 (see&nbsp;here&nbsp;for a link to the 1982 paper, not behind a paywall). Demaine et al. gave an easier proof with some nice properties. (Just in case the link goes away I downloaded the paper to my files and you can find it&nbsp;here.)&nbsp;</p><p>I needed the bib reference for the FT-1982 paper and rather than copy it from Demaine et al. I wanted to cut-and-paste, so I looked for it in DBLP. I didn't find the 1982 paper but I did find a book from 2002 that reprinted it. The book, Collision-based computing, has a website&nbsp;here. The book itself is behind a paywall.</p><p>On the website is the following curious statement:</p><p>[This book] Gives a state-of-the-art overview of an emerging topic, on which there is little published literature at the moment. [The book] Includes 2 classic paper, both of which are widely referred to but are NOT EASILY AVAILABLE (E. Fredkin and T. Toffoli: Conservative Logic, and N . Margolous Physics-Like Models of Computation).&nbsp;</p><p>The caps are mine.</p><p>Not easily available? I found a link in less than a minute, and I used it above when I pointed to the paper.&nbsp;</p><p>But the book IS behind a paywall.&nbsp;</p><p>Perhaps Springer does not know that the article is easily available. That would be odd since the place I found the article is also a Springer website.&nbsp;</p><p>The notion of EASILY AVAILABLE is very odd. While not quite related, it reminds me of when MIT Press had to pay a few thousand dollars for permission (that might not be the legal term) to reprint Turing's 1936 paper where he defined Turing Machines (he didn't call them that), which is&nbsp;on line here&nbsp;(and other places), for Harry Lewis's book Ideas that created the future.&nbsp;</p><p><br></p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I was looking at the paper&nbsp;</p><p><i>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PSPACE-Completeness of reversible deterministic systems</i></p><p>by Erik Demaine, Robert Hearn,&nbsp; Dylan Hendrickson, and Jayson Lynch (see&nbsp;<a href="https://arxiv.org/abs/2207.07229">here</a>) and came across the following fascinating result which I paraphrase:</p><p><i>The problem of, given balls on a pool table (though it can be one you devise which is not the standard one) and each balls initial position and velocity, and a particular ball and place, it is PSPACE complete to determine if that ball ever gets to that place.&nbsp;</i></p><p>Demaine et al. stated that this was proven by&nbsp;Edward Fredkin and Tommaso Toffoli in 1982 (see&nbsp;<a href="https://link.springer.com/article/10.1007/BF01857727">here</a>&nbsp;for a link to the 1982 paper, not behind a paywall). Demaine et al. gave an easier proof with some nice properties. (Just in case the link goes away I downloaded the paper to my files and you can find it&nbsp;<a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/clogic.pdf">here</a>.)&nbsp;</p><p>I needed the bib reference for the FT-1982 paper and rather than copy it from Demaine et al. I wanted to cut-and-paste, so I looked for it in DBLP. I didn't find the 1982 paper but I did find a book from 2002 that reprinted it. The book, <i>Collision-based computing,</i> has a website&nbsp;<a href="https://link.springer.com/book/10.1007/978-1-4471-0129-1">here</a>. The book itself is behind a paywall.</p><p>On the website is the following curious statement:</p><p><i>[This book] Gives a state-of-the-art overview of an emerging topic, on which there is little published literature at the moment. [The book] Includes 2 classic paper, both of which are widely referred to but are NOT EASILY AVAILABLE (E. Fredkin and T. Toffoli: Conservative Logic, and N . Margolous Physics-Like Models of Computation).&nbsp;</i></p><p>The caps are mine.</p><p>Not easily available? I found a link in less than a minute, and I used it above when I pointed to the paper.&nbsp;</p><p>But the book IS behind a paywall.&nbsp;</p><p>Perhaps Springer does not know that the article is easily available. That would be odd since the place I found the article is also a Springer website.&nbsp;</p><p>The notion of EASILY AVAILABLE is very odd. While not quite related, it reminds me of when MIT Press had to pay a few thousand dollars for permission (that might not be the legal term) to reprint Turing's 1936 paper where he defined Turing Machines (he didn't call them that), which is&nbsp;<a href="https://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf">on line here</a>&nbsp;(and other places), for Harry Lewis's book <i>Ideas that created the</i> <i>future.&nbsp;</i></p><p><br /></p><p><i><br /></i></p><p><i><br /></i></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-12T21:22:00Z">Sunday, February 12 2023, 21:22</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, February 11
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/'>Are We Nuts?</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Gil Kalai is one of the top researchers in the world in the area of combinatorics. His blog is one of the best in the universe. He also has some of the top results of anyone. One measure of excellence is how important not your results are, but how important your conjectures are. He with [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Gil Kalai is one of the top researchers in the world in the area of combinatorics. His <a href="https://gilkalai.wordpress.com">blog</a> is one of the best in the universe.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/gk-2/" rel="attachment wp-att-21072"><img data-attachment-id="21072" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/gk-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/gk.jpeg?fit=278%2C181&amp;ssl=1" data-orig-size="278,181" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="gk" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/gk.jpeg?fit=278%2C181&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/gk.jpeg?fit=278%2C181&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/gk.jpeg?resize=278%2C181&#038;ssl=1" alt="" width="278" height="181" class="aligncenter size-full wp-image-21072" data-recalc-dims="1" /></a></p>
<p>He also has some of the top results of anyone. One measure of excellence is how important not your results are, but how important your conjectures are. He with Jeff Kahn created in 2006 the expectation threshold <a href="https://arxiv.org/abs/math/0603218">conjecture</a> which was just solved by Jinyoung Park and Huy Tuan Pham&#8212; <a href="https://arxiv.org/abs/2203.17207">here</a>.<br />
<span id="more-21068"></span></p>
<p>The fact that open problems are perhaps more important than results will be reflected in the next FOCS 2023. There will be a whole <a href="https://windowsontheory.org/2023/01/16/new-in-focs-2023-a-conjectures-track/">track</a> on open problems. See Amit Sahai, Shubhangi Saraf, and Thomas Vidick who have put together an FAQ about this: This year, FOCS 2023 will include something new: a Conjectures Track, separate from the Main Track. Submissions to the Main Track will be evaluated along similar lines as STOC/FOCS papers typically are, aiming to accept papers that obtain the very best results across all fields of theoretical computer science. Submissions to the new Conjectures Track will be evaluated completely separately from submissions to the Main Track. There is no a priori acceptance quota for either track, or desired number of accepted papers: it will all depend on the quality of submissions only.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/am-2/" rel="attachment wp-att-21082"><img data-attachment-id="21082" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/am-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/am.jpeg?fit=171%2C295&amp;ssl=1" data-orig-size="171,295" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="am" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/am.jpeg?fit=171%2C295&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/am.jpeg?fit=171%2C295&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/am.jpeg?resize=171%2C295&#038;ssl=1" alt="" width="171" height="295" class="aligncenter size-full wp-image-21082" data-recalc-dims="1" /></a></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/ss-2/" rel="attachment wp-att-21077"><img data-attachment-id="21077" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/ss-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?fit=225%2C225&amp;ssl=1" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ss" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?fit=225%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?fit=225%2C225&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?resize=225%2C225&#038;ssl=1" alt="" width="225" height="225" class="aligncenter size-full wp-image-21077" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?w=225&amp;ssl=1 225w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/ss.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1" /></a></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/tv-2/" rel="attachment wp-att-21079"><img data-attachment-id="21079" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/tv-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/tv.jpeg?fit=198%2C255&amp;ssl=1" data-orig-size="198,255" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tv" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/tv.jpeg?fit=198%2C255&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/tv.jpeg?fit=198%2C255&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/tv.jpeg?resize=198%2C255&#038;ssl=1" alt="" width="198" height="255" class="aligncenter size-full wp-image-21079" data-recalc-dims="1" /></a></p>
<p><strong>Against Quantum Computers</strong></p>
<p>Gil Kalai has argued against quantum computation being a faster type of computation. See his paper <a href="https://gilkalai.wordpress.com">here</a> for one example. Or see <a href="https://gilkalai.wordpress.com/2020/12/29/the-argument-against-quantum-computers-a-very-short-introduction/">anti 1</a> and <a href="https://arxiv.org/abs/1908.02499">anti 2</a>.</p>
<p><strong>The New Yorker Magazine</strong></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/cover-3/" rel="attachment wp-att-21074"><img data-attachment-id="21074" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/cover-3/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpeg?fit=258%2C352&amp;ssl=1" data-orig-size="258,352" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cover" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpeg?fit=220%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpeg?fit=258%2C352&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpeg?resize=258%2C352&#038;ssl=1" alt="" width="258" height="352" class="aligncenter size-full wp-image-21074" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpeg?w=258&amp;ssl=1 258w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cover.jpeg?resize=220%2C300&amp;ssl=1 220w" sizes="(max-width: 258px) 100vw, 258px" data-recalc-dims="1" /></a></p>
<p>Last month the New Yorker had two articles about math. That&#8217;s two more than usual.</p>
<p>The main article was on quantum algorithms by Stephen Witt. He is a reporter and has a degree in 2001 from the University of Chicago in mathematics.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/sw/" rel="attachment wp-att-21073"><img data-attachment-id="21073" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/sw/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?fit=225%2C225&amp;ssl=1" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sw" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?fit=225%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?fit=225%2C225&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?resize=225%2C225&#038;ssl=1" alt="" width="225" height="225" class="aligncenter size-full wp-image-21073" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?w=225&amp;ssl=1 225w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/sw.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1" /></a></p>
<p>His article features Peter Shor a leader in quantum algorithms&#8212;no relationship to Santa&#8212;but long time friend.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/peter-2/" rel="attachment wp-att-21076"><img data-attachment-id="21076" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/peter-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?fit=224%2C224&amp;ssl=1" data-orig-size="224,224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="peter" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?fit=224%2C224&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?fit=224%2C224&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?resize=224%2C224&#038;ssl=1" alt="" width="224" height="224" class="aligncenter size-full wp-image-21076" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?w=224&amp;ssl=1 224w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/peter.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 224px) 100vw, 224px" data-recalc-dims="1" /></a></p>
<p>Witt&#8217;s article features other friends of ours such as Scott Aaronson&#8212;the owner of the wonderful <a href="https://scottaaronson.blog">blog</a>&#8212;Shtetl-Optimized. Scott&#8217;s post starts: I, Scott confess: this was the first time I felt visceral anger, rather than mere bemusement, over this wormhole affair. Before, I had implicitly assumed: no one was actually hoodwinked by this. No one really, literally believed that this little 9-qubit simulation opened up a wormhole, or helped prove the holographic nature of the real universe, or anything like that. I was wrong.</p>
<p><strong>Quantum Is Weird</strong></p>
<p>Read the New Yorker article, which is a nice popular writeup by Witt. Quantum is tricky, but his article is pretty straightforward.</p>
<p>Witt&#8217;s main focus is on the potential to build quantum computers that can solve real problems. The goal is of course to make quantum computers that can handle more and more qubits. Witt says this will make: Quantum physics win the Nobel prizes; Quantum chemistry will write the checks. Tens of billions of dollars are being invested in searching for ways to make such quantum computers. The <a href="https://thequantuminsider.com">investments</a> are by existing huge companies as well as new startups.</p>
<p><strong>Quantum Is Powerful?</strong></p>
<p>Witt assumes the usual view that classic computers are weaker than quantum computers. This is likely to be the case; it is the main viewpoint, but it is open. It could be that quantum computers could indeed be efficiently simulated by classic computers. That is still an open problem. See list of blogs on quantum for the main view.</p>
<p>We cannot prove that PSPACE is more powerful than P=POLYTIME. This is believed by most, but it is open. It could be the case that they are equal. If that is true, then Shor&#8217;s factoring algorithm is in P and other shocks happen. But it could be true.</p>
<p>Take a look at the recent <em>A Closer Look at Some Recent Proof Compression-Related Claims</em> <a href="https://arxiv.org/pdf/2212.12150.pdf}{https://arxiv.org/pdf/2212.12150.pdf">paper</a> by Michael Chavrimootoo, Ethan Ferland, Erin Gibson, Ashley Wilson. They show that a claimed proof that resolves a related open problem fails. But it could be possible via some other argument. It is interesting that people believe they have an approach to such results&#8212;even if their arguments are wrong.</p>
<p><strong>Open Problems</strong></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/just2/" rel="attachment wp-att-21075"><img data-attachment-id="21075" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/just2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?fit=225%2C225&amp;ssl=1" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="just2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?fit=225%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?fit=225%2C225&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?resize=225%2C225&#038;ssl=1" alt="" width="225" height="225" class="aligncenter size-full wp-image-21075" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?w=225&amp;ssl=1 225w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/just2.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1" /></a></p>
<p>Are we nuts to point out that quantum computers could be no more powerful than classic computers? Are the billions of dollars being spent on quantum computers foolish? What do you think? Should some resources be spent on advances in classic algorithms?</p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-11T13:25:38Z">Saturday, February 11 2023, 13:25</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, February 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04322'>Quantum free games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anand Natarajan, Tina Zhang</p><p>The complexity of free games with two or more classical players was
essentially settled by Aaronson, Impagliazzo, and Moshkovitz (CCC'14). There
are two complexity classes that can be considered quantum analogues of
classical free games: (1) AM*, the multiprover interactive proof class
corresponding to free games with entangled players, and, somewhat less
obviously, (2) BellQMA(2), the class of quantum Merlin-Arthur proof systems
with two unentangled Merlins, whose proof states are separately measured by
Arthur. In this work, we make significant progress towards a tight
characterization of both of these classes. 1. We show a BellQMA(2) protocol for
3SAT on $n$ variables, where the total amount of communication is
$\tilde{O}(\sqrt{n})$. This answers an open question of Chen and Drucker (2010)
and also shows, conditional on ETH, that the algorithm of Brand\~{a}o,
Christandl and Yard (STOC'11) is tight up to logarithmic factors. 2. We show
that $\mathsf{AM}^*[n_{\text{provers}} = 2, q = O(1), a =\mathrm{poly}\log(n)]
= \mathsf{RE}$, i.e. that free entangled games with constant-sized questions
are as powerful as general entangled games. Our result is a significant
improvement over the headline result of Ji et al. (2020), whose MIP* protocol
for the halting problem has $\mathrm{poly}(n)$-sized questions and answers. 3.
We obtain a zero-gap AM* protocol for a $\Pi_2$ complete language with
constant-size questions and almost logarithmically large answers, improving on
the headline result of Mousavi, Nezhadi and Yuen (STOC'22). 4. Using a
connection to the nonuniform complexity of the halting problem we show that any
MIP* protocol for RE requires $\Omega(\log n)$ bits of communication. It
follows that our results in item 3 are optimal up to an $O(\log^* n)$ factor,
and that the gapless compression theorems of MNY'22 are asymptotically optimal.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Natarajan_A/0/1/0/all/0/1">Anand Natarajan</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhang_T/0/1/0/all/0/1">Tina Zhang</a></p><p>The complexity of free games with two or more classical players was
essentially settled by Aaronson, Impagliazzo, and Moshkovitz (CCC'14). There
are two complexity classes that can be considered quantum analogues of
classical free games: (1) AM*, the multiprover interactive proof class
corresponding to free games with entangled players, and, somewhat less
obviously, (2) BellQMA(2), the class of quantum Merlin-Arthur proof systems
with two unentangled Merlins, whose proof states are separately measured by
Arthur. In this work, we make significant progress towards a tight
characterization of both of these classes. 1. We show a BellQMA(2) protocol for
3SAT on $n$ variables, where the total amount of communication is
$\tilde{O}(\sqrt{n})$. This answers an open question of Chen and Drucker (2010)
and also shows, conditional on ETH, that the algorithm of Brand\~{a}o,
Christandl and Yard (STOC'11) is tight up to logarithmic factors. 2. We show
that $\mathsf{AM}^*[n_{\text{provers}} = 2, q = O(1), a =\mathrm{poly}\log(n)]
= \mathsf{RE}$, i.e. that free entangled games with constant-sized questions
are as powerful as general entangled games. Our result is a significant
improvement over the headline result of Ji et al. (2020), whose MIP* protocol
for the halting problem has $\mathrm{poly}(n)$-sized questions and answers. 3.
We obtain a zero-gap AM* protocol for a $\Pi_2$ complete language with
constant-size questions and almost logarithmically large answers, improving on
the headline result of Mousavi, Nezhadi and Yuen (STOC'22). 4. Using a
connection to the nonuniform complexity of the halting problem we show that any
MIP* protocol for RE requires $\Omega(\log n)$ bits of communication. It
follows that our results in item 3 are optimal up to an $O(\log^* n)$ factor,
and that the gapless compression theorems of MNY'22 are asymptotically optimal.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04482'>Secret Sharing on Superconcentrator</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuan Li</p><p>Using information inequalities, we prove any unrestricted arithmetic circuits
computing the shares of any $(t, n)$-threshold secret sharing scheme must
satisfy some superconcentrator-like connection properties. In the reverse
direction, we prove, when the underlying field is large enough, any graph
satisfying these connection properties can be turned into a linear arithmetic
circuit computing the shares of a $(t, n)$-threshold secret sharing scheme.
Specifically, $n$ shares can be computed by a linear arithmetic circuits with
$O(n)$ wires in depth $O(\alpha(t, n))$, where $\alpha(t, n)$ is the
two-parameter version of the inverse Ackermann function. For example, when $n
\ge t^{2.5}$, depth $2$ would be enough; when $n \ge t \log^{2.5} t$, depth 3
would be enough.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuan Li</a></p><p>Using information inequalities, we prove any unrestricted arithmetic circuits
computing the shares of any $(t, n)$-threshold secret sharing scheme must
satisfy some superconcentrator-like connection properties. In the reverse
direction, we prove, when the underlying field is large enough, any graph
satisfying these connection properties can be turned into a linear arithmetic
circuit computing the shares of a $(t, n)$-threshold secret sharing scheme.
Specifically, $n$ shares can be computed by a linear arithmetic circuits with
$O(n)$ wires in depth $O(\alpha(t, n))$, where $\alpha(t, n)$ is the
two-parameter version of the inverse Ackermann function. For example, when $n
\ge t^{2.5}$, depth $2$ would be enough; when $n \ge t \log^{2.5} t$, depth 3
would be enough.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04522'>Hardness of monadic second-order formulae over succinct graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guilhem Gamard (LORIA), Pierre Guillon (I2M), K&#xe9;vin Perrot (LIS), Guillaume Theyssier (I2M)</p><p>Our main result is a succinct counterpoint to Courcelle's meta-theorem as
follows: every arborescent monadic second-order (MSO) property is either
NP-hard or coNP-hard over graphs given by succinct representations. Succint
representations are Boolean circuits computing the adjacency relation.
Arborescent properties are those which have infinitely many models and
countermodels with bounded treewidth. We actually prove this result in the
terminology of automata network, which is a generalization of finite cellular
automata over arbitrary graphs. This model arose from the biological
modelization of neural networks and gene regulation networks. Our result states
that every arborescent MSO property on the transition graph of automata
networks is either NP-hard or coNP-hard. Moreover, we explore what happens when
the arborescence condition is dropped and show that, under a reasonable
complexity assumption, the previous dichotomy fails, even for questions
expressible in first-order logic.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gamard_G/0/1/0/all/0/1">Guilhem Gamard</a> (LORIA), <a href="http://arxiv.org/find/cs/1/au:+Guillon_P/0/1/0/all/0/1">Pierre Guillon</a> (I2M), <a href="http://arxiv.org/find/cs/1/au:+Perrot_K/0/1/0/all/0/1">K&#xe9;vin Perrot</a> (LIS), <a href="http://arxiv.org/find/cs/1/au:+Theyssier_G/0/1/0/all/0/1">Guillaume Theyssier</a> (I2M)</p><p>Our main result is a succinct counterpoint to Courcelle's meta-theorem as
follows: every arborescent monadic second-order (MSO) property is either
NP-hard or coNP-hard over graphs given by succinct representations. Succint
representations are Boolean circuits computing the adjacency relation.
Arborescent properties are those which have infinitely many models and
countermodels with bounded treewidth. We actually prove this result in the
terminology of automata network, which is a generalization of finite cellular
automata over arbitrary graphs. This model arose from the biological
modelization of neural networks and gene regulation networks. Our result states
that every arborescent MSO property on the transition graph of automata
networks is either NP-hard or coNP-hard. Moreover, we explore what happens when
the arborescence condition is dropped and show that, under a reasonable
complexity assumption, the previous dichotomy fails, even for questions
expressible in first-order logic.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04731'>Find a witness or shatter: the landscape of computable PAC learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Valentino Delle Rose, Alexander Kozachinskiy, Cristobal Rojas, Tomasz Steifer</p><p>This paper contributes to the study of CPAC learnability -- a computable
version of PAC learning -- by solving three open questions from recent papers.
Firstly, we prove that every improperly CPAC learnable class is contained in a
class which is properly CPAC learnable with polynomial sample complexity. This
confirms a conjecture by Agarwal et al (COLT 2021). Secondly, we show that
there exists a decidable class of hypothesis which is properly CPAC learnable,
but only with uncomputably fast growing sample complexity. This solves a
question from Sterkenburg (COLT 2022). Finally, we construct a decidable class
of finite Littlestone dimension which is not improperly CPAC learnable,
strengthening a recent result of Sterkenburg (2022) and answering a question
posed by Hasrati and Ben-David (ALT 2023). Together with previous work, our
results provide a complete landscape for the learnability problem in the CPAC
setting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rose_V/0/1/0/all/0/1">Valentino Delle Rose</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozachinskiy_A/0/1/0/all/0/1">Alexander Kozachinskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Rojas_C/0/1/0/all/0/1">Cristobal Rojas</a>, <a href="http://arxiv.org/find/cs/1/au:+Steifer_T/0/1/0/all/0/1">Tomasz Steifer</a></p><p>This paper contributes to the study of CPAC learnability -- a computable
version of PAC learning -- by solving three open questions from recent papers.
Firstly, we prove that every improperly CPAC learnable class is contained in a
class which is properly CPAC learnable with polynomial sample complexity. This
confirms a conjecture by Agarwal et al (COLT 2021). Secondly, we show that
there exists a decidable class of hypothesis which is properly CPAC learnable,
but only with uncomputably fast growing sample complexity. This solves a
question from Sterkenburg (COLT 2022). Finally, we construct a decidable class
of finite Littlestone dimension which is not improperly CPAC learnable,
strengthening a recent result of Sterkenburg (2022) and answering a question
posed by Hasrati and Ben-David (ALT 2023). Together with previous work, our
results provide a complete landscape for the learnability problem in the CPAC
setting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04749'>Quantum Advantage from One-Way Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tomoyuki Morimae, Takashi Yamakawa</p><p>We demonstrate quantum advantage with several basic assumptions, specifically
based on only the existence of OWFs. We introduce inefficient-verifier proofs
of quantumness (IV-PoQ), and construct it from classical bit commitments.
IV-PoQ is an interactive protocol between a verifier and a quantum prover
consisting of two phases. In the first phase, the verifier is probabilistic
polynomial-time, and it interacts with the prover. In the second phase, the
verifier becomes inefficient, and makes its decision based on the transcript of
the first phase. If the prover is honest, the inefficient verifier accepts with
high probability, but any classical malicious prover only has a small
probability of being accepted by the inefficient verifier. Our construction
demonstrates the following results: (1)If one-way functions exist, then IV-PoQ
exist. (2)If distributional collision-resistant hash functions exist (which
exist if hard-on-average problems in $\mathbf{SZK}$ exist), then constant-round
IV-PoQ exist. We also demonstrate quantum advantage based on worst-case-hard
assumptions. We define auxiliary-input IV-PoQ (AI-IV-PoQ) that only require
that for any malicious prover, there exist infinitely many auxiliary inputs
under which the prover cannot cheat. We construct AI-IV-PoQ from an
auxiliary-input version of commitments in a similar way, showing that (1)If
auxiliary-input one-way functions exist (which exist if
$\mathbf{CZK}\not\subseteq\mathbf{BPP}$), then AI-IV-PoQ exist. (2)If
auxiliary-input collision-resistant hash functions exist (which is equivalent
to $\mathbf{PWPP}\nsubseteq \mathbf{FBPP}$) or $\mathbf{SZK}\nsubseteq
\mathbf{BPP}$, then constant-round AI-IV-PoQ exist.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Morimae_T/0/1/0/all/0/1">Tomoyuki Morimae</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yamakawa_T/0/1/0/all/0/1">Takashi Yamakawa</a></p><p>We demonstrate quantum advantage with several basic assumptions, specifically
based on only the existence of OWFs. We introduce inefficient-verifier proofs
of quantumness (IV-PoQ), and construct it from classical bit commitments.
IV-PoQ is an interactive protocol between a verifier and a quantum prover
consisting of two phases. In the first phase, the verifier is probabilistic
polynomial-time, and it interacts with the prover. In the second phase, the
verifier becomes inefficient, and makes its decision based on the transcript of
the first phase. If the prover is honest, the inefficient verifier accepts with
high probability, but any classical malicious prover only has a small
probability of being accepted by the inefficient verifier. Our construction
demonstrates the following results: (1)If one-way functions exist, then IV-PoQ
exist. (2)If distributional collision-resistant hash functions exist (which
exist if hard-on-average problems in $\mathbf{SZK}$ exist), then constant-round
IV-PoQ exist. We also demonstrate quantum advantage based on worst-case-hard
assumptions. We define auxiliary-input IV-PoQ (AI-IV-PoQ) that only require
that for any malicious prover, there exist infinitely many auxiliary inputs
under which the prover cannot cheat. We construct AI-IV-PoQ from an
auxiliary-input version of commitments in a similar way, showing that (1)If
auxiliary-input one-way functions exist (which exist if
$\mathbf{CZK}\not\subseteq\mathbf{BPP}$), then AI-IV-PoQ exist. (2)If
auxiliary-input collision-resistant hash functions exist (which is equivalent
to $\mathbf{PWPP}\nsubseteq \mathbf{FBPP}$) or $\mathbf{SZK}\nsubseteq
\mathbf{BPP}$, then constant-round AI-IV-PoQ exist.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04462'>Nonlinear Random Matrices and Applications to the Sum of Squares Hierarchy</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Goutham Rajendran</p><p>We develop new tools in the theory of nonlinear random matrices and apply
them to study the performance of the Sum of Squares (SoS) hierarchy on
average-case problems.
</p>
<p>The SoS hierarchy is a powerful optimization technique that has achieved
tremendous success for various problems in combinatorial optimization, robust
statistics and machine learning. It's a family of convex relaxations that lets
us smoothly trade off running time for approximation guarantees. In recent
works, it's been shown to be extremely useful for recovering structure in high
dimensional noisy data. It also remains our best approach towards refuting the
notorious Unique Games Conjecture.
</p>
<p>In this work, we analyze the performance of the SoS hierarchy on fundamental
problems stemming from statistics, theoretical computer science and statistical
physics. In particular, we show subexponential-time SoS lower bounds for the
problems of the Sherrington-Kirkpatrick Hamiltonian, Planted Slightly Denser
Subgraph, Tensor Principal Components Analysis and Sparse Principal Components
Analysis. These SoS lower bounds involve analyzing large random matrices,
wherein lie our main contributions. These results offer strong evidence for the
truth of and insight into the low-degree likelihood ratio hypothesis, an
important conjecture that predicts the power of bounded-time algorithms for
hypothesis testing.
</p>
<p>We also develop general-purpose tools for analyzing the behavior of random
matrices which are functions of independent random variables. Towards this, we
build on and generalize the matrix variant of the Efron-Stein inequalities. In
particular, our general theorem on matrix concentration recovers various
results that have appeared in the literature. We expect these random matrix
theory ideas to have other significant applications.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rajendran_G/0/1/0/all/0/1">Goutham Rajendran</a></p><p>We develop new tools in the theory of nonlinear random matrices and apply
them to study the performance of the Sum of Squares (SoS) hierarchy on
average-case problems.
</p>
<p>The SoS hierarchy is a powerful optimization technique that has achieved
tremendous success for various problems in combinatorial optimization, robust
statistics and machine learning. It's a family of convex relaxations that lets
us smoothly trade off running time for approximation guarantees. In recent
works, it's been shown to be extremely useful for recovering structure in high
dimensional noisy data. It also remains our best approach towards refuting the
notorious Unique Games Conjecture.
</p>
<p>In this work, we analyze the performance of the SoS hierarchy on fundamental
problems stemming from statistics, theoretical computer science and statistical
physics. In particular, we show subexponential-time SoS lower bounds for the
problems of the Sherrington-Kirkpatrick Hamiltonian, Planted Slightly Denser
Subgraph, Tensor Principal Components Analysis and Sparse Principal Components
Analysis. These SoS lower bounds involve analyzing large random matrices,
wherein lie our main contributions. These results offer strong evidence for the
truth of and insight into the low-degree likelihood ratio hypothesis, an
important conjecture that predicts the power of bounded-time algorithms for
hypothesis testing.
</p>
<p>We also develop general-purpose tools for analyzing the behavior of random
matrices which are functions of independent random variables. Towards this, we
build on and generalize the matrix variant of the Efron-Stein inequalities. In
particular, our general theorem on matrix concentration recovers various
results that have appeared in the literature. We expect these random matrix
theory ideas to have other significant applications.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04378'>Fast Parallel Degree+1 List Coloring</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sam Coy, Artur Czumaj, Peter Davies, Gopinath Mishra</p><p>Graph coloring problems are arguably among the most fundamental graph
problems in parallel and distributed computing with numerous applications. In
particular, in recent years the classical ($\Delta+1$)-coloring problem became
a benchmark problem to study the impact of local computation for parallel and
distributed algorithms. In this work, we study the parallel complexity of a
generalization of the ($\Delta+1$)-coloring problem: the problem of
(degree+1)-list coloring (${\mathsf{D1LC}}$), where each node has an input
palette of acceptable colors, of size one more than its degree, and the
objective is to find a proper coloring using these palettes.
</p>
<p>In a recent work, Halld\'orsson et al. (STOC'22) presented a randomized
$O(\log^3\log n)$-rounds distributed algorithm for ${\mathsf{D1LC}}$ in the
${\mathsf{LOCAL}}$ model, matching for the first time the state-of-the art
complexity for $(\Delta+1)$-coloring due to Chang et al. (SICOMP'20).
</p>
<p>In this paper, we obtain a similar connection for $\mathsf{D1LC}$ in the
Massively Parallel Computation (${\mathsf{MPC}}$) model with sublinear local
space: we present a randomized $O(\log\log\log n)$-round ${\mathsf{MPC}}$
algorithm for ${\mathsf{D1LC}}$, matching the state-of-the art ${\mathsf{MPC}}$
algorithm for the $(\Delta+1)$-coloring problem. We also show that our
algorithm can be efficiently derandomized.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Coy_S/0/1/0/all/0/1">Sam Coy</a>, <a href="http://arxiv.org/find/cs/1/au:+Czumaj_A/0/1/0/all/0/1">Artur Czumaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Davies_P/0/1/0/all/0/1">Peter Davies</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_G/0/1/0/all/0/1">Gopinath Mishra</a></p><p>Graph coloring problems are arguably among the most fundamental graph
problems in parallel and distributed computing with numerous applications. In
particular, in recent years the classical ($\Delta+1$)-coloring problem became
a benchmark problem to study the impact of local computation for parallel and
distributed algorithms. In this work, we study the parallel complexity of a
generalization of the ($\Delta+1$)-coloring problem: the problem of
(degree+1)-list coloring (${\mathsf{D1LC}}$), where each node has an input
palette of acceptable colors, of size one more than its degree, and the
objective is to find a proper coloring using these palettes.
</p>
<p>In a recent work, Halld\'orsson et al. (STOC'22) presented a randomized
$O(\log^3\log n)$-rounds distributed algorithm for ${\mathsf{D1LC}}$ in the
${\mathsf{LOCAL}}$ model, matching for the first time the state-of-the art
complexity for $(\Delta+1)$-coloring due to Chang et al. (SICOMP'20).
</p>
<p>In this paper, we obtain a similar connection for $\mathsf{D1LC}$ in the
Massively Parallel Computation (${\mathsf{MPC}}$) model with sublinear local
space: we present a randomized $O(\log\log\log n)$-round ${\mathsf{MPC}}$
algorithm for ${\mathsf{D1LC}}$, matching the state-of-the art ${\mathsf{MPC}}$
algorithm for the $(\Delta+1)$-coloring problem. We also show that our
algorithm can be efficiently derandomized.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04384'>SF-SGL: Solver-Free Spectral Graph Learning from Linear Measurements</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ying Zhang, Zhiqiang Zhao, Zhuo Feng</p><p>This work introduces a highly-scalable spectral graph densification framework
(SGL) for learning resistor networks with linear measurements, such as node
voltages and currents. We show that the proposed graph learning approach is
equivalent to solving the classical graphical Lasso problems with
Laplacian-like precision matrices. We prove that given $O(\log N)$ pairs of
voltage and current measurements, it is possible to recover sparse $N$-node
resistor networks that can well preserve the effective resistance distances on
the original graph. In addition, the learned graphs also preserve the
structural (spectral) properties of the original graph, which can potentially
be leveraged in many circuit design and optimization tasks.
</p>
<p>To achieve more scalable performance, we also introduce a solver-free method
(SF-SGL) that exploits multilevel spectral approximation of the graphs and
allows for a scalable and flexible decomposition of the entire graph spectrum
(to be learned) into multiple different eigenvalue clusters (frequency bands).
Such a solver-free approach allows us to more efficiently identify the most
spectrally-critical edges for reducing various ranges of spectral embedding
distortions. Through extensive experiments for a variety of real-world test
cases, we show that the proposed approach is highly scalable for learning
sparse resistor networks without sacrificing solution quality. We also
introduce a data-driven EDA algorithm for vectorless power/thermal integrity
verifications to allow estimating worst-case voltage/temperature (gradient)
distributions across the entire chip by leveraging a few voltage/temperature
measurements.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Ying Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhiqiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhuo Feng</a></p><p>This work introduces a highly-scalable spectral graph densification framework
(SGL) for learning resistor networks with linear measurements, such as node
voltages and currents. We show that the proposed graph learning approach is
equivalent to solving the classical graphical Lasso problems with
Laplacian-like precision matrices. We prove that given $O(\log N)$ pairs of
voltage and current measurements, it is possible to recover sparse $N$-node
resistor networks that can well preserve the effective resistance distances on
the original graph. In addition, the learned graphs also preserve the
structural (spectral) properties of the original graph, which can potentially
be leveraged in many circuit design and optimization tasks.
</p>
<p>To achieve more scalable performance, we also introduce a solver-free method
(SF-SGL) that exploits multilevel spectral approximation of the graphs and
allows for a scalable and flexible decomposition of the entire graph spectrum
(to be learned) into multiple different eigenvalue clusters (frequency bands).
Such a solver-free approach allows us to more efficiently identify the most
spectrally-critical edges for reducing various ranges of spectral embedding
distortions. Through extensive experiments for a variety of real-world test
cases, we show that the proposed approach is highly scalable for learning
sparse resistor networks without sacrificing solution quality. We also
introduce a data-driven EDA algorithm for vectorless power/thermal integrity
verifications to allow estimating worst-case voltage/temperature (gradient)
distributions across the entire chip by leveraging a few voltage/temperature
measurements.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04475'>Locally consistent decomposition of strings with applications to edit distance sketching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sudatta Bhattacharya, Michal Kouck&#xfd;</p><p>In this paper we provide a new locally consistent decomposition of strings.
Each string $x$ is decomposed into blocks that can be described by grammars of
size $\widetilde{O}(k)$ (using some amount of randomness). If we take two
strings $x$ and $y$ of edit distance at most $k$ then their block decomposition
uses the same number of grammars and the $i$-th grammar of $x$ is the same as
the $i$-th grammar of $y$ except for at most $k$ indexes $i$. The edit distance
of $x$ and $y$ equals to the sum of edit distances of pairs of blocks where $x$
and $y$ differ. Our decomposition can be used to design a sketch of size
$\widetilde{O}(k^2)$ for edit distance, and also a rolling sketch for edit
distance of size $\widetilde{O}(k^2)$. The rolling sketch allows to update the
sketched string by appending a symbol or removing a symbol from the beginning
of the string.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1">Sudatta Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Koucky_M/0/1/0/all/0/1">Michal Kouck&#xfd;</a></p><p>In this paper we provide a new locally consistent decomposition of strings.
Each string $x$ is decomposed into blocks that can be described by grammars of
size $\widetilde{O}(k)$ (using some amount of randomness). If we take two
strings $x$ and $y$ of edit distance at most $k$ then their block decomposition
uses the same number of grammars and the $i$-th grammar of $x$ is the same as
the $i$-th grammar of $y$ except for at most $k$ indexes $i$. The edit distance
of $x$ and $y$ equals to the sum of edit distances of pairs of blocks where $x$
and $y$ differ. Our decomposition can be used to design a sketch of size
$\widetilde{O}(k^2)$ for edit distance, and also a rolling sketch for edit
distance of size $\widetilde{O}(k^2)$. The rolling sketch allows to update the
sketched string by appending a symbol or removing a symbol from the beginning
of the string.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04496'>Dual Algorithmic Reasoning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Danilo Numeroso, Davide Bacciu, Petar Veli&#x10d;kovi&#x107;</p><p>Neural Algorithmic Reasoning is an emerging area of machine learning which
seeks to infuse algorithmic computation in neural networks, typically by
training neural models to approximate steps of classical algorithms. In this
context, much of the current work has focused on learning reachability and
shortest path graph algorithms, showing that joint learning on similar
algorithms is beneficial for generalisation. However, when targeting more
complex problems, such similar algorithms become more difficult to find. Here,
we propose to learn algorithms by exploiting duality of the underlying
algorithmic problem. Many algorithms solve optimisation problems. We
demonstrate that simultaneously learning the dual definition of these
optimisation problems in algorithmic learning allows for better learning and
qualitatively better solutions. Specifically, we exploit the max-flow min-cut
theorem to simultaneously learn these two algorithms over synthetically
generated graphs, demonstrating the effectiveness of the proposed approach. We
then validate the real-world utility of our dual algorithmic reasoner by
deploying it on a challenging brain vessel classification task, which likely
depends on the vessels' flow properties. We demonstrate a clear performance
gain when using our model within such a context, and empirically show that
learning the max-flow and min-cut algorithms together is critical for achieving
such a result.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Numeroso_D/0/1/0/all/0/1">Danilo Numeroso</a>, <a href="http://arxiv.org/find/cs/1/au:+Bacciu_D/0/1/0/all/0/1">Davide Bacciu</a>, <a href="http://arxiv.org/find/cs/1/au:+Velickovic_P/0/1/0/all/0/1">Petar Veli&#x10d;kovi&#x107;</a></p><p>Neural Algorithmic Reasoning is an emerging area of machine learning which
seeks to infuse algorithmic computation in neural networks, typically by
training neural models to approximate steps of classical algorithms. In this
context, much of the current work has focused on learning reachability and
shortest path graph algorithms, showing that joint learning on similar
algorithms is beneficial for generalisation. However, when targeting more
complex problems, such similar algorithms become more difficult to find. Here,
we propose to learn algorithms by exploiting duality of the underlying
algorithmic problem. Many algorithms solve optimisation problems. We
demonstrate that simultaneously learning the dual definition of these
optimisation problems in algorithmic learning allows for better learning and
qualitatively better solutions. Specifically, we exploit the max-flow min-cut
theorem to simultaneously learn these two algorithms over synthetically
generated graphs, demonstrating the effectiveness of the proposed approach. We
then validate the real-world utility of our dual algorithmic reasoner by
deploying it on a challenging brain vessel classification task, which likely
depends on the vessels' flow properties. We demonstrate a clear performance
gain when using our model within such a context, and empirically show that
learning the max-flow and min-cut algorithms together is critical for achieving
such a result.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04581'>A Reduction from Chores Allocation to Job Scheduling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xin Huang, Erel Segal-Halevi</p><p>We consider allocating indivisible chores among agents with different cost
functions, such that all agents receive a cost of at most a constant factor
times their maximin share. The state-of-the-art was presented in In EC 2021 by
Huang and Lu. They presented a non-polynomial-time algorithm, called HFFD, that
attains an 11/9 approximation, and a polynomial-time algorithm that attains a
5/4 approximation.
</p>
<p>In this paper, we show that HFFD can be reduced to an algorithm called
MultiFit, developed by Coffman, Garey and Johnson in 1978 for makespan
minimization in job scheduling. Using this reduction, we prove that the
approximation ratio of HFFD is in fact equal to that of MultiFit, which is
known to be 13/11 in general, 20/17 for n at most 7, and 15/13 for n=3.
</p>
<p>Moreover, we develop an algorithm for (13/11+epsilon)-maximin-share
allocation for any epsilon&gt;0, with run-time polynomial in the problem size and
1/epsilon. For n=3, we can improve the algorithm to find a 15/13-maximin-share
allocation with run-time polynomial in the problem size. Thus, we have
practical algorithms that attain the best known approximation to maximin-share
chore allocation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Segal_Halevi_E/0/1/0/all/0/1">Erel Segal-Halevi</a></p><p>We consider allocating indivisible chores among agents with different cost
functions, such that all agents receive a cost of at most a constant factor
times their maximin share. The state-of-the-art was presented in In EC 2021 by
Huang and Lu. They presented a non-polynomial-time algorithm, called HFFD, that
attains an 11/9 approximation, and a polynomial-time algorithm that attains a
5/4 approximation.
</p>
<p>In this paper, we show that HFFD can be reduced to an algorithm called
MultiFit, developed by Coffman, Garey and Johnson in 1978 for makespan
minimization in job scheduling. Using this reduction, we prove that the
approximation ratio of HFFD is in fact equal to that of MultiFit, which is
known to be 13/11 in general, 20/17 for n at most 7, and 15/13 for n=3.
</p>
<p>Moreover, we develop an algorithm for (13/11+epsilon)-maximin-share
allocation for any epsilon&gt;0, with run-time polynomial in the problem size and
1/epsilon. For n=3, we can improve the algorithm to find a 15/13-maximin-share
allocation with run-time polynomial in the problem size. Thus, we have
practical algorithms that attain the best known approximation to maximin-share
chore allocation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04624'>A new width parameter of graphs based on edge cuts: $\alpha$-edge-crossing width</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yeonsu Chang, O-joung Kwon, Myounghwan Lee</p><p>We introduce graph width parameters, called $\alpha$-edge-crossing width and
edge-crossing width. These are defined in terms of the number of edges crossing
a bag of a tree-cut decomposition. They are motivated by edge-cut width,
recently introduced by Brand et al. (WG 2022). We show that edge-crossing width
is equivalent to the known parameter tree-partition-width. On the other hand,
$\alpha$-edge-crossing width is a new parameter; tree-cut width and
$\alpha$-edge-crossing width are incomparable, and they both lie between
tree-partition-width and edge-cut width.
</p>
<p>We provide an algorithm that, for a given $n$-vertex graph $G$ and integers
$k$ and $\alpha$, in time $2^{O((\alpha+k)\log (\alpha+k))}n^2$ either outputs
a tree-cut decomposition certifying that the $\alpha$-edge-crossing width of
$G$ is at most $2\alpha^2+5k$ or confirms that the $\alpha$-edge-crossing width
of $G$ is more than $k$. As applications, for every fixed $\alpha$, we obtain
FPT algorithms for the List Coloring and Precoloring Extension problems
parameterized by $\alpha$-edge-crossing width. They were known to be W[1]-hard
parameterized by tree-partition-width, and FPT parameterized by edge-cut width,
and we close the complexity gap between these two parameters.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yeonsu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_O/0/1/0/all/0/1">O-joung Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1">Myounghwan Lee</a></p><p>We introduce graph width parameters, called $\alpha$-edge-crossing width and
edge-crossing width. These are defined in terms of the number of edges crossing
a bag of a tree-cut decomposition. They are motivated by edge-cut width,
recently introduced by Brand et al. (WG 2022). We show that edge-crossing width
is equivalent to the known parameter tree-partition-width. On the other hand,
$\alpha$-edge-crossing width is a new parameter; tree-cut width and
$\alpha$-edge-crossing width are incomparable, and they both lie between
tree-partition-width and edge-cut width.
</p>
<p>We provide an algorithm that, for a given $n$-vertex graph $G$ and integers
$k$ and $\alpha$, in time $2^{O((\alpha+k)\log (\alpha+k))}n^2$ either outputs
a tree-cut decomposition certifying that the $\alpha$-edge-crossing width of
$G$ is at most $2\alpha^2+5k$ or confirms that the $\alpha$-edge-crossing width
of $G$ is more than $k$. As applications, for every fixed $\alpha$, we obtain
FPT algorithms for the List Coloring and Precoloring Extension problems
parameterized by $\alpha$-edge-crossing width. They were known to be W[1]-hard
parameterized by tree-partition-width, and FPT parameterized by edge-cut width,
and we close the complexity gap between these two parameters.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04747'>An $O(\log k)$-Approximation for Directed Steiner Tree in Planar Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zachary Friggstad, Ramin Mousavi</p><p>We present an $O(\log k)$-approximation for both the edge-weighted and
node-weighted versions of \DST in planar graphs where $k$ is the number of
terminals. We extend our approach to \MDST (in general graphs \MDST and \DST
are easily seen to be equivalent but in planar graphs this is not the case
necessarily) in which we get a $O(R+\log k)$-approximation for planar graphs
for where $R$ is the number of roots.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Friggstad_Z/0/1/0/all/0/1">Zachary Friggstad</a>, <a href="http://arxiv.org/find/cs/1/au:+Mousavi_R/0/1/0/all/0/1">Ramin Mousavi</a></p><p>We present an $O(\log k)$-approximation for both the edge-weighted and
node-weighted versions of \DST in planar graphs where $k$ is the number of
terminals. We extend our approach to \MDST (in general graphs \MDST and \DST
are easily seen to be equivalent but in planar graphs this is not the case
necessarily) in which we get a $O(R+\log k)$-approximation for planar graphs
for where $R$ is the number of roots.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04783'>$t$-sails and sparse hereditary classes of unbounded tree-width</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Cocks</p><p>It has long been known that the following basic objects are obstructions to
bounded tree-width: for arbitrarily large $t$, $(1)$ a subdivision of the
complete graph $K_t$, $(2)$ a subdivision of the complete bipartite graph
$K_{t,t}$, $(3)$ a subdivision of the $(t \times t)$-wall and $(4)$ a line
graph of a subdivision of the $(t \times t)$-wall. We are now able to add a
further \emph{boundary object} to this list, a subdivision of a
\emph{$t$-sail}. We identify new hereditary graph classes of unbounded
tree-width that do not contain any of the four basic obstructions but instead
contain arbitrarily large $t$-sails or subdivisions of a $t$-sail. We also show
that these sparse graph classes do not contain a minimal class of unbounded
tree-width.
</p>
<p>These results have been obtained by studying \emph{path-star} graph classes,
a type of sparse hereditary graph class formed by combining a path (or union of
paths) with a forest of stars, characterised by an infinite word over a
possibly infinite alphabet.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Cocks_D/0/1/0/all/0/1">Daniel Cocks</a></p><p>It has long been known that the following basic objects are obstructions to
bounded tree-width: for arbitrarily large $t$, $(1)$ a subdivision of the
complete graph $K_t$, $(2)$ a subdivision of the complete bipartite graph
$K_{t,t}$, $(3)$ a subdivision of the $(t \times t)$-wall and $(4)$ a line
graph of a subdivision of the $(t \times t)$-wall. We are now able to add a
further \emph{boundary object} to this list, a subdivision of a
\emph{$t$-sail}. We identify new hereditary graph classes of unbounded
tree-width that do not contain any of the four basic obstructions but instead
contain arbitrarily large $t$-sails or subdivisions of a $t$-sail. We also show
that these sparse graph classes do not contain a minimal class of unbounded
tree-width.
</p>
<p>These results have been obtained by studying \emph{path-star} graph classes,
a type of sparse hereditary graph class formed by combining a path (or union of
paths) with a forest of stars, characterised by an infinite word over a
possibly infinite alphabet.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-10T01:30:00Z">Friday, February 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, February 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/why-cant-little-chatty-do-math.html'>Why Can't Little Chatty Do Math?</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Despite OpenAI's claim that ChatGPT has improved mathematical capabilities, we don't get far multiplying large numbers.<br>♦<br>Typical for ChatGPT, the answer passes the smell test. It has the right number of digits and has correct first and last couple of digits. But the real answer is&nbsp;646382140418841070,&nbsp; quite different from the number given.<br>As far as I know, multiplication isn't known to be in&nbsp;TC0, the complexity class that roughly corresponds to neural nets. [Note Added: Multiplication is in TC0. See comments.] Also functions learned by deep learning can often be inverted by deep learning. So if AI can learn how to multiply, it might also learn how to factor.&nbsp;<br>But what about addition? Addition is known to be in TC0 and ChatGPT performs better.<br>♦<br>The correct answer is&nbsp;1612502411, only one digit off but still wrong. The TC0 algorithm needs to do some tricks for carry lookahead that is probably hard to learn. Addition is easier if you work from right to left, but ChatGPT has trouble reversing numbers. There's a limit to its self-attention.<br>♦<br><br>ChatGPT can't multiply but it does know how to write a program to multiply.<br>♦<br>It still claims the result will be the same as before. Running the program gives the correct answer&nbsp;646382140418841070.&nbsp;<br>ChatGPT is run on a general purpose computer, so one could hope a later version that could determine when its given a math question, write a program and run it. That's probably too dangerous--we would want to avoid a code injection vulnerability. But still it could use an API to WolframAlpha or some other math engine. Or a chess engine to play chess. Etc.&nbsp;<p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <div>Despite OpenAI's claim that ChatGPT has improved mathematical capabilities, we don't get far multiplying large numbers.</div><div><br /></div><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnHsNFxbQ6oNEW1qIr0bFD8Jw_ESAXGWVGYfpsQyeZVoVnhlOgUHS5lozsRweLvsHAe3MFc5GU4tWvOyU7IbcykpHEVL2fo5Pm7kMkz-WIb5khJqZhVyXv9mI9bvRhlI9n6Jl0T29uzy8nVlcCtrEki46W0We3IxOBaXYZZHB36dMopnKWPA/s887/mult.jpg" style="margin-left: 1em; margin-right: 1em;"><img alt="L:What is 866739766 * 745762645?  C:647733560997969470" border="0" data-original-height="191" data-original-width="887" height="86" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnHsNFxbQ6oNEW1qIr0bFD8Jw_ESAXGWVGYfpsQyeZVoVnhlOgUHS5lozsRweLvsHAe3MFc5GU4tWvOyU7IbcykpHEVL2fo5Pm7kMkz-WIb5khJqZhVyXv9mI9bvRhlI9n6Jl0T29uzy8nVlcCtrEki46W0We3IxOBaXYZZHB36dMopnKWPA/w400-h86/mult.jpg" width="400" /></a></div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">Typical for ChatGPT, the answer passes the smell test. It has the right number of digits and has correct first and last couple of digits. But the real answer is&nbsp;646382140418841070,&nbsp; quite different from the number given.</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">As far as I know, multiplication isn't known to be in&nbsp;<a href="https://complexityzoo.net/Complexity_Zoo:T#tc0">TC<sup>0</sup></a>, the complexity class that roughly corresponds to neural nets. [Note Added: Multiplication is in TC<sup>0</sup>. See <a href="https://blog.computationalcomplexity.org/2023/02/why-cant-little-chatty-do-math.html?showComment=1675963811947#c5283298584977635369">comments</a>.] Also functions learned by deep learning can often be inverted by deep learning. So if AI can learn how to multiply, it might also learn how to factor.&nbsp;</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">But what about addition? Addition is known to be in TC<sup>0</sup> and ChatGPT performs better.</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVo4fuwVf4sege-8Wm41_dOSQZvTeHhUB7Wn5oe3_OQZna0J-y2EmiBka5yq8ftdHPrG4Lth6SJyEcerSExsJpQm6DbsiKN9Hf49Fkcgf3XReVRCzYylbGfGJqzHmsCj8BF46UCv4DLWcIFfSnFrG41RoTtUCMb6YwaaP2V7nAC6LntsM26A/s897/add.jpg" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="193" data-original-width="897" height="86" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVo4fuwVf4sege-8Wm41_dOSQZvTeHhUB7Wn5oe3_OQZna0J-y2EmiBka5yq8ftdHPrG4Lth6SJyEcerSExsJpQm6DbsiKN9Hf49Fkcgf3XReVRCzYylbGfGJqzHmsCj8BF46UCv4DLWcIFfSnFrG41RoTtUCMb6YwaaP2V7nAC6LntsM26A/w400-h86/add.jpg" width="400" /></a></div><br /><div class="separator" style="clear: both; text-align: left;">The correct answer is&nbsp;1612502411, only one digit off but still wrong. The TC<sup>0</sup> algorithm needs to do some tricks for carry lookahead that is probably hard to learn. Addition is easier if you work from right to left, but ChatGPT has trouble reversing numbers. There's a limit to its self-attention.</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiVaCr_CJXUTeQUVDWj38LkVnI37p0u5P8_ABoOqBG5T4ymxwEUxlzc60UU9-YSCXSccpH1ICpDlJJ8KGuK8h7Olf4JmYdwsW2nd3kdEhmnm4mQe0HikFlmkiZt1v6Zj3jddoVV-waokMYLixiFYQAR4pV58e9s6ULshXUql32JuR5nIzd7Lg/s892/backwards.jpg" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="201" data-original-width="892" height="90" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiVaCr_CJXUTeQUVDWj38LkVnI37p0u5P8_ABoOqBG5T4ymxwEUxlzc60UU9-YSCXSccpH1ICpDlJJ8KGuK8h7Olf4JmYdwsW2nd3kdEhmnm4mQe0HikFlmkiZt1v6Zj3jddoVV-waokMYLixiFYQAR4pV58e9s6ULshXUql32JuR5nIzd7Lg/w400-h90/backwards.jpg" width="400" /></a></div><br /><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">ChatGPT can't multiply but it does know how to write a program to multiply.</div><br /><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjAtKeY7oA8q4mgvad016knm2noD1Nd7-Pk2wSicc_6fs-4nAF0f2LWInnmeV0sBnHB7sw92eeFbEfsXDCD1kNoebURfH4zziLhSbVVv-GKL0g_EwnE8A2PH8Qr5J12uC1xkYk16I6HwMdmmodECNEijrrSV5FeArwyLA1qKZ-3QdCC8lxOiQ/s907/python.jpg" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="528" data-original-width="907" height="233" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjAtKeY7oA8q4mgvad016knm2noD1Nd7-Pk2wSicc_6fs-4nAF0f2LWInnmeV0sBnHB7sw92eeFbEfsXDCD1kNoebURfH4zziLhSbVVv-GKL0g_EwnE8A2PH8Qr5J12uC1xkYk16I6HwMdmmodECNEijrrSV5FeArwyLA1qKZ-3QdCC8lxOiQ/w400-h233/python.jpg" width="400" /></a></div><br /><div>It still claims the result will be the same as before. Running the program gives the correct answer&nbsp;646382140418841070.&nbsp;</div><div><br /></div><div>ChatGPT is run on a general purpose computer, so one could hope a later version that could determine when its given a math question, write a program and run it. That's probably too dangerous--we would want to avoid a code injection vulnerability. But still it could use an API to WolframAlpha or some other math engine. Or a chess engine to play chess. Etc.&nbsp;</div><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T14:59:00Z">Thursday, February 09 2023, 14:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/02/09/mathematics-of-the-impossible-computational-complexity-chapter-4-reductions/'>Mathematics of the impossible: Computational Complexity, chapter 4, reductions</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          All posts in this series. A PDF version of this post will be published with a delay, but if you’d like to have it soon let me know. Contents 4 Reductions 4.1 Types of reductions 4.2 Reductions 4.2.1 Multiplication 4.2.2 3Sum 4.3 Reductions from 3Sat 4.4 Power hardness from SETH 4.5 Search problems 4.5.1 Fastest [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <hr />
<p><!--?xml version="1.0" encoding="iso-8859-1" ?--> <!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd--> <!-- html,xhtml,-css,NoFonts --></p>
<div class="maketitle">
<div class="date"><a href="https://emanueleviola.wordpress.com/tag/moti/">All posts in this series.</a><br />
A PDF version of this post will be published with a delay, but if you’d like to have it soon let me know.</div>
</div>
<h2 class="likechapterHead"><a id="x1-1000"></a>Contents</h2>
<div class="tableofcontents"><span class="chapterToc">4 <a id="QQ2-1-48" href="#x1-450004">Reductions</a></span><br />
<span class="sectionToc">4.1 <a id="QQ2-1-49" href="#x1-460004.1">Types of reductions</a></span><br />
<span class="sectionToc">4.2 <a id="QQ2-1-50" href="#x1-470004.2">Reductions</a></span><br />
<span class="subsectionToc">4.2.1 <a id="QQ2-1-51" href="#x1-480004.2.1">Multiplication</a></span><br />
<span class="subsectionToc">4.2.2 <a id="QQ2-1-52" href="#x1-490004.2.2">3Sum</a></span><br />
<span class="sectionToc">4.3 <a id="QQ2-1-53" href="#x1-500004.3">Reductions from 3Sat </a></span><br />
<span class="sectionToc">4.4 <a id="QQ2-1-54" href="#x1-510004.4">Power hardness from SETH</a></span><br />
<span class="sectionToc">4.5 <a id="QQ2-1-55" href="#x1-520004.5">Search problems</a></span><br />
<span class="subsectionToc">4.5.1 <a id="QQ2-1-56" href="#x1-530004.5.1">Fastest algorithm for Search-3Sat</a></span><br />
<span class="sectionToc">4.6 <a id="QQ2-1-57" href="#x1-540004.6">Gap-SAT: The PCP theorem </a></span><br />
<span class="sectionToc">4.7 <a id="QQ2-1-58" href="#x1-550004.7">Problems</a></span></div>
<div id="verbatim-1" class="verbatim"></div>
<p style="text-align: justify">
<h2 class="chapterHead"><span class="titlemark">Chapter&nbsp;4</span><br />
<a id="x1-450004"></a>Reductions</h2>
<div class="flushright">
<p style="text-align: justify"><img src="hamiltonian.png" alt="PIC" width="371" height="321"/></p>
</div>
<div class="flushright">
<p style="text-align: justify"><a href="https://xkcd.com/230/" rel="nofollow">https://xkcd.com/230/</a></p>
</div>
<p style="text-align: justify">One can relate the complexity of functions via <em>reductions</em>. This concept is so ingrained in common reasoning that giving it a name may feel, at times, strange. For in some sense pretty much everything proceeds by reductions. In any algorithms textbook, the majority of algorithms can be cast as reductions to algorithms presented earlier in the book, and so on. And it is worthwhile to emphasize now that, as we shall see below, reductions, even in the context of computing, have been used for millennia. For about a century reductions have been used in the context of undecidability in a modern way, starting with the incompleteness theorem in logic <span class="cite">[<a href="#XMR1549939">8</a>]</span>, whose proof reduces questions in logic to questions in arithmetic.</p>
<p style="text-align: justify">Perhaps one reason for the more recent interest in complexity reductions is that we can use them to relate problems that are tantalizingly close to problems that today we solve routinely on somewhat large scale inputs with computers, and that therefore appear to be just out of reach. By contrast, reductions in the context of undecidability tend to apply to problems that are completely out of reach, and in this sense remote from our immediate worries.</p>
<h3 class="sectionHead"><span class="titlemark">4.1 </span> <a id="x1-460004.1"></a>Types of reductions</h3>
<p style="text-align: justify">Informally, a reduction from a function <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> to a function <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> is a way to compute <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> given that we can compute <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" />. One can define reductions in different ways, depending on the overhead required to compute <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> given that we can compute <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" />. The most general type of reduction is simply an <em>implication</em>.</p>
<div style="text-align: center">
<p style="text-align: justify">
<div class="minipage">
<p style="text-align: justify"><b>General form of reduction from <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" />:</b></p>
<p style="text-align: justify">&nbsp;&nbsp;<b>If</b> <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> can be computed with resources <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> <b>then </b><img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> can be computed with resources <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" />.</p>
</div>
</div>
<p style="text-align: justify">A common setting is when <img src="https://s0.wp.com/latex.php?latex=X%3DY&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%3DY&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%3DY&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X=Y" class="latex" />. In this case the reduction allows us to stay within the same complexity class.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-46001r1"></a> <b>Definition</b> 4.1. </span>We say that <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> (or under <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> reductions) if</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+g%5Cin+X%5CRightarrow+f%5Cin+X.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+g%5Cin+X%5CRightarrow+f%5Cin+X.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+g%5Cin+X%5CRightarrow+f%5Cin+X.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} g&#92;in X&#92;Rightarrow f&#92;in X. &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">
</div>
<p style="text-align: justify">A further special and noteworthy case is when <img src="https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X=&#92;text {P}" class="latex" />, or <img src="https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X=&#92;text {BPP}" class="latex" />; in these cases the reduction can be interpreted as saying that if <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> is easy to compute than <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is too.But in general <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> may not be equal to <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" />. We will see examples of such implications for various <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" />.</p>
<p style="text-align: justify">It is sometimes useful to be more specific about how the implication is proved. For example, this is useful when inferring various properties of <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> from properties of <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" />, something which can be obscured by a stark implication. The following definition gives a specific way in which the implication can be proved.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-46002r2"></a> <b>Definition</b> 4.2. </span>We say that <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> <em>map reduces </em>to <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> (or via a map in <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" />) if there is <img src="https://s0.wp.com/latex.php?latex=M%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M&#92;in X" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3Dg%28M%28x%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3Dg%28M%28x%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3Dg%28M%28x%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)=g(M(x))" class="latex" /> for every <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-46003r1"></a> <b>Exercise</b> 4.1. </span>Suppose that <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> map reduces to <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" />.</p>
<p style="text-align: justify">(1) Suppose <img src="https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X=&#92;text {P}" class="latex" />. Show <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BX%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BX%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BX%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {X}" class="latex" />.</p>
<p style="text-align: justify">(2) Suppose <img src="https://s0.wp.com/latex.php?latex=X%3D%5Cbigcup+_%7Bd%7D%5Ctext+%7BTime%7D%28d%5Ccdot+n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%3D%5Cbigcup+_%7Bd%7D%5Ctext+%7BTime%7D%28d%5Ccdot+n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%3D%5Cbigcup+_%7Bd%7D%5Ctext+%7BTime%7D%28d%5Ccdot+n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X=&#92;bigcup _{d}&#92;text {Time}(d&#92;cdot n^{2})" class="latex" />. Can you still show that <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BX%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BX%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BX%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {X}" class="latex" />?</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Many reductions we shall see are not mapping reductions. In fact, our first example is not a mapping reduction.</p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">4.2 </span> <a id="x1-470004.2"></a>Reductions</h3>
<p style="text-align: justify">
<h4 class="subsectionHead"><span class="titlemark">4.2.1 </span> <a id="x1-480004.2.1"></a>Multiplication</h4>
<p style="text-align: justify">Summing two <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />-bit integers is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BCktGates%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BCktGates%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BCktGates%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {CktGates}(cn)" class="latex" /> (Exercise <a href="#x1-25005r8">2.8<!--tex4ht:ref: xca:sum-ckt --></a>). But the smallest circuit known for multiplication has <img src="https://s0.wp.com/latex.php?latex=%5Cge+cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+cn%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge cn&#92;log n" class="latex" /> gates <span class="cite">[<a href="#X10.4007/annals.2021.193.2.4">10</a>]</span>. (The same situation holds for MTMs; over RAMs and related models multiplication can be done in time <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" /> <span class="cite">[<a href="journals/siamcomp/Schonhage80">21</a>]</span>.) It is a long-standing question whether we can multiply two <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />-bit integers with a linear-size circuit.</p>
<p style="text-align: justify">What about squaring integers? Is that harder or easier than multiplication? Obviously, if we can multiply two numbers we can also square a number: simply multiply it by itself. This is a trivial example of a reduction. What about the other way around? We can use a reduction established millennia ago by the Babylonians. They employed the equation</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5Ccdot+b%3D%5Cfrac+%7B%28a%2Bb%29%5E%7B2%7D-%28a-b%29%5E%7B2%7D%7D%7B4%7D%7E%7E%7E%7E%284.1%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5Ccdot+b%3D%5Cfrac+%7B%28a%2Bb%29%5E%7B2%7D-%28a-b%29%5E%7B2%7D%7D%7B4%7D%7E%7E%7E%7E%284.1%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5Ccdot+b%3D%5Cfrac+%7B%28a%2Bb%29%5E%7B2%7D-%28a-b%29%5E%7B2%7D%7D%7B4%7D%7E%7E%7E%7E%284.1%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} a&#92;cdot b=&#92;frac {(a+b)^{2}-(a-b)^{2}}{4}~~~~(4.1) &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">to reduce multiplication to squaring, plus some easy operations like addition and division by four. In our terminology we have the following.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-48001r3"></a> <b>Definition</b> 4.3. </span>Multiplication is the problem of computing the product of two <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />-bit integers. Squaring is the problem of computing the square of an <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />-bit integer.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-48002r1"></a> <b>Theorem</b> 4.1. </span>If Squaring has linear-size circuits then Multiplication has linear-size circuits.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>.&nbsp;</span>Suppose <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> computes Squaring. Then we can multiply using equation&nbsp;(??). Specifically, given <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b" class="latex" /> we use Exercise <a href="#x1-25005r8">2.8<!--tex4ht:ref: xca:sum-ckt --></a> to compute <img src="https://s0.wp.com/latex.php?latex=a%2Bb&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%2Bb&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%2Bb&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a+b" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=a-b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a-b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a-b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a-b" class="latex" />. (We haven’t seen subtraction or negative integers, but it’s similar to addition.) Then we run <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> on both of them. Finally, we again use Exercise <a href="#x1-25005r8">2.8<!--tex4ht:ref: xca:sum-ckt --></a> for computing their difference. It remains to divide by four. In binary, this is accomplished by ignoring the last two bits – which costs nothing on a circuit. <b>QED</b></p>
</div>
<p style="text-align: justify">
<h4 class="subsectionHead"><span class="titlemark">4.2.2 </span> <a id="x1-490004.2.2"></a>3Sum</h4>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49001r4"></a> <b>Definition</b> 4.4. </span> The <img src="https://s0.wp.com/latex.php?latex=3%5Ctext+%7BSum%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3%5Ctext+%7BSum%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3%5Ctext+%7BSum%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3&#92;text {Sum}" class="latex" /> problem: Given a list of integers, are there three integers that sum to <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" />?</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">It is easy to solve 3Sum in time <img src="https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn%5E%7B2%7D%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn^{2}&#92;log n" class="latex" /> on a RAM. (We can first sort the integers then for each pair <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(a,b)" class="latex" /> we can do a binary search to check if <img src="https://s0.wp.com/latex.php?latex=-%28a%2Bb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=-%28a%2Bb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=-%28a%2Bb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="-(a+b)" class="latex" /> is also present.) The time can be improved <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D%2F%5Clog+%5E%7Bc%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}/&#92;log ^{c}n" class="latex" />.</p>
<p style="text-align: justify">3Sum is believed to require quadratic time.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49002r5"></a> <b>Definition</b> 4.5. </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSubquadraticTime%7D%3A%3D%5Cbigcup+_%7B%5Cepsilon+%3E0%7D%5Ctext+%7BTime%7D%28n%5E%7B2-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSubquadraticTime%7D%3A%3D%5Cbigcup+_%7B%5Cepsilon+%3E0%7D%5Ctext+%7BTime%7D%28n%5E%7B2-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BSubquadraticTime%7D%3A%3D%5Cbigcup+_%7B%5Cepsilon+%3E0%7D%5Ctext+%7BTime%7D%28n%5E%7B2-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {SubquadraticTime}:=&#92;bigcup _{&#92;epsilon &gt;0}&#92;text {Time}(n^{2-&#92;epsilon })" class="latex" />.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49003r1"></a> <b>Conjecture</b> 4.1. </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cnot+%5Cin+%5Ctext+%7BSubquadraticTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cnot+%5Cin+%5Ctext+%7BSubquadraticTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cnot+%5Cin+%5Ctext+%7BSubquadraticTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sum}&#92;not &#92;in &#92;text {SubquadraticTime}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">One can reduce 3Sum to a number of other interesting problem to infer that, under Conjecture <a href="#x1-49003r1">4.1<!--tex4ht:ref: conj:3sum --></a>, those problems require quadratic time too.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49004r6"></a> <b>Definition</b> 4.6. </span>The Collinearity problem: Given a list of points in the plane, are there three points on a line?</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49005r2"></a> <b>Theorem</b> 4.2. </span><span class="cite">[<a href="#XGajentaanO95">6</a>]</span> <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BCollinearity%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BCollinearity%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BCollinearity%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Collinearity}&#92;in &#92;text {SubquadraticTime&#92;ensuremath {&#92;Rightarrow &#92;text {3Sum}&#92;in &#92;text {SubquadraticTime}} (i.e., }" class="latex" />Conjecture <a href="#x1-49003r1">4.1<!--tex4ht:ref: conj:3sum --></a> is false).</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>.&nbsp;</span>We map instance <img src="https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Ca_%7B2%7D%2C%5Cldots+%2Ca_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Ca_%7B2%7D%2C%5Cldots+%2Ca_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Ca_%7B2%7D%2C%5Cldots+%2Ca_%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a_{1},a_{2},&#92;ldots ,a_{n}" class="latex" /> of 3Sum to the points</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28a_%7B1%7D%2Ca_%7B1%7D%5E%7B3%7D%29%2C%28a_%7B2%7D%2Ca_%7B2%7D%5E%7B3%7D%29%2C%5Cldots+%2C%28a_%7Bn%7D%2Ca_%7Bn%7D%5E%7B3%7D%29%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28a_%7B1%7D%2Ca_%7B1%7D%5E%7B3%7D%29%2C%28a_%7B2%7D%2Ca_%7B2%7D%5E%7B3%7D%29%2C%5Cldots+%2C%28a_%7Bn%7D%2Ca_%7Bn%7D%5E%7B3%7D%29%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28a_%7B1%7D%2Ca_%7B1%7D%5E%7B3%7D%29%2C%28a_%7B2%7D%2Ca_%7B2%7D%5E%7B3%7D%29%2C%5Cldots+%2C%28a_%7Bn%7D%2Ca_%7Bn%7D%5E%7B3%7D%29%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} (a_{1},a_{1}^{3}),(a_{2},a_{2}^{3}),&#92;ldots ,(a_{n},a_{n}^{3}), &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">and solve Collinearity on those points.</p>
<p style="text-align: justify">To verify correctness, notice that points <img src="https://s0.wp.com/latex.php?latex=%28x%2Cx%5E%7B3%7D%29%2C%28y%2Cy%5E%7B3%7D%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cx%5E%7B3%7D%29%2C%28y%2Cy%5E%7B3%7D%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cx%5E%7B3%7D%29%2C%28y%2Cy%5E%7B3%7D%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,x^{3}),(y,y^{3})," class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%28z%2Cz%5E%7B3%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28z%2Cz%5E%7B3%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28z%2Cz%5E%7B3%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(z,z^{3})" class="latex" /> are on a line iff</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac+%7By%5E%7B3%7D-x%5E%7B3%7D%7D%7By-x%7D%3D%5Cfrac+%7Bz%5E%7B3%7D-x%5E%7B3%7D%7D%7Bz-x%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac+%7By%5E%7B3%7D-x%5E%7B3%7D%7D%7By-x%7D%3D%5Cfrac+%7Bz%5E%7B3%7D-x%5E%7B3%7D%7D%7Bz-x%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac+%7By%5E%7B3%7D-x%5E%7B3%7D%7D%7By-x%7D%3D%5Cfrac+%7Bz%5E%7B3%7D-x%5E%7B3%7D%7D%7Bz-x%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;frac {y^{3}-x^{3}}{y-x}=&#92;frac {z^{3}-x^{3}}{z-x}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align: justify">Because <img src="https://s0.wp.com/latex.php?latex=y%5E%7B3%7D-x%5E%7B3%7D%3D%28y-x%29%28y%5E%7B2%7D%2Byx%2Bx%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y%5E%7B3%7D-x%5E%7B3%7D%3D%28y-x%29%28y%5E%7B2%7D%2Byx%2Bx%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y%5E%7B3%7D-x%5E%7B3%7D%3D%28y-x%29%28y%5E%7B2%7D%2Byx%2Bx%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y^{3}-x^{3}=(y-x)(y^{2}+yx+x^{2})" class="latex" />, this condition is equivalent to</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%2Byx%2Bx%5E%7B2%7D%3Dz%5E%7B2%7D%2Bzx%2Bx%5E%7B2%7D%5CLeftrightarrow+%28x%2B%28y%2Bz%29%29%28y-z%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%2Byx%2Bx%5E%7B2%7D%3Dz%5E%7B2%7D%2Bzx%2Bx%5E%7B2%7D%5CLeftrightarrow+%28x%2B%28y%2Bz%29%29%28y-z%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%2Byx%2Bx%5E%7B2%7D%3Dz%5E%7B2%7D%2Bzx%2Bx%5E%7B2%7D%5CLeftrightarrow+%28x%2B%28y%2Bz%29%29%28y-z%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} y^{2}+yx+x^{2}=z^{2}+zx+x^{2}&#92;Leftrightarrow (x+(y+z))(y-z). &#92;end{aligned}" class="latex" /></div>
<p>Assuming <img src="https://s0.wp.com/latex.php?latex=y%5Cne+z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y%5Cne+z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y%5Cne+z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y&#92;ne z" class="latex" />, i.e., that the 3Sum instance consists of distinct numbers, this is equivalent to <img src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x+y+z=0" class="latex" />, as desired. (The case where there can be duplicates is left as an exercise.)</p>
<p style="text-align: justify">Note that the Collinearity instance has length linear in the 3Sum instance, and the result follows. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49006r2"></a> <b>Exercise</b> 4.2. </span>The Tripartite-3Sum problem: Given lists <img src="https://s0.wp.com/latex.php?latex=A_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A_{1}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=A_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A_{2}" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=A_%7B3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A_%7B3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A_%7B3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A_{3}" class="latex" /> of numbers, are there <img src="https://s0.wp.com/latex.php?latex=a_%7Bi%7D%5Cin+A_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a_%7Bi%7D%5Cin+A_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a_%7Bi%7D%5Cin+A_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a_{i}&#92;in A_{i}" class="latex" /> s.t.&nbsp;<img src="https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Ba_%7B2%7D%2Ba_%7B3%7D%3D0%3F&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Ba_%7B2%7D%2Ba_%7B3%7D%3D0%3F&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Ba_%7B2%7D%2Ba_%7B3%7D%3D0%3F&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a_{1}+a_{2}+a_{3}=0?" class="latex" /></p>
<p style="text-align: justify">Prove that Tripartite-3Sum is in subquadratic time iff 3Sum is.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">We now give a reduction in the other direction: We reduce a problem to 3Sum.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49007r7"></a> <b>Definition</b> 4.7. </span>The 3Cycle-Detection problem: Given the adjacency list of a directed graph, is there a cycle of length 3?</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">This problem can be solved in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%5Comega+%2F%28%5Comega+%2B1%29%2Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%5Comega+%2F%28%5Comega+%2B1%29%2Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%5Comega+%2F%28%5Comega+%2B1%29%2Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2&#92;omega /(&#92;omega +1)+o(1)}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%5Comega+%3C2.373&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Comega+%3C2.373&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Comega+%3C2.373&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;omega &lt;2.373" class="latex" /> is the exponent of matrix multiplication. If <img src="https://s0.wp.com/latex.php?latex=%5Comega+%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Comega+%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Comega+%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;omega =2" class="latex" /> then the bound is <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1.3%5Cbar+%7B3%7D%2Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B1.3%5Cbar+%7B3%7D%2Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B1.3%5Cbar+%7B3%7D%2Bo%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{1.3&#92;bar {3}+o(1)}" class="latex" />. It is not known if any subquadratic algorithm for 3Sum would improve these bounds. However, we can show that an improvement follows if <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B1%2B%5Cepsilon%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sum}&#92;in &#92;text {Time}(n^{1+&#92;epsilon})" class="latex" /> for a small enough <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49008r3"></a> <b>Theorem</b> 4.3. </span><span class="cite">[<a href="#XViola-xxx">26</a>]</span> <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BTime%7D%28t%28n%29%29%5CRightarrow+%5Ctext+%7B3Cycle-Detection%7D%5Cin+%5Ctext+%7BBPTime%7D%28ct%28n%29%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BTime%7D%28t%28n%29%29%5CRightarrow+%5Ctext+%7B3Cycle-Detection%7D%5Cin+%5Ctext+%7BBPTime%7D%28ct%28n%29%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BTime%7D%28t%28n%29%29%5CRightarrow+%5Ctext+%7B3Cycle-Detection%7D%5Cin+%5Ctext+%7BBPTime%7D%28ct%28n%29%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sum}&#92;in &#92;text {Time}(t(n))&#92;Rightarrow &#92;text {3Cycle-Detection}&#92;in &#92;text {BPTime}(ct(n))," class="latex" /> for any <img src="https://s0.wp.com/latex.php?latex=t%28n%29%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)&#92;ge n" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">The reduction can be derandomized (that is, one can replace <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPTime}" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}" class="latex" /> in the conclusion) but the randomized case contains the main ideas.</p>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>.&nbsp;</span>We assign random numbers <img src="https://s0.wp.com/latex.php?latex=r_%7Bx%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bx%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bx%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{x}" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=4%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=4%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=4%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="4&#92;log n" class="latex" /> bits to each node <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> in the graph. The 3Sum instance consists of the integers <img src="https://s0.wp.com/latex.php?latex=r_%7Bx%7D-r_%7By%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bx%7D-r_%7By%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bx%7D-r_%7By%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{x}-r_{y}" class="latex" /> for every edge <img src="https://s0.wp.com/latex.php?latex=x%5Cto+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cto+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cto+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;to y" class="latex" /> in the graph.</p>
<p style="text-align: justify">To verify correctness, suppose that there is a cycle</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5Cto+y%5Cto+z%5Cto+x+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5Cto+y%5Cto+z%5Cto+x+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5Cto+y%5Cto+z%5Cto+x+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} x&#92;to y&#92;to z&#92;to x &#92;end{aligned}" class="latex" /></div>
<p>in the graph. Then we have <img src="https://s0.wp.com/latex.php?latex=r_%7Bx%7D-r_%7By%7D%2Br_%7By%7D-r_%7Bz%7D%2Br_%7Bz%7D-r_%7Bx%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bx%7D-r_%7By%7D%2Br_%7By%7D-r_%7Bz%7D%2Br_%7Bz%7D-r_%7Bx%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bx%7D-r_%7By%7D%2Br_%7By%7D-r_%7Bz%7D%2Br_%7Bz%7D-r_%7Bx%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{x}-r_{y}+r_{y}-r_{z}+r_{z}-r_{x}=0" class="latex" />, for any random choices.</p>
<p style="text-align: justify">Conversely, suppose there is no cycle, and consider any three numbers <img src="https://s0.wp.com/latex.php?latex=r_%7Bx1%7D-r_%7By1%7D%2Cr_%7Bx2%7D-r_%7By2%7D%2Cr_%7Bx3%7D-r_%7By3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bx1%7D-r_%7By1%7D%2Cr_%7Bx2%7D-r_%7By2%7D%2Cr_%7Bx3%7D-r_%7By3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bx1%7D-r_%7By1%7D%2Cr_%7Bx2%7D-r_%7By2%7D%2Cr_%7Bx3%7D-r_%7By3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{x1}-r_{y1},r_{x2}-r_{y2},r_{x3}-r_{y3}" class="latex" /> from the reduction and its corresponding edges. Some node <img src="https://s0.wp.com/latex.php?latex=xi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=xi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=xi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="xi" class="latex" /> has unequal in-degree and out-degree in those edges. This means that when summing the three numbers, the random variable <img src="https://s0.wp.com/latex.php?latex=r_%7Bxi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bxi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bxi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{xi}" class="latex" /> will not cancel out. When selecting uniform values for that variable, the probability of getting <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> is at most <img src="https://s0.wp.com/latex.php?latex=1%2Fn%5E%7B4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%2Fn%5E%7B4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%2Fn%5E%7B4%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1/n^{4}" class="latex" />.</p>
<p style="text-align: justify">By a union bound, the probability there there are three numbers that sum to zero is <img src="https://s0.wp.com/latex.php?latex=%5Cle+n%5E%7B3%7D%2Fn%5E%7B4%7D%3C1%2F3.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n%5E%7B3%7D%2Fn%5E%7B4%7D%3C1%2F3.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n%5E%7B3%7D%2Fn%5E%7B4%7D%3C1%2F3.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n^{3}/n^{4}&lt;1/3." class="latex" /> <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-49009r3"></a> <b>Exercise</b> 4.3. </span>Prove an analogous result for undirected graphs. Note TBD: This exercise should be more interesting for 4-cycles, because you can’t just duplicate edges, I think.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Many other clusters of problems exist, for example based on matrix multiplication or all-pairs shortest path.</p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">4.3 </span> <a id="x1-500004.3"></a>Reductions from 3Sat</h3>
<p style="text-align: justify">In this section we begin to explore an important cluster of problems not known to be in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPP}" class="latex" />. What’s special about these problems is that in Chapter ?? we will show that we can reduce <em>arbitrary computation</em> to them, while this is unknown for the problems in the previous section.</p>
<p style="text-align: justify">Perhaps the most basic problem in the cluster is the following.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50001r8"></a> <b>Definition</b> 4.8. </span>The 3Sat problem: Given a 3CNF <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" />, is there an assignment <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> s.t.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cphi+%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi (x)=1" class="latex" />?</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50002r2"></a> <b>Conjecture</b> 4.2. </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%5Censuremath+%7B%5Cnot+%7D%5Censuremath+%7B%5Censuremath+%7B%5Cin+%5Ctext+%7BP%7D%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%5Censuremath+%7B%5Cnot+%7D%5Censuremath+%7B%5Censuremath+%7B%5Cin+%5Ctext+%7BP%7D%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%5Censuremath+%7B%5Cnot+%7D%5Censuremath+%7B%5Censuremath+%7B%5Cin+%5Ctext+%7BP%7D%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat&#92;ensuremath {&#92;not }&#92;ensuremath {&#92;ensuremath {&#92;in &#92;text {P}}}.}" class="latex" /></p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Stronger conjectures have been made.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50003r3"></a> <b>Conjecture</b> 4.3. </span><span class="cite">[<a href="#XIP99">13</a>]</span> [Exponential time hypothesis (ETH)] There is <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon&gt;0" class="latex" /> such that there is no algorithm that on input a <img src="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3" class="latex" />CNF <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v" class="latex" /> variables and <img src="https://s0.wp.com/latex.php?latex=cv%5E%7B3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cv%5E%7B3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cv%5E%7B3%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cv^{3}" class="latex" /> clauses decides if <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> is satisfiable in time <img src="https://s0.wp.com/latex.php?latex=2%5E%7B%28%5Cepsilon+%2Bo%281%29%29v%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7B%28%5Cepsilon+%2Bo%281%29%29v%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7B%28%5Cepsilon+%2Bo%281%29%29v%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{(&#92;epsilon +o(1))v}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50004r4"></a> <b>Conjecture</b> 4.4. </span><span class="cite">[<a href="#XIPZ01">14</a>]</span> [Strong exponential-time hypothesis (SETH)] For every <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon &gt;0" class="latex" /> there is <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" /> such that there is no algorithm that on input a <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />CNF <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v" class="latex" /> variables and <img src="https://s0.wp.com/latex.php?latex=cv%5E%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cv%5E%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cv%5E%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cv^{k}" class="latex" /> clauses decides if <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> is satisfiable in time <img src="https://s0.wp.com/latex.php?latex=2%5E%7B%281-%5Cepsilon+%2Bo%281%29%29v%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7B%281-%5Cepsilon+%2Bo%281%29%29v%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7B%281-%5Cepsilon+%2Bo%281%29%29v%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{(1-&#92;epsilon +o(1))v}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">It is known that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSETH%7D%5CRightarrow+%5Ctext+%7BETH%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSETH%7D%5CRightarrow+%5Ctext+%7BETH%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BSETH%7D%5CRightarrow+%5Ctext+%7BETH%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {SETH}&#92;Rightarrow &#92;text {ETH}," class="latex" /> but the proof is not immediate.</p>
<p style="text-align: justify">We now give reductions from 3Sat to several other problems. The reductions are in fact mapping reductions. Moreover, the reduction map can be extremely restricted, see Problem <a href="#x1-55004r4">4.4<!--tex4ht:ref: prob:reducing-the-complexity-of-reductions --></a>. In this sense, therefore, this reduction can be viewed as a direct translation of the problem, and maybe we shouldn’t really be thinking of the problems as different, even if they at first sight refer to different types of objects (formulas, graphs, numbers, etc.).</p>
<p style="text-align: justify"><b>Watch videos 29, 30, 31, and 32 </b>covering reductions: 3SAT to CLIQUE, CLIQUE to VERTEX-COVER, 3SAT to SUBSET-SUM, 3SAT to 3COLOR <b>from <a href="https://www.ccs.neu.edu/home/viola/classes/algm-generic.html" rel="nofollow">https://www.ccs.neu.edu/home/viola/classes/algm-generic.html</a></b></p>
<p style="text-align: justify">Note: The videos use the terminology “polynomial time” instead of “power time” here.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50005r4"></a> <b>Exercise</b> 4.4. </span>The problem System is defined as follows. A <em>linear inequality</em> is an inequality involving sums of variables and constants, such as <img src="https://s0.wp.com/latex.php?latex=x%2By%5Cge+z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%2By%5Cge+z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%2By%5Cge+z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x+y&#92;ge z" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=x%5Cle+-17&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cle+-17&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cle+-17&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;le -17" class="latex" />, and so on. A system of linear inequalities has an <em>integer</em> solution if it is possible to substitute integer values for the variables so that every inequality in the system becomes true. The language System consists of systems of linear inequalities that have an integer solution. For example,</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2By%5Cge+z%2Cx%5Cle+5%2Cy%5Cle+1%2Cz%5Cge+5%29%5Cin+%5Cmbox+%7BSystem+%7D%5C%5C+%28x%2By%5Cge+2z%2Cx%5Cle+5%2Cy%5Cle+1%2Cz%5Cge+5%29%5Cnot+%5Cin+%5Cmbox+%7BSystem+%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2By%5Cge+z%2Cx%5Cle+5%2Cy%5Cle+1%2Cz%5Cge+5%29%5Cin+%5Cmbox+%7BSystem+%7D%5C%5C+%28x%2By%5Cge+2z%2Cx%5Cle+5%2Cy%5Cle+1%2Cz%5Cge+5%29%5Cnot+%5Cin+%5Cmbox+%7BSystem+%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2By%5Cge+z%2Cx%5Cle+5%2Cy%5Cle+1%2Cz%5Cge+5%29%5Cin+%5Cmbox+%7BSystem+%7D%5C%5C+%28x%2By%5Cge+2z%2Cx%5Cle+5%2Cy%5Cle+1%2Cz%5Cge+5%29%5Cnot+%5Cin+%5Cmbox+%7BSystem+%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} (x+y&#92;ge z,x&#92;le 5,y&#92;le 1,z&#92;ge 5)&#92;in &#92;mbox {System }&#92;&#92; (x+y&#92;ge 2z,x&#92;le 5,y&#92;le 1,z&#92;ge 5)&#92;not &#92;in &#92;mbox {System } &#92;end{aligned}" class="latex" /></div>
<p>Reduce 3Sat to System in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50006r5"></a> <b>Exercise</b> 4.5. </span>For an integer <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-Color is the problem of deciding if the nodes of a given undirected graph <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> can be colored using <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" /> colors in such a way that no two adjacent vertices have the same color.</p>
<p style="text-align: justify">Reduce 3-Color to 4-Color P.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Reductions in the opposite directions are possible, and so in fact the problems in this section are <em>power-time equivalent</em> in the sense that any of the problems is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> iff all the others are. We will see a generic reduction in the next chapter. For now, we illustrate this equivalence in a particular case.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-50007r6"></a> <b>Exercise</b> 4.6. </span>Reduce 3Color to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />, following these steps:</p>
<p style="text-align: justify">1. Given a graph <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" />, introduce variables <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%2Cc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7Bi%2Cc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bi%2Cc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{i,c}" class="latex" /> representing that node <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> has color <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c" class="latex" /> ranges in the set of colors <img src="https://s0.wp.com/latex.php?latex=C%3D%5C%7Bg%2Cr%2Cb%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3D%5C%7Bg%2Cr%2Cb%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3D%5C%7Bg%2Cr%2Cb%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C=&#92;{g,r,b&#92;}" class="latex" />. Describe a set of clauses that is satisfiable if and only if for every <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> there is exactly one <img src="https://s0.wp.com/latex.php?latex=c%5Cin+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Cin+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Cin+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;in C" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%2Cc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7Bi%2Cc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bi%2Cc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{i,c}" class="latex" /> is true.</p>
<p style="text-align: justify">2. Introduce clauses representing that adjacent nodes do not have the same color.</p>
<p style="text-align: justify">3. Briefly conclude the proof.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Thus, we are identifying a cluster of problems which are all power-time equivalent. This cluster is so prominent that problems in it have been compiled into books <span class="cite">[<a href="#XGareyJ79">7</a>]</span>. More recently, it was shown that it contains (generalized versions of) several games including: Tetris, Lemmings, Sudoku, etc. For a list see e.g.&nbsp;the wikipedia page <a href="https://en.wikipedia.org/wiki/List_of_NP-complete_problems" rel="nofollow">https://en.wikipedia.org/wiki/List_of_NP-complete_problems</a></p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">4.4 </span> <a id="x1-510004.4"></a>Power hardness from SETH</h3>
<p style="text-align: justify">In this section we show that a conjecture similar to Conjecture <a href="#x1-49003r1">4.1<!--tex4ht:ref: conj:3sum --></a> can be proved assuming SETH. This is an interesting example of how we can connect different parameter regimes, since SETH is stated in terms of exponential running times. In general, “scaling” parameters is a powerful technique in the complexity toolkit.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-51001r9"></a> <b>Definition</b> 4.9. </span>The Or-Vector problem: Given two sets <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> of strings of the same length, determine if there is <img src="https://s0.wp.com/latex.php?latex=a%5Cin+A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%5Cin+A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%5Cin+A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a&#92;in A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=b%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b&#92;in B" class="latex" /> such that the bit-wise Or <img src="https://s0.wp.com/latex.php?latex=a%5Cvee+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%5Cvee+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%5Cvee+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a&#92;vee b" class="latex" /> equals the all-one vector.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">The Or-Vector problem is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28n%5E%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(n^{2})" class="latex" />. We can show that a substantial improvement would disprove SETH.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-51002r4"></a> <b>Theorem</b> 4.4. </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BOr-Vector%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%5CRightarrow+%5Ctext+%7BSETH+is+false.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BOr-Vector%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%5CRightarrow+%5Ctext+%7BSETH+is+false.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BOr-Vector%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%5CRightarrow+%5Ctext+%7BSETH+is+false.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Or-Vector}&#92;in &#92;text {SubquadraticTime}&#92;Rightarrow &#92;text {SETH is false.}" class="latex" /></p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>.&nbsp;</span>Divide the variables in two blocks of <img src="https://s0.wp.com/latex.php?latex=v%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v/2" class="latex" /> each. For each assignment to the variables in the first block construct the vector in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{d}" class="latex" /> where bit <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> iff clause <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> is satisfied by the variables in the first block. Call <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> the resulting set of vectors. Let <img src="https://s0.wp.com/latex.php?latex=N%3A%3D2%5E%7Bv%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N%3A%3D2%5E%7Bv%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N%3A%3D2%5E%7Bv%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N:=2^{v/2}" class="latex" /> and note <img src="https://s0.wp.com/latex.php?latex=%7CA%7C%3DN&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CA%7C%3DN&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CA%7C%3DN&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|A|=N" class="latex" />. Do the same for the other block and call the resulting set <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" />.</p>
<p style="text-align: justify">Note that <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> is satisfiable iff <img src="https://s0.wp.com/latex.php?latex=%5Cexists+a%5Cin+A%2Cb%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+a%5Cin+A%2Cb%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+a%5Cin+A%2Cb%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists a&#92;in A,b&#92;in B" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=a%5Cvee+b%3D1%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%5Cvee+b%3D1%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%5Cvee+b%3D1%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a&#92;vee b=1^{d}" class="latex" />.</p>
<p style="text-align: justify">Constructing these sets takes time <img src="https://s0.wp.com/latex.php?latex=Nd%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Nd%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Nd%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Nd^{c}" class="latex" />. If <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BOr-Vector%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B2-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BOr-Vector%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B2-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BOr-Vector%7D%5Cin+%5Ctext+%7BTime%7D%28n%5E%7B2-%5Cepsilon+%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Or-Vector}&#92;in &#92;text {Time}(n^{2-&#92;epsilon })" class="latex" /> for some <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon &gt;0" class="latex" />, we can take <img src="https://s0.wp.com/latex.php?latex=k%3Dc_%7B%5Cepsilon%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k%3Dc_%7B%5Cepsilon%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k%3Dc_%7B%5Cepsilon%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k=c_{&#92;epsilon}" class="latex" /> and rule out SETH. <b>QED</b></p>
</div>
<p style="text-align: justify">Tight hardness results based on SETH have been established for several well-studied problems, including longest-common subsequence <span class="cite">[<a href="conf/focs/AbboudBW15">1</a>]</span> and edit distance <span class="cite">[<a href="journals/siamcomp/BackursI18">5</a>]</span>.</p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">4.5 </span> <a id="x1-520004.5"></a>Search problems</h3>
<p style="text-align: justify">Most of the problems in the previous sections ask about the <em>existence</em> of solutions. For example 3Sat asks about the existence of a satisfying assignment. It is natural to ask about computing such a solution, if it exists. Such non-boolean problems are known as <em>search problems</em>.</p>
<p style="text-align: justify">Next we show that in some cases we can reduce a search problem to the corresponding boolean problem.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-52001r10"></a> <b>Definition</b> 4.10. </span>Search-3Sat is the problem: Given a satisfiable 3CNF formula, output a satisfying assignment.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-52002r5"></a> <b>Theorem</b> 4.5. </span> Search-3Sat reduces to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />. That is: <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {P}&#92;Rightarrow &#92;text {Search-3Sat}&#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>.&nbsp;</span>We construct a satisfying assignment one variable at the time. Given a satisfiable 3CNF, set the first variable to <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> and check if it is still satisfiable with the assumed algorithm for 3Sat. If it is, go to the next variable. If it is not, set the first variable to <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> and go to the next variable. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-52003r7"></a> <b>Exercise</b> 4.7. </span>Show <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BClique%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-Clique%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BClique%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-Clique%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BClique%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-Clique%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Clique}&#92;in &#92;text {P}&#92;Rightarrow &#92;text {Search-Clique}&#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<h4 class="subsectionHead"><span class="titlemark">4.5.1 </span> <a id="x1-530004.5.1"></a>Fastest algorithm for Search-3Sat</h4>
<p style="text-align: justify">A curious fact about many search problems is that we know of an algorithm which is, in an asymptotic sense to be discussed now, essentially the fastest possible algorithm. This algorithm proceeds by simulating every possible program. When a program stops and outputs the answer, we can <em>check it</em> efficiently. Naturally, we can’t just take any program and simulate it until it ends, since it may never end. So we will clock programs, and stop them if they take too long. There is a particular simulation schedule which leads to efficient running times.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-53001r6"></a> <b>Theorem</b> 4.6. </span> <span class="cite">[<a href="#XLevin73">17</a>]</span> There is a RAM <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> such that on input any satisfiable formula <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />:</p>
<p style="text-align: justify">(1) <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> outputs a satisfying assignment, and</p>
<p style="text-align: justify">(2) If there is a RAM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> that on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> outputs a satisfying assignment for <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> steps then <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> stops in <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%2B%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%2B%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%2B%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}t+|x|^{c}" class="latex" /> steps.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">We are taking advantage of the RAM model. On other models it is not known if the dependence on <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> can be linear.</p>
<p style="text-align: justify">
<div class="proof">
<p style="text-align: justify"><span class="head"> <b>Proof</b>.&nbsp;</span>For <img src="https://s0.wp.com/latex.php?latex=i%3D1%2C2%2C%5Cldots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%3D1%2C2%2C%5Cldots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%3D1%2C2%2C%5Cldots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i=1,2,&#92;ldots " class="latex" /> the RAM <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> simulates RAM <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{i}" class="latex" /> steps. <a href="#x1-26006r2">2.2<!--tex4ht:ref: lem-univ-ram --></a> guarantees that for each <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> the simulation takes time <img src="https://s0.wp.com/latex.php?latex=c2%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c2%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c2%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c2^{i}" class="latex" />. If RAM <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> stops and outputs <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> checks in time <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|^{c}" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> is a satisfying assignment. If it is, then <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> outputs <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> and stops. Otherwise it continues.</p>
<p style="text-align: justify">Now let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be as in (2). As before, we work with an enumeration of programs where each program appears infinitely often. Hence we can assume that <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> has a description of length <img src="https://s0.wp.com/latex.php?latex=%5Cell+%3A%3Dc_%7BM%7D%2B%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cell+%3A%3Dc_%7BM%7D%2B%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cell+%3A%3Dc_%7BM%7D%2B%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ell :=c_{M}+&#92;log t" class="latex" />. Thus the simulation will terminate when <img src="https://s0.wp.com/latex.php?latex=i%3D%5Cell+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%3D%5Cell+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%3D%5Cell+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i=&#92;ell " class="latex" />.</p>
<p style="text-align: justify">The time spent by <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> for a fixed <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cle+c%5Ccdot+2%5E%7Bi%7D%2B%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c%5Ccdot+2%5E%7Bi%7D%2B%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c%5Ccdot+2%5E%7Bi%7D%2B%7Cx%7C%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c&#92;cdot 2^{i}+|x|^{c}" class="latex" />. Hence he total running time of <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> is</p>
<div style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+c%5Csum+_%7Bj%3D1%7D%5E%7B%5Cell+%7D%5Cleft+%28c2%5E%7Bj%7D%2B%7Cx%7C%5E%7Bc%7D%5Cright+%29%5Cle+c_%7BM%7D2%5E%7B%5Cell+%7D%2Bc_%7BM%7D%7Cx%7C%5E%7Bc%7D%5Cle+c_%7BM%7D%28t%2B%7Cx%7C%5E%7Bc%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+c%5Csum+_%7Bj%3D1%7D%5E%7B%5Cell+%7D%5Cleft+%28c2%5E%7Bj%7D%2B%7Cx%7C%5E%7Bc%7D%5Cright+%29%5Cle+c_%7BM%7D2%5E%7B%5Cell+%7D%2Bc_%7BM%7D%7Cx%7C%5E%7Bc%7D%5Cle+c_%7BM%7D%28t%2B%7Cx%7C%5E%7Bc%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cle+c%5Csum+_%7Bj%3D1%7D%5E%7B%5Cell+%7D%5Cleft+%28c2%5E%7Bj%7D%2B%7Cx%7C%5E%7Bc%7D%5Cright+%29%5Cle+c_%7BM%7D2%5E%7B%5Cell+%7D%2Bc_%7BM%7D%7Cx%7C%5E%7Bc%7D%5Cle+c_%7BM%7D%28t%2B%7Cx%7C%5E%7Bc%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;le c&#92;sum _{j=1}^{&#92;ell }&#92;left (c2^{j}+|x|^{c}&#92;right )&#92;le c_{M}2^{&#92;ell }+c_{M}|x|^{c}&#92;le c_{M}(t+|x|^{c}). &#92;end{aligned}" class="latex" /></div>
<p><b>QED</b></p>
</div>
<p style="text-align: justify">This result nicely illustrates how “constant factors” can lead to impractical results because, of course, the problem is that the constant in front of <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is enormous. Specifically, it is exponential in the size of the program, see Problem <a href="#x1-55005r5">4.5<!--tex4ht:ref: prob:universal-search-program-enumeration-bottleneck --></a>.</p>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">4.6 </span> <a id="x1-540004.6"></a>Gap-SAT: The PCP theorem</h3>
<table class="quotation" cellspacing="15" cellpadding="0" border="0">
<tbody>
<tr>
<td>
<div class="quotation">
<p style="text-align: justify">“Furthermore, most problem reductions do not create or preserve such gaps. There would appear to be a last resort, namely to <em>create </em>such a gap in the generic reduction [C]. Unfortunately, this also seems doubtful. The intuitive reason is that computation is an inherently unstable, non-robust mathematical object, in the sense that it can be turned from non-accepting by changes that would be insignificant in any reasonable metric – say, by flipping a single state to accepting.” <span class="cite">[<a href="journals/jcss/PapadimitriouY91">19</a>]</span></p>
</div>
</td>
</tr>
</tbody>
</table>
<p>One of the most exciting, consequential, and technical developments in complexity theory of the last few decades has been the development of reductions that create <em>gaps.</em></p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-54001r11"></a> <b>Definition</b> 4.11. </span><img src="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma " class="latex" />-Gap-3Sat is the 3Sat problem restricted to input formulas <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> that are either satisfiable or such that any assignment satisfies at most a <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma " class="latex" /> fraction of clauses.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Note that 3Sat is equivalent to <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma " class="latex" />-Gap-3Sat for <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3D1-1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+%3D1-1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+%3D1-1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma =1-1/n" class="latex" />, since a formula of size <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> has at most <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> clauses. At first sight it is unclear how to connect the problems when <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma " class="latex" /> is much smaller. But in fact it is possible to obtain a constant <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma " class="latex" />. This result is known as the PCP theorem, where PCP stands for probabilistically-checkable-proofs. The connection to proofs will be discussed in Chapter ??.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-54002r7"></a> <b>Theorem</b> 4.7. </span><span class="cite">[<a href="#XAroraLuMoSuSz98">4</a>]</span> [PCP] There is <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3C1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+%3C1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+%3C1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma &lt;1" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+%5Ctext+%7B-Gap-3Sat%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+%5Ctext+%7B-Gap-3Sat%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+%5Ctext+%7B-Gap-3Sat%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma &#92;text {-Gap-3Sat}&#92;in &#92;text {P}&#92;Rightarrow &#92;text {3Sat}&#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Similar results can be established for other problems such as 3Color, but the reductions in the previous section don’t preserve gaps and can’t be immediately applied.</p>
<p style="text-align: justify">A major application of the PCP theorem is in <em>inapproximability</em> results. A typical optimization problem is Max-3Sat.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-54003r12"></a> <b>Definition</b> 4.12. </span>The Max-3Sat problem: given a 3CNF formula, find a satisfying assignment that satisfies the maximum number of clauses.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">Solving 3Sat reduces to Max-3Sat (in Chapter ?? we will give a reverse reduction as well). But we can ask for <em><img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" />-approximating</em> Max-3Sat, that is, computing an assignment that satisfies a number of clauses that is at least a <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" /> fraction of the maximum possible clauses that can be satisfied.</p>
<p style="text-align: justify">The PCP Theorem <a href="#x1-54002r7">4.7<!--tex4ht:ref: thm:-=00005BPCP=00005D --></a> implies that 3Sat reduces to <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+-&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+-&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+-&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta -" class="latex" />approximating Max-3Sat, for some constant <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3C1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+%3C1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+%3C1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta &lt;1" class="latex" />.</p>
<p style="text-align: justify">It has been a major line of research to obtain tight approximation factors <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" /> for a variety of problems. For example, 3Sat reduces to <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;beta " class="latex" />-approximating Max-3Sat for any <img src="https://s0.wp.com/latex.php?latex=%5Cb+%3E7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cb+%3E7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cb+%3E7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;b &gt;7/8" class="latex" />. This constant is tight because a random uniform assignment to the variables satisfies each clause with probability <img src="https://s0.wp.com/latex.php?latex=7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="7/8" class="latex" /> and hence expects to satisfy a <img src="https://s0.wp.com/latex.php?latex=7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=7%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="7/8" class="latex" /> fraction of the clauses.</p>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-54004r8"></a> <b>Exercise</b> 4.8. </span>Turn this latter observation in an efficient randomized algorithm with an approximation factor <img src="https://s0.wp.com/latex.php?latex=7%2F8-o%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=7%2F8-o%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=7%2F8-o%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="7/8-o(1)" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<h3 class="sectionHead"><span class="titlemark">4.7 </span> <a id="x1-550004.7"></a>Problems</h3>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-55001r1"></a> <b>Problem</b> 4.1. </span>Reduce 3Sat to the PIT problem (Definition <a href="#x1-32001r8">2.8<!--tex4ht:ref: def:arithmetic-circuit-PIT --></a>) over the field with two elements.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-55002r2"></a> <b>Problem</b> 4.2. </span>Prove that 3Sat is not <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5E%7B1.99%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5E%7B1.99%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTM-Time%7D%28n%5E%7B1.99%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TM-Time}(n^{1.99})" class="latex" />. (Hint: Consider the <em>Padded-Palindromes </em>problem which is like palindromes except the input is divided in blocks of <img src="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log n" class="latex" /> bits, and only the first bit of each block may be non-zero. (1) Prove a time lower bound for Padded-Palindromes by explaining what modifications are needed to the proof of Theorem <a href="#x1-38001r1">3.1<!--tex4ht:ref: thm:TM-pal-requires-quadratic --></a>. (2) Give a suitable reduction from Padded-Palindromes to 3Sat.)</p>
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-55003r3"></a> <b>Problem</b> 4.3. </span>Show that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Color%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-3Color%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Color%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-3Color%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Color%7D%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BSearch-3Color%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Color}&#92;in &#92;text {P}&#92;Rightarrow &#92;text {Search-3Color}&#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-55004r4"></a> <b>Problem</b> 4.4. </span>Give an encoding of 3Sat so that the reduction to 3Color in section&nbsp;º<a href="#x1-500004.3">4.3<!--tex4ht:ref: sec:Reductions-from-3Sat --></a> can be computed, for any input length, by a <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" />-local map (in particular, a circuit of constant depth).</p>
<p style="text-align: justify">
</div>
<div class="newtheorem">
<p style="text-align: justify"><span class="head"> <a id="x1-55005r5"></a> <b>Problem</b> 4.5. </span>Suppose there exists <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a" class="latex" /> such that Theorem <a href="#x1-53001r6">4.6<!--tex4ht:ref: thm:univeral-search --></a> holds with the running time of <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="U" class="latex" /> replaced with <img src="https://s0.wp.com/latex.php?latex=%28%7CM%7C%5Ccdot+t%5Ccdot+%7Cx%7C%29%5E%7Ba%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%7CM%7C%5Ccdot+t%5Ccdot+%7Cx%7C%29%5E%7Ba%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%7CM%7C%5Ccdot+t%5Ccdot+%7Cx%7C%29%5E%7Ba%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(|M|&#92;cdot t&#92;cdot |x|)^{a}" class="latex" />. (That is, the dependence on the program description improved to polynomial, and we allow even weaker dependence on <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />.) Prove that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align: justify">
</div>
<p style="text-align: justify">
<h3 class="likesectionHead"><a id="x1-560004.7"></a>References</h3>
<p style="text-align: justify">
<div class="thebibliography">
<p class="bibitem"><span class="biblabel"> [1]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/focs/AbboudBW15"></a>Amir Abboud, Arturs Backurs, and Virginia&nbsp;Vassilevska Williams. Tight hardness results for LCS and other sequence similarity measures. In Venkatesan Guruswami, editor, IEEE 56th Annual Symposium on Foundations of Computer Science, FOCS 2015, Berkeley, CA, USA, 17-20 October, 2015, pages 59–78. IEEE Computer Society, 2015.</p>
<p class="bibitem"><span class="biblabel"> [2]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAdleman78"></a>Leonard Adleman. Two theorems on random polynomial time. In 19th IEEE Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 75–83. 1978.</p>
<p class="bibitem"><span class="biblabel"> [3]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/AngluinV79"></a>Dana Angluin and Leslie&nbsp;G. Valiant. Fast probabilistic algorithms for hamiltonian circuits and matchings. J. Comput. Syst. Sci., 18(2):155–193, 1979.</p>
<p class="bibitem"><span class="biblabel"> [4]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAroraLuMoSuSz98"></a>Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy. Proof verification and the hardness of approximation problems. J.&nbsp;of the ACM, 45(3):501–555, May 1998.</p>
<p class="bibitem"><span class="biblabel"> [5]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/BackursI18"></a>Arturs Backurs and Piotr Indyk. Edit distance cannot be computed in strongly subquadratic time (unless SETH is false). SIAM J. Comput., 47(3):1087–1097, 2018.</p>
<p class="bibitem"><span class="biblabel"> [6]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGajentaanO95"></a>Anka Gajentaan and Mark&nbsp;H. Overmars. On a class of <img src="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="{O}(n^2)" class="latex" /> problems in computational geometry. Comput. Geom., 5:165–185, 1995.</p>
<p class="bibitem"><span class="biblabel"> [7]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGareyJ79"></a>M.&nbsp;R. Garey and David&nbsp;S. Johnson. Computers and Intractability: A Guide to the Theory of NP-Completeness. W. H. Freeman, 1979.</p>
<p class="bibitem"><span class="biblabel"> [8]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR1549939"></a>K.&nbsp;G÷del. ▄ber formal unentscheidbare sΣtze der Principia Mathematica und verwandter systeme I. Monatsh. Math. Phys., 38, 1931.</p>
<p class="bibitem"><span class="biblabel"> [9]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGoldreich08Complexity"></a>Oded Goldreich. Computational Complexity: A Conceptual Perspective. Cambridge University Press, 2008.</p>
<p class="bibitem"><span class="biblabel"> [10]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="X10.4007/annals.2021.193.2.4"></a>David Harvey and Joris van&nbsp;der Hoeven. Integer multiplication in time <img src="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(n&#92;mathrm {log}&#92;, n)" class="latex" />. Annals of Mathematics, 193(2):563 – 617, 2021.</p>
<p class="bibitem"><span class="biblabel"> [11]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F.&nbsp;C. Hennie. One-tape, off-line turing machine computations. Information and Control, 8(6):553–578, 1965.</p>
<p class="bibitem"><span class="biblabel"> [12]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XHennieS66"></a>Fred Hennie and Richard Stearns. Two-tape simulation of multitape turing machines. J.&nbsp;of the ACM, 13:533–546, October 1966.</p>
<p class="bibitem"><span class="biblabel"> [13]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIP99"></a>Russell Impagliazzo and Ramamohan Paturi. The complexity of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-sat. In IEEE Conf.&nbsp;on Computational Complexity (CCC), pages 237–, 1999.</p>
<p class="bibitem"><span class="biblabel"> [14]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIPZ01"></a>Russell Impagliazzo, Ramamohan Paturi, and Francis Zane. Which problems have strongly exponential complexity? J. Computer &amp; Systems Sciences, 63(4):512–530, Dec 2001.</p>
<p class="bibitem"><span class="biblabel"> [15]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImW97"></a>Russell Impagliazzo and Avi Wigderson. <img src="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathit {P} = &#92;mathit {BPP}" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E" class="latex" /> requires exponential circuits: Derandomizing the XOR lemma. In 29th ACM Symp.&nbsp;on the Theory of Computing (STOC), pages 220–229. ACM, 1997.</p>
<p class="bibitem"><span class="biblabel"> [16]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi. On the structure of one-tape nondeterministic turing machine time hierarchy. Theor. Comput. Sci., 40:175–193, 1985.</p>
<p class="bibitem"><span class="biblabel"> [17]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLevin73"></a>Leonid&nbsp;A. Levin. Universal sequential search problems. Problemy Peredachi Informatsii, 9(3):115–116, 1973.</p>
<p class="bibitem"><span class="biblabel"> [18]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLupanov58"></a>O.&nbsp;B. Lupanov. A method of circuit synthesis. Izv. VUZ Radiofiz., 1:120–140, 1958.</p>
<p class="bibitem"><span class="biblabel"> [19]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/PapadimitriouY91"></a>Christos&nbsp;H. Papadimitriou and Mihalis Yannakakis. Optimization, approximation, and complexity classes. J. Comput. Syst. Sci., 43(3):425–440, 1991.</p>
<p class="bibitem"><span class="biblabel"> [20]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPippengerF79"></a>Nicholas Pippenger and Michael&nbsp;J. Fischer. Relations among complexity measures. J.&nbsp;of the ACM, 26(2):361–381, 1979.</p>
<p class="bibitem"><span class="biblabel"> [21]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Schonhage80"></a>Arnold Sch÷nhage. Storage modification machines. SIAM J. Comput., 9(3):490–508, 1980.</p>
<p class="bibitem"><span class="biblabel"> [22]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR29860"></a>Claude&nbsp;E. Shannon. The synthesis of two-terminal switching circuits. Bell System Tech. J., 28:59–98, 1949.</p>
<p class="bibitem"><span class="biblabel"> [23]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSho90"></a>Victor Shoup. New algorithms for finding irreducible polynomials over finite fields. Mathematics of Computation, 54(189):435–447, 1990.</p>
<p class="bibitem"><span class="biblabel"> [24]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert&nbsp;R. Meyer. Cosmological lower bound on the circuit complexity of a small problem in logic. J. ACM, 49(6):753–784, 2002.</p>
<p class="bibitem"><span class="biblabel"> [25]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/x/Turing37"></a>Alan&nbsp;M. Turing. On computable numbers, with an application to the entscheidungsproblem. Proc. London Math. Soc., s2-42(1):230–265, 1937.</p>
<p class="bibitem"><span class="biblabel"> [26]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViola-xxx"></a>Emanuele Viola. Reducing 3XOR to listing triangles, an exposition. Available at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2011.</p>
<p class="bibitem"><span class="biblabel"> [27]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-tm"></a>Emanuele Viola. Pseudorandom bits and lower bounds for randomized turing machines. Theory of Computing, 18(10):1–12, 2022.</p>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T14:06:22Z">Thursday, February 09 2023, 14:06</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04108'>Triplet Loss-less Center Loss Sampling Strategies in Facial Expression Recognition Scenarios</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hossein Rajoli, Fatemeh Lotfi, Adham Atyabi, Fatemeh Afghah</p><p>Facial expressions convey massive information and play a crucial role in
emotional expression. Deep neural network (DNN) accompanied by deep metric
learning (DML) techniques boost the discriminative ability of the model in
facial expression recognition (FER) applications. DNN, equipped with only
classification loss functions such as Cross-Entropy cannot compact intra-class
feature variation or separate inter-class feature distance as well as when it
gets fortified by a DML supporting loss item. The triplet center loss (TCL)
function is applied on all dimensions of the sample's embedding in the
embedding space. In our work, we developed three strategies: fully-synthesized,
semi-synthesized, and prediction-based negative sample selection strategies. To
achieve better results, we introduce a selective attention module that provides
a combination of pixel-wise and element-wise attention coefficients using
high-semantic deep features of input samples. We evaluated the proposed method
on the RAF-DB, a highly imbalanced dataset. The experimental results reveal
significant improvements in comparison to the baseline for all three negative
sample selection strategies.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rajoli_H/0/1/0/all/0/1">Hossein Rajoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Lotfi_F/0/1/0/all/0/1">Fatemeh Lotfi</a>, <a href="http://arxiv.org/find/cs/1/au:+Atyabi_A/0/1/0/all/0/1">Adham Atyabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Afghah_F/0/1/0/all/0/1">Fatemeh Afghah</a></p><p>Facial expressions convey massive information and play a crucial role in
emotional expression. Deep neural network (DNN) accompanied by deep metric
learning (DML) techniques boost the discriminative ability of the model in
facial expression recognition (FER) applications. DNN, equipped with only
classification loss functions such as Cross-Entropy cannot compact intra-class
feature variation or separate inter-class feature distance as well as when it
gets fortified by a DML supporting loss item. The triplet center loss (TCL)
function is applied on all dimensions of the sample's embedding in the
embedding space. In our work, we developed three strategies: fully-synthesized,
semi-synthesized, and prediction-based negative sample selection strategies. To
achieve better results, we introduce a selective attention module that provides
a combination of pixel-wise and element-wise attention coefficients using
high-semantic deep features of input samples. We evaluated the proposed method
on the RAF-DB, a highly imbalanced dataset. The experimental results reveal
significant improvements in comparison to the baseline for all three negative
sample selection strategies.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04162'>Optimal Sufficient Requirements on the Embedded Ising Problem in Polynomial Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Elisabeth Lobe, Volker Kaibel</p><p>One of the central applications for quantum annealers is to find the
solutions of Ising problems. Suitable Ising problems, however, need to be
formulated such that they, on the one hand, respect the specific restrictions
of the hardware and, on the other hand, represent the original problems which
shall actually be solved. We evaluate sufficient requirements on such an
embedded Ising problem analytically and transform them into a linear
optimization problem. With an objective function aiming to minimize the maximal
absolute problem parameter, the precision issues of the annealers are
addressed. Due to the redundancy of several constraints, we can show that the
formally exponentially large optimization problem can be reduced and finally
solved in polynomial time for the standard embedding setting where the embedded
vertices induce trees. This allows to formulate provably equivalent embedded
Ising problems in a practical setup.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Lobe_E/0/1/0/all/0/1">Elisabeth Lobe</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kaibel_V/0/1/0/all/0/1">Volker Kaibel</a></p><p>One of the central applications for quantum annealers is to find the
solutions of Ising problems. Suitable Ising problems, however, need to be
formulated such that they, on the one hand, respect the specific restrictions
of the hardware and, on the other hand, represent the original problems which
shall actually be solved. We evaluate sufficient requirements on such an
embedded Ising problem analytically and transform them into a linear
optimization problem. With an objective function aiming to minimize the maximal
absolute problem parameter, the precision issues of the annealers are
addressed. Due to the redundancy of several constraints, we can show that the
formally exponentially large optimization problem can be reduced and finally
solved in polynomial time for the standard embedding setting where the embedded
vertices induce trees. This allows to formulate provably equivalent embedded
Ising problems in a practical setup.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.04218'>On the Computational Complexity of Ethics: Moral Tractability for Minds and Machines</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jakob Stenseke</p><p>Why should moral philosophers, moral psychologists, and machine ethicists
care about computational complexity? Debates on whether artificial intelligence
(AI) can or should be used to solve problems in ethical domains have mainly
been driven by what AI can or cannot do in terms of human capacities. In this
paper, we tackle the problem from the other end by exploring what kind of moral
machines are possible based on what computational systems can or cannot do. To
do so, we analyze normative ethics through the lens of computational
complexity. First, we introduce computational complexity for the uninitiated
reader and discuss how the complexity of ethical problems can be framed within
Marr's three levels of analysis. We then study a range of ethical problems
based on consequentialism, deontology, and virtue ethics, with the aim of
elucidating the complexity associated with the problems themselves (e.g., due
to combinatorics, uncertainty, strategic dynamics), the computational methods
employed (e.g., probability, logic, learning), and the available resources
(e.g., time, knowledge, learning). The results indicate that most problems the
normative frameworks pose lead to tractability issues in every category
analyzed. Our investigation also provides several insights about the
computational nature of normative ethics, including the differences between
rule- and outcome-based moral strategies, and the implementation-variance with
regard to moral resources. We then discuss the consequences complexity results
have for the prospect of moral machines in virtue of the trade-off between
optimality and efficiency. Finally, we elucidate how computational complexity
can be used to inform both philosophical and cognitive-psychological research
on human morality by advancing the Moral Tractability Thesis (MTT).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Stenseke_J/0/1/0/all/0/1">Jakob Stenseke</a></p><p>Why should moral philosophers, moral psychologists, and machine ethicists
care about computational complexity? Debates on whether artificial intelligence
(AI) can or should be used to solve problems in ethical domains have mainly
been driven by what AI can or cannot do in terms of human capacities. In this
paper, we tackle the problem from the other end by exploring what kind of moral
machines are possible based on what computational systems can or cannot do. To
do so, we analyze normative ethics through the lens of computational
complexity. First, we introduce computational complexity for the uninitiated
reader and discuss how the complexity of ethical problems can be framed within
Marr's three levels of analysis. We then study a range of ethical problems
based on consequentialism, deontology, and virtue ethics, with the aim of
elucidating the complexity associated with the problems themselves (e.g., due
to combinatorics, uncertainty, strategic dynamics), the computational methods
employed (e.g., probability, logic, learning), and the available resources
(e.g., time, knowledge, learning). The results indicate that most problems the
normative frameworks pose lead to tractability issues in every category
analyzed. Our investigation also provides several insights about the
computational nature of normative ethics, including the differences between
rule- and outcome-based moral strategies, and the implementation-variance with
regard to moral resources. We then discuss the consequences complexity results
have for the prospect of moral machines in virtue of the trade-off between
optimality and efficiency. Finally, we elucidate how computational complexity
can be used to inform both philosophical and cognitive-psychological research
on human morality by advancing the Moral Tractability Thesis (MTT).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03771'>A generalization of the persistent Laplacian to simplicial maps</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aziz Burak G&#xfc;len, Facundo M&#xe9;moli, Zhengchao Wan, Yusu Wang</p><p>The graph Laplacian is a fundamental object in the analysis of and
optimization on graphs. This operator can be extended to a simplicial complex
$K$ and therefore offers a way to perform ``signal processing" on
$p$-(co)chains of $K$. Recently, the concept of persistent Laplacian was
proposed and studied for a pair of simplicial complexes $K\hookrightarrow L$
connected by an inclusion relation, further broadening the use of Laplace-based
operators.
</p>
<p>In this paper, we expand the scope of the persistent Laplacian by
generalizing it to a pair of simplicial complexes connected by a simplicial map
$f: K \to L$. Such simplicial map setting arises frequently, e.g., when
relating a coarsened simplicial representation with an original representation,
or the case when the two simplicial complexes are spanned by different point
sets i.e. cases in which it does not hold that $K\subset L$. However, the
simplicial map setting is more challenging than the inclusion setting since the
underlying algebraic structure is more complicated.
</p>
<p>We present a natural generalization of the persistent Laplacian to the
simplicial setting. To shed insight on the structure behind it, as well as to
develop an algorithm to compute it, we exploit the relationship between the
persistent Laplacian and the Schur complement of a matrix. A critical step is
to view the Schur complement as a functorial way of restricting a self-adjoint
PSD operator to a given subspace. As a consequence, we prove that persistent
Betti numbers of a simplicial map can be recovered by persistent Laplacians. We
then propose an algorithm for finding the matrix representations of persistent
Laplacians which in turn yields a new algorithm for computing persistent Betti
numbers of a simplicial map. Finally, we study the persistent Laplacian on
simplicial towers under simplicial maps and establish monotonicity results for
their eigenvalues.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gulen_A/0/1/0/all/0/1">Aziz Burak G&#xfc;len</a>, <a href="http://arxiv.org/find/math/1/au:+Memoli_F/0/1/0/all/0/1">Facundo M&#xe9;moli</a>, <a href="http://arxiv.org/find/math/1/au:+Wan_Z/0/1/0/all/0/1">Zhengchao Wan</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_Y/0/1/0/all/0/1">Yusu Wang</a></p><p>The graph Laplacian is a fundamental object in the analysis of and
optimization on graphs. This operator can be extended to a simplicial complex
$K$ and therefore offers a way to perform ``signal processing" on
$p$-(co)chains of $K$. Recently, the concept of persistent Laplacian was
proposed and studied for a pair of simplicial complexes $K\hookrightarrow L$
connected by an inclusion relation, further broadening the use of Laplace-based
operators.
</p>
<p>In this paper, we expand the scope of the persistent Laplacian by
generalizing it to a pair of simplicial complexes connected by a simplicial map
$f: K \to L$. Such simplicial map setting arises frequently, e.g., when
relating a coarsened simplicial representation with an original representation,
or the case when the two simplicial complexes are spanned by different point
sets i.e. cases in which it does not hold that $K\subset L$. However, the
simplicial map setting is more challenging than the inclusion setting since the
underlying algebraic structure is more complicated.
</p>
<p>We present a natural generalization of the persistent Laplacian to the
simplicial setting. To shed insight on the structure behind it, as well as to
develop an algorithm to compute it, we exploit the relationship between the
persistent Laplacian and the Schur complement of a matrix. A critical step is
to view the Schur complement as a functorial way of restricting a self-adjoint
PSD operator to a given subspace. As a consequence, we prove that persistent
Betti numbers of a simplicial map can be recovered by persistent Laplacians. We
then propose an algorithm for finding the matrix representations of persistent
Laplacians which in turn yields a new algorithm for computing persistent Betti
numbers of a simplicial map. Finally, we study the persistent Laplacian on
simplicial towers under simplicial maps and establish monotonicity results for
their eigenvalues.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.03690'>Storing a Trie with Compact and Predictable Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuxuan Dong</p><p>This paper proposed a storing approach for trie structures, called Coordinate
Hash Trie. For a trie with $n$ nodes and an alphabet with size $m$, the
execution time of finding, inserting and deleting a child node, is $O(1)$ for
the average case, $O(m)$ for the worst case. The space used by this approach is
$O(n)$, unrelated to $m$. The constant of space consumption is predictable,
with no need for reallocation or resizing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yuxuan Dong</a></p><p>This paper proposed a storing approach for trie structures, called Coordinate
Hash Trie. For a trie with $n$ nodes and an alphabet with size $m$, the
execution time of finding, inserting and deleting a child node, is $O(1)$ for
the average case, $O(m)$ for the worst case. The space used by this approach is
$O(n)$, unrelated to $m$. The constant of space consumption is predictable,
with no need for reallocation or resizing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-09T01:30:00Z">Thursday, February 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
