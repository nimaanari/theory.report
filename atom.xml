<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Theory of Computing Report</title>
  <link rel="self" href=""/>
  <link href=""/>
  <id></id>
  <updated></updated>
  <generator uri="http://feedreader.github.io/">Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]</generator>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-123 |  The Approximate Degree of DNF and CNF Formulas | 

	Alexander A. Sherstov</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/123"/>
    <id>https://eccc.weizmann.ac.il/report/2022/123</id>
    <updated>2022-09-05T04:49:37+00:00</updated>
    <content type="html" xml:lang="en">
    The approximate degree of a Boolean function $f\colon\{0,1\}^n\to\{0,1\}$ is the minimum degree of a real polynomial $p$ that approximates $f$ pointwise: $|f(x)-p(x)|\leq1/3$ for all $x\in\{0,1\}^n.$ For every $\delta&amp;gt;0,$ we construct CNF and DNF formulas of polynomial size with approximate degree $\Omega(n^{1-\delta}),$ essentially matching the trivial upper bound of $n.$ This improves polynomially on previous lower bounds and fully resolves the approximate degree of constant-depth circuits ($\text{AC}^{0}$), a question that has seen extensive research over the past 10 years. Prior to our work, an $\Omega(n^{1-\delta})$ lower bound was known only for $\text{AC}^{0}$ circuits of depth that grows with $1/\delta$ (Bun and Thaler, FOCS 2017). Furthermore, the CNF and DNF formulas that we construct are the simplest possible in that they have constant width. Our result holds even for one-sided approximation: for any $\delta&amp;gt;0$, we construct a polynomial-size constant-width CNF formula with one-sided approximate degree $\Omega(n^{1-\delta})$.

Our work has the following consequences.

(i) We essentially settle the communication complexity of $\text{AC}^{0}$ circuits in the bounded-error quantum model, $k$-party number-on-the-forehead randomized model, and $k$-party number-on-the-forehead nondeterministic model: we prove that for every $\delta&amp;gt;0$, these models require $\Omega(n^{1-\delta})$, $\Omega(n/4^{k}k^{2})^{1-\delta}$, and $\Omega(n/4^{k}k^{2})^{1-\delta}$, respectively, bits of communication even for polynomial-size constant-width CNF formulas.

(ii) In particular, we show that the multiparty communication class $\text{coNP}_{k}$ can be separated essentially optimally from $\text{NP}_{k}$ and $\text{BPP}_{k}$ by a particularly simple function, a polynomial-size constant-width CNF formula.

(iii) We give an essentially tight separation, of $O(1)$ versus $\Omega(n^{1-\delta})$, for the one-sided versus two-sided approximate degree of a function; and $O(1)$ versus $\Omega(n^{1-\delta})$ for the one-sided approximate degree of a function $f$ versus its negation $\neg f$.

Our proof departs significantly from previous approaches and contributes a novel, number-theoretic method for amplifying approximate degree.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Richard Lipton: Legal Complexity</title>
    <link href="https://rjlipton.wpcomstaging.com/2022/09/04/legal-complexity/"/>
    <id>https://rjlipton.wpcomstaging.com/?p=20362</id>
    <updated>2022-09-05T03:53:23+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;
&lt;font color=&quot;#0044cc&quot;&gt;&lt;br /&gt;
&lt;em&gt;Formal logical methods may be needed to represent the Donald Trump documents case&lt;/em&gt;&lt;br /&gt;
&lt;font color=&quot;#000000&quot;&gt;&lt;/p&gt;
&lt;table class=&quot;image alignright&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2022/09/04/legal-complexity/monicapalmirani/&quot; rel=&quot;attachment wp-att-20364&quot;&gt;&lt;img data-attachment-id=&quot;20364&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2022/09/04/legal-complexity/monicapalmirani/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/MonicaPalmirani.jpg?fit=133%2C193&amp;amp;ssl=1&quot; data-orig-size=&quot;133,193&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;1&amp;quot;}&quot; data-image-title=&quot;MonicaPalmirani&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/MonicaPalmirani.jpg?fit=133%2C193&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/MonicaPalmirani.jpg?fit=133%2C193&amp;amp;ssl=1&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/MonicaPalmirani.jpg?resize=87%2C127&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;87&quot; height=&quot;127&quot; class=&quot;alignright wp-image-20364&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;caption alignright&quot;&gt;&lt;font size=&quot;-2&quot;&gt;&lt;a href=&quot;https://www.unibo.it/sitoweb/monica.palmirani/cv-en&quot;&gt;her page&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;
Monica Palmirani is a &lt;a href=&quot;https://www.unibo.it/sitoweb/monica.palmirani/cv-en&quot;&gt;Professor&lt;/a&gt; of Computer Science and Law at the University of Bologna in Italy. She is one of the &lt;a href=&quot;http://www.aicol.eu/?page_id=8&quot;&gt;Program Chairs&lt;/a&gt; of the 2021-2022 &lt;a href=&quot;http://www.aicol.eu/&quot;&gt;AICOL&lt;/a&gt; conference: Artificial Intelligence Approaches to the Complexity of Legal Systems.&lt;/p&gt;
&lt;p&gt;
Today Ken and I discuss how logical methods may be used to model complex legal cases.&lt;/p&gt;
&lt;p&gt;
We recently &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2022/07/18/complexity-2022/&quot;&gt;noted&lt;/a&gt; that the principal annual hand-weaving conference shares the moniker &amp;#8220;Complexity 2022&amp;#8221; with one in our field. We were being lighthearted, but here the use of &amp;#8220;complexity&amp;#8221; is seriously aligned with ours. Consider a recent &lt;a href=&quot;https://ebooks.iospress.nl/volumearticle/58532&quot;&gt;paper&lt;/a&gt; by Palmirani with three colleagues at Bologna, titled &amp;#8220;Hybrid AI Framework for Legal Analysis of the EU Legislation Corrigenda.&amp;#8221; It defines a taxonomy for correction rules exemplified by:&lt;/p&gt;
&lt;p&gt;
&lt;FONT SIZE=&quot;-1&quot;&gt;&lt;br /&gt;
&lt;CODE&gt;&lt;br /&gt;
On page 257, point (b) of the first paragraph of Article 112: for:&lt;br /&gt;
&amp;#8216;(b) Article 10 and points (a) and (b) of Article 12(1) of Directive 98/79/EC, and …&amp;#8217;,&lt;br /&gt;
read&lt;br /&gt;
&amp;#8216;(b) Article 10, points (a) and (b) of Article 12(1) and Article 15(5) of Directive 98/79/EC, and &amp;#8230;&amp;#8217;&lt;br /&gt;
&lt;/CODE&gt;&lt;br /&gt;
&lt;/FONT&gt;&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
This is minute stuff, yet so voluminous that management systems are needed. One of their main results is that the corpus of previously made corrections involve far higher Levenstein edit distance than their rules identify as needed. &lt;/p&gt;
&lt;p&gt;
The newly-prominent Donald Trump documents case involves matters just as voluminous and much less minute. We have written about systems of logic applied to real-world reasoning on several prior occasions. This one brings multiple taxonomies: of levels of secrecy, of presidential powers, of security mandates, of grades of offense to applicable laws. There is a timeline with critical junctures. An AI system, at least of the knowledge-representation kind, may be needed just to keep it all straight.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Secrets &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
We&amp;#8217;ll begin with rules governing secrecy. I once was a keeper of secrets when I consulted for the government during the height of the Cold War. This does not allow me to say anything about details on any secrets we kept. But it does, I feel, allow me to remark on the keeping of secrets in general. &lt;/p&gt;
&lt;p&gt;
The issue is whether or not Trump violated the law in keeping boxes of classified material at his home at Mar-A-Lago. My understanding of the situation is this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
Trump kept many boxes of classified material at his home at Mar-a-Lago. This was after he left being the President. &lt;/p&gt;
&lt;li&gt;
The FBI made a legal request to a Federal judge to get the boxes from there recently. &lt;/p&gt;
&lt;li&gt;
The judge allowed this and the FBI removed the boxes on August 8, 2022. &lt;/p&gt;
&lt;li&gt;
The FBI request was later partially released to us after being blacked out. Here is the &lt;a href=&quot;https://apps.npr.org/documents/document.html?id=22267188-mar-a-lago-affi&quot;&gt;official copy&lt;/a&gt;.
&lt;/ol&gt;
&lt;p&gt;
The taxonomy of classification given in the FBI affidavit (see pages 4&amp;#8211;5, points 11&amp;#8211;16 for full definitions) is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
Sensitive Compartmented Information (SCI). &lt;/p&gt;
&lt;li&gt;
Special Intelligence (SI), described as &amp;#8220;an SCI control system.&amp;#8221; &lt;/p&gt;
&lt;li&gt;
HUMINT Control System (HCS). &lt;/p&gt;
&lt;li&gt;
Foreign Intelligence Surveillance Act (FISA). &lt;/p&gt;
&lt;li&gt;
Not Releasable to Foreign Nationals (NOFORN). &lt;/p&gt;
&lt;li&gt;
Originator Controlled (ORCON).
&lt;/ol&gt;
&lt;p&gt;
Do Trump&amp;#8217;s actions violate the law? Do they violate any reasonable rule of keeping secrets? Here is an example of the kind of logical modeling we imagine toward answering these questions. ORCON is defined as &amp;#8220;dissemination beyond pre-approved U.S. entities requires originator approval.&amp;#8221; This suggests asking:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Under what circumstances does de-classifying a document marked ORCON without approval of its originator constitute a violation? &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
The answer may depend on the timeline with regard to Trump&amp;#8217;s powers in office, prerogatives after leaving office, and the actions by the Department of Justice and the FBI. Let&amp;#8217;s take a look at that next.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Timeline and Key Dates &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Among various constructions of the timeline, &lt;a href=&quot;https://terikanefield.com/timelinestolendocs/&quot;&gt;this&lt;/a&gt; by the lawyer and author Teri Kanefield also notes the secrecy levels. &lt;/p&gt;
&lt;p&gt;
Let&amp;#8217;s look at the time sequence. The material was kept by Trump at Mar-a-Lago. Then it was removed on August 8, 2022 by the FBI. What Kanefield calls &amp;#8220;Phase 3&amp;#8221; is entirely this key date. &lt;/p&gt;
&lt;p&gt;
One logical inference is that the only time that any secrets could have been violated is from when Trump had the material until August 8, 2022. Since he did not have the material after August 8, it seem safe to say that he could not have compromised the material after that. Note: there seems to be no claim that he &lt;em&gt;made private copies&lt;/em&gt; of the material before the key date, so the time until August 8, 2022, is the only time in question.&lt;/p&gt;
&lt;p&gt;
The instantly-famous &lt;a href=&quot;https://www.npr.org/2022/09/01/1120323225/why-the-dojs-photo-of-top-secret-documents-held-by-trump-matters&quot;&gt;photo&lt;/a&gt; of materials recovered in the search both shows some of the classified designations listed above and hints that the timeline mixes with Trump&amp;#8217;s handling of his own mementoes:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2022/09/04/legal-complexity/trumpdocumentsphoto/&quot; rel=&quot;attachment wp-att-20366&quot;&gt;&lt;img data-attachment-id=&quot;20366&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2022/09/04/legal-complexity/trumpdocumentsphoto/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/TrumpDocumentsPhoto.jpg?fit=745%2C561&amp;amp;ssl=1&quot; data-orig-size=&quot;745,561&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;KWRegan&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;1662247874&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;TrumpDocumentsPhoto&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/TrumpDocumentsPhoto.jpg?fit=300%2C226&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/TrumpDocumentsPhoto.jpg?fit=600%2C452&amp;amp;ssl=1&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/TrumpDocumentsPhoto.jpg?resize=372%2C280&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;372&quot; height=&quot;280&quot; class=&quot;aligncenter wp-image-20366&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/TrumpDocumentsPhoto.jpg?w=745&amp;amp;ssl=1 745w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/TrumpDocumentsPhoto.jpg?resize=300%2C226&amp;amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/TrumpDocumentsPhoto.jpg?resize=400%2C300&amp;amp;ssl=1 400w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/TrumpDocumentsPhoto.jpg?resize=200%2C150&amp;amp;ssl=1 200w&quot; sizes=&quot;(max-width: 372px) 100vw, 372px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Logical Points and Scales &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Our ulterior purpose in this note is to point out that there are &lt;em&gt;at least four&lt;/em&gt; levels on which logical rules can be applied:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
Most fundamental are rules that track consistency of references to relevant sections of legislation. This is the level of the systems described by Palmirani et al. Such rules may seem minute and trivial but their need and heft are not to be discounted. &lt;/p&gt;
&lt;li&gt;
Next level are rules about what constitutes infractions of these statutes, to what level of gravity, and about jurisdiction for prosecuting them. &lt;/p&gt;
&lt;li&gt;
Next level are rules employed in arbitrating whether and which infractions have occurred. This may involve rules of &lt;a href=&quot;https://en.wikipedia.org/wiki/Temporal_logic&quot;&gt;temporal logic&lt;/a&gt; with regard to the timeline of events. &lt;/p&gt;
&lt;li&gt;
The top level is arguing the logic of the accusations and possible defenses to them.
&lt;/ol&gt;
&lt;p&gt;
The top level features most in &amp;#8220;news analysis&amp;#8221; and arguments on social media by many would-be Perry Masons. But our point is that the impact of logical systems as they are programmed comes first and foremost at the bottom, not here. &lt;/p&gt;
&lt;p&gt;
Rules that unfold how designations like NOFORN and ORCON apply in practice occupy the lower levels. Experts on the intelligence and FBI/DoJ sides have begun expounding them in public, but full treatment will be the grist of long legal filings. Let us, however, indulge the higher levels. Continuing with the previous section about the timeline, I believe the key issue is whether or not any access by others to the secret information happened before the key date. If the material was sealed in the Mar-a-Lago rooms and no one had access to the material, it would seem to take the gravest offenses off the table.&lt;/p&gt;
&lt;p&gt;
A higher point is that such defenses saying no leak of secrets occurred before the key date have zero overlap with defenses based on asserting that Trump explicitly or implicitly de-classified it all upon leaving office in January 2021. If the latter, then there were &lt;em&gt;de jure&lt;/em&gt; no secrets. The two kinds of defense can exist in different branches of the case, depending on resolution of the extent of presidential powers to declassify. But they cannot be simultaneously in focus&amp;#8212;then their conjunction brings a logical contradiction. &lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Open Problems &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Have we said enough to indicate how the programming of logical rules, especially at lower levels, will be needed during the full development of this case?&lt;/p&gt;
&lt;p&gt;
&lt;p class=&quot;authors&quot;&gt;By RJLipton+KWRegan&lt;/p&gt;
  </content>
    <author>
      <name>Richard Lipton</name>
      <uri>https://rjlipton.wpcomstaging.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: On the Complexity of Robust Multi-Stage Problems in the Polynomial Hierarchy</title>
    <link href="http://arxiv.org/abs/2209.01011"/>
    <id>http://arxiv.org/abs/2209.01011</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Goerigk_M/0/1/0/all/0/1&quot;&gt;Marc Goerigk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lendl_S/0/1/0/all/0/1&quot;&gt;Stefan Lendl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wulf_L/0/1/0/all/0/1&quot;&gt;Lasse Wulf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the computational complexity of multi-stage robust optimization
problems. Such multi-stage problems are formulated with alternating min/max
quantifiers and therefore naturally fall into higher stage of the polynomial
hierarchy. Despite this, almost no hardness result with respect to the
polynomial hierarchy are known for robust multi-stage problems.
&lt;/p&gt;
&lt;p&gt;In this work, we examine the hardness of robust two-stage adjustable and
robust recoverable optimization with budgeted uncertainty sets. Our main
technical contribution is the introduction of a technique tailored to prove
$\Sigma^p_3$-hardness of such problems. We highlight a difference between
continuous and discrete budgeted uncertainty: In the discrete case, indeed a
wide range of problems becomes complete for the third stage of the polynomial
hierarchy. We highlight the TSP, independent set, and vertex cover problems as
examples of this behavior. However, in the continuous case this does not happen
and all problems remain in the first stage of the hierarchy. Finally, if we
allow the uncertainty to not only affect the objective, but also multiple
constraints, then this distinction disappears and even in the continuous case
we encounter hardness for the third stage of the hierarchy. This shows that
even robust problems which are already NP-complete can still exhibit a
significant computational difference between column-wise and row-wise
uncertainty.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Analysis of a Greedy Heuristic for the Labeling of a Map with a Time-Window Interface</title>
    <link href="http://arxiv.org/abs/2209.00913"/>
    <id>http://arxiv.org/abs/2209.00913</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonerath_A/0/1/0/all/0/1&quot;&gt;Annika Bonerath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Driemel_A/0/1/0/all/0/1&quot;&gt;Anne Driemel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haunert_J/0/1/0/all/0/1&quot;&gt;Jan-Henrik Haunert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haverkort_H/0/1/0/all/0/1&quot;&gt;Herman Haverkort&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Langetepe_E/0/1/0/all/0/1&quot;&gt;Elmar Langetepe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niedermann_B/0/1/0/all/0/1&quot;&gt;Benjamin Niedermann&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we analyze the approximation quality of a greedy heuristic for
automatic map labeling. As input, we have a set of events, each associated with
a label at a fixed position, a timestamp, and a weight. Let a time-window
labeling be a selection of these labels such that all corresponding timestamps
lie in a queried time window and no two labels overlap. A solution to the
time-window labeling problem consists of a data structure that encodes a
time-window labeling for each possible time window; when a user specifies a
time window of interest using a slider interface, we query the data structure
for the corresponding labeling.
&lt;/p&gt;
&lt;p&gt;We define the quality of a time-window labeling solution as the sum of the
weights of the labels in each time-window labeling, integrated over all time
windows. We aim at maximizing the quality under the condition that a label may
never disappear when the user shrinks the time window. In this paper, we
analyze how well a greedy heuristic approximates the maximum quality that can
be realized under this condition.
&lt;/p&gt;
&lt;p&gt;On the one hand, we present an instance with square labels of equal size and
equal weight for which the greedy heuristic fails to find a solution of at
least 1/4 of the quality of an optimal solution. On the other hand, we prove
that the greedy heuristic does guarantee a solution with at least 1/8 of the
quality of an optimal solution. In the case of disk-shaped labels of equal size
and equal weight, the greedy heuristic gives a solution with at least 1/10 of
the quality of an optimal solution. If the labels are squares or disks of equal
size and the maximum weight divided by the minimum weight is at most b, then
the greedy heuristic has approximation ratio Theta(log b).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Mutual Witness Gabriel Drawings of Complete Bipartite Graphs</title>
    <link href="http://arxiv.org/abs/2209.01004"/>
    <id>http://arxiv.org/abs/2209.01004</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lenhart_W/0/1/0/all/0/1&quot;&gt;William J. Lenhart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liotta_G/0/1/0/all/0/1&quot;&gt;Giuseppe Liotta&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $\Gamma$ be a straight-line drawing of a graph and let $u$ and $v$ be two
vertices of $\Gamma$. The Gabriel disk of $u,v$ is the disk having $u$ and $v$
as antipodal points. A pair $\langle \Gamma_0,\Gamma_1 \rangle$ of
vertex-disjoint straight-line drawings form a mutual witness Gabriel drawing
when, for $i=0,1$, any two vertices $u$ and $v$ of $\Gamma_i$ are adjacent if
and only if their Gabriel disk does not contain any vertex of $\Gamma_{1-i}$.
We characterize the pairs $\langle G_0,G_1 \rangle $ of complete bipartite
graphs that admit a mutual witness Gabriel drawing. The characterization leads
to a linear time testing algorithm. We also show that when at least one of the
graphs in the pair $\langle G_0, G_1 \rangle $ is complete $k$-partite with
$k&amp;gt;2$ and all partition sets in the two graphs have size greater than one, the
pair does not admit a mutual witness Gabriel drawing.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Shooting Stars in Simple Drawings of $K_{m,n}$</title>
    <link href="http://arxiv.org/abs/2209.01190"/>
    <id>http://arxiv.org/abs/2209.01190</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aichholzer_O/0/1/0/all/0/1&quot;&gt;Oswin Aichholzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_A/0/1/0/all/0/1&quot;&gt;Alfredo Garc&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parada_I/0/1/0/all/0/1&quot;&gt;Irene Parada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vogtenhuber_B/0/1/0/all/0/1&quot;&gt;Birgit Vogtenhuber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinberger_A/0/1/0/all/0/1&quot;&gt;Alexandra Weinberger&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Simple drawings are drawings of graphs in which two edges have at most one
common point (either a common endpoint, or a proper crossing). It has been an
open question whether every simple drawing of a complete bipartite graph
$K_{m,n}$ contains a plane spanning tree as a subdrawing. We answer this
question to the positive by showing that for every simple drawing of $K_{m,n}$
and for every vertex $v$ in that drawing, the drawing contains a shooting star
rooted at $v$, that is, a plane spanning tree containing all edges incident to
$v$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Can an ML model plainly learn planar layouts?</title>
    <link href="http://arxiv.org/abs/2209.01075"/>
    <id>http://arxiv.org/abs/2209.01075</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wageningen_S/0/1/0/all/0/1&quot;&gt;Smon van Wageningen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mchedlidze_T/0/1/0/all/0/1&quot;&gt;Tamara Mchedlidze&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Planar graph drawings tend to be aesthetically pleasing. In this poster we
explore a Neural Network&#39;s capability of learning various planar graph classes.
Additionally, we also investigate the effectiveness of the model in
generalizing beyond planarity. We find that the model can outperform
conventional techniques for certain graph classes. The model, however, appears
to be more susceptible to randomness in the data, and seems to be less robust
than expected.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Algorithms for Discrepancy, Matchings, and Approximations: Fast, Simple, and Practical</title>
    <link href="http://arxiv.org/abs/2209.01147"/>
    <id>http://arxiv.org/abs/2209.01147</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Csikos_M/0/1/0/all/0/1&quot;&gt;M&amp;#xf3;nika Csik&amp;#xf3;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mustafa_N/0/1/0/all/0/1&quot;&gt;Nabil H. Mustafa&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study one of the key tools in data approximation and optimization:
low-discrepancy colorings. Formally, given a finite set system $(X,\mathcal
S)$, the \emph{discrepancy} of a two-coloring $\chi:X\to\{-1,1\}$ is defined as
$\max_{S \in \mathcal S}|{\chi(S)}|$, where $\chi(S)=\sum\limits_{x \in
S}\chi(x)$.
&lt;/p&gt;
&lt;p&gt;We propose a randomized algorithm which, for any $d&amp;gt;0$ and $(X,\mathcal S)$
with dual shatter function $\pi^*(k)=O(k^d)$, returns a coloring with expected
discrepancy $O\left({\sqrt{|X|^{1-1/d}\log|\mathcal S|}}\right)$ (this bound is
tight) in time $\tilde O\left({|\mathcal S|\cdot|X|^{1/d}+|X|^{2+1/d}}\right)$,
improving upon the previous-best time of $O\left(|\mathcal S|\cdot|X|^3\right)$
by at least a factor of $|X|^{2-1/d}$ when $|\mathcal S|\geq|X|$. This setup
includes many geometric classes, families of bounded dual VC-dimension, and
others. As an immediate consequence, we obtain an improved algorithm to
construct $\varepsilon$-approximations of sub-quadratic size.
&lt;/p&gt;
&lt;p&gt;Our method uses primal-dual reweighing with an improved analysis of randomly
updated weights and exploits the structural properties of the set system via
matchings with low crossing number -- a fundamental structure in computational
geometry. In particular, we get the same $|X|^{2-1/d}$ factor speed-up on the
construction time of matchings with crossing number
$O\left({|X|^{1-1/d}}\right)$, which is the first improvement since the 1980s.
&lt;/p&gt;
&lt;p&gt;The proposed algorithms are very simple, which makes it possible, for the
first time, to compute colorings with near-optimal discrepancies and
near-optimal sized approximations for abstract and geometric set systems in
dimensions higher than $2$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Generalized $k$-Center: Distinguishing Doubling and Highway Dimension</title>
    <link href="http://arxiv.org/abs/2209.00675"/>
    <id>http://arxiv.org/abs/2209.00675</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldmann_A/0/1/0/all/0/1&quot;&gt;Andreas Emil Feldmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1&quot;&gt;Tung Anh Vu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider generalizations of the $k$-Center problem in graphs of low
doubling and highway dimension. For the Capacitated $k$-Supplier with Outliers
(CkSwO) problem, we show an efficient parameterized approximation scheme (EPAS)
when the parameters are $k$, the number of outliers and the doubling dimension
of the supplier set. On the other hand, we show that for the Capacitated
$k$-Center problem, which is a special case of CkSwO, obtaining a parameterized
approximation scheme (PAS) is $\mathrm{W[1]}$-hard when the parameters are $k$,
and the highway dimension. This is the first known example of a problem for
which it is hard to obtain a PAS for highway dimension, while simultaneously
admitting an EPAS for doubling dimension.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Online Demand Scheduling with Failovers</title>
    <link href="http://arxiv.org/abs/2209.00710"/>
    <id>http://arxiv.org/abs/2209.00710</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mellou_K/0/1/0/all/0/1&quot;&gt;Konstantina Mellou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molinaro_M/0/1/0/all/0/1&quot;&gt;Marco Molinaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1&quot;&gt;Rudy Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Motivated by cloud computing applications, we study the problem of how to
optimally deploy new hardware subject to both power and robustness constraints.
To model the situation observed in large-scale data centers, we introduce the
Online Demand Scheduling with Failover problem. There are $m$ identical devices
with capacity constraints. Demands come one-by-one and, to be robust against a
device failure, need to be assigned to a pair of devices. When a device fails
(in a failover scenario), each demand assigned to it is rerouted to its paired
device (which may now run at increased capacity). The goal is to assign demands
to the devices to maximize the total utilization subject to both the normal
capacity constraints as well as these novel failover constraints. These latter
constraints introduce new decision tradeoffs not present in classic assignment
problems such as the Multiple Knapsack problem and AdWords.
&lt;/p&gt;
&lt;p&gt;In the worst-case model, we design a deterministic $\approx
\frac{1}{2}$-competitive algorithm, and show this is essentially tight. To
circumvent this constant-factor loss, which in the context of big cloud
providers represents substantial capital losses, we consider the stochastic
arrival model, where all demands come i.i.d. from an unknown distribution. In
this model we design an algorithm that achieves a sub-linear additive regret
(i.e. as OPT or $m$ increases, the multiplicative competitive ratio goes to
$1$). This requires a combination of different techniques, including a
configuration LP with a non-trivial post-processing step and an online monotone
matching procedure introduced by Rhee and Talagrand.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Optimal General Factor Problem and Jump System Intersection</title>
    <link href="http://arxiv.org/abs/2209.00779"/>
    <id>http://arxiv.org/abs/2209.00779</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1&quot;&gt;Yusuke Kobayashi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the optimal general factor problem, given a graph $G=(V, E)$ and a set
$B(v) \subseteq \mathbb Z$ of integers for $v \in V$, we seek for an edge
subset $F$ of maximum cardinality subject to $d_F(v) \in B(v)$ for $v \in V$,
where $d_F(v)$ denotes the number of edges in $F$ incident to $v$. A recent
crucial work by Dudycz and Paluch shows that this problem can be solved in
polynomial time if each $B(v)$ has no gap of length more than one. While their
algorithm is very simple, its correctness proof is quite complicated. In this
paper, we formulate the optimal general factor problem as the jump system
intersection, and reveal when the algorithm by Dudycz and Paluch can be applied
to this abstract form of the problem. By using this abstraction, we give
another correctness proof of the algorithm, which is simpler than the original
one. We also extend our result to the valuated case.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Optimal Diagonal Preconditioning: Theory and Practice</title>
    <link href="http://arxiv.org/abs/2209.00809"/>
    <id>http://arxiv.org/abs/2209.00809</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Qu_Z/0/1/0/all/0/1&quot;&gt;Zhaonan Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Wenzhi Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hinder_O/0/1/0/all/0/1&quot;&gt;Oliver Hinder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ye_Y/0/1/0/all/0/1&quot;&gt;Yinyu Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhengyuan Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Preconditioning has been a staple technique in optimization and machine
learning. It often reduces the condition number of the matrix it is applied to,
thereby speeding up convergence of optimization algorithms. Although there are
many popular preconditioning techniques in practice, most lack theoretical
guarantees for reductions in condition number. In this paper, we study the
problem of optimal diagonal preconditioning to achieve maximal reduction in the
condition number of any full-rank matrix by scaling its rows or columns
separately or simultaneously. We first reformulate the problem as a
quasi-convex problem and provide a baseline bisection algorithm that is easy to
implement in practice, where each iteration consists of an SDP feasibility
problem. Then we propose a polynomial time potential reduction algorithm with
$O(\log(\frac{1}{\epsilon}))$ iteration complexity, where each iteration
consists of a Newton update based on the Nesterov-Todd direction. Our algorithm
is based on a formulation of the problem which is a generalized version of the
Von Neumann optimal growth problem. Next, we specialize to one-sided optimal
diagonal preconditioning problems, and demonstrate that they can be formulated
as standard dual SDP problems, to which we apply efficient customized solvers
and study the empirical performance of our optimal diagonal preconditioners.
Our extensive experiments on large matrices demonstrate the practical appeal of
optimal diagonal preconditioners at reducing condition numbers compared to
heuristics-based preconditioners.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Treasure Hunt in Graph using Pebbles</title>
    <link href="http://arxiv.org/abs/2209.00857"/>
    <id>http://arxiv.org/abs/2209.00857</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1&quot;&gt;Adri Bhattacharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorain_B/0/1/0/all/0/1&quot;&gt;Barun Gorain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandal_P/0/1/0/all/0/1&quot;&gt;Partha Sarathi Mandal&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we study the treasure hunt problem in a graph by a mobile
agent. The nodes in the graph $G=(V,E)$ are anonymous and the edges incident to
a vertex $v\in V$ whose degree is $deg(v)$ are labeled arbitrarily as
$0,1,\ldots, deg(v)-1$. At a node $t$ in $G$ a stationary object, called {\it
treasure} is located. The mobile agent that is initially located at a node $s$
in $G$, the starting point of the agent, must find the treasure by reaching the
node $t$. The distance from $s$ to $t$ is $D$. The {\it time} required to find
the treasure is the total number of edges the agent visits before it finds the
treasure. The agent does not have any prior knowledge about the graph or the
position of the treasure. An oracle, that knows the graph, the initial position
of the agent, and the position of the treasure, places some pebbles on the
nodes, at most one per node, of the graph to guide the agent towards the
treasure.
&lt;/p&gt;
&lt;p&gt;This paper aims to study the trade-off between the number of pebbles provided
and the time required to find the treasure. To be specific, we aim to answer
the following question. ``What is the minimum time for treasure hunt in a graph
with maximum degree $\Delta$ and diameter $D$ if $k$ pebbles are placed? &quot;
&lt;/p&gt;
&lt;p&gt;We answer the above question when $k&amp;lt;D$ or $k=cD$ for some positive integer
$c$. We design efficient algorithms for the agent for different values of $k$.
We also propose an almost matching lower bound result for $k&amp;lt;D$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Scalable Adversarial Attack Algorithms on Influence Maximization</title>
    <link href="http://arxiv.org/abs/2209.00892"/>
    <id>http://arxiv.org/abs/2209.00892</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1&quot;&gt;Lichao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rui_X/0/1/0/all/0/1&quot;&gt;Xiaobin Rui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we study the adversarial attacks on influence maximization
under dynamic influence propagation models in social networks. In particular,
given a known seed set S, the problem is to minimize the influence spread from
S by deleting a limited number of nodes and edges. This problem reflects many
application scenarios, such as blocking virus (e.g. COVID-19) propagation in
social networks by quarantine and vaccination, blocking rumor spread by
freezing fake accounts, or attacking competitor&#39;s influence by incentivizing
some users to ignore the information from the competitor. In this paper, under
the linear threshold model, we adapt the reverse influence sampling approach
and provide efficient algorithms of sampling valid reverse reachable paths to
solve the problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Johnson-Lindenstrauss embeddings for noisy vectors -- taking advantage of the noise</title>
    <link href="http://arxiv.org/abs/2209.01006"/>
    <id>http://arxiv.org/abs/2209.01006</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1&quot;&gt;Zhen Shao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper investigates theoretical properties of subsampling and hashing as
tools for approximate Euclidean norm-preserving embeddings for vectors with
(unknown) additive Gaussian noises. Such embeddings are sometimes called
Johnson-lindenstrauss embeddings due to their celebrated lemma. Previous work
shows that as sparse embeddings, the success of subsampling and hashing closely
depends on the $l_\infty$ to $l_2$ ratios of the vector to be mapped. This
paper shows that the presence of noise removes such constrain in
high-dimensions, in other words, sparse embeddings such as subsampling and
hashing with comparable embedding dimensions to dense embeddings have similar
approximate norm-preserving dimensionality-reduction properties. The key is
that the noise should be treated as an information to be exploited, not simply
something to be removed. Theoretical bounds for subsampling and hashing to
recover the approximate norm of a high dimension vector in the presence of
noise are derived, with numerical illustrations showing better performances are
achieved in the presence of noise.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Elastic-Degenerate String Matching with 1 Error</title>
    <link href="http://arxiv.org/abs/2209.01095"/>
    <id>http://arxiv.org/abs/2209.01095</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bernardini_G/0/1/0/all/0/1&quot;&gt;Giulia Bernardini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gabory_E/0/1/0/all/0/1&quot;&gt;Est&amp;#xe9;ban Gabory&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pissis_S/0/1/0/all/0/1&quot;&gt;Solon P. Pissis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stougie_L/0/1/0/all/0/1&quot;&gt;Leen Stougie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sweering_M/0/1/0/all/0/1&quot;&gt;Michelle Sweering&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuba_W/0/1/0/all/0/1&quot;&gt;Wiktor Zuba&lt;/a&gt;&lt;/p&gt;&lt;p&gt;An elastic-degenerate string is a sequence of $n$ finite sets of strings of
total length $N$, introduced to represent a set of related DNA sequences, also
known as a pangenome. The ED string matching (EDSM) problem consists in
reporting all occurrences of a pattern of length $m$ in an ED text. This
problem has recently received some attention by the combinatorial pattern
matching community, culminating in an
$\tilde{\mathcal{O}}(nm^{\omega-1})+\mathcal{O}(N)$-time algorithm [Bernardini
et al., SIAM J. Comput. 2022], where $\omega$ denotes the matrix multiplication
exponent and the $\tilde{\mathcal{O}}(\cdot)$ notation suppresses polylog
factors. In the $k$-EDSM problem, the approximate version of EDSM, we are asked
to report all pattern occurrences with at most $k$ errors. $k$-EDSM can be
solved in $\mathcal{O}(k^2mG+kN)$ time, under edit distance, or
$\mathcal{O}(kmG+kN)$ time, under Hamming distance, where $G$ denotes the total
number of strings in the ED text [Bernardini et al., Theor. Comput. Sci. 2020].
Unfortunately, $G$ is only bounded by $N$, and so even for $k=1$, the existing
algorithms run in $\Omega(mN)$ time in the worst case. In this paper we show
that $1$-EDSM can be solved in $\mathcal{O}((nm^2 + N)\log m)$ or
$\mathcal{O}(nm^3 + N)$ time under edit distance. For the decision version, we
present a faster $\mathcal{O}(nm^2\sqrt{\log m} + N\log\log m)$-time algorithm.
We also show that $1$-EDSM can be solved in $\mathcal{O}(nm^2 + N\log m)$ time
under Hamming distance. Our algorithms for edit distance rely on non-trivial
reductions from $1$-EDSM to special instances of classic computational geometry
problems (2d rectangle stabbing or 2d range emptiness), which we show how to
solve efficiently. In order to obtain an even faster algorithm for Hamming
distance, we rely on employing and adapting the $k$-errata trees for indexing
with errors [Cole et al., STOC 2004].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: The distance backbone of directed networks</title>
    <link href="http://arxiv.org/abs/2209.01181"/>
    <id>http://arxiv.org/abs/2209.01181</id>
    <updated>2022-09-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_F/0/1/0/all/0/1&quot;&gt;Felipe Xavier Costa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Correia_R/0/1/0/all/0/1&quot;&gt;Rion Brattig Correia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rocha_L/0/1/0/all/0/1&quot;&gt;Luis M. Rocha&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In weighted graphs the shortest path between two nodes is often reached
through an indirect path, out of all possible connections, leading to
structural redundancies which play key roles in the dynamics and evolution of
complex networks. We have previously developed a parameter-free,
algebraically-principled methodology to uncover such redundancy and reveal the
distance backbone of weighted graphs, which has been shown to be important in
transmission dynamics, inference of important paths, and quantifying the
robustness of networks. However, the method was developed for undirected
graphs. Here we expand this methodology to weighted directed graphs and study
the redundancy and robustness found in nine networks ranging from social,
biomedical, and technical systems. We found that similarly to undirected
graphs, directed graphs in general also contain a large amount of redundancy,
as measured by the size of their (directed) distance backbone. Our methodology
adds an additional tool to the principled sparsification of complex networks
and the measure of their robustness.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Scott Aaronson: What I&amp;#8217;ve learned from having COVID</title>
    <link href="https://scottaaronson.blog/?p=6704"/>
    <id>https://scottaaronson.blog/?p=6704</id>
    <updated>2022-09-04T14:40:54+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;ol&gt;&lt;li&gt;The same thing Salman Rushdie learned: either you spend your entire life in hiding, or &lt;em&gt;eventually&lt;/em&gt; it&amp;#8217;ll come for you.  Years might pass.  You might emerge from hiding once, ten times, a hundred times, be fine, and conclude (emotionally if not intellectually) that the danger must now be over, that if it were going to come at all then it already would have, that maybe you&amp;#8217;re even magically safe.  But this is just the nature of a Poisson process: 0, 0, 0, followed by 1.&lt;/li&gt;&lt;li&gt;First comes the foreboding (in my case, on the flight back home from the wonderful &lt;a href=&quot;http://www.fields.utoronto.ca/activities/22-23/CQIQC-IX&quot;&gt;CQIQC&lt;/a&gt; meeting in Toronto)&amp;#8212;&amp;#8220;could this be COVID?&amp;#8221;&amp;#8212;the urge to reassure yourself that it isn&amp;#8217;t, the premature relief when the test is negative.  Only then, up to a day later, comes the second vertical line on the plastic cartridge.&lt;/li&gt;&lt;li&gt;I&amp;#8217;m grateful for the vaccines, which have up to a 1% probability of having saved my life.  My body was as ready for this virus as my brain would&amp;#8217;ve been for someone pointing a gun at my head and demanding to know a proof of the Karp-Lipton Theorem.  All the same, I wish I &lt;em&gt;also&lt;/em&gt; could&amp;#8217;ve taken a nasal vaccine, to neutralize the intruder at the gate.  Through inaction, through delays, through safetyism that&amp;#8217;s ironically caused millions of additional deaths, the regulatory bureaucracies of the US and other nations have a staggering amount to answer for.&lt;/li&gt;&lt;li&gt;Likewise, Paxlovid should&amp;#8217;ve been distributed like candy, so that everyone would have a supply and could start the instant they tested positive.  By the time you&amp;#8217;re able to book an online appointment and send a loved one to a pharmacy, a night has likely passed and the Paxlovid is less effective.&lt;/li&gt;&lt;li&gt;By the usual standards of a cold, this is mild.  But the headaches, the weakness, the &lt;strong&gt;tiredness&lt;/strong&gt; &amp;#8230; holy crap the tiredness.  I now know what it&amp;#8217;s like to be a male lion or a hundred-year-old man, to sleep for 20 hours per day and have that feel perfectly appropriate and normal.  I can only hope I won&amp;#8217;t be one of the long-haulers; if I were, this could be the end of my scientific career.  Fortunately the probability seems small.&lt;/li&gt;&lt;li&gt;You can quarantine in your bedroom, speak to your family only through the door, have meals passed to you, but your illness will still cast a penumbra on everyone around you.  Your spouse will be stuck watching the kids alone.  Other parents won&amp;#8217;t let their kids play with your kids &amp;#8230; and you can&amp;#8217;t blame them; you&amp;#8217;d do the same in their situation.&lt;/li&gt;&lt;li&gt;It&amp;#8217;s hard to generalize from a sample size of 1 (or 2 if you count my son Daniel, who recovered from a thankfully mild case half a year ago).  Readers: what are &lt;em&gt;your&lt;/em&gt; COVID stories?&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </content>
    <author>
      <name>Scott Aaronson</name>
      <uri>https://scottaaronson.blog</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Scott Aaronson: Win a $250,000 Scott Aaronson Grant for Advanced Precollege STEM Education!</title>
    <link href="https://scottaaronson.blog/?p=6678"/>
    <id>https://scottaaronson.blog/?p=6678</id>
    <updated>2022-09-02T02:31:32+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Back in January, you might recall, Skype cofounder Jaan Tallinn&amp;#8217;s &lt;a href=&quot;https://survivalandflourishing.fund/&quot;&gt;Survival and Flourishing Fund&lt;/a&gt; (SFF) was kind enough to earmark $200,000 for me to donate to any charitable organizations of my choice.  So I posted a &lt;a href=&quot;https://scottaaronson.blog/?p=6232&quot;&gt;call for proposals&lt;/a&gt; on this blog.  You &amp;#8220;applied&amp;#8221; to my &amp;#8220;foundation&amp;#8221; by simply sending me an email, or leaving a comment on this blog, with a link to your organization&amp;#8217;s website and a 1-paragraph explanation of what you wanted the grant for, and then answering any followup questions that I had.&lt;/p&gt;



&lt;p&gt;After receiving about 20 awesome proposals in diverse areas, in the end I decided to &lt;a href=&quot;https://scottaaronson.blog/?p=6256&quot;&gt;split the allotment&lt;/a&gt; among organizations around the world doing fantastic, badly-needed work in math and science enrichment at the precollege level.  These included &lt;a href=&quot;https://www.mathcamp.org/&quot;&gt;Canada/USA Mathcamp&lt;/a&gt;, &lt;a href=&quot;https://www.addiscoder.com/&quot;&gt;AddisCoder&lt;/a&gt;, a &lt;a href=&quot;https://www.mssm.org/&quot;&gt;magnet school in Maine&lt;/a&gt;, a &lt;a href=&quot;https://pages.uoregon.edu/nemirovm/emc.html&quot;&gt;math circle in Oregon&lt;/a&gt;, a &lt;a href=&quot;https://misemaths.wordpress.com/&quot;&gt;math enrichment program in Ghana&lt;/a&gt;, and four others.  I chose to focus on advanced precollege STEM education both because I have some actual knowledge and experience there, and because I wanted to make a strong statement about an underfunded cause close to my heart that&amp;#8217;s recently suffered unjust attacks.&lt;/p&gt;



&lt;p&gt;To quote the immortal Carl Sagan, from shortly before his death:&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;&lt;p&gt;[C]hildren with special abilities and skills need to be nourished and encouraged. They are a national treasure. Challenging programs for the “gifted” are sometimes decried as “elitism.” Why aren’t intensive practice sessions for varsity football, baseball, and basketball players and interschool competition deemed elitism? After all, only the most gifted athletes participate. There is a self-defeating double standard at work here, nationwide.&lt;/p&gt;&lt;/blockquote&gt;



&lt;p&gt;Anyway, the thank-you notes from the programs I selected were some of the most gratifying emails I&amp;#8217;ve ever received.&lt;/p&gt;



&lt;p&gt;But wait, it gets better!  After reading about the Scott Aaronson Speculation Grants on this blog, representatives from a large, reputable family foundation contacted me to say that they wanted to be involved too.  This foundation, which wishes to remain anonymous at this stage although not to the potential grant recipient, intends to make a &lt;em&gt;single US$250,000 grant&lt;/em&gt; in the area of advanced precollege STEM education.  They wanted my advice on where their grant should go.&lt;/p&gt;



&lt;p&gt;Of course, I could&amp;#8217;ve simply picked one of the same wonderful organizations that SFF and I helped in the first round.  On reflection, though, I decided that it would be more on the up-and-up to issue a fresh call for proposals.&lt;/p&gt;



&lt;p&gt;So: do you run a &lt;strong&gt;registered 501(c)(3) nonprofit dedicated to advanced precollege STEM education&lt;/strong&gt;?  If so, &lt;strong&gt;email me or leave a comment here by Friday, September 9&lt;/strong&gt;, telling me a bit about what your organization does and what more it could do with an extra $250K.  Include a rough budget, if that will help convince me that you can actually make productive use of that amount, that it won&amp;#8217;t just sit in your bank account.  Organizations that received a Scott Aaronson Speculation Grant the last time are welcome to reapply; newcomers are also welcome.&lt;/p&gt;



&lt;p&gt;I&amp;#8217;ll pass up to three finalists along to the funder, which will then make a final decision as to the recipient.  The funder will be directly in touch with the potential grantee(s) and will proceed with its intake, review and due diligence process.&lt;/p&gt;



&lt;p&gt;We expect to be able to announce a recipient on or around October 24.  Can&amp;#8217;t wait to see what people come up with!&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </content>
    <author>
      <name>Scott Aaronson</name>
      <uri>https://scottaaronson.blog</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: On the Complexity of the Storyplan Problem</title>
    <link href="http://arxiv.org/abs/2209.00453"/>
    <id>http://arxiv.org/abs/2209.00453</id>
    <updated>2022-09-02T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Binucci_C/0/1/0/all/0/1&quot;&gt;Carla Binucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giacomo_E/0/1/0/all/0/1&quot;&gt;Emilio Di Giacomo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lenhart_W/0/1/0/all/0/1&quot;&gt;William J. Lenhart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liotta_G/0/1/0/all/0/1&quot;&gt;Giuseppe Liotta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montecchiani_F/0/1/0/all/0/1&quot;&gt;Fabrizio Montecchiani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nollenburg_M/0/1/0/all/0/1&quot;&gt;Martin N&amp;#xf6;llenburg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Symvonis_A/0/1/0/all/0/1&quot;&gt;Antonios Symvonis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Motivated by dynamic graph visualization, we study the problem of
representing a graph $G$ in the form of a \emph{storyplan}, that is, a sequence
of frames with the following properties. Each frame is a planar drawing of the
subgraph of $G$ induced by a suitably defined subset of its vertices. Between
two consecutive frames, a new vertex appears while some other vertices may
disappear, namely those whose incident edges have already been drawn in at
least one frame. In a storyplan, each vertex appears and disappears exactly
once. For a vertex (edge) visible in a sequence of consecutive frames, the
point (curve) representing it does not change throughout the sequence.
&lt;/p&gt;
&lt;p&gt;Note that the order in which the vertices of $G$ appear in the sequence of
frames is a total order. In the \textsc{StoryPlan} problem, we are given a
graph and we want to decide whether there exists a total order of its vertices
for which a storyplan exists. We prove that the problem is NP-complete, and
complement this hardness with two parameterized algorithms, one in the vertex
cover number and one in the feedback edge set number of $G$. Also, we prove
that partial $3$-trees always admit a storyplan, which can be computed in
linear time. Finally, we show that the problem remains NP-complete in the case
in which the total order of the vertices is given as part of the input and we
have to choose how to draw the frames.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Spherical Graph Drawing by Multi-dimensional Scaling</title>
    <link href="http://arxiv.org/abs/2209.00191"/>
    <id>http://arxiv.org/abs/2209.00191</id>
    <updated>2022-09-02T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1&quot;&gt;Jacob Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huroyan_V/0/1/0/all/0/1&quot;&gt;Vahan Huroyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kobourov_S/0/1/0/all/0/1&quot;&gt;Stephen Kobourov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We describe an efficient and scalable spherical graph embedding method. The
method uses a generalization of the Euclidean stress function for
Multi-Dimensional Scaling adapted to spherical space, where geodesic pairwise
distances are employed instead of Euclidean distances. The resulting spherical
stress function is optimized by means of stochastic gradient descent.
Quantitative and qualitative evaluations demonstrate the scalability and
effectiveness of the proposed method. We also show that some graph families can
be embedded with lower distortion on the sphere, than in Euclidean and
hyperbolic spaces.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Visibility Representations of Toroidal and Klein-bottle Graphs</title>
    <link href="http://arxiv.org/abs/2209.00576"/>
    <id>http://arxiv.org/abs/2209.00576</id>
    <updated>2022-09-02T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biedl_T/0/1/0/all/0/1&quot;&gt;Therese Biedl&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we study visibility representations of graphs that are
embedded on a torus or a Klein bottle. Mohar and Rosenstiehl showed that any
toroidal graph has a visibility representation on a flat torus bounded by a
parallelogram, but left open the question whether one can assume a rectangular
flat torus, i.e., a flat torus bounded by a rectangle. Independently the same
question was asked by Tamassia and Tollis. We answer this question in the
positive. With the same technique, we can also show that any graph embedded on
a Klein bottle has a visibility representation on the rectangular flat Klein
bottle.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Minimum Flow Decomposition in Graphs with Cycles using Integer Linear Programming</title>
    <link href="http://arxiv.org/abs/2209.00042"/>
    <id>http://arxiv.org/abs/2209.00042</id>
    <updated>2022-09-02T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dias_F/0/1/0/all/0/1&quot;&gt;Fernando H. C. Dias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williams_L/0/1/0/all/0/1&quot;&gt;Lucia Williams&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mumey_B/0/1/0/all/0/1&quot;&gt;Brendan Mumey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomescu_A/0/1/0/all/0/1&quot;&gt;Alexandru I. Tomescu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Minimum flow decomposition (MFD) -- the problem of finding a minimum set of
weighted source-to-sink paths that perfectly decomposes a flow -- is a
classical problem in Computer Science, and variants of it are powerful models
in different fields such as Bioinformatics and Transportation. Even on acyclic
graphs, the problem is NP-hard, and most practical solutions have been via
heuristics or approximations. While there is an extensive body of research on
acyclic graphs, currently, there is no \emph{exact} solution on graphs with
cycles. In this paper, we present the first ILP formulation for three natural
variants of the MFD problem in graphs with cycles, asking for a decomposition
consisting only of weighted source-to-sink paths or cycles, trails, and walks,
respectively. On three datasets of increasing levels of complexity from both
Bioinformatics and Transportation, our approaches solve any instance in under
10 minutes. Our implementations are freely available at
github.com/algbio/MFD-ILP.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Complexity of diameter on AT-free graphs is linear</title>
    <link href="http://arxiv.org/abs/2209.00110"/>
    <id>http://arxiv.org/abs/2209.00110</id>
    <updated>2022-09-02T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Saadi_O/0/1/0/all/0/1&quot;&gt;Oleksiy Al-Saadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deogun_J/0/1/0/all/0/1&quot;&gt;Jitender Deogun&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We exploit properties of dominating pair sets (polar pairs) in asteroidal
triple-free (AT-free) graphs to compute diameter in linear-time. As a
consequence, we improve the best known running time of the well-known graph
theoretical problems of finding a simplicial vertex and triangle recognition in
general graphs to $O(n^2)$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Space-efficient data structure for next/previous larger/smaller value queries</title>
    <link href="http://arxiv.org/abs/2209.00158"/>
    <id>http://arxiv.org/abs/2209.00158</id>
    <updated>2022-09-02T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jo_S/0/1/0/all/0/1&quot;&gt;Seungbum Jo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1&quot;&gt;Geunho Kim&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given an array of size $n$ from a total order, we consider the problem of
constructing a data structure that supports various queries (range
minimum/maximum queries with their variants and next/previous larger/smaller
queries) efficiently. In the encoding model (i.e., the queries can be answered
without the input array), we propose a $(3.701n + o(n))$-bit data structure,
which supports all these queries in $O(\log^{(\ell)}n)$ time, for any positive
integer $\ell$ (here, $\log^{(1)} n = \log n$, and for $\ell &amp;gt; 1$,
$\log^{(\ell)} n = \log ({\log^{(\ell-1)}} n)$). The space of our data
structure matches the current best upper bound of Tsur (Inf. Process. Lett.,
2019), which does not support the queries efficiently. Also, we show that at
least $3.16n-\Theta(\log n)$ bits are necessary for answering all the queries.
Our result is obtained by generalizing Gawrychowski and Nicholson&#39;s $(3n -
\Theta(\log n))$-bit lower bound (ICALP 15) for answering range minimum and
maximum queries on a permutation of size $n$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Maximal Closed Substrings</title>
    <link href="http://arxiv.org/abs/2209.00271"/>
    <id>http://arxiv.org/abs/2209.00271</id>
    <updated>2022-09-02T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Badkobeh_G/0/1/0/all/0/1&quot;&gt;Golnaz Badkobeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luca_A/0/1/0/all/0/1&quot;&gt;Alessandro De Luca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fici_G/0/1/0/all/0/1&quot;&gt;Gabriele Fici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puglisi_S/0/1/0/all/0/1&quot;&gt;Simon Puglisi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A string is closed if it has length 1 or has a nonempty border without
internal occurrences. In this paper we introduce the definition of a maximal
closed substring (MCS), which is an occurrence of a closed substring that
cannot be extended to the left nor to the right into a longer closed substring.
MCSs with exponent at least $2$ are commonly called runs; those with exponent
smaller than $2$, instead, are particular cases of maximal gapped repeats. We
show that a string of length $n$ contains $\mathcal O(n^{1.5})$ MCSs. We also
provide an output-sensitive algorithm that, given a string of length $n$ over a
constant-size alphabet, locates all $m$ MCSs the string contains in $\mathcal
O(n\log n + m)$ time.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Diameter Minimization by Shortcutting with Degree Constraints</title>
    <link href="http://arxiv.org/abs/2209.00370"/>
    <id>http://arxiv.org/abs/2209.00370</id>
    <updated>2022-09-02T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adriaens_F/0/1/0/all/0/1&quot;&gt;Florian Adriaens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gionis_A/0/1/0/all/0/1&quot;&gt;Aristides Gionis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the problem of adding a fixed number of new edges to an
undirected graph in order to minimize the diameter of the augmented graph, and
under the constraint that the number of edges added for each vertex is bounded
by an integer. The problem is motivated by network-design applications, where
we want to minimize the worst case communication in the network without
excessively increasing the degree of any single vertex, so as to avoid
additional overload. We present three algorithms for this task, each with their
own merits. The special case of a matching augmentation, when every vertex can
be incident to at most one new edge, is of particular interest, for which we
show an inapproximability result, and provide bounds on the smallest achievable
diameter when these edges are added to a path. Finally, we empirically evaluate
and compare our algorithms on several real-life networks of varying types.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: The Rique-Number of Graphs</title>
    <link href="http://arxiv.org/abs/2209.00424"/>
    <id>http://arxiv.org/abs/2209.00424</id>
    <updated>2022-09-02T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bekos_M/0/1/0/all/0/1&quot;&gt;Michael A. Bekos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Felsner_S/0/1/0/all/0/1&quot;&gt;Stefan Felsner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kindermann_P/0/1/0/all/0/1&quot;&gt;Philipp Kindermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kobourov_S/0/1/0/all/0/1&quot;&gt;Stephen Kobourov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kratovil_J/0/1/0/all/0/1&quot;&gt;Jan Kratov&amp;#xed;l&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rutter_I/0/1/0/all/0/1&quot;&gt;Ignaz Rutter&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We continue the study of linear layouts of graphs in relation to known data
structures. At a high level, given a data structure, the goal is to find a
linear order of the vertices of the graph and a partition of its edges into
pages, such that the edges in each page follow the restriction of the given
data structure in the underlying order. In this regard, the most notable
representatives are the stack and queue layouts, while there exists some work
also for deques.
&lt;/p&gt;
&lt;p&gt;In this paper, we study linear layouts of graphs that follow the restriction
of a restricted-input queue (rique), in which insertions occur only at the
head, and removals occur both at the head and the tail. We characterize the
graphs admitting rique layouts with a single page and we use the
characterization to derive a corresponding testing algorithm when the input
graph is maximal planar. We finally give bounds on the number of needed pages
(so-called rique-number) of complete graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Online Load Balancing on Uniform Machines with Limited Migration</title>
    <link href="http://arxiv.org/abs/2209.00565"/>
    <id>http://arxiv.org/abs/2209.00565</id>
    <updated>2022-09-02T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maack_M/0/1/0/all/0/1&quot;&gt;Marten Maack&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the problem of online load balancing on uniformly related machines with
bounded migration, jobs arrive online one after another and have to be
immediately placed on one of a given set of machines without knowledge about
jobs that may arrive later on. Each job has a size and each machine has a
speed, and the load due to a job assigned to a machine is obtained by dividing
the first value by the second. The goal is to minimize the maximum overall load
any machine receives. However, unlike in the pure online case, each time a new
job arrives it contributes a migration potential equal to the product of its
size and a certain migration factor. This potential can be spend to reassign
jobs either right away (non-amortized case) or at any later time (amortized
case). Semi-online models of this flavor have been studied intensively for
several fundamental problems, e.g., load balancing on identical machines and
bin packing, but uniformly related machines have not been considered up to now.
In the present paper, the classical doubling strategy on uniformly related
machines is combined with migration to achieve an
$(8/3+\varepsilon)$-competitive algorithm and a $(4+\varepsilon)$-competitive
algorithm with $O(1/\varepsilon)$ amortized and non-amortized migration,
respectively, while the best known competitive ratio in the pure online setting
is roughly $5.828$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: QuICS Hartree Postdoctoral Fellowships at Joint Center for Quantum Information and Computer Science (QuICS) at QuICS/University of Maryland (apply by December 1, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/09/01/quics-hartree-postdoctoral-fellowships-at-joint-center-for-quantum-information-and-computer-science-quics-at-quics-university-of-maryland-apply-by-december-1-2022/"/>
    <id>http://cstheory-jobs.org/2022/09/01/quics-hartree-postdoctoral-fellowships-at-joint-center-for-quantum-information-and-computer-science-quics-at-quics-university-of-maryland-apply-by-december-1-2022/</id>
    <updated>2022-09-01T00:51:37+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The Joint Center for Quantum Information and Computer Science (QuICS, &lt;a href=&quot;http://quics.umd.edu&quot;&gt;http://quics.umd.edu&lt;/a&gt;) is seeking exceptional candidates for the QuICS Hartree Postdoctoral Fellowships in Quantum Information and Computer Science. Applications should be submitted through AcademicJobsOnline at &lt;a href=&quot;https://academicjobsonline.org/ajo/jobs/22534&quot;&gt;https://academicjobsonline.org/ajo/jobs/22534&lt;/a&gt;. Please indicate interest in “HPF.”&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://academicjobsonline.org/ajo/jobs/22534&quot;&gt;https://academicjobsonline.org/ajo/jobs/22534&lt;/a&gt;&lt;br /&gt;
Email: quics-coordinator@umiacs.umd.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Fine-Grained Distribution-Dependent Learning Curves</title>
    <link href="http://arxiv.org/abs/2208.14615"/>
    <id>http://arxiv.org/abs/2208.14615</id>
    <updated>2022-09-01T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bousquet_O/0/1/0/all/0/1&quot;&gt;Olivier Bousquet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanneke_S/0/1/0/all/0/1&quot;&gt;Steve Hanneke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1&quot;&gt;Shay Moran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafer_J/0/1/0/all/0/1&quot;&gt;Jonathan Shafer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolstikhin_I/0/1/0/all/0/1&quot;&gt;Ilya Tolstikhin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Learning curves plot the expected error of a learning algorithm as a function
of the number of labeled input samples. They are widely used by machine
learning practitioners as a measure of an algorithm&#39;s performance, but classic
PAC learning theory cannot explain their behavior. In this paper we introduce a
new combinatorial characterization called the VCL dimension that improves and
refines the recent results of Bousquet et al. (2021). Our characterization
sheds new light on the structure of learning curves by providing fine-grained
bounds, and showing that for classes with finite VCL, the rate of decay can be
decomposed into a linear component that depends only on the hypothesis class
and an exponential component that depends also on the target distribution. In
particular, the finer nuance of the VCL dimension implies lower bounds that are
quantitatively stronger than the bounds of Bousquet et al. (2021) and
qualitatively stronger than classic &#39;no free lunch&#39; lower bounds. The VCL
characterization solves an open problem studied by Antos and Lugosi (1998), who
asked in what cases such lower bounds exist. As a corollary, we recover their
lower bound for half-spaces in $\mathbb{R}^d$, and we do so in a principled way
that should be applicable to other cases as well. Finally, to provide another
viewpoint on our work and how it compares to traditional PAC learning bounds,
we also present an alternative formulation of our results in a language that is
closer to the PAC setting.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Complete and tractable machine-independent characterizations of second-order polytime</title>
    <link href="http://arxiv.org/abs/2208.14739"/>
    <id>http://arxiv.org/abs/2208.14739</id>
    <updated>2022-09-01T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hainry_E/0/1/0/all/0/1&quot;&gt;Emmanuel Hainry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapron_B/0/1/0/all/0/1&quot;&gt;Bruce M. Kapron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marion_J/0/1/0/all/0/1&quot;&gt;Jean-Yves Marion&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pechoux_R/0/1/0/all/0/1&quot;&gt;Romain P&amp;#xe9;choux&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The class of Basic Feasible Functionals BFF is the second-order counterpart
of the class of first-order functions computable in polynomial time. We present
several implicit characterizations of BFF based on a typed programming language
of terms. These terms may perform calls to imperative procedures, which are not
recursive. The type discipline has two layers: the terms follow a standard
simply-typed discipline and the procedures follow a standard tier-based type
discipline. BFF consists exactly of the second-order functionals that are
computed by typable and terminating programs. The completeness of this
characterization surprisingly still holds in the absence of lambda-abstraction.
Moreover, the termination requirement can be specified as a
completeness-preserving instance, which can be decided in time quadratic in the
size of the program. As typing is decidable in polynomial time, we obtain the
first tractable (i.e., decidable in polynomial time), sound, complete, and
implicit characterization of BFF, thus solving a problem opened for more than
20 years.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Reducing the Complexity of the Sensor-Target Coverage Problem Through Point and Set Classification</title>
    <link href="http://arxiv.org/abs/2208.14800"/>
    <id>http://arxiv.org/abs/2208.14800</id>
    <updated>2022-09-01T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thron_C/0/1/0/all/0/1&quot;&gt;Christophter Thron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreno_A/0/1/0/all/0/1&quot;&gt;Anthony Moreno&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The problem of covering random points in a plane with sets of a given shape
has several practical applications in communications and operations research.
One especially prominent application is the coverage of randomly-located points
of interest by randomly-located sensors in a wireless sensor network. In this
article we consider the situation of a large area containing randomly placed
points (representing points of interest), as well a number of randomly-placed
disks of equal radius in the same region (representing individual sensors&#39;
coverage areas). The problem of finding the smallest possible set of disks that
cover the given points is known to be NP-complete. We show that the
computational complexity may be reduced by classifying the disks into several
definite classes that can be characterized as necessary, excludable, or
indeterminate. The problem may then be reduced to considering only the
indeterminate sets and the points that they cover. In addition, indeterminate
sets and the points that they cover may be divided into disjoint ``islands&#39;&#39;
that can be solved separately. Hence the actual complexity is determined by the
number of points and sets in the largest island. We run a number of simulations
to show how the proportion of sets and points of various types depend on two
basic scale-invariant parameters related to point and set density. We show that
enormous reductions in complexity can be achieved even in situations where
point and set density is relatively high.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On weighted graph separation problems and flow-augmentation</title>
    <link href="http://arxiv.org/abs/2208.14841"/>
    <id>http://arxiv.org/abs/2208.14841</id>
    <updated>2022-09-01T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1&quot;&gt;Eun Jung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1&quot;&gt;Marcin Pilipczuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1&quot;&gt;Roohani Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wahlstrom_M/0/1/0/all/0/1&quot;&gt;Magnus Wahlstr&amp;#xf6;m&lt;/a&gt;&lt;/p&gt;&lt;p&gt;One of the first application of the recently introduced technique of
\emph{flow-augmentation} [Kim et al., STOC 2022] is a fixed-parameter algorithm
for the weighted version of \textsc{Directed Feedback Vertex Set}, a landmark
problem in parameterized complexity. In this note we explore applicability of
flow-augmentation to other weighted graph separation problems parameterized by
the size of the cutset. We show the following. -- In weighted undirected graphs
\textsc{Multicut} is FPT, both in the edge- and vertex-deletion version. -- The
weighted version of \textsc{Group Feedback Vertex Set} is FPT, even with an
oracle access to group operations. -- The weighted version of \textsc{Directed
Subset Feedback Vertex Set} is FPT. Our study reveals \textsc{Directed
Symmetric Multicut} as the next important graph separation problem whose
parameterized complexity remains unknown, even in the unweighted setting.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Unbalancing Binary Trees</title>
    <link href="http://arxiv.org/abs/2208.14481"/>
    <id>http://arxiv.org/abs/2208.14481</id>
    <updated>2022-09-01T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ginsberg_M/0/1/0/all/0/1&quot;&gt;Matthew L. Ginsberg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Assuming Zipf&#39;s Law to be accurate, we show that existing techniques for
partially optimizing binary trees produce results that are approximately 10%
worse than true optimal. We present a new approximate optimization technique
that runs in O(n log n) time and produces trees approximately 1% worse than
optimal. The running time is comparable to that of the Garsia-Wachs algorithm
but the technique can be applied to the more useful case where the node being
searched for is expected to be contained in the tree as opposed to outside of
it.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Pattern matching under DTW distance</title>
    <link href="http://arxiv.org/abs/2208.14669"/>
    <id>http://arxiv.org/abs/2208.14669</id>
    <updated>2022-09-01T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gourdel_G/0/1/0/all/0/1&quot;&gt;Garance Gourdel&lt;/a&gt; (IRISA, DI-ENS), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Driemel_A/0/1/0/all/0/1&quot;&gt;Anne Driemel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peterlongo_P/0/1/0/all/0/1&quot;&gt;Pierre Peterlongo&lt;/a&gt; (IRISA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Starikovskaya_T/0/1/0/all/0/1&quot;&gt;Tatiana Starikovskaya&lt;/a&gt; (DI-ENS)&lt;/p&gt;&lt;p&gt;In this work, we consider the problem of pattern matching under the dynamic
time warping (DTW) distance motivated by potential applications in the analysis
of biological data produced by the third generation sequencing. To measure the
DTW distance between two strings, one must &quot;warp&quot; them, that is, double some
letters in the strings to obtain two equal-lengths strings, and then sum the
distances between the letters in the corresponding positions. When the
distances between letters are integers, we show that for a pattern P with m
runs and a text T with n runs: 1. There is an O(m + n)-time algorithm that
computes all locations where the DTW distance from P to T is at most 1; 2.
There is an O(kmn)-time algorithm that computes all locations where the DTW
distance from P to T is at most k. As a corollary of the second result, we also
derive an approximation algorithm for general metrics on the alphabet.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Combinatorial Algorithms for Subsequence Matching: A Survey</title>
    <link href="http://arxiv.org/abs/2208.14722"/>
    <id>http://arxiv.org/abs/2208.14722</id>
    <updated>2022-09-01T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kosche_M/0/1/0/all/0/1&quot;&gt;Maria Kosche&lt;/a&gt; (G&amp;#xf6;ttingen University, Germany), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koss_T/0/1/0/all/0/1&quot;&gt;Tore Ko&amp;#xdf;&lt;/a&gt; (G&amp;#xf6;ttingen University, Germany), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manea_F/0/1/0/all/0/1&quot;&gt;Florin Manea&lt;/a&gt; (G&amp;#xf6;ttingen University, Germany), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siemer_S/0/1/0/all/0/1&quot;&gt;Stefan Siemer&lt;/a&gt; (G&amp;#xf6;ttingen University, Germany)&lt;/p&gt;&lt;p&gt;In this paper we provide an overview of a series of recent results regarding
algorithms for searching for subsequences in words or for the analysis of the
sets of subsequences occurring in a word.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Computing all-vs-all MEMs in run-length encoded collections of HiFi reads</title>
    <link href="http://arxiv.org/abs/2208.14787"/>
    <id>http://arxiv.org/abs/2208.14787</id>
    <updated>2022-09-01T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diaz_Dominguez_D/0/1/0/all/0/1&quot;&gt;Diego D&amp;#xed;az-Dom&amp;#xed;nguez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puglisi_S/0/1/0/all/0/1&quot;&gt;Simon J. Puglisi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salmela_L/0/1/0/all/0/1&quot;&gt;Leena Salmela&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We describe an algorithm to find maximal exact matches (MEMs) among HiFi
reads with homopolymer errors. The main novelty in our work is that we resort
to run-length compression to help deal with errors. Our method receives as
input a run-length-encoded string collection containing the HiFi reads along
with their reverse complements. Subsequently, it splits the encoding into two
arrays, one storing the sequence of symbols for equal-symbol runs and another
storing the run lengths. The purpose of the split is to get the BWT of the run
symbols and reorder their lengths accordingly. We show that this special BWT,
as it encodes the HiFi reads and their reverse complements, supports
bi-directional queries for the HiFi reads. Then, we propose a variation of the
MEM algorithm of Belazzougui et al. (2013) that exploits the run-length
encoding and the implicit bi-directional property of our BWT to compute
approximate MEMs. Concretely, if the algorithm finds that two substrings, $a_1
\ldots a_p$ and $b_1 \ldots b_p$, have a MEM, then it reports the MEM only if
their corresponding length sequences, $\ell^{a}_1 \ldots \ell^{a}_p$ and
$\ell^{b}_1 \ldots \ell^{b}_p$, do not differ beyond an input threshold. We use
a simple metric to calculate the similarity of the length sequences that we
call the {\em run-length excess}. Our technique facilitates the detection of
MEMs with homopolymer errors as it does not require dynamic programming to find
approximate matches where the only edits are the lengths of the equal-symbol
runs. Finally, we present a method that relies on a geometric data structure to
report the text occurrences of the MEMs detected by our algorithm.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A heuristic algorithm for the maximum happy vertices problem using tree decompositions</title>
    <link href="http://arxiv.org/abs/2208.14921"/>
    <id>http://arxiv.org/abs/2208.14921</id>
    <updated>2022-09-01T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carpentier_L/0/1/0/all/0/1&quot;&gt;Louis Carpentier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jooken_J/0/1/0/all/0/1&quot;&gt;Jorik Jooken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goedgebeur_J/0/1/0/all/0/1&quot;&gt;Jan Goedgebeur&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We propose a new heuristic algorithm for the Maximum Happy Vertices problem,
using tree decompositions. Traditionally, such algorithms construct an optimal
solution of the given problem instance through a dynamic programming approach.
We modify this procedure by integrating a parameter $W$ that dictates the
number of dynamic programming states to consider. We drop the exactness
guarantee in favour of a shorter running time. However, if $W$ is large enough
such that all valid states are considered, our heuristic algorithm proves
optimality of the constructed solution. Our algorithm more efficiently
constructs an optimal solution for the Maximum Happy Vertices problem than the
exact algorithm for graphs of bounded treewidth. Furthermore, our algorithm
constructs higher quality solutions than state-of-the-art heuristic algorithms
Greedy-MHV and Growth-MHV for instances of which at least 40% of the vertices
are initially coloured, at the cost of a larger running time.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: The NIST Process for Post-Quantum Cryptography</title>
    <link href="http://blog.computationalcomplexity.org/2022/08/the-nist-competition-for-post-quantum.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-1874664086811883884</id>
    <updated>2022-08-31T19:35:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;div&gt;&lt;i&gt;Guest post by &lt;a href=&quot;https://www.cs.umd.edu/~jkatz/&quot;&gt;Jonathan Katz&lt;/a&gt;&lt;/i&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;Over the past few months there have been several interesting developments in the &lt;a href=&quot;https://csrc.nist.gov/Projects/post-quantum-cryptography&quot;&gt;NIST post-quantum standardization process&lt;/a&gt;.&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;By way of background, since the advent of &lt;a href=&quot;https://en.wikipedia.org/wiki/Shor%27s_algorithm&quot;&gt;Shor&#39;s algorithm&lt;/a&gt; in 1994 we have known that a large-scale, general-purpose quantum computer would be able to break all currently deployed public-key cryptography in (quantum) polynomial time. While estimates vary as to when (or even whether!) quantum computers will become a realistic threat to existing public-key cryptosystems, it seems prudent to already begin developing/deploying newer &quot;post-quantum&quot; schemes that are plausibly secure against quantum computers.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;With the above in mind, NIST initiated an open process in 2017 for designing post-quantum cryptographic standards. Researchers from around the world submitted candidate algorithms for public-key encryption/key exchange and digital signatures. These were winnowed down over a series of rounds as cryptographers publicly debated the relative merits of different proposals, or showed  security weaknesses in some candidates.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;On July 5 of this year, NIST &lt;a href=&quot;https://nvlpubs.nist.gov/nistpubs/ir/2022/NIST.IR.8413.pdf&quot;&gt;announced&lt;/a&gt; that it had selected four of the submissions as finalists for standardization. Only one candidate for public-key encryption was chosen, along with three digital signature schemes. Three of the four selected algorithms rely on the hardness of lattice problems; the only non-lattice scheme is a hash-based signature scheme. (It is possible to build digital signatures using &quot;symmetric-key&quot; assumptions alone.) In addition, four other public-key encryption schemes not based on lattices were designated for further study and possible standardization at a later point in time.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Less than one month later, &lt;a href=&quot;https://eprint.iacr.org/2022/975&quot;&gt;Castryck and Decru announced&lt;/a&gt; a &lt;strong&gt;classical&lt;/strong&gt; attack on SIKE, one of the public-key encryption schemes chosen for further study. &lt;a href=&quot;https://sike.org/&quot;&gt;SIKE&lt;/a&gt; is based on a conjectured hard problem related to isogenies on supersingular elliptic curves.&amp;nbsp;The attack was not just theoretical; the researchers were able to implement the attack and run it in less than a day or less, depending on the security level being considered. Details of the attack are quite complex, but Galbraith &lt;a href=&quot;https://ellipticnews.wordpress.com/2022/07/31/breaking-supersingular-isogeny-diffie-hellman-sidh/&quot;&gt;gives a high-level overview&lt;/a&gt;. &lt;a href=&quot;https://ellipticnews.wordpress.com/2022/08/12/attacks-on-sidh-sike/&quot;&gt;Subsequent improvements&lt;/a&gt; to the attack followed.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;It is worth adding that the above follows an &lt;a href=&quot;https://eprint.iacr.org/2022/214&quot;&gt;entirely classical attack&lt;/a&gt; shown roughly six months earlier on Rainbow, another submission to the NIST standardization process that made it to the 3rd round. (Rainbow is a signature scheme that relies on an entirely different mathematical problem than SIKE.) For completeness, note that none of the four finalists are impacted by any of these attacks.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;A few reflections on the above:&lt;/div&gt;&lt;div&gt;&lt;ul style=&quot;text-align: left;&quot;&gt;&lt;li&gt;It is amazing that the factoring and RSA problems are still hard (for classical computers), more than 40 used after they were proposed for cryptography. The same goes for the discrete-logarithm problem (in certain groups).&lt;/li&gt;&lt;li&gt;It is not easy to find other hard mathematical problems! &lt;a href=&quot;https://en.wikipedia.org/wiki/McEliece_cryptosystem&quot;&gt;Code-based cryptography&lt;/a&gt; has been around about as long as factoring, but has been somewhat unpopular for reasons of efficiency. Lattice-based cryptosystems still seem to give the leading candidates.&lt;/li&gt;&lt;li&gt;We need more (non-cryptographers) studying cryptographic assumptions. The attacks on SIKE involved deep mathematics; attacks on lattice problems may involve algorithmic ideas that cryptographers haven&#39;t thought of.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Scott Aaronson: My Quantum Information Science II Lecture Notes: The wait is over!</title>
    <link href="https://scottaaronson.blog/?p=6685"/>
    <id>https://scottaaronson.blog/?p=6685</id>
    <updated>2022-08-31T19:33:15+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.scottaaronson.com/qisii.pdf&quot;&gt;Here they are [PDF]&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;They&amp;#8217;re 155 pages of awesome&amp;#8212;for a certain extremely specific definition of &amp;#8220;awesome&amp;#8221;&amp;#8212;which I&amp;#8217;m hereby offering to the world free of charge (for noncommercial use only, of course).  They cover material that I taught, for the first time, in my Introduction to Quantum Information Science II undergrad course at UT Austin in Spring 2022.&lt;/p&gt;



&lt;p&gt;The new notes pick up exactly where my older &lt;a href=&quot;https://www.scottaaronson.com/qclec.pdf&quot;&gt;QIS I lecture notes&lt;/a&gt; left off, and they presuppose familiarity with the QIS I material.  So, if you&amp;#8217;re just beginning your quantum information journey, then please start with my QIS I notes, which presuppose only linear algebra and a bit of classical algorithms (e.g., recurrence relations and big-O notation), and which self-containedly explain all the rules of QM, moving on to (e.g.) quantum circuits, density matrices, entanglement entropy, Wiesner&amp;#8217;s quantum money, QKD, quantum teleportation, the Bell inequality, interpretations of QM, the Shor 9-qubit code, and the algorithms of Deutsch-Jozsa, Bernstein-Vazirani, Simon, Shor, and Grover.  Master all that, and you&amp;#8217;ll be close to the quantum information research frontier of circa 1996.&lt;/p&gt;



&lt;p&gt;My new QIS II notes cover a bunch of topics, but the main theme is &amp;#8220;perspectives on quantum computing that go beyond the bare quantum circuit model, and that became increasingly central to the field from the late 1990s onwards.&amp;#8221;  Thus, it covers:&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;Hamiltonians, ground states, the adiabatic algorithm, and the universality of adiabatic QC&lt;/li&gt;&lt;li&gt;The stabilizer formalism, the 1996 Gottesman-Knill Theorem on efficient classical simulation of stabilizer QC, my and Gottesman&amp;#8217;s 2004 elaborations, boosting up to universality via &amp;#8220;magic states,&amp;#8221; transversal codes, and the influential 2016 concept of &lt;em&gt;stabilizer rank&lt;/em&gt;&lt;/li&gt;&lt;li&gt;Bosons and fermions: the formalism of Fock space and of creation and annihilation operators, connection to the permanents and determinants of matrices, efficient classical simulation of free fermionic systems (Valiant&amp;#8217;s 2002 &amp;#8220;matchcircuits&amp;#8221;), the 2001 Knill-Laflamme-Milburn (KLM) theorem on universal optical QC, BosonSampling and its computational complexity, and the current experimental status of BosonSampling&lt;/li&gt;&lt;li&gt;Cluster states, Raussendorf and Briegel&amp;#8217;s 2000 measurement-based quantum computation (MBQC), and Gottesman and Chuang&amp;#8217;s 1999 &amp;#8220;gate teleportation&amp;#8221; trick&lt;/li&gt;&lt;li&gt;Matrix product states, and Vidal&amp;#8217;s 2003 efficient classical simulation of &amp;#8220;slightly entangled&amp;#8221; quantum computations&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Extra bonus topics include:&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;The 2007 Broadbent-Fitzsimons-Kashefi (BFK) protocol for blind and authenticated QC; brief discussion of later developments including Reichardt-Unger-Vazirani 2012 and Mahadev 2018&lt;/li&gt;&lt;li&gt;Basic protocols for quantum state tomography&lt;/li&gt;&lt;li&gt;My 2007 work on PAC-learnability of quantum states&lt;/li&gt;&lt;li&gt;The &amp;#8220;dessert course&amp;#8221;: the black hole information problem, and the Harlow-Hayden argument on the computational hardness of decoding Hawking radiation&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Master all this, and hopefully you&amp;#8217;ll have the conceptual vocabulary to understand a large fraction of what people in quantum computing and information care about today, how they now think about building scalable QCs, and what they post to the quant-ph arXiv.&lt;/p&gt;



&lt;p&gt;Note that my QIS II course is complementary to my graduate course on quantum complexity theory, for which &lt;a href=&quot;https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-845-quantum-complexity-theory-fall-2010/lecture-notes/&quot;&gt;the lecture notes are here&lt;/a&gt;.  There&amp;#8217;s very little overlap between the two (and even less overlap between QIS II and &lt;em&gt;&lt;a href=&quot;https://www.amazon.ca/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565&quot;&gt;Quantum Computing Since Democritus&lt;/a&gt;&lt;/em&gt;).&lt;/p&gt;



&lt;p&gt;The biggest, most important topic related to the QIS II theme that I &lt;em&gt;didn&amp;#8217;t&lt;/em&gt; cover was &lt;a href=&quot;https://en.wikipedia.org/wiki/Topological_quantum_computer&quot;&gt;topological quantum computing&lt;/a&gt;.  I&amp;#8217;d wanted to, but it quickly became clear that topological QC begs for a whole course of its own, and that I had neither the time nor the expertise to do it justice.  In retrospect, I do wish I&amp;#8217;d at least covered the &lt;a href=&quot;https://en.wikipedia.org/wiki/Toric_code&quot;&gt;Kitaev surface code&lt;/a&gt;.&lt;/p&gt;



&lt;p&gt;Crucially, these lecture notes don&amp;#8217;t represent my effort alone.  I worked from draft scribe notes prepared by the QIS II students, who did a far better job than I had any right to expect (including creating the beautiful figures).  My wonderful course TA and PhD student Daniel Liang, along with students Ethan Tan, Samuel Ziegelbein, and Steven Han, then assembled everything, fixed numerous errors, and compiled the bibliography.  I’m grateful to all of them.  At the last minute, we had a LaTeX issue that none of us knew how to fix&amp;#8212;but, in response to a plea, &lt;em&gt;Shtetl-Optimized&lt;/em&gt; reader Pablo Cingolani generously volunteered to help, completed the work by the very next day (I&amp;#8217;d imagined it taking a month!), and earned a fruit basket from me in gratitude.&lt;/p&gt;



&lt;p&gt;Anyway, let me know of any mistakes you find!  We&amp;#8217;ll try to fix them.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </content>
    <author>
      <name>Scott Aaronson</name>
      <uri>https://scottaaronson.blog</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">David Eppstein: Linkage</title>
    <link href="https://11011110.github.io/blog/2022/08/31/linkage.html"/>
    <id>https://11011110.github.io/blog/2022/08/31/linkage</id>
    <updated>2022-08-31T17:28:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;You’re probably familiar with machine-learning-based translation between natural languages, based on finding patterns in large datasets of known translations, for instance as used by Google translate. Now the Xena people are trying to use the same methods to &lt;a href=&quot;https://xenaproject.wordpress.com/2022/08/16/the-future-of-interactive-theorem-proving/&quot;&gt;convert LaTeX-formatted natural-language descriptions of mathematical propositions into the formal language used by the Lean theorem prover&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108834522515462270&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.shadertoy.com/view/wddBRX&quot;&gt;Pretty shadertoy flythrough of the Laves graph&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108841798903036223&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://matthewarcus.wordpress.com/2020/11/19/the-laves-graph/&quot;&gt;via&lt;/a&gt;).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.computationalcomplexity.org/2022/08/conference-modality.html&quot;&gt;The Computational Complexity blog takes on the question of the conference-based publishing culture in computer science&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108848289896382888&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; and whether in-person vs virtual vs hybrid conferences can really be said to be working, now that we have enough experience going back and forth between these modalities and the novelty of the virtual and hybrid formats has worn off.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://gilkalai.wordpress.com/2022/08/19/alexander-a-gaifullin-many-27-vertex-triangulations-of-manifolds-like-the-octonionic-projective-plane-not-even-one-was-known-before/&quot;&gt;Many minimal triangulations of “manifolds like the octonionic projective plane”&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108854003041559158&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; Blog post by Gil Kalai based on &lt;a href=&quot;https://arxiv.org/abs/2207.08507&quot;&gt;a new preprint by Alexander Gaifullin&lt;/a&gt;. Gaifullin conjectures that these all are the octonionic projective plane (not merely “like it”). Gil’s post connects this to several other extremal problems, mostly in polyhedral combinatorics but also including the existence of a girth-5 degree-57 &lt;a href=&quot;https://en.wikipedia.org/wiki/Moore_graph&quot;&gt;Moore graph&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://doi.org/10.1016/j.jvir.2022.07.008&quot;&gt;The &lt;em&gt;Journal of Vascular and Interventional Radiology&lt;/em&gt; retracts its crossword puzzle&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108856663784900462&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://retractionwatch.com/2022/08/20/weekend-reads-who-cares-about-publication-integrity-revealing-a-galileo-forgery-repeat-predatory-journal-authors/&quot;&gt;via&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/ivanoransky/status/1559174872714051584&quot;&gt;via2&lt;/a&gt;). No explanation why yet, but I suspect it’s not because of falsified experimental data.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Today’s simple and somewhat obvious geometry observation &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108865083323085368&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; made while trying to fit old CD cover art into sleeves of a CD binder for more compact storage: if you’re trying to fit a flexible sheet into a flexible sleeve that is only just barely big enough to hold it, it doesn’t help to bend both into a convex curve; they will still be too tight. Instead, if you bend the sheet into a compound curve, while letting the sleeve fall into a convex shape surrounding it, you can make more room.&lt;/p&gt;

    &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;/blog/assets/2022/envelopment.svg&quot; alt=&quot;A convex curve, bent to fit a too-tight sleeve, remains too tight (top) while an S-shaped curve fits more easily (bottom)&quot; style=&quot;width:100%;max-width:540px&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Olligobber implements &lt;a href=&quot;https://en.wikipedia.org/wiki/Combinatory_logic&quot;&gt;combinatory logic&lt;/a&gt; in &lt;a href=&quot;https://gist.github.com/olligobber/e044c87a834b34bc74d8c8903b0b0d94&quot;&gt;\(\TeX\) macros&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@olligobber/106533354539487538&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.ams.org/journals/notices/202208/noti2522/noti2522.html&quot;&gt;The graph minor theorem meets algebra&lt;/a&gt;: in the &lt;em&gt;Notices&lt;/em&gt;, Eric Ramos explains a conjectured category-theoretic generalization of the fact that graph minors form a well-quasi-ordering. Via &lt;a href=&quot;https://mathstodon.xyz/@johncarlosbaez/108879289204270102&quot;&gt;a long multi-post thread by John Baez&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://hardness.mit.edu/&quot;&gt;New draft book on lower bounds in complexity theory&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108883442872860109&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;http://blog.computationalcomplexity.org/2022/08/computers-and-intractability-guide-to.html&quot;&gt;via&lt;/a&gt;), by Demaine, Gasarch, and Hajiaghayi, intended as a replacement for Garey and Johnson’s 1979 NP-completeness book.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://scilogs.spektrum.de/hlf/why-a4-the-mathematical-beauty-of-paper-size/&quot;&gt;Why A4? – the mathematical beauty of paper size&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108889131132278902&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; You probably already knew about the self-reproducing shape of \(1\times\sqrt2\) rectangles when folded in half, but the link is a nice explainer of why A4 paper has such odd-looking dimensions for those who didn’t know.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Talk slides for my papers at the just-concluded &lt;a href=&quot;https://www.torontomu.ca/canadian-conference-computational-geometry-2022/&quot;&gt;Canadian Conference on Computational Geometry&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;MLINK&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;):&lt;/span&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://www.ics.uci.edu/~eppstein/pubs/Epp-CCCG-22a.pdf&quot;&gt;Orthogonal dissection into few rectangles&lt;/a&gt; (see &lt;a href=&quot;/blog/2022/06/22/dehn-rank-revisited.html&quot;&gt;earlier post&lt;/a&gt;)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://www.ics.uci.edu/~eppstein/pubs/Epp-CCCG-22b.pdf&quot;&gt;Locked and unlocked smooth embeddings of surfaces&lt;/a&gt; (see &lt;a href=&quot;/blog/2022/06/28/motion-bend-lines.html&quot;&gt;earlier post&lt;/a&gt;)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://www.ics.uci.edu/~eppstein/pubs/Epp-CCCG-22c.pdf&quot;&gt;Reflections in an octagonal mirror maze&lt;/a&gt; (see &lt;a href=&quot;/blog/2022/06/24/reflections-octagonal-mirror.html&quot;&gt;earlier post&lt;/a&gt;)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;An update on the “coffee near Ryerson” map from &lt;a href=&quot;/blog/2022/08/22/permuted-points-interest.html&quot;&gt;my recent post&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108900798389538030&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;):&lt;/span&gt;  I tried four cafés, only one of which was highlighted by a line on the map: Black Bear, Page One, Hailed, and Mast. I would have also tried Le Génie but it was closed mornings. The best coffee was at Hailed, but it’s tiny, with only outdoor seating. Second-best coffee, and the best space to hang out to drink the coffee, was Mast. The others did not disappoint but were not as good as Hailed and Mast.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://sigbed.org/2022/08/22/the-toxic-culture-of-rejection-in-computer-science/&quot;&gt;The toxic culture of rejection in computer science&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108910723093352198&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://news.ycombinator.com/item?id=32605494&quot;&gt;via&lt;/a&gt;), Edward Lee in the ACM SIGBED blog. I disagree with the post’s preference for incrementalism over novelty, but I agree that there’s big price for being too selective. Beyond frustrating everyone, I think it leads to dominance of trendiness and in-groups over significance, progress, originality, and depth. And though that may be good for those in the trendy in-groups, it’s not good for the field.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://electionlawblog.org/?p=131555&quot;&gt;Accusations of research misconduct against Princeton gerrymandering researcher Sam Wang, made by a Republican political operative, have been found to be “without merit” by the university&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108916373574688890&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://retractionwatch.com/2022/08/27/weekend-reads-the-problem-of-irreproducible-bioscience-research-how-to-stop-the-unknowing-citation-of-retracted-papers-data-scandal-leads-to-stock-drop/&quot;&gt;via&lt;/a&gt;).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.tokyoweekender.com/2022/07/origami-influencing-engineering-technology/&quot;&gt;How origami is engineering new technological opportunities&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108920072649801627&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; Interview with mechanical engineer Sachiko Ishida of Meiji University on applications of folded structures in engineering, and where origami engineering is headed.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;authors&quot;&gt;By David Eppstein&lt;/p&gt;
  </content>
    <author>
      <name>David Eppstein</name>
      <uri>https://11011110.github.io/blog/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">TCS+ Seminar Series: Guest Post: TCS Women Travel Scholarships for FOCS’22</title>
    <link href="https://tcsplus.wordpress.com/2022/08/30/guest-post-tcs-women-travel-scholarships-for-focs22/"/>
    <id>http://tcsplus.wordpress.com/?p=632</id>
    <updated>2022-08-31T01:08:20+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;em&gt;Below is an announcement on behalf of &lt;a href=&quot;https://sigact.org/tcswomen/&quot;&gt;TCS Women&lt;/a&gt; regarding the upcoming FOCS&amp;#8217;22.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;TCS Women is offering travel scholarships to attend FOCS 2022 in Denver, Colorado, USA. TCS Women Travel Scholarships are intended for researchers at the beginning of their career. This scholarship is being made available for women and minorities, and anyone who identifies as such is welcome to apply; this scholarship is open to both US and international students. Preference will be given to students at the beginning of their studies. If we have sufficient funding, we will give awards to more senior students and possibly even postdocs.&lt;/p&gt;



&lt;p&gt;To apply, you will need to fill out the following form by&amp;nbsp;&lt;strong&gt;Sept 2nd, 2022&lt;/strong&gt;&amp;nbsp;(11:59 pm PDT) in which you provide basic information about yourself, an estimate of your expenses, and a brief statement:&lt;/p&gt;



&lt;p class=&quot;has-text-align-center&quot;&gt;&lt;a href=&quot;https://protect-au.mimecast.com/s/Y8mEC2xMQzikvQnLYhnDVRj?domain=forms.gle&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;Apply for a travel grant here.&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;In addition, you will need to have your advisor (or department head or other faculty mentor if you do not yet have an advisor) send a letter of support to &lt;a rel=&quot;noreferrer noopener&quot; href=&quot;mailto:tcswomen@gmail.com&quot; target=&quot;_blank&quot;&gt;tcswomen@gmail.com&lt;/a&gt; by Sept 2nd, 2022. Your advisor’s letter should also describe the availability of other travel funds.  Note for advisors: Specifics about alternative funding are very helpful.  Statements like “funding is tight” are not very helpful. This letter should be sent with the subject line &lt;em&gt;“support letter for [your name]”&lt;/em&gt;. This is very important. Your application is not complete without this letter.&lt;/p&gt;



&lt;p&gt;For more information, check out the website: &lt;a href=&quot;https://protect-au.mimecast.com/s/i-5BC3QNPBimwvLjkcqEmbE?domain=sigact.org/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;https://sigact.org/tcswomen/5th-tcs-women-meeting/travel-scholarship/&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By plustcs&lt;/p&gt;
  </content>
    <author>
      <name>TCS+ Seminar Series</name>
      <uri>https://tcsplus.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Generating Regular Hyperbolic Honeycombs</title>
    <link href="http://arxiv.org/abs/2208.13816"/>
    <id>http://arxiv.org/abs/2208.13816</id>
    <updated>2022-08-31T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celinska_Kopczynska_D/0/1/0/all/0/1&quot;&gt;Dorota Celi&amp;#x144;ska-Kopczy&amp;#x144;ska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kopczynski_E/0/1/0/all/0/1&quot;&gt;Eryk Kopczy&amp;#x144;ski&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Geodesic regular tree structures are essential to combat numerical precision
issues that arise while working with large-scale computational hyperbolic
geometry and have applications in algorithms based on distances in such
tessellations. We present a method of generating and applying such structures
to the tessellations of 3-dimensional hyperbolic space.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Minimum color spanning circle of imprecise points</title>
    <link href="http://arxiv.org/abs/2208.13865"/>
    <id>http://arxiv.org/abs/2208.13865</id>
    <updated>2022-08-31T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Acharyya_A/0/1/0/all/0/1&quot;&gt;Ankush Acharyya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jallu_R/0/1/0/all/0/1&quot;&gt;Ramesh K. Jallu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keikha_V/0/1/0/all/0/1&quot;&gt;Vahideh Keikha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loffler_M/0/1/0/all/0/1&quot;&gt;Maarten L&amp;#xf6;ffler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saumell_M/0/1/0/all/0/1&quot;&gt;Maria Saumell&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $\cal R$ be a set of $n$ colored imprecise points, where each point is
colored by one of $k$ colors. Each imprecise point is specified by a unit disk
in which the point lies. We study the problem of computing the smallest and the
largest possible minimum color spanning circle, among all possible choices of
points inside their corresponding disks. We present an $O(nk\log n)$ time
algorithm to compute a smallest minimum color spanning circle. Regarding the
largest minimum color spanning circle, we show that the problem is NP-Hard and
present a $\frac{1}{3}$-factor approximation algorithm. We improve the
approximation factor to $\frac{1}{2}$ for the case where no two disks of
distinct color intersect.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Approximation Algorithm for Minimum $p$ Union Under a Geometric Setting</title>
    <link href="http://arxiv.org/abs/2208.14264"/>
    <id>http://arxiv.org/abs/2208.14264</id>
    <updated>2022-08-31T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ran_Y/0/1/0/all/0/1&quot;&gt;Yingli Ran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhao Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a minimum $p$ union problem (Min$p$U), given a hypergraph $G=(V,E)$ and an
integer $p$, the goal is to find a set of $p$ hyperedges $E&#39;\subseteq E$ such
that the number of vertices covered by $E&#39;$ (that is $|\bigcup_{e\in E&#39;}e|$) is
minimized. It was known that Min$p$U is at least as hard as the densest
$k$-subgraph problem. A question is: how about the problem in some geometric
settings? In this paper, we consider the unit square Min$p$U problem
(Min$p$U-US) in which $V$ is a set of points on the plane, and each hyperedge
of $E$ consists of a set of points in a unit square. A
$(\frac{1}{1+\varepsilon},4)$-bicriteria approximation algorithm is presented,
that is, the algorithm finds at least $\frac{p}{1+\varepsilon}$ unit squares
covering at most $4opt$ points, where $opt$ is the optimal value for the
Min$p$U-US instance (the minimum number of points that can be covered by $p$
unit squares).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Randomized Approximation Schemes for the Tutte Polynomial and Random Clustering in Subdense and Superdense Graphs</title>
    <link href="http://arxiv.org/abs/2208.13809"/>
    <id>http://arxiv.org/abs/2208.13809</id>
    <updated>2022-08-31T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hauptmann_M/0/1/0/all/0/1&quot;&gt;Mathias Hauptmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiling_R/0/1/0/all/0/1&quot;&gt;Ronja Tiling&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Extending the work of Alon, Frieze abnd Welsh, we show that there are
randomized polynomial time approximation schemes for computing the Tutte
polynomial in subdense graphs with an minimal node degree of $\Omega\left (
\frac{n}{\sqrt{\log n}}\right )$ . The same holds for the partition function
$Z$ in the random cluster model with uniform edge probabilities and for the
associated distribution $\lambda (A),\: A \subseteq E$ whenever the underlying
graph $G=(V,E)$ is $c\cdot\frac{n}{\sqrt{\log (n)}}$-subdense. In the
superdense case with node degrees $n-o(n)$, we show that the Tutte polynomial
$T_G(x,y)$ is asymptotically equal to $Q=(x-1)(y-1)$. Moreover, we briefly
discuss the problem of approximating $Z$ in the case of $(\alpha, \beta
)$-power law graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On Sparse Hitting Sets: from Fair Vertex Cover to Highway Dimension</title>
    <link href="http://arxiv.org/abs/2208.14132"/>
    <id>http://arxiv.org/abs/2208.14132</id>
    <updated>2022-08-31T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blum_J/0/1/0/all/0/1&quot;&gt;Johannes Blum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Disser_Y/0/1/0/all/0/1&quot;&gt;Yann Disser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldmann_A/0/1/0/all/0/1&quot;&gt;Andreas Feldmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1&quot;&gt;Siddharth Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zych_Pawlewicz_A/0/1/0/all/0/1&quot;&gt;Anna Zych-Pawlewicz&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the Sparse Hitting Set (Sparse-HS) problem, where we are given a
set system $(V,\mathcal{F},\mathcal{B})$ with two families
$\mathcal{F},\mathcal{B}$ of subsets of $V$. The task is to find a hitting set
for $\mathcal{F}$ that minimizes the maximum number of elements in any of the
sets of $\mathcal{B}$. Our focus is on determining the complexity of some
special cases of Sparse-HS with respect to the sparseness $k$, which is the
optimum number of hitting set elements in any set of $\mathcal{B}$.
&lt;/p&gt;
&lt;p&gt;For the Sparse Vertex Cover (Sparse-VC) problem, $V$ is given by the vertex
set of a graph, and $\mathcal{F}$ is its edge set. We prove NP-hardness for
sparseness $k\geq 2$ and polynomial time solvability for $k=1$. We also provide
a polynomial-time $2$-approximation for any $k$. A special case of Sparse-VC is
Fair Vertex Cover (Fair-VC), where the family $\mathcal{B}$ is given by vertex
neighbourhoods. For this problem we prove NP-hardness for constant $k$ and
provide a polynomial-time $(2-\frac{1}{k})$-approximation. This is better than
any approximation possible for Sparse-VC or Vertex Cover (under UGC).
&lt;/p&gt;
&lt;p&gt;We then consider two problems derived from Sparse-HS related to the highway
dimension, a graph parameter modelling transportation networks. Most algorithms
for graphs of low highway dimension compute solutions to the $r$-Shortest Path
Cover ($r$-SPC) problem, where $r&amp;gt;0$, $\mathcal{F}$ contains all shortest paths
of length between $r$ and $2r$, and $\mathcal{B}$ contains all balls of radius
$2r$. There is an XP algorithm that computes solutions to $r$-SPC of sparseness
at most $h$ if the input graph has highway dimension $h$, but the existence if
an FPT algorithm was open. We prove that $r$-SPC and also the related
$r$-Highway Dimension ($r$-HD) problem are both W[1]-hard. Furthermore, we
prove that $r$-SPC admits a polynomial-time $O(\log n)$-approximation.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Unit-length Rectangular Drawings of Graphs</title>
    <link href="http://arxiv.org/abs/2208.14142"/>
    <id>http://arxiv.org/abs/2208.14142</id>
    <updated>2022-08-31T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alegria_C/0/1/0/all/0/1&quot;&gt;Carlos Alegria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lozzo_G/0/1/0/all/0/1&quot;&gt;Giordano Da Lozzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Battista_G/0/1/0/all/0/1&quot;&gt;Giuseppe Di Battista&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frati_F/0/1/0/all/0/1&quot;&gt;Fabrizio Frati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosso_F/0/1/0/all/0/1&quot;&gt;Fabrizio Grosso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patrignani_M/0/1/0/all/0/1&quot;&gt;Maurizio Patrignani&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A rectangular drawing of a planar graph $G$ is a planar drawing of $G$ in
which vertices are mapped to grid points, edges are mapped to horizontal and
vertical straight-line segments, and faces are drawn as rectangles. Sometimes
this latter constraint is relaxed for the outer face. In this paper, we study
rectangular drawings in which the edges have unit length. We show a complexity
dichotomy for the problem of deciding the existence of a unit-length
rectangular drawing, depending on whether the outer face must also be drawn as
a rectangle or not. Specifically, we prove that the problem is NP-complete for
biconnected graphs when the drawing of the outer face is not required to be a
rectangle, even if the sought drawing must respect a given planar embedding,
whereas it is polynomial-time solvable, both in the fixed and the variable
embedding settings, if the outer face is required to be drawn as a rectangle.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Minimum Coverage Instrumentation</title>
    <link href="http://arxiv.org/abs/2208.13907"/>
    <id>http://arxiv.org/abs/2208.13907</id>
    <updated>2022-08-31T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Li Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoag_E/0/1/0/all/0/1&quot;&gt;Ellis Hoag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kyungwoo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mestre_J/0/1/0/all/0/1&quot;&gt;Julian Mestre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pupyrev_S/0/1/0/all/0/1&quot;&gt;Sergey Pupyrev&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Modern compilers leverage block coverage profile data to carry out downstream
profile-guided optimizations to improve the runtime performance and the size of
a binary. Given a control-flow graph $G=(V, E)$ of a function in the binary,
where nodes in $V$ correspond to basic blocks (sequences of instructions that
are always executed sequentially) and edges in $E$ represent jumps in the
control flow, the goal is to know for each block $u \in V$ whether $u$ was
executed during a session. To this end, extra instrumentation code that records
when a block is executed needs to be added to the binary. This extra code
creates a time and space overhead, which one would like to minimize as much as
possible. Motivated by this application, we study the Minimum Coverage
Instrumentation problem, where the goal is to find a minimum size subset of
blocks to instrument such that the coverage of the remaining blocks in the
graph can be inferred from the coverage status of the instrumented subset. Our
main result is an algorithm to find an optimal instrumentation strategy and to
carry out the inference in $O(|E|)$ time. We also study variants of this basic
problem in which we are interested in learning the coverage of edges instead of
the nodes, or when we are only allowed to instrument edges instead of the
nodes.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


</feed>
