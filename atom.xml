<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Theory of Computing Report</title>
  <link rel="self" href=""/>
  <link href=""/>
  <id></id>
  <updated></updated>
  <generator uri="http://feedreader.github.io/">Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]</generator>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Richard Lipton: Why Study Logic?</title>
    <link href="https://rjlipton.wpcomstaging.com/2023/01/25/why-study-logic/"/>
    <id>https://rjlipton.wpcomstaging.com/?p=20949</id>
    <updated>2023-01-25T07:23:44+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;
&lt;font color=&quot;#0044cc&quot;&gt;&lt;br /&gt;
&lt;em&gt;Before and after it is mechanized&amp;#8230;&lt;/em&gt;&lt;br /&gt;
&lt;font color=&quot;#000000&quot;&gt;&lt;/p&gt;
&lt;p&gt;
Peter Andrews is a Professor of Mathematics, Emeritus at Carnegie Mellon University (CMU) in Pittsburgh, Pennsylvania. He has studied logic his whole life&amp;#8212;he is a logician.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/01/25/why-study-logic/andrews/&quot; rel=&quot;attachment wp-att-20954&quot;&gt;&lt;img data-attachment-id=&quot;20954&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/01/25/why-study-logic/andrews/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/andrews.jpg?fit=800%2C800&amp;amp;ssl=1&quot; data-orig-size=&quot;800,800&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;1&amp;quot;}&quot; data-image-title=&quot;andrews&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/andrews.jpg?fit=300%2C300&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/andrews.jpg?fit=600%2C600&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/andrews.jpg?resize=200%2C200&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;200&quot; height=&quot;200&quot; class=&quot;aligncenter wp-image-20954&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/andrews.jpg?resize=300%2C300&amp;amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/andrews.jpg?resize=150%2C150&amp;amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/andrews.jpg?resize=768%2C768&amp;amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/andrews.jpg?resize=400%2C400&amp;amp;ssl=1 400w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/andrews.jpg?resize=200%2C200&amp;amp;ssl=1 200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/andrews.jpg?w=800&amp;amp;ssl=1 800w&quot; sizes=&quot;(max-width: 200px) 100vw, 200px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
I always loved formal logic, but was never an expert on &lt;a href=&quot;https://www.thoughtco.com/good-reasons-to-study-logic-2670416&quot;&gt;why study logic?&lt;/a&gt; I did take his logic class when I was a graduate student at CMU. I enjoyed it very much. &lt;/p&gt;
&lt;p&gt;
Peter was, as we just &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/&quot;&gt;mentioned&lt;/a&gt;, a student of Alonzo Church. His thesis appeared in &lt;a href=&quot;https://www.abebooks.com/first-edition/Transfinite-Type-Theory-Variables-Peter-Andrews/30354797382/bd&quot;&gt;book&lt;/a&gt; form, &lt;em&gt;A Transfinite Type Theory with Type Variables&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;
Saying &amp;#8220;transfinite&amp;#8221; sounds rarefied. However, transfinite systems still keep one finite foot on the ground, in that all descending chains are finite. Peter extended his and other work with Church to develop systems including &lt;a href=&quot;https://en.wikipedia.org/wiki/Q0_(mathematical_logic)&quot;&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BQ_0%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{Q_0}&quot; class=&quot;latex&quot; /&gt;&lt;/a&gt; that can be expressly programmed. &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BQ_0%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{Q_0}&quot; class=&quot;latex&quot; /&gt; became a backbone of the Theorem Proving System (&lt;a href=&quot;https://gtps.math.cmu.edu/tps.html&quot;&gt;TPS&lt;/a&gt;) designed by Andrews and colleagues.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; From Peter the Author &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Peter wrote a &lt;a href=&quot;https://www.amazon.com/Introduction-Mathematical-Logic-Type-Theory/dp/1402007639&quot;&gt;textbook&lt;/a&gt; in 2002 that makes these advanced logic systems accessible to students. It is titled &lt;em&gt;An Introduction to Mathematical Logic and Type Theory: To Truth Through Proof&lt;/em&gt;. Never mind that Kurt G&amp;ouml;del showed respects in which proof must fall short of truth&amp;#8212;proof remains our most reliable guide to truth. The essence of the book and the educational wing &lt;a href=&quot;http://www.cs.cmu.edu/Groups/fox/people/fp/papers/etps02.pdf&quot;&gt;ETPS&lt;/a&gt; of TPS is to use proof for learning and discovery.&lt;/p&gt;
&lt;p&gt;
Here is what the textbook&amp;#8217;s description says about the application of type theory:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; The last three chapters of the book provide an introduction to type theory (higher-order logic). It is shown how various mathematical concepts can be formalized in this very expressive formal language. This expressive notation facilitates proofs of the classical incompleteness and undecidability theorems which are very elegant and easy to understand. The discussion of semantics makes clear the important distinction between standard and nonstandard models which is so important in understanding puzzling phenomena such as the incompleteness theorems and Skolem&amp;#8217;s Paradox about countable models of set theory. &lt;/p&gt;
&lt;p&gt;
Some of the numerous exercises require giving formal proofs. A computer program called ETPS which is available from the web facilitates doing and checking such exercises. Audience: This volume will be of interest to mathematicians, computer scientists, and philosophers in universities, as well as to computer scientists in industry who wish to use higher-order logic for hardware and software specification and verification. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Peter expressed a motivation for learning and employing powerful logic implementations in his 2003 Herbrand Award acceptance &lt;a href=&quot;https://www.academia.edu/12038075/Herbrand_Award_Acceptance_Speech&quot;&gt;speech&lt;/a&gt;. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; We need very sophisticated methods of thinking about complex problems. Our technology and scientiﬁc knowledge progress steadily, but are we any better at thinking than Socrates or Pythagoras? &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
He continued into how one needs to base work in a system that is built around a simple core:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Church’s type theory is much simpler, and is at the same time a richer, more expressive language [than Principia Mathematica], since it recognizes functions as ﬁrst-class objects which do not have to be regarded as sets of ordered &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{n}&quot; class=&quot;latex&quot; /&gt;-tuples. &amp;#8230; A simple introduction to type theory can be found in the last three chapters of my book. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
His speech finished by observing how &amp;#8220;serious efforts to mechanize logic&amp;#8221; have made progress unmatched in the 2,500+ year study of logic.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; From Logic Puzzles to Reasoning About Knowledge &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Another student of Church was Raymond Smullyan, and his work enters Andrews&amp;#8217;s story as well. We &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2010/06/11/does-cantors-diagonalization-proof-cheat/&quot;&gt;featured&lt;/a&gt; him &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2015/07/28/playing-chess-with-the-devil/&quot;&gt;before&lt;/a&gt; and &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2017/02/27/working-backward/&quot;&gt;after&lt;/a&gt; our &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2017/02/14/raymond-smullyan-1919-2017/&quot;&gt;memorial&lt;/a&gt; on his passing at age 98. He was best known popularly for numerous books on logic puzzles. &lt;/p&gt;
&lt;p&gt;
Among the most difficult logic puzzles are those that concern logical inference about others&amp;#8217; state of knowledge. One such puzzle is called &amp;#8220;&lt;a href=&quot;https://www.reddit.com/r/puzzles/comments/1h3guk/the_kings_advisor/&quot;&gt;The King&amp;#8217;s Advisor&lt;/a&gt;.&amp;#8221; Here is a &lt;a href=&quot;https://puzzlefry.com/puzzles/king-and-hats-famous-puzzle/&quot;&gt;statement&lt;/a&gt; (edited by us):&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; A king wants an advisor and comes to ask the 3 wisest sages. He blindfolds them and put hats on their heads. Afterwards, the king takes off their blindfolds. He tells them that their hat is either blue or white. He tells them that whoever can deduce the color of their hat will be his next advisor. Also he tells them that at least one of the sages will be wearing a blue hat. &lt;/p&gt;
&lt;p&gt;
The sages can all see each other’s hats except of course, their own. Sage A sees that the other 2 are wearing blue hats. For hours no one speaks, then Sage A stands up and tells the king the color of his hat. What color is it and how does he know? &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Wikipedia illustrates its &lt;a href=&quot;https://en.wikipedia.org/wiki/Common_knowledge_(logic)&quot;&gt;page&lt;/a&gt; on common-knowledge logic puzzles with what many consider the hardest of this kind, the &amp;#8220;blue-eyed islander&amp;#8221; puzzle. It has an &lt;a href=&quot;http://xkcd.com/blue_eyes.html&quot;&gt;xkcd page&lt;/a&gt;. I (Ken filling in material here) thought we had written about this puzzle on this blog, but it turns out to be a &lt;a href=&quot;https://terrytao.wordpress.com/2011/04/07/the-blue-eyed-islanders-puzzle-repost/&quot;&gt;memory&lt;/a&gt; from Terry Tao&amp;#8217;s blog.&lt;/p&gt;
&lt;p&gt;
Quantifying the possible gain of knowledge is integral to the analysis of many modern cryptographic protocols. Four logician friends of ours stepped in with an even broader approach.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/01/25/why-study-logic/faginhalpernmosesvardi/&quot; rel=&quot;attachment wp-att-20952&quot;&gt;&lt;img data-attachment-id=&quot;20952&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/01/25/why-study-logic/faginhalpernmosesvardi/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/FaginHalpernMosesVardi.png?fit=339%2C422&amp;amp;ssl=1&quot; data-orig-size=&quot;339,422&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;FaginHalpernMosesVardi&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/FaginHalpernMosesVardi.png?fit=241%2C300&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/FaginHalpernMosesVardi.png?fit=339%2C422&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/FaginHalpernMosesVardi.png?resize=241%2C300&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;241&quot; height=&quot;300&quot; class=&quot;aligncenter size-medium wp-image-20952&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/FaginHalpernMosesVardi.png?resize=241%2C300&amp;amp;ssl=1 241w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/FaginHalpernMosesVardi.png?w=339&amp;amp;ssl=1 339w&quot; sizes=&quot;(max-width: 241px) 100vw, 241px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
Here is what Ronald Fagin, Joseph Halpern, Yoram Moses, and Moshe Vardi say about their &lt;a href=&quot;https://mitpress.mit.edu/9780262562003/reasoning-about-knowledge/&quot;&gt;book&lt;/a&gt;, &lt;em&gt;Reasoning About Knowledge&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Reasoning about knowledge&amp;#8212;particularly the knowledge of agents who reason about the world and each other&amp;#8217;s knowledge&amp;#8212;was once the exclusive province of philosophers and puzzle solvers. &lt;/p&gt;
&lt;p&gt;
More recently, this type of reasoning has been shown to play a key role in a surprising number of contexts, from understanding conversations to the analysis of distributed computer algorithms. [Our book] brings eight years of work by the authors into a cohesive framework for understanding and analyzing reasoning about knowledge that is intuitive, mathematically well founded, useful in practice, and widely applicable. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
A crisp way to boil down their advice on &amp;#8220;why study logic?&amp;#8221;&amp;#8212;and logic about others&amp;#8217; logic in particular&amp;#8212;is that more walks of life are &amp;#8220;going meta&amp;#8221; in the near future&amp;#8212;in ways that existing protocols have also started to mechanize. &lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Logic Has A World Day &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Here is another indicator on why logic is important: It has an official world day. A nice &lt;a href=&quot;https://www.theguardian.com/science/2022/jan/10/can-you-solve-it-godels-incompleteness-theorem&quot;&gt;article&lt;/a&gt; in the &lt;em&gt;Guardian&lt;/em&gt; a year ago explained why the date 14 January was chosen:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; The date was chosen since it is both the day G&amp;ouml;del died, in 1978, and the day the logician Alfred Tarski was born, in 1901. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
The article gives a wonderful puzzle by Smullyan that illustrates G&amp;ouml;del&amp;#8217;s first incompleteness theorem. &lt;/p&gt;
&lt;p&gt;
The world day was &lt;a href=&quot;https://unesdoc.unesco.org/ark:/48223/pf0000371483&quot;&gt;proclaimed&lt;/a&gt; by UNESCO in November 2019. The Director-General of UNESCO since 2017 is Audrey Azoulay.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/01/25/why-study-logic/unesco/&quot; rel=&quot;attachment wp-att-20955&quot;&gt;&lt;img data-attachment-id=&quot;20955&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/01/25/why-study-logic/unesco/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/unesco.jpeg?fit=177%2C200&amp;amp;ssl=1&quot; data-orig-size=&quot;177,200&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;1&amp;quot;}&quot; data-image-title=&quot;unesco&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/unesco.jpeg?fit=177%2C200&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/unesco.jpeg?fit=177%2C200&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/unesco.jpeg?resize=177%2C200&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;177&quot; height=&quot;200&quot; class=&quot;aligncenter size-full wp-image-20955&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
A reason why she is a perfect spokesperson for logic emerges on her Wikipedia &lt;a href=&quot;https://en.wikipedia.org/wiki/Audrey_Azoulay&quot;&gt;page&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Her father, Andr&amp;eacute; Azoulay, is the current advisor to King Mohammed VI of Morocco, having previously been the advisor to his predecessor Hassan II from 1991 to 1999. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
It is clear that her father wears several hats. Whether she had to deal with knights who tell the truth and knaves who lie in the royal palaces of her childhood is immaterial, as she doubtless encountered plenty of both in her prior career in politics. She gave further remarks at the first &lt;a href=&quot;https://en.unesco.org/commemorations/worldlogicday/2020&quot;&gt;observance&lt;/a&gt;, in January 2020:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; &amp;#8220;In the twenty-first century&amp;#8212;indeed, now more than ever&amp;#8212;the discipline of logic is a particularly timely one, utterly vital to our societies and economies. Computer science and information and communications technology, for example, are rooted in logical and algorithmic reasoning.&amp;#8221; &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
The 2020 World Logic Day really was marked by &lt;a href=&quot;http://www.logica-universalis.org/wld2&quot;&gt;events&lt;/a&gt; around the world. Here is a rundown on what happened earlier this month, in &lt;a href=&quot;https://nationaltoday.com/world-logic-day/&quot;&gt;2023&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Open Problems &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
So why is logic important? What do you say?&lt;/p&gt;
&lt;p&gt;
The &lt;a href=&quot;https://www.thoughtco.com/good-reasons-to-study-logic-2670416&quot;&gt;article&lt;/a&gt; linked under &amp;#8220;why study logic?&amp;#8221; in our intro illustrates its 5 reasons with some weirdly-chosen photographs. One with a woman under her car hood while her toddler son watches has more going on&amp;#8212;with matching colors and all&amp;#8212;than the paragraph relates. Two other photos are of a scarecrow and Spock wielding a giant Vulcan shovel. Our &amp;#8220;meta&amp;#8221; logic puzzle is, what was the author thinking?&lt;/p&gt;
&lt;p&gt;
&lt;p class=&quot;authors&quot;&gt;By RJLipton+KWRegan&lt;/p&gt;
  </content>
    <author>
      <name>Richard Lipton</name>
      <uri>https://rjlipton.wpcomstaging.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: A Useful Inequality for the Binary Entropy Function</title>
    <link href="http://arxiv.org/abs/2301.09664"/>
    <id>http://arxiv.org/abs/2301.09664</id>
    <updated>2023-01-25T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Boppana_R/0/1/0/all/0/1&quot;&gt;Ravi B. Boppana&lt;/a&gt; (MIT)&lt;/p&gt;&lt;p&gt;We provide a simple proof of a curious inequality for the binary entropy
function, an inequality that has been used in two different contexts. In the
1980&#39;s, Boppana used this entropy inequality to prove lower bounds on Boolean
formulas. More recently, the inequality was used to achieve major progress on
Frankl&#39;s union-closed sets conjecture. Our proof of the entropy inequality uses
basic differential calculus.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Restricted optimal pebbling is NP-hard</title>
    <link href="http://arxiv.org/abs/2301.09867"/>
    <id>http://arxiv.org/abs/2301.09867</id>
    <updated>2023-01-25T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Papp_L/0/1/0/all/0/1&quot;&gt;L&amp;#xe1;szl&amp;#xf3; F. Papp&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Consider a distribution of pebbles on a graph. A pebbling move removes two
pebbles from a vertex and place one at an adjacent vertex. A vertex is
reachable under a pebble distribution if it has a pebble after the application
of a sequence of pebbling moves. A pebble distribution is solvable if each
vertex is reachable under it. The size of a pebble distribution is the total
number of pebbles. The optimal pebbling number $\pi^*(G)$ is the size of the
smallest solvable distribution. A $t$-restricted pebble distribution places at
most $t$ pebbles at each vertex. The $t$-restricted optimal pebbling number
$\pi_t^*(G)$ is the size of the smallest solvable $t$-restricted pebble
distribution. We show that deciding whether $\pi^*_2(G)\leq k$ is NP-complete.
We prove that $\pi_t^*(G)=\pi^*(G)$ if $\delta(G)\geq \frac{2|V(G)|}{3}-1$ and
we show infinitely many graphs which satisfies $\delta(H)\approx
\frac{1}{2}|V(H)|$ but $\pi_t^*(H)\neq\pi^*(H)$, where $\delta$ denotes the
minimum degree.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Word-Mappings of level $3$</title>
    <link href="http://arxiv.org/abs/2301.09966"/>
    <id>http://arxiv.org/abs/2301.09966</id>
    <updated>2023-01-25T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Senizergues_G/0/1/0/all/0/1&quot;&gt;G. S&amp;#xe9;nizergues&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Sequences of numbers (either natural integers, or integers or rational) of
level $k \in \mathbb{N}$ have been defined in \cite{Fra05,Fra-Sen06} as the
sequences which can be computed by deterministic pushdown automata of level
$k$. This definition has been extended to sequences of {\em words} indexed by
{\em words} in \cite{Sen07,Fer-Mar-Sen14}. We characterise here the sequences
of level 3 as the compositions of two HDT0L-systems. Two applications are
derived:
&lt;/p&gt;
&lt;p&gt;- the sequences of rational numbers of level 3 are characterised by
polynomial recurrences
&lt;/p&gt;
&lt;p&gt;- the equality problem for sequences of rational numbers of level 3 is
decidable.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Treewidth is NP-Complete on Cubic Graphs (and related results)</title>
    <link href="http://arxiv.org/abs/2301.10031"/>
    <id>http://arxiv.org/abs/2301.10031</id>
    <updated>2023-01-25T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bodlaender_H/0/1/0/all/0/1&quot;&gt;Hans L. Bodlaender&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonnet_E/0/1/0/all/0/1&quot;&gt;&amp;#xc9;douard Bonnet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaffke_L/0/1/0/all/0/1&quot;&gt;Lars Jaffke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knop_D/0/1/0/all/0/1&quot;&gt;Du&amp;#x161;an Knop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lima_P/0/1/0/all/0/1&quot;&gt;Paloma T. Lima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milanic_M/0/1/0/all/0/1&quot;&gt;Martin Milani&amp;#x10d;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ordyniak_S/0/1/0/all/0/1&quot;&gt;Sebastian Ordyniak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pandey_S/0/1/0/all/0/1&quot;&gt;Sukanya Pandey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suchy_O/0/1/0/all/0/1&quot;&gt;Ond&amp;#x159;ej Such&amp;#xfd;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we give a very simple proof that Treewidth is NP-complete;
this proof also shows NP-completeness on the class of co-bipartite graphs. We
then improve the result by Bodlaender and Thilikos from 1997 that Treewidth is
NP-complete on graphs with maximum degree at most 9, by showing that Treewidth
is NP-complete on cubic graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improved Pseudorandom Generators for $\mathsf{AC}^0$ Circuits</title>
    <link href="http://arxiv.org/abs/2301.10102"/>
    <id>http://arxiv.org/abs/2301.10102</id>
    <updated>2023-01-25T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1&quot;&gt;Xin Lyu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show a new PRG construction fooling depth-$d$, size-$m$ $\mathsf{AC}^0$
circuits within error $\varepsilon$, which has seed length
$O(\log^{d-1}(m)\log(m/\varepsilon)\log\log(m))$. Our PRG improves on previous
work (Trevisan and Xue 2013, Servedio and Tan 2019, Kelley 2021) from various
aspects. It has optimal dependence on $\frac{1}{\varepsilon}$ and is only one
``$\log\log(m)$&#39;&#39; away from the lower bound barrier. For the case of $d=2$, the
seed length tightly matches the best-known PRG for CNFs (De et al. 2010, Tal
2017).
&lt;/p&gt;
&lt;p&gt;There are two technical ingredients behind our new result; both of them might
be of independent interest. First, we use a partitioning-based approach to
construct PRGs based on restriction lemmas for $\mathsf{AC}^0$, which follows
and extends the seminal work of (Ajtai and Wigderson 1989). Second, improving
and extending prior works (Trevisan and Xue 2013, Servedio and Tan 2019, Kelley
2021), we prove a full derandomization of the powerful multi-switching lemma
for a family of DNFs (H{\aa}stad 2014).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Balanced Allocations with Heterogeneous Bins: The Power of Memory</title>
    <link href="http://arxiv.org/abs/2301.09810"/>
    <id>http://arxiv.org/abs/2301.09810</id>
    <updated>2023-01-25T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Los_D/0/1/0/all/0/1&quot;&gt;Dimitrios Los&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sauerwald_T/0/1/0/all/0/1&quot;&gt;Thomas Sauerwald&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sylvester_J/0/1/0/all/0/1&quot;&gt;John Sylvester&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the allocation of $m$ balls (jobs) into $n$ bins (servers). In
the standard Two-Choice process, at each step $t=1,2,\ldots,m$ we first sample
two bins uniformly at random and place a ball in the least loaded bin. It is
well-known that for any $m \geq n$, this results in a gap (difference between
the maximum and average load) of $\log_2 \log n + \Theta(1)$ (with high
probability). In this work, we consider the Memory process [Mitzenmacher,
Prabhakar and Shah 2002] where instead of two choices, we only sample one bin
per step but we have access to a cache which can store the location of one bin.
Mitzenmacher, Prabhakar and Shah showed that in the lightly loaded case ($m =
n$), the Memory process achieves a gap of $\mathcal{O}(\log \log n)$.
&lt;/p&gt;
&lt;p&gt;Extending the setting of Mitzenmacher et al. in two ways, we first allow the
number of balls $m$ to be arbitrary, which includes the challenging heavily
loaded case where $m \geq n$. Secondly, we follow the heterogeneous bins model
of Wieder [Wieder 2007], where the sampling distribution of bins can be biased
up to some arbitrary multiplicative constant. Somewhat surprisingly, we prove
that even in this setting, the Memory process still achieves an
$\mathcal{O}(\log \log n)$ gap bound. This is in stark contrast with the
Two-Choice (or any $d$-Choice with $d=\mathcal{O}(1)$) process, where it is
known that the gap diverges as $m \rightarrow \infty$ [Wieder 2007]. Further,
we show that for any sampling distribution independent of $m$ (but possibly
dependent on $n$) the Memory process has a gap that can be bounded
independently of $m$. Finally, we prove a tight gap bound of $\mathcal{O}(\log
n)$ for Memory in another relaxed setting with heterogeneous (weighted) balls
and a cache which can only be maintained for two steps.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Distinct Elements in Streams: An Algorithm for the (Text) Book</title>
    <link href="http://arxiv.org/abs/2301.10191"/>
    <id>http://arxiv.org/abs/2301.10191</id>
    <updated>2023-01-25T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1&quot;&gt;Sourav Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinodchandran_N/0/1/0/all/0/1&quot;&gt;N.V. Vinodchandran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meel_K/0/1/0/all/0/1&quot;&gt;Kuldeep S. Meel&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a data stream $\mathcal{D} = \langle a_1, a_2, \ldots, a_m \rangle$ of
$m$ elements where each $a_i \in [n]$, the Distinct Elements problem is to
estimate the number of distinct elements in $\mathcal{D}$.
&lt;/p&gt;
&lt;p&gt;Distinct Elements has been a subject of theoretical and empirical
investigations over the past four decades resulting in space optimal algorithms
for it.
&lt;/p&gt;
&lt;p&gt;All the current state-of-the-art algorithms are, however, beyond the reach of
an undergraduate textbook owing to their reliance on the usage of notions such
as pairwise independence and universal hash functions. We present a simple,
intuitive, sampling-based space-efficient algorithm whose description and the
proof are accessible to undergraduates with the knowledge of basic probability
theory.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Postdoc at Bocconi University (apply by January 31, 2023)</title>
    <link href="https://cstheory-jobs.org/2023/01/24/postdoc-at-bocconi-university-apply-by-january-31-2023/"/>
    <id>http://cstheory-jobs.org/2023/01/24/postdoc-at-bocconi-university-apply-by-january-31-2023/</id>
    <updated>2023-01-24T12:53:56+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Luca Trevisan is looking for three postdoctoral fellows for the next academic year to work with him at Bocconi on topics such as spectral graph theory, average-case complexity, pseudorandomness and approximation algorithms&lt;/p&gt;
&lt;p&gt;The positions offer an internationally competitive salary (up to 65,000 Euro per year, tax-free, plus relocation assistance and travel allowance), in a wonderful location.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://lucatrevisan.wordpress.com/2022/12/19/postdoc-positions-for-2023-24/&quot;&gt;https://lucatrevisan.wordpress.com/2022/12/19/postdoc-positions-for-2023-24/&lt;/a&gt;&lt;br /&gt;
Email: l.trevisan@unibocconi.it&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: New Insights into Multi-Calibration</title>
    <link href="http://arxiv.org/abs/2301.08837"/>
    <id>http://arxiv.org/abs/2301.08837</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dwork_C/0/1/0/all/0/1&quot;&gt;Cynthia Dwork&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Daniel Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Huijia Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tankala_P/0/1/0/all/0/1&quot;&gt;Pranay Tankala&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We identify a novel connection between the recent literature on multi-group
fairness for prediction algorithms and well-established notions of graph
regularity from extremal graph theory. We frame our investigation using new,
statistical distance-based variants of multi-calibration that are closely
related to the concept of outcome indistinguishability. Adopting this
perspective leads us naturally not only to our graph theoretic results, but
also to new multi-calibration algorithms with improved complexity in certain
parameter regimes, and to a generalization of a state-of-the-art result on
omniprediction. Along the way, we also unify several prior algorithms for
achieving multi-group fairness, as well as their analyses, through the lens of
no-regret learning.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Diversity of Answers to Conjunctive Queries</title>
    <link href="http://arxiv.org/abs/2301.08848"/>
    <id>http://arxiv.org/abs/2301.08848</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merkl_T/0/1/0/all/0/1&quot;&gt;Timo Camillo Merkl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pichler_R/0/1/0/all/0/1&quot;&gt;Reinhard Pichler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skritek_S/0/1/0/all/0/1&quot;&gt;Sebastian Skritek&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Enumeration problems aim at outputting, without repetition, the set of
solutions to a given problem instance. However, outputting the entire solution
set may be prohibitively expensive if it is too big. In this case, outputting a
small, sufficiently diverse subset of the solutions would be preferable. This
leads to the Diverse-version of the original enumeration problem, where the
goal is to achieve a certain level d of diversity by selecting k solutions. In
this paper, we look at the Diverse-version of the query answering problem for
Conjunctive Queries and extensions thereof. That is, we study the problem if it
is possible to achieve a certain level d of diversity by selecting k answers to
the given query and, in the positive case, to actually compute such k answers.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: On the (Im)plausibility of Public-Key Quantum Money from Collision-Resistant Hash Functions</title>
    <link href="http://arxiv.org/abs/2301.09236"/>
    <id>http://arxiv.org/abs/2301.09236</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ananth_P/0/1/0/all/0/1&quot;&gt;Prabhanjan Ananth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zihan Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yuen_H/0/1/0/all/0/1&quot;&gt;Henry Yuen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Public-key quantum money is a cryptographic proposal for using highly
entangled quantum states as currency that is publicly verifiable yet resistant
to counterfeiting due to the laws of physics. Despite significant interest,
constructing provably-secure public-key quantum money schemes based on standard
cryptographic assumptions has remained an elusive goal. Even proposing
plausibly-secure candidate schemes has been a challenge.
&lt;/p&gt;
&lt;p&gt;These difficulties call for a deeper and systematic study of the structure of
public-key quantum money schemes and the assumptions they can be based on.
Motivated by this, we present the first black-box separation of quantum money
and cryptographic primitives. Specifically, we show that collision-resistant
hash functions cannot be used as a black-box to construct public-key quantum
money schemes where the banknote verification makes classical queries to the
hash function. Our result involves a novel combination of state synthesis
techniques from quantum complexity theory and simulation techniques, including
Zhandry&#39;s compressed oracle technique.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: The Identity Problem in the special affine group of $\mathbb{Z}^2$</title>
    <link href="http://arxiv.org/abs/2301.09502"/>
    <id>http://arxiv.org/abs/2301.09502</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dong_R/0/1/0/all/0/1&quot;&gt;Ruiwen Dong&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider semigroup algorithmic problems in the Special Affine group
$\mathsf{SA}(2, \mathbb{Z}) = \mathbb{Z}^2 \rtimes \mathsf{SL}(2, \mathbb{Z})$,
which is the group of affine transformations of the lattice $\mathbb{Z}^2$ that
preserve orientation. Our paper focuses on two decision problems introduced by
Choffrut and Karhum\&quot;{a}ki (2005): the Identity Problem (does a semigroup
contain a neutral element?) and the Group Problem (is a semigroup a group?) for
finitely generated sub-semigroups of $\mathsf{SA}(2, \mathbb{Z})$. We show that
both problems are decidable and NP-complete. Since $\mathsf{SL}(2, \mathbb{Z})
\leq \mathsf{SA}(2, \mathbb{Z}) \leq \mathsf{SL}(3, \mathbb{Z})$, our result
extends that of Bell, Hirvensalo and Potapov (SODA 2017) on the NP-completeness
of both problems in $\mathsf{SL}(2, \mathbb{Z})$, and contributes a first step
towards the open problems in $\mathsf{SL}(3, \mathbb{Z})$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Splitting Plane Graphs to Outerplanarity</title>
    <link href="http://arxiv.org/abs/2301.09440"/>
    <id>http://arxiv.org/abs/2301.09440</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gronemann_M/0/1/0/all/0/1&quot;&gt;Martin Gronemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nollenburg_M/0/1/0/all/0/1&quot;&gt;Martin N&amp;#xf6;llenburg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villedieu_A/0/1/0/all/0/1&quot;&gt;Ana&amp;#xef;s Villedieu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Vertex splitting replaces a vertex by two copies and partitions its incident
edges amongst the copies. This problem has been studied as a graph editing
operation to achieve desired properties with as few splits as possible, most
often planarity, for which the problem is NP-hard. Here we study how to
minimize the number of splits to turn a plane graph into an outerplane one. We
tackle this problem by establishing a direct connection between splitting a
plane graph to outerplanarity, finding a connected face cover, and finding a
feedback vertex set in its dual. We prove NP-completeness for plane biconnected
graphs, while we show that a polynomial-time algorithm exists for maximal
planar graphs. Finally, we provide upper and lower bounds for certain families
of maximal planar graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improved Hardness of Approximation for Geometric Bin Packing</title>
    <link href="http://arxiv.org/abs/2301.09272"/>
    <id>http://arxiv.org/abs/2301.09272</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1&quot;&gt;Arka Ray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sandeep_S/0/1/0/all/0/1&quot;&gt;Sai Sandeep&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Geometric Bin Packing (GBP) problem is a generalization of Bin Packing
where the input is a set of $d$-dimensional rectangles, and the goal is to pack
them into unit $d$-dimensional cubes efficiently. It is NP-Hard to obtain a
PTAS for the problem, even when $d=2$. For general $d$, the best known
approximation algorithm has an approximation guarantee exponential in $d$,
while the best hardness of approximation is still a small constant
inapproximability from the case when $d=2$. In this paper, we show that the
problem cannot be approximated within $d^{1-\epsilon}$ factor unless NP=ZPP.
&lt;/p&gt;
&lt;p&gt;Recently, $d$-dimensional Vector Bin Packing, a closely related problem to
the GBP, was shown to be hard to approximate within $\Omega(\log d)$ when $d$
is a fixed constant, using a notion of Packing Dimension of set families. In
this paper, we introduce a geometric analog of it, the Geometric Packing
Dimension of set families. While we fall short of obtaining similar
inapproximability results for the Geometric Bin Packing problem when $d$ is
fixed, we prove a couple of key properties of the Geometric Packing Dimension
that highlight the difference between Geometric Packing Dimension and Packing
Dimension.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Fast likelihood-based change point detection</title>
    <link href="http://arxiv.org/abs/2301.08892"/>
    <id>http://arxiv.org/abs/2301.08892</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tatti_N/0/1/0/all/0/1&quot;&gt;Nikolaj Tatti&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Change point detection plays a fundamental role in many real-world
applications, where the goal is to analyze and monitor the behaviour of a data
stream. In this paper, we study change detection in binary streams. To this
end, we use a likelihood ratio between two models as a measure for indicating
change. The first model is a single bernoulli variable while the second model
divides the stored data in two segments, and models each segment with its own
bernoulli variable. Finding the optimal split can be done in $O(n)$ time, where
$n$ is the number of entries since the last change point. This is too expensive
for large $n$. To combat this we propose an approximation scheme that yields
$(1 - \epsilon)$ approximation in $O(\epsilon^{-1} \log^2 n)$ time. The
speed-up consists of several steps: First we reduce the number of possible
candidates by adopting a known result from segmentation problems. We then show
that for fixed bernoulli parameters we can find the optimal change point in
logarithmic time. Finally, we show how to construct a candidate list of size
$O(\epsilon^{-1} \log n)$ for model parameters. We demonstrate empirically the
approximation quality and the running time of our algorithm, showing that we
can gain a significant speed-up with a minimal average loss in optimality.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Efficient Flow-based Approximation Algorithms for Submodular Hypergraph Partitioning via a Generalized Cut-Matching Game</title>
    <link href="http://arxiv.org/abs/2301.08920"/>
    <id>http://arxiv.org/abs/2301.08920</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ameranis_K/0/1/0/all/0/1&quot;&gt;Konstantinos Ameranis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1&quot;&gt;Antares Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orecchia_L/0/1/0/all/0/1&quot;&gt;Lorenzo Orecchia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tani_E/0/1/0/all/0/1&quot;&gt;Erasmo Tani&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the past 20 years, increasing complexity in real world data has lead to
the study of higher-order data models based on partitioning hypergraphs.
However, hypergraph partitioning admits multiple formulations as hyperedges can
be cut in multiple ways. Building upon a class of hypergraph partitioning
problems introduced by Li &amp;amp; Milenkovic, we study the problem of minimizing
ratio-cut objectives over hypergraphs given by a new class of cut functions,
monotone submodular cut functions (mscf&#39;s), which captures hypergraph expansion
and conductance as special cases.
&lt;/p&gt;
&lt;p&gt;We first define the ratio-cut improvement problem, a family of local
relaxations of the minimum ratio-cut problem. This problem is a natural
extension of the Andersen &amp;amp; Lang cut improvement problem to the hypergraph
setting. We demonstrate the existence of efficient algorithms for approximately
solving this problem. These algorithms run in almost-linear time for the case
of hypergraph expansion, and when the hypergraph rank is at most $O(1)$.
&lt;/p&gt;
&lt;p&gt;Next, we provide an efficient $O(\log n)$-approximation algorithm for finding
the minimum ratio-cut of $G$. We generalize the cut-matching game framework of
Khandekar et. al. to allow for the cut player to play unbalanced cuts, and
matching player to route approximate single-commodity flows. Using this
framework, we bootstrap our algorithms for the ratio-cut improvement problem to
obtain approximation algorithms for minimum ratio-cut problem for all mscf&#39;s.
This also yields the first almost-linear time $O(\log n)$-approximation
algorithms for hypergraph expansion, and constant hypergraph rank.
&lt;/p&gt;
&lt;p&gt;Finally, we extend a result of Louis &amp;amp; Makarychev to a broader set of
objective functions by giving a polynomial time $O\big(\sqrt{\log
n}\big)$-approximation algorithm for the minimum ratio-cut problem based on
rounding $\ell_2^2$-metric embeddings.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Statistically Optimal Robust Mean and Covariance Estimation for Anisotropic Gaussians</title>
    <link href="http://arxiv.org/abs/2301.09024"/>
    <id>http://arxiv.org/abs/2301.09024</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Minasyan_A/0/1/0/all/0/1&quot;&gt;Arshak Minasyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhivotovskiy_N/0/1/0/all/0/1&quot;&gt;Nikita Zhivotovskiy&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Assume that $X_{1}, \ldots, X_{N}$ is an $\varepsilon$-contaminated sample of
$N$ independent Gaussian vectors in $\mathbb{R}^d$ with mean $\mu$ and
covariance $\Sigma$. In the strong $\varepsilon$-contamination model we assume
that the adversary replaced an $\varepsilon$ fraction of vectors in the
original Gaussian sample by any other vectors. We show that there is an
estimator $\widehat \mu$ of the mean satisfying, with probability at least $1 -
\delta$, a bound of the form \[ \|\widehat{\mu} - \mu\|_2 \le
c\left(\sqrt{\frac{\operatorname{Tr}(\Sigma)}{N}} +
\sqrt{\frac{\|\Sigma\|\log(1/\delta)}{N}} +
\varepsilon\sqrt{\|\Sigma\|}\right), \] where $c &amp;gt; 0$ is an absolute constant
and $\|\Sigma\|$ denotes the operator norm of $\Sigma$. In the same
contaminated Gaussian setup, we construct an estimator $\widehat \Sigma$ of the
covariance matrix $\Sigma$ that satisfies, with probability at least $1 -
\delta$, \[ \left\|\widehat{\Sigma} - \Sigma\right\| \le
c\left(\sqrt{\frac{\|\Sigma\|\operatorname{Tr}(\Sigma)}{N}} +
\|\Sigma\|\sqrt{\frac{\log(1/\delta)}{N}} + \varepsilon\|\Sigma\|\right). \]
Both results are optimal up to multiplicative constant factors. Despite the
recent significant interest in robust statistics, achieving both dimension-free
bounds in the canonical Gaussian case remained open. In fact, several
previously known results were either dimension-dependent and required $\Sigma$
to be close to identity, or had a sub-optimal dependence on the contamination
level $\varepsilon$.
&lt;/p&gt;
&lt;p&gt;As a part of the analysis, we derive sharp concentration inequalities for
central order statistics of Gaussian, folded normal, and chi-squared
distributions.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A graph isomorphism invariant based on neighborhood aggregation</title>
    <link href="http://arxiv.org/abs/2301.09187"/>
    <id>http://arxiv.org/abs/2301.09187</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Juttner_A/0/1/0/all/0/1&quot;&gt;Alp&amp;#xe1;r J&amp;#xfc;ttner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madarasi_P/0/1/0/all/0/1&quot;&gt;P&amp;#xe9;ter Madarasi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper presents a new graph isomorphism invariant, called
$\mathfrak{w}$-labeling, that can be used to design a polynomial-time algorithm
for solving the graph isomorphism problem for various graph classes. For
example, all non-cospectral graph pairs are distinguished by the proposed
combinatorial method, furthermore, even non-isomorphic cospectral graphs can be
distinguished assuming certain properties of their eigenspaces.
&lt;/p&gt;
&lt;p&gt;We also investigate a refinement of the aforementioned labeling, called
$\mathfrak{s}^k$-labeling, which has both theoretical and practical
applications. Among others, it can be used to generate graph fingerprints,
which uniquely identify all graphs in the considered databases, including all
strongly regular graphs on at most 64 nodes and all graphs on at most 12 nodes.
It provably identifies all trees and 3-connected planar graphs up to
isomorphism, which -- as a byproduct -- gives a new isomorphism algorithm for
both graph classes. The practical importance of this fingerprint lies in
significantly speeding up searching in graph databases, which is a commonly
required task in biological and chemical applications.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Relaxed Models for Adversarial Streaming: The Advice Model and the Bounded Interruptions Model</title>
    <link href="http://arxiv.org/abs/2301.09203"/>
    <id>http://arxiv.org/abs/2301.09203</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadigurschi_M/0/1/0/all/0/1&quot;&gt;Menachem Sadigurschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shechner_M/0/1/0/all/0/1&quot;&gt;Moshe Shechner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1&quot;&gt;Uri Stemmer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Streaming algorithms are typically analyzed in the oblivious setting, where
we assume that the input stream is fixed in advance. Recently, there is a
growing interest in designing adversarially robust streaming algorithms that
must maintain utility even when the input stream is chosen adaptively and
adversarially as the execution progresses. While several fascinating results
are known for the adversarial setting, in general, it comes at a very high cost
in terms of the required space. Motivated by this, in this work we set out to
explore intermediate models that allow us to interpolate between the oblivious
and the adversarial models. Specifically, we put forward the following two
models:
&lt;/p&gt;
&lt;p&gt;(1) *The advice model*, in which the streaming algorithm may occasionally ask
for one bit of advice.
&lt;/p&gt;
&lt;p&gt;(2) *The bounded interruptions model*, in which we assume that the adversary
is only partially adaptive.
&lt;/p&gt;
&lt;p&gt;We present both positive and negative results for each of these two models.
In particular, we present generic reductions from each of these models to the
oblivious model. This allows us to design robust algorithms with significantly
improved space complexity compared to what is known in the plain adversarial
model.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Multiplicative Auction Algorithm for Approximate Maximum Weight Bipartite Matching</title>
    <link href="http://arxiv.org/abs/2301.09217"/>
    <id>http://arxiv.org/abs/2301.09217</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1&quot;&gt;Da Wei Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1&quot;&gt;Monika Henzinger&lt;/a&gt;&lt;/p&gt;&lt;p&gt;$\newcommand{\eps}{\varepsilon}$ We present an \emph{auction algorithm} using
multiplicative instead of constant weight updates to compute a
$(1-\eps)$-approximate maximum weight matching (MWM) in a bipartite graph with
$n$ vertices and $m$ edges in time $O(m\eps^{-1}\log(\eps^{-1}))$, matching the
running time of the linear-time approximation algorithm of Duan and Pettie
[JACM &#39;14]. Our algorithm is very simple and it can be extended to give a
dynamic data structure that maintains a $(1-\eps)$-approximate maximum weight
matching under (1) edge deletions in amortized $O(\eps^{-1}\log(\eps^{-1}))$
time and (2) one-sided vertex insertions. If all edges incident to an inserted
vertex are given in sorted weight the amortized time is
$O(\eps^{-1}\log(\eps^{-1}))$ per inserted edge. If the inserted incident edges
are not sorted, the amortized time per inserted edge increases by an additive
term of $O(\log n)$. The fastest prior dynamic $(1-\eps)$-approximate algorithm
in weighted graphs took time $O(\sqrt{m}\eps^{-1}\log (w_{max}))$ per updated
edge, where the edge weights lie in the range $[1,w_{max}]$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improved Approximation Algorithm for Minimum-Weight $(1,m)$--Connected Dominating Set</title>
    <link href="http://arxiv.org/abs/2301.09247"/>
    <id>http://arxiv.org/abs/2301.09247</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jiao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ran_Y/0/1/0/all/0/1&quot;&gt;Yingli Ran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Shaojie Tang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The classical minimum connected dominating set (MinCDS) problem aims to find
a minimum-size subset of connected nodes in a network such that every other
node has at least one neighbor in the subset. This problem is drawing
considerable attention in the field of wireless sensor networks because
connected dominating sets can serve as virtual backbones of such networks.
Considering fault-tolerance, researchers developed the minimum $k$-connected
$m$-fold CDS (Min$(k,m)$CDS) problem. Many studies have been conducted on
MinCDSs, especially those in unit disk graphs. However, for the minimum-weight
CDS (MinWCDS) problem in general graphs, algorithms with guaranteed
approximation ratios are rare. Guha and Khuller designed a
$(1.35+\varepsilon)\ln n$-approximation algorithm for MinWCDS, where $n$ is the
number of nodes. In this paper, we improved the approximation ratio to
$2H(\delta_{\max}+m-1)$ for MinW$(1,m)$CDS, where $\delta_{\max}$ is the
maximum degree of the graph.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Approximating Knapsack and Partition via Dense Subset Sums</title>
    <link href="http://arxiv.org/abs/2301.09333"/>
    <id>http://arxiv.org/abs/2301.09333</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_M/0/1/0/all/0/1&quot;&gt;Mingyang Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1&quot;&gt;Ce Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1&quot;&gt;Xiao Mao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Knapsack and Partition are two important additive problems whose fine-grained
complexities in the $(1-\varepsilon)$-approximation setting are not yet
settled. In this work, we make progress on both problems by giving improved
algorithms.
&lt;/p&gt;
&lt;p&gt;- Knapsack can be $(1 - \varepsilon)$-approximated in $\tilde O(n +
(1/\varepsilon) ^ {2.2} )$ time, improving the previous $\tilde O(n +
(1/\varepsilon) ^ {2.25} )$ by Jin (ICALP&#39;19). There is a known conditional
lower bound of $(n+\varepsilon)^{2-o(1)}$ based on $(\min,+)$-convolution
hypothesis.
&lt;/p&gt;
&lt;p&gt;- Partition can be $(1 - \varepsilon)$-approximated in $\tilde O(n +
(1/\varepsilon) ^ {1.25} )$ time, improving the previous $\tilde O(n +
(1/\varepsilon) ^ {1.5} )$ by Bringmann and Nakos (SODA&#39;21). There is a known
conditional lower bound of $(1/\varepsilon)^{1-o(1)}$ based on Strong
Exponential Time Hypothesis.
&lt;/p&gt;
&lt;p&gt;Both of our new algorithms apply the additive combinatorial results on dense
subset sums by Galil and Margalit (SICOMP&#39;91), Bringmann and Wellnitz
(SODA&#39;21). Such techniques have not been explored in the context of Knapsack
prior to our work. In addition, we design several new methods to speed up the
divide-and-conquer steps which naturally arise in solving additive problems.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A New Dynamic Programming Approach for Spanning Trees with Chain Constraints and Beyond</title>
    <link href="http://arxiv.org/abs/2301.09340"/>
    <id>http://arxiv.org/abs/2301.09340</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagele_M/0/1/0/all/0/1&quot;&gt;Martin N&amp;#xe4;gele&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zenklusen_R/0/1/0/all/0/1&quot;&gt;Rico Zenklusen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Short spanning trees subject to additional constraints are important building
blocks in various approximation algorithms. Especially in the context of the
Traveling Salesman Problem (TSP), new techniques for finding spanning trees
with well-defined properties have been crucial in recent progress. We consider
the problem of finding a spanning tree subject to constraints on the edges in
cuts forming a laminar family of small width. Our main contribution is a new
dynamic programming approach where the value of a table entry does not only
depend on the values of previous table entries, as it is usually the case, but
also on a specific representative solution saved together with each table
entry. This allows for handling a broad range of constraint types.
&lt;/p&gt;
&lt;p&gt;In combination with other techniques -- including negatively correlated
rounding and a polyhedral approach that, in the problems we consider, allows
for avoiding potential losses in the objective through the randomized rounding
-- we obtain several new results. We first present a quasi-polynomial time
algorithm for the Minimum Chain-Constrained Spanning Tree Problem with an
essentially optimal guarantee. More precisely, each chain constraint is
violated by a factor of at most $1+\varepsilon$, and the cost is no larger than
that of an optimal solution not violating any chain constraint. The best
previous procedure is a bicriteria approximation violating each chain
constraint by up to a constant factor and losing another factor in the
objective. Moreover, our approach can naturally handle lower bounds on the
chain constraints, and it can be extended to constraints on cuts forming a
laminar family of constant width.
&lt;/p&gt;
&lt;p&gt;Furthermore, we show how our approach can also handle parity constraints (or,
more precisely, a proxy thereof) as used in the context of (Path) TSP and one
of its generalizations, and discuss implications in this context.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Sliding Window String Indexing in Streams</title>
    <link href="http://arxiv.org/abs/2301.09477"/>
    <id>http://arxiv.org/abs/2301.09477</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bille_P/0/1/0/all/0/1&quot;&gt;Philip Bille&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_J/0/1/0/all/0/1&quot;&gt;Johannes Fischer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gortz_I/0/1/0/all/0/1&quot;&gt;Inge Li G&amp;#xf8;rtz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedersen_M/0/1/0/all/0/1&quot;&gt;Max Rish&amp;#xf8;j Pedersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stordalen_T/0/1/0/all/0/1&quot;&gt;Tord Joakim Stordalen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a string $S$ over an alphabet $\Sigma$, the &#39;string indexing problem&#39;
is to preprocess $S$ to subsequently support efficient pattern matching
queries, i.e., given a pattern string $P$ report all the occurrences of $P$ in
$S$. In this paper we study the &#39;streaming sliding window string indexing
problem&#39;. Here the string $S$ arrives as a stream, one character at a time, and
the goal is to maintain an index of the last $w$ characters, called the
&#39;window&#39;, for a specified parameter $w$. At any point in time a pattern
matching query for a pattern $P$ may arrive, also streamed one character at a
time, and all occurrences of $P$ within the current window must be returned.
The streaming sliding window string indexing problem naturally captures
scenarios where we want to index the most recent data (i.e. the window) of a
stream while supporting efficient pattern matching.
&lt;/p&gt;
&lt;p&gt;Our main result is a simple $O(w)$ space data structure that uses $O(\log w)$
time with high probability to process each character from both the input string
$S$ and the pattern string $P$. Reporting each occurrence from $P$ uses
additional constant time per reported occurrence. Compared to previous work in
similar scenarios this result is the first to achieve an efficient worst-case
time per character from the input stream. We also consider a delayed variant of
the problem, where a query may be answered at any point within the next
$\delta$ characters that arrive from either stream. We present an $O(w +
\delta)$ space data structure for this problem that improves the above time
bounds to $O(\log(w/\delta))$. In particular, for a delay of $\delta = \epsilon
w$ we obtain an $O(w)$ space data structure with constant time processing per
character. The key idea to achieve our result is a novel and simple
hierarchical structure of suffix trees of independent interest, inspired by the
classic log-structured merge trees.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A New Approach to Learning Linear Dynamical Systems</title>
    <link href="http://arxiv.org/abs/2301.09519"/>
    <id>http://arxiv.org/abs/2301.09519</id>
    <updated>2023-01-24T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bakshi_A/0/1/0/all/0/1&quot;&gt;Ainesh Bakshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liu_A/0/1/0/all/0/1&quot;&gt;Allen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Moitra_A/0/1/0/all/0/1&quot;&gt;Ankur Moitra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yau_M/0/1/0/all/0/1&quot;&gt;Morris Yau&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Linear dynamical systems are the foundational statistical model upon which
control theory is built. Both the celebrated Kalman filter and the linear
quadratic regulator require knowledge of the system dynamics to provide
analytic guarantees. Naturally, learning the dynamics of a linear dynamical
system from linear measurements has been intensively studied since Rudolph
Kalman&#39;s pioneering work in the 1960&#39;s. Towards these ends, we provide the
first polynomial time algorithm for learning a linear dynamical system from a
polynomial length trajectory up to polynomial error in the system parameters
under essentially minimal assumptions: observability, controllability, and
marginal stability. Our algorithm is built on a method of moments estimator to
directly estimate Markov parameters from which the dynamics can be extracted.
Furthermore, we provide statistical lower bounds when our observability and
controllability assumptions are violated.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Gil Kalai: The Trifference Problem</title>
    <link href="https://gilkalai.wordpress.com/2023/01/24/the-trifference-problem/"/>
    <id>http://gilkalai.wordpress.com/2023/01/24/the-trifference-problem/</id>
    <updated>2023-01-23T22:20:42+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;div class=&quot;wpcom-reblog-snapshot&quot;&gt;&lt;div class=&quot;reblogger-note&quot;&gt;&lt;div class=&#39;reblogger-note-content&#39;&gt;&lt;blockquote&gt;&lt;p&gt;Anurag Bishnoi wrote this beautiful post on a problem going back to a 1988 paper of Körner and Marton, and on a recent lovely paper by Anurag Bishnoi, Jozefien D&amp;#8217;haeseleer, Dion Gijswijt, and Aditya Potukuchi, &lt;a href=&quot;https://arxiv.org/abs/2301.09457&quot;&gt;Blocking sets, minimal codes and trifferent codes&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;reblog-post&quot;&gt;&lt;p class=&quot;reblog-from&quot;&gt;&lt;img alt=&#39;&#39; src=&#39;https://2.gravatar.com/avatar/8e373e9f67476aa095fc58285fda5d5a?s=32&amp;#038;d=identicon&amp;#038;r=PG&#39; class=&#39;avatar avatar-32&#39; height=&#39;32&#39; width=&#39;32&#39; /&gt;&lt;a href=&quot;https://anuragbishnoi.wordpress.com/2023/01/23/the-trifference-problem/&quot;&gt;Anurag&amp;#039;s Math Blog&lt;/a&gt;&lt;/p&gt;&lt;div class=&quot;reblogged-content&quot;&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p class=&quot;has-text-align-center&quot;&gt;What is the largest possible size of a set $latex C$ of ternary strings of length $latex n$, with the property that for any three distinct strings in $latex C$, there is a position where they all differ?&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Let $latex T(n)$ denote this largest size. Trivially, $latex T(1) = 3^1 = 3$, and after some playing around you can perhaps prove that $latex T(2) = 4$ (I encourage you to try it so that you understand the problem). With a bit more effort, and perhaps the help of a computer, you might also be able to show that $latex T(3) = 6$, and $latex T(4) = 9$. For example, here is a set of nine ternary strings showing that $latex T(4) geq 9$: $latex 0000, 0111, 2012, 2201, 2120, 0111, 1012, 1101, 1210$. You should check that for any three strings from these nine, there is at least one position…&lt;/p&gt;
&lt;/div&gt;&lt;p class=&quot;reblog-source&quot;&gt;&lt;a href=&quot;https://anuragbishnoi.wordpress.com/2023/01/23/the-trifference-problem/&quot;&gt;View original post&lt;/a&gt; &lt;span class=&quot;more-words&quot;&gt;872 more words&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;p class=&quot;authors&quot;&gt;By Gil Kalai&lt;/p&gt;
  </content>
    <author>
      <name>Gil Kalai</name>
      <uri>https://gilkalai.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">David Eppstein: Doubled planar drawings of doubled planar graphs</title>
    <link href="https://11011110.github.io/blog/2023/01/23/doubled-planar-drawings.html"/>
    <id>https://11011110.github.io/blog/2023/01/23/doubled-planar-drawings</id>
    <updated>2023-01-23T18:17:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;If you start with a planar graph, and make two copies of each vertex, you should be able to draw the result as two planar graphs, right? But it’s more complicated than just copying a drawing of your starting graph, because you get four copies of each edge, and you have to put them all somewhere.&lt;/p&gt;

&lt;p&gt;For instance, the graph \(K_{2,2,2}\) is planar (it’s the graph of an octahedron). Doubling it gives \(K_{4,4,4}\). And \(K_{4,4,4}\) can indeed be drawn as two planar graphs, but not as two octahedra. Here it is as two octagonal bipyramids:&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;/blog/assets/2023/bipyramidal-K444.svg&quot; alt=&quot;The complete tripartite graph K_{4,4,4} drawn as  the union of two octagonal bipyramids&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And here it is drawn as two planar graphs in a different way:&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;/blog/assets/2023/nested-quad-K444.svg&quot; alt=&quot;Another drawing of the complete tripartite graph K_{4,4,4} as the union of two planar graphs&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Drawings like this, where a nonplanar graph is presented as the union of two planar graphs, are called &lt;em&gt;biplanar&lt;/em&gt;. Another word for the same idea is &lt;em&gt;thickness&lt;/em&gt;: the thickness of a graph is the number of planar subgraphs needed to cover all of its edges, and a graph is biplanar if it has thickness two. A famous unsolved problem in graph theory, &lt;a href=&quot;https://en.wikipedia.org/wiki/Earth%E2%80%93Moon_problem&quot;&gt;Ringel’s Earth–Moon problem&lt;/a&gt;, asks how many colors are necessary to color biplanar graphs. The name comes from the idea that you might want to color a pair of maps of countries that all have space colonies on the Moon, using the same color for each country and its colony. The map of their adjacencies on the Earth gives you one planar graph, and the map of adjacencies between their colonies on the Moon gives you the other.  \(K_{4,4,4}\) is not a very interesting example for this question, because it only needs three colors; some other biplanar graphs need as many as nine. On the other hand, we only know how to prove that twelve colors are always enough, so there’s a pretty big gap. Ellen Gethner published &lt;a href=&quot;https://doi.org/10.1007%2F978-3-319-97686-0_11&quot;&gt;a nice survey on the problem&lt;/a&gt; in 2018, including also some other material on biplanar graphs.&lt;/p&gt;

&lt;p&gt;One of Gethner’s conjectures from that survey is that doubled planar graphs (or as she calls them, 2-blowups) are always biplanar. The conjecture is plausible, because the number of edges is within the right range to be biplanar. If the starting planar graph has \(n\) vertices, it has at most \(3n-6\) edges, and its blowup has \(2n\) vertices and at most \(12n-24\) edges. This is fewer than \(12n-12\), the limit on the number of edges for biplanar graphs with \(2n\) vertices. And for a wide class of planar graphs, even those with the maximum possible number of edges, I can prove that their blowups are indeed biplanar. This works whenever the dual graph can be partitioned into two induced paths. In the original graph, these paths form strips of faces connected end-to-end, and in the biplanar drawing of the blowup they become sequences of nested quadrilaterals. For instance, \(K_{4,4,4}\) is the blowup of the octahedral graph \(K_{2,2,2}\), whose dual graph is a cube, and the cube can be partitioned into two induced paths:&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;/blog/assets/2023/cube-path-partition.svg&quot; alt=&quot;Partition of a cube into two induced paths&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The second of the biplanar drawings of \(K_{4,4,4}\) above comes from this dual induced path partition.&lt;/p&gt;

&lt;p&gt;Despite this positive evidence, the conjecture turns out to be false. My latest preprint, “On the biplanarity of blowups”, &lt;a href=&quot;https://arxiv.org/abs/2301.09246&quot;&gt;arXiv:2301.09246&lt;/a&gt;, constructs counterexamples, planar graphs whose blowups are not biplanar. The general idea of the construction is very similar to one of my earlier papers, on &lt;a href=&quot;/blog/2020/09/01/isosceles-polyhedra.html&quot;&gt;polyhedral graphs that cannot be realized as convex polyhedra with isosceles-triangle faces&lt;/a&gt;. Both papers are based on the construction of a &lt;a href=&quot;https://en.wikipedia.org/wiki/Kleetope&quot;&gt;Kleetope&lt;/a&gt;, a polyhedron formed from another polyhedron by attaching a pyramid to each face.
If you repeat the Kleetope construction, you get a polyhedron enclosed by multiple layers of pyramids, and any drawing or geometric realization of this layered polyhedron also gives you a drawing or realization of the simpler polyhedra underneath those layers.
Each time you layer on more pyramids, any possible biplanar drawing of the result gets more and more constrained, until with enough layers it becomes completely impossible.&lt;/p&gt;

&lt;p&gt;Because not all planar blowups are biplanar, the question arises: which ones are, and which ones aren’t? Is there an efficient algorithm that takes as input a planar graph, produces a biplanar drawing of its blowup if such a drawing exists, and tells you when such a drawing doesn’t exist? I don’t know.&lt;/p&gt;

&lt;p&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109742463628336203&quot;&gt;Discuss on Mastodon&lt;/a&gt;)&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By David Eppstein&lt;/p&gt;
  </content>
    <author>
      <name>David Eppstein</name>
      <uri>https://11011110.github.io/blog/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: The Betty White Award for 2022</title>
    <link href="https://blog.computationalcomplexity.org/2023/01/the-betty-white-award-for-2022.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-8096489251092585014</id>
    <updated>2023-01-23T02:50:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;In Dec 2021 I noted in&amp;nbsp;&lt;a href=&quot;https://blog.computationalcomplexity.org/2022/01/did-betty-white-die-in-2021why-do.html?m=0&quot;&gt;this post&lt;/a&gt;, which was my 1000th post ever (according to Ken Regan, see&amp;nbsp;&lt;a href=&quot;https://blog.computationalcomplexity.org/2022/01/regan-lipton-celebrates-my-1000th-blog.html&quot;&gt;here&lt;/a&gt;) that Betty White had the misfortune of dying on Dec 31, 2021, so AFTER the P&lt;i&gt;eople we said goodbye to in&lt;/i&gt; &lt;i&gt;2021 &lt;/i&gt;articles had already appeared.&amp;nbsp;&lt;/p&gt;&lt;p&gt;That might not be quite right since when she died it was Jan 1 SOMEWHERE in the world. I learned a new phrase- AWE- AnyWhere on Earth.&amp;nbsp; But no, she was not mentioned in the &lt;i&gt;People we said goodbye to&lt;/i&gt; in 2022 articles.&lt;/p&gt;&lt;p&gt;The &lt;i&gt;Betty White award&lt;/i&gt; goes to a celebrity that had the same fate- dying too late in the year to be mentioned in those articles. I had not thought of what criteria I would use if there is more than one option, and indeed, this year there are three candidates that I know of.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Pel%C3%A9&quot;&gt;Pele&lt;/a&gt;&amp;nbsp;was the greatest soccer player of all time.&amp;nbsp; Died Dec 29, 2022, at the age of 82.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Barbara_Walters&quot;&gt;Barbara Walters&lt;/a&gt;&amp;nbsp;was a famous broadcast journalist. Died Dec 30, 2022, at the age of 93.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Pope_Benedict_XVI&quot;&gt;Pope Emeritus  Benedict &lt;/a&gt;&amp;nbsp;was a prior Pope (obviously). Died Dec 31, 2022 at the age of 95. He died at 9:34AM Vatican Time. I do not think he died on Jan 1, 2023 AWE though that would not disqualify him since he surely will not be in the 2023 &lt;i&gt;People we say goodbye to in 2022&amp;nbsp;&lt;/i&gt;articles.&lt;/p&gt;&lt;p&gt;So which one should get the award?&lt;/p&gt;&lt;p&gt;The term&lt;i&gt; famous &lt;/i&gt;means &lt;i&gt;famous when they died. &lt;/i&gt;They were all much more famous some years ago than they are now. I am using &lt;i&gt;famous when they died&lt;/i&gt;&amp;nbsp;as a criteria.&amp;nbsp;&lt;/p&gt;&lt;p&gt;a) I am not sure who is more famous internationally- Pele or Pope Emeritus Benedict. Walters is not famous internationally.&amp;nbsp;&lt;/p&gt;&lt;p&gt;b) Walters is more famous in America. I think Benedict is second, though its hard to tell.&amp;nbsp; Frankly none of the three are that famous in America. Walters was at one time. Fame is fleeting!&lt;/p&gt;&lt;p&gt;c) Benedict died older and later in the year.&lt;/p&gt;&lt;p&gt;d) Of the three, one was prominent in one of worlds largest religions. The others were a broadcast journalist and a former Pope.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Rather than try to find a well defined criteria, I will give it the Betty White award to all three of them.&lt;/p&gt;&lt;p&gt;ADDED LATER: Lance has tweeted a poll so you can vote on who you think should have won the ward. The poll has you vote for one of the three, so you can&#39;t vote for two of the three, or (as I would have done) vote for all three.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Note that&amp;nbsp; Martin Davis avoided being considered for the award since he died on Jan 1, 2023.&amp;nbsp;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By gasarch&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: A Quantum EL Theorem</title>
    <link href="http://arxiv.org/abs/2301.08348"/>
    <id>http://arxiv.org/abs/2301.08348</id>
    <updated>2023-01-23T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1&quot;&gt;Samuel Epstein&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we prove a quantum version of the EL Theorem. It states that
non-exotic projections of large rank must have simple quantum states in their
images. A consequence to this is there is no way to communicate a quantum
source with corresponding large enough von Neumann entropy without using simple
quantum states.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Coresets for Clustering with General Assignment Constraints</title>
    <link href="http://arxiv.org/abs/2301.08460"/>
    <id>http://arxiv.org/abs/2301.08460</id>
    <updated>2023-01-23T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lingxiao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Shaofeng Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xuan Wu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Designing small-sized \emph{coresets}, which approximately preserve the costs
of the solutions for large datasets, has been an important research direction
for the past decade. We consider coreset construction for a variety of general
constrained clustering problems. We significantly extend and generalize the
results of a very recent paper (Braverman et al., FOCS&#39;22), by demonstrating
that the idea of hierarchical uniform sampling (Chen, SICOMP&#39;09; Braverman et
al., FOCS&#39;22) can be applied to efficiently construct coresets for a very
general class of constrained clustering problems with general assignment
constraints, including capacity constraints on cluster centers, and assignment
structure constraints for data points (modeled by a convex body $\mathcal{B})$.
&lt;/p&gt;
&lt;p&gt;Our main theorem shows that a small-sized $\epsilon$-coreset exists as long
as a complexity measure $\mathsf{Lip}(\mathcal{B})$ of the structure
constraint, and the \emph{covering exponent} $\Lambda_\epsilon(\mathcal{X})$
for metric space $(\mathcal{X},d)$ are bounded. The complexity measure
$\mathsf{Lip}(\mathcal{B})$ for convex body $\mathcal{B}$ is the Lipschitz
constant of a certain transportation problem constrained in $\mathcal{B}$,
called \emph{optimal assignment transportation problem}. We prove nontrivial
upper bounds of $\mathsf{Lip}(\mathcal{B})$ for various polytopes, including
the general matroid basis polytopes, and laminar matroid polytopes (with better
bound). As an application of our general theorem, we construct the first
coreset for the fault-tolerant clustering problem (with or without capacity
upper/lower bound) for the above metric spaces, in which the fault-tolerance
requirement is captured by a uniform matroid basis polytope.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Hypercore Decomposition for Non-Fragile Hyperedges: Concepts, Algorithms, Observations, and Applications</title>
    <link href="http://arxiv.org/abs/2301.08440"/>
    <id>http://arxiv.org/abs/2301.08440</id>
    <updated>2023-01-23T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bu_F/0/1/0/all/0/1&quot;&gt;Fanchen Bu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1&quot;&gt;Geon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1&quot;&gt;Kijung Shin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Hypergraphs are a powerful abstraction for modeling high-order relations,
which are ubiquitous in many fields. A hypergraph consists of nodes and
hyperedges (i.e., subsets of nodes); and there have been a number of attempts
to extend the notion of $k$-cores, which proved useful with numerous
applications for pairwise graphs, to hypergraphs. However, the previous
extensions are based on an unrealistic assumption that hyperedges are fragile,
i.e., a high-order relation becomes obsolete as soon as a single member leaves
it.
&lt;/p&gt;
&lt;p&gt;In this work, we propose a new substructure model, called ($k$,
$t$)-hypercore, based on the assumption that high-order relations remain as
long as at least $t$ fraction of the members remain. Specifically, it is
defined as the maximal subhypergraph where (1) every node has degree at least
$k$ in it and (2) at least $t$ fraction of the nodes remain in every hyperedge.
We first prove that, given $t$ (or $k$), finding the ($k$, $t$)-hypercore for
every possible $k$ (or $t$) can be computed in time linear w.r.t the sum of the
sizes of hyperedges. Then, we demonstrate that real-world hypergraphs from the
same domain share similar ($k$, $t$)-hypercore structures, which capture
different perspectives depending on $t$. Lastly, we show the successful
applications of our model in identifying influential nodes, dense
substructures, and vulnerability in hypergraphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Superpolynomial Lower Bounds for Learning Monotone Classes</title>
    <link href="http://arxiv.org/abs/2301.08486"/>
    <id>http://arxiv.org/abs/2301.08486</id>
    <updated>2023-01-23T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bshouty_N/0/1/0/all/0/1&quot;&gt;Nader H. Bshouty&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Koch, Strassle, and Tan [SODA 2023], show that, under the randomized
exponential time hypothesis, there is no distribution-free PAC-learning
algorithm that runs in time $n^{\tilde O(\log\log s)}$ for the classes of
$n$-variable size-$s$ DNF, size-$s$ Decision Tree, and $\log s$-Junta by DNF
(that returns a DNF hypothesis). Assuming a natural conjecture on the hardness
of set cover, they give the lower bound $n^{\Omega(\log s)}$. This matches the
best known upper bound for $n$-variable size-$s$ Decision Tree, and $\log
s$-Junta.
&lt;/p&gt;
&lt;p&gt;In this paper, we give the same lower bounds for PAC-learning of $n$-variable
size-$s$ Monotone DNF, size-$s$ Monotone Decision Tree, and Monotone $\log
s$-Junta by~DNF. This solves the open problem proposed by Koch, Strassle, and
Tan and subsumes the above results.
&lt;/p&gt;
&lt;p&gt;The lower bound holds, even if the learner knows the distribution, can draw a
sample according to the distribution in polynomial time, and can compute the
target function on all the points of the support of the distribution in
polynomial time.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Online Dependent Rounding Schemes</title>
    <link href="http://arxiv.org/abs/2301.08680"/>
    <id>http://arxiv.org/abs/2301.08680</id>
    <updated>2023-01-23T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joseph/0/1/0/all/0/1&quot;&gt;Joseph&lt;/a&gt; (Seffi) &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naor/0/1/0/all/0/1&quot;&gt;Naor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1&quot;&gt;Aravind Srinivasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wajc_D/0/1/0/all/0/1&quot;&gt;David Wajc&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the abstract problem of rounding fractional bipartite $b$-matchings
online. The input to the problem is an unknown fractional bipartite
$b$-matching, exposed node-by-node on one side. The objective is to maximize
the \emph{rounding ratio} of the output matching $\mathcal{M}$, which is the
minimum over all fractional $b$-matchings $\mathbf{x}$, and edges $e$, of the
ratio $\Pr[e\in \mathcal{M}]/x_e$. In offline settings, many dependent rounding
schemes achieving a ratio of one and strong negative correlation properties are
known (e.g., Gandhi et al., J.ACM&#39;06 and Chekuri et al., FOCS&#39;10), and have
found numerous applications. Motivated by online applications, we present
\emph{online dependent-rounding schemes} (ODRSes) for $b$-matching.
&lt;/p&gt;
&lt;p&gt;For the special case of uniform matroids (single offline node), we present a
simple online algorithm with a rounding ratio of one. Interestingly, we show
that our algorithm yields \emph{the same distribution} as its classic offline
counterpart, pivotal sampling (Srinivasan, FOCS&#39;01), and so inherits the
latter&#39;s strong correlation properties. In arbitrary bipartite graphs, an
online rounding ratio of one is impossible, and we show that a combination of
our uniform matroid ODRS with repeated invocations of \emph{offline} contention
resolution schemes (CRSes) yields a rounding ratio of $1-1/e\approx 0.632$. Our
main technical contribution is an ODRS breaking this pervasive bound, yielding
rounding ratios of $0.646$ and $0.652$ for $b$-matchings and simple matchings,
respectively. We obtain these results by grouping nodes and using CRSes for
negatively-correlated distributions, together with a new method we call
\emph{group discount and individual markup}, analyzed using the theory of
negative association. We present a number of applications of our ODRSes to
online edge coloring, several stochastic optimization problems, and algorithmic
fairness.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR23-006 |  Superpolynomial Lower Bounds for Learning Monotone Classes | 

	Nader Bshouty</title>
    <link href="https://eccc.weizmann.ac.il/report/2023/006"/>
    <id>https://eccc.weizmann.ac.il/report/2023/006</id>
    <updated>2023-01-22T08:29:45+00:00</updated>
    <content type="html" xml:lang="en">
    Koch, Strassle, and Tan [SODA 2023], show that, under the randomized exponential time hypothesis, there is no distribution-free PAC-learning algorithm that runs in time $n^{\tilde O(\log\log s)}$ for the classes of $n$-variable size-$s$ DNF, size-$s$ Decision Tree, and $\log s$-Junta by DNF (that returns a DNF hypothesis). Assuming a natural conjecture on the hardness of set cover, they give the lower bound $n^{\Omega(\log s)}$. This matches the best known upper bound for $n$-variable size-$s$ Decision Tree, and $\log s$-Junta.

In this paper, we give the same lower bounds for PAC-learning of $n$-variable size-$s$ Monotone DNF, size-$s$ Monotone Decision Tree, and Monotone $\log s$-Junta by~DNF. This solves the open problem proposed by Koch, Strassle, and Tan and subsumes the above results. 

The lower bound holds, even if the learner knows the distribution, can draw a sample according to the distribution in polynomial time, and can compute the target function on all the points of the support of the distribution in polynomial time.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: postdoc at ENS Lyon (apply by February 19, 2023)</title>
    <link href="https://cstheory-jobs.org/2023/01/21/postdoc-at-ens-lyon-apply-by-february-19-2023/"/>
    <id>http://cstheory-jobs.org/2023/01/21/postdoc-at-ens-lyon-apply-by-february-19-2023/</id>
    <updated>2023-01-21T20:48:55+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;All research areas of the LIP laboratory are eligible. Application (CV + publication list + research statement + recommendation letters) to be sent to Nicolas Trotignon and Russ Harmer.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;http://www.ens-lyon.fr/LIP&quot; rel=&quot;nofollow&quot;&gt;http://www.ens-lyon.fr/LIP&lt;/a&gt;&lt;br /&gt;
Email: [russel.harmer,nicolas.trotignon]@ens-lyon.fr&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">TOC for Fairness: FORC 2023 Deadline Approaching</title>
    <link href="https://toc4fairness.org/forc-2023-deadline-approaching/"/>
    <id>https://toc4fairness.org/?p=2538</id>
    <updated>2023-01-21T04:43:45+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The &lt;a href=&quot;https://responsiblecomputing.org/forc-2023/&quot;&gt;4th annual Symposium on Foundations of Responsible Computing&lt;/a&gt; (FORC) will be held on June 7-9, 2023 in Stanford University, CA, USA. The&lt;a href=&quot;https://responsiblecomputing.org/call-for-papers/&quot; data-type=&quot;URL&quot; data-id=&quot;https://responsiblecomputing.org/call-for-papers/&quot;&gt; call for papers&lt;/a&gt; is out and the deadline is nearing: &lt;/p&gt;



&lt;ul&gt;
&lt;li&gt;Paper Registration (title and abstract): Tuesday, Feb 07, 2023.&lt;/li&gt;



&lt;li&gt;Submission Deadline: Thursday, Feb 09, 2023.&lt;/li&gt;



&lt;li&gt;Author Notification: Friday, Mar 31, 2023.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Please consider FORC for your papers on all topics of responsible computing. Best paper awards are awaiting your excellent submissions in the archival track.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Omer Reingold&lt;/p&gt;
  </content>
    <author>
      <name>TOC for Fairness</name>
      <uri>https://toc4fairness.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Postdoc at HSE University (apply by January 31, 2023)</title>
    <link href="https://cstheory-jobs.org/2023/01/20/postdoc-at-hse-university-apply-by-january-31-2023/"/>
    <id>http://cstheory-jobs.org/2023/01/20/postdoc-at-hse-university-apply-by-january-31-2023/</id>
    <updated>2023-01-20T12:24:52+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;HSE University invites applications for the postdoc positions in theoretical ML, complex systems and applied math, algebraic topology and transformation groups, process and pattern mining. Requirements: a recent PhD degree in a relevant field; fluent English; graduates of the research-oriented PhD programme are more preferable.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://iri.hse.ru/announcements/801288859.html&quot;&gt;https://iri.hse.ru/announcements/801288859.html&lt;/a&gt;&lt;br /&gt;
Email: fellowship@hse.ru&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: stateQIP = statePSPACE</title>
    <link href="http://arxiv.org/abs/2301.07730"/>
    <id>http://arxiv.org/abs/2301.07730</id>
    <updated>2023-01-20T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Metger_T/0/1/0/all/0/1&quot;&gt;Tony Metger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yuen_H/0/1/0/all/0/1&quot;&gt;Henry Yuen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Complexity theory traditionally studies the hardness of solving classical
computational problems. In the quantum setting, it is also natural to consider
a different notion of complexity, namely the complexity of physically preparing
a certain quantum state. We study the relation between two such state
complexity classes: statePSPACE, which contains states that can be generated by
space-uniform polynomial-space quantum circuits, and stateQIP, which contains
states that a polynomial-time quantum verifier can generate by interacting with
an all-powerful untrusted quantum prover. The latter class was recently
introduced by Rosenthal and Yuen (ITCS 2022), who proved that statePSPACE
$\subseteq$ stateQIP.
&lt;/p&gt;
&lt;p&gt;Our main result is the reverse inclusion, stateQIP $\subseteq$ statePSPACE,
thereby establishing equality of the two classes and providing a natural
state-complexity analogue to the celebrated QIP = PSPACE theorem of Jain, et
al. (J. ACM 2011). To prove this, we develop a polynomial-space quantum
algorithm for solving exponentially large &quot;PSPACE-computable&quot; semidefinite
programs (SDPs), which also prepares an optimiser encoded in a quantum state.
Our SDP solver relies on recent block-encoding techniques from quantum
algorithms, demonstrating that these techniques are also useful for complexity
theory.
&lt;/p&gt;
&lt;p&gt;Using similar techniques, we also show that optimal prover strategies for
general quantum interactive protocols can be implemented in quantum polynomial
space. We prove this by studying an algorithmic version of Uhlmann&#39;s theorem
and establishing an upper bound on the complexity of implementing Uhlmann
transformations.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Freeze-Tag is NP-Hard in 3D with $L_1$ distance</title>
    <link href="http://arxiv.org/abs/2301.07757"/>
    <id>http://arxiv.org/abs/2301.07757</id>
    <updated>2023-01-20T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_L/0/1/0/all/0/1&quot;&gt;Lucas de Oliveira Silva&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Arkin et al. in 2002 introduced a scheduling-like problem called Freeze-Tag
Problem (FTP) motivated by robot swarm activation. The input consists of the
locations of n mobile punctual robots in some metric space or graph. Only one
begins &quot;active&quot;, while the others are initially &quot;frozen&quot;. All active robots can
move at unit speed and, upon reaching a frozen one&#39;s location, activates it.
The goal is to activate all the robots in the minimum amount of time, the
so-called makespan. Until 2017 the hardness of this problem in metric spaces
was still open, but then Yu et al. proved it to be NP-Hard in the Euclidian
plane, and in the same year, Demaine and Roudoy demonstrated that the FTP is
also hard in 3D with any $L_p$ distance (with p &amp;gt; 1). However, we still don&#39;t
know whether Demaine&#39;s and Roudoy&#39;s result could be translated to the plane.
This paper fills the p=1 gap by showing that the FTP is NP-Hard in 3D with
$L_1$ distance.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: SoftEnNet: Symbiotic Monocular Depth Estimation and Lumen Segmentation for Colonoscopy Endorobots</title>
    <link href="http://arxiv.org/abs/2301.08157"/>
    <id>http://arxiv.org/abs/2301.08157</id>
    <updated>2023-01-20T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mathew_A/0/1/0/all/0/1&quot;&gt;Alwyn Mathew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Magerand_L/0/1/0/all/0/1&quot;&gt;Ludovic Magerand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Trucco_E/0/1/0/all/0/1&quot;&gt;Emanuele Trucco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Manfredi_L/0/1/0/all/0/1&quot;&gt;Luigi Manfredi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Colorectal cancer is the third most common cause of cancer death worldwide.
Optical colonoscopy is the gold standard for detecting colorectal cancer;
however, about 25 percent of polyps are missed during the procedure. A
vision-based autonomous endorobot can improve colonoscopy procedures
significantly through systematic, complete screening of the colonic mucosa. The
reliable robot navigation needed requires a three-dimensional understanding of
the environment and lumen tracking to support autonomous tasks. We propose a
novel multi-task model that simultaneously predicts dense depth and lumen
segmentation with an ensemble of deep networks. The depth estimation
sub-network is trained in a self-supervised fashion guided by view synthesis;
the lumen segmentation sub-network is supervised. The two sub-networks are
interconnected with pathways that enable information exchange and thereby
mutual learning. As the lumen is in the image&#39;s deepest visual space, lumen
segmentation helps with the depth estimation at the farthest location. In turn,
the estimated depth guides the lumen segmentation network as the lumen location
defines the farthest scene location. Unlike other environments, view synthesis
often fails in the colon because of the deformable wall, textureless surface,
specularities, and wide field of view image distortions, all challenges that
our pipeline addresses. We conducted qualitative analysis on a synthetic
dataset and quantitative analysis on a colon training model and real
colonoscopy videos. The experiments show that our model predicts accurate
scale-invariant depth maps and lumen segmentation from colonoscopy images in
near real-time.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improved Tradeoffs for Leader Election</title>
    <link href="http://arxiv.org/abs/2301.08235"/>
    <id>http://arxiv.org/abs/2301.08235</id>
    <updated>2023-01-20T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kutten_S/0/1/0/all/0/1&quot;&gt;Shay Kutten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_P/0/1/0/all/0/1&quot;&gt;Peter Robinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1&quot;&gt;Ming Ming Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xianbin Zhu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider leader election in clique networks, where $n$ nodes are connected
by point-to-point communication links. For the synchronous clique under
simultaneous wake-up, i.e., where all nodes start executing the algorithm in
round $1$, we show a tradeoff between the number of messages and the amount of
time. More specifically, we show that any deterministic algorithm with a
message complexity of $n f(n)$ requires $\Omega\left(\frac{\log n}{\log
f(n)+1}\right)$ rounds, for $f(n) = \Omega(\log n)$. Our result holds even if
the node IDs are chosen from a relatively small set of size $\Theta(n\log n)$,
as we are able to avoid using Ramsey&#39;s theorem. We also give an upper bound
that improves over the previously-best tradeoff. Our second contribution for
the synchronous clique under simultaneous wake-up is to show that $\Omega(n\log
n)$ is in fact a lower bound on the message complexity that holds for any
deterministic algorithm with a termination time $T(n)$. We complement this
result by giving a simple deterministic algorithm that achieves leader election
in sublinear time while sending only $o(n\log n)$ messages, if the ID space is
of at most linear size. We also show that Las Vegas algorithms (that never
fail) require $\Theta(n)$ messages. For the synchronous clique under
adversarial wake-up, we show that $\Omega(n^{3/2})$ is a tight lower bound for
randomized $2$-round algorithms. Finally, we turn our attention to the
asynchronous clique: Assuming adversarial wake-up, we give a randomized
algorithm that achieves a message complexity of $O(n^{1 + 1/k})$ and an
asynchronous time complexity of $k+8$. For simultaneous wake-up, we translate
the deterministic tradeoff algorithm of Afek and Gafni to the asynchronous
model, thus partially answering an open problem they pose.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Emanuele Viola: Mathematics of the impossible: Computational Complexity</title>
    <link href="https://emanueleviola.wordpress.com/2023/01/19/mathematics-of-the-impossible-computational-complexity/"/>
    <id>http://emanueleviola.wordpress.com/?p=1115</id>
    <updated>2023-01-19T19:02:11+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;I am teaching and writing some notes on complexity. I hope they will become a book, so they are organized as such. The notes will be serialized on this blog, and you can find &lt;a href=&quot;https://www.ccs.neu.edu/home/viola/papers/moti.pdf&quot;&gt;the latest version of the book in pdf here&lt;/a&gt;, which has a better rendering of tables, pictures, comic strips, etc.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 class=&quot;sectionHead&quot;&gt;&lt;span class=&quot;titlemark&quot;&gt;0.1   &lt;/span&gt; &lt;a id=&quot;x1-20000.1&quot;&gt;&lt;/a&gt;Conventions, choices, and caveats&lt;/h3&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;I write this section before the work is complete, so some of it may change.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   This book covers basic results in complexity theory and can be used for a course on the subject. At the same time, it is perhaps &lt;em&gt;sui generis&lt;/em&gt; in that it also tells a story of the quest for impossibility results, includes some personal reflections, and makes some non-standard choices about topics and technical details. Some of this is discussed next.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;To test your understanding of the material&amp;#8230;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   this book is interspersed with mistakes, some subtle, some blatant, some not even mistakes but worrying glimpses into the author’s mind. Please send all bug reports and comments to &lt;em&gt;(my five-letter last name)@ccs.neu.edu &lt;/em&gt;to be included in the list of heroes.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;The &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; notation.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   The mathematical symbol &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; has a special meaning in this text. Every &lt;em&gt;occurrence&lt;/em&gt; of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; denotes a real number &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%3E0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%3E0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%3E0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;gt;0&quot; class=&quot;latex&quot; /&gt;. There exist choices for these numbers such that the claims in this book are (or are meant to be) correct. This replaces, is more compact than, and is less prone to abuse than the big-Oh notation (sloppiness hides inside brackets).&lt;/p&gt;
&lt;div class=&quot;newtheorem&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;span class=&quot;head&quot;&gt; &lt;a id=&quot;x1-2001r1&quot;&gt;&lt;/a&gt; &lt;b&gt;Example&lt;/b&gt; 0.1.  &lt;/span&gt;“For all sufficiently large &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;” can be written as &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n%5Cge+c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n%5Cge+c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Cge+c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&amp;#92;ge c&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   “For every &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;epsilon &quot; class=&quot;latex&quot; /&gt; and all sufficiently large &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;” can be written as &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n%5Cge+c_%7B%5Cepsilon+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n%5Cge+c_%7B%5Cepsilon+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Cge+c_%7B%5Cepsilon+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&amp;#92;ge c_{&amp;#92;epsilon }&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   The following are correct statements:&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   “It is an open problem to show that some function in NP requires circuits of size &lt;img src=&quot;https://s0.wp.com/latex.php?latex=cn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=cn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;cn&quot; class=&quot;latex&quot; /&gt;.” At the moment of this writing, one can replace this occurrence with &lt;img src=&quot;https://s0.wp.com/latex.php?latex=5&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=5&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=5&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;5&quot; class=&quot;latex&quot; /&gt;. Note such a claim will remain true if someone proves a &lt;img src=&quot;https://s0.wp.com/latex.php?latex=6n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=6n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=6n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;6n&quot; class=&quot;latex&quot; /&gt; lower bounds. One just needs to “recompile” the constants in this book.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   “&lt;img src=&quot;https://s0.wp.com/latex.php?latex=c%3E1%2Bc&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c%3E1%2Bc&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%3E1%2Bc&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&amp;gt;1+c&quot; class=&quot;latex&quot; /&gt;”, e.g.&amp;nbsp;assign &lt;img src=&quot;https://s0.wp.com/latex.php?latex=2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;2&quot; class=&quot;latex&quot; /&gt; to the first occurrence, &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt; to the second.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   “&lt;img src=&quot;https://s0.wp.com/latex.php?latex=100n%5E%7B15%7D%3Cn%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=100n%5E%7B15%7D%3Cn%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=100n%5E%7B15%7D%3Cn%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;100n^{15}&amp;lt;n^{c}&quot; class=&quot;latex&quot; /&gt;&amp;#8221;, for=&amp;quot;&amp;quot; all=&amp;quot;&amp;quot; large=&amp;quot;&amp;quot; enough=&amp;quot;&amp;quot; &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%22%22+n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%22%22+n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%22%22+n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;quot;&amp;quot; n&quot; class=&quot;latex&quot; /&gt;.=&amp;quot;&amp;quot; assign=&amp;quot;&amp;quot; c=&amp;quot;16$.&amp;quot;
&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   The following are not true:&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   “&lt;img src=&quot;https://s0.wp.com/latex.php?latex=c%3C1%2Fn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c%3C1%2Fn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%3C1%2Fn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&amp;lt;1/n&quot; class=&quot;latex&quot; /&gt; for every &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;”. No matter what we assign &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; to, we can pick a large enough &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;. Note the assignment to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; is absolute, independent of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   More generally, when subscripted this notation indicates a function of the subscript. There exist choices for these functions such that the claims in this book are (or are meant to be) correct. Again, each occurrence can indicate a different function.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   For the reader who prefers the big-Oh notation a quick an dirty fix is to replace every occurrence of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; in this book with &lt;img src=&quot;https://s0.wp.com/latex.php?latex=O%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=O%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;O(1)&quot; class=&quot;latex&quot; /&gt;.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;The alphabet of TMs.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   I define TMs with a fixed alphabet. This choice slightly simplifies the exposition (one parameter vs.&amp;nbsp;two), while being more in line with common experience (it is more common experience to increase the length of a program than its alphabet). This choice affects the proof of Theorem ??. But it isn’t clear that the details are any worse.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Partial vs.&amp;nbsp;total functions (a.k.a.&amp;nbsp;on promise problems).&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;quote&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;Recall that &lt;em&gt;promise problems offer the most direct way of formulating natural       computational problems. [&amp;#8230;]  &lt;/em&gt;In spite of the foregoing opinions, we adopt the       convention of focusing on standard decision and search problems. &lt;em&gt;&lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XGoldreich08Complexity&quot;&gt;2&lt;/a&gt;]&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;I define complexity w.r.t.&amp;nbsp;&lt;em&gt;partial &lt;/em&gt;functions whereas most texts consider &lt;em&gt;total&lt;/em&gt; functions, i.e.&amp;nbsp;we consider computing functions with arbitrary domains rather than any possible string. This is sometimes called “promise problems.” This affects many things, for example the hierarchy for &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {BPTime}&quot; class=&quot;latex&quot; /&gt; (Exercise ??).    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;References and names.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   I decided to keep references in the main text to a minimum, just to avoid having a long list later with items “Result X is due to Y,” but relegate discussion to bibliographic notes. I have also decided to not spell out names of authors, which is increasingly awkward. Central results, such as the PCP theorem, are co-authored by five or more people.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Polynomial.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   It is customary in complexity theory to bound quantities by a polynomial, as in polynomial time, when in fact the only terms that matters is the leading time. This also lends itself to confusion since polynomials with many terms are useful for many other things. I use &lt;em&gt;power&lt;/em&gt; instead of polynomial, as in power time.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Random-access machines.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   “Random access” also leads to strange expressions like “randomized random-access” &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;journals/jcss/AngluinV79&quot;&gt;1&lt;/a&gt;]&lt;/span&gt;.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Reductions.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   Are presented as an implication.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Randomness and circuits.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   While randomness and circuits are everywhere in current research, and seem to be on everyone’s mind, they are sometimes still relegated to later chapters, almost as an afterthought. This book starts with them right away, and attempts to weave them through the narrative.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Data structures&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   Their study, especially negative results, squarely belongs to complexity theory. Yet data structures are strangely omitted in common textbooks. Results on data structures even tend to miss main venues for complexity theory to land instead on more algorithmic venues! We hope this book helps to revert this trend.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Algorithms &amp;amp; Complexity&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   &amp;#8230;are of course two sides of the same coin. The rule of thumb I follow is to present algorithms that are &lt;em&gt;surprising&lt;/em&gt; and &lt;em&gt;challenge our intuition of computation&lt;/em&gt;, and ideally match lower bounds, even though they may not be immediately deployed.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Exercises and problems.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   Exercises are interspersed within the narrative and serve as “concept check.” They are not meant to be difficult or new, though some are. Problems are collected at the end and tend to be harder and more original, though some are not.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Summary of some terminological and not choices.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   Here it is:&lt;/p&gt;
&lt;div class=&quot;tabular&quot;&gt;
&lt;table id=&quot;TBL-2&quot; class=&quot;tabular&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;colgroup id=&quot;TBL-2-1g&quot;&gt;
&lt;col id=&quot;TBL-2-1&quot;/&gt;&lt;/colgroup&gt;
&lt;colgroup id=&quot;TBL-2-2g&quot;&gt;
&lt;col id=&quot;TBL-2-2&quot;/&gt;&lt;/colgroup&gt;
&lt;colgroup id=&quot;TBL-2-3g&quot;&gt;
&lt;col id=&quot;TBL-2-3&quot;/&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-1-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-1-1&quot; class=&quot;td11&quot;&gt;     Some other sources&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-1-2&quot; class=&quot;td11&quot;&gt;          this book&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-1-3&quot; class=&quot;td11&quot;&gt;acronym&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-2-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-2-1&quot; class=&quot;td11&quot;&gt;             &lt;img src=&quot;https://s0.wp.com/latex.php?latex=O%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=O%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;O(1)&quot; class=&quot;latex&quot; /&gt;, &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5COmega+%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5COmega+%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5COmega+%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;Omega (1)&quot; class=&quot;latex&quot; /&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-2-2&quot; class=&quot;td11&quot;&gt;             &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-2-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-3-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-3-1&quot; class=&quot;td11&quot;&gt;       Turing machine&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-3-2&quot; class=&quot;td11&quot;&gt;        tape machine&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-3-3&quot; class=&quot;td11&quot;&gt;  TM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-4-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-4-1&quot; class=&quot;td11&quot;&gt;   random-access machine&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-4-2&quot; class=&quot;td11&quot;&gt;     rapid-access machine&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-4-3&quot; class=&quot;td11&quot;&gt; RAM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-5-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-5-1&quot; class=&quot;td11&quot;&gt;      polynomial time&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-5-2&quot; class=&quot;td11&quot;&gt;         power time&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-5-3&quot; class=&quot;td11&quot;&gt;   P&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-6-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-6-1&quot; class=&quot;td11&quot;&gt;mapping reduction (sometimes)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-6-2&quot; class=&quot;td11&quot;&gt;    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=A&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=A&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;A&quot; class=&quot;latex&quot; /&gt; reduces to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=B&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=B&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;B&quot; class=&quot;latex&quot; /&gt; in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {P}&quot; class=&quot;latex&quot; /&gt; means &lt;img src=&quot;https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D%5CRightarrow+A%5Cin+%5Ctext+%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D%5CRightarrow+A%5Cin+%5Ctext+%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D%5CRightarrow+A%5Cin+%5Ctext+%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;B&amp;#92;in &amp;#92;text {P}&amp;#92;Rightarrow A&amp;#92;in &amp;#92;text {P}&quot; class=&quot;latex&quot; /&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-6-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-7-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-7-1&quot; class=&quot;td11&quot;&gt;Extended Church-Turing thesis&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-7-2&quot; class=&quot;td11&quot;&gt;Power-time computability thesis&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-7-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-8-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-8-1&quot; class=&quot;td11&quot;&gt;    pairwise independent&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-8-2&quot; class=&quot;td11&quot;&gt;      pairwise uniform&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-8-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-9-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-9-1&quot; class=&quot;td11&quot;&gt;       FP, promise-P&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-9-2&quot; class=&quot;td11&quot;&gt;             P&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-9-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-10-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-10-1&quot; class=&quot;td11&quot;&gt;    TM with any alphabet&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-10-2&quot; class=&quot;td11&quot;&gt;   TM with fixed alphabet&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-10-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-11-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-11-1&quot; class=&quot;td11&quot;&gt;  classes have total functions&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-11-2&quot; class=&quot;td11&quot;&gt; classes have partial functions&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-11-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-12-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-12-1&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Copyright 2022-present by Emanuele Viola&lt;/b&gt;&lt;/p&gt;
&lt;h2 class=&quot;chapterHead&quot;&gt;&lt;span class=&quot;titlemark&quot;&gt;Chapter&amp;nbsp;1&lt;/span&gt;&lt;br /&gt;
&lt;a id=&quot;x1-30001&quot;&gt;&lt;/a&gt;A teaser&lt;/h2&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;Consider a computer with &lt;em&gt;three&lt;/em&gt; bits of memory. There’s also a clock, beating &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1%2C2%2C3%2C%5Cldots+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1%2C2%2C3%2C%5Cldots+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%2C2%2C3%2C%5Cldots+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1,2,3,&amp;#92;ldots &quot; class=&quot;latex&quot; /&gt; In one clock cycle the computer can read one bit of the input and update its memory arbitrarily based on the value of the bit and the current memory, or stop and return a value.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   Let’s give a few examples of what such computer can do.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   First, it can compute the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BAnd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BAnd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BAnd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {And}&quot; class=&quot;latex&quot; /&gt; function on &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; bits:&lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;
&lt;div class=&quot;fbox&quot;&gt;
&lt;div class=&quot;minipage&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BComputing+And+of+%28%5Censuremath+%7Bx_%7B1%7D%7D%2C%5Censuremath+%7Bx_%7B2%7D%7D%2C%5Censuremath+%7B%5Cldots+%7D%2C%5Censuremath+%7Bx_%7Bn%7D%7D%29%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BComputing+And+of+%28%5Censuremath+%7Bx_%7B1%7D%7D%2C%5Censuremath+%7Bx_%7B2%7D%7D%2C%5Censuremath+%7B%5Cldots+%7D%2C%5Censuremath+%7Bx_%7Bn%7D%7D%29%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BComputing+And+of+%28%5Censuremath+%7Bx_%7B1%7D%7D%2C%5Censuremath+%7Bx_%7B2%7D%7D%2C%5Censuremath+%7B%5Cldots+%7D%2C%5Censuremath+%7Bx_%7Bn%7D%7D%29%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Computing And of (&amp;#92;ensuremath {x_{1}},&amp;#92;ensuremath {x_{2}},&amp;#92;ensuremath {&amp;#92;ldots },&amp;#92;ensuremath {x_{n}})}&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BFor+%7Di%3D1%2C2%2C%5Cldots+%5Ctext+%7B+until+%7Dn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BFor+%7Di%3D1%2C2%2C%5Cldots+%5Ctext+%7B+until+%7Dn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BFor+%7Di%3D1%2C2%2C%5Cldots+%5Ctext+%7B+until+%7Dn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {For }i=1,2,&amp;#92;ldots &amp;#92;text { until }n&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;  &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BRead+%7Dx_%7Bi%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BRead+%7Dx_%7Bi%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BRead+%7Dx_%7Bi%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Read }x_{i}&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;  If &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x_%7Bi%7D%3D0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=x_%7Bi%7D%3D0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bi%7D%3D0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;x_{i}=0&quot; class=&quot;latex&quot; /&gt; return 0&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BReturn+%7D1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BReturn+%7D1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BReturn+%7D1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Return }1&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   We didn’t really use the memory. Let’s consider a slightly more complicated example. A word is &lt;em&gt;palindrome&lt;/em&gt; if it reads the same both ways, like &lt;em&gt;racecar&lt;/em&gt;, &lt;em&gt;non&lt;/em&gt;, &lt;em&gt;anna, &lt;/em&gt;and so on. Similarly, example of palindrome bit strings are &lt;img src=&quot;https://s0.wp.com/latex.php?latex=11%2C0110&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=11%2C0110&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=11%2C0110&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;11,0110&quot; class=&quot;latex&quot; /&gt;, and so on.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   Let’s show that the computer can decide if a given string is palindrome quickly, in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; steps&lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;
&lt;div class=&quot;fbox&quot;&gt;
&lt;div class=&quot;minipage&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BDeciding+if+%5Censuremath+%7B%28x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D%29%7D+is+palindrome%3A%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BDeciding+if+%5Censuremath+%7B%28x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D%29%7D+is+palindrome%3A%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BDeciding+if+%5Censuremath+%7B%28x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D%29%7D+is+palindrome%3A%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Deciding if &amp;#92;ensuremath {(x_{1},x_{2},&amp;#92;ldots ,x_{n})} is palindrome:}&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BFor+%7Di%3D1%2C2%2C%5Cldots+%5Ctext+%7B+until+%7Di%3En%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BFor+%7Di%3D1%2C2%2C%5Cldots+%5Ctext+%7B+until+%7Di%3En%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BFor+%7Di%3D1%2C2%2C%5Cldots+%5Ctext+%7B+until+%7Di%3En%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {For }i=1,2,&amp;#92;ldots &amp;#92;text { until }i&amp;gt;n/2&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;  &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BRead+%5Censuremath+%7Bx_%7Bi%7D%7D+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BRead+%5Censuremath+%7Bx_%7Bi%7D%7D+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BRead+%5Censuremath+%7Bx_%7Bi%7D%7D+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Read &amp;#92;ensuremath {x_{i}} }&quot; class=&quot;latex&quot; /&gt;and write it in memory bit &lt;img src=&quot;https://s0.wp.com/latex.php?latex=m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;m&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;  If &lt;img src=&quot;https://s0.wp.com/latex.php?latex=m%5Cne+x_%7Bn-i%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=m%5Cne+x_%7Bn-i%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m%5Cne+x_%7Bn-i%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;m&amp;#92;ne x_{n-i}&quot; class=&quot;latex&quot; /&gt; return 0&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BReturn+%7D1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BReturn+%7D1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BReturn+%7D1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Return }1&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   That was easy. Now consider the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BMajority%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BMajority%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BMajority%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Majority}&quot; class=&quot;latex&quot; /&gt; function on &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; bits, which is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt; iff the sum of the input bits is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%3En%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%3En%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%3En%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;gt;n/2&quot; class=&quot;latex&quot; /&gt; and &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt; otherwise. Majority, like any other function on &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; bits, can be computed on such a computer in time &lt;em&gt;exponential&lt;/em&gt; in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;. To do that, you do a pass on the input and check if it’s all zero, using the program for And given above. If it is, return &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;. If it is not, you do another pass now checking if it’s all zero except the last bit is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;. If it is, return &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;. You continue this way until you exhausted all the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;2^{n}/2&quot; class=&quot;latex&quot; /&gt; possible inputs with Majority equals to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;. If you never returned &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt; you can now safely return &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   As we said, this works for any function, but it’s terribly inefficient. Can we do better for Majority? Can we compute it in time which is just a power of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;?&lt;/p&gt;
&lt;div class=&quot;newtheorem&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;span class=&quot;head&quot;&gt; &lt;a id=&quot;x1-3001r1&quot;&gt;&lt;/a&gt; &lt;b&gt;Exercise&lt;/b&gt; 1.1.  &lt;/span&gt;Convince yourself that this is impossible. Hint: If you start counting bits, you’ll soon run out of memory.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   If you solved the exercise, you are not alone.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   And yet, we will see the following shocking result:&lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;span class=&quot;doublebox&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;minipage&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Shocking theorem:&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;Majority can be computed on such a computer in time &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n^{c}&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   And this is not a trick tailored to majority. Many other problems, apparently much more complicated, can also be solved in the same time.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   But, there’s something possibly even more shocking.&lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;span class=&quot;doublebox&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;minipage&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Shocking situation:&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;It is consistent with our state of knowledge that every “textbook algorithm” can be solved in time &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n^{c}&quot; class=&quot;latex&quot; /&gt; on such a computer! Nobody can disprove that. (Textbook algorithms include sorting, maxflow, dynamic programming algorithms like longest common subsequence etc., graph problems, numerical problems, etc.)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   The &lt;b&gt;Shocking theorem &lt;/b&gt;gives some explanation for the &lt;b&gt;Shocking situation&lt;/b&gt;. It will be hard to rule out efficient programs on this model, since they are so powerful and counterintuitive. In fact, we will see later that this can be formalized. Basically, we will show that the model is so strong that it can compute functions that provably escape the reach of current mathematics&amp;#8230; if you believe certain things, like that it’s hard to factor numbers. This now enters some of the &lt;em&gt;mysticism&lt;/em&gt; that surrounds complexity theory, where different beliefs and conjectures are pitted against each other in a battle for ground truth.&lt;/p&gt;
&lt;h3 class=&quot;likesectionHead&quot;&gt;&lt;a id=&quot;x1-40001&quot;&gt;&lt;/a&gt;References&lt;/h3&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;
&lt;div class=&quot;thebibliography&quot;&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt;  [1]&lt;span class=&quot;bibsp&quot;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XDBLP:journals/jcss/AngluinV79&quot;&gt;&lt;/a&gt;Dana Angluin and Leslie&amp;nbsp;G. Valiant.  Fast probabilistic algorithms for hamiltonian    circuits and matchings. J. Comput. Syst. Sci., 18(2):155–193, 1979.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt;  [2]&lt;span class=&quot;bibsp&quot;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XGoldreich08Complexity&quot;&gt;&lt;/a&gt;Oded Goldreich.  Computational Complexity: A Conceptual Perspective.  Cambridge    University Press, 2008.&lt;/p&gt;
&lt;/div&gt;
&lt;p class=&quot;authors&quot;&gt;By Manu&lt;/p&gt;
  </content>
    <author>
      <name>Emanuele Viola</name>
      <uri>https://emanueleviola.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: Meta-Complexity</title>
    <link href="https://blog.computationalcomplexity.org/2023/01/meta-complexity.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-5852987754636111781</id>
    <updated>2023-01-19T14:42:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;I&#39;m sure many of you long-time readers are asking, &quot;Why all this big focus on machine learning in your posts and tweets? You are the &#39;Computational Complexity&#39; blog! You&#39;ve barely said a word about meta-complexity.&quot;&lt;/p&gt;&lt;p&gt;So what is meta-complexity? From what I can tell the term goes back a few years but really came into wide use in computational complexity in the past year. The Computational Complexity Conference held an invited talk on meta-complexity by Rahul Santhanam, and the Simons Institute is hosting a &lt;a href=&quot;https://simons.berkeley.edu/programs/Meta-Complexity2023&quot;&gt;research program&lt;/a&gt; this spring on the topic.&lt;/p&gt;&lt;p&gt;As the name suggests, meta-complexity studies the complexity of computing the complexity of various problems. It&#39;s a term that encompasses recent research into the Minimum Circuit Value Problem (given the truth-table of a Boolean function, find the size of the smallest circuit that computes it) and the complexity of time-bounded Kolmogorov complexity.&amp;nbsp;&lt;/p&gt;&lt;p&gt;To quote from the &lt;a href=&quot;https://simons.berkeley.edu/programs/Meta-Complexity2023&quot;&gt;Simons page&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Meta-complexity provides a unifying framework for a variety of important tasks in several important areas of computer science, including computational complexity, proof complexity, cryptography, and learning theory. These areas are all intimately linked, but only recently are these links being made explicit and studied more closely. For example, learning can be interpreted as solving search versions of the Minimum Circuit Size Problem and related problems. Basing primitives such as one-way functions and indistinguishability obfuscation on standard complexity assumptions is one of the main objectives in theoretical cryptography. Important recent directions involving meta-complexity within proof complexity, such as lifting and automatability, strengthen analogies and connections between proof complexity and circuit complexity. In addition, independence results such as the natural proofs framework have intuitive interpretations in terms of meta-complexity. These connections have led to several recent breakthroughs, including &lt;a href=&quot;https://drops.dagstuhl.de/opus/volltexte/2016/5855/&quot;&gt;quasi-polynomial time PAC-learning algorithms for constant-depth circuits with parity gates&lt;/a&gt;, &lt;a href=&quot;https://doi.org/10.1109/FOCS.2018.00032&quot;&gt;new worst-case to average-case reductions for NP problems&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/2009.11514&quot;&gt;a new complexity-theoretic characterization of one-way functions&lt;/a&gt;, and &lt;a href=&quot;https://arxiv.org/abs/1904.02991&quot;&gt;the NP-hardness of automating resolution&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Not to mention the &lt;a href=&quot;https://blog.computationalcomplexity.org/2022/12/complexity-year-in-review-2022.html&quot;&gt;theorem of the year&lt;/a&gt;,&amp;nbsp;Shuichi Hirahara&#39;s&amp;nbsp;&lt;a href=&quot;https://eccc.weizmann.ac.il/report/2022/119/&quot;&gt;proof&lt;/a&gt; that determining the minimum circuit of a partially specified function is NP-complete.&amp;nbsp;&lt;/p&gt;&lt;p&gt;When you get down to it meta-complexity is all about learning, determining the complexity of finding programs. You cannot escape it.&lt;/p&gt;&lt;p&gt;To dive deeper into meta-complexity check out the &lt;a href=&quot;https://simons.berkeley.edu/workshops/meta-complexity-boot-camp/videos#simons-tabs&quot;&gt;videos&lt;/a&gt; of the Simons meta-complexity bootcamp.&amp;nbsp;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Richard Lipton: Rabin-Scott Time</title>
    <link href="https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/"/>
    <id>https://rjlipton.wpcomstaging.com/?p=20921</id>
    <updated>2023-01-19T07:52:41+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;
&lt;font color=&quot;#0044cc&quot;&gt;&lt;br /&gt;
&lt;em&gt;Nondeterminism&amp;#8212;why did it take so long?&lt;/em&gt;&lt;br /&gt;
&lt;font color=&quot;#000000&quot;&gt;&lt;/p&gt;
&lt;table class=&quot;image alignright&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/rabinscott/&quot; rel=&quot;attachment wp-att-20923&quot;&gt;&lt;img data-attachment-id=&quot;20923&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/rabinscott/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/RabinScott.jpg?fit=332%2C195&amp;amp;ssl=1&quot; data-orig-size=&quot;332,195&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;1&amp;quot;}&quot; data-image-title=&quot;RabinScott&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/RabinScott.jpg?fit=300%2C176&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/RabinScott.jpg?fit=332%2C195&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/RabinScott.jpg?resize=200%2C120&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;200&quot; height=&quot;120&quot; class=&quot;alignright wp-image-20923&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;caption alignright&quot;&gt;&lt;font size=&quot;-2&quot;&gt;2010 interview &lt;a href=&quot;https://cacm.acm.org/magazines/2010/2/69370-an-interview-with-michael-rabin/abstract&quot;&gt;src1&lt;/a&gt;, Society for Science &lt;a href=&quot;https://www.societyforscience.org/alumni/notable/dana-scott/&quot;&gt;src2&lt;/a&gt;&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;
Michael Rabin and Dana Scott won the 1976 Turing Award. They obtained their PhD under Alonzo Church in 1957 and 1958, respectively. They are the only Turing-recognized students of Church&amp;#8212;unless you count Alan Turing himself (1938). &lt;/p&gt;
&lt;p&gt;
Today we talk about their 1959 &lt;a href=&quot;https://www.cse.chalmers.se/~coquand/AUTOMATA/rs.pdf&quot;&gt;paper&lt;/a&gt; &amp;#8220;Finite Automata and Their Decision Problems,&amp;#8221; which was &lt;a href=&quot;https://amturing.acm.org/award_winners/rabin_9681074.cfm&quot;&gt;specifically&lt;/a&gt; &lt;a href=&quot;https://amturing.acm.org/award_winners/scott_1193622.cfm&quot;&gt;cited&lt;/a&gt; in their award.&lt;br /&gt;
&lt;span id=&quot;more-20921&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;
I believe I met each of these other famous students of Church at least once:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
Peter Andrews 1964 &lt;/p&gt;
&lt;li&gt;
Martin Davis 1950 &lt;/p&gt;
&lt;li&gt;
Stephen Kleene 1934 &lt;/p&gt;
&lt;li&gt;
Simon Kochen 1959 &lt;/p&gt;
&lt;li&gt;
Hartley Rogers 1952 &lt;/p&gt;
&lt;li&gt;
Barkley Rosser 1934 &lt;/p&gt;
&lt;li&gt;
Raymond Smullyan 1959
&lt;/ul&gt;
&lt;p&gt;
Of these, &lt;a href=&quot;https://en.wikipedia.org/wiki/Peter_B._Andrews&quot;&gt;Peter&lt;/a&gt; was special to me first: I took a class from him when I was a graduate student at CMU. He was a great lecturer&amp;#8212;I will say more about him soon. &lt;/p&gt;
&lt;p&gt;
Ken and I have just noticed while writing that Martin Davis passed away at the beginning of this month&amp;#8212;see this &lt;a href=&quot;https://www.digitalfieldguide.com/blog/20341&quot;&gt;memorial&lt;/a&gt;. We saw him and Scott speak at the 2012 Turing &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2012/05/17/turings-tiger-birthday-party/&quot;&gt;centennial&lt;/a&gt; event in Princeton. &lt;/p&gt;
&lt;p&gt;
We have mentioned Rabin and Scott together several times on this blog at least in passing, and we said more about Dana&amp;#8217;s work in logic long ago &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2009/05/11/simulation-of-nondeterministic-machines/&quot;&gt;here&lt;/a&gt;. Michael&amp;#8212;I&amp;#8217;m more used to calling him Rabin in writing&amp;#8212;became absolutely central to computational complexity and more besides. He has won just about every award for theory, and we have discussed his work several times: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2009/03/01/rabin-flips-a-coin/&quot;&gt;Rabin Flips a Coin&lt;/a&gt; &lt;/p&gt;
&lt;li&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2011/07/21/rabins-80th-birthday/&quot;&gt;Rabin&amp;#8217;s 80th Birthday&lt;/a&gt; &lt;/p&gt;
&lt;li&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2011/09/05/happy-birthday-michael-rabin/&quot;&gt;Happy Birthday Michael Rabin&lt;/a&gt; &lt;/p&gt;
&lt;li&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2014/03/10/how-to-carry-fame/&quot;&gt;How To Carry Fame&lt;/a&gt;
&lt;/ul&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Talking About Their Paper &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
The Turing award citation says:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; &amp;#8230;for their joint paper &amp;#8220;Finite Automata and Their Decision Problem,&amp;#8221; which introduced the idea of nondeterministic machines, which has proved to be an enormously valuable concept. Their (Scott &amp;amp; Rabin) classic paper has been a continuous source of inspiration for subsequent work in this field. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Whoops&amp;#8212;are we the first to notice the typo of the missing &amp;#8216;s&amp;#8217; from &amp;#8220;Problems&amp;#8221; in the paper title? It is &lt;a href=&quot;https://en.wikipedia.org/wiki/Turing_Award&quot;&gt;reproduced&lt;/a&gt; in Wikipedia&amp;#8217;s version. We have fingered (C)ACM editing &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2022/12/15/a-mutation-carol-2/&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2022/03/26/waiting-for-self-deriving-cars/&quot;&gt;times&lt;/a&gt; &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2021/08/26/great-go-glitchy-grammar/&quot;&gt;recently&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;
Scott&amp;#8217;s Turing Award &lt;a href=&quot;https://amturing.acm.org/award_winners/scott_1193622.cfm&quot;&gt;description&lt;/a&gt; also says:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Computational complexity theory is the study of what is possible to calculate given a specific set of resources &amp;#8230; Scott and Rabin’s concept of nondeterministic machines has proved extremely productive in this research area. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Yet both Rabin and Scott avoided covering the paper in their Turing Award lectures. Scott &lt;a href=&quot;https://dl.acm.org/ft_gateway.cfm?id=1283932&amp;#038;type=pdf&quot;&gt;talked&lt;/a&gt; about his subsequent work on logics for programming. Rabin titled his &lt;a href=&quot;https://dl.acm.org/ft_gateway.cfm?id=1283931&amp;#038;type=pdf&quot;&gt;talk&lt;/a&gt; &amp;#8220;Complexity of Computations.&amp;#8221; This was in accord with what he relates starting from &lt;a href=&quot;https://youtu.be/L3FZzGU3n14?t=2761&quot;&gt;this point&lt;/a&gt; of a 2015 CACM &lt;a href=&quot;https://www.acm.org/turing-award-50/turing-laureate-interviews&quot;&gt;interview&lt;/a&gt; about his Turing Award implicitly also recognizing his 1960 &lt;a href=&quot;https://www.cs.toronto.edu/~sacook/homepage/rabin_thesis.pdf&quot;&gt;paper&lt;/a&gt;, &amp;#8220;Degree of Difficulty of Computing a Function and a Partial Ordering of Recursive Sets.&amp;#8221; However, even in the expanded version of Rabin&amp;#8217;s lecture which CACM published (&lt;a href=&quot;http://rkka21.ru/docs/turing-award/mr1976e.pdf&quot;&gt;searchable copy&lt;/a&gt;), the word &amp;#8220;nondeterministic&amp;#8221; is absent, and &amp;#8220;NP&amp;#8221; is mentioned only as part of &amp;#8220;P = NP&amp;#8221; twice in passing. What gives? &lt;/p&gt;
&lt;p&gt;
One look at the Rabin-Scott &lt;a href=&quot;https://www.cse.chalmers.se/~coquand/AUTOMATA/rs.pdf&quot;&gt;paper&lt;/a&gt; suffices to see that it lives up to the encomium of the CACM&amp;#8217;s preface:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;
&lt;em&gt; [It] has become a classic paper in formal language theory that still forms one of the best introductions to the area. The paper is simultaneously a survey and a research article; it is technically simple and mathematically impeccable. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
The &amp;#8216;survey&amp;#8217; aspect is that the paper includes, organizes, and polishes equally famous work by Kleene, John Myhill, and Anil Nerode, plus building on papers by Edward Moore, Arthur Burks and Hao Wang, and (with mutual rounds of interchange) John Shepherdson. The final paper&amp;#8212;including the results original to Rabin and Scott&amp;#8212;reads like how we teach the automata section of an intro theory course today. The seminal original result to teach is their &lt;a href=&quot;https://en.wikipedia.org/wiki/Powerset_construction&quot;&gt;powerset construction&lt;/a&gt; converting an NFA into an equivalent DFA. Yet some elements are missing, and they may be key to why nondeterminism took so long to formulate.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Time Lapse and a Missing Link? &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
The introduction of nondeterministic machines is often dated to Rabin-Scott in &lt;b&gt;1959&lt;/b&gt;. Yet Kleene&amp;#8217;s famous theorem converting deterministic finite automata (DFAs) into what he termed regular &amp;#8220;events&amp;#8221; dates to &lt;a href=&quot;https://www.rand.org/content/dam/rand/pubs/research_memoranda/2008/RM704.pdf&quot;&gt;1951&lt;/a&gt;. Their equivalence naturally goes through nondeterministic finite automata (NFAs). Were NFAs really unknown to Kleene? Moreover, notions of existentially quantified predicates equivalent to nodeterminism go back even before Turing, as noted in this StackExchange &lt;a href=&quot;https://cstheory.stackexchange.com/questions/32403/who-introduced-nondeterministic-computation&quot;&gt;query&lt;/a&gt; on &amp;#8220;Who introduced nondeterministic computation?&amp;#8221;&lt;/p&gt;
&lt;p&gt;
Some of this apparent 8-year gap is closed by a footnote on the first page of Rabin-Scott:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; &amp;#8220;The bulk of this work was done while the authors were associated with the IBM Research Center during the summer of 1957.&amp;#8221; &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
That shaves off two years. Five more may owe to Kleene&amp;#8217;s report not appearing in final journal form until &lt;a href=&quot;https://www.dlsi.ua.es/~mlf/nnafmc/papers/kleene56representation.pdf&quot;&gt;1956&lt;/a&gt;, when the notation for what he now termed regular &lt;em&gt;expressions&lt;/em&gt; was more polished. But this version still gives nothing near the &amp;#8220;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM+%3D+%28Q%2C%5CSigma%2C%5Cdelta%2Cs%2CF%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M = (Q,&amp;#92;Sigma,&amp;#92;delta,s,F)}&quot; class=&quot;latex&quot; /&gt;&amp;#8221; style of notation which is inchoate in Rabin-Scott. Kleene&amp;#8217;s graphical diagrams are of &lt;em&gt;nerve nets&lt;/em&gt;, as defined in 1944 by Warren McCullogh and Walter Pitts, not state graphs as we represent them now. &lt;/p&gt;
&lt;p&gt;
I&amp;#8212;Ken writing these sections&amp;#8212;still wonder why NFAs were not defined earlier. Current renditions of Kleene&amp;#8217;s Theorem do not care whether a DFA or NFA is given. I speculate the reason is that the most elegant association of NFAs to regular expressions requires what was literally a missing link:&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/epsilonarc/&quot; rel=&quot;attachment wp-att-20924&quot;&gt;&lt;img data-attachment-id=&quot;20924&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/epsilonarc/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/EpsilonArc.png?fit=570%2C160&amp;amp;ssl=1&quot; data-orig-size=&quot;570,160&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;EpsilonArc&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/EpsilonArc.png?fit=300%2C84&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/EpsilonArc.png?fit=570%2C160&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/EpsilonArc.png?resize=200%2C56&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;200&quot; height=&quot;56&quot; class=&quot;aligncenter wp-image-20924&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/EpsilonArc.png?resize=300%2C84&amp;amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/EpsilonArc.png?w=570&amp;amp;ssl=1 570w&quot; sizes=&quot;(max-width: 200px) 100vw, 200px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
Here &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt; stands for the empty string. Thus the arc represents a change of state without stimulus, an idea that is antithetical to nerve nets. I still imagine an alternate history where someone like Charles Peirce, whose electrical diagrams of Boolean logic we noted &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/&quot;&gt;here&lt;/a&gt;, conceived a century earlier of representing the laws of electric circuits symbolically like so:&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/circuitexpressions/&quot; rel=&quot;attachment wp-att-20925&quot;&gt;&lt;img data-attachment-id=&quot;20925&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/circuitexpressions/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/CircuitExpressions.png?fit=1684%2C416&amp;amp;ssl=1&quot; data-orig-size=&quot;1684,416&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;CircuitExpressions&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/CircuitExpressions.png?fit=300%2C74&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/CircuitExpressions.png?fit=600%2C148&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/CircuitExpressions.png?resize=600%2C150&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;150&quot; class=&quot;aligncenter wp-image-20925&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/CircuitExpressions.png?resize=300%2C74&amp;amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/CircuitExpressions.png?zoom=2&amp;amp;resize=600%2C150&amp;amp;ssl=1 1200w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
When the conversion from regular expressions to NFAs was published by Robert McNaughton and Hisao Yamada in &lt;a href=&quot;https://ieeexplore.ieee.org/document/5221603&quot;&gt;1960&lt;/a&gt;, they conditioned their regular expressions into a form that avoided occurrences of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt;. Using &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt; for this conversion has been &lt;a href=&quot;https://en.wikipedia.org/wiki/Thompson&#39;s_construction&quot;&gt;traced&lt;/a&gt; &lt;a href=&quot;https://alexandria.tue.nl/extra1/wskrap/publichtml/9313452.pdf&quot;&gt;back&lt;/a&gt; only to Ken Thompson in &lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/363347.363387&quot;&gt;1968&lt;/a&gt;. That was only a few years before I met this future Turing laureate at the &lt;a href=&quot;https://www.westfieldchessclub.org/&quot;&gt;Westfield Chess Club&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;
In my alternate history, nondeterminism would have seemed natural from forking electrical flow. Instead, as Rabin relates at &lt;a href=&quot;https://youtu.be/L3FZzGU3n14?t=2294&quot;&gt;this point&lt;/a&gt; in his 2015 interview, he and Scott felt they needed to start from a limited form of a Turing machine, the full model then seeming unapproachable. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; &amp;#8220;So we had the model of what are called finite automata and then we decided, as pure exercises for imagination, to consider all possible variations. One of those variations was nondeterministic automata.&amp;#8221; &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Their other variations allowed two-way heads or multiple tapes. In my telling, nondeterminism might have been regarded not as a &amp;#8220;variation&amp;#8221; but as &lt;em&gt;more&lt;/em&gt; fundamental than determinism. Going back to Rabin-Scott and forward again to Thompson and his co-workers at Bell Labs, this is what I argue next.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Nondeterminism is Fundamental &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
A text by John Martin makes the joke that understanding tuple notation like &amp;#8220;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM+%3D+%28Q%2C%5CSigma%2C%5Cdelta%2Cs%2CF%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M = (Q,&amp;#92;Sigma,&amp;#92;delta,s,F)}&quot; class=&quot;latex&quot; /&gt;&amp;#8221; is a sign of being a mathematician. I turn it around and say it&amp;#8217;s really a sign of being an object-oriented programmer:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&lt;br /&gt;
class FA {&lt;br /&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;set&amp;lt;State&amp;gt; Q;&lt;br /&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;set&amp;lt;char&amp;gt; Sigma;&lt;br /&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;State s;&lt;br /&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;set&amp;lt;State&amp;gt; F;&lt;br /&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;...&lt;br /&gt;
}&lt;br /&gt;
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;
I continue by saying that if you were to define &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;delta}&quot; class=&quot;latex&quot; /&gt; as a method via &lt;tt&gt;State delta(State q, char c)&lt;/tt&gt; then you would be stuck with the same method body for each machine instance. This issue can be fixed by making &lt;tt&gt;delta&lt;/tt&gt; a function pointer (or &amp;#8220;delegate&amp;#8221; in terms of the programming language C#), but I hold it more natural to make &lt;tt&gt;delta&lt;/tt&gt; a &lt;tt&gt;set&lt;/tt&gt; of triples of type &lt;tt&gt;(State,char,State)&lt;/tt&gt; instead, which I call &lt;em&gt;instructions&lt;/em&gt;. This notation naturally defines an NFA. Then the machine is deterministic (i.e., a DFA) when for all states &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p}&quot; class=&quot;latex&quot; /&gt; and characters &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{c}&quot; class=&quot;latex&quot; /&gt; there is exactly one &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{q}&quot; class=&quot;latex&quot; /&gt; such that &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%28p%2Cc%2Cq%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{(p,c,q)}&quot; class=&quot;latex&quot; /&gt; is an instruction. I then ask the students,&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Which is the base class, &lt;b&gt;DFA&lt;/b&gt; or &lt;b&gt;NFA&lt;/b&gt;? &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Insofar as automata once created are immutable, the answer is &lt;b&gt;NFA&lt;/b&gt;: A DFA &amp;#8220;Is-A&amp;#8221; NFA that obeys the logical constraint on the set of instructions. In this rendition, NFA is the simpler and more fundamental concept.  It remains so after allowing triples of type &lt;tt&gt;(State,&amp;epsilon;,State)&lt;/tt&gt; too.&lt;/p&gt;
&lt;p&gt;
Later in the course I plump nondeterminism over determinism in other ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
The widest expanse of interesting computational problems are complete in NP, not in P. &lt;/p&gt;
&lt;li&gt;
Many of the problems we put into P&amp;#8212;including some decision problems in the Rabin-Scott paper&amp;#8212;are really complete for nondeterministic logspace. &lt;/p&gt;
&lt;li&gt;
The canonical simulation via breadth-first search goes from &lt;em&gt;nondeterministic&lt;/em&gt; space to deterministic time, and depth-first search takes one from &lt;em&gt;nondeterministic&lt;/em&gt; time to deterministic space. Nondeterministic machines are the necessary givens. &lt;/p&gt;
&lt;li&gt;
Nondeterministic/existential forms of classes often have more characterizations and closure properties. &lt;/p&gt;
&lt;li&gt;
Hadamard gates are nondeterministic; quantum circuits using only Pauli and permutation gates (CNOT, Toffoli, &amp;#8230;) can do classical logic only.
&lt;/ul&gt;
&lt;p&gt;
But the main point I make right away is about &lt;b&gt;succinctness&lt;/b&gt;: NFAs are not only usually smaller and more readable than their equivalent DFAs, they are often &lt;em&gt;more workable&lt;/em&gt;. To exemplify this, I offer two ways of deciding whether a given string &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{x}&quot; class=&quot;latex&quot; /&gt; matches a given regular expression &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Br%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{r}&quot; class=&quot;latex&quot; /&gt;: After converting &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Br%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{r}&quot; class=&quot;latex&quot; /&gt; into an equivalent NFA &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N}&quot; class=&quot;latex&quot; /&gt; via Thompson&amp;#8217;s algorithm diagrammed above, one can either&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
Convert &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N}&quot; class=&quot;latex&quot; /&gt; into an equivalent DFA &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M}&quot; class=&quot;latex&quot; /&gt; and simply run &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M}&quot; class=&quot;latex&quot; /&gt; on &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{x}&quot; class=&quot;latex&quot; /&gt;; or &lt;/p&gt;
&lt;li&gt;
Simulate &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N}&quot; class=&quot;latex&quot; /&gt; on &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bx+%3D+x_1+x_2+%5Ccdots+x_n%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{x = x_1 x_2 &amp;#92;cdots x_n}&quot; class=&quot;latex&quot; /&gt; by updating the set &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_%7Bi-1%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_{i-1}}&quot; class=&quot;latex&quot; /&gt; of possible states before &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{x_i}&quot; class=&quot;latex&quot; /&gt; is read to &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_i%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_i}&quot; class=&quot;latex&quot; /&gt; after &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{x_i}&quot; class=&quot;latex&quot; /&gt; is &amp;#8220;processed,&amp;#8221; as in the guts of the proof of the Rabin-Scott construction.
&lt;/ol&gt;
&lt;p&gt;
I give the examples &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Br_k+%3D+%280+%5Ccup+1%29%5E%2A+1+%280+%5Ccup+1%29%5E%7Bk-1%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{r_k = (0 &amp;#92;cup 1)^* 1 (0 &amp;#92;cup 1)^{k-1}}&quot; class=&quot;latex&quot; /&gt;, which denotes binary strings whose &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k}&quot; class=&quot;latex&quot; /&gt;-th bit from the end is a &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B1%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{1}&quot; class=&quot;latex&quot; /&gt;. Ways I show of economizing on &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt;-arcs yield an NFA &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N_k}&quot; class=&quot;latex&quot; /&gt; with just &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%2B1%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k+1}&quot; class=&quot;latex&quot; /&gt; states. Whereas, the smallest DFA &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M_k}&quot; class=&quot;latex&quot; /&gt; such that &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BL%28M%29+%3D+L%28r_k%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{L(M) = L(r_k)}&quot; class=&quot;latex&quot; /&gt; has &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B2%5Ek%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{2^k}&quot; class=&quot;latex&quot; /&gt; states&amp;#8212;as we prove via Myhill and Nerode&amp;#8217;s theorems (using the latter as given in the survey part of Rabin-Scott). &lt;/p&gt;
&lt;p&gt;
Thus, method 1 involves exponential time in worst case, while method 2 works in time polynomial in &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{n}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k}&quot; class=&quot;latex&quot; /&gt;. Method 2 is essentially the algorithm designed by Thompson and co-workers. This is the first example in the course of the contrast between exponential and polynomial times for the same problem. I show how the NFAs &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N_k}&quot; class=&quot;latex&quot; /&gt; capture the logic of the problem, whereas the DFAs &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M_k}&quot; class=&quot;latex&quot; /&gt; look like a twisty mess even for &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%3D3%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k=3}&quot; class=&quot;latex&quot; /&gt;. Showing a diagram of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM_3%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M_3}&quot; class=&quot;latex&quot; /&gt; or a partial sketch of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM_4%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M_4}&quot; class=&quot;latex&quot; /&gt;, I ask:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Would nature ever do this? &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
This aims to say: the NFA is often &lt;em&gt;more real&lt;/em&gt; than the equivalent DFA.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Open Problems &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Would Rabin or Scott go this far? We could ask them&amp;#8230; We note, however, that the word &amp;#8220;deterministic&amp;#8221;&amp;#8212;to say nothing of &amp;#8220;nondeterministic&amp;#8221; and their other word forms&amp;#8212;is absent from this wonderful list of &lt;a href=&quot;http://www.eecs.harvard.edu/~cat/rabinisms.html&quot;&gt;quotes&lt;/a&gt; from Rabin&amp;#8217;s classes, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
This is trivial, but not obvious. (Fall 1996) &lt;/p&gt;
&lt;li&gt;
If P = NP, then all of modern cryptography collapses. On this happy thought&amp;#8230; (Fall 1998) &lt;/p&gt;
&lt;li&gt;
Zero plus zero is still zero, even in this advanced class. (Spring 2002) &lt;/p&gt;
&lt;li&gt;
It is customary for a student and teacher to be on first name basis once the student gets his Ph.D. Personally I found it difficult to address Church as &amp;#8220;Alonzo&amp;#8221;, but I managed. So let us do it. (Spring 2008)
&lt;/ul&gt;
&lt;p&gt;
We have been talking about people over age 90 and this is true of both Rabin and Scott&amp;#8212;and Nerode. We wish them &lt;a href=&quot;https://en.wikipedia.org/wiki/Sto_lat&quot;&gt;sto lat&lt;/a&gt;&amp;#8212;but at this point, could that traditional long-life wish be an underestimate? &lt;/p&gt;
&lt;p&gt;
&lt;p class=&quot;authors&quot;&gt;By RJLipton+KWRegan&lt;/p&gt;
  </content>
    <author>
      <name>Richard Lipton</name>
      <uri>https://rjlipton.wpcomstaging.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Polynomial-Time Axioms of Choice and Polynomial-Time Cardinality</title>
    <link href="http://arxiv.org/abs/2301.07123"/>
    <id>http://arxiv.org/abs/2301.07123</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grochow_J/0/1/0/all/0/1&quot;&gt;Joshua A. Grochow&lt;/a&gt;&lt;/p&gt;&lt;p&gt;There is no single canonical polynomial-time version of the Axiom of Choice
(AC); several statements of AC that are equivalent in Zermelo-Fraenkel (ZF) set
theory are already inequivalent from a constructive point of view, and are
similarly inequivalent from a complexity-theoretic point of view. In this paper
we show that many classical formulations of AC, when restricted to polynomial
time in natural ways, are equivalent to standard complexity-theoretic
hypotheses, including several that were of interest to Selman. This provides a
unified view of these hypotheses, and we hope provides additional motivation
for studying some of the lesser-known hypotheses that appear here.
&lt;/p&gt;
&lt;p&gt;Additionally, because several classical forms of AC are formulated in terms
of cardinals, we develop a theory of polynomial-time cardinality. Nerode &amp;amp;
Remmel (Contemp. Math. 106, 1990 and Springer Lec. Notes Math. 1432, 1990)
developed a related theory, but restricted to unary sets. Downey (Math. Reviews
MR1071525) suggested that such a theory over larger alphabets could have
interesting connections to more standard complexity questions, and we
illustrate some of those connections here.
&lt;/p&gt;
&lt;p&gt;The connections between AC, cardinality, and complexity questions also allow
us to highlight some of Selman&#39;s work. We hope this paper is more of a
beginning than an end, introducing new concepts and raising many new questions,
ripe for further research.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Pseudorandom Generators for Sliding-Window Algorithms</title>
    <link href="http://arxiv.org/abs/2301.07384"/>
    <id>http://arxiv.org/abs/2301.07384</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Modanese_A/0/1/0/all/0/1&quot;&gt;Augusto Modanese&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A sliding-window algorithm of window size $t$ is an algorithm whose current
operation depends solely on the last $t$ symbols read. We construct
pseudorandom generators (PRGs) for low-space randomized sliding-window
algorithms that have access to a binary randomness source. More specifically,
we lift these algorithms to the non-uniform setting of branching programs and
study them as a subclass thereof that we call sliding-window branching programs
(SWBPs), accordingly. For general SWBPs, given a base PRG $G_\mathrm{base}$
with seed length $d_\mathrm{base}$ that $\varepsilon_\mathrm{base}$-fools
width-$w$, length-$t$ (general) branching programs, we give two PRG
constructions for fooling any same-width SWBP of length $n$ and window size $t$
(where we assume $w \ge n$). The first uses an additional $d_\mathrm{base} +
O(\log(n/t) \log(1/\varepsilon_\mathrm{base}))$ random bits, whereas the second
has a seed length of $O((d_\mathrm{base} + \log\log(n/t) +
\log(1/\varepsilon_\mathrm{base})) \log(d_\mathrm{base} +
\log(1/\varepsilon_\mathrm{base})))$. Both PRGs incur only a $(n/2t)^{O(1)}$
multiplicative loss in the error parameter.
&lt;/p&gt;
&lt;p&gt;As an application, we show how to decide the language of a sublinear-time
probabilistic cellular automaton using small space. More specifically, these
results target the model of PACAs, which are probabilistic cellular automata
that accept if and only if all cells are simultaneously accepting. For
(sublinear) $T(n) = \Omega(\log n)^{1.01}$, we prove that every language
accepted by a $T$-time one-sided error PACA (the PACA equivalent of
$\mathsf{RP}$) can be decided using only $O(T)$ space. Meanwhile, forgoing the
previous requirement on $T$, we show the same holds for $T$-time two-sided
error PACA (the PACA equivalent of $\mathsf{BPP}$) if we use $\tilde{O}(T) +
O(\log n)$ space instead (where the $\tilde{O}$ notation hides only
$\mathsf{polylog}(T)$ factors).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: A New Construction of the Vietoris-Rips Complex</title>
    <link href="http://arxiv.org/abs/2301.07191"/>
    <id>http://arxiv.org/abs/2301.07191</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Rieser_A/0/1/0/all/0/1&quot;&gt;Antonio Rieser&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present a new, inductive construction of the Vietoris-Rips complex, in
which we take advantage of a small amount of unexploited combinatorial
structure in the $k$-skeleton of the complex in order to avoid unnecessary
comparisons when identifying its $(k+1)$-simplices. In doing so, we achieve an
order-of-magnitude speedup over current algorithms when constructing the clique
complexes of Erd\H{o}s-R\&#39;enyi graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: A Note on the $k$-colored Crossing Ratio of Dense Geometric Graphs</title>
    <link href="http://arxiv.org/abs/2301.07261"/>
    <id>http://arxiv.org/abs/2301.07261</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fabila_Monroy_R/0/1/0/all/0/1&quot;&gt;Ruy Fabila-Monroy&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A \emph{geometric graph} is a graph whose vertex set is a set of points in
general position in the plane, and its edges are straight line segments joining
these points. We show that for every integer $k \ge 2$, there exists a constat
$c&amp;gt;0$ such that the following holds. The edges of every dense geometric graph
can be colored with $k$ colors, such that the number of pairs of edges of the
same color that cross is at most $(1/k-c)$ times the total number of pairs of
edges that cross. The case when $k=2$ and $G$ is a complete geometric graph,
was proved by Aichholzer et al.[\emph{GD} 2019].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Robust Zero-crossings Detection in Noisy Signals using Topological Signal Processing</title>
    <link href="http://arxiv.org/abs/2301.07703"/>
    <id>http://arxiv.org/abs/2301.07703</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanweer_S/0/1/0/all/0/1&quot;&gt;Sunia Tanweer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khasawneh_F/0/1/0/all/0/1&quot;&gt;Firas A. Khasawneh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munch_E/0/1/0/all/0/1&quot;&gt;Elizabeth Munch&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We explore a novel application of zero-dimensional persistent homology from
Topological Data Analysis (TDA) for bracketing zero-crossings of both
one-dimensional continuous functions, and uniformly sampled time series. We
present an algorithm and show its robustness in the presence of noise for a
range of sampling frequencies. In comparison to state-of-the-art software-based
methods for finding zeros of a time series, our method generally converges
faster, provides higher accuracy, and is capable of finding all the roots in a
given interval instead of converging only to one of them. We also present and
compare options for automatically setting the persistence threshold parameter
that influences the accurate bracketing of the roots.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


</feed>
