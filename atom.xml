<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Theory of Computing Report</title>
  <link rel="self" href=""/>
  <link href=""/>
  <id></id>
  <updated></updated>
  <generator uri="http://feedreader.github.io/">Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]</generator>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Finite model theory for pseudovarieties and universal algebra: preservation, definability and complexity</title>
    <link href="http://arxiv.org/abs/2212.02653"/>
    <id>http://arxiv.org/abs/2212.02653</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ham_L/0/1/0/all/0/1&quot;&gt;Lucy Ham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jackson_M/0/1/0/all/0/1&quot;&gt;Marcel Jackson&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We explore new interactions between finite model theory and a number of
classical streams of universal algebra and semigroup theory. After refocussing
some finite model theoretic tools in universal algebraic context, we present a
number of results. A key result is an example of a finite algebra whose variety
is not finitely axiomatisable in first order logic, but which has first order
definable finite membership problem. This algebra witnesses the simultaneous
failure of the {\L}os-Tarski Theorem, the SP-preservation theorem and
Birkhoff&#39;s HSP-preservation theorem at the finite level as well as providing a
negative solution to the first order formulation of the long-standing Eilenberg
Sch\&quot;utzenberger problem. The example also shows that a pseudovariety without
any finite pseudo-identity basis may be finitely axiomatisable in first order
logic. Other results include the undecidability of deciding first order
definability of the pseudovariety of a finite algebra and a mapping from any
fixed template constraint satisfaction problem to a first order equivalent
variety membership problem, thereby providing examples of variety membership
problems complete in each of the classes $\texttt{L}$, $\texttt{NL}$,
$\texttt{Mod}_p(\texttt{L})$, $\texttt{P}$ (provided they are nonempty), and
infinitely many others (depending on complexity-theoretic assumptions).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: On the Size of Chromatic Delaunay Mosaics</title>
    <link href="http://arxiv.org/abs/2212.03121"/>
    <id>http://arxiv.org/abs/2212.03121</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Biswas_R/0/1/0/all/0/1&quot;&gt;Ranita Biswas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Montesano_S/0/1/0/all/0/1&quot;&gt;Sebastiano Cultrera di Montesano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Draganov_O/0/1/0/all/0/1&quot;&gt;Ond&amp;#x159;ej Draganov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Edelsbrunner_H/0/1/0/all/0/1&quot;&gt;Herbert Edelsbrunner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Saghafian_M/0/1/0/all/0/1&quot;&gt;Morteza Saghafian&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a locally finite set $A \subseteq \mathbb{R}^d$ and a coloring $\chi
\colon A \to \{0,1,\ldots,s\}$, we introduce the chromatic Delaunay mosaic of
$\chi$, which is a Delaunay mosaic in $\mathbb{R}^{s+d}$ that represents how
points of different colors mingle. Our main results are bounds on the size of
the chromatic Delaunay mosaic, in which we assume that $d$ and $s$ are
constants. For example, if $A$ is finite with $n = \#{A}$, and the coloring is
random, then the chromatic Delaunay mosaic has $O(n^{\lceil{d/2}\rceil})$ cells
in expectation. In contrast, for Delone sets and Poisson point processes in
$\mathbb{R}^d$, the expected number of cells within a closed ball is only a
constant times the number of points in this ball. Furthermore, in
$\mathbb{R}^2$ all colorings of a dense set of $n$ points have chromatic
Delaunay mosaics of size $O(n)$. This encourages the use of chromatic Delaunay
mosaics in applications.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Persistent Homology of Chromatic Alpha Complexes</title>
    <link href="http://arxiv.org/abs/2212.03128"/>
    <id>http://arxiv.org/abs/2212.03128</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Montesano_S/0/1/0/all/0/1&quot;&gt;Sebastiano Cultrera di Montesano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Draganov_O/0/1/0/all/0/1&quot;&gt;Ond&amp;#x159;ej Draganov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Edelsbrunner_H/0/1/0/all/0/1&quot;&gt;Herbert Edelsbrunner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Saghafian_M/0/1/0/all/0/1&quot;&gt;Morteza Saghafian&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Motivated by applications in medical sciences, we study finite chromatic sets
in Euclidean space from a topological perspective. Based on persistent homology
for images, kernels and cokernels, we design provably stable homological
quantifiers that describe the geometric micro- and macro-structure of how the
color classes mingle. These can be efficiently computed using chromatic
variants of Delaunay mosaics and Alpha complexes.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improved Approximation Schemes for (Un-)Bounded Subset-Sum and Partition</title>
    <link href="http://arxiv.org/abs/2212.02883"/>
    <id>http://arxiv.org/abs/2212.02883</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lin Chen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the SUBSET SUM problem and its important variants in this paper.
In the SUBSET SUM problem, a (multi-)set $X$ of $n$ positive numbers and a
target number $t$ are given, and the task is to find a subset of $X$ with the
maximal sum that does not exceed $t$. It is well known that this problem is
NP-hard and admits fully polynomial-time approximation schemes (FPTASs). In
recent years, it has been shown that there does not exist an FPTAS of running
time $\tilde\OO( 1/\epsilon^{2-\delta})$ for arbitrary small $\delta&amp;gt;0$
assuming ($\min$,+)-convolution conjecture~\cite{bringmann2021fine}. However,
the lower bound can be bypassed if we relax the constraint such that the task
is to find a subset of $X$ that can slightly exceed the threshold $t$ by
$\epsilon$ times, and the sum of numbers within the subset is at least
$1-\tilde\OO(\epsilon)$ times the optimal objective value that respects the
constraint. Approximation schemes that may violate the constraint are also
known as weak approximation schemes. For the SUBSET SUM problem, there is a
randomized weak approximation scheme running in time $\tilde\OO(n+
1/\epsilon^{5/3})$ [Mucha et al.&#39;19]. For the special case where the target $t$
is half of the summation of all input numbers, weak approximation schemes are
equivalent to approximation schemes that do not violate the constraint, and the
best-known algorithm runs in $\tilde\OO(n+1/\epsilon^{{3}/{2}})$ time
[Bringmann and Nakos&#39;21].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A Strongly Polynomial Algorithm for Approximate Forster Transforms and its Application to Halfspace Learning</title>
    <link href="http://arxiv.org/abs/2212.03008"/>
    <id>http://arxiv.org/abs/2212.03008</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1&quot;&gt;Ilias Diakonikolas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1&quot;&gt;Christos Tzamos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1&quot;&gt;Daniel M. Kane&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Forster transform is a method of regularizing a dataset by placing it in
{\em radial isotropic position} while maintaining some of its essential
properties. Forster transforms have played a key role in a diverse range of
settings spanning computer science and functional analysis. Prior work had
given {\em weakly} polynomial time algorithms for computing Forster transforms,
when they exist. Our main result is the first {\em strongly polynomial time}
algorithm to compute an approximate Forster transform of a given dataset or
certify that no such transformation exists. By leveraging our strongly
polynomial Forster algorithm, we obtain the first strongly polynomial time
algorithm for {\em distribution-free} PAC learning of halfspaces. This learning
result is surprising because {\em proper} PAC learning of halfspaces is {\em
equivalent} to linear programming. Our learning approach extends to give a
strongly polynomial halfspace learner in the presence of random classification
noise and, more generally, Massart noise.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Inapproximability of counting independent sets in linear hypergraphs</title>
    <link href="http://arxiv.org/abs/2212.03072"/>
    <id>http://arxiv.org/abs/2212.03072</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_G/0/1/0/all/0/1&quot;&gt;Guoliang Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiaheng Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;It is shown in this note that approximating the number of independent sets in
a $k$-uniform linear hypergraph with maximum degree at most $\Delta$ is NP-hard
if $\Delta\geq 5\cdot 2^{k-1}+1$. This confirms that for the relevant sampling
and approximate counting problems, the regimes on the maximum degree where the
state-of-the-art algorithms work are tight, up to some small factors. These
algorithms include: the approximate sampler and randomised approximation scheme
by Hermon, Sly and Zhang (2019), the perfect sampler by Qiu, Wang and Zhang
(2022), and the deterministic approximation scheme by Feng, Guo, Wang, Wang and
Yin (2022).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Higher Lower Bounds for Sparse Oblivious Subspace Embeddings</title>
    <link href="http://arxiv.org/abs/2212.02913"/>
    <id>http://arxiv.org/abs/2212.02913</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Mingmou Liu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;An oblivious subspace embedding (OSE), characterized by parameters
$m,n,d,\epsilon,\delta$, is a random matrix $\Pi\in \mathbb{R}^{m\times n}$
such that for any $d$-dimensional subspace $T\subseteq \mathbb{R}^n$,
$\Pr_\Pi[\forall x\in T, (1-\epsilon)\|x\|_2 \leq \|\Pi x\|_2\leq
(1+\epsilon)\|x\|_2] \geq 1-\delta$. When an OSE has $1/(9\epsilon)$ nonzero
entries in each column, we show it must hold that $m =
\Omega(d^2/\epsilon^{1-O(\delta)})$, which is the first lower bound with
multiplicative factors of $d^2$ and $1/\epsilon$, improving on the previous
$\Omega(\epsilon^{O(\delta)}d^2)$ lower bound due to Li and Liu (PODS 2022).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improved Algebraic Degeneracy Testing</title>
    <link href="http://arxiv.org/abs/2212.03030"/>
    <id>http://arxiv.org/abs/2212.03030</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardinal_J/0/1/0/all/0/1&quot;&gt;Jean Cardinal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharir_M/0/1/0/all/0/1&quot;&gt;Micha Sharir&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the classical linear degeneracy testing problem, we are given $n$ real
numbers and a $k$-variate linear polynomial $F$, for some constant $k$, and
have to determine whether there exist $k$ numbers $a_1,\ldots,a_k$ from the set
such that $F(a_1,\ldots,a_k) = 0$. We consider a generalization of this problem
in which $F$ is an arbitrary constant-degree polynomial, we are given $k$ sets
of $n$ numbers, and have to determine whether there exist a $k$-tuple of
numbers, one in each set, on which $F$ vanishes. We give the first improvement
over the na\&quot;ive $O^*(n^{k-1})$ algorithm for this problem (where the
$O^*(\cdot)$ notation omits subpolynomial factors).
&lt;/p&gt;
&lt;p&gt;We show that the problem can be solved in time $O^*\left( n^{k - 2 + \frac
4{k+2}}\right)$ for even $k$ and in time $O^*\left( n^{k - 2 +
\frac{4k-8}{k^2-5}}\right)$ for odd $k$ in the real RAM model of computation.
We also prove that for $k=4$, the problem can be solved in time
$O^*(n^{2.625})$ in the algebraic decision tree model, and for $k=5$ it can be
solved in time $O^*(n^{3.56})$ in the same model, both improving on the above
uniform bounds.
&lt;/p&gt;
&lt;p&gt;All our results rely on an algebraic generalization of the standard
meet-in-the-middle algorithm for $k$-SUM, powered by recent algorithmic
advances in the polynomial method for semi-algebraic range searching. In fact,
our main technical result is much more broadly applicable, as it provides a
general tool for detecting incidences and other interactions between points and
algebraic surfaces in any dimension. In particular, it yields an efficient
algorithm for a general, algebraic version of Hopcroft&#39;s point-line incidence
detection problem in any dimension.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Robustness of Quantum Algorithms for Nonconvex Optimization</title>
    <link href="http://arxiv.org/abs/2212.02548"/>
    <id>http://arxiv.org/abs/2212.02548</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gong_W/0/1/0/all/0/1&quot;&gt;Weiyuan Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chenyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Tongyang Li&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Recent results suggest that quantum computers possess the potential to speed
up nonconvex optimization problems. However, a crucial factor for the
implementation of quantum optimization algorithms is their robustness against
experimental and statistical noises. In this paper, we systematically study
quantum algorithms for finding an $\epsilon$-approximate second-order
stationary point ($\epsilon$-SOSP) of a $d$-dimensional nonconvex function, a
fundamental problem in nonconvex optimization, with noisy zeroth- or
first-order oracles as inputs. We first prove that, up to noise of
$O(\epsilon^{10}/d^5)$, accelerated perturbed gradient descent with quantum
gradient estimation takes $O(\log d/\epsilon^{1.75})$ quantum queries to find
an $\epsilon$-SOSP. We then prove that perturbed gradient descent is robust to
the noise of $O(\epsilon^6/d^4)$ and $O(\epsilon/d^{0.5+\zeta})$ for $\zeta&amp;gt;0$
on the zeroth- and first-order oracles, respectively, which provides a quantum
algorithm with poly-logarithmic query complexity. We then propose a stochastic
gradient descent algorithm using quantum mean estimation on the Gaussian
smoothing of noisy oracles, which is robust to $O(\epsilon^{1.5}/d)$ and
$O(\epsilon/\sqrt{d})$ noise on the zeroth- and first-order oracles,
respectively. The quantum algorithm takes $O(d^{2.5}/\epsilon^{3.5})$ and
$O(d^2/\epsilon^3)$ queries to the two oracles, giving a polynomial speedup
over the classical counterparts. Moreover, we characterize the domains where
quantum algorithms can find an $\epsilon$-SOSP with poly-logarithmic,
polynomial, or exponential number of queries in $d$, or the problem is
information-theoretically unsolvable even by an infinite number of queries. In
addition, we prove an $\Omega(\epsilon^{-12/7})$ lower bound in $\epsilon$ for
any randomized classical and quantum algorithm to find an $\epsilon$-SOSP using
either noisy zeroth- or first-order oracles.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Collabs: Composable Collaborative Data Structures</title>
    <link href="http://arxiv.org/abs/2212.02618"/>
    <id>http://arxiv.org/abs/2212.02618</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weidner_M/0/1/0/all/0/1&quot;&gt;Matthew Weidner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_H/0/1/0/all/0/1&quot;&gt;Heather Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1&quot;&gt;Huairui Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kjaer_M/0/1/0/all/0/1&quot;&gt;Maxime Kjaer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pradeep_R/0/1/0/all/0/1&quot;&gt;Ria Pradeep&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geordie_B/0/1/0/all/0/1&quot;&gt;Benito Geordie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meiklejohn_C/0/1/0/all/0/1&quot;&gt;Christopher Meiklejohn&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Replicated data types (RDTs), such as Conflict-free Replicated Data Types
(CRDTs), provide an abstraction for reasoning about replication and consistency
in distributed systems. To make them as useful as ordinary, local data
structures, RDTs need to be both modular and composable, so that programmers
can create new app-specific RDTs by composing existing ones. However, no
existing RDT libraries combine these properties; either they use monolithic
architectures that rule out new RDTs or they do not support composition
techniques.
&lt;/p&gt;
&lt;p&gt;In this work, we introduce the Collab (collaborative data structure), a novel
abstraction for modular and composable RDTs. We also describe the collabs
library, an open-source TypeScript library that we built around this
abstraction. Our library supports arbitrary programmer-added RDTs and includes
composition techniques that make them easier to implement. This allows
programmers to work at a higher level of abstraction: custom RDTs for arbitrary
concepts in their application, instead of just a fixed menu of generic RDTs. It
also allows programmers to extend the library with new RDT algorithms as they
are published, instead of waiting for the library to implement them. Our
library includes a collection of built-in op-based CRDT implementations,
including several that were not previously implemented. To demonstrate the
library, we built numerous apps on top of it, including decentralized
collaborative apps that can be deployed from a static web page. Benchmarks show
that its CRDTs have performance comparable to state-of-the-art CRDT libraries
for web apps, and that unlike existing libraries, it can support 100
simultaneous users with low latency in a geo-distributed collaborative app.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Stars: Tera-Scale Graph Building for Clustering and Graph Learning</title>
    <link href="http://arxiv.org/abs/2212.02635"/>
    <id>http://arxiv.org/abs/2212.02635</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carey_C/0/1/0/all/0/1&quot;&gt;CJ Carey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Halcrow_J/0/1/0/all/0/1&quot;&gt;Jonathan Halcrow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jayaram_R/0/1/0/all/0/1&quot;&gt;Rajesh Jayaram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1&quot;&gt;Vahab Mirrokni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schudy_W/0/1/0/all/0/1&quot;&gt;Warren Schudy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_P/0/1/0/all/0/1&quot;&gt;Peilin Zhong&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A fundamental procedure in the analysis of massive datasets is the
construction of similarity graphs. Such graphs play a key role for many
downstream tasks, including clustering, classification, graph learning, and
nearest neighbor search. For these tasks, it is critical to build graphs which
are sparse yet still representative of the underlying data. The benefits of
sparsity are twofold: firstly, constructing dense graphs is infeasible in
practice for large datasets, and secondly, the runtime of downstream tasks is
directly influenced by the sparsity of the similarity graph. In this work, we
present $\textit{Stars}$: a highly scalable method for building extremely
sparse graphs via two-hop spanners, which are graphs where similar points are
connected by a path of length at most two. Stars can construct two-hop spanners
with significantly fewer similarity comparisons, which are a major bottleneck
for learning based models where comparisons are expensive to evaluate.
Theoretically, we demonstrate that Stars builds a graph in nearly-linear time,
where approximate nearest neighbors are contained within two-hop neighborhoods.
In practice, we have deployed Stars for multiple data sets allowing for graph
building at the $\textit{Tera-Scale}$, i.e., for graphs with tens of trillions
of edges. We evaluate the performance of Stars for clustering and graph
learning, and demonstrate 10~1000-fold improvements in pairwise similarity
comparisons compared to different baselines, and 2~10-fold improvement in
running time without quality loss.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Low Power Mesh Algorithms for Image Problems</title>
    <link href="http://arxiv.org/abs/2212.02640"/>
    <id>http://arxiv.org/abs/2212.02640</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stout_Q/0/1/0/all/0/1&quot;&gt;Quentin Stout&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We analyze a physically motivated fine-grained mesh-connected computer model,
assuming that a word of information takes a fixed area and that it takes unit
time and unit energy to move a word unit distance. This is a representation of
computing on a chip with myriad tiny processors arranged as a mesh. While most
mesh algorithms assume all processors are active at all times, we give
algorithms that have only a few processors on at any one time, which reduces
the power required. We apply this approach to basic problems involving images,
showing that there can be dramatic reductions in the peak power with only
small, if any, changes in the time required. We also show that these algorithms
give a more efficient way to utilize power when more power is available.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Online Min-Max Paging</title>
    <link href="http://arxiv.org/abs/2212.03016"/>
    <id>http://arxiv.org/abs/2212.03016</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiplunkar_A/0/1/0/all/0/1&quot;&gt;Ashish Chiplunkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1&quot;&gt;Monika Henzinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kale_S/0/1/0/all/0/1&quot;&gt;Sagar Sudhir Kale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Votsch_M/0/1/0/all/0/1&quot;&gt;Maximilian V&amp;#xf6;tsch&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Motivated by fairness requirements in communication networks, we introduce a
natural variant of the online paging problem, called \textit{min-max} paging,
where the objective is to minimize the maximum number of faults on any page.
While the classical paging problem, whose objective is to minimize the total
number of faults, admits $k$-competitive deterministic and $O(\log
k)$-competitive randomized algorithms, we show that min-max paging does not
admit a $c(k)$-competitive algorithm for any function $c$. Specifically, we
prove that the randomized competitive ratio of min-max paging is
$\Omega(\log(n))$ and its deterministic competitive ratio is
$\Omega(k\log(n)/\log(k))$, where $n$ is the total number of pages ever
requested.
&lt;/p&gt;
&lt;p&gt;We design a fractional algorithm for paging with a more general objective --
minimize the value of an $n$-variate differentiable convex function applied to
the vector of the number of faults on each page. This gives an
$O(\log(n)\log(k))$-competitive fractional algorithm for min-max paging. We
show how to round such a fractional algorithm with at most a $k$ factor loss in
the competitive ratio, resulting in a deterministic
$O(k\log(n)\log(k))$-competitive algorithm for min-max paging. This matches our
lower bound modulo a $\mathrm{poly}(\log(k))$ factor. We also give a randomized
rounding algorithm that results in a $O(\log^2 n \log k)$-competitive
algorithm.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Pareto Optimal Compression of Genomic Dictionaries, with or without Random Access in Main Memory</title>
    <link href="http://arxiv.org/abs/2212.03067"/>
    <id>http://arxiv.org/abs/2212.03067</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giancarlo_R/0/1/0/all/0/1&quot;&gt;Raffaele Giancarlo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grimaudo_G/0/1/0/all/0/1&quot;&gt;Gennaro Grimaudo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Motivation: A Genomic Dictionary, i.e., the set of the k-mers appearing in a
genome, is a fundamental source of genomic information: its collection is the
first step in strategic computational methods ranging from assembly to sequence
comparison and phylogeny. Unfortunately, it is costly to store. This motivates
some recent studies regarding the compression of those k-mer sets. However,
such an area does not have the maturity of genomic compression, lacking an
homogeneous and methodologically sound experimental foundation that allows to
fairly compare the relative merits of the available solutions, and that takes
into account also the rich choices of compression methods that can be used.
&lt;/p&gt;
&lt;p&gt;Results: We provide such a foundation here, supporting it with an extensive
set of experiments that use reference datasets and a carefully selected set of
representative data compressors. Our results highlight the spectrum of
compressor choices one has in terms of Pareto Optimality of compression vs.
post-processing, this latter being important when the Dictionary needs to be
decompressed many times. In addition to the useful indications, not available
elsewhere, that this study offers to the researchers interested in storing
k-mer dictionaries in compressed form, a software system that can be readily
used to explore the Pareto Optimal solutions available r a given Dictionary is
also provided.
&lt;/p&gt;
&lt;p&gt;Availability: The software system is available at
https://github.com/GenGrim76/Pareto-Optimal-GDC, together with user manuals and
installation instructions.
&lt;/p&gt;
&lt;p&gt;Contact: raffaele.giancarlo@unipa.it
&lt;/p&gt;
&lt;p&gt;Supplementary information: Additional data are available in the Supplementary
Material.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Extending Snow&#39;s algorithm for computations in the finite Weyl groups</title>
    <link href="http://arxiv.org/abs/2212.03156"/>
    <id>http://arxiv.org/abs/2212.03156</id>
    <updated>2022-12-07T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Stekolshchik_R/0/1/0/all/0/1&quot;&gt;Rafael Stekolshchik&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In 1990, D.Snow proposed an effective algorithm for computing the orbits of
finite Weyl groups. Snow&#39;s algorithm is designed for computation of weights,
$W$-orbits and elements of the Weyl group. An extension of Snow&#39;s algorithm is
proposed, which allows to find pairs of mutually inverse elements together with
the calculation of $W$-orbits in the same runtime cycle. This simplifies the
calculation of conjugacy classes in the Weyl group. As an example, the complete
list of elements of the Weyl group $W(D_4)$ obtained using the extended Snow&#39;s
algorithm is given. The elements of $W(D_4)$ are specified in two ways: as
reduced expressions and as matrices of the faithful representation. We present
a partition of this group into conjugacy classes with elements specified as
reduced expressions. Various forms are given for representatives of the
conjugacy classes of $W(D_4)$: using Carter diagrams, using reduced expressions
and using signed cycle-types. In the appendix, we provide an implementation of
the algorithm in Python.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-177 |  Quantum Worst-Case to Average-Case Reductions for All Linear Problems | 

	Vahid Reza Asadi, 

	Alexander Golovnev, 

	Tom Gur, 

	Igor Shinkar, 

	Sathyawageeswar Subramanian</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/177"/>
    <id>https://eccc.weizmann.ac.il/report/2022/177</id>
    <updated>2022-12-06T22:35:48+00:00</updated>
    <content type="html" xml:lang="en">
    We study the problem of designing worst-case to average-case reductions for quantum algorithms. For all linear problems, we provide an explicit and efficient transformation of quantum algorithms that are only correct on a small (even sub-constant) fraction of their inputs into ones that are correct on all inputs. This stands in contrast to the classical setting, where such results are only known for a small number of specific problems or restricted computational models. En route, we obtain a tight $\Omega(n^2)$ lower bound on the average-case quantum query complexity of the Matrix-Vector Multiplication problem. 

Our techniques strengthen and generalise the recently introduced additive combinatorics framework for classical worst-case to average-case reductions (STOC 2022) to the quantum setting. We rely on quantum singular value transformations to construct quantum algorithms for linear verification in superposition and learning Bogolyubov subspaces from noisy quantum oracles. We use these tools to prove a quantum local correction lemma, which lies at the heart of our reductions, based on a noise-robust probabilistic generalisation of Bogolyubov&amp;#39;s lemma from additive combinatorics.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Theory Dish: Stanford Blog: 2023 Motwani Postdoc Announced</title>
    <link href="https://theorydish.blog/2022/12/05/2023-motwani-postdoc-announced/"/>
    <id>http://theorydish.blog/?p=2859</id>
    <updated>2022-12-06T02:29:30+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15.&lt;/p&gt;



&lt;p&gt;Website:&amp;nbsp;&lt;a href=&quot;https://academicjobsonline.org/ajo/jobs/23929&quot;&gt;https://academicjobsonline.org/ajo/jobs/23929&lt;/a&gt;&lt;br&gt;Email: theory.stanford@gmail.com&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Omer Reingold&lt;/p&gt;
  </content>
    <author>
      <name>Theory Dish: Stanford Blog</name>
      <uri>https://theorydish.blog</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: A Gap in the Subrank of Tensors</title>
    <link href="http://arxiv.org/abs/2212.01668"/>
    <id>http://arxiv.org/abs/2212.01668</id>
    <updated>2022-12-06T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Christandl_M/0/1/0/all/0/1&quot;&gt;Matthias Christandl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gesmundo_F/0/1/0/all/0/1&quot;&gt;Fulvio Gesmundo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zuiddam_J/0/1/0/all/0/1&quot;&gt;Jeroen Zuiddam&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The subrank of tensors is a measure of how much a tensor can be
&#39;&#39;diagonalized&#39;&#39;. This parameter was introduced by Strassen to study fast
matrix multiplication algorithms in algebraic complexity theory and is closely
related to many central tensor parameters (e.g. slice rank, partition rank,
analytic rank, geometric rank, G-stable rank) and problems in combinatorics,
computer science and quantum information theory. Strassen (J. Reine Angew.
Math., 1988) proved that there is a gap in the subrank when taking large powers
under the tensor product: either the subrank of all powers is at most one, or
it grows as a power of a constant strictly larger than one. In this paper, we
precisely determine this constant for tensors of any order. Additionally, for
tensors of order three, we prove that there is a second gap in the possible
rates of growth. Our results strengthen the recent work of Costa and Dalai (J.
Comb. Theory, Ser. A, 2021), who proved a similar gap for the slice rank. Our
theorem on the subrank has wider applications by implying such gaps not only
for the slice rank, but for any ``normalized monotone&#39;&#39;. In order to prove the
main result, we characterize when a tensor has a very structured tensor (the
W-tensor) in its orbit closure. Our methods include degenerations in
Grassmanians, which may be of independent interest.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Stabbing balls with line segments and polygonal paths</title>
    <link href="http://arxiv.org/abs/2212.01458"/>
    <id>http://arxiv.org/abs/2212.01458</id>
    <updated>2022-12-06T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neuhaus_A/0/1/0/all/0/1&quot;&gt;Alexander Neuhaus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rohde_D/0/1/0/all/0/1&quot;&gt;Dennis Rohde&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the problem of ordered stabbing of $n$ balls (of arbitrary and
possibly different radii, no ball contained in another) in $\mathbb{R}^d$, $d
\geq 3$, with either a directed line segment or a (directed) polygonal curve.
Here, the line segment, respectively polygonal curve, shall visit (intersect)
the given sequence of balls in the order of the sequence. We present a
deterministic algorithm that decides whether there exists a line segment
stabbing the given sequence of balls in order, in time $O(n^{4d-2} \log n)$.
Due to the descriptional complexity of the region containing these line
segments, we can not extend this algorithm to actually compute one. We
circumvent this hurdle by devising a randomized algorithm for a relaxed variant
of the ordered line segment stabbing problem, which is built upon the central
insights from the aforementioned decision algorithm. We further show that this
algorithm can be plugged into an algorithmic scheme by Guibas et al., yielding
an algorithm for a relaxed variant of the minimum-link ordered stabbing path
problem that achieves approximation factor 2 with respect to the number of
links. We conclude with experimental evaluations of the latter two algorithms,
showing practical applicability.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Cup Product Persistence and Its Efficient Computation</title>
    <link href="http://arxiv.org/abs/2212.01633"/>
    <id>http://arxiv.org/abs/2212.01633</id>
    <updated>2022-12-06T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dey_T/0/1/0/all/0/1&quot;&gt;Tamal Dey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rathod_A/0/1/0/all/0/1&quot;&gt;Abhishek Rathod&lt;/a&gt;&lt;/p&gt;&lt;p&gt;It is well-known that cohomology has a richer structure than homology.
However, so far, in practice, the use of cohomology in persistence setting has
been limited to speeding up of barcode computations. Two recently introduced
invariants, namely, persistent cup-length and persistent Steenrod modules, to
some extent, fill this gap. When added to the standard persistence barcode,
they lead to invariants that are more discriminative than the standard
persistence barcode. In this work, we introduce (the persistent variants of)
the order-$k$ cup product modules, which are images of maps from the $k$-fold
tensor products of the cohomology vector space of a complex to the cohomology
vector space of the complex itself. We devise an $O(d n^4)$ algorithm for
computing the order-$k$ cup product persistent modules for all $k \in \{2,
\dots, d\}$, where $d$ denotes the dimension of the filtered complex, and $n$
denotes its size. Furthermore, we show that these modules are stable for Cech
and Rips filtrations. Finally, we note that the persistent cup length can be
obtained as a byproduct of our computations leading to a significantly faster
algorithm for computing it.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Euler Characteristic Curves and Profiles: a stable shape invariant for big data problems</title>
    <link href="http://arxiv.org/abs/2212.01666"/>
    <id>http://arxiv.org/abs/2212.01666</id>
    <updated>2022-12-06T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dlotko_P/0/1/0/all/0/1&quot;&gt;Pawe&amp;#x142; D&amp;#x142;otko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gurnari_D/0/1/0/all/0/1&quot;&gt;Davide Gurnari&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Tools of Topological Data Analysis provide stable summaries encapsulating the
shape of the considered data. Persistent homology, the most standard and well
studied data summary, suffers a number of limitations; its computations are
hard to distribute, it is hard to generalize to multifiltrations and is
computationally prohibitive for big data-sets. In this paper we study the
concept of Euler Characteristics Curves, for one parameter filtrations and
Euler Characteristic Profiles, for multi-parameter filtrations. While being a
weaker invariant in one dimension, we show that Euler Characteristic based
approaches do not possess some handicaps of persistent homology; we show
efficient algorithms to compute them in a distributed way, their generalization
to multifiltrations and practical applicability for big data problems. In
addition we show that the Euler Curves and Profiles enjoys certain type of
stability which makes them robust tool in data analysis. Lastly, to show their
practical applicability, multiple use-cases are considered.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Parameterized Approximation for Maximum Weight Independent Set of Rectangles and Segments</title>
    <link href="http://arxiv.org/abs/2212.01620"/>
    <id>http://arxiv.org/abs/2212.01620</id>
    <updated>2022-12-06T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cslovjecsek_J/0/1/0/all/0/1&quot;&gt;Jana Cslovjecsek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1&quot;&gt;Micha&amp;#x142; Pilipczuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wegrzycki_K/0/1/0/all/0/1&quot;&gt;Karol W&amp;#x119;grzycki&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the Maximum Weight Independent Set of Rectangles problem (MWISR) we are
given a weighted set of $n$ axis-parallel rectangles in the plane. The task is
to find a subset of pairwise non-overlapping rectangles with the maximum
possible total weight. This problem is NP-hard and the best-known
polynomial-time approximation algorithm, due to by Chalermsook and Walczak
(SODA 2021), achieves approximation factor $O(\log\log n )$. While in the
unweighted setting, constant factor approximation algorithms are known, due to
Mitchell (FOCS 2021) and to G\&#39;alvez et al. (SODA 2022), it remains open to
extend these techniques to the weighted setting.
&lt;/p&gt;
&lt;p&gt;In this paper, we consider MWISR through the lens of parameterized
approximation. Grandoni et al. (ESA 2019) gave a $(1-\epsilon)$-approximation
algorithm with running time $k^{O(k/\epsilon^8)} n^{O(1/\epsilon^8)}$ time,
where $k$ is the number of rectangles in an optimum solution. Unfortunately,
their algorithm works only in the unweighted setting and they left it as an
open problem to give a parameterized approximation scheme in the weighted
setting.
&lt;/p&gt;
&lt;p&gt;Our contribution is a partial answer to the open question of Grandoni et al.
(ESA 2019). We give a parameterized approximation algorithm for MWISR that
given a parameter $k$, finds a set of non-overlapping rectangles of weight at
least $(1-\epsilon) \text{opt}_k$ in $2^{O(k \log(k/\epsilon))}
n^{O(1/\epsilon)}$ time, where $\text{opt}_k$ is the maximum weight of a
solution of cardinality at most $k$. Note that thus, our algorithm may return a
solution consisting of more than $k$ rectangles. To complement this apparent
weakness, we also propose a parameterized approximation scheme with running
time $2^{O(k^2 \log(k/\epsilon))} n^{O(1)}$ that finds a solution with
cardinality at most $k$ and total weight at least $(1-\epsilon)\text{opt}_k$
for the special case of axis-parallel segments.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Pandora&#39;s Problem with Nonobligatory Inspection: Optimal Structure and a PTAS</title>
    <link href="http://arxiv.org/abs/2212.01524"/>
    <id>http://arxiv.org/abs/2212.01524</id>
    <updated>2022-12-06T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beyhaghi_H/0/1/0/all/0/1&quot;&gt;Hedyeh Beyhaghi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_L/0/1/0/all/0/1&quot;&gt;Linda Cai&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Weitzman introduced Pandora&#39;s box problem as a mathematical model of
sequential search with inspection costs, in which a searcher is allowed to
select a prize from one of $n$ alternatives. Several decades later, Doval
introduced a close version of the problem, where the searcher does not need to
incur the inspection cost of an alternative, and can select it uninspected.
Unlike the original problem, the optimal solution to the nonobligatory
inspection variant is proved to need adaptivity, and by recent work of [FLL22],
finding the optimal solution is NP-hard.
&lt;/p&gt;
&lt;p&gt;Our first main result is a structural characterization of the optimal policy:
We show there exists an optimal policy that follows only two different
pre-determined orders of inspection, and transitions from one to the other at
most once. Our second main result is a polynomial time approximation scheme
(PTAS). Our proof involves a novel reduction to a framework developed by
[FLX18], utilizing our optimal two-phase structure. Furthermore, we show
Pandora&#39;s problem with nonobligatory inspection belongs to class NP, which by
using the hardness result of [FLL22], settles the computational complexity
class of the problem. Finally, we provide a tight 0.8 approximation and a novel
proof for committing policies [BK19] (informally, the set of nonadaptive
policies) for general classes of distributions, which was previously shown only
for discrete and finite distributions [GMS08].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A Unified Quantum Algorithm Framework for Estimating Properties of Discrete Probability Distributions</title>
    <link href="http://arxiv.org/abs/2212.01571"/>
    <id>http://arxiv.org/abs/2212.01571</id>
    <updated>2022-12-06T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Tongyang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinzhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shengyu Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Estimating statistical properties is fundamental in statistics and computer
science. In this paper, we propose a unified quantum algorithm framework for
estimating properties of discrete probability distributions, with estimating
R\&#39;enyi entropies as specific examples. In particular, given a quantum oracle
that prepares an $n$-dimensional quantum state
$\sum_{i=1}^{n}\sqrt{p_{i}}|i\rangle$, for $\alpha&amp;gt;1$ and $0&amp;lt;\alpha&amp;lt;1$, our
algorithm framework estimates $\alpha$-R\&#39;enyi entropy $H_{\alpha}(p)$ to
within additive error $\epsilon$ with probability at least $2/3$ using
$\widetilde{\mathcal{O}}(n^{1-\frac{1}{2\alpha}}/\epsilon +
\sqrt{n}/\epsilon^{1+\frac{1}{2\alpha}})$ and
$\widetilde{\mathcal{O}}(n^{\frac{1}{2\alpha}}/\epsilon^{1+\frac{1}{2\alpha}})$
queries, respectively. This improves the best known dependence in $\epsilon$ as
well as the joint dependence between $n$ and $1/\epsilon$. Technically, our
quantum algorithms combine quantum singular value transformation, quantum
annealing, and variable-time amplitude estimation. We believe that our
algorithm framework is of general interest and has wide applications.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Parameterized temporal exploration problems</title>
    <link href="http://arxiv.org/abs/2212.01594"/>
    <id>http://arxiv.org/abs/2212.01594</id>
    <updated>2022-12-06T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erlebach_T/0/1/0/all/0/1&quot;&gt;Thomas Erlebach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spooner_J/0/1/0/all/0/1&quot;&gt;Jakob T. Spooner&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper we study the fixed-parameter tractability of the problem of
deciding whether a given temporal graph admits a temporal walk that visits all
vertices (temporal exploration) or, in some problem variants, a certain subset
of the vertices. Formally, a temporal graph is a sequence &amp;lt;G_1,...,G_L&amp;gt; of
graphs with V(G_t) = V(G) and E(G_t) a subset of E(G) for all t in [L] and some
underlying graph G, and a temporal walk is a time-respecting sequence of
edge-traversals. We consider both the strict variant, in which edges must be
traversed in strictly increasing timesteps, and the non-strict variant, in
which an arbitrary number of edges can be traversed in each timestep. For both
variants, we give FPT algorithms for the problem of finding a temporal walk
that visits a given set X of vertices, parameterized by |X|, and for the
problem of finding a temporal walk that visits at least k distinct vertices in
V(G), parameterized by k. We also show W[2]-hardness for a set version of the
temporal exploration problem for both variants. For the non-strict variant, we
give an FPT algorithm for the temporal exploration problem parameterized by the
lifetime of the input graph, and we show that the temporal exploration problem
can be solved in polynomial time if the graph in each timestep has at most two
connected components.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Notes on the complexity of coverings for Kronecker powers of symmetric matrices</title>
    <link href="http://arxiv.org/abs/2212.01776"/>
    <id>http://arxiv.org/abs/2212.01776</id>
    <updated>2022-12-06T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sergeev_I/0/1/0/all/0/1&quot;&gt;Igor S. Sergeev&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the present note, we study a new method of constructing efficient
coverings for Kronecker powers of matrices, recently proposed by J. Alman, Y.
Guan, A. Padaki [arXiv, 2022]. We provide an alternative proof for the case of
symmetric matrices in a stronger form. As a consequence, the previously known
upper bound on the depth-2 additive complexity of the boolean $N\times N$
Kneser-Sierpinski matrices is improved to $O(N^{1.251})$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Clustering Permutations: New Techniques with Streaming Applications</title>
    <link href="http://arxiv.org/abs/2212.01821"/>
    <id>http://arxiv.org/abs/2212.01821</id>
    <updated>2022-12-06T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1&quot;&gt;Diptarka Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1&quot;&gt;Debarati Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krauthgamer_R/0/1/0/all/0/1&quot;&gt;Robert Krauthgamer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the classical metric $k$-median clustering problem over a set of
input rankings (i.e., permutations), which has myriad applications, from
social-choice theory to web search and databases. A folklore algorithm provides
a $2$-approximate solution in polynomial time for all $k=O(1)$, and works
irrespective of the underlying distance measure, so long it is a metric;
however, going below the $2$-factor is a notorious challenge. We consider the
Ulam distance, a variant of the well-known edit-distance metric, where strings
are restricted to be permutations. For this metric, Chakraborty, Das, and
Krauthgamer [SODA, 2021] provided a $(2-\delta)$-approximation algorithm for
$k=1$, where $\delta\approx 2^{-40}$.
&lt;/p&gt;
&lt;p&gt;Our primary contribution is a new algorithmic framework for clustering a set
of permutations. Our first result is a $1.999$-approximation algorithm for the
metric $k$-median problem under the Ulam metric, that runs in time $(k \log
(nd))^{O(k)}n d^3$ for an input consisting of $n$ permutations over $[d]$. In
fact, our framework is powerful enough to extend this result to the streaming
model (where the $n$ input permutations arrive one by one) using only
polylogarithmic (in $n$) space. Additionally, we show that similar results can
be obtained even in the presence of outliers, which is presumably a more
difficult problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Postdoc at George Mason University (apply by December 31, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/12/05/postdoc-at-george-mason-university-apply-by-december-31-2022/"/>
    <id>http://cstheory-jobs.org/2022/12/05/postdoc-at-george-mason-university-apply-by-december-31-2022/</id>
    <updated>2022-12-05T21:30:49+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Postdoc in theoretical foundations of Algorithms and AI at George Mason University. Starting Fall23 and hosted by Grigory Yaroslavtsev (&lt;a href=&quot;http://grigory.ai&quot;&gt;http://grigory.ai&lt;/a&gt;). GMU is located in the Washington, DC metro area, is the largest public university in Virginia and has one of the fastest growing CS departments in the U.S.&lt;/p&gt;
&lt;p&gt;To apply email CV and research statement. Reference letters will be requested.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;http://grigory.ai&quot;&gt;http://grigory.ai&lt;/a&gt;&lt;br /&gt;
Email: grigory@grigory.us&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: The Future of Education is Personal</title>
    <link href="http://blog.computationalcomplexity.org/2022/12/the-future-of-education-is-personal.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-2041922047028548572</id>
    <updated>2022-12-05T13:53:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbsNuEriIphlZE_oc0Xj44gFxfBp1LCCnFM4ps7FL2KtdUjta77CAddfqgxJQa24OCZ2mv2gqaxRisUhVgvhSj4QIl9Cov-phWAb2wwyIy-rJmHdcsIPcv-60JGncHmMJAIbgi8KwGHExESHI_12_H5TGV2woNv6dn38DtzD2vRo9wXF635Q/s1024/DALL%C2%B7E%202022-12-03%2014.23.49%20-%20An%20oil%20painting%20of%20a%20Darth%20Vader%20tutoring%20a%20human%20student.png&quot; style=&quot;clear: right; float: right; margin-bottom: 1em; margin-left: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1024&quot; data-original-width=&quot;1024&quot; height=&quot;320&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbsNuEriIphlZE_oc0Xj44gFxfBp1LCCnFM4ps7FL2KtdUjta77CAddfqgxJQa24OCZ2mv2gqaxRisUhVgvhSj4QIl9Cov-phWAb2wwyIy-rJmHdcsIPcv-60JGncHmMJAIbgi8KwGHExESHI_12_H5TGV2woNv6dn38DtzD2vRo9wXF635Q/s320/DALL%C2%B7E%202022-12-03%2014.23.49%20-%20An%20oil%20painting%20of%20a%20Darth%20Vader%20tutoring%20a%20human%20student.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;With all the excitement about &lt;a href=&quot;https://chat.openai.com/&quot;&gt;ChatGPT&lt;/a&gt;, how will machine learning disrupt education, say five to ten years down the road?&lt;/p&gt;&lt;p&gt;My guess: individualized tutors. Imagine a tutor working with you teaching you important concepts, walking you through examples, answering your questions, going at your own pace, like the&amp;nbsp;&lt;a href=&quot;https://www.new.ox.ac.uk/tutorial-system&quot;&gt;Oxford system&lt;/a&gt;. The Oxford tutor system doesn&#39;t scale well, or at least it wouldn&#39;t if we have human tutors. But we can scale using machine learning and we&#39;re not far away from being able to do so. Such tutors will be infinitely patient, have full knowledge of all written material, speak in any language with any voice and personality.&lt;/p&gt;&lt;p&gt;You can &quot;meet&quot; with your tutor in many different ways, from a deep fake video chat or with augmented or virtual reality to have a tutor in the room with you, or perhaps a physical robot, neural implant or something we haven&#39;t even though of yet. In poorer countries you can get tutored with something as simple as text messages on a cell phone.&amp;nbsp;&lt;/p&gt;&lt;p&gt;A tutor can take on any form. You could get tutored by fictional characters such as Yoda, Darth Vader or &lt;a href=&quot;https://en.wikipedia.org/wiki/The_Magic_School_Bus_(TV_series)&quot;&gt;Miss Frizzle&lt;/a&gt;. ML can capture the personality of real people--imaging a course about Kurt Vonnegut taught by the author, government from Henry Kissinger or a course in quantum computing from your own personal Scott Aaronson. But most importantly you can have a tutor who looks and sounds like you, with your own language, gender, race and ethnicity.&lt;/p&gt;&lt;p&gt;Somehow we&#39;ll have to find ways to include the social aspects such as working in groups, socializing, playing sports and living together. But that one-one-one teaching experience that most of us cannot afford&amp;nbsp; today will be cheaply available tomorrow.&lt;/p&gt;&lt;p&gt;And what will this all mean for teachers, professors and universities? A good question for future blog posts.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Turing&#39;s Invisible Hand: 2023 SIGecom Test of Time Award  Call for Nominations</title>
    <link href="https://agtb.wordpress.com/2022/12/05/2023-sigecom-test-of-time-award-call-for-nominations/"/>
    <id>http://agtb.wordpress.com/?p=3548</id>
    <updated>2022-12-05T09:16:02+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The SIGecom Test of Time Award recognizes the author or authors of an influential paper or series of papers published between ten and twenty-five years ago that has significantly impacted research or applications exemplifying the interplay of economics and computation.&lt;/p&gt;



&lt;p&gt;The 2023 SIGecom Test of Time Award will be given for papers published no earlier than 1998 and no later than 2013. Nominations are due by&amp;nbsp;&lt;em&gt;February 28th, 2023&lt;/em&gt;&amp;nbsp;(Anywhere on Earth), and must be made&amp;nbsp;together with the endorsement letters by submission using&amp;nbsp;&lt;a target=&quot;_blank&quot; href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSdm6Hk4uYDi45rvQxHj0dQasjyNMD3XBbS72SK7MPnypWTMmQ/viewform&quot; rel=&quot;noreferrer noopener&quot;&gt;this form&lt;/a&gt;. Any member of SIGecom may submit a nomination. Self-nomination is not allowed.&lt;/p&gt;



&lt;p&gt;More details regarding the nomination procedure can be found&amp;nbsp;&lt;a href=&quot;https://www.sigecom.org/award-tot-details.html&quot;&gt;here&lt;/a&gt;.&amp;nbsp; The list of winners from previous years can be found&amp;nbsp;&lt;a href=&quot;https://www.sigecom.org/award-tot.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;



&lt;p&gt;&lt;/p&gt;



&lt;p class=&quot;has-text-align-left&quot;&gt;&lt;strong&gt;The 2023 Test of Time Award Committee&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Alvin Roth&lt;/strong&gt;, Stanford University&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Moshe Tennenholtz&lt;/strong&gt;, The Technion&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Noam Nisan (chair)&lt;/strong&gt;, The Hebrew University of Jerusalem&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Noam Nisan&lt;/p&gt;
  </content>
    <author>
      <name>Turing's Invisible Hand</name>
      <uri>https://agtb.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Motwani Postdoctoral Fellowship at Stanford Computer Science (apply by December 15, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/12/05/motwani-postdoctoral-fellowship-at-stanford-computer-science-apply-by-december-15-2022/"/>
    <id>http://cstheory-jobs.org/2022/12/05/motwani-postdoctoral-fellowship-at-stanford-computer-science-apply-by-december-15-2022/</id>
    <updated>2022-12-05T08:32:41+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://academicjobsonline.org/ajo/jobs/23929&quot;&gt;https://academicjobsonline.org/ajo/jobs/23929&lt;/a&gt;&lt;br /&gt;
Email: theory.stanford@gmail.com&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Quantum Cryptography in Algorithmica</title>
    <link href="http://arxiv.org/abs/2212.00879"/>
    <id>http://arxiv.org/abs/2212.00879</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kretschmer_W/0/1/0/all/0/1&quot;&gt;William Kretschmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Qian_L/0/1/0/all/0/1&quot;&gt;Luowen Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sinha_M/0/1/0/all/0/1&quot;&gt;Makrand Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Tal_A/0/1/0/all/0/1&quot;&gt;Avishay Tal&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We construct a classical oracle relative to which $\mathsf{P} = \mathsf{NP}$
yet single-copy secure pseudorandom quantum states exist. In the language of
Impagliazzo&#39;s five worlds, this is a construction of pseudorandom states in
&quot;Algorithmica,&quot; and hence shows that in a black-box setting, quantum
cryptography based on pseudorandom states is possible even if one-way functions
do not exist. As a consequence, we demonstrate that there exists a property of
a cryptographic hash function that simultaneously (1) suffices to construct
pseudorandom states, (2) holds for a random oracle, and (3) is independent of
$\mathsf{P}$ vs. $\mathsf{NP}$ in the black-box setting. We also introduce a
conjecture that would generalize our results to multi-copy secure pseudorandom
states.
&lt;/p&gt;
&lt;p&gt;We build on the recent construction by Aaronson, Ingram, and Kretschmer (CCC
2022) of an oracle relative to which $\mathsf{P} = \mathsf{NP}$ but
$\mathsf{BQP} \neq \mathsf{QCMA}$, based on hardness of the OR $\circ$
Forrelation problem. Our proof also introduces a new discretely-defined variant
of the Forrelation distribution, for which we prove pseudorandomness against
$\mathsf{AC^0}$ circuits. This variant may be of independent interest.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Identifying the reach from high-dimensional point cloud data with connections to r-convexity</title>
    <link href="http://arxiv.org/abs/2212.01013"/>
    <id>http://arxiv.org/abs/2212.01013</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cotsakis_R/0/1/0/all/0/1&quot;&gt;Ryan Cotsakis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The convexity of a set can be generalized to the two weaker notions of reach
and $r$-convexity; both describe the regularity of a set&#39;s boundary. In this
article, these two notions are shown to be equivalent for closed subsets of
$\mathbb{R}^d$ with $C^1$ smooth, $(d-1)$-dimensional boundary. In the general
case, for closed subsets of $\mathbb{R}^d$, we detail a new characterization of
the reach in terms of the distance-to-set function applied to midpoints of
pairs of points in the set. For compact subsets of $\mathbb{R}^d$, we provide
methods of approximating the reach and $r$-convexity based on high-dimensional
point cloud data. These methods are intuitive and highly tractable, and produce
upper bounds that converge to the respective quantities as the density of the
point cloud is increased. Simulation studies suggest that the rates at which
the approximation methods converge correspond to those established
theoretically.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: The medial axis of closed bounded sets is Lipschitz stable with respect to the Hausdorff distance under ambient diffeomorphisms</title>
    <link href="http://arxiv.org/abs/2212.01118"/>
    <id>http://arxiv.org/abs/2212.01118</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kourimska_H/0/1/0/all/0/1&quot;&gt;Hana Dal Poz Kou&amp;#x159;imsk&amp;#xe1;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lieutier_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; Lieutier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wintraecken_M/0/1/0/all/0/1&quot;&gt;Mathijs Wintraecken&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We prove that the medial axis of closed sets is Hausdorff stable in the
following sense: Let $\mathcal{S} \subseteq \mathbb{R}^d$ be (fixed) closed set
(that contains a bounding sphere). Consider the space of $C^{1,1}$
diffeomorphisms of $\mathbb{R}^d$ to itself, which keep the bounding sphere
invariant. The map from this space of diffeomorphisms (endowed with some Banach
norm) to the space of closed subsets of $\mathbb{R}^d$ (endowed with the
Hausdorff distance), mapping a diffeomorphism $F$ to the closure of the medial
axis of $F(\mathcal{S})$, is Lipschitz. This extends a previous stability
result of Chazal and Soufflet on the stability of the medial axis of $C^2$
manifolds under $C^2$ ambient diffeomorphisms.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Sometimes Two Irrational Guards are Needed</title>
    <link href="http://arxiv.org/abs/2212.01211"/>
    <id>http://arxiv.org/abs/2212.01211</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meijer_L/0/1/0/all/0/1&quot;&gt;Lucas Meijer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miltzow_T/0/1/0/all/0/1&quot;&gt;Tillmann Miltzow&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the art gallery problem, we are given a closed polygon $P$, with rational
coordinates and an integer $k$. We are asked whether it is possible to find a
set (of guards) $G$ of size $k$ such that any point $p\in P$ is seen by a point
in $G$. We say two points $p$, $q$ see each other if the line segment $pq$ is
contained inside $P$. It was shown by Abrahamsen, Adamaszek, and Miltzow that
there is a polygon that can be guarded with three guards, but requires four
guards if the guards are required to have rational coordinates. In other words,
an optimal solution of size three might need to be irrational. We show that an
optimal solution of size two might need to be irrational. Note that it is
well-known that any polygon that can be guarded with one guard has an optimal
guard placement with rational coordinates. Hence, our work closes the gap on
when irrational guards are possible to occur.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Disjoint faces in simple drawings of the complete graph and topological Heilbronn problems</title>
    <link href="http://arxiv.org/abs/2212.01311"/>
    <id>http://arxiv.org/abs/2212.01311</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hubard_A/0/1/0/all/0/1&quot;&gt;Alfredo Hubard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Suk_A/0/1/0/all/0/1&quot;&gt;Andrew Suk&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a complete simple topological graph $G$, a $k$-face generated by $G$ is
the open bounded region enclosed by the edges of a non-self-intersecting
$k$-cycle in $G$. Interestingly, there are complete simple topological graphs
with the property that every odd face it generates contains the origin. In this
paper, we show that every complete $n$-vertex simple topological graph
generates at least $\Omega(n^{1/3})$ pairwise disjoint 4-faces. As an immediate
corollary, every complete simple topological graph on $n$ vertices drawn in the
unit square generates a 4-face with area at most $O(n^{-1/3})$. Finally, we
investigate a $\mathbb Z_2$ variant of Heilbronn triangle problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Trie-Compressed Intersectable Sets</title>
    <link href="http://arxiv.org/abs/2212.00946"/>
    <id>http://arxiv.org/abs/2212.00946</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arroyuelo_D/0/1/0/all/0/1&quot;&gt;Diego Arroyuelo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castillo_J/0/1/0/all/0/1&quot;&gt;Juan Pablo Castillo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce space- and time-efficient algorithms and data structures for the
offline set intersection problem. We show that a sorted integer set $S
\subseteq [0{..}u)$ of $n$ elements can be represented using compressed space
while supporting $k$-way intersections in adaptive
$O(k\delta\lg{\!(u/\delta)})$ time, $\delta$ being the alternation measure
introduced by Barbay and Kenyon. Our experimental results suggest that our
approaches are competitive in practice, outperforming the most efficient
alternatives (Partitioned Elias-Fano indexes, Roaring Bitmaps, and Recursive
Universe Partitioning (RUP)) in several scenarios, offering in general relevant
space-time trade-offs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Bin Packing with Partition Matroid can be Approximated within $o(OPT)$ Bins</title>
    <link href="http://arxiv.org/abs/2212.01025"/>
    <id>http://arxiv.org/abs/2212.01025</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doron_Arad_I/0/1/0/all/0/1&quot;&gt;Ilan Doron-Arad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulik_A/0/1/0/all/0/1&quot;&gt;Ariel Kulik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shachnai_H/0/1/0/all/0/1&quot;&gt;Hadas Shachnai&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the Bin Packing problem with a partition matroid constraint. The
input is a set of items of sizes in $(0,1]$, and a partition matroid over the
items. The goal is to pack all items in a minimum number of unit-size bins,
such that each bin forms an independent set in the matroid. The problem is a
generalization of both Group Bin Packing and Bin Packing with Cardinality
Constraints. Bin Packing with Partition Matroid naturally arises in resource
allocation to ensure fault tolerance and security, as well as in harvesting
computing capacity. Our main result is a polynomial-time algorithm that packs
the items in $OPT + o(OPT)$ bins, where OPT is the minimum number of bins
required for packing the given instance. This matches the best known result for
the classic Bin Packing problem up to the function hidden by o(OPT). As special
cases, our result improves upon the existing APTAS for Group Bin Packing and
generalizes the AFTPAS for Bin Packing with Cardinality Constraints. Our
approach is based on rounding a solution for a configuration-LP formulation of
the problem. The rounding takes a novel point of view of prototypes in which
items are interpreted as placeholders for other items and applies fractional
grouping to modify a fractional solution (prototype) into one having nice
integrality properties.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Computing the optimal BWT of very large string collections</title>
    <link href="http://arxiv.org/abs/2212.01156"/>
    <id>http://arxiv.org/abs/2212.01156</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cenzato_D/0/1/0/all/0/1&quot;&gt;Davide Cenzato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerrini_V/0/1/0/all/0/1&quot;&gt;Veronica Guerrini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liptak_Z/0/1/0/all/0/1&quot;&gt;Zsuzsanna Lipt&amp;#xe1;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosone_G/0/1/0/all/0/1&quot;&gt;Giovanna Rosone&lt;/a&gt;&lt;/p&gt;&lt;p&gt;It is known that the exact form of the Burrows-Wheeler-Transform (BWT) of a
string collection depends, in most implementations, on the input order of the
strings in the collection. Reordering strings of an input collection affects
the number of equal-letter runs $r$, arguably the most important parameter of
BWT-based data structures, such as the FM-index or the $r$-index. Bentley,
Gibney, and Thankachan [ESA 2020] introduced a linear-time algorithm for
computing the permutation of the input collection which yields the minimum
number of runs of the resulting BWT.
&lt;/p&gt;
&lt;p&gt;In this paper, we present the first tool that guarantees a
Burrows-Wheeler-Transform with minimum number of runs (optBWT), by combining i)
an algorithm that builds the BWT from a string collection (either SAIS-based
[Cenzato et al., SPIRE 2021] or BCR [Bauer et al., CPM 2011]); ii) the SAP
array data structure introduced in [Cox et al., Bioinformatics, 2012]; and iii)
the algorithm by Bentley et al.
&lt;/p&gt;
&lt;p&gt;We present results both on real-life and simulated data, showing that the
improvement achieved in terms of $r$ with respect to the input order is
significant and the overhead created by the computation of the optimal BWT
negligible, making our tool competitive with other tools for BWT-computation in
terms of running time and space usage. In particular, on real data the optBWT
obtains up to 31 times fewer runs with only a $1.39\times$ slowdown.
&lt;/p&gt;
&lt;p&gt;Source code is available at https://github.com/davidecenzato/optimalBWT.git.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-176 |  The power of the Binary Value Principle | 

	Yaroslav Alekseev, 

	Edward Hirsch</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/176"/>
    <id>https://eccc.weizmann.ac.il/report/2022/176</id>
    <updated>2022-12-04T04:21:35+00:00</updated>
    <content type="html" xml:lang="en">
    The (extended) Binary Value Principle (eBVP, the equation $\sum x_i 2^{i-1} = -k$ for $k &amp;gt; 0$
and in the presence of $x_i^2=x_i$) has received a lot of attention recently, several lower
bounds have been proved for it [Alekseev et al 20, Alekseev 21, Part and Tzameret 21]. 
Also it has been shown [Alekseev et al 20] that the 
probabilistically verifiable Ideal Proof System (IPS) [Grochow and Pitassi 18] together with eBVP
polynomially simulates a similar semialgebraic proof system. In this paper we consider
Polynomial Calculus with the algebraic version of Tseitins extension rule (Ext-PC). Contrary
to IPS, this is a Cook--Reckhow proof system. We show that in this context eBVP still allows
to simulate similar semialgebraic systems. We also prove that it allows to simulate the
Square Root Rule [Grigoriev and Hirsch 03], which is in sharp contrast with the result of [Alekseev 21] that shows
an exponential lower bound on the size of Ext-PC derivations of the Binary Value Principle
from its square. On the other hand, we demonstrate that eBVP probably does not help in
proving exponential lower bounds for Boolean formulas: we show that an Ext-PC (even with
the Square Root Rule) derivation of any unsatisfiable Boolean formula in CNF from eBVP
must be of exponential size.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-175 |  Derandomization Under Different Resource Constraints | 

	Samuel Epstein</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/175"/>
    <id>https://eccc.weizmann.ac.il/report/2022/175</id>
    <updated>2022-12-04T04:19:03+00:00</updated>
    <content type="html" xml:lang="en">
    We provide another proof to the EL Theorem. We show the tradeoff between compressibility of codebooks and their communication capacity. A resource bounded version of the EL Theorem is proven. This is used to prove three instances of resource bounded derandomization.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-174 |  Noisy Radio Network Lower Bounds Via Noiseless Beeping Lower Bounds | 

	Raghuvansh Saxena, 

	Gillat Kol, 

	Klim Efremenko, 

	Dmitry Paramonov</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/174"/>
    <id>https://eccc.weizmann.ac.il/report/2022/174</id>
    <updated>2022-12-04T04:13:34+00:00</updated>
    <content type="html" xml:lang="en">
    Much of today&amp;#39;s communication is carried out over large wireless systems with different input-output behaviors. In this work, we compare the power of central abstractions of wireless communication through the general notion of boolean symmetric $f$-channels: In every round of the $f$-channel, each of its $n$ parties decides to either broadcast or not, and the channel outputs $f(m)$, where $m$ is the number of broadcasting parties.

Our first result is that the well studied beeping channel, where $f$ is the threshold-$1$ function, is not stronger than any other $f$-channel. To this end, we design a protocol over the $f$-channel and prove that any protocol that simulates it over the beeping channel blows up the round complexity by a factor of $\Omega(\log n)$. Our lower bound technique may be of independent interest, as it essentially generalizes the popular fooling set technique by exploiting a &amp;quot;local&amp;quot; relaxation of combinatorial rectangles.

Curiously, while this result shows the limitations of a noiseless channel, namely, the beeping channel, we are able to use it to show the limitations of the noisy version of many other channels. This includes the extensively studied single-hop radio network model with collisions-as-silence (CAS), which is equivalent to the $f$-channel with $f(m)=1$ iff $m=1$.

In particular, our second and main result, obtained from the first, shows that converting CAS protocols to noise resilient ones may incur a large performance overhead, i.e., no constant rate interactive code exists. To this end, we design a CAS protocol and prove that any protocol that simulates it over the noisy CAS model with correlated stochastic noise, blows up the round complexity by a factor of $\Omega(\log n)$. We mention that the $\Omega(\log n)$ overhead in both our results is tight.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">TOC for Fairness: Our 2023 Postdoc Program is up</title>
    <link href="https://toc4fairness.org/our-2023-postdoc-program-is-up/"/>
    <id>https://toc4fairness.org/?p=2387</id>
    <updated>2022-12-03T19:20:43+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;/p&gt;



&lt;p&gt;The &lt;a href=&quot;https://toc4fairness.org/&quot; data-type=&quot;URL&quot; data-id=&quot;https://toc4fairness.org/&quot;&gt;Simons collaboration on the theory of algorithmic fairness&lt;/a&gt; is excited to announce &lt;a href=&quot;https://toc4fairness.org/postdoc-opportunities/&quot; data-type=&quot;URL&quot; data-id=&quot;https://toc4fairness.org/postdoc-opportunities/&quot;&gt;our new postdoc program&lt;/a&gt;. We are seeking strong candidates from a diverse set of academic backgrounds and personal experiences who want to work with one or more of the PIs on algorithmic fairness and responsible computing more broadly. We expect to be extending multiple offers.  &lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Omer Reingold&lt;/p&gt;
  </content>
    <author>
      <name>TOC for Fairness</name>
      <uri>https://toc4fairness.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Postdoc in combinatorial optimization at University of Copenhagen (apply by January 15, 2023)</title>
    <link href="https://cstheory-jobs.org/2022/12/03/postdoc-in-combinatorial-optimization-at-university-of-copenhagen-apply-by-january-15-2023/"/>
    <id>http://cstheory-jobs.org/2022/12/03/postdoc-in-combinatorial-optimization-at-university-of-copenhagen-apply-by-january-15-2023/</id>
    <updated>2022-12-03T11:49:30+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The CS department at the University of Copenhagen invites applications for postdoc positions in combinatorial optimization. The application deadline is January 15. See &lt;a href=&quot;http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230115.html&quot;&gt;http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230115.html&lt;/a&gt; for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to jn@di.ku.dk.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230115.html&quot;&gt;http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230115.html&lt;/a&gt;&lt;br /&gt;
Email: jn@di.ku.dk&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">TCS+ Seminar Series: TCS+ Test of Time talk: Wednesday, December 7  Ronitt Rubinfeld, MIT and Tel Aviv University</title>
    <link href="https://tcsplus.wordpress.com/2022/12/03/tcs-test-of-time-talk-wednesday-december-7-ronitt-rubinfeld-mit-and-tel-aviv-university/"/>
    <id>http://tcsplus.wordpress.com/?p=658</id>
    <updated>2022-12-03T05:33:48+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;/p&gt;


&lt;p&gt;The next TCS+ talk will take place this coming Wednesday, December 7th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). &lt;a href=&quot;https://people.csail.mit.edu/ronitt/&quot;&gt;&lt;strong&gt;Ronitt Rubinfeld&lt;/strong&gt;&lt;/a&gt; from MIT and Tel Aviv University will give our very first &amp;#8220;Test of Time&amp;#8221; talk, titled &amp;#8220;&lt;em&gt;A Comedy of Errors&lt;/em&gt;&amp;#8221; (abstract below).&lt;/p&gt;
&lt;p&gt;You can reserve a spot as an individual or a group to join us live by signing up on &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/next-tcs-talk&quot;&gt;the online form&lt;/a&gt;. Registration is &lt;em&gt;not&lt;/em&gt; required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/past-talks&quot;&gt;on our website&lt;/a&gt; afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/suggest-a-talk&quot;&gt;suggest&lt;/a&gt; a possible topic or speaker, please see &lt;a href=&quot;https://sites.google.com/view/tcsplus/&quot;&gt;the website&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;Abstract: In the late 1980s, a new model of &amp;#8220;Program Checking&amp;#8221; was put forth by Blum and Kannan in order to prevail over errors in programs. With that as a starting point, several lines of research developed &amp;#8212; including one that eventually morphed into the area of sublinear time algorithms. Along the way, errors were made and others were detected. We will recount a personal view of the arbitrary nature of this process and place it in historical context.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The talk will be followed by an unrecorded &amp;#8220;Ask Me Anything&amp;#8221; (AMA) session.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;&lt;p class=&quot;authors&quot;&gt;By plustcs&lt;/p&gt;
  </content>
    <author>
      <name>TCS+ Seminar Series</name>
      <uri>https://tcsplus.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Simons-Berkeley Research Fellowships at Simons Institute (apply by December 15, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/12/03/simons-berkeley-research-fellowships-at-simons-institute-apply-by-december-15-2022/"/>
    <id>http://cstheory-jobs.org/2022/12/03/simons-berkeley-research-fellowships-at-simons-institute-apply-by-december-15-2022/</id>
    <updated>2022-12-03T02:40:31+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;[Deadline Reminder] The Simons Institute for the Theory of Computing invites applications for Simons-Berkeley Research Fellowships for the Summer 2023, Fall 2023, and Spring 2024 semesters. The deadline for receipt of applications is December 15, 2022.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications&quot;&gt;https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications&lt;/a&gt;&lt;br /&gt;
Email: simonsvisitorservices@berkeley.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Scott Aaronson: Google&amp;#8217;s Sycamore chip: no wormholes, no superfast classical simulation either</title>
    <link href="https://scottaaronson.blog/?p=6871"/>
    <id>https://scottaaronson.blog/?p=6871</id>
    <updated>2022-12-02T23:04:15+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;div class=&quot;wp-block-image&quot;&gt;
&lt;figure class=&quot;aligncenter size-large&quot;&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://www.scottaaronson.com/sycamore.jpg&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Update (Dec. 6):&lt;/mark&gt;&lt;/strong&gt; I&amp;#8217;m having a blast at the &lt;a href=&quot;https://www.ias.edu/sns/scientific-program-qubit-2022&quot;&gt;Workshop on Spacetime and Quantum Information&lt;/a&gt; at the Institute for Advanced Study in Princeton.  I&amp;#8217;m learning a huge amount from the talks and discussions here&amp;#8212;and also simply enjoying being back in Princeton, to see old friends and visit old haunts like the &lt;a href=&quot;https://palmersquare.com/directory/the-bent-spoon/&quot;&gt;Bent Spoon&lt;/a&gt;.  Tomorrow I&amp;#8217;ll speak about my &lt;a href=&quot;https://arxiv.org/abs/2210.15601&quot;&gt;recent work with Jason Pollack&lt;/a&gt; on polynomial-time AdS bulk reconstruction.&lt;/p&gt;



&lt;p&gt;But there&amp;#8217;s one thing, relevant to this post, that I can&amp;#8217;t let pass without comment.  Tonight, David Nirenberg, Director of the IAS and a medieval historian, gave an after-dinner speech to our workshop, centered around how auspicious it was that the workshop was being held a mere week after the momentous announcement that &lt;em&gt;a wormhole had been created on a microchip (!!)&lt;/em&gt;&amp;#8212;in a feat that experts were calling the first-ever laboratory investigation of quantum gravity, and a new frontier for experimental physics itself.  Nirenberg speculated that, a century from today, people might look back on the wormhole achievement as today we look back on Eddington&amp;#8217;s 1919 eclipse observations providing the evidence for general relativity.&lt;/p&gt;



&lt;p&gt;I confess: this was the first time I felt visceral anger, rather than mere bemusement, over this wormhole affair.  Before, I had implicitly assumed: no one was &lt;em&gt;actually&lt;/em&gt; hoodwinked by this.  No one &lt;em&gt;really, literally&lt;/em&gt; believed that this little 9-qubit simulation opened up a wormhole, or helped prove the holographic nature of the real universe, or anything like that.  I was wrong.&lt;/p&gt;



&lt;p&gt;To be clear, I don&amp;#8217;t blame Professor Nirenberg at all.  If &lt;em&gt;I&lt;/em&gt; were a medieval historian, everything he said about the experiment&amp;#8217;s historic significance might strike me as perfectly valid inferences from what I&amp;#8217;d read in the press.  I don&amp;#8217;t blame the It from Qubit community&amp;#8212;most of which, I can report, was grinding its teeth and turning red in the face right alongside me.  I don&amp;#8217;t even blame most of the authors of the wormhole paper, such as Daniel Jafferis, who gave a perfectly sober, reasonable, technical talk at the workshop about how he and others managed to compress a simulation of a variant of the SYK model into a mere 9 qubits&amp;#8212;a talk that eschewed all claims of historic significance and of literal wormhole creation.&lt;/p&gt;



&lt;p&gt;But it&amp;#8217;s now clear to me that, between&lt;/p&gt;



&lt;p&gt;(1) the It from Qubit community that likes to explore speculative ideas like holographic wormholes, and&lt;/p&gt;



&lt;p&gt;(2) the lay news readers who are now under the impression that Google just did one of the greatest physics experiments of all time,&lt;/p&gt;



&lt;p&gt;&lt;em&gt;something&lt;/em&gt; went terribly wrong&amp;#8212;something that risks damaging trust in the scientific process itself.  And I think it&amp;#8217;s worth reflecting on what we can do to prevent it from happening again.&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;This is going to be one of the many &lt;em&gt;Shtetl-Optimized&lt;/em&gt; posts that I didn&amp;#8217;t feel like writing, but was given no choice but to write.&lt;/p&gt;



&lt;p&gt;News, social media, and my inbox have been abuzz with two claims about Google&amp;#8217;s Sycamore quantum processor, the one that now has 72 superconducting qubits.&lt;/p&gt;



&lt;p&gt;The first claim is that Sycamore created a wormhole (!)&amp;#8212;a historic feat possible only with a quantum computer.  See for example the &lt;em&gt;&lt;a href=&quot;https://www.nytimes.com/2022/11/30/science/physics-wormhole-quantum-computer.html&quot;&gt;New York Times&lt;/a&gt;&lt;/em&gt; and &lt;em&gt;&lt;a href=&quot;https://www.quantamagazine.org/physicists-create-a-wormhole-using-a-quantum-computer-20221130/&quot;&gt;Quanta&lt;/a&gt;&lt;/em&gt; and &lt;em&gt;&lt;a href=&quot;https://arstechnica.com/science/2022/12/no-physicists-didnt-make-a-real-wormhole-what-they-did-was-still-pretty-cool/&quot;&gt;Ars Technica&lt;/a&gt;&lt;/em&gt; and &lt;em&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-022-03832-z&quot;&gt;Nature&lt;/a&gt;&lt;/em&gt; (and of course, the &lt;a href=&quot;https://www.nature.com/articles/s41586-022-05424-3&quot;&gt;actual paper&lt;/a&gt;), as well as &lt;a href=&quot;https://www.math.columbia.edu/~woit/wordpress/?p=13181&quot;&gt;Peter Woit&amp;#8217;s blog&lt;/a&gt; and &lt;a href=&quot;https://chadorzel.substack.com/p/wormhole-to-2006&quot;&gt;Chad Orzel&amp;#8217;s blog&lt;/a&gt;.&lt;/p&gt;



&lt;p&gt;The second claim is that Sycamore&amp;#8217;s pretensions to quantum supremacy have been refuted.  The latter claim is based on &lt;a href=&quot;https://arxiv.org/abs/2211.03999&quot;&gt;this recent preprint&lt;/a&gt; by Dorit Aharonov, Xun Gao, Zeph Landau, Yunchao Liu, and Umesh Vazirani.  No one&amp;#8212;least of all me!&amp;#8212;doubts that these authors have proved a strong new technical result, solving a significant open problem in the theory of noisy random circuit sampling.  On the other hand, it might be less obvious how to interpret their result and put it in context.  See also a &lt;a href=&quot;https://www.youtube.com/watch?v=zDnA1gu4QO0&quot;&gt;YouTube video&lt;/a&gt; of Yunchao speaking about the new result at this week&amp;#8217;s Simons Institute Quantum Colloquium, and of a panel discussion afterwards, where Yunchao, Umesh Vazirani, Adam Bouland, Sergio Boixo, and your humble blogger discuss what it means.&lt;/p&gt;



&lt;p&gt;On their face, the two claims about Sycamore might seem to be in tension.  After all, if Sycamore can&amp;#8217;t do anything beyond what a classical computer can do, then how exactly did it &lt;em&gt;bend the topology of spacetime&lt;/em&gt;?&lt;/p&gt;



&lt;p&gt;I submit that neither claim is true.  On the one hand, Sycamore did not &amp;#8220;create a wormhole.&amp;#8221;  On the other hand, it remains pretty hard to simulate with a classical computer, as far as anyone knows.  To summarize, then, our knowledge of what Sycamore can and can&amp;#8217;t do remains much the same as last week or last month!&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;Let&amp;#8217;s start with the wormhole thing.  I can&amp;#8217;t really improve over how I put it in Dennis Overbye&amp;#8217;s &lt;em&gt;NYT&lt;/em&gt; piece:&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;The most important thing Id want New York Times readers to understand is this, Scott Aaronson, a quantum computing expert at the University of Texas in Austin, wrote in an email. If this experiment has brought a wormhole into actual physical existence, then a strong case could be made that you, too, bring a wormhole into actual physical existence every time you sketch one with pen and paper.&lt;/p&gt;
&lt;/blockquote&gt;



&lt;p&gt;More broadly, Overbye&amp;#8217;s &lt;em&gt;NYT&lt;/em&gt; piece explains with admirable clarity what this experiment did and didn&amp;#8217;t do&amp;#8212;leaving only the question &amp;#8220;wait &amp;#8230; if that&amp;#8217;s all that&amp;#8217;s going on here, then why is it being written up in the &lt;em&gt;NYT&lt;/em&gt;??&amp;#8221;  This is a rare case where, in my opinion, the &lt;em&gt;NYT&lt;/em&gt; did a much better job than &lt;em&gt;Quanta&lt;/em&gt;, which unequivocally accepted and amplified the &amp;#8220;QC creates a wormhole&amp;#8221; framing.&lt;/p&gt;



&lt;p&gt;Alright, but what&amp;#8217;s the actual basis for the &amp;#8220;QC creates a wormhole&amp;#8221; claim, for those who don&amp;#8217;t want to leave this blog to read about it?  Well, the authors used 9 of Sycamore&amp;#8217;s 72 qubits to do a crude simulation of something called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sachdev%E2%80%93Ye%E2%80%93Kitaev_model&quot;&gt;SYK (Sachdev-Ye-Kitaev) model&lt;/a&gt;.  SYK has become popular as a toy model for quantum gravity.  In particular, it has a holographic dual description, which can indeed involve a spacetime with one or more wormholes.  So, they ran a quantum circuit that crudely modelled the SYK dual of a scenario with information sent through a wormhole.  They then confirmed that the circuit did what it was supposed to do&amp;#8212;i.e., what theyd already classically calculated that it &lt;em&gt;would&lt;/em&gt; do.&lt;/p&gt;



&lt;p&gt;So, the objection is obvious: if someone simulates a black hole on their classical computer, they don&amp;#8217;t say they thereby &amp;#8220;created a black hole.&amp;#8221;  Or if they do, journalists don&amp;#8217;t uncritically repeat the claim.  Why should the standards be different just because we&amp;#8217;re talking about a quantum computer rather than a classical one?&lt;/p&gt;



&lt;p&gt;Did we at least &lt;em&gt;learn anything new&lt;/em&gt; about SYK wormholes from the simulation?  Alas, not really, because 9 qubits take a mere 2&lt;sup&gt;9&lt;/sup&gt;=512 complex numbers to specify their wavefunction, and are therefore trivial to simulate on a laptop.  There&amp;#8217;s some argument in the paper that, if the simulation were scaled up to (say) 100 qubits, then maybe we &lt;em&gt;would&lt;/em&gt; learn something new about SYK.  Even then, however, we&amp;#8217;d mostly learn about certain corrections that arise &lt;em&gt;because&lt;/em&gt; the simulation was being done with &amp;#8220;only&amp;#8221; n=100 qubits, rather than in the n limit where SYK is rigorously understood.  But while those corrections, arising when n is &amp;#8220;neither too large nor too small,&amp;#8221; would surely be interesting to specialists, they&amp;#8217;d have no obvious bearing on the prospects for creating real physical wormholes in our universe.&lt;/p&gt;



&lt;p&gt;And yet, this is not a sensationalistic misunderstanding invented by journalists.  Some prominent quantum gravity theorists themselves&amp;#8212;including some of my close friends and collaborators&amp;#8212;persist in talking about the simulated SYK wormhole as &amp;#8220;actually being&amp;#8221; a wormhole.  What are they thinking?&lt;/p&gt;



&lt;p&gt;Daniel Harlow explained the thinking to me as follows (he stresses that he&amp;#8217;s explaining it, not necessarily endorsing it).  If you had two entangled quantum computers, one on Earth and the other in the Andromeda galaxy, and if they were both simulating SYK, and if Alice on Earth and Bob in Andromeda both &lt;em&gt;uploaded their own brains into their respective quantum simulations&lt;/em&gt;, then it seems possible that the simulated Alice and Bob could have the experience of jumping into a wormhole and meeting each other in the middle.  Granted, they couldn&amp;#8217;t get a message back &lt;em&gt;out&lt;/em&gt; from the wormhole, at least not without &amp;#8220;going the long way,&amp;#8221; which could happen only at the speed of light&amp;#8212;so only simulated-Alice and simulated-Bob themselves could ever &lt;em&gt;test&lt;/em&gt; this prediction.  Nevertheless, &lt;em&gt;if true&lt;/em&gt;, I suppose some would treat it as grounds for regarding a quantum simulation of SYK as &amp;#8220;more real&amp;#8221; or &amp;#8220;more wormholey&amp;#8221; than a classical simulation.&lt;/p&gt;



&lt;p&gt;Of course, this scenario depends on strong assumptions not merely about quantum gravity, but &lt;em&gt;also&lt;/em&gt; about the metaphysics of consciousness!  And I&amp;#8217;d &lt;em&gt;still&lt;/em&gt; prefer to call it a simulated wormhole for simulated people.&lt;/p&gt;



&lt;p&gt;For completeness, here&amp;#8217;s Harlow&amp;#8217;s passage from the &lt;em&gt;NYT&lt;/em&gt; article:&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;Daniel Harlow, a physicist at M.I.T. who was not involved in the experiment, noted that the experiment was based on a model of quantum gravity that was so simple, and unrealistic, that it could just as well have been studied using a pencil and paper.&lt;/p&gt;



&lt;p&gt;So Id say that this doesnt teach us anything about quantum gravity that we didnt already know, Dr. Harlow wrote in an email. On the other hand, I think it is exciting as a technical achievement, because if we cant even do this (and until now we couldnt), then simulating more interesting quantum gravity theories would CERTAINLY be off the table. Developing computers big enough to do so might take 10 or 15 years, he added.&lt;/p&gt;
&lt;/blockquote&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;Alright, let&amp;#8217;s move on to the claim that quantum supremacy has been refuted.  What Aharonov et al. actually show in their &lt;a href=&quot;https://arxiv.org/abs/2211.03999&quot;&gt;new work&lt;/a&gt;, building on &lt;a href=&quot;https://arxiv.org/abs/1810.03176&quot;&gt;earlier work by Gao and Duan&lt;/a&gt;, is that Random Circuit Sampling, with a constant rate of noise per gate and no error-correction, can&amp;#8217;t provide a &lt;em&gt;scalable&lt;/em&gt; approach to quantum supremacy.  Or more precisely: as the number of qubits n goes to infinity, and assuming you&amp;#8217;re in the &amp;#8220;anti-concentration regime&amp;#8221; (which in practice probably means: the depth of your quantum circuit is at least ~log(n)), there&amp;#8217;s a classical algorithm to approximately sample the quantum circuit&amp;#8217;s output distribution in poly(n) time (albeit, not yet a practical algorithm).&lt;/p&gt;



&lt;p&gt;Here&amp;#8217;s what&amp;#8217;s crucial to understand: this is &lt;em&gt;100% consistent&lt;/em&gt; with what those of us working on quantum supremacy had assumed since at least 2016!  We &lt;em&gt;knew&lt;/em&gt; that if you tried to scale Random Circuit Sampling to 200 or 500 or 1000 qubits, while you also increased the circuit depth proportionately, the signal-to-noise ratio would become exponentially small, meaning that your quantum speedup would disappear.  That&amp;#8217;s why, from the very beginning, we targeted the &amp;#8220;practical&amp;#8221; regime of 50-100 qubits: a regime where&lt;/p&gt;



&lt;ol&gt;
&lt;li&gt;you can still see explicitly that you&amp;#8217;re exploiting a 2&lt;sup&gt;50&lt;/sup&gt;&amp;#8211; or 2&lt;sup&gt;100&lt;/sup&gt;-dimensional Hilbert space for computational advantage, thereby confirming one of the main predictions of quantum computing theory, but&lt;/li&gt;



&lt;li&gt;you &lt;em&gt;also&lt;/em&gt; have a signal that (as it turned out) is large enough to see with heroic effort.  &lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;To their credit, Aharonov et al. explain all this perfectly clearly in their abstract and introduction.  I&amp;#8217;m just worried that &lt;em&gt;others&lt;/em&gt; aren&amp;#8217;t reading their paper as carefully as they should be!&lt;/p&gt;



&lt;p&gt;So then, what&amp;#8217;s the new advance in the Aharonov et al. paper?  Well, there had been some hope that circuit depth ~log(n) might be a sweet spot, where an exponential quantum speedup might both exist &lt;em&gt;and&lt;/em&gt; survive constant noise, even in the asymptotic limit of n qubits.  Nothing in Google&amp;#8217;s or USTC&amp;#8217;s actual Random Circuit Sampling experiments depended on that hope, but it would&amp;#8217;ve been nice if it were true.  What Aharonov et al. have now done is to kill that hope, using powerful techniques involving summing over Feynman paths in the Pauli basis.&lt;/p&gt;



&lt;p&gt;Stepping back, what &lt;em&gt;is&lt;/em&gt; the current status of quantum supremacy based on Random Circuit Sampling?  I would say it&amp;#8217;s still standing, but more precariously than I&amp;#8217;d like&amp;#8212;underscoring the need for new and better quantum supremacy experiments.  In more detail, &lt;a href=&quot;https://arxiv.org/abs/2111.03011&quot;&gt;Pan, Chen, and Zhang&lt;/a&gt; have shown how to simulate Google&amp;#8217;s 53-qubit Sycamore chip classically, using what I estimated to be 100-1000X the electricity cost of running the quantum computer itself (&lt;em&gt;including&lt;/em&gt; the dilution refrigerator!).  Approaching from the problem from a different angle, &lt;a href=&quot;https://arxiv.org/abs/2112.01657&quot;&gt;Gao et al.&lt;/a&gt; have given a polynomial-time classical algorithm for spoofing Google&amp;#8217;s Linear Cross-Entropy Benchmark (LXEB)&amp;#8212;&lt;em&gt;but&lt;/em&gt; their algorithm can currently achieve only about 10% of the excess in LXEB that Google&amp;#8217;s experiment found.&lt;/p&gt;



&lt;p&gt;So, though it&amp;#8217;s been under sustained attack from multiple directions these past few years, I&amp;#8217;d say that the flag of quantum supremacy yet waves.  The Extended Church-Turing Thesis is still on thin ice.  The wormhole is still open.  Wait &amp;#8230; &lt;em&gt;no&lt;/em&gt; &amp;#8230; that&amp;#8217;s not what I meant to write&amp;#8230;&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;/mark&gt;With this post, as with future science posts, &lt;em&gt;all off-topic comments will be ruthlessly left in moderation&lt;/em&gt;.  Yes, even if the comments &amp;#8220;create their own reality&amp;#8221; full of anger and disappointment that I talked about what I talked about, instead of what the commenter wanted me to talk about.  Even if merely &lt;em&gt;refuting&lt;/em&gt; the comments would require me to give in and talk about their preferred topics after all.  Please stop.  This is a wormholes-&amp;#8216;n-supremacy post.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </content>
    <author>
      <name>Scott Aaronson</name>
      <uri>https://scottaaronson.blog</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-173 |  On Disperser/Lifting Properties of the Index and Inner-Product Functions | 

	Sajin Koroth, 

	Paul Beame</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/173"/>
    <id>https://eccc.weizmann.ac.il/report/2022/173</id>
    <updated>2022-12-02T22:55:23+00:00</updated>
    <content type="html" xml:lang="en">
    Query-to-communication lifting theorems, which connect the query complexity of a Boolean function to the communication complexity of an associated `lifted&amp;#39; function obtained by composing the function with many copies of another function known as a gadget, have been instrumental in resolving many open questions in computational complexity. Several important complexity questions could be resolved if we could make substantial improvements in the input size required for lifting with the Index function, from its current near-linear size down to polylogarithmic in the number of inputs $N$ of the original function or, ideally, constant. The near-linear size bound was shown by Lovett, Meka, Mertz, Pitassi and Zhang using a recent breakthrough improvement on the Sunflower Lemma to show that a certain graph associated with the Index function of near-linear size is a disperser. They also stated a conjecture about the Index function that is essential for further improvements in the size required for lifting with Index using current techniques. In this paper we prove the following;
  1) The conjecture of Lovett et al. is false when the size of the Index gadget is $\log N-\omega(1)$.
  2) Also, the Inner-Product function, which satisfies the disperser property at size $O(\log N)$, does not have this property when its size is  $\log N-\omega(1)$.
  3) Nonetheless, using Index gadgets of size at least 4, we prove a lifting theorem for a restricted class of communication protocols in which one of the players is limited to sending parities of its inputs.
  4) Using the ideas from this lifting theorem, we derive a strong lifting theorem from decision tree size to parity decision tree size. We use this to derive a general lifting theorem in proof complexity from tree-resolution size to tree-like $Res(\oplus)$ refutation size, which yields many new exponential lower bounds on such proofs.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-172 |  Lifting to Parity Decision Trees Via Stifling | 

	Arkadev Chattopadhyay, 

	Nikhil Mande, 

	Swagato Sanyal, 

	Suhail Sherif</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/172"/>
    <id>https://eccc.weizmann.ac.il/report/2022/172</id>
    <updated>2022-12-02T22:16:33+00:00</updated>
    <content type="html" xml:lang="en">
    We show that the deterministic decision tree complexity of a (partial) function or relation $f$ lifts to the deterministic parity decision tree (PDT) size complexity of the composed function/relation $f \circ g$ as long as the gadget $g$ satisfies a property that we call stifling. We observe that several simple gadgets of constant size, like Indexing on 3 input bits, Inner Product on 4 input bits, Majority on 3 input bits and random functions, satisfy this property. It can be shown that existing randomized communication lifting theorems ([Gs, Pitassi, Watson. SICOMP&amp;#39;20], [Chattopadhyay et al. SICOMP&amp;#39;21]) imply PDT-size lifting. However there are two shortcomings of this approach: first they lift randomized decision tree complexity of $f$, which could be exponentially smaller than its deterministic counterpart when either $f$ is a partial function or even a total search problem. Second, the size of the gadgets in such lifting theorems are as large as logarithmic in the size of the input to $f$. Reducing the gadget size to a constant is an important open problem at the frontier of current research.

Our result shows that even a random constant-size gadget does enable lifting to PDT size. Further, it also yields the first systematic way of turning lower bounds on the width of tree-like resolution proofs of the unsatisfiability of constant-width CNF formulas to lower bounds on the size of tree-like proofs in the resolution with parity system, i.e., $\mathrm{Res}$($\oplus$), of the unsatisfiability of closely related constant-width CNF formulas.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: The Smoothed Complexity of Policy Iteration for Markov Decision Processes</title>
    <link href="http://arxiv.org/abs/2212.00083"/>
    <id>http://arxiv.org/abs/2212.00083</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christ_M/0/1/0/all/0/1&quot;&gt;Miranda Christ&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yannakakis_M/0/1/0/all/0/1&quot;&gt;Mihalis Yannakakis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show subexponential lower bounds (i.e., $2^{\Omega (n^c)}$) on the
smoothed complexity of the classical Howard&#39;s Policy Iteration algorithm for
Markov Decision Processes. The bounds hold for the total reward and the average
reward criteria. The constructions are robust in the sense that the
subexponential bound holds not only on the average for independent random
perturbations of the MDP parameters (transition probabilities and rewards), but
for all arbitrary perturbations within an inverse polynomial range. We show
also an exponential lower bound on the worst-case complexity for the simple
reachability objective.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


</feed>
