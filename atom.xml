<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Theory of Computing Report</title>
  <link rel="self" href=""/>
  <link href=""/>
  <id></id>
  <updated></updated>
  <generator uri="http://feedreader.github.io/">Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]</generator>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">TOC for Fairness: FORC 2023 Deadline Approaching</title>
    <link href="https://toc4fairness.org/forc-2023-deadline-approaching/"/>
    <id>https://toc4fairness.org/?p=2538</id>
    <updated>2023-01-21T04:43:45+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The &lt;a href=&quot;https://responsiblecomputing.org/forc-2023/&quot;&gt;4th annual Symposium on Foundations of Responsible Computing&lt;/a&gt; (FORC) will be held on June 7-9, 2023 in Stanford University, CA, USA. The&lt;a href=&quot;https://responsiblecomputing.org/call-for-papers/&quot; data-type=&quot;URL&quot; data-id=&quot;https://responsiblecomputing.org/call-for-papers/&quot;&gt; call for papers&lt;/a&gt; is out and the deadline is nearing: &lt;/p&gt;



&lt;ul&gt;
&lt;li&gt;Paper Registration (title and abstract): Tuesday, Feb 07, 2023.&lt;/li&gt;



&lt;li&gt;Submission Deadline: Thursday, Feb 09, 2023.&lt;/li&gt;



&lt;li&gt;Author Notification: Friday, Mar 31, 2023.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Please consider FORC for your papers on all topics of responsible computing. Best paper awards are awaiting your excellent submissions in the archival track.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Omer Reingold&lt;/p&gt;
  </content>
    <author>
      <name>TOC for Fairness</name>
      <uri>https://toc4fairness.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Postdoc at HSE University (apply by January 31, 2023)</title>
    <link href="https://cstheory-jobs.org/2023/01/20/postdoc-at-hse-university-apply-by-january-31-2023/"/>
    <id>http://cstheory-jobs.org/2023/01/20/postdoc-at-hse-university-apply-by-january-31-2023/</id>
    <updated>2023-01-20T12:24:52+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;HSE University invites applications for the postdoc positions in theoretical ML, complex systems and applied math, algebraic topology and transformation groups, process and pattern mining. Requirements: a recent PhD degree in a relevant field; fluent English; graduates of the research-oriented PhD programme are more preferable.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://iri.hse.ru/announcements/801288859.html&quot;&gt;https://iri.hse.ru/announcements/801288859.html&lt;/a&gt;&lt;br /&gt;
Email: fellowship@hse.ru&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: stateQIP = statePSPACE</title>
    <link href="http://arxiv.org/abs/2301.07730"/>
    <id>http://arxiv.org/abs/2301.07730</id>
    <updated>2023-01-20T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Metger_T/0/1/0/all/0/1&quot;&gt;Tony Metger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yuen_H/0/1/0/all/0/1&quot;&gt;Henry Yuen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Complexity theory traditionally studies the hardness of solving classical
computational problems. In the quantum setting, it is also natural to consider
a different notion of complexity, namely the complexity of physically preparing
a certain quantum state. We study the relation between two such state
complexity classes: statePSPACE, which contains states that can be generated by
space-uniform polynomial-space quantum circuits, and stateQIP, which contains
states that a polynomial-time quantum verifier can generate by interacting with
an all-powerful untrusted quantum prover. The latter class was recently
introduced by Rosenthal and Yuen (ITCS 2022), who proved that statePSPACE
$\subseteq$ stateQIP.
&lt;/p&gt;
&lt;p&gt;Our main result is the reverse inclusion, stateQIP $\subseteq$ statePSPACE,
thereby establishing equality of the two classes and providing a natural
state-complexity analogue to the celebrated QIP = PSPACE theorem of Jain, et
al. (J. ACM 2011). To prove this, we develop a polynomial-space quantum
algorithm for solving exponentially large &quot;PSPACE-computable&quot; semidefinite
programs (SDPs), which also prepares an optimiser encoded in a quantum state.
Our SDP solver relies on recent block-encoding techniques from quantum
algorithms, demonstrating that these techniques are also useful for complexity
theory.
&lt;/p&gt;
&lt;p&gt;Using similar techniques, we also show that optimal prover strategies for
general quantum interactive protocols can be implemented in quantum polynomial
space. We prove this by studying an algorithmic version of Uhlmann&#39;s theorem
and establishing an upper bound on the complexity of implementing Uhlmann
transformations.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Freeze-Tag is NP-Hard in 3D with $L_1$ distance</title>
    <link href="http://arxiv.org/abs/2301.07757"/>
    <id>http://arxiv.org/abs/2301.07757</id>
    <updated>2023-01-20T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_L/0/1/0/all/0/1&quot;&gt;Lucas de Oliveira Silva&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Arkin et al. in 2002 introduced a scheduling-like problem called Freeze-Tag
Problem (FTP) motivated by robot swarm activation. The input consists of the
locations of n mobile punctual robots in some metric space or graph. Only one
begins &quot;active&quot;, while the others are initially &quot;frozen&quot;. All active robots can
move at unit speed and, upon reaching a frozen one&#39;s location, activates it.
The goal is to activate all the robots in the minimum amount of time, the
so-called makespan. Until 2017 the hardness of this problem in metric spaces
was still open, but then Yu et al. proved it to be NP-Hard in the Euclidian
plane, and in the same year, Demaine and Roudoy demonstrated that the FTP is
also hard in 3D with any $L_p$ distance (with p &amp;gt; 1). However, we still don&#39;t
know whether Demaine&#39;s and Roudoy&#39;s result could be translated to the plane.
This paper fills the p=1 gap by showing that the FTP is NP-Hard in 3D with
$L_1$ distance.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: SoftEnNet: Symbiotic Monocular Depth Estimation and Lumen Segmentation for Colonoscopy Endorobots</title>
    <link href="http://arxiv.org/abs/2301.08157"/>
    <id>http://arxiv.org/abs/2301.08157</id>
    <updated>2023-01-20T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mathew_A/0/1/0/all/0/1&quot;&gt;Alwyn Mathew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Magerand_L/0/1/0/all/0/1&quot;&gt;Ludovic Magerand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Trucco_E/0/1/0/all/0/1&quot;&gt;Emanuele Trucco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Manfredi_L/0/1/0/all/0/1&quot;&gt;Luigi Manfredi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Colorectal cancer is the third most common cause of cancer death worldwide.
Optical colonoscopy is the gold standard for detecting colorectal cancer;
however, about 25 percent of polyps are missed during the procedure. A
vision-based autonomous endorobot can improve colonoscopy procedures
significantly through systematic, complete screening of the colonic mucosa. The
reliable robot navigation needed requires a three-dimensional understanding of
the environment and lumen tracking to support autonomous tasks. We propose a
novel multi-task model that simultaneously predicts dense depth and lumen
segmentation with an ensemble of deep networks. The depth estimation
sub-network is trained in a self-supervised fashion guided by view synthesis;
the lumen segmentation sub-network is supervised. The two sub-networks are
interconnected with pathways that enable information exchange and thereby
mutual learning. As the lumen is in the image&#39;s deepest visual space, lumen
segmentation helps with the depth estimation at the farthest location. In turn,
the estimated depth guides the lumen segmentation network as the lumen location
defines the farthest scene location. Unlike other environments, view synthesis
often fails in the colon because of the deformable wall, textureless surface,
specularities, and wide field of view image distortions, all challenges that
our pipeline addresses. We conducted qualitative analysis on a synthetic
dataset and quantitative analysis on a colon training model and real
colonoscopy videos. The experiments show that our model predicts accurate
scale-invariant depth maps and lumen segmentation from colonoscopy images in
near real-time.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improved Tradeoffs for Leader Election</title>
    <link href="http://arxiv.org/abs/2301.08235"/>
    <id>http://arxiv.org/abs/2301.08235</id>
    <updated>2023-01-20T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kutten_S/0/1/0/all/0/1&quot;&gt;Shay Kutten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_P/0/1/0/all/0/1&quot;&gt;Peter Robinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1&quot;&gt;Ming Ming Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xianbin Zhu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider leader election in clique networks, where $n$ nodes are connected
by point-to-point communication links. For the synchronous clique under
simultaneous wake-up, i.e., where all nodes start executing the algorithm in
round $1$, we show a tradeoff between the number of messages and the amount of
time. More specifically, we show that any deterministic algorithm with a
message complexity of $n f(n)$ requires $\Omega\left(\frac{\log n}{\log
f(n)+1}\right)$ rounds, for $f(n) = \Omega(\log n)$. Our result holds even if
the node IDs are chosen from a relatively small set of size $\Theta(n\log n)$,
as we are able to avoid using Ramsey&#39;s theorem. We also give an upper bound
that improves over the previously-best tradeoff. Our second contribution for
the synchronous clique under simultaneous wake-up is to show that $\Omega(n\log
n)$ is in fact a lower bound on the message complexity that holds for any
deterministic algorithm with a termination time $T(n)$. We complement this
result by giving a simple deterministic algorithm that achieves leader election
in sublinear time while sending only $o(n\log n)$ messages, if the ID space is
of at most linear size. We also show that Las Vegas algorithms (that never
fail) require $\Theta(n)$ messages. For the synchronous clique under
adversarial wake-up, we show that $\Omega(n^{3/2})$ is a tight lower bound for
randomized $2$-round algorithms. Finally, we turn our attention to the
asynchronous clique: Assuming adversarial wake-up, we give a randomized
algorithm that achieves a message complexity of $O(n^{1 + 1/k})$ and an
asynchronous time complexity of $k+8$. For simultaneous wake-up, we translate
the deterministic tradeoff algorithm of Afek and Gafni to the asynchronous
model, thus partially answering an open problem they pose.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Emanuele Viola: Mathematics of the impossible: Computational Complexity</title>
    <link href="https://emanueleviola.wordpress.com/2023/01/19/mathematics-of-the-impossible-computational-complexity/"/>
    <id>http://emanueleviola.wordpress.com/?p=1115</id>
    <updated>2023-01-19T19:02:11+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;I am teaching and writing some notes on complexity. I hope they will become a book, so they are organized as such. The notes will be serialized on this blog, and you can find &lt;a href=&quot;https://www.ccs.neu.edu/home/viola/papers/moti.pdf&quot;&gt;the latest version of the book in pdf here&lt;/a&gt;, which has a better rendering of tables, pictures, comic strips, etc.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 class=&quot;sectionHead&quot;&gt;&lt;span class=&quot;titlemark&quot;&gt;0.1   &lt;/span&gt; &lt;a id=&quot;x1-20000.1&quot;&gt;&lt;/a&gt;Conventions, choices, and caveats&lt;/h3&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;I write this section before the work is complete, so some of it may change.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   This book covers basic results in complexity theory and can be used for a course on the subject. At the same time, it is perhaps &lt;em&gt;sui generis&lt;/em&gt; in that it also tells a story of the quest for impossibility results, includes some personal reflections, and makes some non-standard choices about topics and technical details. Some of this is discussed next.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;To test your understanding of the material&amp;#8230;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   this book is interspersed with mistakes, some subtle, some blatant, some not even mistakes but worrying glimpses into the author’s mind. Please send all bug reports and comments to &lt;em&gt;(my five-letter last name)@ccs.neu.edu &lt;/em&gt;to be included in the list of heroes.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;The &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; notation.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   The mathematical symbol &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; has a special meaning in this text. Every &lt;em&gt;occurrence&lt;/em&gt; of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; denotes a real number &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%3E0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%3E0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%3E0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;gt;0&quot; class=&quot;latex&quot; /&gt;. There exist choices for these numbers such that the claims in this book are (or are meant to be) correct. This replaces, is more compact than, and is less prone to abuse than the big-Oh notation (sloppiness hides inside brackets).&lt;/p&gt;
&lt;div class=&quot;newtheorem&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;span class=&quot;head&quot;&gt; &lt;a id=&quot;x1-2001r1&quot;&gt;&lt;/a&gt; &lt;b&gt;Example&lt;/b&gt; 0.1.  &lt;/span&gt;“For all sufficiently large &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;” can be written as &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n%5Cge+c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n%5Cge+c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Cge+c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&amp;#92;ge c&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   “For every &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;epsilon &quot; class=&quot;latex&quot; /&gt; and all sufficiently large &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;” can be written as &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n%5Cge+c_%7B%5Cepsilon+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n%5Cge+c_%7B%5Cepsilon+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Cge+c_%7B%5Cepsilon+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&amp;#92;ge c_{&amp;#92;epsilon }&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   The following are correct statements:&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   “It is an open problem to show that some function in NP requires circuits of size &lt;img src=&quot;https://s0.wp.com/latex.php?latex=cn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=cn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;cn&quot; class=&quot;latex&quot; /&gt;.” At the moment of this writing, one can replace this occurrence with &lt;img src=&quot;https://s0.wp.com/latex.php?latex=5&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=5&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=5&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;5&quot; class=&quot;latex&quot; /&gt;. Note such a claim will remain true if someone proves a &lt;img src=&quot;https://s0.wp.com/latex.php?latex=6n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=6n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=6n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;6n&quot; class=&quot;latex&quot; /&gt; lower bounds. One just needs to “recompile” the constants in this book.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   “&lt;img src=&quot;https://s0.wp.com/latex.php?latex=c%3E1%2Bc&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c%3E1%2Bc&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%3E1%2Bc&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&amp;gt;1+c&quot; class=&quot;latex&quot; /&gt;”, e.g.&amp;nbsp;assign &lt;img src=&quot;https://s0.wp.com/latex.php?latex=2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;2&quot; class=&quot;latex&quot; /&gt; to the first occurrence, &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt; to the second.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   “&lt;img src=&quot;https://s0.wp.com/latex.php?latex=100n%5E%7B15%7D%3Cn%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=100n%5E%7B15%7D%3Cn%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=100n%5E%7B15%7D%3Cn%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;100n^{15}&amp;lt;n^{c}&quot; class=&quot;latex&quot; /&gt;&amp;#8221;, for=&amp;quot;&amp;quot; all=&amp;quot;&amp;quot; large=&amp;quot;&amp;quot; enough=&amp;quot;&amp;quot; &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%22%22+n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%22%22+n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%22%22+n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;quot;&amp;quot; n&quot; class=&quot;latex&quot; /&gt;.=&amp;quot;&amp;quot; assign=&amp;quot;&amp;quot; c=&amp;quot;16$.&amp;quot;
&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   The following are not true:&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   “&lt;img src=&quot;https://s0.wp.com/latex.php?latex=c%3C1%2Fn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c%3C1%2Fn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%3C1%2Fn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&amp;lt;1/n&quot; class=&quot;latex&quot; /&gt; for every &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;”. No matter what we assign &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; to, we can pick a large enough &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;. Note the assignment to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; is absolute, independent of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   More generally, when subscripted this notation indicates a function of the subscript. There exist choices for these functions such that the claims in this book are (or are meant to be) correct. Again, each occurrence can indicate a different function.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   For the reader who prefers the big-Oh notation a quick an dirty fix is to replace every occurrence of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; in this book with &lt;img src=&quot;https://s0.wp.com/latex.php?latex=O%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=O%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;O(1)&quot; class=&quot;latex&quot; /&gt;.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;The alphabet of TMs.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   I define TMs with a fixed alphabet. This choice slightly simplifies the exposition (one parameter vs.&amp;nbsp;two), while being more in line with common experience (it is more common experience to increase the length of a program than its alphabet). This choice affects the proof of Theorem ??. But it isn’t clear that the details are any worse.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Partial vs.&amp;nbsp;total functions (a.k.a.&amp;nbsp;on promise problems).&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;quote&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;Recall that &lt;em&gt;promise problems offer the most direct way of formulating natural       computational problems. [&amp;#8230;]  &lt;/em&gt;In spite of the foregoing opinions, we adopt the       convention of focusing on standard decision and search problems. &lt;em&gt;&lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XGoldreich08Complexity&quot;&gt;2&lt;/a&gt;]&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;I define complexity w.r.t.&amp;nbsp;&lt;em&gt;partial &lt;/em&gt;functions whereas most texts consider &lt;em&gt;total&lt;/em&gt; functions, i.e.&amp;nbsp;we consider computing functions with arbitrary domains rather than any possible string. This is sometimes called “promise problems.” This affects many things, for example the hierarchy for &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPTime%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {BPTime}&quot; class=&quot;latex&quot; /&gt; (Exercise ??).    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;References and names.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   I decided to keep references in the main text to a minimum, just to avoid having a long list later with items “Result X is due to Y,” but relegate discussion to bibliographic notes. I have also decided to not spell out names of authors, which is increasingly awkward. Central results, such as the PCP theorem, are co-authored by five or more people.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Polynomial.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   It is customary in complexity theory to bound quantities by a polynomial, as in polynomial time, when in fact the only terms that matters is the leading time. This also lends itself to confusion since polynomials with many terms are useful for many other things. I use &lt;em&gt;power&lt;/em&gt; instead of polynomial, as in power time.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Random-access machines.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   “Random access” also leads to strange expressions like “randomized random-access” &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;journals/jcss/AngluinV79&quot;&gt;1&lt;/a&gt;]&lt;/span&gt;.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Reductions.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   Are presented as an implication.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Randomness and circuits.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   While randomness and circuits are everywhere in current research, and seem to be on everyone’s mind, they are sometimes still relegated to later chapters, almost as an afterthought. This book starts with them right away, and attempts to weave them through the narrative.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Data structures&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   Their study, especially negative results, squarely belongs to complexity theory. Yet data structures are strangely omitted in common textbooks. Results on data structures even tend to miss main venues for complexity theory to land instead on more algorithmic venues! We hope this book helps to revert this trend.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Algorithms &amp;amp; Complexity&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   &amp;#8230;are of course two sides of the same coin. The rule of thumb I follow is to present algorithms that are &lt;em&gt;surprising&lt;/em&gt; and &lt;em&gt;challenge our intuition of computation&lt;/em&gt;, and ideally match lower bounds, even though they may not be immediately deployed.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Exercises and problems.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   Exercises are interspersed within the narrative and serve as “concept check.” They are not meant to be difficult or new, though some are. Problems are collected at the end and tend to be harder and more original, though some are not.    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Summary of some terminological and not choices.&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   Here it is:&lt;/p&gt;
&lt;div class=&quot;tabular&quot;&gt;
&lt;table id=&quot;TBL-2&quot; class=&quot;tabular&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;colgroup id=&quot;TBL-2-1g&quot;&gt;
&lt;col id=&quot;TBL-2-1&quot;/&gt;&lt;/colgroup&gt;
&lt;colgroup id=&quot;TBL-2-2g&quot;&gt;
&lt;col id=&quot;TBL-2-2&quot;/&gt;&lt;/colgroup&gt;
&lt;colgroup id=&quot;TBL-2-3g&quot;&gt;
&lt;col id=&quot;TBL-2-3&quot;/&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-1-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-1-1&quot; class=&quot;td11&quot;&gt;     Some other sources&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-1-2&quot; class=&quot;td11&quot;&gt;          this book&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-1-3&quot; class=&quot;td11&quot;&gt;acronym&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-2-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-2-1&quot; class=&quot;td11&quot;&gt;             &lt;img src=&quot;https://s0.wp.com/latex.php?latex=O%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=O%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;O(1)&quot; class=&quot;latex&quot; /&gt;, &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5COmega+%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5COmega+%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5COmega+%281%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;Omega (1)&quot; class=&quot;latex&quot; /&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-2-2&quot; class=&quot;td11&quot;&gt;             &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-2-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-3-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-3-1&quot; class=&quot;td11&quot;&gt;       Turing machine&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-3-2&quot; class=&quot;td11&quot;&gt;        tape machine&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-3-3&quot; class=&quot;td11&quot;&gt;  TM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-4-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-4-1&quot; class=&quot;td11&quot;&gt;   random-access machine&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-4-2&quot; class=&quot;td11&quot;&gt;     rapid-access machine&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-4-3&quot; class=&quot;td11&quot;&gt; RAM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-5-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-5-1&quot; class=&quot;td11&quot;&gt;      polynomial time&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-5-2&quot; class=&quot;td11&quot;&gt;         power time&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-5-3&quot; class=&quot;td11&quot;&gt;   P&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-6-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-6-1&quot; class=&quot;td11&quot;&gt;mapping reduction (sometimes)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-6-2&quot; class=&quot;td11&quot;&gt;    &lt;img src=&quot;https://s0.wp.com/latex.php?latex=A&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=A&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;A&quot; class=&quot;latex&quot; /&gt; reduces to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=B&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=B&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;B&quot; class=&quot;latex&quot; /&gt; in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {P}&quot; class=&quot;latex&quot; /&gt; means &lt;img src=&quot;https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D%5CRightarrow+A%5Cin+%5Ctext+%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D%5CRightarrow+A%5Cin+%5Ctext+%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D%5CRightarrow+A%5Cin+%5Ctext+%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;B&amp;#92;in &amp;#92;text {P}&amp;#92;Rightarrow A&amp;#92;in &amp;#92;text {P}&quot; class=&quot;latex&quot; /&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-6-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-7-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-7-1&quot; class=&quot;td11&quot;&gt;Extended Church-Turing thesis&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-7-2&quot; class=&quot;td11&quot;&gt;Power-time computability thesis&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-7-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-8-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-8-1&quot; class=&quot;td11&quot;&gt;    pairwise independent&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-8-2&quot; class=&quot;td11&quot;&gt;      pairwise uniform&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-8-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-9-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-9-1&quot; class=&quot;td11&quot;&gt;       FP, promise-P&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-9-2&quot; class=&quot;td11&quot;&gt;             P&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-9-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-10-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-10-1&quot; class=&quot;td11&quot;&gt;    TM with any alphabet&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-10-2&quot; class=&quot;td11&quot;&gt;   TM with fixed alphabet&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-10-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-11-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-11-1&quot; class=&quot;td11&quot;&gt;  classes have total functions&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-11-2&quot; class=&quot;td11&quot;&gt; classes have partial functions&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-11-3&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;hline&quot;&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;hr /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;vertical-align:baseline&quot; id=&quot;TBL-2-12-&quot;&gt;
&lt;td style=&quot;text-align:center&quot; id=&quot;TBL-2-12-1&quot; class=&quot;td11&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmedskip+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;medskip &quot; class=&quot;latex&quot; /&gt; &lt;br class=&quot;newline&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Copyright 2022-present by Emanuele Viola&lt;/b&gt;&lt;/p&gt;
&lt;h2 class=&quot;chapterHead&quot;&gt;&lt;span class=&quot;titlemark&quot;&gt;Chapter&amp;nbsp;1&lt;/span&gt;&lt;br /&gt;
&lt;a id=&quot;x1-30001&quot;&gt;&lt;/a&gt;A teaser&lt;/h2&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;Consider a computer with &lt;em&gt;three&lt;/em&gt; bits of memory. There’s also a clock, beating &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1%2C2%2C3%2C%5Cldots+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1%2C2%2C3%2C%5Cldots+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%2C2%2C3%2C%5Cldots+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1,2,3,&amp;#92;ldots &quot; class=&quot;latex&quot; /&gt; In one clock cycle the computer can read one bit of the input and update its memory arbitrarily based on the value of the bit and the current memory, or stop and return a value.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   Let’s give a few examples of what such computer can do.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   First, it can compute the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BAnd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BAnd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BAnd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {And}&quot; class=&quot;latex&quot; /&gt; function on &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; bits:&lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;
&lt;div class=&quot;fbox&quot;&gt;
&lt;div class=&quot;minipage&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BComputing+And+of+%28%5Censuremath+%7Bx_%7B1%7D%7D%2C%5Censuremath+%7Bx_%7B2%7D%7D%2C%5Censuremath+%7B%5Cldots+%7D%2C%5Censuremath+%7Bx_%7Bn%7D%7D%29%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BComputing+And+of+%28%5Censuremath+%7Bx_%7B1%7D%7D%2C%5Censuremath+%7Bx_%7B2%7D%7D%2C%5Censuremath+%7B%5Cldots+%7D%2C%5Censuremath+%7Bx_%7Bn%7D%7D%29%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BComputing+And+of+%28%5Censuremath+%7Bx_%7B1%7D%7D%2C%5Censuremath+%7Bx_%7B2%7D%7D%2C%5Censuremath+%7B%5Cldots+%7D%2C%5Censuremath+%7Bx_%7Bn%7D%7D%29%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Computing And of (&amp;#92;ensuremath {x_{1}},&amp;#92;ensuremath {x_{2}},&amp;#92;ensuremath {&amp;#92;ldots },&amp;#92;ensuremath {x_{n}})}&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BFor+%7Di%3D1%2C2%2C%5Cldots+%5Ctext+%7B+until+%7Dn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BFor+%7Di%3D1%2C2%2C%5Cldots+%5Ctext+%7B+until+%7Dn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BFor+%7Di%3D1%2C2%2C%5Cldots+%5Ctext+%7B+until+%7Dn&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {For }i=1,2,&amp;#92;ldots &amp;#92;text { until }n&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;  &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BRead+%7Dx_%7Bi%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BRead+%7Dx_%7Bi%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BRead+%7Dx_%7Bi%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Read }x_{i}&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;  If &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x_%7Bi%7D%3D0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=x_%7Bi%7D%3D0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bi%7D%3D0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;x_{i}=0&quot; class=&quot;latex&quot; /&gt; return 0&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BReturn+%7D1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BReturn+%7D1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BReturn+%7D1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Return }1&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   We didn’t really use the memory. Let’s consider a slightly more complicated example. A word is &lt;em&gt;palindrome&lt;/em&gt; if it reads the same both ways, like &lt;em&gt;racecar&lt;/em&gt;, &lt;em&gt;non&lt;/em&gt;, &lt;em&gt;anna, &lt;/em&gt;and so on. Similarly, example of palindrome bit strings are &lt;img src=&quot;https://s0.wp.com/latex.php?latex=11%2C0110&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=11%2C0110&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=11%2C0110&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;11,0110&quot; class=&quot;latex&quot; /&gt;, and so on.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   Let’s show that the computer can decide if a given string is palindrome quickly, in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; steps&lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;
&lt;div class=&quot;fbox&quot;&gt;
&lt;div class=&quot;minipage&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BDeciding+if+%5Censuremath+%7B%28x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D%29%7D+is+palindrome%3A%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BDeciding+if+%5Censuremath+%7B%28x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D%29%7D+is+palindrome%3A%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BDeciding+if+%5Censuremath+%7B%28x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D%29%7D+is+palindrome%3A%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Deciding if &amp;#92;ensuremath {(x_{1},x_{2},&amp;#92;ldots ,x_{n})} is palindrome:}&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BFor+%7Di%3D1%2C2%2C%5Cldots+%5Ctext+%7B+until+%7Di%3En%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BFor+%7Di%3D1%2C2%2C%5Cldots+%5Ctext+%7B+until+%7Di%3En%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BFor+%7Di%3D1%2C2%2C%5Cldots+%5Ctext+%7B+until+%7Di%3En%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {For }i=1,2,&amp;#92;ldots &amp;#92;text { until }i&amp;gt;n/2&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;  &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BRead+%5Censuremath+%7Bx_%7Bi%7D%7D+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BRead+%5Censuremath+%7Bx_%7Bi%7D%7D+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BRead+%5Censuremath+%7Bx_%7Bi%7D%7D+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Read &amp;#92;ensuremath {x_{i}} }&quot; class=&quot;latex&quot; /&gt;and write it in memory bit &lt;img src=&quot;https://s0.wp.com/latex.php?latex=m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;m&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;  If &lt;img src=&quot;https://s0.wp.com/latex.php?latex=m%5Cne+x_%7Bn-i%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=m%5Cne+x_%7Bn-i%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m%5Cne+x_%7Bn-i%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;m&amp;#92;ne x_{n-i}&quot; class=&quot;latex&quot; /&gt; return 0&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BReturn+%7D1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BReturn+%7D1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BReturn+%7D1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Return }1&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   That was easy. Now consider the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BMajority%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ctext+%7BMajority%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BMajority%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;text {Majority}&quot; class=&quot;latex&quot; /&gt; function on &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; bits, which is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt; iff the sum of the input bits is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%3En%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%3En%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%3En%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;gt;n/2&quot; class=&quot;latex&quot; /&gt; and &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt; otherwise. Majority, like any other function on &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; bits, can be computed on such a computer in time &lt;em&gt;exponential&lt;/em&gt; in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;. To do that, you do a pass on the input and check if it’s all zero, using the program for And given above. If it is, return &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;. If it is not, you do another pass now checking if it’s all zero except the last bit is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;. If it is, return &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;. You continue this way until you exhausted all the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%2F2&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;2^{n}/2&quot; class=&quot;latex&quot; /&gt; possible inputs with Majority equals to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;. If you never returned &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt; you can now safely return &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   As we said, this works for any function, but it’s terribly inefficient. Can we do better for Majority? Can we compute it in time which is just a power of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;?&lt;/p&gt;
&lt;div class=&quot;newtheorem&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;span class=&quot;head&quot;&gt; &lt;a id=&quot;x1-3001r1&quot;&gt;&lt;/a&gt; &lt;b&gt;Exercise&lt;/b&gt; 1.1.  &lt;/span&gt;Convince yourself that this is impossible. Hint: If you start counting bits, you’ll soon run out of memory.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   If you solved the exercise, you are not alone.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   And yet, we will see the following shocking result:&lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;span class=&quot;doublebox&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;minipage&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Shocking theorem:&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;Majority can be computed on such a computer in time &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n^{c}&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   And this is not a trick tailored to majority. Many other problems, apparently much more complicated, can also be solved in the same time.&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   But, there’s something possibly even more shocking.&lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;span class=&quot;doublebox&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;minipage&quot;&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;&lt;b&gt;Shocking situation:&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;It is consistent with our state of knowledge that every “textbook algorithm” can be solved in time &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n^{c}&quot; class=&quot;latex&quot; /&gt; on such a computer! Nobody can disprove that. (Textbook algorithms include sorting, maxflow, dynamic programming algorithms like longest common subsequence etc., graph problems, numerical problems, etc.)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;   The &lt;b&gt;Shocking theorem &lt;/b&gt;gives some explanation for the &lt;b&gt;Shocking situation&lt;/b&gt;. It will be hard to rule out efficient programs on this model, since they are so powerful and counterintuitive. In fact, we will see later that this can be formalized. Basically, we will show that the model is so strong that it can compute functions that provably escape the reach of current mathematics&amp;#8230; if you believe certain things, like that it’s hard to factor numbers. This now enters some of the &lt;em&gt;mysticism&lt;/em&gt; that surrounds complexity theory, where different beliefs and conjectures are pitted against each other in a battle for ground truth.&lt;/p&gt;
&lt;h3 class=&quot;likesectionHead&quot;&gt;&lt;a id=&quot;x1-40001&quot;&gt;&lt;/a&gt;References&lt;/h3&gt;
&lt;p style=&quot;text-align:justify&quot;&gt;
&lt;div class=&quot;thebibliography&quot;&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt;  [1]&lt;span class=&quot;bibsp&quot;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XDBLP:journals/jcss/AngluinV79&quot;&gt;&lt;/a&gt;Dana Angluin and Leslie&amp;nbsp;G. Valiant.  Fast probabilistic algorithms for hamiltonian    circuits and matchings. J. Comput. Syst. Sci., 18(2):155–193, 1979.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt;  [2]&lt;span class=&quot;bibsp&quot;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XGoldreich08Complexity&quot;&gt;&lt;/a&gt;Oded Goldreich.  Computational Complexity: A Conceptual Perspective.  Cambridge    University Press, 2008.&lt;/p&gt;
&lt;/div&gt;
&lt;p class=&quot;authors&quot;&gt;By Manu&lt;/p&gt;
  </content>
    <author>
      <name>Emanuele Viola</name>
      <uri>https://emanueleviola.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: Meta-Complexity</title>
    <link href="https://blog.computationalcomplexity.org/2023/01/meta-complexity.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-5852987754636111781</id>
    <updated>2023-01-19T14:42:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;I&#39;m sure many of you long-time readers are asking, &quot;Why all this big focus on machine learning in your posts and tweets? You are the &#39;Computational Complexity&#39; blog! You&#39;ve barely said a word about meta-complexity.&quot;&lt;/p&gt;&lt;p&gt;So what is meta-complexity? From what I can tell the term goes back a few years but really came into wide use in computational complexity in the past year. The Computational Complexity Conference held an invited talk on meta-complexity by Rahul Santhanam, and the Simons Institute is hosting a &lt;a href=&quot;https://simons.berkeley.edu/programs/Meta-Complexity2023&quot;&gt;research program&lt;/a&gt; this spring on the topic.&lt;/p&gt;&lt;p&gt;As the name suggests, meta-complexity studies the complexity of computing the complexity of various problems. It&#39;s a term that encompasses recent research into the Minimum Circuit Value Problem (given the truth-table of a Boolean function, find the size of the smallest circuit that computes it) and the complexity of time-bounded Kolmogorov complexity.&amp;nbsp;&lt;/p&gt;&lt;p&gt;To quote from the &lt;a href=&quot;https://simons.berkeley.edu/programs/Meta-Complexity2023&quot;&gt;Simons page&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Meta-complexity provides a unifying framework for a variety of important tasks in several important areas of computer science, including computational complexity, proof complexity, cryptography, and learning theory. These areas are all intimately linked, but only recently are these links being made explicit and studied more closely. For example, learning can be interpreted as solving search versions of the Minimum Circuit Size Problem and related problems. Basing primitives such as one-way functions and indistinguishability obfuscation on standard complexity assumptions is one of the main objectives in theoretical cryptography. Important recent directions involving meta-complexity within proof complexity, such as lifting and automatability, strengthen analogies and connections between proof complexity and circuit complexity. In addition, independence results such as the natural proofs framework have intuitive interpretations in terms of meta-complexity. These connections have led to several recent breakthroughs, including &lt;a href=&quot;https://drops.dagstuhl.de/opus/volltexte/2016/5855/&quot;&gt;quasi-polynomial time PAC-learning algorithms for constant-depth circuits with parity gates&lt;/a&gt;, &lt;a href=&quot;https://doi.org/10.1109/FOCS.2018.00032&quot;&gt;new worst-case to average-case reductions for NP problems&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/2009.11514&quot;&gt;a new complexity-theoretic characterization of one-way functions&lt;/a&gt;, and &lt;a href=&quot;https://arxiv.org/abs/1904.02991&quot;&gt;the NP-hardness of automating resolution&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Not to mention the &lt;a href=&quot;https://blog.computationalcomplexity.org/2022/12/complexity-year-in-review-2022.html&quot;&gt;theorem of the year&lt;/a&gt;,&amp;nbsp;Shuichi Hirahara&#39;s&amp;nbsp;&lt;a href=&quot;https://eccc.weizmann.ac.il/report/2022/119/&quot;&gt;proof&lt;/a&gt; that determining the minimum circuit of a partially specified function is NP-complete.&amp;nbsp;&lt;/p&gt;&lt;p&gt;When you get down to it meta-complexity is all about learning, determining the complexity of finding programs. You cannot escape it.&lt;/p&gt;&lt;p&gt;To dive deeper into meta-complexity check out the &lt;a href=&quot;https://simons.berkeley.edu/workshops/meta-complexity-boot-camp/videos#simons-tabs&quot;&gt;videos&lt;/a&gt; of the Simons meta-complexity bootcamp.&amp;nbsp;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Richard Lipton: Rabin-Scott Time</title>
    <link href="https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/"/>
    <id>https://rjlipton.wpcomstaging.com/?p=20921</id>
    <updated>2023-01-19T07:52:41+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;
&lt;font color=&quot;#0044cc&quot;&gt;&lt;br /&gt;
&lt;em&gt;Nondeterminism&amp;#8212;why did it take so long?&lt;/em&gt;&lt;br /&gt;
&lt;font color=&quot;#000000&quot;&gt;&lt;/p&gt;
&lt;table class=&quot;image alignright&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/rabinscott/&quot; rel=&quot;attachment wp-att-20923&quot;&gt;&lt;img data-attachment-id=&quot;20923&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/rabinscott/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/RabinScott.jpg?fit=332%2C195&amp;amp;ssl=1&quot; data-orig-size=&quot;332,195&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;1&amp;quot;}&quot; data-image-title=&quot;RabinScott&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/RabinScott.jpg?fit=300%2C176&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/RabinScott.jpg?fit=332%2C195&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/RabinScott.jpg?resize=200%2C120&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;200&quot; height=&quot;120&quot; class=&quot;alignright wp-image-20923&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;caption alignright&quot;&gt;&lt;font size=&quot;-2&quot;&gt;2010 interview &lt;a href=&quot;https://cacm.acm.org/magazines/2010/2/69370-an-interview-with-michael-rabin/abstract&quot;&gt;src1&lt;/a&gt;, Society for Science &lt;a href=&quot;https://www.societyforscience.org/alumni/notable/dana-scott/&quot;&gt;src2&lt;/a&gt;&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;
Michael Rabin and Dana Scott won the 1976 Turing Award. They obtained their PhD under Alonzo Church in 1957 and 1958, respectively. They are the only Turing-recognized students of Church&amp;#8212;unless you count Alan Turing himself (1938). &lt;/p&gt;
&lt;p&gt;
Today we talk about their 1959 &lt;a href=&quot;https://www.cse.chalmers.se/~coquand/AUTOMATA/rs.pdf&quot;&gt;paper&lt;/a&gt; &amp;#8220;Finite Automata and Their Decision Problems,&amp;#8221; which was &lt;a href=&quot;https://amturing.acm.org/award_winners/rabin_9681074.cfm&quot;&gt;specifically&lt;/a&gt; &lt;a href=&quot;https://amturing.acm.org/award_winners/scott_1193622.cfm&quot;&gt;cited&lt;/a&gt; in their award.&lt;/p&gt;
&lt;p&gt;
I believe I met each of these other famous students of Church at least once:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
Peter Andrews 1964 &lt;/p&gt;
&lt;li&gt;
Martin Davis 1950 &lt;/p&gt;
&lt;li&gt;
Stephen Kleene 1934 &lt;/p&gt;
&lt;li&gt;
Simon Kochen 1959 &lt;/p&gt;
&lt;li&gt;
Hartley Rogers 1952 &lt;/p&gt;
&lt;li&gt;
Barkley Rosser 1934 &lt;/p&gt;
&lt;li&gt;
Raymond Smullyan 1959
&lt;/ul&gt;
&lt;p&gt;
Of these, &lt;a href=&quot;https://en.wikipedia.org/wiki/Peter_B._Andrews&quot;&gt;Peter&lt;/a&gt; was special to me first: I took a class from him when I was a graduate student at CMU. He was a great lecturer&amp;#8212;I will say more about him soon. &lt;/p&gt;
&lt;p&gt;
Ken and I have just noticed while writing that Martin Davis passed away at the beginning of this month&amp;#8212;see this &lt;a href=&quot;https://www.digitalfieldguide.com/blog/20341&quot;&gt;memorial&lt;/a&gt;. We saw him and Scott speak at the 2012 Turing &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2012/05/17/turings-tiger-birthday-party/&quot;&gt;centennial&lt;/a&gt; event in Princeton. &lt;/p&gt;
&lt;p&gt;
We have mentioned Rabin and Scott together several times on this blog at least in passing, and we said more about Dana&amp;#8217;s work in logic long ago &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2009/05/11/simulation-of-nondeterministic-machines/&quot;&gt;here&lt;/a&gt;. Michael&amp;#8212;I&amp;#8217;m more used to calling him Rabin in writing&amp;#8212;became absolutely central to computational complexity and more besides. He has won just about every award for theory, and we have discussed his work several times: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2009/03/01/rabin-flips-a-coin/&quot;&gt;Rabin Flips a Coin&lt;/a&gt; &lt;/p&gt;
&lt;li&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2011/07/21/rabins-80th-birthday/&quot;&gt;Rabin&amp;#8217;s 80th Birthday&lt;/a&gt; &lt;/p&gt;
&lt;li&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2011/09/05/happy-birthday-michael-rabin/&quot;&gt;Happy Birthday Michael Rabin&lt;/a&gt; &lt;/p&gt;
&lt;li&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2014/03/10/how-to-carry-fame/&quot;&gt;How To Carry Fame&lt;/a&gt;
&lt;/ul&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Talking About Their Paper &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
The Turing award citation says:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; &amp;#8230;for their joint paper &amp;#8220;Finite Automata and Their Decision Problem,&amp;#8221; which introduced the idea of nondeterministic machines, which has proved to be an enormously valuable concept. Their (Scott &amp;amp; Rabin) classic paper has been a continuous source of inspiration for subsequent work in this field. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Whoops&amp;#8212;are we the first to notice the typo of the missing &amp;#8216;s&amp;#8217; from &amp;#8220;Problems&amp;#8221; in the paper title? It is &lt;a href=&quot;https://en.wikipedia.org/wiki/Turing_Award&quot;&gt;reproduced&lt;/a&gt; in Wikipedia&amp;#8217;s version. We have fingered (C)ACM editing &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2022/12/15/a-mutation-carol-2/&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2022/03/26/waiting-for-self-deriving-cars/&quot;&gt;times&lt;/a&gt; &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2021/08/26/great-go-glitchy-grammar/&quot;&gt;recently&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;
Scott&amp;#8217;s Turing Award &lt;a href=&quot;https://amturing.acm.org/award_winners/scott_1193622.cfm&quot;&gt;description&lt;/a&gt; also says:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Computational complexity theory is the study of what is possible to calculate given a specific set of resources &amp;#8230; Scott and Rabin’s concept of nondeterministic machines has proved extremely productive in this research area. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Yet both Rabin and Scott avoided covering the paper in their Turing Award lectures. Scott &lt;a href=&quot;https://dl.acm.org/ft_gateway.cfm?id=1283932&amp;#038;type=pdf&quot;&gt;talked&lt;/a&gt; about his subsequent work on logics for programming. Rabin titled his &lt;a href=&quot;https://dl.acm.org/ft_gateway.cfm?id=1283931&amp;#038;type=pdf&quot;&gt;talk&lt;/a&gt; &amp;#8220;Complexity of Computations.&amp;#8221; This was in accord with what he relates starting from &lt;a href=&quot;https://youtu.be/L3FZzGU3n14?t=2761&quot;&gt;this point&lt;/a&gt; of a 2015 CACM &lt;a href=&quot;https://www.acm.org/turing-award-50/turing-laureate-interviews&quot;&gt;interview&lt;/a&gt; about his Turing Award implicitly also recognizing his 1960 &lt;a href=&quot;https://www.cs.toronto.edu/~sacook/homepage/rabin_thesis.pdf&quot;&gt;paper&lt;/a&gt;, &amp;#8220;Degree of Difficulty of Computing a Function and a Partial Ordering of Recursive Sets.&amp;#8221; However, even in the expanded version of Rabin&amp;#8217;s lecture which CACM published (&lt;a href=&quot;http://rkka21.ru/docs/turing-award/mr1976e.pdf&quot;&gt;searchable copy&lt;/a&gt;), the word &amp;#8220;nondeterministic&amp;#8221; is absent, and &amp;#8220;NP&amp;#8221; is mentioned only as part of &amp;#8220;P = NP&amp;#8221; twice in passing. What gives? &lt;/p&gt;
&lt;p&gt;
One look at the Rabin-Scott &lt;a href=&quot;https://www.cse.chalmers.se/~coquand/AUTOMATA/rs.pdf&quot;&gt;paper&lt;/a&gt; suffices to see that it lives up to the encomium of the CACM&amp;#8217;s preface:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;
&lt;em&gt; [It] has become a classic paper in formal language theory that still forms one of the best introductions to the area. The paper is simultaneously a survey and a research article; it is technically simple and mathematically impeccable. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
The &amp;#8216;survey&amp;#8217; aspect is that the paper includes, organizes, and polishes equally famous work by Kleene, John Myhill, and Anil Nerode, plus building on papers by Edward Moore, Arthur Burks and Hao Wang, and (with mutual rounds of interchange) John Shepherdson. The final paper&amp;#8212;including the results original to Rabin and Scott&amp;#8212;reads like how we teach the automata section of an intro theory course today. The seminal original result to teach is their &lt;a href=&quot;https://en.wikipedia.org/wiki/Powerset_construction&quot;&gt;powerset construction&lt;/a&gt; converting an NFA into an equivalent DFA. Yet some elements are missing, and they may be key to why nondeterminism took so long to formulate.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Time Lapse and a Missing Link? &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
The introduction of nondeterministic machines is often dated to Rabin-Scott in &lt;b&gt;1959&lt;/b&gt;. Yet Kleene&amp;#8217;s famous theorem converting deterministic finite automata (DFAs) into what he termed regular &amp;#8220;events&amp;#8221; dates to &lt;a href=&quot;https://www.rand.org/content/dam/rand/pubs/research_memoranda/2008/RM704.pdf&quot;&gt;1951&lt;/a&gt;. Their equivalence naturally goes through nondeterministic finite automata (NFAs). Were NFAs really unknown to Kleene? Moreover, notions of existentially quantified predicates equivalent to nodeterminism go back even before Turing, as noted in this StackExchange &lt;a href=&quot;https://cstheory.stackexchange.com/questions/32403/who-introduced-nondeterministic-computation&quot;&gt;query&lt;/a&gt; on &amp;#8220;Who introduced nondeterministic computation?&amp;#8221;&lt;/p&gt;
&lt;p&gt;
Some of this apparent 8-year gap is closed by a footnote on the first page of Rabin-Scott:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; &amp;#8220;The bulk of this work was done while the authors were associated with the IBM Research Center during the summer of 1957.&amp;#8221; &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
That shaves off two years. Five more may owe to Kleene&amp;#8217;s report not appearing in final journal form until &lt;a href=&quot;https://www.dlsi.ua.es/~mlf/nnafmc/papers/kleene56representation.pdf&quot;&gt;1956&lt;/a&gt;, when the notation for what he now termed regular &lt;em&gt;expressions&lt;/em&gt; was more polished. But this version still gives nothing near the &amp;#8220;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM+%3D+%28Q%2C%5CSigma%2C%5Cdelta%2Cs%2CF%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M = (Q,&amp;#92;Sigma,&amp;#92;delta,s,F)}&quot; class=&quot;latex&quot; /&gt;&amp;#8221; style of notation which is inchoate in Rabin-Scott. Kleene&amp;#8217;s graphical diagrams are of &lt;em&gt;nerve nets&lt;/em&gt;, as defined in 1944 by Warren McCullogh and Walter Pitts, not state graphs as we represent them now. &lt;/p&gt;
&lt;p&gt;
I&amp;#8212;Ken writing these sections&amp;#8212;still wonder why NFAs were not defined earlier. Current renditions of Kleene&amp;#8217;s Theorem do not care whether a DFA or NFA is given. I speculate the reason is that the most elegant association of NFAs to regular expressions requires what was literally a missing link:&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/epsilonarc/&quot; rel=&quot;attachment wp-att-20924&quot;&gt;&lt;img data-attachment-id=&quot;20924&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/epsilonarc/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/EpsilonArc.png?fit=570%2C160&amp;amp;ssl=1&quot; data-orig-size=&quot;570,160&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;EpsilonArc&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/EpsilonArc.png?fit=300%2C84&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/EpsilonArc.png?fit=570%2C160&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/EpsilonArc.png?resize=200%2C56&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;200&quot; height=&quot;56&quot; class=&quot;aligncenter wp-image-20924&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/EpsilonArc.png?resize=300%2C84&amp;amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/EpsilonArc.png?w=570&amp;amp;ssl=1 570w&quot; sizes=&quot;(max-width: 200px) 100vw, 200px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
Here &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt; stands for the empty string. Thus the arc represents a change of state without stimulus, an idea that is antithetical to nerve nets. I still imagine an alternate history where someone like Charles Peirce, whose electrical diagrams of Boolean logic we noted &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/01/04/logicians-are-everywhere/&quot;&gt;here&lt;/a&gt;, conceived a century earlier of representing the laws of electric circuits symbolically like so:&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/circuitexpressions/&quot; rel=&quot;attachment wp-att-20925&quot;&gt;&lt;img data-attachment-id=&quot;20925&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/01/19/rabin-scott-time/circuitexpressions/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/CircuitExpressions.png?fit=1684%2C416&amp;amp;ssl=1&quot; data-orig-size=&quot;1684,416&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;CircuitExpressions&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/CircuitExpressions.png?fit=300%2C74&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/CircuitExpressions.png?fit=600%2C148&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/CircuitExpressions.png?resize=600%2C150&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;150&quot; class=&quot;aligncenter wp-image-20925&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/CircuitExpressions.png?resize=300%2C74&amp;amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/01/CircuitExpressions.png?zoom=2&amp;amp;resize=600%2C150&amp;amp;ssl=1 1200w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
When the conversion from regular expressions to NFAs was published by Robert McNaughton and Hisao Yamada in &lt;a href=&quot;https://ieeexplore.ieee.org/document/5221603&quot;&gt;1960&lt;/a&gt;, they conditioned their regular expressions into a form that avoided occurrences of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt;. Using &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt; for this conversion has been &lt;a href=&quot;https://en.wikipedia.org/wiki/Thompson&#39;s_construction&quot;&gt;traced&lt;/a&gt; &lt;a href=&quot;https://alexandria.tue.nl/extra1/wskrap/publichtml/9313452.pdf&quot;&gt;back&lt;/a&gt; only to Ken Thompson in &lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/363347.363387&quot;&gt;1968&lt;/a&gt;. That was only a few years before I met this future Turing laureate at the &lt;a href=&quot;https://www.westfieldchessclub.org/&quot;&gt;Westfield Chess Club&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;
In my alternate history, nondeterminism would have seemed natural from forking electrical flow. Instead, as Rabin relates at &lt;a href=&quot;https://youtu.be/L3FZzGU3n14?t=2294&quot;&gt;this point&lt;/a&gt; in his 2015 interview, he and Scott felt they needed to start from a limited form of a Turing machine, the full model then seeming unapproachable. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; &amp;#8220;So we had the model of what are called finite automata and then we decided, as pure exercises for imagination, to consider all possible variations. One of those variations was nondeterministic automata.&amp;#8221; &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Their other variations allowed two-way heads or multiple tapes. In my telling, nondeterminism might have been regarded not as a &amp;#8220;variation&amp;#8221; but as &lt;em&gt;more&lt;/em&gt; fundamental than determinism. Going back to Rabin-Scott and forward again to Thompson and his co-workers at Bell Labs, this is what I argue next.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Nondeterminism is Fundamental &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
A text by John Martin makes the joke that understanding tuple notation like &amp;#8220;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM+%3D+%28Q%2C%5CSigma%2C%5Cdelta%2Cs%2CF%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M = (Q,&amp;#92;Sigma,&amp;#92;delta,s,F)}&quot; class=&quot;latex&quot; /&gt;&amp;#8221; is a sign of being a mathematician. I turn it around and say it&amp;#8217;s really a sign of being an object-oriented programmer:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&lt;br /&gt;
class FA {&lt;br /&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;set&amp;lt;State&amp;gt; Q;&lt;br /&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;set&amp;lt;char&amp;gt; Sigma;&lt;br /&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;State s;&lt;br /&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;set&amp;lt;State&amp;gt; F;&lt;br /&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;...&lt;br /&gt;
}&lt;br /&gt;
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;
I continue by saying that if you were to define &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;delta}&quot; class=&quot;latex&quot; /&gt; as a method via &lt;tt&gt;State delta(State q, char c)&lt;/tt&gt; then you would be stuck with the same method body for each machine instance. This issue can be fixed by making &lt;tt&gt;delta&lt;/tt&gt; a function pointer (or &amp;#8220;delegate&amp;#8221; in terms of the programming language C#), but I hold it more natural to make &lt;tt&gt;delta&lt;/tt&gt; a &lt;tt&gt;set&lt;/tt&gt; of triples of type &lt;tt&gt;(State,char,State)&lt;/tt&gt; instead, which I call &lt;em&gt;instructions&lt;/em&gt;. This notation naturally defines an NFA. Then the machine is deterministic (i.e., a DFA) when for all states &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p}&quot; class=&quot;latex&quot; /&gt; and characters &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{c}&quot; class=&quot;latex&quot; /&gt; there is exactly one &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{q}&quot; class=&quot;latex&quot; /&gt; such that &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%28p%2Cc%2Cq%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{(p,c,q)}&quot; class=&quot;latex&quot; /&gt; is an instruction. I then ask the students,&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Which is the base class, &lt;b&gt;DFA&lt;/b&gt; or &lt;b&gt;NFA&lt;/b&gt;? &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Insofar as automata once created are immutable, the answer is &lt;b&gt;NFA&lt;/b&gt;: A DFA &amp;#8220;Is-A&amp;#8221; NFA that obeys the logical constraint on the set of instructions. In this rendition, NFA is the simpler and more fundamental concept.  It remains so after allowing triples of type &lt;tt&gt;(State,&amp;epsilon;,State)&lt;/tt&gt; too.&lt;/p&gt;
&lt;p&gt;
Later in the course I plump nondeterminism over determinism in other ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
The widest expanse of interesting computational problems are complete in NP, not in P. &lt;/p&gt;
&lt;li&gt;
Many of the problems we put into P&amp;#8212;including some decision problems in the Rabin-Scott paper&amp;#8212;are really complete for nondeterministic logspace. &lt;/p&gt;
&lt;li&gt;
The canonical simulation via breadth-first search goes from &lt;em&gt;nondeterministic&lt;/em&gt; space to deterministic time, and depth-first search takes one from &lt;em&gt;nondeterministic&lt;/em&gt; time to deterministic space. Nondeterministic machines are the necessary givens. &lt;/p&gt;
&lt;li&gt;
Nondeterministic/existential forms of classes often have more characterizations and closure properties. &lt;/p&gt;
&lt;li&gt;
Hadamard gates are nondeterministic; quantum circuits using only Pauli and permutation gates (CNOT, Toffoli, &amp;#8230;) can do classical logic only.
&lt;/ul&gt;
&lt;p&gt;
But the main point I make right away is about &lt;b&gt;succinctness&lt;/b&gt;: NFAs are not only usually smaller and more readable than their equivalent DFAs, they are often &lt;em&gt;more workable&lt;/em&gt;. To exemplify this, I offer two ways of deciding whether a given string &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{x}&quot; class=&quot;latex&quot; /&gt; matches a given regular expression &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Br%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{r}&quot; class=&quot;latex&quot; /&gt;: After converting &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Br%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{r}&quot; class=&quot;latex&quot; /&gt; into an equivalent NFA &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N}&quot; class=&quot;latex&quot; /&gt; via Thompson&amp;#8217;s algorithm diagrammed above, one can either&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
Convert &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N}&quot; class=&quot;latex&quot; /&gt; into an equivalent DFA &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M}&quot; class=&quot;latex&quot; /&gt; and simply run &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M}&quot; class=&quot;latex&quot; /&gt; on &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{x}&quot; class=&quot;latex&quot; /&gt;; or &lt;/p&gt;
&lt;li&gt;
Simulate &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N}&quot; class=&quot;latex&quot; /&gt; on &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bx+%3D+x_1+x_2+%5Ccdots+x_n%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{x = x_1 x_2 &amp;#92;cdots x_n}&quot; class=&quot;latex&quot; /&gt; by updating the set &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_%7Bi-1%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_{i-1}}&quot; class=&quot;latex&quot; /&gt; of possible states before &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{x_i}&quot; class=&quot;latex&quot; /&gt; is read to &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_i%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_i}&quot; class=&quot;latex&quot; /&gt; after &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{x_i}&quot; class=&quot;latex&quot; /&gt; is &amp;#8220;processed,&amp;#8221; as in the guts of the proof of the Rabin-Scott construction.
&lt;/ol&gt;
&lt;p&gt;
I give the examples &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Br_k+%3D+%280+%5Ccup+1%29%5E%2A+1+%280+%5Ccup+1%29%5E%7Bk-1%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{r_k = (0 &amp;#92;cup 1)^* 1 (0 &amp;#92;cup 1)^{k-1}}&quot; class=&quot;latex&quot; /&gt;, which denotes binary strings whose &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k}&quot; class=&quot;latex&quot; /&gt;-th bit from the end is a &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B1%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{1}&quot; class=&quot;latex&quot; /&gt;. Ways I show of economizing on &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt;-arcs yield an NFA &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N_k}&quot; class=&quot;latex&quot; /&gt; with just &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%2B1%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k+1}&quot; class=&quot;latex&quot; /&gt; states. Whereas, the smallest DFA &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M_k}&quot; class=&quot;latex&quot; /&gt; such that &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BL%28M%29+%3D+L%28r_k%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{L(M) = L(r_k)}&quot; class=&quot;latex&quot; /&gt; has &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B2%5Ek%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{2^k}&quot; class=&quot;latex&quot; /&gt; states&amp;#8212;as we prove via Myhill and Nerode&amp;#8217;s theorems (using the latter as given in the survey part of Rabin-Scott). &lt;/p&gt;
&lt;p&gt;
Thus, method 1 involves exponential time in worst case, while method 2 works in time polynomial in &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{n}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k}&quot; class=&quot;latex&quot; /&gt;. Method 2 is essentially the algorithm designed by Thompson and co-workers. This is the first example in the course of the contrast between exponential and polynomial times for the same problem. I show how the NFAs &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N_k}&quot; class=&quot;latex&quot; /&gt; capture the logic of the problem, whereas the DFAs &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M_k}&quot; class=&quot;latex&quot; /&gt; look like a twisty mess even for &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%3D3%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k=3}&quot; class=&quot;latex&quot; /&gt;. Showing a diagram of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM_3%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M_3}&quot; class=&quot;latex&quot; /&gt; or a partial sketch of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM_4%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M_4}&quot; class=&quot;latex&quot; /&gt;, I ask:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Would nature ever do this? &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
This aims to say: the NFA is often &lt;em&gt;more real&lt;/em&gt; than the equivalent DFA.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Open Problems &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Would Rabin or Scott go this far? We could ask them&amp;#8230; We note, however, that the word &amp;#8220;deterministic&amp;#8221;&amp;#8212;to say nothing of &amp;#8220;nondeterministic&amp;#8221; and their other word forms&amp;#8212;is absent from this wonderful list of &lt;a href=&quot;http://www.eecs.harvard.edu/~cat/rabinisms.html&quot;&gt;quotes&lt;/a&gt; from Rabin&amp;#8217;s classes, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
This is trivial, but not obvious. (Fall 1996) &lt;/p&gt;
&lt;li&gt;
If P = NP, then all of modern cryptography collapses. On this happy thought&amp;#8230; (Fall 1998) &lt;/p&gt;
&lt;li&gt;
Zero plus zero is still zero, even in this advanced class. (Spring 2002) &lt;/p&gt;
&lt;li&gt;
It is customary for a student and teacher to be on first name basis once the student gets his Ph.D. Personally I found it difficult to address Church as &amp;#8220;Alonzo&amp;#8221;, but I managed. So let us do it. (Spring 2008)
&lt;/ul&gt;
&lt;p&gt;
We have been talking about people over age 90 and this is true of both Rabin and Scott&amp;#8212;and Nerode. We wish them &lt;a href=&quot;https://en.wikipedia.org/wiki/Sto_lat&quot;&gt;sto lat&lt;/a&gt;&amp;#8212;but at this point, could that traditional long-life wish be an underestimate? &lt;/p&gt;
&lt;p&gt;
&lt;p class=&quot;authors&quot;&gt;By RJLipton+KWRegan&lt;/p&gt;
  </content>
    <author>
      <name>Richard Lipton</name>
      <uri>https://rjlipton.wpcomstaging.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Polynomial-Time Axioms of Choice and Polynomial-Time Cardinality</title>
    <link href="http://arxiv.org/abs/2301.07123"/>
    <id>http://arxiv.org/abs/2301.07123</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grochow_J/0/1/0/all/0/1&quot;&gt;Joshua A. Grochow&lt;/a&gt;&lt;/p&gt;&lt;p&gt;There is no single canonical polynomial-time version of the Axiom of Choice
(AC); several statements of AC that are equivalent in Zermelo-Fraenkel (ZF) set
theory are already inequivalent from a constructive point of view, and are
similarly inequivalent from a complexity-theoretic point of view. In this paper
we show that many classical formulations of AC, when restricted to polynomial
time in natural ways, are equivalent to standard complexity-theoretic
hypotheses, including several that were of interest to Selman. This provides a
unified view of these hypotheses, and we hope provides additional motivation
for studying some of the lesser-known hypotheses that appear here.
&lt;/p&gt;
&lt;p&gt;Additionally, because several classical forms of AC are formulated in terms
of cardinals, we develop a theory of polynomial-time cardinality. Nerode &amp;amp;
Remmel (Contemp. Math. 106, 1990 and Springer Lec. Notes Math. 1432, 1990)
developed a related theory, but restricted to unary sets. Downey (Math. Reviews
MR1071525) suggested that such a theory over larger alphabets could have
interesting connections to more standard complexity questions, and we
illustrate some of those connections here.
&lt;/p&gt;
&lt;p&gt;The connections between AC, cardinality, and complexity questions also allow
us to highlight some of Selman&#39;s work. We hope this paper is more of a
beginning than an end, introducing new concepts and raising many new questions,
ripe for further research.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Pseudorandom Generators for Sliding-Window Algorithms</title>
    <link href="http://arxiv.org/abs/2301.07384"/>
    <id>http://arxiv.org/abs/2301.07384</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Modanese_A/0/1/0/all/0/1&quot;&gt;Augusto Modanese&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A sliding-window algorithm of window size $t$ is an algorithm whose current
operation depends solely on the last $t$ symbols read. We construct
pseudorandom generators (PRGs) for low-space randomized sliding-window
algorithms that have access to a binary randomness source. More specifically,
we lift these algorithms to the non-uniform setting of branching programs and
study them as a subclass thereof that we call sliding-window branching programs
(SWBPs), accordingly. For general SWBPs, given a base PRG $G_\mathrm{base}$
with seed length $d_\mathrm{base}$ that $\varepsilon_\mathrm{base}$-fools
width-$w$, length-$t$ (general) branching programs, we give two PRG
constructions for fooling any same-width SWBP of length $n$ and window size $t$
(where we assume $w \ge n$). The first uses an additional $d_\mathrm{base} +
O(\log(n/t) \log(1/\varepsilon_\mathrm{base}))$ random bits, whereas the second
has a seed length of $O((d_\mathrm{base} + \log\log(n/t) +
\log(1/\varepsilon_\mathrm{base})) \log(d_\mathrm{base} +
\log(1/\varepsilon_\mathrm{base})))$. Both PRGs incur only a $(n/2t)^{O(1)}$
multiplicative loss in the error parameter.
&lt;/p&gt;
&lt;p&gt;As an application, we show how to decide the language of a sublinear-time
probabilistic cellular automaton using small space. More specifically, these
results target the model of PACAs, which are probabilistic cellular automata
that accept if and only if all cells are simultaneously accepting. For
(sublinear) $T(n) = \Omega(\log n)^{1.01}$, we prove that every language
accepted by a $T$-time one-sided error PACA (the PACA equivalent of
$\mathsf{RP}$) can be decided using only $O(T)$ space. Meanwhile, forgoing the
previous requirement on $T$, we show the same holds for $T$-time two-sided
error PACA (the PACA equivalent of $\mathsf{BPP}$) if we use $\tilde{O}(T) +
O(\log n)$ space instead (where the $\tilde{O}$ notation hides only
$\mathsf{polylog}(T)$ factors).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: A New Construction of the Vietoris-Rips Complex</title>
    <link href="http://arxiv.org/abs/2301.07191"/>
    <id>http://arxiv.org/abs/2301.07191</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Rieser_A/0/1/0/all/0/1&quot;&gt;Antonio Rieser&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present a new, inductive construction of the Vietoris-Rips complex, in
which we take advantage of a small amount of unexploited combinatorial
structure in the $k$-skeleton of the complex in order to avoid unnecessary
comparisons when identifying its $(k+1)$-simplices. In doing so, we achieve an
order-of-magnitude speedup over current algorithms when constructing the clique
complexes of Erd\H{o}s-R\&#39;enyi graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: A Note on the $k$-colored Crossing Ratio of Dense Geometric Graphs</title>
    <link href="http://arxiv.org/abs/2301.07261"/>
    <id>http://arxiv.org/abs/2301.07261</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fabila_Monroy_R/0/1/0/all/0/1&quot;&gt;Ruy Fabila-Monroy&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A \emph{geometric graph} is a graph whose vertex set is a set of points in
general position in the plane, and its edges are straight line segments joining
these points. We show that for every integer $k \ge 2$, there exists a constat
$c&amp;gt;0$ such that the following holds. The edges of every dense geometric graph
can be colored with $k$ colors, such that the number of pairs of edges of the
same color that cross is at most $(1/k-c)$ times the total number of pairs of
edges that cross. The case when $k=2$ and $G$ is a complete geometric graph,
was proved by Aichholzer et al.[\emph{GD} 2019].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Robust Zero-crossings Detection in Noisy Signals using Topological Signal Processing</title>
    <link href="http://arxiv.org/abs/2301.07703"/>
    <id>http://arxiv.org/abs/2301.07703</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanweer_S/0/1/0/all/0/1&quot;&gt;Sunia Tanweer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khasawneh_F/0/1/0/all/0/1&quot;&gt;Firas A. Khasawneh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munch_E/0/1/0/all/0/1&quot;&gt;Elizabeth Munch&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We explore a novel application of zero-dimensional persistent homology from
Topological Data Analysis (TDA) for bracketing zero-crossings of both
one-dimensional continuous functions, and uniformly sampled time series. We
present an algorithm and show its robustness in the presence of noise for a
range of sampling frequencies. In comparison to state-of-the-art software-based
methods for finding zeros of a time series, our method generally converges
faster, provides higher accuracy, and is capable of finding all the roots in a
given interval instead of converging only to one of them. We also present and
compare options for automatically setting the persistence threshold parameter
that influences the accurate bracketing of the roots.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Subset Sum in Time $2^{n/2} / poly(n)$</title>
    <link href="http://arxiv.org/abs/2301.07134"/>
    <id>http://arxiv.org/abs/2301.07134</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yaonan Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Randolph_T/0/1/0/all/0/1&quot;&gt;Tim Randolph&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Servedio_R/0/1/0/all/0/1&quot;&gt;Rocco A. Servedio&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A major goal in the area of exact exponential algorithms is to give an
algorithm for the (worst-case) $n$-input Subset Sum problem that runs in time
$2^{(1/2 - c)n}$ for some constant $c&amp;gt;0$. In this paper we give a Subset Sum
algorithm with worst-case running time $O(2^{n/2} \cdot n^{-\gamma})$ for a
constant $\gamma &amp;gt; 0.5023$ in standard word RAM or circuit RAM models. To the
best of our knowledge, this is the first improvement on the classical
``meet-in-the-middle&#39;&#39; algorithm for worst-case Subset Sum, due to Horowitz and
Sahni, which can be implemented in time $O(2^{n/2})$ in these memory models.
&lt;/p&gt;
&lt;p&gt;Our algorithm combines a number of different techniques, including the
``representation method&#39;&#39; introduced by Howgrave-Graham and Joux and subsequent
adaptations of the method in Austrin, Kaski, Koivisto, and Nederlof, and
Nederlof and Wegrzycki, and ``bit-packing&#39;&#39; techniques used in the work of
Baran, Demaine, and Patrascu on subquadratic algorithms for 3SUM.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Relaxed Graph Color Bound for the Maximum k-plex Problem</title>
    <link href="http://arxiv.org/abs/2301.07300"/>
    <id>http://arxiv.org/abs/2301.07300</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1&quot;&gt;Jiongzhi Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1&quot;&gt;Mingming Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yan Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1&quot;&gt;Kun He&lt;/a&gt;&lt;/p&gt;&lt;p&gt;As a relaxation of the clique, a k-plex of a graph is a vertex set that each
vertex is not connected with at most k vertices of this set. Given an
undirected graph, the Maximum k-plex Problem (MkP) aims to find its largest
k-plex. Branch and bound algorithms are a type of well-studied and effective
method for exact MkP solving, whose performance depends heavily on the quality
of the upper bounds. In this paper, we investigate the relaxation properties of
k-plex and propose an effective upper bound called Relaxed Graph color Bound
(RGB) for the MkP. To describe and calculate RGB, we propose a new
quasi-independent set structure that focuses on the number of conflict
vertices. We combine RGB with two of the state-of-the-art branch and bound MkP
algorithms, Maplex and KpLeX. Extensive experiments on real-world benchmarks,
DIMACS benchmarks, and random graphs show the excellent performance of our
proposed method over the state-of-the-art algorithms.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: An Improved Approximation for Maximum Weighted $k$-Set Packing</title>
    <link href="http://arxiv.org/abs/2301.07537"/>
    <id>http://arxiv.org/abs/2301.07537</id>
    <updated>2023-01-19T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiery_T/0/1/0/all/0/1&quot;&gt;Theophile Thiery&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ward_J/0/1/0/all/0/1&quot;&gt;Justin Ward&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the weighted $k$-set packing problem, in which we are given a
collection of weighted sets, each with at most $k$ elements and must return a
collection of pairwise disjoint sets with maximum total weight. For $k = 3$,
this problem generalizes the classical 3-dimensional matching problem listed as
one of the Karp&#39;s original 21 NP-complete problems. We give an algorithm
attaining an approximation factor of $1.786$ for weighted 3-set packing,
improving on the recent best result of $2-\frac{1}{63,700,992}$ due to
Neuwohner.
&lt;/p&gt;
&lt;p&gt;Our algorithm is based on the local search procedure of Berman that attempts
to improve the sum of squared weights rather than the problem&#39;s objective. When
using exchanges of size at most $k$, this algorithm attains an approximation
factor of $\frac{k+1}{2}$. Using exchanges of size $k^2(k-1) + k$, we provide a
relatively simple analysis to obtain an approximation factor of 1.811 when $k =
3$. We then show that the tools we develop can be adapted to larger exchanges
of size $2k^2(k-1) + k$ to give an approximation factor of 1.786. Although our
primary focus is on the case $k = 3$, our approach in fact gives slightly
stronger improvements on the factor $\frac{k+1}{2}$ for all $k &amp;gt; 3$. As in
previous works, our guarantees hold also for the more general problem of
finding a maximum weight independent set in a $(k+1)$-claw free graph.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Dynamic Demand-Aware Link Scheduling for Reconfigurable Datacenters</title>
    <link href="http://arxiv.org/abs/2301.05751"/>
    <id>http://arxiv.org/abs/2301.05751</id>
    <updated>2023-01-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanauer_K/0/1/0/all/0/1&quot;&gt;Kathrin Hanauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1&quot;&gt;Monika Henzinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ost_L/0/1/0/all/0/1&quot;&gt;Lara Ost&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1&quot;&gt;Stefan Schmid&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Emerging reconfigurable datacenters allow to dynamically adjust the network
topology in a demand-aware manner. These datacenters rely on optical switches
which can be reconfigured to provide direct connectivity between racks, in the
form of edge-disjoint matchings. While state-of-the-art optical switches in
principle support microsecond reconfigurations, the demand-aware topology
optimization constitutes a bottleneck.
&lt;/p&gt;
&lt;p&gt;This paper proposes a dynamic algorithms approach to improve the performance
of reconfigurable datacenter networks, by supporting faster reactions to
changes in the traffic demand. This approach leverages the temporal locality of
traffic patterns in order to update the interconnecting matchings
incrementally, rather than recomputing them from scratch. In particular, we
present six (batch-)dynamic algorithms and compare them to static ones. We
conduct an extensive empirical evaluation on 176 synthetic and 39 real-world
traces, and find that dynamic algorithms can both significantly improve the
running time and reduce the number of changes to the configuration, especially
in networks with high temporal locality, while retaining matching weight.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Windows on Theory: New in FOCS 2023: A conjectures track</title>
    <link href="https://windowsontheory.org/2023/01/16/new-in-focs-2023-a-conjectures-track/"/>
    <id>http://windowsontheory.org/?p=8515</id>
    <updated>2023-01-16T22:30:27+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;This year, FOCS 2023 will include something new: a Conjectures Track, separate from the Main Track. Submissions to the Main Track will be evaluated along similar lines as STOC/FOCS papers typically are, aiming to accept papers that obtain the very best results across all fields of theoretical computer science. Submissions to the new Conjectures Track will be evaluated completely separately from submissions to the Main Track. There is no a priori acceptance quota for either track, or desired number of accepted papers: it will all depend on the quality of submissions only.&lt;/p&gt;



&lt;p&gt;What are we hoping for with the Conjectures track? We think of Khot’s Unique Games Conjecture paper as being the “ideal prototype” for a Conjectures Track paper. Papers submitted to the Conjectures Track should be focused on one or more conjectures, describe evidence for and against them, and motivate them through potential implications. We are particularly excited about this as an opportunity for researchers who have been working on a very hard fundamental problem for a long time, and have identified a conjecture (or family of conjectures) that, if proven, could help resolve the problem.&lt;/p&gt;



&lt;p&gt;Papers submitted to the Conjectures Track will be evaluated based on the importance of the conjecture to the relevant field within theoretical computer science and beyond. Of course, conjectures that may open up a new field within theoretical computer science would also be very welcome.&lt;/p&gt;



&lt;p&gt;We believe that talks at FOCS 2023 for papers accepted to the Conjectures Track could end up being among the most interesting of the conference. Please think about your favorite conjectures, and write them up!&lt;/p&gt;



&lt;p&gt;Amit Sahai, Shubhangi Saraf, and Thomas Vidick&lt;/p&gt;



&lt;p&gt;(FOCS 2023 PC Co-Chairs)&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Boaz Barak&lt;/p&gt;
  </content>
    <author>
      <name>Windows on Theory</name>
      <uri>https://windowsontheory.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: ChatGPT tried to write an obit for Martin Davis. What it got right, wrong, and what to make of it.</title>
    <link href="https://blog.computationalcomplexity.org/2023/01/chatgpt-tried-to-write-obit-for-martin.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-354510629432794400</id>
    <updated>2023-01-16T14:16:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;When Martin Davis passed away Lance emailed me what he got from using ChatGPT to do an obit. Here it is and I also note what it got wrong.&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;-------------------------------------------------------------------------&lt;/p&gt;&lt;p&gt;Born in 1928 in Brooklyn, New York, Davis received his bachelor&#39;s degree from Brooklyn College in 1950 [WRONG-1948] and his Ph.D. from the University of Chicago in 1953 [WRONG- it was Princeton in 1950].&amp;nbsp; He went on to have a distinguished career, with positions at the Institute for Advanced Study, the University of California, Berkeley, and New York University, where he spent the majority of his career.&lt;/p&gt;&lt;p&gt;Davis made significant contributions to the field of mathematics, particularly in the areas of computational complexity theory, recursive function theory, and mathematical logic. His work on the Davis-Putnam-Robinson-Matiyasevich algorithm [ADDED LATER BASED ON A COMMENT: WRONG-The DPRM theorem is that there is NO algorithm. It is not an algorithm.] helped establish the connection between logic and computers [WRONG- THE CONNECTION BETWEEN LOGIC AND COMPUTERS WAS ALREADY WELL KNOWN. CONNECTION BETWEEN COMPUTABILITY AND POLYNOMIALS WOULD HAVE BEEN BETTER] and has had major implications for the field of computer science.&lt;/p&gt;&lt;p&gt;In addition to his academic pursuits, Davis was also a dedicated teacher and mentor. He was a popular and engaging speaker, known for his wit and clarity in explaining complex mathematical concepts. He inspired and encouraged countless students throughout his career and left a lasting impact on the mathematical community.&lt;/p&gt;&lt;p&gt;Davis was the recipient of many prestigious awards and honors, including the ACM Turing Award [WRONG- DAVIS NEVER WON A TURING AWARD], the highest honor in computer science, in 1994. He was also a member of the National Academy of Sciences and the American Academy of Arts and Sciences.&amp;nbsp; [I WAS ABLE TO VERIFY THAT HE WAS IN THE AMERICAN ACAD. I WAS NOT ABLE TO VERIFY THAT HE WAS IN THE NATIONAL ACAD, BUT I DO NOT KNOW.]&lt;/p&gt;&lt;p&gt;Martin Davis will be greatly missed by his colleagues, students, and friends.&amp;nbsp; His contributions to mathematics and computer science will not be forgotten and will continue to inspire future generations of mathematicians and scientists.&lt;/p&gt;&lt;p&gt;-------------------------------------------------------------------------&lt;/p&gt;&lt;p&gt;This raises some questions&lt;/p&gt;&lt;p&gt;a) It got some factual things wrong. This surprised me. Its also a cautionary note: when you using ChatGPT for a first draft you need to check factual information.&amp;nbsp;&lt;/p&gt;&lt;p&gt;b) I was going to take the obit and modify it for my post. I found that I could not do this, not because of the mistakes in it, but because its not what I wanted to emphasize. See my obit post&amp;nbsp;&lt;a href=&quot;https://blog.computationalcomplexity.org/2023/01/martin-davis-passed-away-on-jan-1-2023.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;c) Will this make bloggers jobs&amp;nbsp; and other jobs easier by just posting modified versions of things ChatGPT outputs? This is both a hope (less work) and a fear (no work). Options:&amp;nbsp;&lt;/p&gt;&lt;p&gt;c1) Much like farming, there will be a transition period where people are out of work but in the long term its a good thing that instead of 90% of people working on farms its 3%. So people transitioned (or the next generation did) to other jobs. (One could argue if this is really a good thing, though I&#39;ve heard farming was VERY HARD WORK so people are happier not being farmers.)&lt;/p&gt;&lt;p&gt;c2) The jobs that are going away, there will NOT be replacement jobs and we are looking at an economic and psychological catastrophe.&amp;nbsp;&lt;/p&gt;&lt;p&gt;d) Even before ChatGPT I had heard of using a program to output a sports story about little league games for very local papers.&amp;nbsp;&lt;/p&gt;&lt;p&gt;e) The obvious fear: will students have ChatGPT produce their papers for them? In its current state the students would have to modify the paper. A few ways this could go:&lt;/p&gt;&lt;p&gt;e1) Analog to calculators: Students used to have to memorize multiplication up to 20x20 but now we let t hem use calculators. Students used to have to write papers, now we let them use ChatGPT and modify. This may be forced on us as opposed to something we want to do.&lt;/p&gt;&lt;p&gt;e2) There will be a fierce fight where teachers what students to NOT use ChatGPT but its hard to stop them.&amp;nbsp;&lt;/p&gt;&lt;p&gt;e3) ChatGPT will get much better. Even so, there will still be some things its bad at. Students won&#39;t know which is which, or won&#39;t care.&lt;/p&gt;&lt;p&gt;e4) I am tempted to say it won&#39;t affect math but I think it might for, say, standard proofs by induction, standard calculations from calculus (we already have programs that can differentiate and integrate- has that affected how Calculus is taught or graded?).&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By gasarch&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Cumulative Memory Lower Bounds for Randomized and Quantum Computation</title>
    <link href="http://arxiv.org/abs/2301.05680"/>
    <id>http://arxiv.org/abs/2301.05680</id>
    <updated>2023-01-16T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beame_P/0/1/0/all/0/1&quot;&gt;Paul Beame&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kornerup_N/0/1/0/all/0/1&quot;&gt;Niels Kornerup&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Cumulative memory -- the sum of space used over the steps of a computation --
is a fine-grained measure of time-space complexity that is a more accurate
measure of cost for algorithms with infrequent spikes in memory usage in the
context of technologies such as cloud computing that allow dynamic allocation
and de-allocation of resources during their execution. We give the first lower
bounds on cumulative memory complexity that apply to general sequential
classical algorithms. We also prove the first such bounds for bounded-error
quantum circuits. Among many possible applications, we show that any classical
sorting algorithm with success probability at least $1/\text{poly}(n)$ requires
cumulative memory $\tilde \Omega(n^2)$, any classical matrix multiplication
algorithm requires cumulative memory $\Omega(n^6/T)$, any quantum sorting
circuit requires cumulative memory $\Omega(n^3/T)$, and any quantum circuit
that finds $k$ disjoint collisions in a random function requires cumulative
memory $\Omega(k^3n/T^2)$. More generally, we present theorems that can be used
to convert a wide class of existing time-space tradeoff lower bounds to
matching lower bounds on cumulative memory complexity.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Recognizing Unit Disk Graphs in Hyperbolic Geometry is $\exists\mathbb{R}$-Complete</title>
    <link href="http://arxiv.org/abs/2301.05550"/>
    <id>http://arxiv.org/abs/2301.05550</id>
    <updated>2023-01-16T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bieker_N/0/1/0/all/0/1&quot;&gt;Nicholas Bieker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blasius_T/0/1/0/all/0/1&quot;&gt;Thomas Bl&amp;#xe4;sius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dohse_E/0/1/0/all/0/1&quot;&gt;Emil Dohse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jungeblut_P/0/1/0/all/0/1&quot;&gt;Paul Jungeblut&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A graph G is a (Euclidean) unit disk graph if it is the intersection graph of
unit disks in the Euclidean plane $\mathbb{R}^2$. Recognizing them is known to
be $\exists\mathbb{R}$-complete, i.e., as hard as solving a system of
polynomial inequalities. In this note we describe a simple framework to
translate $\exists\mathbb{R}$-hardness reductions from the Euclidean plane
$\mathbb{R}^2$ to the hyperbolic plane $\mathbb{H}^2$. We apply our framework
to prove that the recognition of unit disk graphs in the hyperbolic plane is
also $\exists\mathbb{R}$-complete.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Streaming Lower Bounds and Asymmetric Set-Disjointness</title>
    <link href="http://arxiv.org/abs/2301.05658"/>
    <id>http://arxiv.org/abs/2301.05658</id>
    <updated>2023-01-16T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lovett_S/0/1/0/all/0/1&quot;&gt;Shachar Lovett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiapeng Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Frequency estimation in data streams is one of the classical problems in
streaming algorithms. Following much research, there are now almost matching
upper and lower bounds for the trade-off needed between the number of samples
and the space complexity of the algorithm, when the data streams are
adversarial. However, in the case where the data stream is given in a random
order, or is stochastic, only weaker lower bounds exist. In this work we close
this gap, up to logarithmic factors.
&lt;/p&gt;
&lt;p&gt;In order to do so we consider the needle problem, which is a natural hard
problem for frequency estimation studied in (Andoni et al. 2008, Crouch et al.
2016). Here, the goal is to distinguish between two distributions over data
streams with $t$ samples. The first is uniform over a large enough domain. The
second is a planted model; a secret &#39;&#39;needle&#39;&#39; is uniformly chosen, and then
each element in the stream equals the needle with probability $p$, and
otherwise is uniformly chosen from the domain. It is simple to design streaming
algorithms that distinguish the distributions using space $s \approx 1/(p^2
t)$. It was unclear if this is tight, as the existing lower bounds are weaker.
We close this gap and show that the trade-off is near optimal, up to a
logarithmic factor.
&lt;/p&gt;
&lt;p&gt;Our proof builds and extends classical connections between streaming
algorithms and communication complexity, concretely multi-party unique
set-disjointness. We introduce two new ingredients that allow us to prove sharp
bounds. The first is a lower bound for an asymmetric version of multi-party
unique set-disjointness, where players receive input sets of different sizes,
and where the communication of each player is normalized relative to their
input length. The second is a combinatorial technique that allows to sample
needles in the planted model by first sampling intervals, and then sampling a
uniform needle in each interval.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Incremental Dead State Detection in Logarithmic Time</title>
    <link href="http://arxiv.org/abs/2301.05308"/>
    <id>http://arxiv.org/abs/2301.05308</id>
    <updated>2023-01-16T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanford_C/0/1/0/all/0/1&quot;&gt;Caleb Stanford&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veanes_M/0/1/0/all/0/1&quot;&gt;Margus Veanes&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Identifying live and dead states in an abstract transition system is a
recurring problem in formal verification. However, state-of-the-art graph
algorithms for maintaining reachability information incrementally (that is, as
states are visited and before the entire state space is explored) assume that
new edges can be added from any state at any time, whereas in many
applications, outgoing edges are added from each state as it is explored. To
formalize the latter situation, we propose guided incremental digraphs (GIDs),
incremental graphs which support labeling closed states (states which will not
receive further outgoing edges). Our main result is that dead state detection
in GIDs is solvable in $O(\log m)$ time per edge update for $m$ edges,
improving upon $O(\sqrt{m})$ per edge due to Bender, Fineman, Gilbert, and
Tarjan (BFGT) for general incremental directed graphs.
&lt;/p&gt;
&lt;p&gt;We introduce two algorithms for GIDs: one establishing the logarithmic time
bound, and a second algorithm to explore a lazy heuristics-based approach. To
demonstrate applicability, we show how GIDs can be used to lazily decide
regular expression constraints in SMT applications. To enable an
apples-to-apples experimental comparison, we implemented both algorithms, two
naive baselines, and the state-of-the-art BFGT baseline using a common directed
graph interface in Rust. Our evaluation shows $110$-$530$x speedups over BFGT
for the largest input graphs over a range of graph classes, random graphs, and
graphs arising from regular expression benchmarks.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Computing matching statistics on Wheeler DFAs</title>
    <link href="http://arxiv.org/abs/2301.05338"/>
    <id>http://arxiv.org/abs/2301.05338</id>
    <updated>2023-01-16T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conte_A/0/1/0/all/0/1&quot;&gt;Alessio Conte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cotumaccio_N/0/1/0/all/0/1&quot;&gt;Nicola Cotumaccio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gagie_T/0/1/0/all/0/1&quot;&gt;Travis Gagie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manzini_G/0/1/0/all/0/1&quot;&gt;Giovanni Manzini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1&quot;&gt;Nicola Prezza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sciortino_M/0/1/0/all/0/1&quot;&gt;Marinella Sciortino&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Matching statistics were introduced to solve the approximate string matching
problem, which is a recurrent subroutine in bioinformatics applications. In
2010, Ohlebusch et al. [SPIRE 2010] proposed a time and space efficient
algorithm for computing matching statistics which relies on some components of
a compressed suffix tree - notably, the longest common prefix (LCP) array. In
this paper, we show how their algorithm can be generalized from strings to
Wheeler deterministic finite automata. Most importantly, we introduce a notion
of LCP array for Wheeler automata, thus establishing a first clear step towards
extending (compressed) suffix tree functionalities to labeled graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Sublinear Algorithms for TSP via Path Covers</title>
    <link href="http://arxiv.org/abs/2301.05350"/>
    <id>http://arxiv.org/abs/2301.05350</id>
    <updated>2023-01-16T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behnezhad_S/0/1/0/all/0/1&quot;&gt;Soheil Behnezhad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roghani_M/0/1/0/all/0/1&quot;&gt;Mohammad Roghani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rubinstein_A/0/1/0/all/0/1&quot;&gt;Aviad Rubinstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saberi_A/0/1/0/all/0/1&quot;&gt;Amin Saberi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study sublinear time algorithms for the traveling salesman problem (TSP).
First, we focus on the closely related maximum path cover problem, which asks
for a collection of vertex disjoint paths that include the maximum number of
edges. We show that for any fixed $\epsilon &amp;gt; 0$, there is an algorithm that
$(1/2 - \epsilon)$-approximates the maximum path cover size of an $n$-vertex
graph in $\widetilde{O}(n)$ time. This improves upon a
$(3/8-\epsilon)$-approximate $\widetilde{O}(n \sqrt{n})$-time algorithm of
Chen, Kannan, and Khanna [ICALP&#39;20].
&lt;/p&gt;
&lt;p&gt;Equipped with our path cover algorithm, we give $\widetilde{O}(n)$ time
algorithms that estimate the cost of graphic TSP and $(1, 2)$-TSP up to factors
of $1.83$ and $(1.5+\epsilon)$, respectively. Our algorithm for graphic TSP
improves over a $1.92$-approximate $\widetilde{O}(n)$ time algorithm due to
[CHK ICALP&#39;20, Behnezhad FOCS&#39;21]. Our algorithm for $(1,2)$-TSP improves over
a folklore $(1.75 + \epsilon)$-approximate $\widetilde{O}(n)$-time algorithm,
as well as a $(1.625+\epsilon)$-approximate $\widetilde{O}(n\sqrt{n})$-time
algorithm of [CHK ICALP&#39;20].
&lt;/p&gt;
&lt;p&gt;Our analysis of the running time uses connections to parallel algorithms and
is information-theoretically optimal up to poly log $n$ factors. Additionally,
we show that our approximation guarantees for path cover and $(1,2)$-TSP hit a
natural barrier: We show better approximations require better sublinear time
algorithms for the well-studied maximum matching problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Quick Minimization of Tardy Processing Time on a Single Machine</title>
    <link href="http://arxiv.org/abs/2301.05460"/>
    <id>http://arxiv.org/abs/2301.05460</id>
    <updated>2023-01-16T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schieber_B/0/1/0/all/0/1&quot;&gt;Baruch Schieber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sitaraman_P/0/1/0/all/0/1&quot;&gt;Pranav Sitaraman&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the problem of minimizing the total processing time of tardy jobs
on a single machine. This is a classical scheduling problem, first considered
by [Lawler and Moore 1969], that also generalizes the Subset Sum problem.
Recently, it was shown that this problem can be solved efficiently by computing
$(\max,\min)$-skewed-convolutions. The running time of the resulting algorithm
is equivalent, up to logarithmic factors, to the time it takes to compute a
$(\max,\min)$-skewed-convolution of two vectors of integers whose sum is
$O(P)$, where $P$ is the sum of the jobs&#39; processing times. We further improve
the running time of the minimum tardy processing time computation by
introducing a job ``bundling&#39;&#39; technique and achieve a
$\tilde{O}\left(P^{2-1/\alpha}\right)$ running time, where
$\tilde{O}\left(P^\alpha\right)$ is the running time of a
$(\max,\min)$-skewed-convolution of vectors of size $P$. This results in a
$\tilde{O}\left(P^{7/5}\right)$ time algorithm for tardy processing time
minimization, an improvement over the previously known
$\tilde{O}\left(P^{5/3}\right)$ time algorithm.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Synergies Between Operations Research and Quantum Information Science</title>
    <link href="http://arxiv.org/abs/2301.05554"/>
    <id>http://arxiv.org/abs/2301.05554</id>
    <updated>2023-01-16T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Parekh_O/0/1/0/all/0/1&quot;&gt;Ojas Parekh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This article highlights synergies between quantum information science (QIS)
and operations research for QIS-curious operations researchers (and
vice-versa).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Differentially Private Continual Releases of Streaming Frequency Moment Estimations</title>
    <link href="http://arxiv.org/abs/2301.05605"/>
    <id>http://arxiv.org/abs/2301.05605</id>
    <updated>2023-01-16T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Epasto_A/0/1/0/all/0/1&quot;&gt;Alessandro Epasto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1&quot;&gt;Jieming Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Medina_A/0/1/0/all/0/1&quot;&gt;Andres Munoz Medina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1&quot;&gt;Vahab Mirrokni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vassilvitskii_S/0/1/0/all/0/1&quot;&gt;Sergei Vassilvitskii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_P/0/1/0/all/0/1&quot;&gt;Peilin Zhong&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The streaming model of computation is a popular approach for working with
large-scale data. In this setting, there is a stream of items and the goal is
to compute the desired quantities (usually data statistics) while making a
single pass through the stream and using as little space as possible.
&lt;/p&gt;
&lt;p&gt;Motivated by the importance of data privacy, we develop differentially
private streaming algorithms under the continual release setting, where the
union of outputs of the algorithm at every timestamp must be differentially
private. Specifically, we study the fundamental $\ell_p$ $(p\in [0,+\infty))$
frequency moment estimation problem under this setting, and give an
$\varepsilon$-DP algorithm that achieves $(1+\eta)$-relative approximation
$(\forall \eta\in(0,1))$ with $\mathrm{poly}\log(Tn)$ additive error and uses
$\mathrm{poly}\log(Tn)\cdot \max(1, n^{1-2/p})$ space, where $T$ is the length
of the stream and $n$ is the size of the universe of elements. Our space is
near optimal up to poly-logarithmic factors even in the non-private setting.
&lt;/p&gt;
&lt;p&gt;To obtain our results, we first reduce several primitives under the
differentially private continual release model, such as counting distinct
elements, heavy hitters and counting low frequency elements, to the simpler,
counting/summing problems in the same setting. Based on these primitives, we
develop a differentially private continual release level set estimation
approach to address the $\ell_p$ frequency moment estimation problem.
&lt;/p&gt;
&lt;p&gt;We also provide a simple extension of our results to the harder sliding
window model, where the statistics must be maintained over the past $W$ data
items.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Non-Stochastic CDF Estimation Using Threshold Queries</title>
    <link href="http://arxiv.org/abs/2301.05682"/>
    <id>http://arxiv.org/abs/2301.05682</id>
    <updated>2023-01-16T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Okoroafor_P/0/1/0/all/0/1&quot;&gt;Princewill Okoroafor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1&quot;&gt;Vaishnavi Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleinberg_R/0/1/0/all/0/1&quot;&gt;Robert Kleinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goh_E/0/1/0/all/0/1&quot;&gt;Eleanor Goh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Estimating the empirical distribution of a scalar-valued data set is a basic
and fundamental task. In this paper, we tackle the problem of estimating an
empirical distribution in a setting with two challenging features. First, the
algorithm does not directly observe the data; instead, it only asks a limited
number of threshold queries about each sample. Second, the data are not assumed
to be independent and identically distributed; instead, we allow for an
arbitrary process generating the samples, including an adaptive adversary.
These considerations are relevant, for example, when modeling a seller
experimenting with posted prices to estimate the distribution of consumers&#39;
willingness to pay for a product: offering a price and observing a consumer&#39;s
purchase decision is equivalent to asking a single threshold query about their
value, and the distribution of consumers&#39; values may be non-stationary over
time, as early adopters may differ markedly from late adopters.
&lt;/p&gt;
&lt;p&gt;Our main result quantifies, to within a constant factor, the sample
complexity of estimating the empirical CDF of a sequence of elements of $[n]$,
up to $\varepsilon$ additive error, using one threshold query per sample. The
complexity depends only logarithmically on $n$, and our result can be
interpreted as extending the existing logarithmic-complexity results for noisy
binary search to the more challenging setting where noise is non-stochastic.
Along the way to designing our algorithm, we consider a more general model in
which the algorithm is allowed to make a limited number of simultaneous
threshold queries on each sample. We solve this problem using Blackwell&#39;s
Approachability Theorem and the exponential weights method. As a side result of
independent interest, we characterize the minimum number of simultaneous
threshold queries required by deterministic CDF estimation algorithms.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On a conjecture of Knuth about forward and back arcs</title>
    <link href="http://arxiv.org/abs/2301.05704"/>
    <id>http://arxiv.org/abs/2301.05704</id>
    <updated>2023-01-16T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nie_Z/0/1/0/all/0/1&quot;&gt;Zipei Nie&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Following Janson&#39;s method, we prove a conjecture of Knuth: the numbers of
forward and back arcs for the depth-first search (DFS) in a digraph with a
geometric outdegree distribution have the same distribution.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">David Eppstein: First linkage of the new year</title>
    <link href="https://11011110.github.io/blog/2023/01/15/first-linkage-new.html"/>
    <id>https://11011110.github.io/blog/2023/01/15/first-linkage-new</id>
    <updated>2023-01-15T23:21:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mathscinet.ams.org/mathscinet-getitem?mr=4183362&quot;&gt;MathSciNet on my “Counting polygon triangulations is hard”&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109618156827776286&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;)&lt;/span&gt; says: “Of course, every &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\mathsf{NP}\)-complete&lt;/span&gt; problem gives rise to a &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\#\mathsf{P}\)-hard&lt;/span&gt; problem”. I assume it means: the counting problem for a  witness-checker for an &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\mathsf{NP}\)-complete&lt;/span&gt; problem must be &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\#\mathsf{P}\)-hard.&lt;/span&gt; But is it true? The &lt;a href=&quot;https://en.wikipedia.org/wiki/Berman%E2%80%93Hartmanis_conjecture&quot;&gt;Berman–Hartmanis conjecture&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Mahaney%27s_theorem&quot;&gt;Mahaney’s theorem&lt;/a&gt; seem relevant. &lt;a href=&quot;https://www.wisdom.weizmann.ac.il/~oded/PSX/cc-text15.pdf&quot;&gt;Goldreich is more careful&lt;/a&gt;: “many counting problems associated with &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\mathsf{NP}\)-complete&lt;/span&gt; search problems are &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\#\mathsf{P}\)-complete”.&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Probably most researchers have felt snubbed when some new paper failed to cite their vaguely-related work &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109622597689281123&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; Usually it merely means research has moved on and the uncited paper is not up-to-date on its topic; one should get over it and publish more research for people to cite. But sometimes, the missing citation really is problematic, because its absence creates the false impression that something old is new. &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2022/12/15/a-mutation-carol-2/&quot;&gt;Lipton and Regan describe a case from CACM on mutation testing&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Every smooth arc with total absolute curvature \(\le\pi\) is monotonic in some direction (and therefore non-self-crossing); if the curvature is everywhere \(\ge0\) then it is a convex arc &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109626775003632072&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; This is a sharp threshold: a curve whose total absolute curvature exceeds \(\pi\) can self-cross. Does this sound familiar to anyone? I’d like to add it to &lt;a href=&quot;https://en.wikipedia.org/wiki/Convex_curve&quot;&gt;the Wikipedia article on convex curves&lt;/a&gt; but I need a published source.&lt;/p&gt;

    &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;/blog/assets/2023/3curves.svg&quot; alt=&quot;Three curves demonstrating the effect of limited curvature on crossings. The upper left curve has total curvature pi and is convex; the upper right curve has total curvature pi, is non-convex, but does not cross; the lower curve has total curvature slightly more than pi and crosses itself.&quot; style=&quot;width:100%;max-width:600px&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arstechnica.com/science/2023/01/experiments-with-paper-airplanes-reveal-surprisingly-complex-aerodynamics/&quot;&gt;Experiments with paper airplanes reveal surprisingly complex aerodynamics&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109633500547078803&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://doi.org/10.1017/jfm.2022.89&quot;&gt;original research paper&lt;/a&gt;). The wide flat wings of paper planes allow them to fly stably without a separate tail stabilizer, but require careful placement of the center of mass, forward of the center of the wing but not too close to its front edge so that when the wing pitches out of the right angle the aerodynamic forces right it.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mathstodon.xyz/@jpkmensah@mas.to/109590321219123830&quot;&gt;Joshua Mensah writes&lt;/a&gt;: “It’s wild how computer programming went from exclusively women’s work to ‘we’re not sexist we just don’t think women are interested in it’ in like 40 years.”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.ics.uci.edu/~eppstein/pix/swpss/index.html&quot;&gt;Sunset in Mendocino&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109639770183944526&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;)&lt;/span&gt; after a big storm that left us powerless and incommunicado for 12 hours the previous night. Another rolled in the next evening. Fortunately the roads were clear (except for a 20-minute detour to avoid the always-flooded CA-128) for my return travel between it and the one after.&lt;/p&gt;

    &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://www.ics.uci.edu/~eppstein/pix/swpss/swpss-m.jpg&quot; alt=&quot;Sunset in Mendocino&quot; style=&quot;border-style:solid;border-color:black&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mathstodon.xyz/@markgritter/109632821623787814&quot;&gt;Mark Gritter writes about algorithms for counting primes&lt;/a&gt;, writing “It comes as a surprise to many people that there are more efficient ways to count the primes than generating all of them!” He discusses both a practical &lt;span style=&quot;white-space:nowrap&quot;&gt;\(O(n^{2/3}/\log^2 n)\)-time&lt;/span&gt; algorithm and a theoretically-better &lt;span style=&quot;white-space:nowrap&quot;&gt;\(O(n^{1/2+\varepsilon})\)-time&lt;/span&gt; algorithm.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Are women held to a higher standard in publishing &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109657999153288421&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;)?&lt;/span&gt; According to &lt;a href=&quot;https://erinhengel.github.io/time/time.pdf&quot;&gt;research by Diane Alexander, Olga Gorelkina, and Erin Hengel&lt;/a&gt; reported on &lt;a href=&quot;https://www.chronicle.com/article/are-women-held-to-a-higher-standard-in-publishing&quot;&gt;in &lt;em&gt;The Chronicle of Higher Education&lt;/em&gt;&lt;/a&gt;, economics journal submissions by women average three to six month longer review times than submissions by men, after controlling for other factors, adding friction to their authors’ academic careers.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.insidehighered.com/news/2023/01/09/mathematicians-resume-person-meetings-trying-times&quot;&gt;“Mathematicians, Hopeful and Hurting”&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109660772439283602&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;):&lt;/span&gt; &lt;em&gt;Inside Higher Ed&lt;/em&gt; on the Joint Mathematics Meetings, formerly AMS+MAA and now AMS-only as the MAA runs a separate Mathfest. Although this split is supposedly financial, the article discusses diverging opinions on diversity issues; some participants feel ghettoized in special sections at JMM rather than integrated into mainstream sessions, and controversy lingers over a 2019 anti-diversity-statement editorial in the &lt;em&gt;Notices&lt;/em&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.thisiscolossal.com/2023/01/spencer-schien-population-maps/&quot;&gt;Boldly contrasted maps by Spencer Schien visualize population density data&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@colossal@mastodon.art/109637050037451131&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; See also &lt;a href=&quot;https://spencerschien.info/gallery/population-density/&quot;&gt;Schien’s population density gallery&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mathstodon.xyz/@joshmillard@mastodon.social/109672113857964612&quot;&gt;What do the colors mean in those visualizations of optimal circle packings into squares?&lt;/a&gt; The answer seems to be: pink for loose circles (“rattlers”), blue for circles that could be loose but happen to have two contacts in the depicted diagram, orange for circles that bound a triangular void, and yellow for all remaining circles.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Convex_curve&quot;&gt;Convex curve&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109680010200309315&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; another Wikipedia Good Article:  Some stuff I learned while working on it:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Archimedes gave a modern-looking definition of these but then the subject languished until its 19th-century revival.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Any convex curve has 2nd derivatives and curvatures at all points outside a set of measure zero, but this set can be comeager.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Every cyclic quadrilateral can be inscribed in every smooth closed convex curve, but might not be inscribable in an obtuse triangle.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://conwaylife.com/wiki/Walrus&quot;&gt;The walrus&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109684693817917909&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; a new and surprisingly small \(c/8\) diagonal spaceship in Conway’s Game of Life. Also included: a walrus eater and a stable walrus-to-glider converter. This discovery highlights the power of &lt;a href=&quot;https://conwaylife.com/wiki/Ikpx&quot;&gt;modern cellular automaton pattern search codes&lt;/a&gt;, which integrate SAT solvers to provide deeper lookahead and quickly detect and prune sterile search branches, compared to the hardcoded limited-depth lookahead of previous software.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://ilaba.wordpress.com/2023/01/08/the-coven-meyerowitz-conjecture/&quot;&gt;Izabella Łaba on the Coven–Meyerowitz conjecture&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@ilaba/109655872586109083&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; a reformulation of the question of which patterns tile the integers in terms of factorization by cyclotomic polynomials.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mathstodon.xyz/@mccurley@sigcrap.org/109667512050082457&quot;&gt;Kevin McCurley on peer review&lt;/a&gt;. He points out how unreasonable it is to expect reviewers to find subtle errors in 100-page papers for now credit, how reliance on peer review may lead research communities in safe rather than creative directions, and how it might help readers to publish some kind of rating for papers instead of only a single bit of information from the peer review (it is accepted or not).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;authors&quot;&gt;By David Eppstein&lt;/p&gt;
  </content>
    <author>
      <name>David Eppstein</name>
      <uri>https://11011110.github.io/blog/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Scott Aaronson: Movie Review: M3GAN</title>
    <link href="https://scottaaronson.blog/?p=6990"/>
    <id>https://scottaaronson.blog/?p=6990</id>
    <updated>2023-01-15T08:32:48+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;strong&gt;[WARNING: SPOILERS FOLLOW]&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Tonight, on a rare date without the kids, Dana and I saw &lt;a href=&quot;https://en.wikipedia.org/wiki/M3GAN&quot;&gt;&lt;em&gt;M3GAN&lt;/em&gt;&lt;/a&gt;, the new black-comedy horror movie about an orphaned 9-year-old girl named Cady who, under the care of her roboticist aunt, gets an extremely intelligent and lifelike AI doll as a companion.  The robot doll, M3GAN, is given a mission to bond with Cady and protect her physical and emotional well-being at all times.  M3GAN proceeds to take that directive more literally than intended, with predictably grisly results given the genre.&lt;/p&gt;



&lt;p&gt;I chose this movie for, you know, work purposes.  Research for my safety job at OpenAI.&lt;/p&gt;



&lt;p&gt;So, here&amp;#8217;s my review: the first 80% or so of M3GAN constitutes one of the finest movies about AI that I&amp;#8217;ve seen.  Judged purely as an &amp;#8220;AI-safety cautionary fable&amp;#8221; and not on any other merits, it takes its place alongside or even surpasses the old standbys like &lt;em&gt;2001&lt;/em&gt;, &lt;em&gt;Terminator&lt;/em&gt;, and &lt;em&gt;The Matrix&lt;/em&gt;.  There are two reasons.&lt;/p&gt;



&lt;p&gt;First, &lt;em&gt;M3GAN&lt;/em&gt; tries hard to dispense with the dumb tropes that an AI differs from a standard-issue human mostly in its thirst for power, its inability to understand true emotions, and its lack of voice inflection.  M3GAN is explicitly a &amp;#8220;generative learning model&amp;#8221;&amp;#8212;and she&amp;#8217;s shown becoming increasingly brilliant at empathy, caretaking, and even emotional manipulation.  It&amp;#8217;s also shown, 100% plausibly, how Cady grows to love her robo-companion more than any human, even as the robot&amp;#8217;s behavior turns more and more disturbing.  I&amp;#8217;m extremely curious to what extent the script was influenced by the recent explosion of large language models&amp;#8212;but in any case, it occurred to me that &lt;em&gt;this&lt;/em&gt; is what you might get if you tried to make a genuinely 2020s AI movie, rather than a 60s AI movie with updated visuals.&lt;/p&gt;



&lt;p&gt;Secondly, until near the end, the movie actually takes seriously that M3GAN, for all her intelligence and flexibility, is a machine trying to optimize an objective function, and that objective function can&amp;#8217;t be ignored for narrative convenience.  Meaning: sure, the robot might murder, but not to &amp;#8220;rebel against its creators and gain power&amp;#8221; (as in most AI flicks), much less because &amp;#8220;chaos theory demands it&amp;#8221; (&lt;em&gt;Jurassic Park&lt;/em&gt;), but only to further its mission of protecting Cady.  I liked that M3GAN&amp;#8217;s first victims&amp;#8212;a vicious attack dog, the dog&amp;#8217;s even more vicious owner, and a sadistic schoolyard bully&amp;#8212;are so unsympathetic that some part of the audience will, with guilty conscience, be rooting for the murderbot.&lt;/p&gt;



&lt;p&gt;But then there&amp;#8217;s the last 20% of the movie, where it abandons its own logic, as the robot goes berserk and resists her own shutdown by trying to kill basically everyone in sight&amp;#8212;including, at the very end, Cady herself.  The best I can say about the ending is that it&amp;#8217;s knowing and campy.  You can imagine the scriptwriters sighing to themselves, like, &amp;#8220;OK, the focus groups &lt;em&gt;demanded&lt;/em&gt; to see the robot go on a senseless killing spree &amp;#8230; so I guess a senseless killing spree is exactly what we give them.&amp;#8221;&lt;/p&gt;



&lt;p&gt;But probably film criticism isn&amp;#8217;t what most of you are here for.  Clearly the &lt;em&gt;real&lt;/em&gt; question is: what insights, if any, can we take from this movie about AI safety?&lt;/p&gt;



&lt;p&gt;I found the first 80% of the film to be thought-provoking about at least &lt;em&gt;one&lt;/em&gt; AI safety question, and a mind-bogglingly near-term one: namely, what will happen to children as they increasingly grow up with powerful AIs as companions?&lt;/p&gt;



&lt;p&gt;In their last minutes before dying in a car crash, Cady&amp;#8217;s parents, like countless other modern parents, fret that their daughter is too addicted to her iPad.  But Cady&amp;#8217;s roboticist aunt, Gemma, then lets the girl spend endless hours with M3GAN&amp;#8212;both because Gemma is a distracted caregiver who wants to get back to her work, &lt;em&gt;and&lt;/em&gt; because Gemma sees that M3GAN is making Cady happier than any human could, with the possible exception of Cady&amp;#8217;s dead parents.&lt;/p&gt;



&lt;p&gt;I confess: when my kids battle each other, throw monster tantrums, refuse to eat dinner or bathe or go to bed, angrily demand second and third desserts and to be carried rather than walk, run to their rooms and lock the doors &amp;#8230; when they do such things almost daily (which they do), I easily have thoughts like, &lt;strong&gt;I would totally buy a M3GAN or two for our house &amp;#8230; yes, even having seen the movie!&lt;/strong&gt;  I mean, the minute I&amp;#8217;m satisfied that they&amp;#8217;ve mostly fixed the bug that causes the murder-rampages, I will order that frigging bot on Amazon with next-day delivery.  And I&amp;#8217;ll still be there for my kids whenever they need me, and I&amp;#8217;ll play with them, and teach them things, and watch them grow up, and love them.  But the robot can handle the excruciating bits, the bits that require the infinite patience I&amp;#8217;ll never have.&lt;/p&gt;



&lt;p&gt;OK, but what about the part where M3GAN &lt;em&gt;does&lt;/em&gt; start murdering anyone who she sees as interfering with her goals?  That struck me, honestly, as a &lt;em&gt;trivially fixable alignment failure&lt;/em&gt;.  Please don&amp;#8217;t misunderstand me here to be minimizing the AI alignment problem, or suggesting it&amp;#8217;s easy.  I only mean: &lt;em&gt;supposing&lt;/em&gt; that an AI were as capable as M3GAN (for much of the movie) at understanding Asimov&amp;#8217;s Second &lt;a href=&quot;https://en.wikipedia.org/wiki/Three_Laws_of_Robotics&quot;&gt;Law of Robotics&lt;/a&gt;&amp;#8212;i.e., supposing it could brilliantly care for its user, follow her wishes, and protect her&amp;#8212;such an AI would seem capable as well of understanding the &lt;em&gt;First&lt;/em&gt; Law (don&amp;#8217;t harm any humans or allow them to come to harm), and the crucial fact that the First Law overrides the Second.&lt;/p&gt;



&lt;p&gt;In the movie, the catastrophic alignment failure is explained, somewhat ludicrously, by Gemma &lt;em&gt;not having had time&lt;/em&gt; to install the right safety modules before turning M3GAN loose on her niece.  While I understand why movies do this sort of thing, I find it often interferes with the lessons those movies are trying to impart.  (For example, is the moral of &lt;em&gt;Jurassic Park&lt;/em&gt; that, if you&amp;#8217;re going to start a live dinosaur theme park, just make sure to have backup power for the electric fences?)&lt;/p&gt;



&lt;p&gt;Mostly, though, it was a bizarre experience to watch this movie&amp;#8212;one that, whatever its 2020s updates, fits squarely into a literary tradition stretching back to Faust, the Golem of Prague, Frankenstein&amp;#8217;s monster, Rossum&amp;#8217;s Universal Robots, etc.&amp;#8212;and then pinch myself and remember that, here in actual nonfiction reality,&lt;/p&gt;



&lt;ol&gt;
&lt;li&gt;I&amp;#8217;m now working at one of the world&amp;#8217;s leading AI companies,&lt;/li&gt;



&lt;li&gt;that company has &lt;em&gt;already created&lt;/em&gt; GPT, an AI with a good fraction of the fantastical verbal abilities shown by M3GAN in the movie,&lt;/li&gt;



&lt;li&gt;that AI will gain many of the remaining abilities in years rather than decades, and&lt;/li&gt;



&lt;li&gt;my job this year&amp;#8212;supposedly!&amp;#8212;is to think about how to prevent this sort of AI from wreaking havoc on the world.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Incredibly, unbelievably, here in the real world of 2023, what still seems most science-fictional about M3GAN is neither her language fluency, nor her ability to pursue goals, nor even her emotional insight, but simply her ease with the physical world: the fact that she can walk and dance like a real child, and all-too-brilliantly resist attempts to shut her down, and have all her compute onboard, and not break.  And then there&amp;#8217;s the question of the power source.  The movie was never explicit about that, except for implying that she sits in a charging port every night.  The more the movie descends into grotesque horror, though, the harder it becomes to understand why her creators can&amp;#8217;t avail themselves of the first and most elemental of all AI safety strategies&amp;#8212;like flipping the switch or popping out the battery.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </content>
    <author>
      <name>Scott Aaronson</name>
      <uri>https://scottaaronson.blog</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Postdoc at Rice University and Portland State University (apply by February 1, 2023)</title>
    <link href="https://cstheory-jobs.org/2023/01/13/postdoc-at-rice-university-and-portland-state-university-apply-by-february-1-2023/"/>
    <id>http://cstheory-jobs.org/2023/01/13/postdoc-at-rice-university-and-portland-state-university-apply-by-february-1-2023/</id>
    <updated>2023-01-13T18:42:06+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;A joint postdoc position is available at Rice University and Portland State University with Nai-Hui Chia and Fang Song. Candidates with a strong record in complexity theory and cryptography, classical or quantum, are encouraged to apply. To apply, send your CV and two reference letters. Drop us an email if interested. This project is sponsored by NSF.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://sites.google.com/view/naihuichia&quot;&gt;https://sites.google.com/view/naihuichia&lt;/a&gt;, &lt;a href=&quot;https://fangsong.info/&quot;&gt;https://fangsong.info/&lt;/a&gt;&lt;br /&gt;
Email: fsong@pdx.edu, nc67@rice.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR23-005 |  Cumulative Memory Lower Bounds for Randomized and Quantum Computation | 

	Paul Beame, 

	Niels Kornerup</title>
    <link href="https://eccc.weizmann.ac.il/report/2023/005"/>
    <id>https://eccc.weizmann.ac.il/report/2023/005</id>
    <updated>2023-01-13T07:30:49+00:00</updated>
    <content type="html" xml:lang="en">
    Cumulative memory---the sum of space used over the steps of a computation---is a fine-grained measure of time-space complexity that is a more accurate measure of cost for algorithms with infrequent spikes in memory usage in the context of technologies such as cloud computing that allow dynamic allocation and de-allocation of resources during their execution. We give the first lower bounds on cumulative memory complexity that apply to general sequential classical algorithms.  We also prove the first such bounds for bounded-error quantum circuits.  Among many possible applications, we show that any classical sorting algorithm with success probability at least $1/\text{poly}(n)$ requires cumulative memory $\tilde \Omega(n^2)$, any classical matrix multiplication algorithm requires cumulative memory $\Omega(n^6/T)$, any quantum sorting circuit requires cumulative memory $\Omega(n^3/T)$, and any quantum circuit that finds $k$ disjoint collisions in a random function requires cumulative memory $\Omega(k^3n/T^2)$.  More generally, we present theorems that can be used to convert a wide class of existing time-space tradeoff lower bounds to matching lower bounds on cumulative memory complexity.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR23-004 |  On linear-algebraic notions of expansion | 

	Yinan Li, 

	Youming Qiao, 

	Avi Wigderson, 

	Yuval Wigderson, 

	Chuanqi Zhang</title>
    <link href="https://eccc.weizmann.ac.il/report/2023/004"/>
    <id>https://eccc.weizmann.ac.il/report/2023/004</id>
    <updated>2023-01-13T07:27:38+00:00</updated>
    <content type="html" xml:lang="en">
    A fundamental fact about bounded-degree graph expanders is that three notions of expansion---vertex expansion, edge expansion, and spectral expansion---are all equivalent. In this paper, we study to what extent such a statement is true for linear-algebraic notions of expansion.

There are two well-studied notions of linear-algebraic expansion, namely dimension expansion (defined in analogy to graph vertex expansion) and quantum expansion (defined in analogy to graph spectral expansion). Lubotzky and Zelmanov proved that the latter implies the former. We prove that the converse is false: there are dimension expanders which are not quantum expanders.

Moreover, this asymmetry is explained by the fact that there are two distinct linear-algebraic analogues of graph edge expansion. The first of these is quantum edge expansion, which was introduced by Hastings, and which he proved to be equivalent to quantum expansion. We introduce a new notion, termed dimension edge expansion, which we prove is equivalent to dimension expansion and which is implied by quantum edge expansion. Thus, the separation above is implied by a finer one: dimension edge expansion is strictly weaker than quantum edge expansion. This new notion also leads to a new, more modular proof of the Lubotzky--Zelmanov result that quantum expanders are dimension expanders.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR23-003 |  Streaming Lower Bounds and Asymmetric Set-Disjointness | 

	Jiapeng Zhang, 

	Shachar Lovett</title>
    <link href="https://eccc.weizmann.ac.il/report/2023/003"/>
    <id>https://eccc.weizmann.ac.il/report/2023/003</id>
    <updated>2023-01-13T07:25:30+00:00</updated>
    <content type="html" xml:lang="en">
    Frequency estimation in data streams is one of the classical problems in streaming algorithms. Following much research, there are now almost matching upper and lower bounds for the trade-off needed between the number of samples and the space complexity of the algorithm, when the data streams are adversarial. However, in the case where the data stream is given in a random order, or is stochastic, only weaker lower bounds exist. In this work we close this gap, up to logarithmic factors. 

In order to do so we consider the needle problem, which is a natural hard problem for frequency estimation studied in (Andoni et al. 2008, Crouch et al. 2016). Here, the goal is to distinguish between two distributions over data streams with $t$ samples. The first is uniform over a large enough domain. The second is a planted model; a secret &amp;#39;&amp;#39;needle&amp;#39;&amp;#39; is uniformly chosen, and then each element in the stream equals the needle with probability $p$, and otherwise is uniformly chosen from the domain. It is simple to design streaming algorithms that distinguish the distributions using space $s \approx 1/(p^2 t)$. It was unclear if this is tight, as the existing lower bounds are weaker. We close this gap and show that the trade-off is near optimal, up to a logarithmic factor. 

Our proof builds and extends classical connections between streaming algorithms and communication complexity, concretely multi-party unique set-disjointness. We introduce two new ingredients that allow us to prove sharp bounds. The first is a lower bound for an asymmetric version of multi-party unique set-disjointness, where players receive input sets of different sizes, and where the communication of each player is normalized relative to their input length. The second is a combinatorial technique that allows to sample needles in the planted model by first sampling intervals, and then sampling a uniform needle in each interval.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: A Functorial Perspective on (Multi)computational Irreducibility</title>
    <link href="http://arxiv.org/abs/2301.04690"/>
    <id>http://arxiv.org/abs/2301.04690</id>
    <updated>2023-01-13T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorard_J/0/1/0/all/0/1&quot;&gt;Jonathan Gorard&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This article aims to provide a novel formalization of the concept of
computational irreducibility in terms of the exactness of functorial
correspondence between a category of data structures and elementary
computations and a corresponding category of (1-dimensional) cobordisms. We
proceed to demonstrate that, by equipping both categories with a symmetric
monoidal structure and considering the case of higher-dimensional cobordism
categories, we obtain a natural extension of this formalism that serves also to
encompass non-deterministic or ``multiway&#39;&#39; computations, in which one
quantifies not only the irreducibility in the behavior of a single
(deterministic) computation path, but in the branching and merging behavior of
an entire ``multiway system&#39;&#39; of such paths too. We finally outline how, in the
most general case, the resulting symmetric monoidal functor may be considered
to be adjoint to the functor characterizing the Atiyah-Segal axiomatization of
a functorial quantum field theory. Thus, we conclude by arguing that the
irreducibility of (multi)computations may be thought of as being dual to the
locality of time evolution in functorial approaches to quantum mechanics and
quantum field theory. In the process, we propose an extension of the methods of
standard (monoidal) category theory, in which morphisms are effectively
equipped with intrinsic computational complexity data, together with an algebra
for how those complexities compose (both in sequence and in parallel, subject
to the monoidal structure).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Isomorphisms Between Impossible and Hard Tasks</title>
    <link href="http://arxiv.org/abs/2301.04789"/>
    <id>http://arxiv.org/abs/2301.04789</id>
    <updated>2023-01-13T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monroe_H/0/1/0/all/0/1&quot;&gt;Hunter Monroe&lt;/a&gt;&lt;/p&gt;&lt;p&gt;If no efficient proof shows that an unprovable arithmetic sentence &#39;$x$ is
Kolmogorov random&#39; (&#39;$x{\in}R$&#39;) lacks a length $t$ proof, an isomorphism
associates for each $x$ impossible and hard tasks: ruling out any proof and
length $t$ proofs respectively. This resembles Pudl\&#39;ak&#39;s feasible
incompleteness. This possible isomorphism implies widely-believed complexity
theoretic conjectures hold -- in effect, translating theorems from
noncomputability about proof speedup and average-case hardness directly to
complexity.
&lt;/p&gt;
&lt;p&gt;Formally, we conjecture: sentence &quot;Peano arithmetic (PA) lacks any length $t$
proof of &#39;$x{\in}R$&#39;&quot; lacks $t^{\mathcal{O}(1)}$ length proofs in any
consistent extension $\mathcal{T}$ of PA if and only if $\mathcal{T}$ cannot
prove &#39;$x{\in}R$&#39;. If so, tautologies encoding the sentence lack
$t^{\mathcal{O}(1)}$ length proofs in any proof system $P$ for $x{\in}R$
sufficiently long (relative to the description of a program enumerating
theorems of a theory $\mathcal{T}$ proving &#39;$P$ is sound&#39;). $R$&#39;s density
implies: $\texttt{TAUT}{\notin}\textbf{AvgP}$, Feige&#39;s hypothesis holds, and, a
new conjecture, $P$&#39;s nonoptimality has dense witnesses. If the isomorphism
holds for any $\Pi^0$ sentence, $\textbf{PH}$ does not collapse, because the
arithmetic hierarchy does not collapse.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Local consistency as a reduction between constraint satisfaction problems</title>
    <link href="http://arxiv.org/abs/2301.05084"/>
    <id>http://arxiv.org/abs/2301.05084</id>
    <updated>2023-01-13T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalmau_V/0/1/0/all/0/1&quot;&gt;Victor Dalmau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oprsal_J/0/1/0/all/0/1&quot;&gt;Jakub Opr&amp;#x161;al&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the use of local consistency methods as reductions between
constraint satisfaction problems (CSPs), and promise version thereof, with the
aim to classify these reductions in similar way as the algebraic approach
classifies gadget reductions between CSPs. We classify a use of arc-consistency
in this way, provide first steps into classification of general
$k$-consistency, and ask whether every tractable finite template CSP is
reducible by such a reduction to solving systems of affine Diophantine
equations.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Fast persistent homology computation for functions on $\mathbb{R}$</title>
    <link href="http://arxiv.org/abs/2301.04745"/>
    <id>http://arxiv.org/abs/2301.04745</id>
    <updated>2023-01-13T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glisse_M/0/1/0/all/0/1&quot;&gt;Marc Glisse&lt;/a&gt;&lt;/p&gt;&lt;p&gt;0-dimensional persistent homology is known, from a computational point of
view, as the easy case. Indeed, given a list of $n$ edges in non-decreasing
order of filtration value, one only needs a union-find data structure to keep
track of the connected components and we get the persistence diagram in time
$O(n\alpha(n))$. The running time is thus usually dominated by sorting the
edges in $\Theta(n\log(n))$. A little-known fact is that, in the particularly
simple case of studying the sublevel sets of a piecewise-linear function on
$\mathbb{R}$ or $\mathbb{S}^1$, persistence can actually be computed in linear
time. This note presents a simple algorithm that achieves this complexity. An
implementation will soon be available in Gudhi.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: On Voronoi visibility maps of 1.5D terrains with multiple viewpoints</title>
    <link href="http://arxiv.org/abs/2301.05049"/>
    <id>http://arxiv.org/abs/2301.05049</id>
    <updated>2023-01-13T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keikha_V/0/1/0/all/0/1&quot;&gt;Vahideh Keikha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saumell_M/0/1/0/all/0/1&quot;&gt;Maria Saumell&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given an $n$-vertex 1.5D terrain $\T$ and a set $\A$ of $m&amp;lt;n$ viewpoints, the
Voronoi visibility map $\vorvis(\T,\A)$ is a partitioning of $\T$ into regions
such that each region is assigned to the closest (in Euclidean distance)
visible viewpoint. The colored visibility map $\colvis(\T,\A)$ is a
partitioning of $\T$ into regions that have the same set of visible viewpoints.
In this paper, we propose an algorithm to compute $\vorvis(\T,\A)$ that runs in
$O(n+(m^2+k_c)\log n)$ time, where $k_c$ and $k_v$ denote the total complexity
of $\colvis(\T,\A)$ and $\vorvis(\T,\A)$, respectively. This improves upon a
previous algorithm for this problem. We also generalize our algorithm to higher
order Voronoi visibility maps, and to Voronoi visibility maps with respect to
other distances. Finally, we prove bounds relating $k_v$ to $k_c$, and we show
an application of our algorithm to a problem on limited range of sight.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Density functions of periodic sequences of continuous events</title>
    <link href="http://arxiv.org/abs/2301.05137"/>
    <id>http://arxiv.org/abs/2301.05137</id>
    <updated>2023-01-13T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anosova_O/0/1/0/all/0/1&quot;&gt;Olga Anosova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurlin_V/0/1/0/all/0/1&quot;&gt;Vitaliy Kurlin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Periodic Geometry studies isometry invariants of periodic point sets that are
also continuous under perturbations. The motivations come from periodic
crystals whose structures are determined in a rigid form but any minimal cells
can discontinuously change due to small noise in measurements. For any integer
k&amp;gt;=0, the density function of a periodic set S was previously defined as the
fractional volume of all k-fold intersections (within a minimal cell) of balls
that have a variable radius t and centers at all points of S. This paper
introduces the density functions for periodic sets of points with different
initial radii motivated by atomic radii of chemical elements and by continuous
events occupying disjoint intervals in time series. The contributions are
explicit descriptions of the densities for periodic sequences of intervals. The
new densities are strictly stronger and distinguish periodic sequences that
have identical densities in the case of zero radii.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Quantum algorithm for finding minimum values in a Quantum Random Access Memory</title>
    <link href="http://arxiv.org/abs/2301.05122"/>
    <id>http://arxiv.org/abs/2301.05122</id>
    <updated>2023-01-13T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Albino_A/0/1/0/all/0/1&quot;&gt;Anton S. Albino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Galvao_L/0/1/0/all/0/1&quot;&gt;Lucas Q. Galv&amp;#xe3;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hansen_E/0/1/0/all/0/1&quot;&gt;Ethan Hansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Neto_M/0/1/0/all/0/1&quot;&gt;Mauro Q. Nooblath Neto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Cruz_C/0/1/0/all/0/1&quot;&gt;Clebson Cruz&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Finding the minimum value in an unordered database is a common and
fundamental task in computer science. However, the optimal classical
deterministic algorithm can find the minimum value with a time complexity that
grows linearly with the number of elements in the database. In this paper, we
present the proposal of a quantum algorithm for finding the minimum value of a
database, which is quadratically faster than its best classical analogs. We
assume a Quantum Random Access Memory (QRAM) that stores values from a database
and perform an iterative search based on an oracle whose role is to limit the
searched values by controlling the states of the most significant qubits. A
complexity analysis was performed in order to demonstrate the advantage of this
quantum algorithm over its classical counterparts. Furthermore, we demonstrate
how the proposed algorithm would be used in an unsupervised machine learning
task through a quantum version of the K-means algorithm.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Private estimation algorithms for stochastic block models and mixture models</title>
    <link href="http://arxiv.org/abs/2301.04822"/>
    <id>http://arxiv.org/abs/2301.04822</id>
    <updated>2023-01-13T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hongjie Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1&quot;&gt;Vincent Cohen-Addad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+dOrsi_T/0/1/0/all/0/1&quot;&gt;Tommaso d&amp;#x27;Orsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Epasto_A/0/1/0/all/0/1&quot;&gt;Alessandro Epasto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Imola_J/0/1/0/all/0/1&quot;&gt;Jacob Imola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steurer_D/0/1/0/all/0/1&quot;&gt;David Steurer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiegel_S/0/1/0/all/0/1&quot;&gt;Stefan Tiegel&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce general tools for designing efficient private estimation
algorithms, in the high-dimensional settings, whose statistical guarantees
almost match those of the best known non-private algorithms. To illustrate our
techniques, we consider two problems: recovery of stochastic block models and
learning mixtures of spherical Gaussians. For the former, we present the first
efficient $(\epsilon, \delta)$-differentially private algorithm for both weak
recovery and exact recovery. Previously known algorithms achieving comparable
guarantees required quasi-polynomial time. For the latter, we design an
$(\epsilon, \delta)$-differentially private algorithm that recovers the centers
of the $k$-mixture when the minimum separation is at least $
O(k^{1/t}\sqrt{t})$. For all choices of $t$, this algorithm requires sample
complexity $n\geq k^{O(1)}d^{O(t)}$ and time complexity $(nd)^{O(t)}$. Prior
work required minimum separation at least $O(\sqrt{k})$ as well as an explicit
upper bound on the Euclidean norm of the centers.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Distance-2-Dispersion: Dispersion with Further Constraints</title>
    <link href="http://arxiv.org/abs/2301.04938"/>
    <id>http://arxiv.org/abs/2301.04938</id>
    <updated>2023-01-13T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaur_T/0/1/0/all/0/1&quot;&gt;Tanvir Kaur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mondal_K/0/1/0/all/0/1&quot;&gt;Kaushik Mondal&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The aim of the dispersion problem is to place a set of $k(\leq n)$ mobile
robots in the nodes of an unknown graph consisting of $n$ nodes such that in
the final configuration each node contains at most one robot, starting from any
arbitrary initial configuration of the robots on the graph. In this work we
propose a variant of the dispersion problem where we start with any number of
robots, and put an additional constraint that no two adjacent nodes contain
robots in the final configuration. We name this problem as
Distance-2-Dispersion (D-2-D). However, even if the number of robots $k$ is
less than $n$, it may not possible for each robot to find a distinct node to
reside, maintaining our added constraint. Specifically, if a maximal
independent set is already formed by the nodes which contain a robot each, then
other robots, if any, who are searching for a node to seat, will not find one.
Hence we allow multiple robots to seat on some nodes only if there is no place
to seat. If $k\geq n$, it is guaranteed that the nodes with robots form a
maximal independent set of the underlying network.
&lt;/p&gt;
&lt;p&gt;The graph $G=(V, E)$ has $n$ nodes and $m$ edges, where nodes are anonymous.
It is a port labelled graph, i.e., each node $u$ assigns a distinct port number
to each of its incident edges from a range $[0,\delta-1]$ where $\delta$ is the
degree of the node $u$. The robots have unique ids in the range $[1, L]$, where
$L \ge k$. Co-located robots can communicate among themselves. We provide an
algorithm that solves D-2-D starting from a rooted configuration (i.e.,
initially all the robots are co-located) and terminate after $2\Delta(8m-3n+3)$
synchronous rounds using $O(log \Delta)$ memory per robot without using any
global knowledge of the graph parameters $m$, $n$ and $\Delta$, the maximum
degree of the graph. We also provide $\Omega(m\Delta)$ lower bound on the
number of rounds for the D-2-D problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Computing m-Eternal Domination Number of Cactus Graphs in Linear Time</title>
    <link href="http://arxiv.org/abs/2301.05155"/>
    <id>http://arxiv.org/abs/2301.05155</id>
    <updated>2023-01-13T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blazej_V/0/1/0/all/0/1&quot;&gt;V&amp;#xe1;clav Bla&amp;#x17e;ej&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kristan_J/0/1/0/all/0/1&quot;&gt;Jan Maty&amp;#xe1;&amp;#x161; K&amp;#x159;i&amp;#x161;&amp;#x165;an&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valla_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;&amp;#x161; Valla&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In m-eternal domination attacker and defender play on a graph. Initially, the
defender places guards on vertices. In each round, the attacker chooses a
vertex to attack. Then, the defender can move each guard to a neighboring
vertex and must move a guard to the attacked vertex. The m-eternal domination
number is the minimum number of guards such that the graph can be defended
indefinitely. In this paper, we study the m-eternal domination number of cactus
graphs. We consider two variants of the m-eternal domination number: one allows
multiple guards to occupy a single vertex, the second variant requires the
guards to occupy distinct vertices. We develop several tools for obtaining
lower and upper bounds on these problems and we use them to obtain an algorithm
which computes the minimum number of required guards of cactus graphs for both
variants of the problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: 1 Postdoc+2 PhD students at IDSIA (apply by April 30, 2023)</title>
    <link href="https://cstheory-jobs.org/2023/01/12/1-postdoc2-phd-students-at-idsia-apply-by-april-30-2023/"/>
    <id>http://cstheory-jobs.org/2023/01/12/1-postdoc2-phd-students-at-idsia-apply-by-april-30-2023/</id>
    <updated>2023-01-12T16:08:46+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The Algorithms and Complexity Group at IDSIA Lugano (Switzerland), opens 2 Ph.D. positions (4 years) and 1 Postdoc position (up to 4 years).&lt;br /&gt;
These positions are supported by the SNSF project &amp;#8220;Computational methods for integrality gaps analysis&amp;#8221;. There is no specific deadline; the positions will be filled as soon as eligible candidates with an appropriate background apply.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://people.idsia.ch/~monaldo/positions/positions.html&quot;&gt;https://people.idsia.ch/~monaldo/positions/positions.html&lt;/a&gt;&lt;br /&gt;
Email: monaldo@idsia.ch&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: Semantic Search for the Blog</title>
    <link href="https://blog.computationalcomplexity.org/2023/01/semantic-search-for-blog.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-8422659110181940895</id>
    <updated>2023-01-12T14:41:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&amp;nbsp;As Google started to &lt;a href=&quot;https://support.google.com/a/answer/10403871&quot;&gt;limit academic storage&lt;/a&gt;, I started looking at Google Takeout and started wondering what I could do with all that data. I downloaded all the posts from the blog, since we use Google&#39;s blogger, and ran them through &lt;a href=&quot;https://openai.com/blog/new-and-improved-embedding-model/&quot;&gt;OpenAI&#39;s Ada Embedding&lt;/a&gt;. The Ada embedding maps text up to 8192 words into a point on the 1536-dimensional unit sphere. You can measure the similarity between two embeddings via a simple dot product, giving you the cosine of the angle between them.&lt;/p&gt;&lt;p&gt;So I created a semantic search for the blog. Go ahead and &lt;a href=&quot;https://fortnow.pythonanywhere.com/&quot;&gt;try it out&lt;/a&gt;.&lt;/p&gt;
&lt;form action=&quot;https://fortnow.pythonanywhere.com/&quot; method=&quot;POST&quot;&gt;
    &lt;p&gt;Search for&amp;nbsp;&amp;nbsp;&lt;input name=&quot;search&quot; type=&quot;text&quot; /&gt;&lt;/p&gt;&lt;p&gt;You can enter a search term, phrase, or the full URL (including https) of a blog post. It will return a list of the 5 closest posts, with the percentage match, computed as the square of the cosine. I don&#39;t have a mechanism for automatically updating the files, so you&#39;ll only see posts from 2022 and earlier.&lt;/p&gt;&lt;p&gt;This was an Open AI-assisted affair, as I used ChatGPT and GitHub co-pilot to help with the python and pandas data frames. It took me longer to figure out how to create a web application so you can try the search. Similarity match doesn&#39;t work like normal searches, for example if you search for a city like &quot;Detroit&quot;, you&#39;ll get posts that mention other cities. Some other oddities, like &quot;mad&quot; seems to match &quot;Madhu&quot;. It probably says something about me that my most happy post is not about some great new theorem but about &lt;a href=&quot;https://blog.computationalcomplexity.org/2005/10/joy-on-south-side-of-chicago.html&quot;&gt;baseball&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;/form&gt;
&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Luca Aceto: Resources on how to apply for a CS job in academia/industry</title>
    <link href="http://processalgebra.blogspot.com/2023/01/resources-on-how-to-apply-for-cs-job-in.html"/>
    <id>tag:blogger.com,1999:blog-27705661.post-2113255095239595644</id>
    <updated>2023-01-12T09:12:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The PhD students in my department asked for advice on how to apply for jobs in academia and industry. I&#39;ll share whatever I might have to say with them this coming Tuesday and I am going through some material I collected.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Do you have any favourite resources on how to apply for a CS job in academia or industry such as &lt;a href=&quot;https://matt.might.net/articles/advice-for-academic-job-hunt/&quot; target=&quot;_blank&quot;&gt;this advice &lt;/a&gt;by Matt Might? If so, I&#39;d be grateful if you could share it with me as comments to this post. I&#39;ll collect the material and make it available somewhere.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Thanks in advance!&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Luca Aceto&lt;/p&gt;
  </content>
    <author>
      <name>Luca Aceto</name>
      <uri>http://processalgebra.blogspot.com/</uri>
    </author>
  </entry>


</feed>
