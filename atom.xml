<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Theory of Computing Report</title>
  <link rel="self" href=""/>
  <link href=""/>
  <id></id>
  <updated></updated>
  <generator uri="http://feedreader.github.io/">Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]</generator>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: No-Existence Of Generalize Diffusion</title>
    <link href="http://arxiv.org/abs/2304.03960"/>
    <id>http://arxiv.org/abs/2304.03960</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ponarovsky_D/0/1/0/all/0/1&quot;&gt;David Ponarovsky&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that there is no operator that given two state
$|\psi\rangle,|\phi\rangle$ compute the transformation:
$D|\psi\rangle|\phi\rangle = |\psi\rangle\bigl( \mathbb{I} - 2
|\psi\rangle\langle\psi| \bigr)|\phi\rangle$ The contradiction of the existence
follows by showing that using $D$ two players can compute the disjoints of
their sets in single round and $O\left( \sqrt{n} \right)$ communication
complexity, which shown by Braverman to be impossible \cite{Braverman}.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: The $n$-vehicle exploration problem is NP-complete</title>
    <link href="http://arxiv.org/abs/2304.03965"/>
    <id>http://arxiv.org/abs/2304.03965</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1&quot;&gt;Jinchuan Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoya Li&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The $n$-vehicle exploration problem (NVEP) is a combinatorial optimization
problem, which tries to find an optimal permutation of a fleet to maximize the
length traveled by the last vehicle. NVEP has a fractional form of objective
function, and its computational complexity of general case remains open. We
show that Hamiltonian Path $\leq_P$ NVEP, and prove that NVEP is NP-complete.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: A Simple Proof of the Mixing of Metropolis-Adjusted Langevin Algorithm under Smoothness and Isoperimetry</title>
    <link href="http://arxiv.org/abs/2304.04095"/>
    <id>http://arxiv.org/abs/2304.04095</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuansi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gatmiry_K/0/1/0/all/0/1&quot;&gt;Khashayar Gatmiry&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the mixing time of Metropolis-Adjusted Langevin algorithm (MALA) for
sampling a target density on $\mathbb{R}^d$. We assume that the target density
satisfies $\psi_\mu$-isoperimetry and that the operator norm and trace of its
Hessian are bounded by $L$ and $\Upsilon$ respectively. Our main result
establishes that, from a warm start, to achieve $\epsilon$-total variation
distance to the target density, MALA mixes in
$O\left(\frac{(L\Upsilon)^{\frac12}}{\psi_\mu^2}
\log\left(\frac{1}{\epsilon}\right)\right)$ iterations. Notably, this result
holds beyond the log-concave sampling setting and the mixing time depends on
only $\Upsilon$ rather than its upper bound $L d$. In the $m$-strongly
logconcave and $L$-log-smooth sampling setting, our bound recovers the previous
minimax mixing bound of MALA~\cite{wu2021minimax}.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: TDANetVis: Suggesting temporal resolutions for graph visualization using zigzag persistent homology</title>
    <link href="http://arxiv.org/abs/2304.03828"/>
    <id>http://arxiv.org/abs/2304.03828</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tinarrage_R/0/1/0/all/0/1&quot;&gt;Rapha&amp;#xeb;l Tinarrage&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ponciano_J/0/1/0/all/0/1&quot;&gt;Jean R. Ponciano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Linhares_C/0/1/0/all/0/1&quot;&gt;Claudio D. G. Linhares&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Traina_A/0/1/0/all/0/1&quot;&gt;Agma J. M. Traina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poco_J/0/1/0/all/0/1&quot;&gt;Jorge Poco&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Temporal graphs are commonly used to represent complex systems and track the
evolution of their constituents over time. Visualizing these graphs is crucial
as it allows one to quickly identify anomalies, trends, patterns, and other
properties leading to better decision-making. In this context, the
to-be-adopted temporal resolution is crucial in constructing and analyzing the
layout visually. The choice of a resolution is critical, e.g., when dealing
with temporally sparse graphs. In such cases, changing the temporal resolution
by grouping events (i.e., edges) from consecutive timestamps, a technique known
as timeslicing, can aid in the analysis and reveal patterns that might not be
discernible otherwise. However, choosing a suitable temporal resolution is not
trivial. In this paper, we propose TDANetVis, a methodology that suggests
temporal resolutions potentially relevant for analyzing a given graph, i.e.,
resolutions that lead to substantial topological changes in the graph
structure. To achieve this goal, TDANetVis leverages zigzag persistent
homology, a well-established technique from Topological Data Analysis (TDA). To
enhance visual graph analysis, TDANetVis also incorporates the colored barcode,
a novel timeline-based visualization built on the persistence barcodes commonly
used in TDA. We demonstrate the usefulness and effectiveness of TDANetVis
through a usage scenario and a user study involving 27 participants.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Improved estimates on the number of unit perimeter triangles</title>
    <link href="http://arxiv.org/abs/2304.03920"/>
    <id>http://arxiv.org/abs/2304.03920</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Goenka_R/0/1/0/all/0/1&quot;&gt;Ritesh Goenka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Moore_K/0/1/0/all/0/1&quot;&gt;Kenneth Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+White_E/0/1/0/all/0/1&quot;&gt;Ethan Patrick White&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We obtain new upper and lower bounds on the number of unit perimeter
triangles spanned by points in the plane. We also establish improved bounds in
the special case where the point set is a section of the integer grid.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Convex Hulls: Surface Mapping onto a Sphere</title>
    <link href="http://arxiv.org/abs/2304.04079"/>
    <id>http://arxiv.org/abs/2304.04079</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kenwright_B/0/1/0/all/0/1&quot;&gt;Ben Kenwright&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Writing an uncomplicated, robust, and scalable three-dimensional convex hull
algorithm is challenging and problematic. This includes, coplanar and collinear
issues, numerical accuracy, performance, and complexity trade-offs. While there
are a number of methods available for finding the convex hull based on
geometric calculations, such as, the distance between points, but do not
address the technical challenges when implementing a usable solution (e.g.,
numerical issues and degenerate cloud points). We explain some common algorithm
pitfalls and engineering modifications to overcome and solve these limitations.
We present a novel iterative method using support mapping and surface
projection to create an uncomplicated and robust 2d and 3d convex hull
algorithm.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On Testability of First-Order Properties in Bounded-Degree Graphs and Connections to Proximity-Oblivious Testing</title>
    <link href="http://arxiv.org/abs/2304.03810"/>
    <id>http://arxiv.org/abs/2304.03810</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adler_I/0/1/0/all/0/1&quot;&gt;Isolde Adler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohler_N/0/1/0/all/0/1&quot;&gt;Noleen K&amp;#xf6;hler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_P/0/1/0/all/0/1&quot;&gt;Pan Peng&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study property testing of properties that are definable in first-order
logic (FO) in the bounded-degree graph and relational structure models. We show
that any FO property that is defined by a formula with quantifier prefix
$\exists^*\forall^*$ is testable (i.e., testable with constant query
complexity), while there exists an FO property that is expressible by a formula
with quantifier prefix $\forall^*\exists^*$ that is not testable. In the dense
graph model, a similar picture is long known (Alon, Fischer, Krivelevich,
Szegedy, Combinatorica 2000), despite the very different nature of the two
models. In particular, we obtain our lower bound by an FO formula that defines
a class of bounded-degree expanders, based on zig-zag products of graphs. We
expect this to be of independent interest.
&lt;/p&gt;
&lt;p&gt;We then use our class of FO definable bounded-degree expanders to answer a
long-standing open problem for proximity-oblivious testers (POTs). POTs are a
class of particularly simple testing algorithms, where a basic test is
performed a number of times that may depend on the proximity parameter, but the
basic test itself is independent of the proximity parameter. In their seminal
work, Goldreich and Ron [STOC 2009; SICOMP 2011] show that the graph properties
that are constant-query proximity-oblivious testable in the bounded-degree
model are precisely the properties that can be expressed as a generalised
subgraph freeness (GSF) property that satisfies the non-propagation condition.
It is left open whether the non-propagation condition is necessary. We give a
negative answer by showing that our property is a GSF property which is
propagating. Hence in particular, our property does not admit a POT. For this
result we establish a new connection between FO properties and GSF-local
properties via neighbourhood profiles.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improving Identity-Robustness for Face Models</title>
    <link href="http://arxiv.org/abs/2304.03838"/>
    <id>http://arxiv.org/abs/2304.03838</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1&quot;&gt;Qi Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ardeshir_S/0/1/0/all/0/1&quot;&gt;Shervin Ardeshir&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Despite the success of deep-learning models in many tasks, there have been
concerns about such models learning shortcuts, and their lack of robustness to
irrelevant confounders. When it comes to models directly trained on human
faces, a sensitive confounder is that of human identities. Many face-related
tasks should ideally be identity-independent, and perform uniformly across
different individuals (i.e. be fair). One way to measure and enforce such
robustness and performance uniformity is through enforcing it during training,
assuming identity-related information is available at scale. However, due to
privacy concerns and also the cost of collecting such information, this is
often not the case, and most face datasets simply contain input images and
their corresponding task-related labels. Thus, improving identity-related
robustness without the need for such annotations is of great importance. Here,
we explore using face-recognition embedding vectors, as proxies for identities,
to enforce such robustness. We propose to use the structure in the
face-recognition embedding space, to implicitly emphasize rare samples within
each class. We do so by weighting samples according to their conditional
inverse density (CID) in the proxy embedding space. Our experiments suggest
that such a simple sample weighting scheme, not only improves the training
robustness, it often improves the overall performance as a result of such
robustness. We also show that employing such constraints during training
results in models that are significantly less sensitive to different levels of
bias in the dataset.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On Rotation Distance of Rank Bounded Trees</title>
    <link href="http://arxiv.org/abs/2304.03985"/>
    <id>http://arxiv.org/abs/2304.03985</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+M%2E_A/0/1/0/all/0/1&quot;&gt;Anoop S. K. M.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarma_J/0/1/0/all/0/1&quot;&gt;Jayalal Sarma&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Computing the rotation distance between two binary trees with $n$ internal
nodes efficiently (in $poly(n)$ time) is a long standing open question in the
study of height balancing in tree data structures. In this paper, we initiate
the study of this problem bounding the rank of the trees given at the input
(defined by Ehrenfeucht and Haussler (1989) in the context of decision trees).
We define the rank-bounded rotation distance between two given binary trees
$T_1$ and $T_2$ (with $n$ internal nodes) of rank at most $r$, denoted by
$d_r(T_1,T_2)$, as the length of the shortest sequence of rotations that
transforms $T_1$ to $T_2$ with the restriction that the intermediate trees must
be of rank at most $r$. We show that the rotation distance problem reduces in
polynomial time to the rank bounded rotation distance problem. This motivates
the study of the problem in the combinatorial and algorithmic frontiers.
Observing that trees with rank $1$ coincide exactly with skew trees (binary
trees where every internal node has at least one leaf as a child), we show the
following results in this frontier :
&lt;/p&gt;
&lt;p&gt;We present an $O(n^2)$ time algorithm for computing $d_1(T_1,T_2)$. That is,
when the given trees are skew trees (we call this variant as skew rotation
distance problem) - where the intermediate trees are restricted to be skew as
well. In particular, our techniques imply that for any two skew trees
$d(T_1,T_2) \le n^2$.
&lt;/p&gt;
&lt;p&gt;We show the following upper bound : for any two trees $T_1$ and $T_2$ of rank
at most $r_1$ and $r_2$ respectively, we have that: $d_r(T_1,T_2) \le n^2
(1+(2n+1)(r_1+r_2-2))$ where $r = max\{r_1,r_2\}$. This bound is asymptotically
tight for $r=1$.
&lt;/p&gt;
&lt;p&gt;En route our proof of the above theorems, we associate binary trees to
permutations and bivariate polynomials, and prove several characterizations in
the case of skew trees.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Prophet Inequalities: Separating Random Order from Order Selection</title>
    <link href="http://arxiv.org/abs/2304.04024"/>
    <id>http://arxiv.org/abs/2304.04024</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giambartolomei_G/0/1/0/all/0/1&quot;&gt;Giordano Giambartolomei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mallmann_Trenn_F/0/1/0/all/0/1&quot;&gt;Frederik Mallmann-Trenn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saona_R/0/1/0/all/0/1&quot;&gt;Raimundo Saona&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Prophet inequalities are a central object of study in optimal stopping
theory. A gambler is sent values online, sampled from an instance of
independent distributions, in an adversarial, random or selected order,
depending on the model. When observing each value, the gambler either accepts
it as a reward or irrevocably rejects it and proceeds to observe the next
value. The goal of the gambler, who cannot see the future, is maximising the
expected value of the reward while competing against the expectation of a
prophet (the offline maximum). In other words, one seeks to maximise the
gambler-to-prophet ratio of the expectations.
&lt;/p&gt;
&lt;p&gt;The model, in which the gambler selects the arrival order first, and then
observes the values, is known as Order Selection. Recently it has been shown
that in this model a ratio of $0.7251$ can be attained for any instance. If the
gambler chooses the arrival order (uniformly) at random, we obtain the Random
Order model. The worst case ratio over all possible instances has been
extensively studied for at least $40$ years. Still, it is not known if
carefully choosing the order, or simply taking it at random, benefits the
gambler. We prove that, in the Random Order model, no algorithm can achieve a
ratio larger than $0.7235$, thus showing for the first time that there is a
real benefit in choosing the order.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A simple and efficient preprocessing step for convex hull problem</title>
    <link href="http://arxiv.org/abs/2304.04196"/>
    <id>http://arxiv.org/abs/2304.04196</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heydari_M/0/1/0/all/0/1&quot;&gt;Mohammad Heydari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalifeh_A/0/1/0/all/0/1&quot;&gt;Ashkan Khalifeh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The present paper is concerned with a recursive algorithm as a preprocessing
step to find the convex hull of $n$ random points uniformly distributed in the
plane. For such a set of points, it is shown that eliminating all but $O(\log
n)$ of points can derive the same convex hull as the input set. Finally it will
be shown that the running time of the algorithm is $O(n)
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On Extend-Only Directed Posets and Derived Byzantine-Tolerant Replicated Data Types (Extended Version)</title>
    <link href="http://arxiv.org/abs/2304.04318"/>
    <id>http://arxiv.org/abs/2304.04318</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacob_F/0/1/0/all/0/1&quot;&gt;Florian Jacob&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hartenstein_H/0/1/0/all/0/1&quot;&gt;Hannes Hartenstein&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We uncover the extend-only directed posets (EDP) structure as a unification
of recently discussed DAG-based Byzantine-tolerant conflict-free replicated
data types (CRDT). We also show how a key-value map model can be derived from
the EDP formulation, and give an outlook on an EDP-based systemic access
control CRDT as a formalization of the CRDT used in the Matrix messaging
system.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Randomized and Deterministic Attention Sparsification Algorithms for Over-parameterized Feature Dimension</title>
    <link href="http://arxiv.org/abs/2304.04397"/>
    <id>http://arxiv.org/abs/2304.04397</id>
    <updated>2023-04-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1&quot;&gt;Yichuan Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahadevan_S/0/1/0/all/0/1&quot;&gt;Sridhar Mahadevan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Large language models (LLMs) have shown their power in different areas.
Attention computation, as an important subroutine of LLMs, has also attracted
interests in theory. Recently the static computation and dynamic maintenance of
attention matrix has been studied by [Alman and Song 2023] and [Brand, Song and
Zhou 2023] from both algorithmic perspective and hardness perspective. In this
work, we consider the sparsification of the attention problem. We make one
simplification which is the logit matrix is symmetric. Let $n$ denote the
length of sentence, let $d$ denote the embedding dimension. Given a matrix $X
\in \mathbb{R}^{n \times d}$, suppose $d \gg n$ and $\| X X^\top \|_{\infty} &amp;lt;
r$ with $r \in (0,0.1)$, then we aim for finding $Y \in \mathbb{R}^{n \times
m}$ (where $m\ll d$) such that \begin{align*} \| D(Y)^{-1} \exp( Y Y^\top ) -
D(X)^{-1} \exp( X X^\top) \|_{\infty} \leq O(r) \end{align*} We provide two
results for this problem.
&lt;/p&gt;
&lt;p&gt;$\bullet$ Our first result is a randomized algorithm. It runs in
$\widetilde{O}(\mathrm{nnz}(X) + n^{\omega} ) $ time, has $1-\delta$ succeed
probability, and chooses $m = O(n \log(n/\delta))$. Here $\mathrm{nnz}(X)$
denotes the number of non-zero entries in $X$. We use $\omega$ to denote the
exponent of matrix multiplication. Currently $\omega \approx 2.373$.
&lt;/p&gt;
&lt;p&gt;$\bullet$ Our second result is a deterministic algorithm. It runs in
$\widetilde{O}(\min\{\sum_{i\in[d]}\mathrm{nnz}(X_i)^2, dn^{\omega-1}\} +
n^{\omega+1})$ time and chooses $m = O(n)$. Here $X_i$ denote the $i$-th column
of matrix $X$.
&lt;/p&gt;
&lt;p&gt;Our main findings have the following implication for applied LLMs task: for
any super large feature dimension, we can reduce it down to the size nearly
linear in length of sentence.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: Complexity and Explainable AI</title>
    <link href="https://blog.computationalcomplexity.org/2023/04/complexity-and-generative-ai.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-8698511952609437812</id>
    <updated>2023-04-10T17:37:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;About six years ago, I &lt;a href=&quot;https://blog.computationalcomplexity.org/2017/04/understanding-machine-learning.html&quot;&gt;posted&lt;/a&gt;&amp;nbsp;on why it was important to understand machine learning, mentioning trust, fairness, security and causality. But I then I brought in complexity.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;What if P = NP? Would that help. Actually it would makes things worse. If you had a quick algorithm for NP-complete problems, you could use it to find the smallest possible circuit for say matching or traveling salesman but you would have no clue why that circuit works.&amp;nbsp;&lt;/blockquote&gt;&lt;p&gt;Ryan Williams &lt;a href=&quot;https://blog.computationalcomplexity.org/2017/04/understanding-machine-learning.html?showComment=1492464695392#c7595821335622802218&quot;&gt;countered&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;If P=NP you could also find the shortest proof in your favorite formal system that the smallest possible circuit does what you wanted it to do, as well as any other claim you are wondering that may be true about the circuit. That proof might not be comprehensible to you, but it could be written in a format where proof assistant software such as HOL or Coq could parse it and convince you it is correct. So if P=NP (with feasible low constants) I think that would definitely help.&lt;/blockquote&gt;&lt;p&gt;So if P = NP maybe you couldn&#39;t understand how the circuit works but any question about how it works you could answer.&amp;nbsp;&lt;/p&gt;&lt;p&gt;While we don&#39;t live in a world where P = NP, we are in a world where we can produce very strong learning algorithms where we can&#39;t understand the programs they produce. They are now powerful enough to apply Ryan&#39;s idea and use the algorithms themselves to understand the decisions they make.&lt;/p&gt;&lt;p&gt;For example I tried using Google Translate on a &lt;a href=&quot;https://mta.hu/mta_hirei/elhunyt-t-sos-vera-matematikus-az-mta-rendes-tagja-112809&quot;&gt;Hungarian obituary&lt;/a&gt; of Vera&amp;nbsp;Sós. Hungarian does not use gendered pronouns and and the translation incorrectly produced male pronouns. I then fed the translation into ChatGPT which translated with the correct female pronouns.&amp;nbsp;&lt;/p&gt;&lt;p&gt;You can speculate why Google Translate uses male pronouns but you can&#39;t ask it why. But you can ask ChatGPT.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;I used female pronouns in the translation because Vera T. Sós is a female name. Vera is a feminine given name, and since the context of the original text is about her life and accomplishments, it is appropriate to use female pronouns in the English translation to maintain clarity and accurately convey information about her.&lt;/blockquote&gt;&lt;p&gt;So perhaps if you want to understand how ML works, perhaps we should seek stronger algorithms, not weaker ones, algorithms that can explain themselves. As &lt;a href=&quot;https://knivesengraved.com/blogs/news/why-sharp-knives-are-safer-than-dull-knives&quot;&gt;they say&lt;/a&gt;, a dull knife is more dangerous than a sharp one.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Quantum delegation with an off-the-shelf device</title>
    <link href="http://arxiv.org/abs/2304.03448"/>
    <id>http://arxiv.org/abs/2304.03448</id>
    <updated>2023-04-10T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Broadbent_A/0/1/0/all/0/1&quot;&gt;Anne Broadbent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Mehta_A/0/1/0/all/0/1&quot;&gt;Arthur Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yuming Zhao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given that reliable cloud quantum computers are becoming closer to reality,
the concept of delegation of quantum computations and its verifiability is of
central interest. Many models have been proposed, each with specific strengths
and weaknesses. Here, we put forth a new model where the client trusts only its
classical processing, makes no computational assumptions, and interacts with a
quantum server in a single round. In addition, during a set-up phase, the
client specifies the size $n$ of the computation and receives an untrusted,
off-the-shelf (OTS) quantum device that is used to report the outcome of a
single constant-sized measurement from a predetermined logarithmic-sized input.
In the OTS model, we thus picture that a single quantum server does the bulk of
the computations, while the OTS device is used as an untrusted and generic
verification device, all in a single round.
&lt;/p&gt;
&lt;p&gt;We show how to delegate polynomial-time quantum computations in the OTS
model. Scaling up the technique also yields an interactive proof system for all
of QMA, which, furthermore, we show can be accomplished in statistical
zero-knowledge. This yields the first relativistic (one-round), two-prover
zero-knowledge proof system for QMA.
&lt;/p&gt;
&lt;p&gt;As a proof approach, we provide a new self-test for $n$-EPR pairs using only
constant-sized Pauli measurements, and show how it provides a new avenue for
the use of simulatable codes for local Hamiltonian verification. Along the way,
we also provide an enhanced version of a well-known stability result due to
Gowers and Hatami and show how it completes a common argument used in
self-testing.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Maximal Distortion of Geodesic Diameters in Polygonal Domains</title>
    <link href="http://arxiv.org/abs/2304.03484"/>
    <id>http://arxiv.org/abs/2304.03484</id>
    <updated>2023-04-10T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dumitrescu_A/0/1/0/all/0/1&quot;&gt;Adrian Dumitrescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toth_C/0/1/0/all/0/1&quot;&gt;Csaba D. T&amp;#xf3;th&lt;/a&gt;&lt;/p&gt;&lt;p&gt;For a polygon $P$ with holes in the plane, we denote by $\varrho(P)$ the
ratio between the geodesic and the Euclidean diameters of $P$. It is shown that
over all convex polygons with $h$~convex holes, the supremum of $\varrho(P)$ is
between $\Omega(h^{1/3})$ and $O(h^{1/2})$. The upper bound improves to
$O(1+\min\{h^{3/4}\Delta,h^{1/2}\Delta^{1/2}\})$ if every hole has diameter at
most $\Delta\cdot {\rm diam}_2(P)$; and to $O(1)$ if every hole is a \emph{fat}
convex polygon. Furthermore, we show that the function $g(h)=\sup_P \varrho(P)$
over convex polygons with $h$ convex holes has the same growth rate as an
analogous quantity over geometric triangulations with $h$ vertices when
$h\rightarrow \infty$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Leveraging Reusability: Improved Competitive Ratio of Greedy for Reusable Resources</title>
    <link href="http://arxiv.org/abs/2304.03377"/>
    <id>http://arxiv.org/abs/2304.03377</id>
    <updated>2023-04-10T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1&quot;&gt;Jackie Baek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shixin Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study online weighted bipartite matching of reusable resources where an
adversarial sequence of requests for resources arrive over time. A resource
that is matched is &#39;used&#39; for a random duration, drawn independently from a
resource-dependent distribution, after which it returns and is able to be
matched again. We study the performance of the greedy policy, which matches
requests to the resource that yields the highest reward. Previously, it was
known that the greedy policy is 1/2 competitive against a clairvoyant benchmark
that knows the request sequence in advance. In this work, we improve this
result by introducing a parameter that quantifies the degree of reusability of
the resources. Specifically, if p represents the smallest probability over the
usage distributions that a matched resource returns in one time step, the
greedy policy achieves a competitive ratio of $1/(2-p)$. Furthermore, when the
usage distributions are geometric, we establish a stronger competitive ratio of
$(1+p)/2$, which we demonstrate to be tight. Both of these results align with
the known results in the two extreme scenarios: p = 0 corresponds to
non-reusable resources, where 1/2 is known to be tight, while p = 1 corresponds
to every resource returning immediately, where greedy is the optimal policy and
hence the competitive ratio is 1. Finally, we show that both results are robust
to approximations of the greedy policy. Our work demonstrates that the
reusability of resources can enhance performance compared to the non-reusable
setting, and that a simple greedy policy suffices when the degree of
reusability is high. Our insights contribute to the understanding of how
resource reusability can influence the performance of online algorithms, and
highlight the potential for improved performance as the degree of reusability
increases.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Convex Minimization with Integer Minima in $\widetilde O(n^4)$ Time</title>
    <link href="http://arxiv.org/abs/2304.03426"/>
    <id>http://arxiv.org/abs/2304.03426</id>
    <updated>2023-04-10T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Haotian Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yin Tat Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lichen Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a convex function $f$ on $\mathbb{R}^n$ with an integer minimizer, we
show how to find an exact minimizer of $f$ using $O(n^2 \log n)$ calls to a
separation oracle and $O(n^4 \log n)$ time. The previous best polynomial time
algorithm for this problem given in [Jiang, SODA 2021, JACM 2022] achieves
$\widetilde{O}(n^2)$ oracle complexity. However, the overall runtime of Jiang&#39;s
algorithm is at least $\widetilde{\Omega}(n^8)$, due to expensive sub-routines
such as the Lenstra-Lenstra-Lov\&#39;asz (LLL) algorithm [Lenstra, Lenstra,
Lov\&#39;asz, Math. Ann. 1982] and random walk based cutting plane method
[Bertsimas, Vempala, JACM 2004]. Our significant speedup is obtained by a
nontrivial combination of a faster version of the LLL algorithm due to
[Neumaier, Stehl\&#39;e, ISSAC 2016] that gives similar guarantees, the volumetric
center cutting plane method (CPM) by [Vaidya, FOCS 1989] and its fast
implementation given in [Jiang, Lee, Song, Wong, STOC 2020].
&lt;/p&gt;
&lt;p&gt;For the special case of submodular function minimization (SFM), our result
implies a strongly polynomial time algorithm for this problem using $O(n^3 \log
n)$ calls to an evaluation oracle and $O(n^4 \log n)$ additional arithmetic
operations. Both the oracle complexity and the number of arithmetic operations
of our more general algorithm are better than the previous best-known runtime
algorithms for this specific problem given in [Lee, Sidford, Wong, FOCS 2015]
and [Dadush, V\&#39;egh, Zambelli, SODA 2018, MOR 2021].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Temporalizing digraphs via linear-size balanced bi-trees</title>
    <link href="http://arxiv.org/abs/2304.03567"/>
    <id>http://arxiv.org/abs/2304.03567</id>
    <updated>2023-04-10T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bessy_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Bessy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Thomasse_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phan Thomass&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Viennot_L/0/1/0/all/0/1&quot;&gt;Laurent Viennot&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a directed graph $D$ on vertex set $v_1,\dots ,v_n$, a \emph{forward arc}
is an arc $v_iv_j$ where $i&amp;lt;j$. A pair $v_i,v_j$ is \emph{forward connected} if
there is a directed path from $v_i$ to $v_j$ consisting of forward arcs. In the
{\tt Forward Connected Pairs Problem} ({\tt FCPP}), the input is a strongly
connected digraph $D$, and the output is the maximum number of forward
connected pairs in some vertex enumeration of $D$. We show that {\tt FCPP} is
in APX, as one can efficiently enumerate the vertices of $D$ in order to
achieve a quadratic number of forward connected pairs. For this, we construct a
linear size balanced bi-tree $T$ (an out-tree and an in-tree with same size
which roots are identified). The existence of such a $T$ was left as an open
problem motivated by the study of temporal paths in temporal networks. More
precisely, $T$ can be constructed in quadratic time (in the number of vertices)
and has size at least $n/3$. The algorithm involves a particular depth-first
search tree (Left-DFS) of independent interest, and shows that every strongly
connected directed graph has a balanced separator which is a circuit.
Remarkably, in the request version {\tt RFCPP} of {\tt FCPP}, where the input
is a strong digraph $D$ and a set of requests $R$ consisting of pairs
$\{x_i,y_i\}$, there is no constant $c&amp;gt;0$ such that one can always find an
enumeration realizing $c.|R|$ forward connected pairs $\{x_i,y_i\}$ (in either
direction).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR23-044 |  Separations between Combinatorial Measures for Transitive Functions | 

	Sourav Chakraborty, 

	Chandrima Kayal, 

	Manaswi Paraashar</title>
    <link href="https://eccc.weizmann.ac.il/report/2023/044"/>
    <id>https://eccc.weizmann.ac.il/report/2023/044</id>
    <updated>2023-04-09T11:26:00+00:00</updated>
    <content type="html" xml:lang="en">
    The role of symmetry in Boolean functions $f:\{0,1\}^n \to \{0,1\}$ has been extensively studied in complexity theory. 
For example, symmetric functions, that is, functions that are invariant under the action of $S_n$ is an important class of functions in the study of Boolean functions.
A function $f:\{0,1\}^n \to \{0,1\}$ is called transitive (or weakly-symmetric) if there exists a transitive group $G$ of $S_n$ such that $f$ is invariant under the action of $G$. In other words, the value of a transitive function remains unchanged even after the input bits of $f$ are moved around according to some permutation $\sigma \in G$. Understanding various complexity measures of transitive functions has been a rich area of research for the past few decades.



In this work, we study transitive functions in light of several combinatorial measures. The question that we try to address in this paper is what is the maximum separations between various pairs of combinatorial measures for transitive functions. Such study for general Boolean functions has been going on for the past many years. The current best-known results for general Boolean functions have been nicely compiled by Aaronson et~al.~(STOC, 2021). But before this paper, no such systematic study has been done for the case of transitive functions. 

 
The separation between a pair of combinatorial measures is shown by constructing interesting functions that demonstrate the separation. Over the past three decades, various interesting classes of functions have been designed for this purpose. In this context, one of the celebrated classes of functions is the class of ``pointer functions&amp;#39;&amp;#39;.
Ambainis et al.~(JACM, 2017) constructed several functions, which are modifications of the pointer function, first introduced in G{\&amp;quot;{o}}{\&amp;quot;{o}}s et~al.~(SICOMP, 2018 / FOCS, 2015), to demonstrate separation between various pairs of measures. In the last few years, pointer functions have been used to show separation between  various other pairs of measures (for example, Mukhopadhyay et~al.~(FSTTCS, 2015), Ben-David et~al.~(ITCS, 2017), G{\&amp;quot;{o}}{\&amp;quot;{o}}s et~al.~(ToCT, 2018 / ICALP, 2017)).  

However, the pointer functions themselves are not transitive. 
Based on the various kinds of pointer functions, we construct new transitive functions whose deterministic query complexity, randomized query complexity, zero-error randomized query complexity, quantum query complexity, degree, and approximate degree are similar to that of the original pointer functions. Thus we demonstrate that even for transitive functions similar separations between pairs of combinatorial measures can be achieved.  

Our constructions of transitive functions depend crucially on construction of particular classes of transitive groups, whose actions, though involved, helps to preserve certain structural features of the input strings.  The transitive groups we construct may be of independent interest in other areas of mathematics and theoretical computer science. 

We summarize the current knowledge of relations between various combinatorial measures of transitive functions in a table similar to the table compiled by Aaronson et~al.~(STOC, 2021) for general functions.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR23-043 |  Coboundary and cosystolic expansion without dependence on dimension or degree | 

	Yotam Dikstein, 

	Irit Dinur</title>
    <link href="https://eccc.weizmann.ac.il/report/2023/043"/>
    <id>https://eccc.weizmann.ac.il/report/2023/043</id>
    <updated>2023-04-09T06:09:10+00:00</updated>
    <content type="html" xml:lang="en">
    We give new bounds on the cosystolic expansion constants of several families of high dimensional expanders, and the known coboundary expansion constants of order complexes of homogeneous geometric lattices, including the spherical building of $SL_n(F_q)$. The improvement applies to the high dimensional expanders constructed by Lubotzky, Samuels and Vishne, and by Kaufman and Oppenheim.

Our new expansion constants do not depend on the degree of the complex nor on its dimension, nor on the group of coefficients. This implies improved bounds on Gromov’s topological overlap constant, and on Dinur and Meshulam’s cover stability, which may have applications for agreement testing. In comparison, existing bounds decay exponentially with the ambient dimension (for spherical buildings) and in addition decay linearly with the degree (for all known bounded-degree high dimensional expanders).

Our results are based on several new techniques:

– We develop a new “color-restriction” technique which enables proving dimension-free expansion by restricting a multi-partite complex to small random subsets of its color classes.

– We give a new “spectral” proof for Evra and Kaufman’s local-to-global theorem, deriving better bounds and getting rid of the dependence on the degree. This theorem bounds the cosystolic expansion of a complex using coboundary expansion and spectral expansion of the links.

– We derive absolute bounds on the coboundary expansion of the spherical building (and any order complex of a homogeneous geometric lattice) by constructing a novel family of very short cones.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Property Testing Review: News for March 2023</title>
    <link href="https://ptreview.sublinear.info/2023/04/news-for-march-2023/"/>
    <id>https://ptreview.sublinear.info/?p=1866</id>
    <updated>2023-04-07T16:45:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;I never thought this day would come.&lt;/p&gt;



&lt;p&gt;For the first time in PTReview history, there is no paper to report. Nada. Zilch.&lt;/p&gt;



&lt;p&gt;The calm before the storm&amp;#8230;?&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Seshadhri&lt;/p&gt;
  </content>
    <author>
      <name>Property Testing Review</name>
      <uri>https://ptreview.sublinear.info</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Tight Correlation Bounds for Circuits Between AC0 and TC0</title>
    <link href="http://arxiv.org/abs/2304.02770"/>
    <id>http://arxiv.org/abs/2304.02770</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vinayak M. Kumar&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We initiate the study of generalized AC0 circuits comprised of negations and
arbitrary unbounded fan-in gates that only need to be constant over inputs of
Hamming weight $\ge k$, which we denote GC0$(k)$. The gate set of this class
includes biased LTFs like the $k$-$OR$ (output $1$ iff $\ge k$ bits are 1) and
$k$-$AND$ (output $0$ iff $\ge k$ bits are 0), and thus can be seen as an
interpolation between AC0 and TC0. We establish a tight multi-switching lemma
for GC0$(k)$ circuits, which bounds the probability that several depth-2
GC0$(k)$ circuits do not simultaneously simplify under a random restriction. We
also establish a new depth reduction lemma such that coupled with our
multi-switching lemma, we can show many results obtained from the
multi-switching lemma for depth-$d$ size-$s$ AC0 circuits lifts to depth-$d$
size-$s^{.99}$ GC0$(.01\log s)$ circuits with no loss in parameters (other than
hidden constants). Our result has the following applications:
&lt;/p&gt;
&lt;p&gt;1.Size-$2^{\Omega(n^{1/d})}$ depth-$d$ GC0$(\Omega(n^{1/d}))$ circuits do not
correlate with parity (extending a result of H{\aa}stad (SICOMP, 2014)).
&lt;/p&gt;
&lt;p&gt;2. Size-$n^{\Omega(\log n)}$ GC0$(\Omega(\log^2 n))$ circuits with $n^{.249}$
arbitrary threshold gates or $n^{.499}$ arbitrary symmetric gates exhibit
exponentially small correlation against an explicit function (extending a
result of Tan and Servedio (RANDOM, 2019)).
&lt;/p&gt;
&lt;p&gt;3. There is a seed length $O((\log m)^{d-1}\log(m/\varepsilon)\log\log(m))$
pseudorandom generator against size-$m$ depth-$d$ GC0$(\log m)$ circuits,
matching the AC0 lower bound of H{\aa}stad stad up to a $\log\log m$ factor
(extending a result of Lyu (CCC, 2022)).
&lt;/p&gt;
&lt;p&gt;4. Size-$m$ GC0$(\log m)$ circuits have exponentially small Fourier tails
(extending a result of Tal (CCC, 2017)).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Inapproximability of sufficient reasons for decision trees</title>
    <link href="http://arxiv.org/abs/2304.02781"/>
    <id>http://arxiv.org/abs/2304.02781</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozachinskiy_A/0/1/0/all/0/1&quot;&gt;Alexander Kozachinskiy&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this note, we establish the hardness of approximation of the problem of
computing the minimal size of a $\delta$-sufficient reason for decision trees.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Improved Hardness of Approximating k-Clique under ETH</title>
    <link href="http://arxiv.org/abs/2304.02943"/>
    <id>http://arxiv.org/abs/2304.02943</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1&quot;&gt;Bingkai Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1&quot;&gt;Xuandi Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yican Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiuhan Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we prove that assuming the exponential time hypothesis (ETH),
there is no $f(k)\cdot n^{k^{o(1/\log\log k)}}$-time algorithm that can decide
whether an $n$-vertex graph contains a clique of size $k$ or contains no clique
of size $k/2$, and no FPT algorithm can decide whether an input graph has a
clique of size $k$ or no clique of size $k/f(k)$, where $f(k)$ is some function
in $k^{1-o(1)}$. Our results significantly improve the previous works [Lin21,
LRSW22]. The crux of our proof is a framework to construct gap-producing
reductions for the \kclique{} problem. More precisely, we show that given an
error-correcting code $C:\Sigma_1^k\to\Sigma_2^{k&#39;}$ that is locally testable
and smooth locally decodable in the parallel setting, one can construct a
reduction which on input a graph $G$ outputs a graph $G&#39;$ in $(k&#39;)^{O(1)}\cdot
n^{O(\log|\Sigma_2|/\log|\Sigma_1|)}$ time such that:
&lt;/p&gt;
&lt;p&gt;$\bullet$ If $G$ has a clique of size $k$, then $G&#39;$ has a clique of size
$K$, where $K = (k&#39;)^{O(1)}$.
&lt;/p&gt;
&lt;p&gt;$\bullet$ If $G$ has no clique of size $k$, then $G&#39;$ has no clique of size
$(1-\varepsilon)\cdot K$ for some constant $\varepsilon\in(0,1)$.
&lt;/p&gt;
&lt;p&gt;We then construct such a code with $k&#39;=k^{\Theta(\log\log k)}$ and
$|\Sigma_2|=|\Sigma_1|^{k^{0.54}}$, establishing the hardness results above.
Our code generalizes the derivative code [WY07] into the case with a super
constant order of derivatives.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: The complexity of decomposing a graph into a matching and a bounded linear forest</title>
    <link href="http://arxiv.org/abs/2304.03256"/>
    <id>http://arxiv.org/abs/2304.03256</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1&quot;&gt;Agnijo Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marciano_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Pedro Marciano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mond_A/0/1/0/all/0/1&quot;&gt;Adva Mond&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petr_J/0/1/0/all/0/1&quot;&gt;Jan Petr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Portier_J/0/1/0/all/0/1&quot;&gt;Julien Portier&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Deciding whether a graph can be edge-decomposed into a matching and a
$k$-bounded linear forest was recently shown by Campbell, H{\&quot;o}rsch and Moore
to be NP-complete for every $k \ge 9$, and solvable in polynomial time for
$k=1,2$. In the first part of this paper, we close this gap by showing that
this problem is in NP-complete for every $k \ge 3$. In the second part of the
paper, we show that deciding whether a graph can be edge-decomposed into a
matching and a $k$-bounded star forest is polynomially solvable for any $k \in
\mathbb{N} \cup \{ \infty \}$, answering another question by Campbell,
H{\&quot;o}rsch and Moore from the same paper.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Software and Analysis for Dynamic Voronoi Diagrams in the Hilbert Metric</title>
    <link href="http://arxiv.org/abs/2304.02745"/>
    <id>http://arxiv.org/abs/2304.02745</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bumpus_M/0/1/0/all/0/1&quot;&gt;Madeline Bumpus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_C/0/1/0/all/0/1&quot;&gt;Caesar Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gezalyan_A/0/1/0/all/0/1&quot;&gt;Auguste H. Gezalyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munoz_S/0/1/0/all/0/1&quot;&gt;Sam Munoz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santhoshkumar_R/0/1/0/all/0/1&quot;&gt;Renita Santhoshkumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1&quot;&gt;Songyu Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mount_D/0/1/0/all/0/1&quot;&gt;David M. Mount&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Hilbert metric is a projective metric defined on a convex body which
generalizes the Cayley-Klein model of hyperbolic geometry to any convex set. In
this paper we analyze Hilbert Voronoi diagrams in the Dynamic setting. In
addition we introduce dynamic visualization software for Voronoi diagrams in
the Hilbert metric on user specified convex polygons.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Fast computation of approximate weak common intervals in multiple indeterminate strings</title>
    <link href="http://arxiv.org/abs/2304.02657"/>
    <id>http://arxiv.org/abs/2304.02657</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doerr_D/0/1/0/all/0/1&quot;&gt;Daniel Doerr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moret_B/0/1/0/all/0/1&quot;&gt;Bernard M.E. Moret&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In ongoing work to define a principled method for syntenic block discovery
and structuring, work based on homology-derived constraints and a
generalization of common intervals, we faced a fundamental computational
problem: how to determine quickly, among a set of indeterminate strings
(strings whose elements consist of subsets of characters), contiguous intervals
that would share a vast majority of their elements, but allow for sharing
subsets of characters subsumed by others, and also for certain elements to be
missing from certain genomes. An algorithm for this problem in the special case
of determinate strings (where each element is a single character of the
alphabet, i.e., &quot;normal&quot; strings) was described by Doerr et al., but its
running time would explode if generalized to indeterminate strings. In this
paper, we describe an algorithm for computing these special common intervals in
time close to that of the simpler algorithm of Doerr et al. and show that can
compute these intervals in just a couple of hours for large collections (tens
to hundreds) of bacterial genomes.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Agnostic proper learning of monotone functions: beyond the black-box correction barrier</title>
    <link href="http://arxiv.org/abs/2304.02700"/>
    <id>http://arxiv.org/abs/2304.02700</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lange_J/0/1/0/all/0/1&quot;&gt;Jane Lange&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasilyan_A/0/1/0/all/0/1&quot;&gt;Arsen Vasilyan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We give the first agnostic, efficient, proper learning algorithm for monotone
Boolean functions. Given $2^{\tilde{O}(\sqrt{n}/\varepsilon)}$ uniformly random
examples of an unknown function $f:\{\pm 1\}^n \rightarrow \{\pm 1\}$, our
algorithm outputs a hypothesis $g:\{\pm 1\}^n \rightarrow \{\pm 1\}$ that is
monotone and $(\mathrm{opt} + \varepsilon)$-close to $f$, where $\mathrm{opt}$
is the distance from $f$ to the closest monotone function. The running time of
the algorithm (and consequently the size and evaluation time of the hypothesis)
is also $2^{\tilde{O}(\sqrt{n}/\varepsilon)}$, nearly matching the lower bound
of Blais et al (RANDOM &#39;15). We also give an algorithm for estimating up to
additive error $\varepsilon$ the distance of an unknown function $f$ to
monotone using a run-time of $2^{\tilde{O}(\sqrt{n}/\varepsilon)}$. Previously,
for both of these problems, sample-efficient algorithms were known, but these
algorithms were not run-time efficient. Our work thus closes this gap in our
knowledge between the run-time and sample complexity.
&lt;/p&gt;
&lt;p&gt;This work builds upon the improper learning algorithm of Bshouty and Tamon
(JACM &#39;96) and the proper semiagnostic learning algorithm of Lange, Rubinfeld,
and Vasilyan (FOCS &#39;22), which obtains a non-monotone Boolean-valued
hypothesis, then ``corrects&#39;&#39; it to monotone using query-efficient local
computation algorithms on graphs. This black-box correction approach can
achieve no error better than $2\mathrm{opt} + \varepsilon$
information-theoretically; we bypass this barrier by
&lt;/p&gt;
&lt;p&gt;a) augmenting the improper learner with a convex optimization step, and
&lt;/p&gt;
&lt;p&gt;b) learning and correcting a real-valued function before rounding its values
to Boolean.
&lt;/p&gt;
&lt;p&gt;Our real-valued correction algorithm solves the ``poset sorting&#39;&#39; problem of
[LRV22] for functions over general posets with non-Boolean labels.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: LSketch: A Label-Enabled Graph Stream Sketch Toward Time-Sensitive Queries</title>
    <link href="http://arxiv.org/abs/2304.02897"/>
    <id>http://arxiv.org/abs/2304.02897</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1&quot;&gt;Yiling Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1&quot;&gt;Chunyao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuhan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1&quot;&gt;Tingjian Ge&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Graph streams represent data interactions in real applications. The mining of
graph streams plays an important role in network security, social network
analysis, and traffic control, among others. However, the sheer volume and high
dynamics cause great challenges for efficient storage and subsequent query
analysis on them. Current studies apply sketches to summarize graph streams. We
propose LSketch that works for heterogeneous graph streams, which effectively
preserves the label information carried by the streams in real scenes, thereby
enriching the expressive ability of sketches. In addition, as graph streams
continue to evolve over time, edges too old may lose their practical
significance. Therefore, we introduce the sliding window model into LSketch to
eliminate the expired edges automatically. LSketch uses sub-linear storage
space and can support structure based queries and time-sensitive queries with
high accuracy. We perform extensive experiments over four real datasets,
demonstrating the superiority of the proposed method over state-of-the-art
methods, in aspects of query accuracy and time efficiency.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Parameterized Approximation Schemes for Clustering with General Norm Objectives</title>
    <link href="http://arxiv.org/abs/2304.03146"/>
    <id>http://arxiv.org/abs/2304.03146</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbasi_F/0/1/0/all/0/1&quot;&gt;Fateme Abbasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1&quot;&gt;Sandip Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Byrka_J/0/1/0/all/0/1&quot;&gt;Jaros&amp;#x142;aw Byrka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chalermsook_P/0/1/0/all/0/1&quot;&gt;Parinya Chalermsook&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gadekar_A/0/1/0/all/0/1&quot;&gt;Ameet Gadekar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khodamoradi_K/0/1/0/all/0/1&quot;&gt;Kamyar Khodamoradi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marx_D/0/1/0/all/0/1&quot;&gt;D&amp;#xe1;niel Marx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1&quot;&gt;Roohani Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spoerhase_J/0/1/0/all/0/1&quot;&gt;Joachim Spoerhase&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper considers the well-studied algorithmic regime of designing a
$(1+\epsilon)$-approximation algorithm for a $k$-clustering problem that runs
in time $f(k,\epsilon)poly(n)$ (sometimes called an efficient parameterized
approximation scheme or EPAS for short). Notable results of this kind include
EPASes in the high-dimensional Euclidean setting for $k$-center [Bad\u{o}iu,
Har-Peled, Indyk; STOC&#39;02] as well as $k$-median, and $k$-means [Kumar,
Sabharwal, Sen; J. ACM 2010]. However, existing EPASes handle only basic
objectives (such as $k$-center, $k$-median, and $k$-means) and are tailored to
the specific objective and metric space.
&lt;/p&gt;
&lt;p&gt;Our main contribution is a clean and simple EPAS that settles more than ten
clustering problems (across multiple well-studied objectives as well as metric
spaces) and unifies well-known EPASes. Our algorithm gives EPASes for a large
variety of clustering objectives (for example, $k$-means, $k$-center,
$k$-median, priority $k$-center, $\ell$-centrum, ordered $k$-median, socially
fair $k$-median aka robust $k$-median, or more generally monotone norm
$k$-clustering) and metric spaces (for example, continuous high-dimensional
Euclidean spaces, metrics of bounded doubling dimension, bounded treewidth
metrics, and planar metrics).
&lt;/p&gt;
&lt;p&gt;Key to our approach is a new concept that we call bounded $\epsilon$-scatter
dimension--an intrinsic complexity measure of a metric space that is a
relaxation of the standard notion of bounded doubling dimension. Our main
technical result shows that two conditions are essentially sufficient for our
algorithm to yield an EPAS on the input metric $M$ for any clustering
objective: (i) The objective is described by a monotone (not necessarily
symmetric!) norm, and (ii) the $\epsilon$-scatter dimension of $M$ is upper
bounded by a function of $\epsilon$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Spectral Toolkit of Algorithms for Graphs: Technical Report (1)</title>
    <link href="http://arxiv.org/abs/2304.03170"/>
    <id>http://arxiv.org/abs/2304.03170</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Macgregor_P/0/1/0/all/0/1&quot;&gt;Peter Macgregor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;He Sun&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Spectral Toolkit of Algorithms for Graphs (STAG) is an open-source library
for efficient spectral graph algorithms, and its development starts in
September 2022. We have so far finished the component on local graph
clustering, and this technical report presents a user&#39;s guide to STAG, showcase
studies, and several technical considerations behind our development.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On the tractability of sampling from the Potts model at low temperatures via Swendsen--Wang dynamics</title>
    <link href="http://arxiv.org/abs/2304.03182"/>
    <id>http://arxiv.org/abs/2304.03182</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Blanca_A/0/1/0/all/0/1&quot;&gt;Antonio Blanca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gheissari_R/0/1/0/all/0/1&quot;&gt;Reza Gheissari&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Sampling from the $q$-state ferromagnetic Potts model is a fundamental
question in statistical physics, probability theory, and theoretical computer
science. On general graphs, this problem is computationally hard, and this
hardness holds at arbitrarily low temperatures. At the same time, in recent
years, there has been significant progress showing the existence of
low-temperature sampling algorithms in various specific families of graphs. Our
aim in this paper is to understand the minimal structural properties of general
graphs that enable polynomial-time sampling from the $q$-state ferromagnetic
Potts model at low temperatures. We study this problem from the perspective of
the widely-used Swendsen--Wang dynamics and the closely related random-cluster
dynamics.
&lt;/p&gt;
&lt;p&gt;Our results demonstrate that the key graph property behind fast or slow
convergence time for these dynamics is whether the independent edge-percolation
on the graph admits a strongly supercritical phase. By this, we mean that at
large $p&amp;lt;1$, it has a unique giant component of linear size, and the complement
of that giant component is comprised of only small components. Specifically, we
prove that such a condition implies fast mixing of the Swendsen--Wang and
random-cluster dynamics on two general families of bounded-degree graphs: (a)
graphs of at most stretched-exponential volume growth and (b) locally treelike
graphs. In the other direction, we show that, even among graphs in those
families, these Markov chains can converge exponentially slowly at arbitrarily
low temperatures if the edge-percolation condition does not hold. In the
process, we develop new tools for the analysis of non-local Markov chains,
including a framework to bound the speed of disagreement propagation in the
presence of long-range correlations, and an understanding of spatial mixing
properties on trees with random boundary conditions.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Krylov Methods are (nearly) Optimal for Low-Rank Approximation</title>
    <link href="http://arxiv.org/abs/2304.03191"/>
    <id>http://arxiv.org/abs/2304.03191</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bakshi_A/0/1/0/all/0/1&quot;&gt;Ainesh Bakshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1&quot;&gt;Shyam Narayanan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the problem of rank-$1$ low-rank approximation (LRA) in the
matrix-vector product model under various Schatten norms: $$
&lt;/p&gt;
&lt;p&gt;\min_{\|u\|_2=1} \|A (I - u u^\top)\|_{\mathcal{S}_p} , $$ where
$\|M\|_{\mathcal{S}_p}$ denotes the $\ell_p$ norm of the singular values of
$M$. Given $\varepsilon&amp;gt;0$, our goal is to output a unit vector $v$ such that
$$
&lt;/p&gt;
&lt;p&gt;\|A(I - vv^\top)\|_{\mathcal{S}_p} \leq (1+\varepsilon) \min_{\|u\|_2=1}\|A(I
- u u^\top)\|_{\mathcal{S}_p}. $$ Our main result shows that Krylov methods
(nearly) achieve the information-theoretically optimal number of matrix-vector
products for Spectral ($p=\infty$), Frobenius ($p=2$) and Nuclear ($p=1$) LRA.
&lt;/p&gt;
&lt;p&gt;In particular, for Spectral LRA, we show that any algorithm requires
$\Omega\left(\log(n)/\varepsilon^{1/2}\right)$ matrix-vector products, exactly
matching the upper bound obtained by Krylov methods [MM15, BCW22]. Our lower
bound addresses Open Question 1 in [Woo14], providing evidence for the lack of
progress on algorithms for Spectral LRA and resolves Open Question 1.2 in
[BCW22]. Next, we show that for any fixed constant $p$, i.e. $1\leq p =O(1)$,
there is an upper bound of
$O\left(\log(1/\varepsilon)/\varepsilon^{1/3}\right)$ matrix-vector products,
implying that the complexity does not grow as a function of input size. This
improves the $O\left(\log(n/\varepsilon)/\varepsilon^{1/3}\right)$ bound
recently obtained in [BCW22], and matches their
$\Omega\left(1/\varepsilon^{1/3}\right)$ lower bound, to a
$\log(1/\varepsilon)$ factor.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Parameterized algorithms for Eccentricity Shortest Path Problem</title>
    <link href="http://arxiv.org/abs/2304.03233"/>
    <id>http://arxiv.org/abs/2304.03233</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhyravarapu_S/0/1/0/all/0/1&quot;&gt;Sriram Bhyravarapu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jana_S/0/1/0/all/0/1&quot;&gt;Satyabrata Jana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanesh_L/0/1/0/all/0/1&quot;&gt;Lawqueen Kanesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1&quot;&gt;Saket Saurabh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1&quot;&gt;Shaily Verma&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given an undirected graph $G=(V,E)$ and an integer $\ell$, the Eccentricity
Shortest Path (ESP) asks to find a shortest path $P$ such that for every vertex
$v\in V(G)$, there is a vertex $w\in P$ such that $d_G(v,w)\leq \ell$, where
$d_G(v,w)$ represents the distance between $v$ and $w$ in $G$. Dragan and
Leitert [Theor. Comput. Sci. 2017] showed that the optimization version of this
problem, which asks to find the minimum $\ell$ for the ESP problem, is NP-hard
even on planar bipartite graphs with maximum degree 3. They also showed that
ESP is W[2]-hard when parameterized by $\ell$. On the positive side, Ku\v cera
and Such\&#39;y [IWOCA 2021] showed that the problem exhibits fixed parameter
tractable (FPT) behavior when parameterized by modular width, cluster vertex
deletion set, maximum leaf number, or the combined parameters disjoint paths
deletion set and $\ell$. It was asked as an open question in the above paper,
if ESP is FPT parameterized by disjoint paths deletion set or feedback vertex
set. We answer these questions partially and obtain the following results: -
ESP is FPT when parameterized by disjoint paths deletion set, split vertex
deletion set or the combined parameters feedback vertex set and eccentricity of
the graph. - We design a $(1+\epsilon)$-factor FPT approximation algorithm when
parameterized by the feedback vertex set number. - ESP is W[2]-hard when
parameterized by the chordal vertex deletion set.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: PhD / Postdoc at Goethe University Frankfurt, Germany (apply by June 16, 2023)</title>
    <link href="https://cstheory-jobs.org/2023/04/06/phd-postdoc-at-goethe-university-frankfurt-germany-apply-by-june-16-2023/"/>
    <id>http://cstheory-jobs.org/2023/04/06/phd-postdoc-at-goethe-university-frankfurt-germany-apply-by-june-16-2023/</id>
    <updated>2023-04-06T09:13:46+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Fully-funded PhD or Postdoc position in “Parameterized Complexity of Network Dynamics” to be carried out under the supervision of Prof. Holger Dell. The 3-year research project at the intersection of parameterized complexity, statistical physics, and graph theory involves the rigorous analysis of dynamic processes on graphs, such as virus or fake news spreading through a social network.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://tcs.uni-frankfurt.de/positions/&quot;&gt;https://tcs.uni-frankfurt.de/positions/&lt;/a&gt;&lt;br /&gt;
Email: tcs-applications@dlist.uni-frankfurt.de&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Richard Lipton: Neil Jones, 1941–2023</title>
    <link href="https://rjlipton.wpcomstaging.com/2023/04/06/neil-jones-1941-2023/"/>
    <id>https://rjlipton.wpcomstaging.com/?p=21402</id>
    <updated>2023-04-06T04:03:23+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;
Neil Jones, sad to relate, just passed away. He was Professor Emeritus of Computer Science at the University of Copenhagen, which he joined on a permanent basis in 1982 after gaining tenure at Penn State and a full professorship at the University of Kansas. &lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/04/06/neil-jones-1941-2023/neil-d-jones-60-aar/&quot; rel=&quot;attachment wp-att-21404&quot;&gt;&lt;img data-attachment-id=&quot;21404&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/04/06/neil-jones-1941-2023/neil-d-jones-60-aar/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?fit=1312%2C2000&amp;amp;ssl=1&quot; data-orig-size=&quot;1312,2000&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;JENS ASTRUP&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;NEIL D. JONES FRA DATALOGISK INSTITUT I KBH\r\rBILLEDET KAN FRIT ANVENDES TIL OMTALE AF HANS 60 AARS  DAG&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;NEIL D. JONES 60 AAR&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;1&amp;quot;}&quot; data-image-title=&quot;NEIL D. JONES 60 AAR&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&amp;lt;p&amp;gt;NEIL D. JONES FRA DATALOGISK INSTITUT I KBH&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;BILLEDET KAN FRIT ANVENDES TIL OMTALE AF HANS 60 AARS  DAG&amp;lt;/p&amp;gt;
&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?fit=197%2C300&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?fit=600%2C914&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=200%2C305&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;200&quot; height=&quot;305&quot; class=&quot;aligncenter wp-image-21404&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=672%2C1024&amp;amp;ssl=1 672w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=197%2C300&amp;amp;ssl=1 197w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=768%2C1171&amp;amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=1008%2C1536&amp;amp;ssl=1 1008w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=1200%2C1829&amp;amp;ssl=1 1200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?w=1312&amp;amp;ssl=1 1312w&quot; sizes=&quot;(max-width: 200px) 100vw, 200px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
Eric Allender wrote a &lt;a href=&quot;https://blog.computationalcomplexity.org&quot;&gt;post&lt;/a&gt; on Neil for Lance Fortnow&amp;#8217;s and Bill Gasarch&amp;#8217;s famous blog. We point to it, hopefully with their full approval, and add some supplementary remarks. Eric&amp;#8217;s tribute leads with Jones&amp;#8217;s work with Alan Selman characterizing logical spectra via languages in nondeterministic &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28n%29%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{2^{O(n)}}&quot; class=&quot;latex&quot; /&gt; time. He quotes remarks by D. Sivakumar that echo what Siva wrote for our &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2021/01/29/alan-selman-1941-2021/&quot;&gt;memorial&lt;/a&gt; to Alan.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; The Space Problem &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Steve Cook and Dick Karp started the quest to understand &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{P = NP}}&quot; class=&quot;latex&quot; /&gt;? What many including Neil have always considered the &amp;#8220;second big problem&amp;#8221; involves the power of space rather than nondeterminism, specifically: is &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BLOGSPACE+%3D+PTIME%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{LOGSPACE = PTIME}}&quot; class=&quot;latex&quot; /&gt;? Neil, like the rest of us, had his thoughts on the conjecture that they are different, but like the rest of us, did not know for sure. His thoughts on the subject ranged from &lt;a href=&quot;https://dblp.uni-trier.de/rec/journals/jcss/Jones75.html&quot;&gt;two&lt;/a&gt; early &lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/800119.803883&quot;&gt;papers&lt;/a&gt; to the last &lt;a href=&quot;https://arxiv.org/pdf/2008.02932.pdf&quot;&gt;paper&lt;/a&gt; on his DBLP page. &lt;/p&gt;
&lt;p&gt;
This last paper is joint with Siddharth Bhaskar, Cynthia Kop, and Jakob Simonsen, and is titled, &amp;#8220;Cons-free Programs and Complexity Classes between LOGSPACE and PTIME.&amp;#8221; It appeared at the 2020 joint meeting of the Horn Clauses for Verification and Synthesis (HCVS) and Verification and Program Transformation (VPT) workshops. They call a program &amp;#8220;cons-free&amp;#8221; if it does not allow agglutination of data, not by &lt;FONT SIZE=&quot;+1&quot;&gt;&lt;tt&gt;cons&lt;/tt&gt;&lt;/FONT&gt; with lists, nor successor, +, or * with integers, nor any allocator of storage. They further consider constraining recursion so as not to mushroom by mandating certain forms of tail recursion. Problems decided by cons-free programs form the class &amp;#8220;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BCF%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{CF}}&quot; class=&quot;latex&quot; /&gt;&amp;#8221; and those further having only tail recursion, &amp;#8220;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BCFTR%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{CFTR}}&quot; class=&quot;latex&quot; /&gt;.&amp;#8221;&lt;/p&gt;
&lt;p&gt;
This use of functional languages represents both a more modern viewpoint&amp;#8212;than how complexity was founded on Turing machines in the 1960s&amp;#8212;and an older one, insofar as Lisp and other ideas of functional languages were fertile before the 1960s. They characterize &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+CF%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{P = CF}}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BLOGSPACE+%3D+CFTR%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{LOGSPACE = CFTR}}&quot; class=&quot;latex&quot; /&gt; as their form also constraining recursion. The former holds some surprise as the cons-free programs are allowed to run for exponential time. If they are constrained to run in polynomial time, a class intermediate between &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BLOGSPACE%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{LOGSPACE}}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{P}}&quot; class=&quot;latex&quot; /&gt; emerges. Is it equivalent to a known class? They leave that open.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Non-Turing Time &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Jones&amp;#8217;s work on other models besides Turing machines caught my attention 30 years ago&amp;#8212;this is Ken writing this section. I was interested in models that have a constant-factor time overhead for universal simulation &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BU%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{U}&quot; class=&quot;latex&quot; /&gt; of any other machine &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M}&quot; class=&quot;latex&quot; /&gt;, in contrast to the standard multitape Turing machine model where &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BU%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{U}&quot; class=&quot;latex&quot; /&gt; incurs an &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+t%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{O(&amp;#92;log t)}&quot; class=&quot;latex&quot; /&gt; time overhead for simulating &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{t}&quot; class=&quot;latex&quot; /&gt; steps of machines &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M}&quot; class=&quot;latex&quot; /&gt; with more tapes than &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BU%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{U}&quot; class=&quot;latex&quot; /&gt; has. This &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Clog+t%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;log t}&quot; class=&quot;latex&quot; /&gt; factor also shows up in the deterministic time hierarchy theorem, though for natural instances it can be shaved down to &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+t%29%5E%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{O(&amp;#92;log t)^&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt; for any fixed &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt; by techniques of &lt;em&gt;padding and translation&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;
Martin F&amp;uuml;rer had &lt;a href=&quot;https://dl.acm.org/doi/10.1145/800070.802172&quot;&gt;shown&lt;/a&gt; that when &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k}&quot; class=&quot;latex&quot; /&gt; is fixed, the log factor goes away. I was interested in leveraging random-access models that have constant-factor overhead while imposing locality restrictions on the random access. The resulting time hierarchy theorems are only &amp;#8220;tight&amp;#8221; in the sense of needing &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bt_1%28n%29+%3D+o%28t_2%28n%29%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{t_1(n) = o(t_2(n))}&quot; class=&quot;latex&quot; /&gt;&amp;#8212;in order to construct a language decidable in time &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bt_2%28n%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{t_2(n)}&quot; class=&quot;latex&quot; /&gt; but not in time &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BO%28t_1%28n%29%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{O(t_1(n))}&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;
Jones went this one better by building a natural programming-based model that has a time hierarchy for a &lt;em&gt;fixed&lt;/em&gt; constant factor. His STOC 1993 &lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/167088.167244&quot;&gt;paper&lt;/a&gt; was titled, &amp;#8220;Constant Time Factors &lt;em&gt;Do&lt;/em&gt; Matter&amp;#8221; with italics on the &lt;em&gt;Do&lt;/em&gt;. This grew into a &lt;a href=&quot;https://link.springer.com/article/10.1007/s002360000038&quot;&gt;paper&lt;/a&gt; in &lt;em&gt;Acta Informatica&lt;/em&gt; 2000 with Amir Ben-Amram. It also became the basis for his 1997 &lt;a href=&quot;https://www.amazon.com/Computability-Complexity-Programming-Perspective-Foundations/dp/0262100649&quot;&gt;textbook&lt;/a&gt;, &lt;em&gt;Computability and Complexity: From a Programming Perspective&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;
The prominence of &amp;#8220;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{P = NP}}&quot; class=&quot;latex&quot; /&gt;?&amp;#8221; masks that our lack of knowledge of lower bounds takes effect at linear time. For circuit models the status is even worse: we still have not refuted the possibility that every language in deterministic &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28n%29%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{2^{O(n)}}&quot; class=&quot;latex&quot; /&gt; time has (possibly nonuniform) &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BO%28n%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{O(n)}&quot; class=&quot;latex&quot; /&gt;-sized circuits. I thought that a new kind of super-linear lower bound could get a grip on peeling the end of a coiled tape that might then freely unroll. As with &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{P}}&quot; class=&quot;latex&quot; /&gt; versus &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BLOGSPACE%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{LOGSPACE}}&quot; class=&quot;latex&quot; /&gt;, however, getting such a grip remains open.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Open Problems &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
I&amp;#8212;Dick again&amp;#8212;worked on related stuff in a 1979 &lt;a href=&quot;https://www2.eecs.berkeley.edu/Pubs/TechRpts/1979/ERL-m-79-54.pdf&quot;&gt;paper&lt;/a&gt; that had a cast of famous brilliant scholars: &amp;#8220;Random Walks, Universal Traversal Sequences, and the Complexity of Maze Problems&amp;#8221;&amp;#8212;by Romas Aleliunas, Dick Karp, me, Laci Lovasz, and Charlie Rackoff. There were ways to build off this to greater results, particularly Omer Reingold&amp;#8217;s blending-in of Irit Dinur&amp;#8217;s PCP proof technique to &lt;a href=&quot;https://omereingold.files.wordpress.com/2014/10/sl.pdf&quot;&gt;show&lt;/a&gt; that undirected maze problems belong to deterministic logspace. Is there a way to build more off Neil&amp;#8217;s results&amp;#8212;the newer and the older ones?&lt;/p&gt;
&lt;p&gt;
&lt;p class=&quot;authors&quot;&gt;By RJLipton+KWRegan&lt;/p&gt;
  </content>
    <author>
      <name>Richard Lipton</name>
      <uri>https://rjlipton.wpcomstaging.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Visualizing Quantum Circuit Probability -- estimating computational action for quantum program synthesis</title>
    <link href="http://arxiv.org/abs/2304.02358"/>
    <id>http://arxiv.org/abs/2304.02358</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Bach_B/0/1/0/all/0/1&quot;&gt;Bao Gia Bach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kundu_A/0/1/0/all/0/1&quot;&gt;Akash Kundu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Acharya_T/0/1/0/all/0/1&quot;&gt;Tamal Acharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sarkar_A/0/1/0/all/0/1&quot;&gt;Aritra Sarkar&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This research applies concepts from algorithmic probability to Boolean and
quantum combinatorial logic circuits. A tutorial-style introduction to states
and various notions of the complexity of states are presented. Thereafter, the
probability of states in the circuit model of computation is defined. Classical
and quantum gate sets are compared to select some characteristic sets. The
reachability and expressibility in a space-time-bounded setting for these gate
sets are enumerated and visualized. These results are studied in terms of
computational resources, universality and quantum behavior. The article
suggests how applications like geometric quantum machine learning, novel
quantum algorithm synthesis and quantum artificial general intelligence can
benefit by studying circuit probabilities.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Picturing counting reductions with the ZH-calculus</title>
    <link href="http://arxiv.org/abs/2304.02524"/>
    <id>http://arxiv.org/abs/2304.02524</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laakkonen_T/0/1/0/all/0/1&quot;&gt;Tuomas Laakkonen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meichanetzidis_K/0/1/0/all/0/1&quot;&gt;Konstantinos Meichanetzidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wetering_J/0/1/0/all/0/1&quot;&gt;John van de Wetering&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Counting the solutions to Boolean formulae defines the problem #SAT, which is
complete for the complexity class #P. We use the ZH-calculus, a universal and
complete graphical language for linear maps which naturally encodes counting
problems in terms of diagrams, to give graphical reductions from #SAT to
several related counting problems. Some of these graphical reductions, like to
#2SAT, are substantially simpler than known reductions via the matrix
permanent. Additionally, our approach allows us to consider the case of
counting solutions modulo an integer on equal footing. Finally, since the
ZH-calculus was originally introduced to reason about quantum computing, we
show that the problem of evaluating ZH-diagrams in the fragment corresponding
to the Clifford+T gateset, is in $FP^{\#P}$. Our results show that graphical
calculi represent an intuitive and useful framework for reasoning about
counting problems.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Top-Down Lower Bounds for Depth-Four Circuits</title>
    <link href="http://arxiv.org/abs/2304.02555"/>
    <id>http://arxiv.org/abs/2304.02555</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goos_M/0/1/0/all/0/1&quot;&gt;Mika G&amp;#xf6;&amp;#xf6;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riazanov_A/0/1/0/all/0/1&quot;&gt;Artur Riazanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sofronova_A/0/1/0/all/0/1&quot;&gt;Anastasia Sofronova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sokolov_D/0/1/0/all/0/1&quot;&gt;Dmitry Sokolov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present a top-down lower-bound method for depth-$4$ boolean circuits. In
particular, we give a new proof of the well-known result that the parity
function requires depth-$4$ circuits of size exponential in $n^{1/3}$. Our
proof is an application of robust sunflowers and block unpredictability.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Algorithm and Hardness for Dynamic Attention Maintenance in Large Language Models</title>
    <link href="http://arxiv.org/abs/2304.02207"/>
    <id>http://arxiv.org/abs/2304.02207</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brand_J/0/1/0/all/0/1&quot;&gt;Jan van den Brand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1&quot;&gt;Tianyi Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Large language models (LLMs) have made fundamental changes in human life. The
attention scheme is one of the key components over all the LLMs, such as BERT,
GPT-1, Transformers, GPT-2, 3, 3.5 and 4. Inspired by previous theoretical
study of static version of the attention multiplication problem [Zandieh, Han,
Daliri, and Karbasi arXiv 2023, Alman and Song arXiv 2023]. In this work, we
formally define a dynamic version of attention matrix multiplication problem.
There are matrices $Q,K, V \in \mathbb{R}^{n \times d}$, they represent query,
key and value in LLMs. In each iteration we update one entry in $K$ or $V$. In
the query stage, we receive $(i,j) \in [n] \times [d]$ as input, and want to
answer $(D^{-1} A V)_{i,j}$, where $A:=\exp(QK^\top) \in \mathbb{R}^{n \times
n}$ is a square matrix and $D := \mathrm{diag}(A {\bf 1}_n) \in \mathbb{R}^{n
\times n}$ is a diagonal matrix. Here ${\bf 1}_n$ denote a length-$n$ vector
that all the entries are ones.
&lt;/p&gt;
&lt;p&gt;We provide two results: an algorithm and a conditional lower bound.
&lt;/p&gt;
&lt;p&gt;$\bullet$ On one hand, inspired by the lazy update idea from [Demetrescu and
Italiano FOCS 2000, Sankowski FOCS 2004, Cohen, Lee and Song STOC 2019, Brand
SODA 2020], we provide a data-structure that uses
$O(n^{\omega(1,1,\tau)-\tau})$ amortized update time, and $O(n^{1+\tau})$
worst-case query time.
&lt;/p&gt;
&lt;p&gt;$\bullet$ On the other hand, show that unless the hinted matrix vector
multiplication conjecture [Brand, Nanongkai and Saranurak FOCS 2019] is false,
there is no algorithm that can use both $O(n^{\omega(1,1,\tau) - \tau-
\Omega(1)})$ amortized update time, and $O(n^{1+\tau-\Omega(1)})$ worst query
time.
&lt;/p&gt;
&lt;p&gt;In conclusion, our algorithmic result is conditionally optimal unless hinted
matrix vector multiplication conjecture is false.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Set Covering with Our Eyes Wide Shut</title>
    <link href="http://arxiv.org/abs/2304.02063"/>
    <id>http://arxiv.org/abs/2304.02063</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Anupam Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kehne_G/0/1/0/all/0/1&quot;&gt;Gregory Kehne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levin_R/0/1/0/all/0/1&quot;&gt;Roie Levin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the stochastic set cover problem (Grandoni et al., FOCS &#39;08), we are given
a collection $\mathcal{S}$ of $m$ sets over a universe $\mathcal{U}$ of size
$N$, and a distribution $D$ over elements of $\mathcal{U}$. The algorithm draws
$n$ elements one-by-one from $D$ and must buy a set to cover each element on
arrival; the goal is to minimize the total cost of sets bought during this
process. A universal algorithm a priori maps each element $u \in \mathcal{U}$
to a set $S(u)$ such that if $U \subseteq \mathcal{U}$ is formed by drawing $n$
times from distribution $D$, then the algorithm commits to outputting $S(U)$.
Grandoni et al. gave an $O(\log mN)$-competitive universal algorithm for this
stochastic set cover problem.
&lt;/p&gt;
&lt;p&gt;We improve unilaterally upon this result by giving a simple, polynomial time
$O(\log mn)$-competitive universal algorithm for the more general prophet
version, in which $U$ is formed by drawing from $n$ different distributions
$D_1, \ldots, D_n$. Furthermore, we show that we do not need full foreknowledge
of the distributions: in fact, a single sample from each distribution suffices.
We show similar results for the 2-stage prophet setting and for the
online-with-a-sample setting.
&lt;/p&gt;
&lt;p&gt;We obtain our results via a generic reduction from the single-sample prophet
setting to the random-order setting; this reduction holds for a broad class of
minimization problems that includes all covering problems. We take advantage of
this framework by giving random-order algorithms for non-metric facility
location and set multicover; using our framework, these automatically translate
to universal prophet algorithms.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Determinantal Sieving</title>
    <link href="http://arxiv.org/abs/2304.02091"/>
    <id>http://arxiv.org/abs/2304.02091</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eiben_E/0/1/0/all/0/1&quot;&gt;Eduard Eiben&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koana_T/0/1/0/all/0/1&quot;&gt;Tomohiro Koana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wahlstrom_M/0/1/0/all/0/1&quot;&gt;Magnus Wahlstr&amp;#xf6;m&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce determinantal sieving, a new, remarkably powerful tool in the
toolbox of algebraic FPT algorithms. Given a polynomial $P(X)$ on a set of
variables $X=\{x_1,\ldots,x_n\}$ and a linear matroid $M=(X,\mathcal{I})$ of
rank $k$, both over a field $\mathbb{F}$ of characteristic 2, in $2^k$
evaluations we can sieve for those terms in the monomial expansion of $P$ which
are multilinear and whose support is a basis for $M$. Alternatively, using
$2^k$ evaluations of $P$ we can sieve for those monomials whose odd support
spans $M$. Applying this framework, we improve on a range of algebraic FPT
algorithms, such as:
&lt;/p&gt;
&lt;p&gt;1. Solving $q$-Matroid Intersection in time $O^*(2^{(q-2)k})$ and $q$-Matroid
Parity in time $O^*(2^{qk})$, improving on $O^*(4^{qk})$ (Brand and Pratt,
ICALP 2021)
&lt;/p&gt;
&lt;p&gt;2. $T$-Cycle, Colourful $(s,t)$-Path, Colourful $(S,T)$-Linkage in undirected
graphs, and the more general Rank $k$ $(S,T)$-Linkage problem, all in
$O^*(2^k)$ time, improving on $O^*(2^{k+|S|})$ respectively $O^*(2^{|S|+O(k^2
\log(k+|\mathbb{F}|))})$ (Fomin et al., SODA 2023)
&lt;/p&gt;
&lt;p&gt;3. Many instances of the Diverse X paradigm, finding a collection of $r$
solutions to a problem with a minimum mutual distance of $d$ in time
$O^*(2^{r(r-1)d/2})$, improving solutions for $k$-Distinct Branchings from time
$2^{O(k \log k)}$ to $O^*(2^k)$ (Bang-Jensen et al., ESA 2021), and for Diverse
Perfect Matchings from $O^*(2^{2^{O(rd)}})$ to $O^*(2^{r^2d/2})$ (Fomin et al.,
STACS 2021)
&lt;/p&gt;
&lt;p&gt;All matroids are assumed to be represented over a field of characteristic 2.
Over general fields, we achieve similar results at the cost of using
exponential space by working over the exterior algebra. For a class of
arithmetic circuits we call strongly monotone, this is even achieved without
any loss of running time. However, the odd support sieving result appears to be
specific to working over characteristic 2.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: The Bit Complexity of Efficient Continuous Optimization</title>
    <link href="http://arxiv.org/abs/2304.02124"/>
    <id>http://arxiv.org/abs/2304.02124</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghadiri_M/0/1/0/all/0/1&quot;&gt;Mehrdad Ghadiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_R/0/1/0/all/0/1&quot;&gt;Richard Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1&quot;&gt;Santosh S. Vempala&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We analyze the bit complexity of efficient algorithms for fundamental
optimization problems, such as linear regression, $p$-norm regression, and
linear programming (LP). State-of-the-art algorithms are iterative, and in
terms of the number of arithmetic operations, they match the current time
complexity of multiplying two $n$-by-$n$ matrices (up to polylogarithmic
factors). However, previous work has typically assumed infinite precision
arithmetic, and due to complicated inverse maintenance techniques, the actual
running times of these algorithms are unknown. To settle the running time and
bit complexity of these algorithms, we demonstrate that a core common
subroutine, known as \emph{inverse maintenance}, is backward-stable.
Additionally, we show that iterative approaches for solving constrained
weighted regression problems can be accomplished with bounded-error
pre-conditioners. Specifically, we prove that linear programs can be solved
approximately in matrix multiplication time multiplied by polylog factors that
depend on the condition number $\kappa$ of the matrix and the inner and outer
radius of the LP problem. $p$-norm regression can be solved approximately in
matrix multiplication time multiplied by polylog factors in $\kappa$. Lastly,
linear regression can be solved approximately in input-sparsity time multiplied
by polylog factors in $\kappa$. Furthermore, we present results for achieving
lower than matrix multiplication time for $p$-norm regression by utilizing
faster solvers for sparse linear systems.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Sequential Linearithmic Time Optimal Unimodal Fitting When Minimizing Univariate Linear Losses</title>
    <link href="http://arxiv.org/abs/2304.02141"/>
    <id>http://arxiv.org/abs/2304.02141</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gokcesu_K/0/1/0/all/0/1&quot;&gt;Kaan Gokcesu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gokcesu_H/0/1/0/all/0/1&quot;&gt;Hakan Gokcesu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper focuses on optimal unimodal transformation of the score outputs of
a univariate learning model under linear loss functions. We demonstrate that
the optimal mapping between score values and the target region is a rectangular
function. To produce this optimal rectangular fit for the observed samples, we
propose a sequential approach that can its estimation with each incoming new
sample. Our approach has logarithmic time complexity per iteration and is
optimally efficient.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Folklore Sampling is Optimal for Exact Hopsets: Confirming the $\sqrt{n}$ Barrier</title>
    <link href="http://arxiv.org/abs/2304.02193"/>
    <id>http://arxiv.org/abs/2304.02193</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bodwin_G/0/1/0/all/0/1&quot;&gt;Greg Bodwin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoppenworth_G/0/1/0/all/0/1&quot;&gt;Gary Hoppenworth&lt;/a&gt;&lt;/p&gt;&lt;p&gt;For a graph $G$, a $D$-diameter-reducing exact hopset is a small set of
additional edges $H$ that, when added to $G$, maintains its graph metric but
guarantees that all node pairs have a shortest path in $G \cup H$ using at most
$D$ edges. A shortcut set is the analogous concept for reachability. These
objects have been studied since the early &#39;90s due to applications in parallel,
distributed, dynamic, and streaming graph algorithms.
&lt;/p&gt;
&lt;p&gt;For most of their history, the state-of-the-art construction for either
object was a simple folklore algorithm, based on randomly sampling nodes to hit
long paths in the graph. However, recent breakthroughs of Kogan and Parter
[SODA &#39;22] and Bernstein and Wein [SODA &#39;23] have finally improved over the
folklore diameter bound of $\widetilde{O}(n^{1/2})$ for shortcut sets and for
$(1+\epsilon)$-approximate hopsets. For both objects it is now known that one
can use $O(n)$ hop-edges to reduce diameter to $\widetilde{O}(n^{1/3})$. The
only setting where folklore sampling remains unimproved is for exact hopsets.
Can these improvements be continued?
&lt;/p&gt;
&lt;p&gt;We settle this question negatively by constructing graphs on which any exact
hopset of $O(n)$ edges has diameter $\widetilde{\Omega}(n^{1/2})$. This
improves on the previous lower bound of $\widetilde{\Omega}(n^{1/3})$ by Kogan
and Parter [FOCS &#39;22]. Using similar ideas, we also polynomially improve the
current lower bounds for shortcut sets, constructing graphs on which any
shortcut set of $O(n)$ edges reduces diameter to $\widetilde{\Omega}(n^{1/4})$.
This improves on the previous lower bound of $\Omega(n^{1/6})$ by Huang and
Pettie [SIAM J. Disc. Math. &#39;18]. We also extend our constructions to provide
lower bounds against $O(p)$-size exact hopsets and shortcut sets for other
values of $p$; in particular, we show that folklore sampling is near-optimal
for exact hopsets in the entire range of $p \in [1, n^2]$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Optimal Sketching Bounds for Sparse Linear Regression</title>
    <link href="http://arxiv.org/abs/2304.02261"/>
    <id>http://arxiv.org/abs/2304.02261</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1&quot;&gt;Tung Mai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munteanu_A/0/1/0/all/0/1&quot;&gt;Alexander Munteanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1&quot;&gt;Cameron Musco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1&quot;&gt;Anup B. Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwiegelshohn_C/0/1/0/all/0/1&quot;&gt;Chris Schwiegelshohn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1&quot;&gt;David P. Woodruff&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study oblivious sketching for $k$-sparse linear regression under various
loss functions such as an $\ell_p$ norm, or from a broad class of hinge-like
loss functions, which includes the logistic and ReLU losses. We show that for
sparse $\ell_2$ norm regression, there is a distribution over oblivious
sketches with $\Theta(k\log(d/k)/\varepsilon^2)$ rows, which is tight up to a
constant factor. This extends to $\ell_p$ loss with an additional additive
$O(k\log(k/\varepsilon)/\varepsilon^2)$ term in the upper bound. This
establishes a surprising separation from the related sparse recovery problem,
which is an important special case of sparse regression. For this problem,
under the $\ell_2$ norm, we observe an upper bound of $O(k \log (d)/\varepsilon
+ k\log(k/\varepsilon)/\varepsilon^2)$ rows, showing that sparse recovery is
strictly easier to sketch than sparse regression. For sparse regression under
hinge-like loss functions including sparse logistic and sparse ReLU regression,
we give the first known sketching bounds that achieve $o(d)$ rows showing that
$O(\mu^2 k\log(\mu n d/\varepsilon)/\varepsilon^2)$ rows suffice, where $\mu$
is a natural complexity parameter needed to obtain relative error bounds for
these loss functions. We again show that this dimension is tight, up to lower
order terms and the dependence on $\mu$. Finally, we show that similar
sketching bounds can be achieved for LASSO regression, a popular convex
relaxation of sparse regression, where one aims to minimize
$\|Ax-b\|_2^2+\lambda\|x\|_1$ over $x\in\mathbb{R}^d$. We show that sketching
dimension $O(\log(d)/(\lambda \varepsilon)^2)$ suffices and that the dependence
on $d$ and $\lambda$ is tight.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: The Laplacian Paradigm in Deterministic Congested Clique</title>
    <link href="http://arxiv.org/abs/2304.02315"/>
    <id>http://arxiv.org/abs/2304.02315</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Forster_S/0/1/0/all/0/1&quot;&gt;Sebatian Forster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vos_T/0/1/0/all/0/1&quot;&gt;Tijn de Vos&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we bring the techniques of the Laplacian paradigm to the
congested clique, while further restricting ourselves to deterministic
algorithms. In particular, we show how to solve a Laplacian system up to
precision $\epsilon$ in $n^{o(1)}\log(1/\epsilon)$ rounds. We show how to
leverage this result within existing interior point methods for solving flow
problems. We obtain an $m^{3/7+o(1)}U^{1/7}$ round algorithm for maximum flow
on a weighted directed graph with maximum weight $U$, and we obtain an
$\tilde{O}(m^{3/7}(n^{0.158}+n^{o(1)}\text{poly}\log W))$ round algorithm for
unit capacity minimum cost flow on a directed graph with maximum cost $W$.
Hereto, we give a novel routine for computing Eulerian orientations in $O(\log
n \log^* n)$ rounds, which we believe may be of separate interest.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On the Power of Threshold-Based Algorithms for Detecting Cycles in the CONGEST Model</title>
    <link href="http://arxiv.org/abs/2304.02360"/>
    <id>http://arxiv.org/abs/2304.02360</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fraigniaud_P/0/1/0/all/0/1&quot;&gt;Pierre Fraigniaud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luce_M/0/1/0/all/0/1&quot;&gt;Ma&amp;#xeb;l Luce&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Todinca_I/0/1/0/all/0/1&quot;&gt;Ioan Todinca&lt;/a&gt;&lt;/p&gt;&lt;p&gt;It is known that, for every $k\geq 2$, $C_{2k}$-freeness can be decided by a
generic Monte-Carlo algorithm running in $n^{1-1/\Theta(k^2)}$ rounds in the
CONGEST model. For $2\leq k\leq 5$, faster Monte-Carlo algorithms do exist,
running in $O(n^{1-1/k})$ rounds, based on upper bounding the number of
messages to be forwarded, and aborting search sub-routines for which this
number exceeds certain thresholds. We investigate the possible extension of
these threshold-based algorithms, for the detection of larger cycles. We first
show that, for every $k\geq 6$, there exists an infinite family of graphs
containing a $2k$-cycle for which any threshold-based algorithm fails to detect
that cycle. Hence, in particular, neither $C_{12}$-freeness nor
$C_{14}$-freeness can be decided by threshold-based algorithms. Nevertheless,
we show that $\{C_{12},C_{14}\}$-freeness can still be decided by a
threshold-based algorithm, running in $O(n^{1-1/7})= O(n^{0.857\dots})$ rounds,
which is faster than using the generic algorithm, which would run in
$O(n^{1-1/22})\simeq O(n^{0.954\dots})$ rounds. Moreover, we exhibit an
infinite collection of families of cycles such that threshold-based algorithms
can decide $\mathcal{F}$-freeness for every $\mathcal{F}$ in this collection.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improved Analysis of two Algorithms for Min-Weighted Sum Bin Packing</title>
    <link href="http://arxiv.org/abs/2304.02498"/>
    <id>http://arxiv.org/abs/2304.02498</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sagnol_G/0/1/0/all/0/1&quot;&gt;Guillaume Sagnol&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the Min-Weighted Sum Bin Packing problem, a variant of the classical
Bin Packing problem in which items have a weight, and each item induces a cost
equal to its weight multiplied by the index of the bin in which it is packed.
This is in fact equivalent to a batch scheduling problem that arises in many
fields of applications such as appointment scheduling or warehouse logistics.
We give improved lower and upper bounds on the approximation ratio of two
simple algorithms for this problem. In particular, we show that the
knapsack-batching algorithm, which iteratively solves knapsack problems over
the set of remaining items to pack the maximal weight in the current bin, has
an approximation ratio of at most 17/10.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


</feed>
