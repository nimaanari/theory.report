<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Theory of Computing Report</title>
  <link rel="self" href=""/>
  <link href=""/>
  <id></id>
  <updated></updated>
  <generator uri="http://feedreader.github.io/">Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]</generator>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: Complexity and Explainable AI</title>
    <link href="https://blog.computationalcomplexity.org/2023/04/complexity-and-generative-ai.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-8698511952609437812</id>
    <updated>2023-04-10T17:37:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;About six years ago, I &lt;a href=&quot;https://blog.computationalcomplexity.org/2017/04/understanding-machine-learning.html&quot;&gt;posted&lt;/a&gt;&amp;nbsp;on why it was important to understand machine learning, mentioning trust, fairness, security and causality. But I then I brought in complexity.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;What if P = NP? Would that help. Actually it would makes things worse. If you had a quick algorithm for NP-complete problems, you could use it to find the smallest possible circuit for say matching or traveling salesman but you would have no clue why that circuit works.&amp;nbsp;&lt;/blockquote&gt;&lt;p&gt;Ryan Williams &lt;a href=&quot;https://blog.computationalcomplexity.org/2017/04/understanding-machine-learning.html?showComment=1492464695392#c7595821335622802218&quot;&gt;countered&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;If P=NP you could also find the shortest proof in your favorite formal system that the smallest possible circuit does what you wanted it to do, as well as any other claim you are wondering that may be true about the circuit. That proof might not be comprehensible to you, but it could be written in a format where proof assistant software such as HOL or Coq could parse it and convince you it is correct. So if P=NP (with feasible low constants) I think that would definitely help.&lt;/blockquote&gt;&lt;p&gt;So if P = NP maybe you couldn&#39;t understand how the circuit works but any question about how it works you could answer.&amp;nbsp;&lt;/p&gt;&lt;p&gt;While we don&#39;t live in a world where P = NP, we are in a world where we can produce very strong learning algorithms where we can&#39;t understand the programs they produce. They are now powerful enough to apply Ryan&#39;s idea and use the algorithms themselves to understand the decisions they make.&lt;/p&gt;&lt;p&gt;For example I tried using Google Translate on a &lt;a href=&quot;https://mta.hu/mta_hirei/elhunyt-t-sos-vera-matematikus-az-mta-rendes-tagja-112809&quot;&gt;Hungarian obituary&lt;/a&gt; of Vera&amp;nbsp;Sós. Hungarian does not use gendered pronouns and and the translation incorrectly produced male pronouns. I then fed the translation into ChatGPT which translated with the correct female pronouns.&amp;nbsp;&lt;/p&gt;&lt;p&gt;You can speculate why Google Translate uses male pronouns but you can&#39;t ask it why. But you can ask ChatGPT.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;I used female pronouns in the translation because Vera T. Sós is a female name. Vera is a feminine given name, and since the context of the original text is about her life and accomplishments, it is appropriate to use female pronouns in the English translation to maintain clarity and accurately convey information about her.&lt;/blockquote&gt;&lt;p&gt;So perhaps if you want to understand how ML works, perhaps we should seek stronger algorithms, not weaker ones, algorithms that can explain themselves. As &lt;a href=&quot;https://knivesengraved.com/blogs/news/why-sharp-knives-are-safer-than-dull-knives&quot;&gt;they say&lt;/a&gt;, a dull knife is more dangerous than a sharp one.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Quantum delegation with an off-the-shelf device</title>
    <link href="http://arxiv.org/abs/2304.03448"/>
    <id>http://arxiv.org/abs/2304.03448</id>
    <updated>2023-04-10T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Broadbent_A/0/1/0/all/0/1&quot;&gt;Anne Broadbent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Mehta_A/0/1/0/all/0/1&quot;&gt;Arthur Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yuming Zhao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given that reliable cloud quantum computers are becoming closer to reality,
the concept of delegation of quantum computations and its verifiability is of
central interest. Many models have been proposed, each with specific strengths
and weaknesses. Here, we put forth a new model where the client trusts only its
classical processing, makes no computational assumptions, and interacts with a
quantum server in a single round. In addition, during a set-up phase, the
client specifies the size $n$ of the computation and receives an untrusted,
off-the-shelf (OTS) quantum device that is used to report the outcome of a
single constant-sized measurement from a predetermined logarithmic-sized input.
In the OTS model, we thus picture that a single quantum server does the bulk of
the computations, while the OTS device is used as an untrusted and generic
verification device, all in a single round.
&lt;/p&gt;
&lt;p&gt;We show how to delegate polynomial-time quantum computations in the OTS
model. Scaling up the technique also yields an interactive proof system for all
of QMA, which, furthermore, we show can be accomplished in statistical
zero-knowledge. This yields the first relativistic (one-round), two-prover
zero-knowledge proof system for QMA.
&lt;/p&gt;
&lt;p&gt;As a proof approach, we provide a new self-test for $n$-EPR pairs using only
constant-sized Pauli measurements, and show how it provides a new avenue for
the use of simulatable codes for local Hamiltonian verification. Along the way,
we also provide an enhanced version of a well-known stability result due to
Gowers and Hatami and show how it completes a common argument used in
self-testing.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Maximal Distortion of Geodesic Diameters in Polygonal Domains</title>
    <link href="http://arxiv.org/abs/2304.03484"/>
    <id>http://arxiv.org/abs/2304.03484</id>
    <updated>2023-04-10T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dumitrescu_A/0/1/0/all/0/1&quot;&gt;Adrian Dumitrescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toth_C/0/1/0/all/0/1&quot;&gt;Csaba D. T&amp;#xf3;th&lt;/a&gt;&lt;/p&gt;&lt;p&gt;For a polygon $P$ with holes in the plane, we denote by $\varrho(P)$ the
ratio between the geodesic and the Euclidean diameters of $P$. It is shown that
over all convex polygons with $h$~convex holes, the supremum of $\varrho(P)$ is
between $\Omega(h^{1/3})$ and $O(h^{1/2})$. The upper bound improves to
$O(1+\min\{h^{3/4}\Delta,h^{1/2}\Delta^{1/2}\})$ if every hole has diameter at
most $\Delta\cdot {\rm diam}_2(P)$; and to $O(1)$ if every hole is a \emph{fat}
convex polygon. Furthermore, we show that the function $g(h)=\sup_P \varrho(P)$
over convex polygons with $h$ convex holes has the same growth rate as an
analogous quantity over geometric triangulations with $h$ vertices when
$h\rightarrow \infty$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Leveraging Reusability: Improved Competitive Ratio of Greedy for Reusable Resources</title>
    <link href="http://arxiv.org/abs/2304.03377"/>
    <id>http://arxiv.org/abs/2304.03377</id>
    <updated>2023-04-10T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1&quot;&gt;Jackie Baek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shixin Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study online weighted bipartite matching of reusable resources where an
adversarial sequence of requests for resources arrive over time. A resource
that is matched is &#39;used&#39; for a random duration, drawn independently from a
resource-dependent distribution, after which it returns and is able to be
matched again. We study the performance of the greedy policy, which matches
requests to the resource that yields the highest reward. Previously, it was
known that the greedy policy is 1/2 competitive against a clairvoyant benchmark
that knows the request sequence in advance. In this work, we improve this
result by introducing a parameter that quantifies the degree of reusability of
the resources. Specifically, if p represents the smallest probability over the
usage distributions that a matched resource returns in one time step, the
greedy policy achieves a competitive ratio of $1/(2-p)$. Furthermore, when the
usage distributions are geometric, we establish a stronger competitive ratio of
$(1+p)/2$, which we demonstrate to be tight. Both of these results align with
the known results in the two extreme scenarios: p = 0 corresponds to
non-reusable resources, where 1/2 is known to be tight, while p = 1 corresponds
to every resource returning immediately, where greedy is the optimal policy and
hence the competitive ratio is 1. Finally, we show that both results are robust
to approximations of the greedy policy. Our work demonstrates that the
reusability of resources can enhance performance compared to the non-reusable
setting, and that a simple greedy policy suffices when the degree of
reusability is high. Our insights contribute to the understanding of how
resource reusability can influence the performance of online algorithms, and
highlight the potential for improved performance as the degree of reusability
increases.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Convex Minimization with Integer Minima in $\widetilde O(n^4)$ Time</title>
    <link href="http://arxiv.org/abs/2304.03426"/>
    <id>http://arxiv.org/abs/2304.03426</id>
    <updated>2023-04-10T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Haotian Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yin Tat Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lichen Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a convex function $f$ on $\mathbb{R}^n$ with an integer minimizer, we
show how to find an exact minimizer of $f$ using $O(n^2 \log n)$ calls to a
separation oracle and $O(n^4 \log n)$ time. The previous best polynomial time
algorithm for this problem given in [Jiang, SODA 2021, JACM 2022] achieves
$\widetilde{O}(n^2)$ oracle complexity. However, the overall runtime of Jiang&#39;s
algorithm is at least $\widetilde{\Omega}(n^8)$, due to expensive sub-routines
such as the Lenstra-Lenstra-Lov\&#39;asz (LLL) algorithm [Lenstra, Lenstra,
Lov\&#39;asz, Math. Ann. 1982] and random walk based cutting plane method
[Bertsimas, Vempala, JACM 2004]. Our significant speedup is obtained by a
nontrivial combination of a faster version of the LLL algorithm due to
[Neumaier, Stehl\&#39;e, ISSAC 2016] that gives similar guarantees, the volumetric
center cutting plane method (CPM) by [Vaidya, FOCS 1989] and its fast
implementation given in [Jiang, Lee, Song, Wong, STOC 2020].
&lt;/p&gt;
&lt;p&gt;For the special case of submodular function minimization (SFM), our result
implies a strongly polynomial time algorithm for this problem using $O(n^3 \log
n)$ calls to an evaluation oracle and $O(n^4 \log n)$ additional arithmetic
operations. Both the oracle complexity and the number of arithmetic operations
of our more general algorithm are better than the previous best-known runtime
algorithms for this specific problem given in [Lee, Sidford, Wong, FOCS 2015]
and [Dadush, V\&#39;egh, Zambelli, SODA 2018, MOR 2021].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Temporalizing digraphs via linear-size balanced bi-trees</title>
    <link href="http://arxiv.org/abs/2304.03567"/>
    <id>http://arxiv.org/abs/2304.03567</id>
    <updated>2023-04-10T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bessy_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Bessy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Thomasse_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phan Thomass&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Viennot_L/0/1/0/all/0/1&quot;&gt;Laurent Viennot&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a directed graph $D$ on vertex set $v_1,\dots ,v_n$, a \emph{forward arc}
is an arc $v_iv_j$ where $i&amp;lt;j$. A pair $v_i,v_j$ is \emph{forward connected} if
there is a directed path from $v_i$ to $v_j$ consisting of forward arcs. In the
{\tt Forward Connected Pairs Problem} ({\tt FCPP}), the input is a strongly
connected digraph $D$, and the output is the maximum number of forward
connected pairs in some vertex enumeration of $D$. We show that {\tt FCPP} is
in APX, as one can efficiently enumerate the vertices of $D$ in order to
achieve a quadratic number of forward connected pairs. For this, we construct a
linear size balanced bi-tree $T$ (an out-tree and an in-tree with same size
which roots are identified). The existence of such a $T$ was left as an open
problem motivated by the study of temporal paths in temporal networks. More
precisely, $T$ can be constructed in quadratic time (in the number of vertices)
and has size at least $n/3$. The algorithm involves a particular depth-first
search tree (Left-DFS) of independent interest, and shows that every strongly
connected directed graph has a balanced separator which is a circuit.
Remarkably, in the request version {\tt RFCPP} of {\tt FCPP}, where the input
is a strong digraph $D$ and a set of requests $R$ consisting of pairs
$\{x_i,y_i\}$, there is no constant $c&amp;gt;0$ such that one can always find an
enumeration realizing $c.|R|$ forward connected pairs $\{x_i,y_i\}$ (in either
direction).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR23-044 |  Separations between Combinatorial Measures for Transitive Functions | 

	Sourav Chakraborty, 

	Chandrima Kayal, 

	Manaswi Paraashar</title>
    <link href="https://eccc.weizmann.ac.il/report/2023/044"/>
    <id>https://eccc.weizmann.ac.il/report/2023/044</id>
    <updated>2023-04-09T11:26:00+00:00</updated>
    <content type="html" xml:lang="en">
    The role of symmetry in Boolean functions $f:\{0,1\}^n \to \{0,1\}$ has been extensively studied in complexity theory. 
For example, symmetric functions, that is, functions that are invariant under the action of $S_n$ is an important class of functions in the study of Boolean functions.
A function $f:\{0,1\}^n \to \{0,1\}$ is called transitive (or weakly-symmetric) if there exists a transitive group $G$ of $S_n$ such that $f$ is invariant under the action of $G$. In other words, the value of a transitive function remains unchanged even after the input bits of $f$ are moved around according to some permutation $\sigma \in G$. Understanding various complexity measures of transitive functions has been a rich area of research for the past few decades.



In this work, we study transitive functions in light of several combinatorial measures. The question that we try to address in this paper is what is the maximum separations between various pairs of combinatorial measures for transitive functions. Such study for general Boolean functions has been going on for the past many years. The current best-known results for general Boolean functions have been nicely compiled by Aaronson et~al.~(STOC, 2021). But before this paper, no such systematic study has been done for the case of transitive functions. 

 
The separation between a pair of combinatorial measures is shown by constructing interesting functions that demonstrate the separation. Over the past three decades, various interesting classes of functions have been designed for this purpose. In this context, one of the celebrated classes of functions is the class of ``pointer functions&amp;#39;&amp;#39;.
Ambainis et al.~(JACM, 2017) constructed several functions, which are modifications of the pointer function, first introduced in G{\&amp;quot;{o}}{\&amp;quot;{o}}s et~al.~(SICOMP, 2018 / FOCS, 2015), to demonstrate separation between various pairs of measures. In the last few years, pointer functions have been used to show separation between  various other pairs of measures (for example, Mukhopadhyay et~al.~(FSTTCS, 2015), Ben-David et~al.~(ITCS, 2017), G{\&amp;quot;{o}}{\&amp;quot;{o}}s et~al.~(ToCT, 2018 / ICALP, 2017)).  

However, the pointer functions themselves are not transitive. 
Based on the various kinds of pointer functions, we construct new transitive functions whose deterministic query complexity, randomized query complexity, zero-error randomized query complexity, quantum query complexity, degree, and approximate degree are similar to that of the original pointer functions. Thus we demonstrate that even for transitive functions similar separations between pairs of combinatorial measures can be achieved.  

Our constructions of transitive functions depend crucially on construction of particular classes of transitive groups, whose actions, though involved, helps to preserve certain structural features of the input strings.  The transitive groups we construct may be of independent interest in other areas of mathematics and theoretical computer science. 

We summarize the current knowledge of relations between various combinatorial measures of transitive functions in a table similar to the table compiled by Aaronson et~al.~(STOC, 2021) for general functions.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR23-043 |  Coboundary and cosystolic expansion without dependence on dimension or degree | 

	Yotam Dikstein, 

	Irit Dinur</title>
    <link href="https://eccc.weizmann.ac.il/report/2023/043"/>
    <id>https://eccc.weizmann.ac.il/report/2023/043</id>
    <updated>2023-04-09T06:09:10+00:00</updated>
    <content type="html" xml:lang="en">
    We give new bounds on the cosystolic expansion constants of several families of high dimensional expanders, and the known coboundary expansion constants of order complexes of homogeneous geometric lattices, including the spherical building of $SL_n(F_q)$. The improvement applies to the high dimensional expanders constructed by Lubotzky, Samuels and Vishne, and by Kaufman and Oppenheim.

Our new expansion constants do not depend on the degree of the complex nor on its dimension, nor on the group of coefficients. This implies improved bounds on Gromov’s topological overlap constant, and on Dinur and Meshulam’s cover stability, which may have applications for agreement testing. In comparison, existing bounds decay exponentially with the ambient dimension (for spherical buildings) and in addition decay linearly with the degree (for all known bounded-degree high dimensional expanders).

Our results are based on several new techniques:

– We develop a new “color-restriction” technique which enables proving dimension-free expansion by restricting a multi-partite complex to small random subsets of its color classes.

– We give a new “spectral” proof for Evra and Kaufman’s local-to-global theorem, deriving better bounds and getting rid of the dependence on the degree. This theorem bounds the cosystolic expansion of a complex using coboundary expansion and spectral expansion of the links.

– We derive absolute bounds on the coboundary expansion of the spherical building (and any order complex of a homogeneous geometric lattice) by constructing a novel family of very short cones.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Property Testing Review: News for March 2023</title>
    <link href="https://ptreview.sublinear.info/2023/04/news-for-march-2023/"/>
    <id>https://ptreview.sublinear.info/?p=1866</id>
    <updated>2023-04-07T16:45:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;I never thought this day would come.&lt;/p&gt;



&lt;p&gt;For the first time in PTReview history, there is no paper to report. Nada. Zilch.&lt;/p&gt;



&lt;p&gt;The calm before the storm&amp;#8230;?&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Seshadhri&lt;/p&gt;
  </content>
    <author>
      <name>Property Testing Review</name>
      <uri>https://ptreview.sublinear.info</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Tight Correlation Bounds for Circuits Between AC0 and TC0</title>
    <link href="http://arxiv.org/abs/2304.02770"/>
    <id>http://arxiv.org/abs/2304.02770</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vinayak M. Kumar&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We initiate the study of generalized AC0 circuits comprised of negations and
arbitrary unbounded fan-in gates that only need to be constant over inputs of
Hamming weight $\ge k$, which we denote GC0$(k)$. The gate set of this class
includes biased LTFs like the $k$-$OR$ (output $1$ iff $\ge k$ bits are 1) and
$k$-$AND$ (output $0$ iff $\ge k$ bits are 0), and thus can be seen as an
interpolation between AC0 and TC0. We establish a tight multi-switching lemma
for GC0$(k)$ circuits, which bounds the probability that several depth-2
GC0$(k)$ circuits do not simultaneously simplify under a random restriction. We
also establish a new depth reduction lemma such that coupled with our
multi-switching lemma, we can show many results obtained from the
multi-switching lemma for depth-$d$ size-$s$ AC0 circuits lifts to depth-$d$
size-$s^{.99}$ GC0$(.01\log s)$ circuits with no loss in parameters (other than
hidden constants). Our result has the following applications:
&lt;/p&gt;
&lt;p&gt;1.Size-$2^{\Omega(n^{1/d})}$ depth-$d$ GC0$(\Omega(n^{1/d}))$ circuits do not
correlate with parity (extending a result of H{\aa}stad (SICOMP, 2014)).
&lt;/p&gt;
&lt;p&gt;2. Size-$n^{\Omega(\log n)}$ GC0$(\Omega(\log^2 n))$ circuits with $n^{.249}$
arbitrary threshold gates or $n^{.499}$ arbitrary symmetric gates exhibit
exponentially small correlation against an explicit function (extending a
result of Tan and Servedio (RANDOM, 2019)).
&lt;/p&gt;
&lt;p&gt;3. There is a seed length $O((\log m)^{d-1}\log(m/\varepsilon)\log\log(m))$
pseudorandom generator against size-$m$ depth-$d$ GC0$(\log m)$ circuits,
matching the AC0 lower bound of H{\aa}stad stad up to a $\log\log m$ factor
(extending a result of Lyu (CCC, 2022)).
&lt;/p&gt;
&lt;p&gt;4. Size-$m$ GC0$(\log m)$ circuits have exponentially small Fourier tails
(extending a result of Tal (CCC, 2017)).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Inapproximability of sufficient reasons for decision trees</title>
    <link href="http://arxiv.org/abs/2304.02781"/>
    <id>http://arxiv.org/abs/2304.02781</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozachinskiy_A/0/1/0/all/0/1&quot;&gt;Alexander Kozachinskiy&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this note, we establish the hardness of approximation of the problem of
computing the minimal size of a $\delta$-sufficient reason for decision trees.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Improved Hardness of Approximating k-Clique under ETH</title>
    <link href="http://arxiv.org/abs/2304.02943"/>
    <id>http://arxiv.org/abs/2304.02943</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1&quot;&gt;Bingkai Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1&quot;&gt;Xuandi Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yican Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiuhan Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we prove that assuming the exponential time hypothesis (ETH),
there is no $f(k)\cdot n^{k^{o(1/\log\log k)}}$-time algorithm that can decide
whether an $n$-vertex graph contains a clique of size $k$ or contains no clique
of size $k/2$, and no FPT algorithm can decide whether an input graph has a
clique of size $k$ or no clique of size $k/f(k)$, where $f(k)$ is some function
in $k^{1-o(1)}$. Our results significantly improve the previous works [Lin21,
LRSW22]. The crux of our proof is a framework to construct gap-producing
reductions for the \kclique{} problem. More precisely, we show that given an
error-correcting code $C:\Sigma_1^k\to\Sigma_2^{k&#39;}$ that is locally testable
and smooth locally decodable in the parallel setting, one can construct a
reduction which on input a graph $G$ outputs a graph $G&#39;$ in $(k&#39;)^{O(1)}\cdot
n^{O(\log|\Sigma_2|/\log|\Sigma_1|)}$ time such that:
&lt;/p&gt;
&lt;p&gt;$\bullet$ If $G$ has a clique of size $k$, then $G&#39;$ has a clique of size
$K$, where $K = (k&#39;)^{O(1)}$.
&lt;/p&gt;
&lt;p&gt;$\bullet$ If $G$ has no clique of size $k$, then $G&#39;$ has no clique of size
$(1-\varepsilon)\cdot K$ for some constant $\varepsilon\in(0,1)$.
&lt;/p&gt;
&lt;p&gt;We then construct such a code with $k&#39;=k^{\Theta(\log\log k)}$ and
$|\Sigma_2|=|\Sigma_1|^{k^{0.54}}$, establishing the hardness results above.
Our code generalizes the derivative code [WY07] into the case with a super
constant order of derivatives.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: The complexity of decomposing a graph into a matching and a bounded linear forest</title>
    <link href="http://arxiv.org/abs/2304.03256"/>
    <id>http://arxiv.org/abs/2304.03256</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1&quot;&gt;Agnijo Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marciano_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Pedro Marciano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mond_A/0/1/0/all/0/1&quot;&gt;Adva Mond&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petr_J/0/1/0/all/0/1&quot;&gt;Jan Petr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Portier_J/0/1/0/all/0/1&quot;&gt;Julien Portier&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Deciding whether a graph can be edge-decomposed into a matching and a
$k$-bounded linear forest was recently shown by Campbell, H{\&quot;o}rsch and Moore
to be NP-complete for every $k \ge 9$, and solvable in polynomial time for
$k=1,2$. In the first part of this paper, we close this gap by showing that
this problem is in NP-complete for every $k \ge 3$. In the second part of the
paper, we show that deciding whether a graph can be edge-decomposed into a
matching and a $k$-bounded star forest is polynomially solvable for any $k \in
\mathbb{N} \cup \{ \infty \}$, answering another question by Campbell,
H{\&quot;o}rsch and Moore from the same paper.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Software and Analysis for Dynamic Voronoi Diagrams in the Hilbert Metric</title>
    <link href="http://arxiv.org/abs/2304.02745"/>
    <id>http://arxiv.org/abs/2304.02745</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bumpus_M/0/1/0/all/0/1&quot;&gt;Madeline Bumpus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_C/0/1/0/all/0/1&quot;&gt;Caesar Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gezalyan_A/0/1/0/all/0/1&quot;&gt;Auguste H. Gezalyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munoz_S/0/1/0/all/0/1&quot;&gt;Sam Munoz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santhoshkumar_R/0/1/0/all/0/1&quot;&gt;Renita Santhoshkumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1&quot;&gt;Songyu Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mount_D/0/1/0/all/0/1&quot;&gt;David M. Mount&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Hilbert metric is a projective metric defined on a convex body which
generalizes the Cayley-Klein model of hyperbolic geometry to any convex set. In
this paper we analyze Hilbert Voronoi diagrams in the Dynamic setting. In
addition we introduce dynamic visualization software for Voronoi diagrams in
the Hilbert metric on user specified convex polygons.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Fast computation of approximate weak common intervals in multiple indeterminate strings</title>
    <link href="http://arxiv.org/abs/2304.02657"/>
    <id>http://arxiv.org/abs/2304.02657</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doerr_D/0/1/0/all/0/1&quot;&gt;Daniel Doerr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moret_B/0/1/0/all/0/1&quot;&gt;Bernard M.E. Moret&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In ongoing work to define a principled method for syntenic block discovery
and structuring, work based on homology-derived constraints and a
generalization of common intervals, we faced a fundamental computational
problem: how to determine quickly, among a set of indeterminate strings
(strings whose elements consist of subsets of characters), contiguous intervals
that would share a vast majority of their elements, but allow for sharing
subsets of characters subsumed by others, and also for certain elements to be
missing from certain genomes. An algorithm for this problem in the special case
of determinate strings (where each element is a single character of the
alphabet, i.e., &quot;normal&quot; strings) was described by Doerr et al., but its
running time would explode if generalized to indeterminate strings. In this
paper, we describe an algorithm for computing these special common intervals in
time close to that of the simpler algorithm of Doerr et al. and show that can
compute these intervals in just a couple of hours for large collections (tens
to hundreds) of bacterial genomes.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Agnostic proper learning of monotone functions: beyond the black-box correction barrier</title>
    <link href="http://arxiv.org/abs/2304.02700"/>
    <id>http://arxiv.org/abs/2304.02700</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lange_J/0/1/0/all/0/1&quot;&gt;Jane Lange&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasilyan_A/0/1/0/all/0/1&quot;&gt;Arsen Vasilyan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We give the first agnostic, efficient, proper learning algorithm for monotone
Boolean functions. Given $2^{\tilde{O}(\sqrt{n}/\varepsilon)}$ uniformly random
examples of an unknown function $f:\{\pm 1\}^n \rightarrow \{\pm 1\}$, our
algorithm outputs a hypothesis $g:\{\pm 1\}^n \rightarrow \{\pm 1\}$ that is
monotone and $(\mathrm{opt} + \varepsilon)$-close to $f$, where $\mathrm{opt}$
is the distance from $f$ to the closest monotone function. The running time of
the algorithm (and consequently the size and evaluation time of the hypothesis)
is also $2^{\tilde{O}(\sqrt{n}/\varepsilon)}$, nearly matching the lower bound
of Blais et al (RANDOM &#39;15). We also give an algorithm for estimating up to
additive error $\varepsilon$ the distance of an unknown function $f$ to
monotone using a run-time of $2^{\tilde{O}(\sqrt{n}/\varepsilon)}$. Previously,
for both of these problems, sample-efficient algorithms were known, but these
algorithms were not run-time efficient. Our work thus closes this gap in our
knowledge between the run-time and sample complexity.
&lt;/p&gt;
&lt;p&gt;This work builds upon the improper learning algorithm of Bshouty and Tamon
(JACM &#39;96) and the proper semiagnostic learning algorithm of Lange, Rubinfeld,
and Vasilyan (FOCS &#39;22), which obtains a non-monotone Boolean-valued
hypothesis, then ``corrects&#39;&#39; it to monotone using query-efficient local
computation algorithms on graphs. This black-box correction approach can
achieve no error better than $2\mathrm{opt} + \varepsilon$
information-theoretically; we bypass this barrier by
&lt;/p&gt;
&lt;p&gt;a) augmenting the improper learner with a convex optimization step, and
&lt;/p&gt;
&lt;p&gt;b) learning and correcting a real-valued function before rounding its values
to Boolean.
&lt;/p&gt;
&lt;p&gt;Our real-valued correction algorithm solves the ``poset sorting&#39;&#39; problem of
[LRV22] for functions over general posets with non-Boolean labels.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: LSketch: A Label-Enabled Graph Stream Sketch Toward Time-Sensitive Queries</title>
    <link href="http://arxiv.org/abs/2304.02897"/>
    <id>http://arxiv.org/abs/2304.02897</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1&quot;&gt;Yiling Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1&quot;&gt;Chunyao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuhan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1&quot;&gt;Tingjian Ge&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Graph streams represent data interactions in real applications. The mining of
graph streams plays an important role in network security, social network
analysis, and traffic control, among others. However, the sheer volume and high
dynamics cause great challenges for efficient storage and subsequent query
analysis on them. Current studies apply sketches to summarize graph streams. We
propose LSketch that works for heterogeneous graph streams, which effectively
preserves the label information carried by the streams in real scenes, thereby
enriching the expressive ability of sketches. In addition, as graph streams
continue to evolve over time, edges too old may lose their practical
significance. Therefore, we introduce the sliding window model into LSketch to
eliminate the expired edges automatically. LSketch uses sub-linear storage
space and can support structure based queries and time-sensitive queries with
high accuracy. We perform extensive experiments over four real datasets,
demonstrating the superiority of the proposed method over state-of-the-art
methods, in aspects of query accuracy and time efficiency.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Parameterized Approximation Schemes for Clustering with General Norm Objectives</title>
    <link href="http://arxiv.org/abs/2304.03146"/>
    <id>http://arxiv.org/abs/2304.03146</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbasi_F/0/1/0/all/0/1&quot;&gt;Fateme Abbasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1&quot;&gt;Sandip Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Byrka_J/0/1/0/all/0/1&quot;&gt;Jaros&amp;#x142;aw Byrka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chalermsook_P/0/1/0/all/0/1&quot;&gt;Parinya Chalermsook&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gadekar_A/0/1/0/all/0/1&quot;&gt;Ameet Gadekar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khodamoradi_K/0/1/0/all/0/1&quot;&gt;Kamyar Khodamoradi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marx_D/0/1/0/all/0/1&quot;&gt;D&amp;#xe1;niel Marx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1&quot;&gt;Roohani Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spoerhase_J/0/1/0/all/0/1&quot;&gt;Joachim Spoerhase&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper considers the well-studied algorithmic regime of designing a
$(1+\epsilon)$-approximation algorithm for a $k$-clustering problem that runs
in time $f(k,\epsilon)poly(n)$ (sometimes called an efficient parameterized
approximation scheme or EPAS for short). Notable results of this kind include
EPASes in the high-dimensional Euclidean setting for $k$-center [Bad\u{o}iu,
Har-Peled, Indyk; STOC&#39;02] as well as $k$-median, and $k$-means [Kumar,
Sabharwal, Sen; J. ACM 2010]. However, existing EPASes handle only basic
objectives (such as $k$-center, $k$-median, and $k$-means) and are tailored to
the specific objective and metric space.
&lt;/p&gt;
&lt;p&gt;Our main contribution is a clean and simple EPAS that settles more than ten
clustering problems (across multiple well-studied objectives as well as metric
spaces) and unifies well-known EPASes. Our algorithm gives EPASes for a large
variety of clustering objectives (for example, $k$-means, $k$-center,
$k$-median, priority $k$-center, $\ell$-centrum, ordered $k$-median, socially
fair $k$-median aka robust $k$-median, or more generally monotone norm
$k$-clustering) and metric spaces (for example, continuous high-dimensional
Euclidean spaces, metrics of bounded doubling dimension, bounded treewidth
metrics, and planar metrics).
&lt;/p&gt;
&lt;p&gt;Key to our approach is a new concept that we call bounded $\epsilon$-scatter
dimension--an intrinsic complexity measure of a metric space that is a
relaxation of the standard notion of bounded doubling dimension. Our main
technical result shows that two conditions are essentially sufficient for our
algorithm to yield an EPAS on the input metric $M$ for any clustering
objective: (i) The objective is described by a monotone (not necessarily
symmetric!) norm, and (ii) the $\epsilon$-scatter dimension of $M$ is upper
bounded by a function of $\epsilon$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Spectral Toolkit of Algorithms for Graphs: Technical Report (1)</title>
    <link href="http://arxiv.org/abs/2304.03170"/>
    <id>http://arxiv.org/abs/2304.03170</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Macgregor_P/0/1/0/all/0/1&quot;&gt;Peter Macgregor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;He Sun&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Spectral Toolkit of Algorithms for Graphs (STAG) is an open-source library
for efficient spectral graph algorithms, and its development starts in
September 2022. We have so far finished the component on local graph
clustering, and this technical report presents a user&#39;s guide to STAG, showcase
studies, and several technical considerations behind our development.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On the tractability of sampling from the Potts model at low temperatures via Swendsen--Wang dynamics</title>
    <link href="http://arxiv.org/abs/2304.03182"/>
    <id>http://arxiv.org/abs/2304.03182</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Blanca_A/0/1/0/all/0/1&quot;&gt;Antonio Blanca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gheissari_R/0/1/0/all/0/1&quot;&gt;Reza Gheissari&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Sampling from the $q$-state ferromagnetic Potts model is a fundamental
question in statistical physics, probability theory, and theoretical computer
science. On general graphs, this problem is computationally hard, and this
hardness holds at arbitrarily low temperatures. At the same time, in recent
years, there has been significant progress showing the existence of
low-temperature sampling algorithms in various specific families of graphs. Our
aim in this paper is to understand the minimal structural properties of general
graphs that enable polynomial-time sampling from the $q$-state ferromagnetic
Potts model at low temperatures. We study this problem from the perspective of
the widely-used Swendsen--Wang dynamics and the closely related random-cluster
dynamics.
&lt;/p&gt;
&lt;p&gt;Our results demonstrate that the key graph property behind fast or slow
convergence time for these dynamics is whether the independent edge-percolation
on the graph admits a strongly supercritical phase. By this, we mean that at
large $p&amp;lt;1$, it has a unique giant component of linear size, and the complement
of that giant component is comprised of only small components. Specifically, we
prove that such a condition implies fast mixing of the Swendsen--Wang and
random-cluster dynamics on two general families of bounded-degree graphs: (a)
graphs of at most stretched-exponential volume growth and (b) locally treelike
graphs. In the other direction, we show that, even among graphs in those
families, these Markov chains can converge exponentially slowly at arbitrarily
low temperatures if the edge-percolation condition does not hold. In the
process, we develop new tools for the analysis of non-local Markov chains,
including a framework to bound the speed of disagreement propagation in the
presence of long-range correlations, and an understanding of spatial mixing
properties on trees with random boundary conditions.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Krylov Methods are (nearly) Optimal for Low-Rank Approximation</title>
    <link href="http://arxiv.org/abs/2304.03191"/>
    <id>http://arxiv.org/abs/2304.03191</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bakshi_A/0/1/0/all/0/1&quot;&gt;Ainesh Bakshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1&quot;&gt;Shyam Narayanan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the problem of rank-$1$ low-rank approximation (LRA) in the
matrix-vector product model under various Schatten norms: $$
&lt;/p&gt;
&lt;p&gt;\min_{\|u\|_2=1} \|A (I - u u^\top)\|_{\mathcal{S}_p} , $$ where
$\|M\|_{\mathcal{S}_p}$ denotes the $\ell_p$ norm of the singular values of
$M$. Given $\varepsilon&amp;gt;0$, our goal is to output a unit vector $v$ such that
$$
&lt;/p&gt;
&lt;p&gt;\|A(I - vv^\top)\|_{\mathcal{S}_p} \leq (1+\varepsilon) \min_{\|u\|_2=1}\|A(I
- u u^\top)\|_{\mathcal{S}_p}. $$ Our main result shows that Krylov methods
(nearly) achieve the information-theoretically optimal number of matrix-vector
products for Spectral ($p=\infty$), Frobenius ($p=2$) and Nuclear ($p=1$) LRA.
&lt;/p&gt;
&lt;p&gt;In particular, for Spectral LRA, we show that any algorithm requires
$\Omega\left(\log(n)/\varepsilon^{1/2}\right)$ matrix-vector products, exactly
matching the upper bound obtained by Krylov methods [MM15, BCW22]. Our lower
bound addresses Open Question 1 in [Woo14], providing evidence for the lack of
progress on algorithms for Spectral LRA and resolves Open Question 1.2 in
[BCW22]. Next, we show that for any fixed constant $p$, i.e. $1\leq p =O(1)$,
there is an upper bound of
$O\left(\log(1/\varepsilon)/\varepsilon^{1/3}\right)$ matrix-vector products,
implying that the complexity does not grow as a function of input size. This
improves the $O\left(\log(n/\varepsilon)/\varepsilon^{1/3}\right)$ bound
recently obtained in [BCW22], and matches their
$\Omega\left(1/\varepsilon^{1/3}\right)$ lower bound, to a
$\log(1/\varepsilon)$ factor.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Parameterized algorithms for Eccentricity Shortest Path Problem</title>
    <link href="http://arxiv.org/abs/2304.03233"/>
    <id>http://arxiv.org/abs/2304.03233</id>
    <updated>2023-04-07T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhyravarapu_S/0/1/0/all/0/1&quot;&gt;Sriram Bhyravarapu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jana_S/0/1/0/all/0/1&quot;&gt;Satyabrata Jana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanesh_L/0/1/0/all/0/1&quot;&gt;Lawqueen Kanesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1&quot;&gt;Saket Saurabh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1&quot;&gt;Shaily Verma&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given an undirected graph $G=(V,E)$ and an integer $\ell$, the Eccentricity
Shortest Path (ESP) asks to find a shortest path $P$ such that for every vertex
$v\in V(G)$, there is a vertex $w\in P$ such that $d_G(v,w)\leq \ell$, where
$d_G(v,w)$ represents the distance between $v$ and $w$ in $G$. Dragan and
Leitert [Theor. Comput. Sci. 2017] showed that the optimization version of this
problem, which asks to find the minimum $\ell$ for the ESP problem, is NP-hard
even on planar bipartite graphs with maximum degree 3. They also showed that
ESP is W[2]-hard when parameterized by $\ell$. On the positive side, Ku\v cera
and Such\&#39;y [IWOCA 2021] showed that the problem exhibits fixed parameter
tractable (FPT) behavior when parameterized by modular width, cluster vertex
deletion set, maximum leaf number, or the combined parameters disjoint paths
deletion set and $\ell$. It was asked as an open question in the above paper,
if ESP is FPT parameterized by disjoint paths deletion set or feedback vertex
set. We answer these questions partially and obtain the following results: -
ESP is FPT when parameterized by disjoint paths deletion set, split vertex
deletion set or the combined parameters feedback vertex set and eccentricity of
the graph. - We design a $(1+\epsilon)$-factor FPT approximation algorithm when
parameterized by the feedback vertex set number. - ESP is W[2]-hard when
parameterized by the chordal vertex deletion set.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: PhD / Postdoc at Goethe University Frankfurt, Germany (apply by June 16, 2023)</title>
    <link href="https://cstheory-jobs.org/2023/04/06/phd-postdoc-at-goethe-university-frankfurt-germany-apply-by-june-16-2023/"/>
    <id>http://cstheory-jobs.org/2023/04/06/phd-postdoc-at-goethe-university-frankfurt-germany-apply-by-june-16-2023/</id>
    <updated>2023-04-06T09:13:46+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Fully-funded PhD or Postdoc position in “Parameterized Complexity of Network Dynamics” to be carried out under the supervision of Prof. Holger Dell. The 3-year research project at the intersection of parameterized complexity, statistical physics, and graph theory involves the rigorous analysis of dynamic processes on graphs, such as virus or fake news spreading through a social network.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://tcs.uni-frankfurt.de/positions/&quot;&gt;https://tcs.uni-frankfurt.de/positions/&lt;/a&gt;&lt;br /&gt;
Email: tcs-applications@dlist.uni-frankfurt.de&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Richard Lipton: Neil Jones, 1941–2023</title>
    <link href="https://rjlipton.wpcomstaging.com/2023/04/06/neil-jones-1941-2023/"/>
    <id>https://rjlipton.wpcomstaging.com/?p=21402</id>
    <updated>2023-04-06T04:03:23+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;
Neil Jones, sad to relate, just passed away. He was Professor Emeritus of Computer Science at the University of Copenhagen, which he joined on a permanent basis in 1982 after gaining tenure at Penn State and a full professorship at the University of Kansas. &lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/04/06/neil-jones-1941-2023/neil-d-jones-60-aar/&quot; rel=&quot;attachment wp-att-21404&quot;&gt;&lt;img data-attachment-id=&quot;21404&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/04/06/neil-jones-1941-2023/neil-d-jones-60-aar/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?fit=1312%2C2000&amp;amp;ssl=1&quot; data-orig-size=&quot;1312,2000&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;JENS ASTRUP&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;NEIL D. JONES FRA DATALOGISK INSTITUT I KBH\r\rBILLEDET KAN FRIT ANVENDES TIL OMTALE AF HANS 60 AARS  DAG&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;NEIL D. JONES 60 AAR&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;1&amp;quot;}&quot; data-image-title=&quot;NEIL D. JONES 60 AAR&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&amp;lt;p&amp;gt;NEIL D. JONES FRA DATALOGISK INSTITUT I KBH&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;BILLEDET KAN FRIT ANVENDES TIL OMTALE AF HANS 60 AARS  DAG&amp;lt;/p&amp;gt;
&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?fit=197%2C300&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?fit=600%2C914&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=200%2C305&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;200&quot; height=&quot;305&quot; class=&quot;aligncenter wp-image-21404&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=672%2C1024&amp;amp;ssl=1 672w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=197%2C300&amp;amp;ssl=1 197w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=768%2C1171&amp;amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=1008%2C1536&amp;amp;ssl=1 1008w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?resize=1200%2C1829&amp;amp;ssl=1 1200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/nj.jpeg?w=1312&amp;amp;ssl=1 1312w&quot; sizes=&quot;(max-width: 200px) 100vw, 200px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
Eric Allender wrote a &lt;a href=&quot;https://blog.computationalcomplexity.org&quot;&gt;post&lt;/a&gt; on Neil for Lance Fortnow&amp;#8217;s and Bill Gasarch&amp;#8217;s famous blog. We point to it, hopefully with their full approval, and add some supplementary remarks. Eric&amp;#8217;s tribute leads with Jones&amp;#8217;s work with Alan Selman characterizing logical spectra via languages in nondeterministic &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28n%29%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{2^{O(n)}}&quot; class=&quot;latex&quot; /&gt; time. He quotes remarks by D. Sivakumar that echo what Siva wrote for our &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2021/01/29/alan-selman-1941-2021/&quot;&gt;memorial&lt;/a&gt; to Alan.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; The Space Problem &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Steve Cook and Dick Karp started the quest to understand &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{P = NP}}&quot; class=&quot;latex&quot; /&gt;? What many including Neil have always considered the &amp;#8220;second big problem&amp;#8221; involves the power of space rather than nondeterminism, specifically: is &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BLOGSPACE+%3D+PTIME%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{LOGSPACE = PTIME}}&quot; class=&quot;latex&quot; /&gt;? Neil, like the rest of us, had his thoughts on the conjecture that they are different, but like the rest of us, did not know for sure. His thoughts on the subject ranged from &lt;a href=&quot;https://dblp.uni-trier.de/rec/journals/jcss/Jones75.html&quot;&gt;two&lt;/a&gt; early &lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/800119.803883&quot;&gt;papers&lt;/a&gt; to the last &lt;a href=&quot;https://arxiv.org/pdf/2008.02932.pdf&quot;&gt;paper&lt;/a&gt; on his DBLP page. &lt;/p&gt;
&lt;p&gt;
This last paper is joint with Siddharth Bhaskar, Cynthia Kop, and Jakob Simonsen, and is titled, &amp;#8220;Cons-free Programs and Complexity Classes between LOGSPACE and PTIME.&amp;#8221; It appeared at the 2020 joint meeting of the Horn Clauses for Verification and Synthesis (HCVS) and Verification and Program Transformation (VPT) workshops. They call a program &amp;#8220;cons-free&amp;#8221; if it does not allow agglutination of data, not by &lt;FONT SIZE=&quot;+1&quot;&gt;&lt;tt&gt;cons&lt;/tt&gt;&lt;/FONT&gt; with lists, nor successor, +, or * with integers, nor any allocator of storage. They further consider constraining recursion so as not to mushroom by mandating certain forms of tail recursion. Problems decided by cons-free programs form the class &amp;#8220;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BCF%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{CF}}&quot; class=&quot;latex&quot; /&gt;&amp;#8221; and those further having only tail recursion, &amp;#8220;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BCFTR%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{CFTR}}&quot; class=&quot;latex&quot; /&gt;.&amp;#8221;&lt;/p&gt;
&lt;p&gt;
This use of functional languages represents both a more modern viewpoint&amp;#8212;than how complexity was founded on Turing machines in the 1960s&amp;#8212;and an older one, insofar as Lisp and other ideas of functional languages were fertile before the 1960s. They characterize &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+CF%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{P = CF}}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BLOGSPACE+%3D+CFTR%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{LOGSPACE = CFTR}}&quot; class=&quot;latex&quot; /&gt; as their form also constraining recursion. The former holds some surprise as the cons-free programs are allowed to run for exponential time. If they are constrained to run in polynomial time, a class intermediate between &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BLOGSPACE%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{LOGSPACE}}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{P}}&quot; class=&quot;latex&quot; /&gt; emerges. Is it equivalent to a known class? They leave that open.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Non-Turing Time &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Jones&amp;#8217;s work on other models besides Turing machines caught my attention 30 years ago&amp;#8212;this is Ken writing this section. I was interested in models that have a constant-factor time overhead for universal simulation &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BU%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{U}&quot; class=&quot;latex&quot; /&gt; of any other machine &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M}&quot; class=&quot;latex&quot; /&gt;, in contrast to the standard multitape Turing machine model where &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BU%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{U}&quot; class=&quot;latex&quot; /&gt; incurs an &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+t%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{O(&amp;#92;log t)}&quot; class=&quot;latex&quot; /&gt; time overhead for simulating &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{t}&quot; class=&quot;latex&quot; /&gt; steps of machines &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M}&quot; class=&quot;latex&quot; /&gt; with more tapes than &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BU%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{U}&quot; class=&quot;latex&quot; /&gt; has. This &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Clog+t%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;log t}&quot; class=&quot;latex&quot; /&gt; factor also shows up in the deterministic time hierarchy theorem, though for natural instances it can be shaved down to &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+t%29%5E%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{O(&amp;#92;log t)^&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt; for any fixed &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt; by techniques of &lt;em&gt;padding and translation&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;
Martin F&amp;uuml;rer had &lt;a href=&quot;https://dl.acm.org/doi/10.1145/800070.802172&quot;&gt;shown&lt;/a&gt; that when &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k}&quot; class=&quot;latex&quot; /&gt; is fixed, the log factor goes away. I was interested in leveraging random-access models that have constant-factor overhead while imposing locality restrictions on the random access. The resulting time hierarchy theorems are only &amp;#8220;tight&amp;#8221; in the sense of needing &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bt_1%28n%29+%3D+o%28t_2%28n%29%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{t_1(n) = o(t_2(n))}&quot; class=&quot;latex&quot; /&gt;&amp;#8212;in order to construct a language decidable in time &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bt_2%28n%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{t_2(n)}&quot; class=&quot;latex&quot; /&gt; but not in time &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BO%28t_1%28n%29%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{O(t_1(n))}&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;
Jones went this one better by building a natural programming-based model that has a time hierarchy for a &lt;em&gt;fixed&lt;/em&gt; constant factor. His STOC 1993 &lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/167088.167244&quot;&gt;paper&lt;/a&gt; was titled, &amp;#8220;Constant Time Factors &lt;em&gt;Do&lt;/em&gt; Matter&amp;#8221; with italics on the &lt;em&gt;Do&lt;/em&gt;. This grew into a &lt;a href=&quot;https://link.springer.com/article/10.1007/s002360000038&quot;&gt;paper&lt;/a&gt; in &lt;em&gt;Acta Informatica&lt;/em&gt; 2000 with Amir Ben-Amram. It also became the basis for his 1997 &lt;a href=&quot;https://www.amazon.com/Computability-Complexity-Programming-Perspective-Foundations/dp/0262100649&quot;&gt;textbook&lt;/a&gt;, &lt;em&gt;Computability and Complexity: From a Programming Perspective&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;
The prominence of &amp;#8220;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{P = NP}}&quot; class=&quot;latex&quot; /&gt;?&amp;#8221; masks that our lack of knowledge of lower bounds takes effect at linear time. For circuit models the status is even worse: we still have not refuted the possibility that every language in deterministic &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28n%29%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{2^{O(n)}}&quot; class=&quot;latex&quot; /&gt; time has (possibly nonuniform) &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BO%28n%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{O(n)}&quot; class=&quot;latex&quot; /&gt;-sized circuits. I thought that a new kind of super-linear lower bound could get a grip on peeling the end of a coiled tape that might then freely unroll. As with &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{P}}&quot; class=&quot;latex&quot; /&gt; versus &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BLOGSPACE%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{LOGSPACE}}&quot; class=&quot;latex&quot; /&gt;, however, getting such a grip remains open.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Open Problems &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
I&amp;#8212;Dick again&amp;#8212;worked on related stuff in a 1979 &lt;a href=&quot;https://www2.eecs.berkeley.edu/Pubs/TechRpts/1979/ERL-m-79-54.pdf&quot;&gt;paper&lt;/a&gt; that had a cast of famous brilliant scholars: &amp;#8220;Random Walks, Universal Traversal Sequences, and the Complexity of Maze Problems&amp;#8221;&amp;#8212;by Romas Aleliunas, Dick Karp, me, Laci Lovasz, and Charlie Rackoff. There were ways to build off this to greater results, particularly Omer Reingold&amp;#8217;s blending-in of Irit Dinur&amp;#8217;s PCP proof technique to &lt;a href=&quot;https://omereingold.files.wordpress.com/2014/10/sl.pdf&quot;&gt;show&lt;/a&gt; that undirected maze problems belong to deterministic logspace. Is there a way to build more off Neil&amp;#8217;s results&amp;#8212;the newer and the older ones?&lt;/p&gt;
&lt;p&gt;
&lt;p class=&quot;authors&quot;&gt;By RJLipton+KWRegan&lt;/p&gt;
  </content>
    <author>
      <name>Richard Lipton</name>
      <uri>https://rjlipton.wpcomstaging.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Visualizing Quantum Circuit Probability -- estimating computational action for quantum program synthesis</title>
    <link href="http://arxiv.org/abs/2304.02358"/>
    <id>http://arxiv.org/abs/2304.02358</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Bach_B/0/1/0/all/0/1&quot;&gt;Bao Gia Bach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kundu_A/0/1/0/all/0/1&quot;&gt;Akash Kundu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Acharya_T/0/1/0/all/0/1&quot;&gt;Tamal Acharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sarkar_A/0/1/0/all/0/1&quot;&gt;Aritra Sarkar&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This research applies concepts from algorithmic probability to Boolean and
quantum combinatorial logic circuits. A tutorial-style introduction to states
and various notions of the complexity of states are presented. Thereafter, the
probability of states in the circuit model of computation is defined. Classical
and quantum gate sets are compared to select some characteristic sets. The
reachability and expressibility in a space-time-bounded setting for these gate
sets are enumerated and visualized. These results are studied in terms of
computational resources, universality and quantum behavior. The article
suggests how applications like geometric quantum machine learning, novel
quantum algorithm synthesis and quantum artificial general intelligence can
benefit by studying circuit probabilities.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Picturing counting reductions with the ZH-calculus</title>
    <link href="http://arxiv.org/abs/2304.02524"/>
    <id>http://arxiv.org/abs/2304.02524</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laakkonen_T/0/1/0/all/0/1&quot;&gt;Tuomas Laakkonen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meichanetzidis_K/0/1/0/all/0/1&quot;&gt;Konstantinos Meichanetzidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wetering_J/0/1/0/all/0/1&quot;&gt;John van de Wetering&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Counting the solutions to Boolean formulae defines the problem #SAT, which is
complete for the complexity class #P. We use the ZH-calculus, a universal and
complete graphical language for linear maps which naturally encodes counting
problems in terms of diagrams, to give graphical reductions from #SAT to
several related counting problems. Some of these graphical reductions, like to
#2SAT, are substantially simpler than known reductions via the matrix
permanent. Additionally, our approach allows us to consider the case of
counting solutions modulo an integer on equal footing. Finally, since the
ZH-calculus was originally introduced to reason about quantum computing, we
show that the problem of evaluating ZH-diagrams in the fragment corresponding
to the Clifford+T gateset, is in $FP^{\#P}$. Our results show that graphical
calculi represent an intuitive and useful framework for reasoning about
counting problems.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Top-Down Lower Bounds for Depth-Four Circuits</title>
    <link href="http://arxiv.org/abs/2304.02555"/>
    <id>http://arxiv.org/abs/2304.02555</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goos_M/0/1/0/all/0/1&quot;&gt;Mika G&amp;#xf6;&amp;#xf6;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riazanov_A/0/1/0/all/0/1&quot;&gt;Artur Riazanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sofronova_A/0/1/0/all/0/1&quot;&gt;Anastasia Sofronova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sokolov_D/0/1/0/all/0/1&quot;&gt;Dmitry Sokolov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present a top-down lower-bound method for depth-$4$ boolean circuits. In
particular, we give a new proof of the well-known result that the parity
function requires depth-$4$ circuits of size exponential in $n^{1/3}$. Our
proof is an application of robust sunflowers and block unpredictability.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Algorithm and Hardness for Dynamic Attention Maintenance in Large Language Models</title>
    <link href="http://arxiv.org/abs/2304.02207"/>
    <id>http://arxiv.org/abs/2304.02207</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brand_J/0/1/0/all/0/1&quot;&gt;Jan van den Brand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1&quot;&gt;Tianyi Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Large language models (LLMs) have made fundamental changes in human life. The
attention scheme is one of the key components over all the LLMs, such as BERT,
GPT-1, Transformers, GPT-2, 3, 3.5 and 4. Inspired by previous theoretical
study of static version of the attention multiplication problem [Zandieh, Han,
Daliri, and Karbasi arXiv 2023, Alman and Song arXiv 2023]. In this work, we
formally define a dynamic version of attention matrix multiplication problem.
There are matrices $Q,K, V \in \mathbb{R}^{n \times d}$, they represent query,
key and value in LLMs. In each iteration we update one entry in $K$ or $V$. In
the query stage, we receive $(i,j) \in [n] \times [d]$ as input, and want to
answer $(D^{-1} A V)_{i,j}$, where $A:=\exp(QK^\top) \in \mathbb{R}^{n \times
n}$ is a square matrix and $D := \mathrm{diag}(A {\bf 1}_n) \in \mathbb{R}^{n
\times n}$ is a diagonal matrix. Here ${\bf 1}_n$ denote a length-$n$ vector
that all the entries are ones.
&lt;/p&gt;
&lt;p&gt;We provide two results: an algorithm and a conditional lower bound.
&lt;/p&gt;
&lt;p&gt;$\bullet$ On one hand, inspired by the lazy update idea from [Demetrescu and
Italiano FOCS 2000, Sankowski FOCS 2004, Cohen, Lee and Song STOC 2019, Brand
SODA 2020], we provide a data-structure that uses
$O(n^{\omega(1,1,\tau)-\tau})$ amortized update time, and $O(n^{1+\tau})$
worst-case query time.
&lt;/p&gt;
&lt;p&gt;$\bullet$ On the other hand, show that unless the hinted matrix vector
multiplication conjecture [Brand, Nanongkai and Saranurak FOCS 2019] is false,
there is no algorithm that can use both $O(n^{\omega(1,1,\tau) - \tau-
\Omega(1)})$ amortized update time, and $O(n^{1+\tau-\Omega(1)})$ worst query
time.
&lt;/p&gt;
&lt;p&gt;In conclusion, our algorithmic result is conditionally optimal unless hinted
matrix vector multiplication conjecture is false.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Set Covering with Our Eyes Wide Shut</title>
    <link href="http://arxiv.org/abs/2304.02063"/>
    <id>http://arxiv.org/abs/2304.02063</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Anupam Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kehne_G/0/1/0/all/0/1&quot;&gt;Gregory Kehne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levin_R/0/1/0/all/0/1&quot;&gt;Roie Levin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the stochastic set cover problem (Grandoni et al., FOCS &#39;08), we are given
a collection $\mathcal{S}$ of $m$ sets over a universe $\mathcal{U}$ of size
$N$, and a distribution $D$ over elements of $\mathcal{U}$. The algorithm draws
$n$ elements one-by-one from $D$ and must buy a set to cover each element on
arrival; the goal is to minimize the total cost of sets bought during this
process. A universal algorithm a priori maps each element $u \in \mathcal{U}$
to a set $S(u)$ such that if $U \subseteq \mathcal{U}$ is formed by drawing $n$
times from distribution $D$, then the algorithm commits to outputting $S(U)$.
Grandoni et al. gave an $O(\log mN)$-competitive universal algorithm for this
stochastic set cover problem.
&lt;/p&gt;
&lt;p&gt;We improve unilaterally upon this result by giving a simple, polynomial time
$O(\log mn)$-competitive universal algorithm for the more general prophet
version, in which $U$ is formed by drawing from $n$ different distributions
$D_1, \ldots, D_n$. Furthermore, we show that we do not need full foreknowledge
of the distributions: in fact, a single sample from each distribution suffices.
We show similar results for the 2-stage prophet setting and for the
online-with-a-sample setting.
&lt;/p&gt;
&lt;p&gt;We obtain our results via a generic reduction from the single-sample prophet
setting to the random-order setting; this reduction holds for a broad class of
minimization problems that includes all covering problems. We take advantage of
this framework by giving random-order algorithms for non-metric facility
location and set multicover; using our framework, these automatically translate
to universal prophet algorithms.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Determinantal Sieving</title>
    <link href="http://arxiv.org/abs/2304.02091"/>
    <id>http://arxiv.org/abs/2304.02091</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eiben_E/0/1/0/all/0/1&quot;&gt;Eduard Eiben&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koana_T/0/1/0/all/0/1&quot;&gt;Tomohiro Koana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wahlstrom_M/0/1/0/all/0/1&quot;&gt;Magnus Wahlstr&amp;#xf6;m&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce determinantal sieving, a new, remarkably powerful tool in the
toolbox of algebraic FPT algorithms. Given a polynomial $P(X)$ on a set of
variables $X=\{x_1,\ldots,x_n\}$ and a linear matroid $M=(X,\mathcal{I})$ of
rank $k$, both over a field $\mathbb{F}$ of characteristic 2, in $2^k$
evaluations we can sieve for those terms in the monomial expansion of $P$ which
are multilinear and whose support is a basis for $M$. Alternatively, using
$2^k$ evaluations of $P$ we can sieve for those monomials whose odd support
spans $M$. Applying this framework, we improve on a range of algebraic FPT
algorithms, such as:
&lt;/p&gt;
&lt;p&gt;1. Solving $q$-Matroid Intersection in time $O^*(2^{(q-2)k})$ and $q$-Matroid
Parity in time $O^*(2^{qk})$, improving on $O^*(4^{qk})$ (Brand and Pratt,
ICALP 2021)
&lt;/p&gt;
&lt;p&gt;2. $T$-Cycle, Colourful $(s,t)$-Path, Colourful $(S,T)$-Linkage in undirected
graphs, and the more general Rank $k$ $(S,T)$-Linkage problem, all in
$O^*(2^k)$ time, improving on $O^*(2^{k+|S|})$ respectively $O^*(2^{|S|+O(k^2
\log(k+|\mathbb{F}|))})$ (Fomin et al., SODA 2023)
&lt;/p&gt;
&lt;p&gt;3. Many instances of the Diverse X paradigm, finding a collection of $r$
solutions to a problem with a minimum mutual distance of $d$ in time
$O^*(2^{r(r-1)d/2})$, improving solutions for $k$-Distinct Branchings from time
$2^{O(k \log k)}$ to $O^*(2^k)$ (Bang-Jensen et al., ESA 2021), and for Diverse
Perfect Matchings from $O^*(2^{2^{O(rd)}})$ to $O^*(2^{r^2d/2})$ (Fomin et al.,
STACS 2021)
&lt;/p&gt;
&lt;p&gt;All matroids are assumed to be represented over a field of characteristic 2.
Over general fields, we achieve similar results at the cost of using
exponential space by working over the exterior algebra. For a class of
arithmetic circuits we call strongly monotone, this is even achieved without
any loss of running time. However, the odd support sieving result appears to be
specific to working over characteristic 2.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: The Bit Complexity of Efficient Continuous Optimization</title>
    <link href="http://arxiv.org/abs/2304.02124"/>
    <id>http://arxiv.org/abs/2304.02124</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghadiri_M/0/1/0/all/0/1&quot;&gt;Mehrdad Ghadiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_R/0/1/0/all/0/1&quot;&gt;Richard Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1&quot;&gt;Santosh S. Vempala&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We analyze the bit complexity of efficient algorithms for fundamental
optimization problems, such as linear regression, $p$-norm regression, and
linear programming (LP). State-of-the-art algorithms are iterative, and in
terms of the number of arithmetic operations, they match the current time
complexity of multiplying two $n$-by-$n$ matrices (up to polylogarithmic
factors). However, previous work has typically assumed infinite precision
arithmetic, and due to complicated inverse maintenance techniques, the actual
running times of these algorithms are unknown. To settle the running time and
bit complexity of these algorithms, we demonstrate that a core common
subroutine, known as \emph{inverse maintenance}, is backward-stable.
Additionally, we show that iterative approaches for solving constrained
weighted regression problems can be accomplished with bounded-error
pre-conditioners. Specifically, we prove that linear programs can be solved
approximately in matrix multiplication time multiplied by polylog factors that
depend on the condition number $\kappa$ of the matrix and the inner and outer
radius of the LP problem. $p$-norm regression can be solved approximately in
matrix multiplication time multiplied by polylog factors in $\kappa$. Lastly,
linear regression can be solved approximately in input-sparsity time multiplied
by polylog factors in $\kappa$. Furthermore, we present results for achieving
lower than matrix multiplication time for $p$-norm regression by utilizing
faster solvers for sparse linear systems.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Sequential Linearithmic Time Optimal Unimodal Fitting When Minimizing Univariate Linear Losses</title>
    <link href="http://arxiv.org/abs/2304.02141"/>
    <id>http://arxiv.org/abs/2304.02141</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gokcesu_K/0/1/0/all/0/1&quot;&gt;Kaan Gokcesu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gokcesu_H/0/1/0/all/0/1&quot;&gt;Hakan Gokcesu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper focuses on optimal unimodal transformation of the score outputs of
a univariate learning model under linear loss functions. We demonstrate that
the optimal mapping between score values and the target region is a rectangular
function. To produce this optimal rectangular fit for the observed samples, we
propose a sequential approach that can its estimation with each incoming new
sample. Our approach has logarithmic time complexity per iteration and is
optimally efficient.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Folklore Sampling is Optimal for Exact Hopsets: Confirming the $\sqrt{n}$ Barrier</title>
    <link href="http://arxiv.org/abs/2304.02193"/>
    <id>http://arxiv.org/abs/2304.02193</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bodwin_G/0/1/0/all/0/1&quot;&gt;Greg Bodwin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoppenworth_G/0/1/0/all/0/1&quot;&gt;Gary Hoppenworth&lt;/a&gt;&lt;/p&gt;&lt;p&gt;For a graph $G$, a $D$-diameter-reducing exact hopset is a small set of
additional edges $H$ that, when added to $G$, maintains its graph metric but
guarantees that all node pairs have a shortest path in $G \cup H$ using at most
$D$ edges. A shortcut set is the analogous concept for reachability. These
objects have been studied since the early &#39;90s due to applications in parallel,
distributed, dynamic, and streaming graph algorithms.
&lt;/p&gt;
&lt;p&gt;For most of their history, the state-of-the-art construction for either
object was a simple folklore algorithm, based on randomly sampling nodes to hit
long paths in the graph. However, recent breakthroughs of Kogan and Parter
[SODA &#39;22] and Bernstein and Wein [SODA &#39;23] have finally improved over the
folklore diameter bound of $\widetilde{O}(n^{1/2})$ for shortcut sets and for
$(1+\epsilon)$-approximate hopsets. For both objects it is now known that one
can use $O(n)$ hop-edges to reduce diameter to $\widetilde{O}(n^{1/3})$. The
only setting where folklore sampling remains unimproved is for exact hopsets.
Can these improvements be continued?
&lt;/p&gt;
&lt;p&gt;We settle this question negatively by constructing graphs on which any exact
hopset of $O(n)$ edges has diameter $\widetilde{\Omega}(n^{1/2})$. This
improves on the previous lower bound of $\widetilde{\Omega}(n^{1/3})$ by Kogan
and Parter [FOCS &#39;22]. Using similar ideas, we also polynomially improve the
current lower bounds for shortcut sets, constructing graphs on which any
shortcut set of $O(n)$ edges reduces diameter to $\widetilde{\Omega}(n^{1/4})$.
This improves on the previous lower bound of $\Omega(n^{1/6})$ by Huang and
Pettie [SIAM J. Disc. Math. &#39;18]. We also extend our constructions to provide
lower bounds against $O(p)$-size exact hopsets and shortcut sets for other
values of $p$; in particular, we show that folklore sampling is near-optimal
for exact hopsets in the entire range of $p \in [1, n^2]$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Optimal Sketching Bounds for Sparse Linear Regression</title>
    <link href="http://arxiv.org/abs/2304.02261"/>
    <id>http://arxiv.org/abs/2304.02261</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1&quot;&gt;Tung Mai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munteanu_A/0/1/0/all/0/1&quot;&gt;Alexander Munteanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1&quot;&gt;Cameron Musco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1&quot;&gt;Anup B. Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwiegelshohn_C/0/1/0/all/0/1&quot;&gt;Chris Schwiegelshohn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1&quot;&gt;David P. Woodruff&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study oblivious sketching for $k$-sparse linear regression under various
loss functions such as an $\ell_p$ norm, or from a broad class of hinge-like
loss functions, which includes the logistic and ReLU losses. We show that for
sparse $\ell_2$ norm regression, there is a distribution over oblivious
sketches with $\Theta(k\log(d/k)/\varepsilon^2)$ rows, which is tight up to a
constant factor. This extends to $\ell_p$ loss with an additional additive
$O(k\log(k/\varepsilon)/\varepsilon^2)$ term in the upper bound. This
establishes a surprising separation from the related sparse recovery problem,
which is an important special case of sparse regression. For this problem,
under the $\ell_2$ norm, we observe an upper bound of $O(k \log (d)/\varepsilon
+ k\log(k/\varepsilon)/\varepsilon^2)$ rows, showing that sparse recovery is
strictly easier to sketch than sparse regression. For sparse regression under
hinge-like loss functions including sparse logistic and sparse ReLU regression,
we give the first known sketching bounds that achieve $o(d)$ rows showing that
$O(\mu^2 k\log(\mu n d/\varepsilon)/\varepsilon^2)$ rows suffice, where $\mu$
is a natural complexity parameter needed to obtain relative error bounds for
these loss functions. We again show that this dimension is tight, up to lower
order terms and the dependence on $\mu$. Finally, we show that similar
sketching bounds can be achieved for LASSO regression, a popular convex
relaxation of sparse regression, where one aims to minimize
$\|Ax-b\|_2^2+\lambda\|x\|_1$ over $x\in\mathbb{R}^d$. We show that sketching
dimension $O(\log(d)/(\lambda \varepsilon)^2)$ suffices and that the dependence
on $d$ and $\lambda$ is tight.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: The Laplacian Paradigm in Deterministic Congested Clique</title>
    <link href="http://arxiv.org/abs/2304.02315"/>
    <id>http://arxiv.org/abs/2304.02315</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Forster_S/0/1/0/all/0/1&quot;&gt;Sebatian Forster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vos_T/0/1/0/all/0/1&quot;&gt;Tijn de Vos&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we bring the techniques of the Laplacian paradigm to the
congested clique, while further restricting ourselves to deterministic
algorithms. In particular, we show how to solve a Laplacian system up to
precision $\epsilon$ in $n^{o(1)}\log(1/\epsilon)$ rounds. We show how to
leverage this result within existing interior point methods for solving flow
problems. We obtain an $m^{3/7+o(1)}U^{1/7}$ round algorithm for maximum flow
on a weighted directed graph with maximum weight $U$, and we obtain an
$\tilde{O}(m^{3/7}(n^{0.158}+n^{o(1)}\text{poly}\log W))$ round algorithm for
unit capacity minimum cost flow on a directed graph with maximum cost $W$.
Hereto, we give a novel routine for computing Eulerian orientations in $O(\log
n \log^* n)$ rounds, which we believe may be of separate interest.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On the Power of Threshold-Based Algorithms for Detecting Cycles in the CONGEST Model</title>
    <link href="http://arxiv.org/abs/2304.02360"/>
    <id>http://arxiv.org/abs/2304.02360</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fraigniaud_P/0/1/0/all/0/1&quot;&gt;Pierre Fraigniaud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luce_M/0/1/0/all/0/1&quot;&gt;Ma&amp;#xeb;l Luce&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Todinca_I/0/1/0/all/0/1&quot;&gt;Ioan Todinca&lt;/a&gt;&lt;/p&gt;&lt;p&gt;It is known that, for every $k\geq 2$, $C_{2k}$-freeness can be decided by a
generic Monte-Carlo algorithm running in $n^{1-1/\Theta(k^2)}$ rounds in the
CONGEST model. For $2\leq k\leq 5$, faster Monte-Carlo algorithms do exist,
running in $O(n^{1-1/k})$ rounds, based on upper bounding the number of
messages to be forwarded, and aborting search sub-routines for which this
number exceeds certain thresholds. We investigate the possible extension of
these threshold-based algorithms, for the detection of larger cycles. We first
show that, for every $k\geq 6$, there exists an infinite family of graphs
containing a $2k$-cycle for which any threshold-based algorithm fails to detect
that cycle. Hence, in particular, neither $C_{12}$-freeness nor
$C_{14}$-freeness can be decided by threshold-based algorithms. Nevertheless,
we show that $\{C_{12},C_{14}\}$-freeness can still be decided by a
threshold-based algorithm, running in $O(n^{1-1/7})= O(n^{0.857\dots})$ rounds,
which is faster than using the generic algorithm, which would run in
$O(n^{1-1/22})\simeq O(n^{0.954\dots})$ rounds. Moreover, we exhibit an
infinite collection of families of cycles such that threshold-based algorithms
can decide $\mathcal{F}$-freeness for every $\mathcal{F}$ in this collection.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improved Analysis of two Algorithms for Min-Weighted Sum Bin Packing</title>
    <link href="http://arxiv.org/abs/2304.02498"/>
    <id>http://arxiv.org/abs/2304.02498</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sagnol_G/0/1/0/all/0/1&quot;&gt;Guillaume Sagnol&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the Min-Weighted Sum Bin Packing problem, a variant of the classical
Bin Packing problem in which items have a weight, and each item induces a cost
equal to its weight multiplied by the index of the bin in which it is packed.
This is in fact equivalent to a batch scheduling problem that arises in many
fields of applications such as appointment scheduling or warehouse logistics.
We give improved lower and upper bounds on the approximation ratio of two
simple algorithms for this problem. In particular, we show that the
knapsack-batching algorithm, which iteratively solves knapsack problems over
the set of remaining items to pack the maximal weight in the current bin, has
an approximation ratio of at most 17/10.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A Simple 1.5-Approximation Algorithm for a Wide Range of Max-SMTI Generalizations</title>
    <link href="http://arxiv.org/abs/2304.02558"/>
    <id>http://arxiv.org/abs/2304.02558</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Csaji_G/0/1/0/all/0/1&quot;&gt;Gergely Cs&amp;#xe1;ji&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We give a simple approximation algorithm for a common generalization of many
previously studied extensions of the stable matching problem with ties. These
generalizations include the existence of critical vertices in the graph,
amongst whom we must match as much as possible, free edges, that cannot be
blocking edges and $\Delta$-stabilities, which mean that for an edge to block,
the improvement should be large enough on one or both sides. We also introduce
other notions to generalize these even further, which allows our framework to
capture many existing and future applications. We show that our edge
duplicating technique allows us to treat these different types of
generalizations simultaneously, while also making the algorithm, the proofs and
the analysis much simpler and shorter then in previous approaches. In
particular, we answer an open question by \cite{socialstable} about the
existence of a $\frac{3}{2}$-approximation algorithm for the \smti\ problem
with free edges. This demonstrates well that this technique can grasp the
underlying essence of these problems quite well and have the potential to be
able to solve countless future applications as well.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Query lower bounds for log-concave sampling</title>
    <link href="http://arxiv.org/abs/2304.02599"/>
    <id>http://arxiv.org/abs/2304.02599</id>
    <updated>2023-04-06T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chewi_S/0/1/0/all/0/1&quot;&gt;Sinho Chewi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pont_J/0/1/0/all/0/1&quot;&gt;Jaume de Dios Pont&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jerry Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Chen Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Narayanan_S/0/1/0/all/0/1&quot;&gt;Shyam Narayanan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Log-concave sampling has witnessed remarkable algorithmic advances in recent
years, but the corresponding problem of proving lower bounds for this task has
remained elusive, with lower bounds previously known only in dimension one. In
this work, we establish the following query lower bounds: (1) sampling from
strongly log-concave and log-smooth distributions in dimension $d\ge 2$
requires $\Omega(\log \kappa)$ queries, which is sharp in any constant
dimension, and (2) sampling from Gaussians in dimension $d$ (hence also from
general log-concave and log-smooth distributions in dimension $d$) requires
$\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ queries, which is nearly sharp
for the class of Gaussians. Here $\kappa$ denotes the condition number of the
target distribution. Our proofs rely upon (1) a multiscale construction
inspired by work on the Kakeya conjecture in harmonic analysis, and (2) a novel
reduction that demonstrates that block Krylov algorithms are optimal for this
problem, as well as connections to lower bound techniques based on Wishart
matrices developed in the matrix-vector query literature.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: The Planted $k$-SUM Problem: Algorithms, Lower Bounds, Hardness Amplification, and Cryptography</title>
    <link href="http://arxiv.org/abs/2304.01787"/>
    <id>http://arxiv.org/abs/2304.01787</id>
    <updated>2023-04-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saga_S/0/1/0/all/0/1&quot;&gt;Sagnik Saga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartzbach_N/0/1/0/all/0/1&quot;&gt;Nikolaj I. Schwartzbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasudevan_P/0/1/0/all/0/1&quot;&gt;Prashant Nalini Vasudevan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the average-case $k$-SUM problem, given $r$ integers chosen uniformly at
random from $\{0,\ldots,M-1\}$, the objective is to find a set of $k$ numbers
that sum to $0$ modulo $M$ (this set is called a solution). In the related
$k$-XOR problem, given $k$ uniformly random Boolean vectors of length
$\log{M}$, the objective is to find a set of $k$ of them whose bitwise-XOR is
the all-zero vector. Both of these problems have widespread applications in the
study of fine-grained complexity and cryptanalysis.
&lt;/p&gt;
&lt;p&gt;The feasibility and complexity of these problems depends on the relative
values of $k$, $r$, and $M$. The dense regime of $M \leq r^k$, where solutions
exist with high probability, is quite well-understood and we have several
non-trivial algorithms and hardness conjectures here. Much less is known about
the sparse regime of $M\gg r^k$, where solutions are unlikely to exist. The
best answers we have for many fundamental questions here are limited to
whatever carries over from the dense or worst-case settings.
&lt;/p&gt;
&lt;p&gt;We study the planted $k$-SUM and $k$-XOR problems in the sparse regime. In
these problems, a random solution is planted in a randomly generated instance
and has to be recovered. As $M$ increases past $r^k$, these planted solutions
tend to be the only solutions with increasing probability, potentially becoming
easier to find. We show several results about the complexity and applications
of these problems.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Quantum Public-Key Encryption with Tamper-Resilient Public Keys from One-Way Functions</title>
    <link href="http://arxiv.org/abs/2304.01800"/>
    <id>http://arxiv.org/abs/2304.01800</id>
    <updated>2023-04-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kitagawa_F/0/1/0/all/0/1&quot;&gt;Fuyuki Kitagawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Morimae_T/0/1/0/all/0/1&quot;&gt;Tomoyuki Morimae&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Nishimaki_R/0/1/0/all/0/1&quot;&gt;Ryo Nishimaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yamakawa_T/0/1/0/all/0/1&quot;&gt;Takashi Yamakawa&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We construct quantum public-key encryption from one-way functions. In our
construction, public keys are quantum, but ciphertexts are classical. Quantum
public-key encryption from one-way functions (or weaker primitives such as
pseudorandom function-like states) are also proposed in some recent works
[Morimae-Yamakawa, eprint:2022/1336; Coladangelo, eprint:2023/282;
Grilo-Sattath-Vu, eprint:2023/345; Barooti-Malavolta-Walter, eprint:2023/306].
However, they have a huge drawback: they are secure only when quantum public
keys can be transmitted to the sender (who runs the encryption algorithm)
without being tampered with by the adversary, which seems to require
unsatisfactory physical setup assumptions such as secure quantum channels. Our
construction is free from such a drawback: it guarantees the secrecy of the
encrypted messages even if we assume only unauthenticated quantum channels.
Thus, the encryption is done with adversarially tampered quantum public keys.
Our construction based only on one-way functions is the first quantum
public-key encryption that achieves the goal of classical public-key
encryption, namely, to establish secure communication over insecure channels.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Minimizing Running Buffers for Tabletop Object Rearrangement: Complexity, Fast Algorithms, and Applications</title>
    <link href="http://arxiv.org/abs/2304.01764"/>
    <id>http://arxiv.org/abs/2304.01764</id>
    <updated>2023-04-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_K/0/1/0/all/0/1&quot;&gt;Kai Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1&quot;&gt;Si Wei Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1&quot;&gt;Baichuan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Jingjin Yu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;For rearranging objects on tabletops with overhand grasps, temporarily
relocating objects to some buffer space may be necessary. This raises the
natural question of how many simultaneous storage spaces, or &quot;running buffers&quot;,
are required so that certain classes of tabletop rearrangement problems are
feasible. In this work, we examine the problem for both labeled and unlabeled
settings. On the structural side, we observe that finding the minimum number of
running buffers (MRB) can be carried out on a dependency graph abstracted from
a problem instance, and show that computing MRB is NP-hard. We then prove that
under both labeled and unlabeled settings, even for uniform cylindrical
objects, the number of required running buffers may grow unbounded as the
number of objects to be rearranged increases. We further show that the bound
for the unlabeled case is tight. On the algorithmic side, we develop effective
exact algorithms for finding MRB for both labeled and unlabeled tabletop
rearrangement problems, scalable to over a hundred objects under very high
object density. More importantly, our algorithms also compute a sequence
witnessing the computed MRB that can be used for solving object rearrangement
tasks. Employing these algorithms, empirical evaluations reveal that random
labeled and unlabeled instances, which more closely mimics real-world setups,
generally have fairly small MRBs. Using real robot experiments, we demonstrate
that the running buffer abstraction leads to state-of-the-art solutions for
in-place rearrangement of many objects in tight, bounded workspace.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: A statistical framework for analyzing shape in a time series of random geometric objects</title>
    <link href="http://arxiv.org/abs/2304.01984"/>
    <id>http://arxiv.org/abs/2304.01984</id>
    <updated>2023-04-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Delft_A/0/1/0/all/0/1&quot;&gt;Anne van Delft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Blumberg_A/0/1/0/all/0/1&quot;&gt;Andrew J. Blumberg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce a new framework to analyze shape descriptors that capture the
geometric features of an ensemble of point clouds. At the core of our approach
is the point of view that the data arises as sampled recordings from a metric
space-valued stochastic process, possibly of nonstationary nature, thereby
integrating geometric data analysis into the realm of functional time series
analysis. We focus on the descriptors coming from topological data analysis.
Our framework allows for natural incorporation of spatial-temporal dynamics,
heterogeneous sampling, and the study of convergence rates. Further, we derive
complete invariants for classes of metric space-valued stochastic processes in
the spirit of Gromov, and relate these invariants to so-called ball volume
processes. Under mild dependence conditions, a weak invariance principle in
$D([0,1]\times [0,\mathscr{R}])$ is established for sequential empirical
versions of the latter, assuming the probabilistic structure possibly changes
over time. Finally, we use this result to introduce novel test statistics for
topological change, which are distribution free in the limit under the
hypothesis of stationarity.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Distribution Testing Under the Parity Trace</title>
    <link href="http://arxiv.org/abs/2304.01374"/>
    <id>http://arxiv.org/abs/2304.01374</id>
    <updated>2023-04-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinto_R/0/1/0/all/0/1&quot;&gt;Renato Ferreira Pinto Jr.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harms_N/0/1/0/all/0/1&quot;&gt;Nathaniel Harms&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Distribution testing is a fundamental statistical task with many
applications, but we are interested in a variety of problems where systematic
mislabelings of the sample prevent us from applying the existing theory. To
apply distribution testing to these problems, we introduce distribution testing
under the parity trace, where the algorithm receives an ordered sample $S$ that
reveals only the least significant bit of each element. This abstraction
reveals connections between the following three problems of interest, allowing
new upper and lower bounds:
&lt;/p&gt;
&lt;p&gt;1. In distribution testing with a confused collector, the collector of the
sample may be incapable of distinguishing between nearby elements of a domain
(e.g. a machine learning classifier). We prove bounds for distribution testing
with a confused collector on domains structured as a cycle or a path.
&lt;/p&gt;
&lt;p&gt;2. Recent work on the fundamental testing vs. learning question established
tight lower bounds on distribution-free sample-based property testing by
reduction from distribution testing, but the tightness is limited to symmetric
properties. The parity trace allows a broader family of equivalences to
non-symmetric properties, while recovering and strengthening many of the
previous results with a different technique.
&lt;/p&gt;
&lt;p&gt;3. We give the first results for property testing in the well-studied trace
reconstruction model, where the goal is to test whether an unknown string $x$
satisfies some property or is far from satisfying that property, given only
independent random traces of $x$.
&lt;/p&gt;
&lt;p&gt;Our main technical result is a tight bound of $\widetilde
\Theta\left((n/\epsilon)^{4/5} + \sqrt n/\epsilon^2\right)$ for testing
uniformity of distributions over $[n]$ under the parity trace, leading also to
results for the problems above.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Tight Space Lower Bound for Pseudo-Deterministic Approximate Counting</title>
    <link href="http://arxiv.org/abs/2304.01438"/>
    <id>http://arxiv.org/abs/2304.01438</id>
    <updated>2023-04-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grossman_O/0/1/0/all/0/1&quot;&gt;Ofer Grossman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1&quot;&gt;Meghal Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sellke_M/0/1/0/all/0/1&quot;&gt;Mark Sellke&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We investigate one of the most basic problems in streaming algorithms:
approximating the number of elements in the stream. In 1978, Morris famously
gave a randomized algorithm achieving a constant-factor approximation error for
streams of length at most N in space $O(\log \log N)$. We investigate the
pseudo-deterministic complexity of the problem and prove a tight $\Omega(\log
N)$ lower bound, thus resolving a problem of
Goldwasser-Grossman-Mohanty-Woodruff.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A greedy approach for increased vehicle utilization in ridesharing networks</title>
    <link href="http://arxiv.org/abs/2304.01225"/>
    <id>http://arxiv.org/abs/2304.01225</id>
    <updated>2023-04-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makhdomi_A/0/1/0/all/0/1&quot;&gt;Aqsa Ashraf Makhdomi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gillani_I/0/1/0/all/0/1&quot;&gt;Iqra Altaf Gillani&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In recent years, ridesharing platforms have become a prominent mode of
transportation for the residents of urban areas. As a fundamental problem,
route recommendation for these platforms is vital for their sustenance. The
works done in this direction have recommended routes with higher passenger
demand. Despite the existing works, statistics have suggested that these
services cause increased greenhouse emissions compared to private vehicles as
they roam around in search of riders. This analysis provides finer details
regarding the functionality of ridesharing systems and it reveals that in the
face of their boom, they have not utilized the vehicle capacity efficiently. We
propose to overcome the above limitations and recommend routes that will fetch
multiple passengers simultaneously which will result in increased vehicle
utilization and thereby decrease the effect of these systems on the
environment. As route recommendation is NP-hard, we propose a k-hop-based
sliding window approximation algorithm that reduces the search space from
entire road network to a window. We further demonstrate that maximizing
expected demand is submodular and greedy algorithms can be used to optimize our
objective function within a window. We evaluate our proposed model on
real-world datasets and experimental results demonstrate superior performance
by our proposed model.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Randomly Punctured Reed-Solomon Codes Achieve the List Decoding Capacity over Polynomial-Size Alphabets</title>
    <link href="http://arxiv.org/abs/2304.01403"/>
    <id>http://arxiv.org/abs/2304.01403</id>
    <updated>2023-04-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1&quot;&gt;Zeyu Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zihan Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper shows that, with high probability, randomly punctured Reed-Solomon
codes over fields of polynomial size achieve the list decoding capacity. More
specifically, we prove that for any $\epsilon&amp;gt;0$ and $R\in (0,1)$, with high
probability, randomly punctured Reed-Solomon codes of block length $n$ and rate
$R$ are $\left(1-R-\epsilon, O({1}/{\epsilon})\right)$ list decodable over
alphabets of size at least $2^{\mathrm{poly}(1/\epsilon)}n^2$. This extends the
recent breakthrough of Brakensiek, Gopi, and Makam (STOC 2023) that randomly
punctured Reed-Solomon codes over fields of exponential size attain the
generalized Singleton bound of Shangguan and Tamo (STOC 2020).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A $d^{1/2+o(1)}$ Monotonicity Tester for Boolean Functions on $d$-Dimensional Hypergrids</title>
    <link href="http://arxiv.org/abs/2304.01416"/>
    <id>http://arxiv.org/abs/2304.01416</id>
    <updated>2023-04-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Black_H/0/1/0/all/0/1&quot;&gt;Hadley Black&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakrabarty_D/0/1/0/all/0/1&quot;&gt;Deeparnab Chakrabarty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seshadhri_C/0/1/0/all/0/1&quot;&gt;C. Seshadhri&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Monotonicity testing of Boolean functions on the hypergrid, $f:[n]^d \to
\{0,1\}$, is a classic topic in property testing. Determining the non-adaptive
complexity of this problem is an important open question. For arbitrary $n$,
[Black-Chakrabarty-Seshadhri, SODA 2020] describe a tester with query
complexity $\widetilde{O}(\varepsilon^{-4/3}d^{5/6})$. This complexity is
independent of $n$, but has a suboptimal dependence on $d$. Recently,
[Braverman-Khot-Kindler-Minzer, ITCS 2023] and [Black-Chakrabarty-Seshadhri,
STOC 2023] describe $\widetilde{O}(\varepsilon^{-2} n^3\sqrt{d})$ and
$\widetilde{O}(\varepsilon^{-2} n\sqrt{d})$-query testers, respectively. These
testers have an almost optimal dependence on $d$, but a suboptimal polynomial
dependence on $n$.
&lt;/p&gt;
&lt;p&gt;In this paper, we describe a non-adaptive, one-sided monotonicity tester with
query complexity $O(\varepsilon^{-2} d^{1/2 + o(1)})$, independent of $n$. Up
to the $d^{o(1)}$-factors, our result resolves the non-adaptive complexity of
monotonicity testing for Boolean functions on hypergrids. The independence of
$n$ yields a non-adaptive, one-sided $O(\varepsilon^{-2} d^{1/2 + o(1)})$-query
monotonicity tester for Boolean functions $f:\mathbb{R}^d \to \{0,1\}$
associated with an arbitrary product measure.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Minimum Cost Flow in the CONGEST Model</title>
    <link href="http://arxiv.org/abs/2304.01600"/>
    <id>http://arxiv.org/abs/2304.01600</id>
    <updated>2023-04-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vos_T/0/1/0/all/0/1&quot;&gt;Tijn de Vos&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the CONGEST model on a network with $n$ nodes, $m$ edges,
diameter $D$, and integer costs and capacities bounded by $\text{poly} n$. In
this paper, we show how to find an exact solution to the minimum cost flow
problem in $n^{1/2+o(1)}(\sqrt{n}+D)$ rounds, improving the state of the art
algorithm with running time $m^{3/7+o(1)}(\sqrt nD^{1/4}+D)$ [Forster et al.
FOCS 2021], which only holds for the special case of unit capacity graphs. For
certain graphs, we achieve even better results. In particular, for planar
graphs, expander graphs, $n^{o(1)}$-genus graphs, $n^{o(1)}$-treewidth graphs,
and excluded-minor graphs our algorithm takes $n^{1/2+o(1)}D$ rounds. We obtain
this result by combining recent results on Laplacian solvers in the CONGEST
model [Forster et al. FOCS 2021, Anagnostides et al. DISC 2022] with a CONGEST
implementation of the LP solver of Lee and Sidford [FOCS 2014], and finally
show that we can round the approximate solution to an exact solution. Our
algorithm solves certain linear programs, that generalize minimum cost flow, up
to additive error $\epsilon$ in $n^{1/2+o(1)}(\sqrt{n}+D)\log^3 (1/\epsilon)$
rounds.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Algorithms for the Generalized Poset Sorting Problem</title>
    <link href="http://arxiv.org/abs/2304.01623"/>
    <id>http://arxiv.org/abs/2304.01623</id>
    <updated>2023-04-05T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Shaofeng H.-C. Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenqian Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yubo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yuhao Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider a generalized poset sorting problem (GPS), in which we are given
a query graph $G = (V, E)$ and an unknown poset $\mathcal{P}(V, \prec)$ that is
defined on the same vertex set $V$, and the goal is to make as few queries as
possible to edges in $G$ in order to fully recover $\mathcal{P}$, where each
query $(u, v)$ returns the relation between $u, v$, i.e., $u \prec v$, $v \prec
u$ or $u \not \sim v$. This generalizes both the poset sorting problem [Faigle
et al., SICOMP 88] and the generalized sorting problem [Huang et al., FOCS 11].
&lt;/p&gt;
&lt;p&gt;We give algorithms with $\tilde{O}(n\cdot \mathrm{poly}(k))$ query complexity
when $G$ is a complete bipartite graph or $G$ is stochastic under the \ER
model, where $k$ is the \emph{width} of the poset, and these generalize
[Daskalakis et al., SICOMP 11] which only studies complete graph $G$. Both
results are based on a unified framework that reduces the poset sorting to
partitioning the vertices with respect to a given pivot element, which may be
of independent interest.
&lt;/p&gt;
&lt;p&gt;Our study of GPS also leads to a new $\tilde{O}(n^{1 - 1 / (2W)})$
competitive ratio for the so-called weighted generalized sorting problem where
$W$ is the number of distinct weights in the query graph. This problem was
considered as an open question in [Charikar et al., JCSS 02], and our result
makes important progress as it yields the first nontrivial $\tilde{O}(n)$ ratio
for general weighted query graphs (and better ratio if $W$ is bounded). We
obtain this via an $\tilde{O}(nk + n^{1.5})$ query complexity algorithm for the
case where every edge in $G$ is guaranteed to be comparable in the poset, which
generalizes the state-of-the-art $\tilde{O}(n^{1.5})$ bound for generalized
sorting [Huang et al., FOCS 11].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


</feed>
