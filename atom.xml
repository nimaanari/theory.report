<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Theory of Computing Report</title>
  <link rel="self" href=""/>
  <link href=""/>
  <id></id>
  <updated></updated>
  <generator uri="http://feedreader.github.io/">Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]</generator>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Windows on Theory: Quick reminders: masters, postdocs, faculty, etc.</title>
    <link href="https://windowsontheory.org/2022/09/14/quick-reminders-masters-postdocs-faculty-etc/"/>
    <id>http://windowsontheory.org/?p=8452</id>
    <updated>2022-09-14T13:50:02+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;As we&amp;#8217;re getting closer to the season when undergraduate students are considering graduate school, and graduate students are considering the next steps such as postdoc or faculty positions,  I wanted to remind people of two resources for such positions: the &lt;a href=&quot;https://cstheory-jobs.org/&quot;&gt;TCS jobs&lt;/a&gt; and &lt;a href=&quot;https://www.cs.princeton.edu/~smattw/masters/masters.html&quot;&gt;crowd-sourced masters&lt;/a&gt; pages. &lt;/p&gt;



&lt;p&gt;The process and market for both graduate studies and faculty positions (at least in the US) is fairly standard, with more or less a common timeline, and general ideas of where to look for positions (universities&amp;#8217; websites are always a good start, as are the websites of &lt;a href=&quot;https://jobs.acm.org/jobs/products/&quot;&gt;ACM&lt;/a&gt; and &lt;a href=&quot;https://cra.org/ads/&quot;&gt;CRA&lt;/a&gt;).  Even so, it&amp;#8217;s not always clear which areas a university is searching for at any given year, and also these resources are very US-centric, while many great places are located outside the US.&lt;/p&gt;



&lt;p&gt;The &lt;strong&gt;postdoc market&lt;/strong&gt; is much more &amp;#8220;ad hoc&amp;#8221;. Some places such as the &lt;a href=&quot;https://simons.berkeley.edu/programs/participate&quot;&gt;Simons institute&lt;/a&gt; and the &lt;a href=&quot;https://www.ias.edu/math/csdm/postdocs&quot;&gt;IAS&lt;/a&gt; search for postdocs yearly and have several positions. (Our own &lt;a href=&quot;https://www.harvard.edu/kempner-institute/&quot;&gt;Kempner Institute&lt;/a&gt; will also be having regular searches after it launches this year.)  But in many other cases, postdoc positions are with an individual researcher that might have availability only every few years, which makes it harder for candidates to find out about this.  For such positions, the &lt;a href=&quot;https://cstheory-jobs.org/&quot;&gt;&lt;strong&gt;Theoretical Computer Science jobs&lt;/strong&gt;&lt;/a&gt; page is a great way to both advertise any position you have to offer, as well as find out about opportunities.  Please post any postdoc or faculty positions relevant to TCS in your institution, as well as advertise it to your students as a place to look for jobs.&lt;/p&gt;



&lt;p&gt;Finding information about &lt;strong&gt;research-oriented Masters programs&lt;/strong&gt; is also sometimes challenging. In the US it&amp;#8217;s common for students to apply straight to a Ph.D from undergraduate, and Masters programs are often intended more for professional development. But, as I &lt;a href=&quot;https://windowsontheory.org/2018/02/20/research-masters/&quot;&gt;wrote in the past,&lt;/a&gt; &lt;em&gt;research-oriented&lt;/em&gt; Masters programs can actually be a great fit for many students. A Ph.D is a huge commitment on both the student and advisor side. If you have not had a chance to do research during your undergraduate studies,  it may be better to start with a Masters before taking such a commitment. Some research Masters programs do not charge any tuition, and several offer a stipend. To post and look for such opportunities, see the &lt;a href=&quot;https://www.cs.princeton.edu/~smattw/masters/masters.html&quot;&gt;&lt;strong&gt;crowdsourced TCS research masters website&lt;/strong&gt;&lt;/a&gt;, managed by Aviad Rubinstein and Matt Weinberg.&lt;/p&gt;



&lt;p&gt;If there are other great resources or opportunities, please post them in the comments!&lt;/p&gt;



&lt;p&gt;In particular, the resources above are geared for theoretical CS. If you have suggestions of analogous resources for other fields, please post them as well.&lt;/p&gt;



&lt;p&gt; &lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Boaz Barak&lt;/p&gt;
  </content>
    <author>
      <name>Windows on Theory</name>
      <uri>https://windowsontheory.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: On bounded depth proofs for Tseitin formulas on the grid; revisited</title>
    <link href="http://arxiv.org/abs/2209.05839"/>
    <id>http://arxiv.org/abs/2209.05839</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+H%5Cr%7Ba%7Dstad_J/0/1/0/all/0/1&quot;&gt;Johan H&amp;#xe5;stad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Risse_K/0/1/0/all/0/1&quot;&gt;Kilian Risse&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study Frege proofs using depth-$d$ Boolean formulas for the Tseitin
contradiction on $n \times n$ grids. We prove that if each line in the proof is
of size $M$ then the number of lines is exponential in $n/(\log M)^{O(d)}$.
This strengthens a recent result of Pitassi et al. [PRT22]. The key technical
step is a multi-switching lemma extending the switching lemma of H\r{a}stad
[H\r{a}s20] for a space of restrictions related to the Tseitin contradiction.
The strengthened lemma also allows us to improve the lower bound for standard
proof size of bounded depth Frege refutations from exponential in $\tilde
\Omega (n^{1/59d})$ to exponential in $\tilde \Omega (n^{1/(2d-1)})$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: What is a combinatorial interpretation?</title>
    <link href="http://arxiv.org/abs/2209.06142"/>
    <id>http://arxiv.org/abs/2209.06142</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pak_I/0/1/0/all/0/1&quot;&gt;Igor Pak&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this survey we discuss the notion of combinatorial interpretation in the
context of Algebraic Combinatorics and related areas. We approach the subject
from the Computational Complexity perspective. We review many examples, state a
workable definition, discuss many open problems, and present recent results on
the subject.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Topological Measures for Pattern quantification of Impact Centers in Piezo Vibration Striking Treatment (PVST)</title>
    <link href="http://arxiv.org/abs/2209.05531"/>
    <id>http://arxiv.org/abs/2209.05531</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yesilli_M/0/1/0/all/0/1&quot;&gt;Melih C. Yesilli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chumley_M/0/1/0/all/0/1&quot;&gt;Max M. Chumley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jisheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khasawneh_F/0/1/0/all/0/1&quot;&gt;Firas A. Khasawneh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yang Guo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Surface texture influences wear and tribological properties of manufactured
parts, and it plays a critical role in end-user products. Therefore,
quantifying the order or structure of a manufactured surface provides important
information on the quality and life expectancy of the product. Although texture
can be intentionally introduced to enhance aesthetics or to satisfy a design
function, sometimes it is an inevitable byproduct of surface treatment
processes such as Piezo Vibration Striking Treatment (PVST). Measures of order
for surfaces have been characterized using statistical, spectral, and geometric
approaches. For nearly hexagonal lattices, topological tools have also been
used to measure the surface order. This paper utilizes tools from Topological
Data Analysis for quantifying the impact centers&#39; pattern in PVST. We compute
measures of order based on optical digital microscope images of surfaces
treated using PVST. These measures are applied to the grid obtained from
estimating the centers of tool impacts, and they quantify the grid&#39;s deviations
from the nominal one. Our results show that TDA provides a convenient framework
for the characterization of pattern type that bypasses some limitations of
existing tools such as difficult manual processing of the data and the need for
an expert user to analyze and interpret the surface images.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Rectilinear Convex Hull of Points in 3D</title>
    <link href="http://arxiv.org/abs/2209.06020"/>
    <id>http://arxiv.org/abs/2209.06020</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Lantero_P/0/1/0/all/0/1&quot;&gt;Pablo P&amp;#xe9;rez-Lantero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seara_C/0/1/0/all/0/1&quot;&gt;Carlos Seara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urrutia_J/0/1/0/all/0/1&quot;&gt;Jorge Urrutia&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $P$ be a set of $n$ points in $\mathbb{R}^3$ in general position, and let
$RCH(P)$ be the rectilinear convex hull of $P$. In this paper we obtain an
optimal $O(n\log n)$-time and $O(n)$-space algorithm to compute $RCH(P)$. We
also obtain an efficient $O(n\log^2 n)$-time and $O(n\log n)$-space algorithm
to compute and maintain the set of vertices of the rectilinear convex hull of
$P$ as we rotate $\mathbb R^3$ around the $z$-axis. Finally we study some
properties of the rectilinear convex hulls of point sets in $\mathbb{R}^3$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Recovery from Non-Decomposable Distance Oracles</title>
    <link href="http://arxiv.org/abs/2209.05676"/>
    <id>http://arxiv.org/abs/2209.05676</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zhuangfei Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xinda Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1&quot;&gt;David P. Woodruff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hongyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shufan Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A line of work has looked at the problem of recovering an input from distance
queries. In this setting, there is an unknown sequence $s \in \{0,1\}^{\leq
n}$, and one chooses a set of queries $y \in \{0,1\}^{\mathcal{O}(n)}$ and
receives $d(s,y)$ for a distance function $d$. The goal is to make as few
queries as possible to recover $s$. Although this problem is well-studied for
decomposable distances, i.e., distances of the form $d(s,y) = \sum_{i=1}^n
f(s_i, y_i)$ for some function $f$, which includes the important cases of
Hamming distance, $\ell_p$-norms, and $M$-estimators, to the best of our
knowledge this problem has not been studied for non-decomposable distances, for
which there are important special cases such as edit distance, dynamic time
warping (DTW), Frechet distance, earth mover&#39;s distance, and so on. We initiate
the study and develop a general framework for such distances. Interestingly,
for some distances such as DTW or Frechet, exact recovery of the sequence $s$
is provably impossible, and so we show by allowing the characters in $y$ to be
drawn from a slightly larger alphabet this then becomes possible. In a number
of cases we obtain optimal or near-optimal query complexity. We also study the
role of adaptivity for a number of different distance functions. One motivation
for understanding non-adaptivity is that the query sequence can be fixed and
the distances of the input to the queries provide a non-linear embedding of the
input, which can be used in downstream applications involving, e.g., neural
networks for natural language processing.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Unsplittable Euclidean Capacitated Vehicle Routing: A $(2+\epsilon)$-Approximation Algorithm</title>
    <link href="http://arxiv.org/abs/2209.05520"/>
    <id>http://arxiv.org/abs/2209.05520</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grandoni_F/0/1/0/all/0/1&quot;&gt;Fabrizio Grandoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathieu_C/0/1/0/all/0/1&quot;&gt;Claire Mathieu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hang Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the unsplittable capacitated vehicle routing problem, we are given a
metric space with a vertex called depot and a set of vertices called terminals.
Each terminal is associated with a positive demand between 0 and 1. The goal is
to find a minimum length collection of tours starting and ending at the depot
such that the demand of each terminal is covered by a single tour (i.e., the
demand cannot be split), and the total demand of the terminals in each tour
does not exceed the capacity of 1.
&lt;/p&gt;
&lt;p&gt;Our main result is a polynomial-time $(2+\epsilon)$-approximation algorithm
for this problem in the two-dimensional Euclidean plane, i.e., for the special
case where the terminals and the depot are associated with points in the
Euclidean plane and their distances are defined accordingly. This improves on
recent work by Blauth, Traub, and Vygen [IPCO&#39;21] and Friggstad, Mousavi,
Rahgoshay, and Salavatipour [IPCO&#39;22].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A Note on the Quickest Minimum Cost Transshipment Problem</title>
    <link href="http://arxiv.org/abs/2209.05558"/>
    <id>http://arxiv.org/abs/2209.05558</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skutella_M/0/1/0/all/0/1&quot;&gt;Martin Skutella&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Klinz and Woeginger (1995) prove that the minimum cost quickest flow problem
is NP-hard. On the other hand, the quickest minimum cost flow problem can be
solved efficiently via a straightforward reduction to the quickest flow problem
without costs. More generally, we show how the quickest minimum cost
transshipment problem can be reduced to the efficiently solvable quickest
transshipment problem, thus adding another mosaic tile to the rich complexity
landscape of flows over time.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: An Improved Lower Bound for Matroid Intersection Prophet Inequalities</title>
    <link href="http://arxiv.org/abs/2209.05614"/>
    <id>http://arxiv.org/abs/2209.05614</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxena_R/0/1/0/all/0/1&quot;&gt;Raghuvansh R. Saxena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velusamy_S/0/1/0/all/0/1&quot;&gt;Santhoshini Velusamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinberg_S/0/1/0/all/0/1&quot;&gt;S. Matthew Weinberg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider prophet inequalities subject to feasibility constraints that are
the intersection of $q$ matroids. The best-known algorithms achieve a
$\Theta(q)$-approximation, even when restricted to instances that are the
intersection of $q$ partition matroids, and with i.i.d.~Bernoulli random
variables. The previous best-known lower bound is $\Theta(\sqrt{q})$ due to a
simple construction of [Kleinberg-Weinberg STOC 2012] (which uses
i.i.d.~Bernoulli random variables, and writes the construction as the
intersection of partition matroids).
&lt;/p&gt;
&lt;p&gt;We establish an improved lower bound of $q^{1/2+\Omega(1/\log \log q)}$ by
writing the construction of [Kleinberg-Weinberg STOC 2012] as the intersection
of asymptotically fewer partition matroids. We accomplish this via an improved
upper bound on the product dimension of a graph with $p^p$ disjoint cliques of
size $p$, using recent techniques developed in [Alon-Alweiss European Journal
of Combinatorics 2020].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Space Optimal Vertex Cover in Dynamic Streams</title>
    <link href="http://arxiv.org/abs/2209.05623"/>
    <id>http://arxiv.org/abs/2209.05623</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naidu_K/0/1/0/all/0/1&quot;&gt;Kheeran K. Naidu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_V/0/1/0/all/0/1&quot;&gt;Vihan Shah&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We optimally resolve the space complexity for the problem of finding an
$\alpha$-approximate minimum vertex cover ($\alpha$MVC) in dynamic graph
streams. We give a randomised algorithm for $\alpha$MVC which uses
$O(n^2/\alpha^2)$ bits of space matching Dark and Konrad&#39;s lower bound [CCC
2020] up to constant factors. By computing a random greedy matching, we
identify `easy&#39; instances of the problem which can trivially be solved by
returning the entire vertex set. The remaining `hard&#39; instances, then have
sparse induced subgraphs which we exploit to get our space savings and solve
$\alpha$MVC.
&lt;/p&gt;
&lt;p&gt;Achieving this type of optimality result is crucial for providing a complete
understanding of a problem, and it has been gaining interest within the dynamic
graph streaming community. For connectivity, Nelson and Yu [SODA 2019] improved
the lower bound showing that $\Omega(n \log^3 n)$ bits of space is necessary
while Ahn, Guha, and McGregor [SODA 2012] have shown that $O(n \log^3 n)$ bits
is sufficient. For finding an $\alpha$-approximate maximum matching, the upper
bound was improved by Assadi and Shah [ITCS 2022] showing that
$O(n^2/\alpha^3)$ bits is sufficient while Dark and Konrad [CCC 2020] have
shown that $\Omega(n^2/\alpha^3)$ bits is necessary. The space complexity,
however, remains unresolved for many other dynamic graph streaming problems
where further improvements can still be made. \end{abstract}
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Fast Algorithms for Monotone Lower Subsets of Kronecker Least Squares Problems</title>
    <link href="http://arxiv.org/abs/2209.05662"/>
    <id>http://arxiv.org/abs/2209.05662</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Malik_O/0/1/0/all/0/1&quot;&gt;Osman Asif Malik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yiming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cheng_N/0/1/0/all/0/1&quot;&gt;Nuojin Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Becker_S/0/1/0/all/0/1&quot;&gt;Stephen Becker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Doostan_A/0/1/0/all/0/1&quot;&gt;Alireza Doostan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Narayan_A/0/1/0/all/0/1&quot;&gt;Akil Narayan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Approximate solutions to large least squares problems can be computed
efficiently using leverage score-based row-sketches, but directly computing the
leverage scores, or sampling according to them with naive methods, still
requires an expensive manipulation and processing of the design matrix. In this
paper we develop efficient leverage score-based sampling methods for matrices
with certain Kronecker product-type structure; in particular we consider
matrices that are monotone lower column subsets of Kronecker product matrices.
Our discussion is general, encompassing least squares problems on infinite
domains, in which case matrices formally have infinitely many rows. We briefly
survey leverage score-based sampling guarantees from the numerical linear
algebra and approximation theory communities, and follow this with efficient
algorithms for sampling when the design matrix has Kronecker-type structure.
Our numerical examples confirm that sketches based on exact leverage score
sampling for our class of structured matrices achieve superior residual
compared to approximate leverage score sampling methods.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A Hash Table Without Hash Functions, and How to Get the Most Out of Your Random Bits</title>
    <link href="http://arxiv.org/abs/2209.06038"/>
    <id>http://arxiv.org/abs/2209.06038</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuszmaul_W/0/1/0/all/0/1&quot;&gt;William Kuszmaul&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper considers the basic question of how efficiently can a
constant-time hash table, storing $n$ $\Theta(\log n)$-bit key/value pairs,
make use of its random bits? That is, how many random bits does a hash table
need to offer constant-time operations with probability $1 - 1 / \poly(n)$?
And, if the number of random bits is unrestricted, then what is the
highest-probability guarantee that a hash table can offer?
&lt;/p&gt;
&lt;p&gt;Past work on these questions has been bottlenecked by limitations of the
known families of hash functions. The hash tables that achieve failure
probabilities $1 / \poly(n)$ use at least $\tilde{\Omega}(\log^2 n)$ random
bits, which is the number of random bits needed to create hash functions with
$\tilde{\Omega}(\log n)$-wise independence. And the only hash tables to achieve
failure probabilities less than $1 / 2^{\polylog n}$ require access to
fully-random hash functions -- if the same hash tables are implemented using
the known explicit families of hash functions, their failure probabilities
become $1 / \poly(n)$.
&lt;/p&gt;
&lt;p&gt;To get around these obstacles, we show how to construct a randomized data
structure that has the same guarantees as a hash table, but that \emph{avoids
the direct use of hash functions}. Building on this, we are then able to give
nearly optimal solutions to both problems described above: we construct a hash
table using $\tilde{O}(\log n)$ random bits that achieves failure-probability
$1 / \poly(n)$; and we construct a hash table using $O(n)$ random bits that
achieves failure probability $1 / n^{n^{1 - \epsilon}}$ for an arbitrary
positive constant $\epsilon$.
&lt;/p&gt;
&lt;p&gt;Finally, if the keys/values are $(1 + \Theta(1)) \log n$ bits each, then we
show that the above guarantees can even be achieved by \emph{succinct
dictionaries}, that is, by dictionaries that use space within a $1 + o(1)$
factor of the information-theoretic optimum.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-128 |  PPP-Completeness and Extremal Combinatorics | 

	Romain Bourneuf, 

	Lukáš Folwarczný, 

	Pavel Hubacek, 

	Alon Rosen, 

	Nikolaj Schwartzbach</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/128"/>
    <id>https://eccc.weizmann.ac.il/report/2022/128</id>
    <updated>2022-09-13T17:22:41+00:00</updated>
    <content type="html" xml:lang="en">
    Many classical theorems in combinatorics establish the emergence of substructures within sufficiently large collections of objects. Well-known examples are Ramsey&amp;#39;s theorem on monochromatic subgraphs and the Erdos-Rado sunflower lemma. Implicit versions of the corresponding total search problems are known to be PWPP-hard; here &amp;quot;implicit&amp;quot; means that the collection is represented by a poly-sized circuit inducing an exponentially large number of objects.

We show that several other well-known  theorems from extremal combinatorics - including Erdos-Ko-Rado, Sperner, and Cayley&amp;#39;s formula - give rise to complete problems for PWPP and PPP. This is in contrast to the Ramsey and Erdos-Rado problems, for which establishing inclusion in PWPP has remained elusive. Besides significantly expanding the set of problems that are complete for PWPP and PPP, our work identifies some key properties of combinatorial proofs of existence that can give rise to completeness for these classes.

Our completeness results rely on efficient encodings for which finding collisions allows extracting the desired substructure. These encodings are made possible by the tightness of the bounds for the problems at hand (tighter than what is known for Ramsey&amp;#39;s theorem and the sunflower lemma). Previous techniques for proving bounds in TFNP invariably made use of structured algorithms. Such algorithms are not known to exist for the theorems considered in this work, as their proofs &amp;quot;from the book&amp;quot; are non-constructive.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-127 |  Kolmogorov Complexity Characterizes Statistical Zero Knowledge | 

	Eric Allender, 

	Shuichi Hirahara, 

	Harsha Tirumala</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/127"/>
    <id>https://eccc.weizmann.ac.il/report/2022/127</id>
    <updated>2022-09-13T17:21:12+00:00</updated>
    <content type="html" xml:lang="en">
    We show that a decidable promise problem has a non-interactive statistical zero-knowledge proof system if and only if it is randomly reducible to a promise problem for Kolmogorov-random strings, with a superlogarithmic additive approximation term.  This extends recent work by Saks and Santhanam (CCC 2022).  We build on this to give new characterizations of Statistical Zero Knowledge (SZK), as well as the related classes NISZK_L and SZK_L.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-126 |  An Invitation to the Promise Constraint Satisfaction Problem | 

	Andrei Krokhin, 

	Jakub Opršal</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/126"/>
    <id>https://eccc.weizmann.ac.il/report/2022/126</id>
    <updated>2022-09-13T16:54:09+00:00</updated>
    <content type="html" xml:lang="en">
    The study of the complexity of the constraint satisfaction problem (CSP), centred around the Feder-Vardi Dichotomy Conjecture, has been very prominent in the last two decades. After a long concerted effort and many partial results, the Dichotomy Conjecture has been proved in 2017 independently by Bulatov and Zhuk.

At about the same time, a vast generalisation of CSP, called promise CSP, has started to gain prominence. In this survey, we explain the importance of promise CSP and highlight many new very interesting features that the study of promise CSP has brought to light. The complexity classification quest for the promise CSP is wide open, and we argue that, despite the promise CSP being more general, this quest is rather more accessible to a wide range of researchers than the dichotomy-led study of the CSP has been.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: On Identity Testing and Noncommutative Rank Computation over the Free Skew Field</title>
    <link href="http://arxiv.org/abs/2209.04797"/>
    <id>http://arxiv.org/abs/2209.04797</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arvind_V/0/1/0/all/0/1&quot;&gt;V. Arvind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1&quot;&gt;Abhranil Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosal_U/0/1/0/all/0/1&quot;&gt;Utsab Ghosal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukhopadhyay_P/0/1/0/all/0/1&quot;&gt;Partha Mukhopadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramya_C/0/1/0/all/0/1&quot;&gt;C. Ramya&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The identity testing of rational formulas (RIT) in the free skew field
efficiently reduces to computing the rank of a matrix whose entries are linear
polynomials in noncommuting variables\cite{HW15}. This rank computation problem
has deterministic polynomial-time white-box algorithms \cite{GGOW16, IQS18} and
a randomized polynomial-time algorithm in the black-box setting \cite{DM17}. In
this paper, we propose a new approach for efficient derandomization of
\emph{black-box} RIT. Additionally, we obtain results for matrix rank
computation over the free skew field, and construct efficient linear pencil
representations for a new class of rational expressions. More precisely, we
show the following results:
&lt;/p&gt;
&lt;p&gt;1. Under the hardness assumption that the ABP (algebraic branching program)
complexity of every polynomial identity for the $k\times k$ matrix algebra is
$2^{\Omega(k)}$ \cite{BW05}, we obtain a subexponential-time black-box
algorithm for RIT in almost general setting. This can be seen as the first
&quot;hardness implies derandomization&quot; type theorem for rational formulas.
&lt;/p&gt;
&lt;p&gt;2. We show that the noncommutative rank of any matrix over the free skew
field whose entries have small linear pencil representations can be computed in
deterministic polynomial time. Prior to this, an efficient rank computation was
only known for matrices with noncommutative formulas as entries\cite{GGOW20}.
As special cases of our algorithm, we obtain the first deterministic
polynomial-time algorithms for rank computation of matrices whose entries are
noncommutative ABPs or rational formulas.
&lt;/p&gt;
&lt;p&gt;3. Motivated by the definition given by Bergman\cite{Ber76}, we define a new
class that contains noncommutative ABPs and rational formulas. We obtain a
polynomial-size linear pencil representation for this class. As a by-product,
we obtain a white-box deterministic polynomial-time identity testing algorithm
for the class.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: PPP-Completeness and Extremal Combinatorics</title>
    <link href="http://arxiv.org/abs/2209.04827"/>
    <id>http://arxiv.org/abs/2209.04827</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bourneuf_R/0/1/0/all/0/1&quot;&gt;Romain Bourneuf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Folwarczny_L/0/1/0/all/0/1&quot;&gt;Luk&amp;#xe1;&amp;#x161; Folwarczn&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hubacek_P/0/1/0/all/0/1&quot;&gt;Pavel Hub&amp;#xe1;&amp;#x10d;ek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosen_A/0/1/0/all/0/1&quot;&gt;Alon Rosen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartzbach_N/0/1/0/all/0/1&quot;&gt;Nikolaj Ignatieff Schwartzbach&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Many classical theorems in combinatorics establish the emergence of
substructures within sufficiently large collections of objects. Well-known
examples are Ramsey&#39;s theorem on monochromatic subgraphs and the Erd\H{o}s-Rado
sunflower lemma. Implicit versions of the corresponding total search problems
are known to be PWPP-hard; here &quot;implici&quot; means that the collection is
represented by a poly-sized circuit inducing an exponentially large number of
objects.
&lt;/p&gt;
&lt;p&gt;We show that several other well-known theorems from extremal combinatorics -
including Erd\H{o}s-Ko-Rado, Sperner, and Cayley&#39;s formula - give rise to
complete problems for PWPP and PPP. This is in contrast to the Ramsey and
Erd\H{o}s-Rado problems, for which establishing inclusion in PWPP has remained
elusive. Besides significantly expanding the set of problems that are complete
for PWPP and PPP, our work identifies some key properties of combinatorial
proofs of existence that can give rise to completeness for these classes.
&lt;/p&gt;
&lt;p&gt;Our completeness results rely on efficient encodings for which finding
collisions allows extracting the desired substructure. These encodings are made
possible by the tightness of the bounds for the problems at hand (tighter than
what is known for Ramsey&#39;s theorem and the sunflower lemma). Previous
techniques for proving bounds in TFNP invariably made use of structured
algorithms. Such algorithms are not known to exist for the theorems considered
in this work, as their proofs &quot;from the book&quot; are non-constructive.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: The Complexity and Expressive Power of Second-Order Extended Logic</title>
    <link href="http://arxiv.org/abs/2209.04837"/>
    <id>http://arxiv.org/abs/2209.04837</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1&quot;&gt;Shiguang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xishun Zhao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the expressive powers of SO-HORN$^{*}$, SO-HORN$^{r}$ and
SO-HORN$^{*r}$ on all finite structures. We show that SO-HORN$^{r}$,
SO-HORN$^{*r}$, FO(LFP) coincide with each other and SO-HORN$^{*}$ is proper
sublogic of SO-HORN$^{r}$. To prove this result, we introduce the notions of
DATALOG$^{*}$ program, DATALOG$^{r}$ program and their stratified versions,
S-DATALOG$^{*}$ program and S-DATALOG$^{r}$ program. It is shown that, on all
structures, DATALOG$^{r}$ and S-DATALOG$^{r}$ are equivalent and DATALOG$^{*}$
is a proper sublogic of DATALOG$^{r}$. SO-HORN$^{*}$ and SO-HORN$^{r}$ can be
treated as the negations of DATALOG$^{*}$ and DATALOG$^{r}$, respectively. We
also show that SO-EHORN$^{r}$ logic which is an extended version of SO-HORN
captures co-NP on all finite structures.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: On The Computational Complexity of Self-Attention</title>
    <link href="http://arxiv.org/abs/2209.04881"/>
    <id>http://arxiv.org/abs/2209.04881</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keles_F/0/1/0/all/0/1&quot;&gt;Feyza Duman Keles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wijewardena_P/0/1/0/all/0/1&quot;&gt;Pruthuvi Mahesakya Wijewardena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hegde_C/0/1/0/all/0/1&quot;&gt;Chinmay Hegde&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Transformer architectures have led to remarkable progress in many
state-of-art applications. However, despite their successes, modern
transformers rely on the self-attention mechanism, whose time- and
space-complexity is quadratic in the length of the input. Several approaches
have been proposed to speed up self-attention mechanisms to achieve
sub-quadratic running time; however, the large majority of these works are not
accompanied by rigorous error guarantees. In this work, we establish lower
bounds on the computational complexity of self-attention in a number of
scenarios. We prove that the time complexity of self-attention is necessarily
quadratic in the input length, unless the Strong Exponential Time Hypothesis
(SETH) is false. This argument holds even if the attention computation is
performed only approximately, and for a variety of attention mechanisms. As a
complement to our lower bounds, we show that it is indeed possible to
approximate dot-product self-attention using finite Taylor series in
linear-time, at the cost of having an exponential dependence on the polynomial
order.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Nearly all $k$-SAT functions are unate</title>
    <link href="http://arxiv.org/abs/2209.04894"/>
    <id>http://arxiv.org/abs/2209.04894</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Balogh_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf3;zsef Balogh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dong_D/0/1/0/all/0/1&quot;&gt;Dingding Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lidicky_B/0/1/0/all/0/1&quot;&gt;Bernard Lidick&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mani_N/0/1/0/all/0/1&quot;&gt;Nitya Mani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yufei Zhao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We prove that $1-o(1)$ fraction of all $k$-SAT functions on $n$ Boolean
variables are unate (i.e., monotone after first negating some variables), for
any fixed positive integer $k$ and as $n \to \infty$. This resolves a
conjecture by Bollob\&#39;as, Brightwell, and Leader from 2003.
&lt;/p&gt;
&lt;p&gt;This paper is the second half of a two-part work solving the problem. The
first part, by Dong, Mani, and Zhao, reduces the conjecture to a Tur\&#39;an
problem on partially directed hypergraphs. In this paper we solve this Tur\&#39;an
problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Gradient-Free Methods for Deterministic and Stochastic Nonsmooth Nonconvex Optimization</title>
    <link href="http://arxiv.org/abs/2209.05045"/>
    <id>http://arxiv.org/abs/2209.05045</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tianyi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zheng_Z/0/1/0/all/0/1&quot;&gt;Zeyu Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Nonsmooth nonconvex optimization problems broadly emerge in machine learning
and business decision making, whereas two core challenges impede the
development of efficient solution methods with finite-time convergence
guarantee: the lack of computationally tractable optimality criterion and the
lack of computationally powerful oracles. The contributions of this paper are
two-fold. First, we establish the relationship between the celebrated Goldstein
subdifferential~\citep{Goldstein-1977-Optimization} and uniform smoothing,
thereby providing the basis and intuition for the design of gradient-free
methods that guarantee the finite-time convergence to a set of Goldstein
stationary points. Second, we propose the gradient-free method (GFM) and
stochastic GFM for solving a class of nonsmooth nonconvex optimization problems
and prove that both of them can return a $(\delta,\epsilon)$-Goldstein
stationary point of a Lipschitz function $f$ at an expected convergence rate at
$O(d^{3/2}\delta^{-1}\epsilon^{-4})$ where $d$ is the problem dimension.
Two-phase versions of GFM and SGFM are also proposed and proven to achieve
improved large-deviation results. Finally, we demonstrate the effectiveness of
2-SGFM on training ReLU neural networks with the \textsc{Minst} dataset.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Localization with Few Distance Measurements</title>
    <link href="http://arxiv.org/abs/2209.04838"/>
    <id>http://arxiv.org/abs/2209.04838</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Halperin_D/0/1/0/all/0/1&quot;&gt;Dan Halperin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LaValle_S/0/1/0/all/0/1&quot;&gt;Steven M. LaValle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ugav_B/0/1/0/all/0/1&quot;&gt;Barak Ugav&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a polygon $W$, a depth sensor placed at point $p=(x,y)$ inside $W$ and
oriented in direction $\theta$ measures the distance $d=h(x,y,\theta)$ between
$p$ and the closest point on the boundary of $W$ along a ray emanating from $p$
in direction $\theta$. We study the following problem: Give a polygon $W$,
possibly with holes, with $n$ vertices, preprocess it such that given a query
real value $d\geq 0$, one can efficiently compute the preimage $h^{-1}(d)$,
namely determine all the possible poses (positions and orientations) of a depth
sensor placed in $W$ that would yield the reading $d$. We employ a
decomposition of $W\times S^1$, which is an extension of the celebrated
trapezoidal decomposition, and which we call rotational trapezoidal
decomposition and present an efficient data structure, which computes the
preimage in an output-sensitive fashion relative to this decomposition: if $k$
cells of the decomposition contribute to the final result, we will report them
in $O(k+1)$ time, after $O(n^2\log n)$ preprocessing time and using $O(n^2)$
storage space. We also analyze the shape of the projection of the preimage onto
the polygon $W$; this projection describes the portion of $W$ where the sensor
could have been placed. Furthermore, we obtain analogous results for the more
useful case (narrowing down the set of possible poses), where the sensor
performs two depth measurement from the same point $p$, one in direction
$\theta$ and the other in direction $\theta+\pi$. While localizations problems
in robotics are often carried out by exploring the full visibility polygon of a
sensor placed at a fixed point of the environment, the approach that we propose
here opens the door to sufficing with only few depth measurements, which is
advantageous as it allows for usage of inexpensive sensors and could also lead
to savings in storage and communication costs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Structured $(\min,+)$-Convolution And Its Applications For The Shortest Vector, Closest Vector, and Separable Nonlinear Knapsack Problems</title>
    <link href="http://arxiv.org/abs/2209.04812"/>
    <id>http://arxiv.org/abs/2209.04812</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gribanov_D/0/1/0/all/0/1&quot;&gt;D. V. Gribanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malyshev_D/0/1/0/all/0/1&quot;&gt;D. S. Malyshev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shumilov_I/0/1/0/all/0/1&quot;&gt;I. A. Shumilov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work we consider the problem of computing the $(\min, +)$-convolution
of two sequences $a$ and $b$ of lengths $n$ and $m$, respectively, where $n
\geq m$. We assume that $a$ is arbitrary, but $b_i = f(i)$, where $f(x) \colon
[0,m) \to \mathbb{R}$ is a function with one of the following properties:
&lt;/p&gt;
&lt;p&gt;1. the linear case, when $f(x) =\beta + \alpha \cdot x$;
&lt;/p&gt;
&lt;p&gt;2. the monotone case, when $f(i+1) \geq f(i)$, for any $i$;
&lt;/p&gt;
&lt;p&gt;3. the convex case, when $f(i+1) - f(i) \geq f(i) - f(i-1)$, for any $i$;
&lt;/p&gt;
&lt;p&gt;4. the concave case, when $f(i+1) - f(i) \leq f(i) - f(i-1)$, for any $i$;
&lt;/p&gt;
&lt;p&gt;5. the piece-wise linear case, when $f(x)$ consist of $p$ linear pieces;
&lt;/p&gt;
&lt;p&gt;6. the polynomial case, when $f \in \mathbb{Z}^d[x]$, for some fixed $d$.
&lt;/p&gt;
&lt;p&gt;To the best of our knowledge, the cases 4-6 were not considered in literature
before. We develop true sub-quadratic algorithms for them.
&lt;/p&gt;
&lt;p&gt;We apply our results to the knapsack problem with a separable nonlinear
objective function, shortest lattice vector, and closest lattice vector
problems.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On finding short reconfiguration sequences between independent sets</title>
    <link href="http://arxiv.org/abs/2209.05145"/>
    <id>http://arxiv.org/abs/2209.05145</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1&quot;&gt;Akanksha Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hait_S/0/1/0/all/0/1&quot;&gt;Soumita Hait&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mouawad_A/0/1/0/all/0/1&quot;&gt;Amer E. Mouawad&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Assume we are given a graph $G$, two independent sets $S$ and $T$ in $G$ of
size $k \geq 1$, and a positive integer $\ell \geq 1$. The goal is to decide
whether there exists a sequence $\langle I_0, I_1, ..., I_\ell \rangle$ of
independent sets such that for all $j \in \{0,\ldots,\ell-1\}$ the set $I_j$ is
an independent set of size $k$, $I_0 = S$, $I_\ell = T$, and $I_{j+1}$ is
obtained from $I_j$ by a predetermined reconfiguration rule. We consider two
reconfiguration rules. Intuitively, we view each independent set as a
collection of tokens placed on the vertices of the graph. Then, the Token
Sliding Optimization (TSO) problem asks whether there exists a sequence of at
most $\ell$ steps that transforms $S$ into $T$, where at each step we are
allowed to slide one token from a vertex to an unoccupied neighboring vertex.
In the Token Jumping Optimization (TJO) problem, at each step, we are allowed
to jump one token from a vertex to any other unoccupied vertex of the graph.
Both TSO and TJO are known to be fixed-parameter tractable when parameterized
by $\ell$ on nowhere dense classes of graphs. In this work, we show that both
problems are fixed-parameter tractable for parameter $k + \ell + d$ on
$d$-degenerate graphs as well as for parameter $|M| + \ell + \Delta$ on graphs
having a modulator $M$ whose deletion leaves a graph of maximum degree
$\Delta$. We complement these result by showing that for parameter $\ell$ alone
both problems become W[1]-hard already on $2$-degenerate graphs. Our positive
result makes use of the notion of independence covering families introduced by
Lokshtanov et al. Finally, we show that using such families one can obtain a
simpler and unified algorithm for the standard Token Jumping Reachability
problem parameterized by $k$ on both degenerate and nowhere dense classes of
graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Experiments and a User Study for Hierarchical Drawings of Graphs</title>
    <link href="http://arxiv.org/abs/2209.04522"/>
    <id>http://arxiv.org/abs/2209.04522</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lionakis_P/0/1/0/all/0/1&quot;&gt;Panagiotis Lionakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kritikakis_G/0/1/0/all/0/1&quot;&gt;Giorgos Kritikakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tollis_I/0/1/0/all/0/1&quot;&gt;Ioannis G. Tollis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present experimental results and a user study for hierarchical drawings of
graphs. A detailed hierarchical graph drawing technique that is based on the
Path Based Framework (PBF) is presented. Extensive edge bundling is applied to
draw all edges of the graph and the height of the drawing is minimized using
compaction. The drawings produced by this framework are compared to drawings
produced by the well known Sugiyama framework in terms of area, number of
bends, number of crossings, and execution time. The new algorithm runs very
fast and produces drawings that are readable and efficient. Since there are
advantages (and disadvantages) to both frameworks, we performed a user study
and the results show that the drawings produced by the new framework are well
received in terms of clarity, readability, and usability. Hence, the new
technique offers an interesting alternative to drawing hierarchical graphs, and
is especially useful in applications where user defined paths are important and
need to be highlighted.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Spectral hypergraph sparsification via chaining</title>
    <link href="http://arxiv.org/abs/2209.04539"/>
    <id>http://arxiv.org/abs/2209.04539</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;James R. Lee&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a hypergraph on $n$ vertices where $D$ is the maximum size of a hyperedge,
there is a weighted hypergraph spectral $\varepsilon$-sparsifier with at most
$O(\varepsilon^{-2} \log(D) \cdot n \log n)$ hyperedges. This improves over the
bound of Kapralov, Krauthgamer, Tardos and Yoshida (2021) who achieve
$O(\varepsilon^{-4} n (\log n)^3)$, as well as the bound $O(\varepsilon^{-2}
D^3 n \log n)$ obtained by Bansal, Svensson, and Trevisan (2019). The same
sparsification result was obtained independently by Jambulapati, Liu, and
Sidford (2022).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: PGAbB: A Block-Based Graph Processing Framework for Heterogeneous Platforms</title>
    <link href="http://arxiv.org/abs/2209.04541"/>
    <id>http://arxiv.org/abs/2209.04541</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yasar_A/0/1/0/all/0/1&quot;&gt;Abdurrahman Yasar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajamanickam_S/0/1/0/all/0/1&quot;&gt;Sivasankaran Rajamanickam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berry_J/0/1/0/all/0/1&quot;&gt;Jonathan W. Berry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catalyurek_U/0/1/0/all/0/1&quot;&gt;Umit V. Catalyurek&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Designing flexible graph kernels that can run well on various platforms is a
crucial research problem due to the frequent usage of graphs for modeling data
and recent architectural advances and variety. In this work, we propose a novel
graph processing framework, PGAbB (Parallel Graph Algorithms by Blocks), for
modern shared-memory heterogeneous platforms. Our framework implements a
block-based programming model. This allows a user to express a graph algorithm
using kernels that operate on subgraphs. PGAbB support graph computations that
fit in host DRAM but not in GPU device memory, and provides simple but
effective scheduling techniques to schedule computations to all available
resources in a heterogeneous architecture. We have demonstrated that one can
easily implement a diverse set of graph algorithms in our framework by
developing five algorithms. Our experimental results show that PGAbB
implementations achieve better or competitive performance compared to
hand-optimized implementations. Based on our experiments on five graph
algorithms and forty-four graphs, in the median, PGAbB achieves 1.6, 1.6, 5.7,
3.4, 4.5, and 2.4 times better performance than GAPBS, Galois, Ligra, LAGraph
Galois-GPU, and Gunrock graph processing systems, respectively.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: The Bayan Algorithm: Detecting Communities in Networks Through Exact and Approximate Optimization of Modularity</title>
    <link href="http://arxiv.org/abs/2209.04562"/>
    <id>http://arxiv.org/abs/2209.04562</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aref_S/0/1/0/all/0/1&quot;&gt;Samin Aref&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chheda_H/0/1/0/all/0/1&quot;&gt;Hriday Chheda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mostajabdaveh_M/0/1/0/all/0/1&quot;&gt;Mahdi Mostajabdaveh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Community detection is a classic problem in network science with extensive
applications in various fields. The most commonly used methods are the
algorithms designed to maximize a utility function, modularity, across
different ways that a network can be partitioned into communities. Despite
their name and design philosophy, current modularity maximization algorithms
generally fail to maximize modularity or guarantee any proximity to an optimal
solution. We propose the Bayan algorithm which, unlike the existing methods,
returns network partitions with a guarantee of either optimality or proximity
to an optimal solution. At the core of the Bayan algorithm is a branch-and-cut
scheme that solves a sparse integer programming formulation of the modularity
maximization problem to optimality or approximate it within a factor. We
analyze the performance of Bayan against 22 existing algorithms using synthetic
and real networks. Through extensive experiments, we demonstrate Bayan&#39;s
distinctive capabilities not only in maximizing modularity, but more
importantly in accurate retrieval of ground-truth communities. Bayan&#39;s
comparative level of performance remains stable over variations in the amount
of noise in the data (graph) generation process. The performance of Bayan as an
exact modularity maximization algorithm also reveals the theoretical capability
limits of maximum-modularity partitions in accurate retrieval of communities.
Overall our analysis points to Bayan as a suitable choice for a
methodologically grounded detection of communities through exact (approximate)
maximization of modularity in networks with up to $\sim10^3$ edges (and larger
networks). Prospective advances in graph optimization and integer programming
can push these limits further.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: An EPTAS for Budgeted Matroid Independent Set</title>
    <link href="http://arxiv.org/abs/2209.04654"/>
    <id>http://arxiv.org/abs/2209.04654</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doron_Arad_I/0/1/0/all/0/1&quot;&gt;Ilan Doron-Arad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulik_A/0/1/0/all/0/1&quot;&gt;Ariel Kulik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shachnai_H/0/1/0/all/0/1&quot;&gt;Hadas Shachnai&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the budgeted matroid independent set problem. The input is a
ground set, where each element has a cost and a non-negative profit, along with
a matroid over the elements and a budget. The goal is to select a subset of
elements which maximizes the total profit subject to the matroid and budget
constraints. Several well known special cases, where we have, e.g., a uniform
matroid and a budget, or no matroid constraint (i.e., the classic knapsack
problem), admit a fully polynomial-time approximation scheme (FPTAS). In
contrast, already a slight generalization to the multi-budgeted matroid
independent set problem has a PTAS but does not admit an efficient
polynomial-time approximation scheme (EPTAS). This implies a PTAS for our
problem, which is the best known result prior to this work. Our main
contribution is an EPTAS for the budgeted matroid independent set problem. A
key idea of the scheme is to find a representative set for the instance, whose
cardinality depends solely on $1/\varepsilon$, where $\varepsilon &amp;gt; 0$ is the
accuracy parameter of the scheme. The representative set is identified via
matroid basis minimization, which can be solved by a simple greedy algorithm.
Our scheme enumerates over subsets of the representative set and extends each
subset using a linear program. The notion of representative sets may be useful
in solving other variants of the budgeted matroid independent set problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Growing a Random Maximal Independent Set Produces a 2-approximate Vertex Cover</title>
    <link href="http://arxiv.org/abs/2209.04673"/>
    <id>http://arxiv.org/abs/2209.04673</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veldt_N/0/1/0/all/0/1&quot;&gt;Nate Veldt&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper presents a fast and simple new 2-approximation algorithm for
minimum weighted vertex cover. The unweighted version of this algorithm is
equivalent to a well-known greedy maximal independent set algorithm. We prove
that this independent set algorithm produces a 2-approximate vertex cover, and
we provide a principled new way to generalize it to node-weighted graphs. Our
analysis is inspired by connections to a clustering objective called
correlation clustering. To demonstrate the relationship between these problems,
we show how a simple Pivot algorithm for correlation clustering implicitly
approximates a special type of hypergraph vertex cover problem. Finally, we use
implicit implementations of this maximal independent set algorithm to develop
fast and simple 2-approximation algorithms for certain edge-deletion problems
that can be reduced to vertex cover in an approximation preserving way.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Hard Optimization Problems have Soft Edges</title>
    <link href="http://arxiv.org/abs/2209.04824"/>
    <id>http://arxiv.org/abs/2209.04824</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Marino_R/0/1/0/all/0/1&quot;&gt;Raffaele Marino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Kirkpatrick_S/0/1/0/all/0/1&quot;&gt;Scott Kirkpatrick&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Finding a Maximum Clique is a classic property test from graph theory; find
any one of the largest complete subgraphs in an Erd{\&quot;o}s-R{\&#39;e}nyi $G(N,p)$
random graph. It is the simplest of many such problems in which algorithms
requiring only a small power of $N$ steps cannot reach solutions which
probabilistic arguments show must exist, exposing an inherently &quot;hard&quot; phase
within the solution space of the problem. Such &quot;hard&quot; phases are seen in many
NP-Complete problems, in the limit when $N \to \infty$. But optimization
problems arise and must be solved at finite N. We use this simplest case,
MaxClique, to explore the structure of the problem as a function of $N$ and
$K$, the clique size. It displays a complex phase boundary, a staircase of
steps at each of which $2 \log_2N$ and $K_{\text{max}}$, the maximum size of
clique that can be found, increase by $1$. Each of its boundaries have finite
width, and these widths allow local algorithms to find cliques beyond the
limits defined by the study of infinite systems. We explore the performance of
a number of extensions of traditional fast local algorithms, and find that much
of the &quot;hard&quot; space remains accessible at finite $N$.
&lt;/p&gt;
&lt;p&gt;The &quot;hidden clique&quot; problem embeds a clique somewhat larger than those which
occur naturally in a $G(N,p)$ random graph. Since such a clique is unique, we
find that local searches which stop early, once evidence for the hidden clique
is found, may outperform the best message passing or spectral algorithms.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Rethink Decision Tree Traversal</title>
    <link href="http://arxiv.org/abs/2209.04825"/>
    <id>http://arxiv.org/abs/2209.04825</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jinxiong Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We will show how to evaluate binary decision tree traversal in the language
of matrix computation motivated by \textit{QuickScorer} in
\cite{lucchese2015quickscorer}. Our main contribution is a novel matrix
representation of the hierarchical structure of the decision tree. And we
propose some equivalent algorithms of binary decision tree traversal based on
rigorous theoretical analysis. The core idea is to find the relation between
the input and exit leaf node. Here we not only understand decisions without the
recursive traverse but also dive into the partitioning nature of tree-based
methods.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: An Improved Algorithm For Online Reranking</title>
    <link href="http://arxiv.org/abs/2209.04870"/>
    <id>http://arxiv.org/abs/2209.04870</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bienkowski_M/0/1/0/all/0/1&quot;&gt;Marcin Bienkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mucha_M/0/1/0/all/0/1&quot;&gt;Marcin Mucha&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study a fundamental model of online preference aggregation, where an
algorithm maintains an ordered list of $n$ elements. An input is a stream of
preferred sets $R_1, R_2, \dots, R_t, \dots$. Upon seeing $R_t$ and without
knowledge of any future sets, an algorithm has to rerank elements (change the
list ordering), so that at least one element of $R_t$ is found near the list
front. The incurred cost is a sum of the list update costs (the number of swaps
of neighboring list elements) and access costs (position of the first element
of $R_t$ on the list). This scenario occurs naturally in applications such as
ordering items in an online shop using aggregated preferences of shop
customers. The theoretical underpinning of this problem is known as Min-Sum Set
Cover.
&lt;/p&gt;
&lt;p&gt;Unlike previous work (Fotakis et al., ICALP 2020, NIPS 2020) that mostly
studied the performance of an online algorithm ALG against the static optimal
solution (a single optimal list ordering), in this paper, we study an arguably
harder variant where the benchmark is the provably stronger optimal dynamic
solution OPT (that may also modify the list ordering). In terms of an online
shop, this means that the aggregated preferences of its user base evolve with
time. We construct a computationally efficient randomized algorithm whose
competitive ratio (ALG-to-OPT cost ratio) is $O(r^2)$ and prove the existence
of a deterministic $O(r^4)$-competitive algorithm. Here, $r$ is the maximum
cardinality of sets $R_t$. This is the first algorithm whose ratio does not
depend on $n$: the previously best algorithm for this problem was $O(r^{3/2}
\cdot \sqrt{n})$-competitive and $\Omega(r)$ is a lower bound on the
performance of any deterministic online algorithm.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Subquadratic Kronecker Regression with Applications to Tensor Decomposition</title>
    <link href="http://arxiv.org/abs/2209.04876"/>
    <id>http://arxiv.org/abs/2209.04876</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fahrbach_M/0/1/0/all/0/1&quot;&gt;Matthew Fahrbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_T/0/1/0/all/0/1&quot;&gt;Thomas Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghadiri_M/0/1/0/all/0/1&quot;&gt;Mehrdad Ghadiri&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Kronecker regression is a highly-structured least squares problem
$\min_{\mathbf{x}} \lVert \mathbf{K}\mathbf{x} - \mathbf{b} \rVert_{2}^2$,
where the design matrix $\mathbf{K} = \mathbf{A}^{(1)} \otimes \cdots \otimes
\mathbf{A}^{(N)}$ is a Kronecker product of factor matrices. This regression
problem arises in each step of the widely-used alternating least squares (ALS)
algorithm for computing the Tucker decomposition of a tensor. We present the
first subquadratic-time algorithm for solving Kronecker regression to a
$(1+\varepsilon)$-approximation that avoids the exponential term
$O(\varepsilon^{-N})$ in the running time. Our techniques combine leverage
score sampling and iterative methods. By extending our approach to block-design
matrices where one block is a Kronecker product, we also achieve
subquadratic-time algorithms for (1) Kronecker ridge regression and (2)
updating the factor matrix of a Tucker decomposition in ALS, which is not a
pure Kronecker regression problem, thereby improving the running time of all
steps of Tucker ALS. We demonstrate the speed and accuracy of this Kronecker
regression algorithm on synthetic data and real-world image tensors.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Cores of Games via Total Dual Integrality, with Applications to Perfect Graphs and Polymatroids</title>
    <link href="http://arxiv.org/abs/2209.04903"/>
    <id>http://arxiv.org/abs/2209.04903</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vazirani_V/0/1/0/all/0/1&quot;&gt;Vijay V. Vazirani&lt;/a&gt;&lt;/p&gt;&lt;p&gt;LP-duality theory has played a central role in the study of cores of games,
right from the early days of this notion to the present time. The classic paper
of Shapley and Shubik \cite{Shapley1971assignment} introduced the &quot;right&quot; way
of exploiting the power of this theory, namely picking problems whose
LP-relaxations support polyhedra having integral vertices. So far, the latter
fact was established by showing that the constraint matrix of the underlying
linear system is {\em totally unimodular}.
&lt;/p&gt;
&lt;p&gt;We attempt to take this methodology to its logical next step -- {\em using
total dual integrality} -- thereby addressing new classes of games which have
their origins in two major theories within combinatorial optimization, namely
perfect graphs and polymatroids. In the former, we address the stable set and
clique games and in the latter, we address the matroid independent set game.
For each of these games, we prove that the set of core imputations is precisely
the set of optimal solutions to the dual LPs.
&lt;/p&gt;
&lt;p&gt;Another novelty is the way the worth of the game is allocated among
sub-coalitions. Previous works follow the {\em bottom-up process} of allocating
to individual agents; the allocation to a sub-coalition is simply the sum of
the allocations to its agents. The {\em natural process for our games is
top-down}. The optimal dual allocates to &quot;objects&quot; in the grand coalition; a
sub-coalition inherits the allocation of each object with which it has
non-empty intersection.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Dynamic Subset Sum with Truly Sublinear Processing Time</title>
    <link href="http://arxiv.org/abs/2209.04936"/>
    <id>http://arxiv.org/abs/2209.04936</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saleh_H/0/1/0/all/0/1&quot;&gt;Hamed Saleh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seddighin_S/0/1/0/all/0/1&quot;&gt;Saeed Seddighin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Subset sum is a very old and fundamental problem in theoretical computer
science. In this problem, $n$ items with weights $w_1, w_2, w_3, \ldots, w_n$
are given as input and the goal is to find out if there is a subset of them
whose weights sum up to a given value $t$. While the problem is NP-hard in
general, when the values are non-negative integer, subset sum can be solved in
pseudo-polynomial time $~\widetilde O(n+t)$.
&lt;/p&gt;
&lt;p&gt;In this work, we consider the dynamic variant of subset sum. In this setting,
an upper bound $\tmax$ is provided in advance to the algorithm and in each
operation, either a new item is added to the problem or for a given integer
value $t \leq \tmax$, the algorithm is required to output whether there is a
subset of items whose sum of weights is equal to $t$. Unfortunately, none of
the existing subset sum algorithms is able to process these operations in truly
sublinear time\footnote{Truly sublinear means $n^{1-\Omega(1)}$.} in terms of
$\tmax$.
&lt;/p&gt;
&lt;p&gt;Our main contribution is an algorithm whose amortized processing
time\footnote{Since the runtimes are amortized, we do not use separate terms
update time and query time for different operations and use processing time for
all types of operations.} for each operation is truly sublinear in $\tmax$ when
the number of operations is at least $\tmax^{2/3+\Omega(1)}$. We also show that
when both element addition and element removal are allowed, there is no
algorithm that can process each operation in time $\tmax^{1-\Omega(1)}$ on
average unless \textsf{SETH}\footnote{The \textit{strong exponential time
hypothesis} states that no algorithm can solve the satisfiability problem in
time $2^{n(1-\Omega(1))}$.} fails.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: QUBO formulations for NP-Hard spanning tree problems</title>
    <link href="http://arxiv.org/abs/2209.05024"/>
    <id>http://arxiv.org/abs/2209.05024</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carvalho_I/0/1/0/all/0/1&quot;&gt;Ivan Carvalho&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce a novel Quadratic Unconstrained Binary Optimization (QUBO)
formulation method for spanning tree problems. Instead of encoding the presence
of edges in the tree individually, we opt to encode spanning trees as a
permutation problem. We apply our method to four NP-hard spanning tree
variants, namely the k-minimum spanning tree, degree-constrained minimum
spanning tree, minimum leaf spanning tree, and maximum leaf spanning tree. Our
main result is a formulation with $\mathcal{O}(|V|k)$ variables for the
k-minimum spanning tree problem, beating related strategies that need
$\mathcal{O}(|V|^{2})$ variables.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: Thirty Years of Dagstuhl</title>
    <link href="http://blog.computationalcomplexity.org/2022/09/thirty-years-of-dagstuhl.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-4092582253443093216</id>
    <updated>2022-09-12T15:26:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&amp;nbsp;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiAVV6vqRxQ0GiKOwjxUJJsrSy10_N1Rnaq7CSWN1LgmRkcVyYHAp5sLgwslboCRbhHq3s6iMU9bSHGJlLBUthZUpI750kpeBrLOkMQcLtDBumFlxNfU-mSDwmO_8nRgw9onQW6AVeluj2ZL1-oGuWqCRxbIVJyT5OZAsdPSTc-BM8UqwioQ/s2668/PXL_20220912_120021005.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;2259&quot; data-original-width=&quot;2668&quot; height=&quot;339&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiAVV6vqRxQ0GiKOwjxUJJsrSy10_N1Rnaq7CSWN1LgmRkcVyYHAp5sLgwslboCRbhHq3s6iMU9bSHGJlLBUthZUpI750kpeBrLOkMQcLtDBumFlxNfU-mSDwmO_8nRgw9onQW6AVeluj2ZL1-oGuWqCRxbIVJyT5OZAsdPSTc-BM8UqwioQ/w400-h339/PXL_20220912_120021005.jpg&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Dagstuhl old-timers at the original castle&lt;br /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;I&#39;m back at Dagstuhl for the seminar on&amp;nbsp;&lt;a href=&quot;https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=22371&quot;&gt;Algebraic and Analytic Methods in Computational Complexity&lt;/a&gt;. My &lt;a href=&quot;https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=9206&quot;&gt;first seminar&lt;/a&gt; at Dagstuhl was back in 1992. I&#39;ve been coming for thirty years and have been here roughly thirty times. My &lt;a href=&quot;https://blog.computationalcomplexity.org/2019/03/back-at-dagstuhl.html&quot;&gt;last trip&lt;/a&gt; was pre-covid (virtual Dagstuhls don&#39;t count) and I really needed this chance to hang out and talk complexity with colleagues old and new.&lt;/p&gt;&lt;p&gt;Some changes since my last trip. The room doors have locks (there are rumors of an incident). You have to create your own keycard on a new machine logging into your Dagstuhl account. I had a long random password through a password manager and it was not so easy as process.&lt;/p&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLRrLcyKcZLTsqhWGocXuS13xG4yxOJNC9A0xL4mwzmXB8KXWwVTEsW4jF5lST7LAfHNbb_z4nwmOQarS1dwdoSwQYg7IX6NdpNqGkriuzDM4M1mP3rgiR99bV2XOAVr2iJvPsyGHBG6ECrwqYuR65Ok9uXvS_CvxogulpL0Eph-4xPLW9EA/s4080/PXL_20220912_122728903.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;3072&quot; data-original-width=&quot;4080&quot; height=&quot;241&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLRrLcyKcZLTsqhWGocXuS13xG4yxOJNC9A0xL4mwzmXB8KXWwVTEsW4jF5lST7LAfHNbb_z4nwmOQarS1dwdoSwQYg7IX6NdpNqGkriuzDM4M1mP3rgiR99bV2XOAVr2iJvPsyGHBG6ECrwqYuR65Ok9uXvS_CvxogulpL0Eph-4xPLW9EA/s320/PXL_20220912_122728903.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;p&gt;The main conference room has been updated with tech for hybrid meetings, and new led lights. Books were removed from the library to create a coffee breakout space.&lt;/p&gt;&lt;p&gt;No Bill this time so no &lt;a href=&quot;https://blog.computationalcomplexity.org/search?q=typecast&quot;&gt;typecasts&lt;/a&gt;. Still the best part of the week is talking and hearing about complexity. Today I learned about the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sperner%27s_lemma#Oriented_variants&quot;&gt;orientations of Sperner&#39;s lemma&lt;/a&gt;, that there is one more triangle oriented according to the direction of the corner vertices than those oriented the other way.&amp;nbsp;Christian Ikenmeyer used this fact to motivate a study of closure properties of #P-functions.&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Quantum optimization with arbitrary connectivity using Rydberg atom arrays</title>
    <link href="http://arxiv.org/abs/2209.03965"/>
    <id>http://arxiv.org/abs/2209.03965</id>
    <updated>2022-09-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Nguyen_M/0/1/0/all/0/1&quot;&gt;Minh-Thi Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jin-Guo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wurtz_J/0/1/0/all/0/1&quot;&gt;Jonathan Wurtz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Lukin_M/0/1/0/all/0/1&quot;&gt;Mikhail D. Lukin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sheng-Tao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pichler_H/0/1/0/all/0/1&quot;&gt;Hannes Pichler&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Programmable quantum systems based on Rydberg atom arrays have recently been
used for hardware-efficient tests of quantum optimization algorithms [Ebadi et
al., Science, 376, 1209 (2022)] with hundreds of qubits. In particular, the
maximum independent set problem on the so-called unit-disk graphs, was shown to
be efficiently encodable in such a quantum system. Here, we extend the classes
of problems that can be efficiently encoded in Rydberg arrays by constructing
explicit mappings from the original computation problems to maximum weighted
independent set problems on unit-disk graphs, with at most a quadratic overhead
in the number of qubits. We analyze several examples, including: maximum
weighted independent set on graphs with arbitrary connectivity, quadratic
unconstrained binary optimization problems with arbitrary or restricted
connectivity, and integer factorization. Numerical simulations on small system
sizes indicate that the adiabatic time scale for solving the mapped problems is
strongly correlated with that of the original problems. Our work provides a
blueprint for using Rydberg atom arrays to solve a wide range of combinatorial
optimization problems with arbitrary connectivity, beyond the restrictions
imposed by the hardware geometry.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Trajectory Range Visibility</title>
    <link href="http://arxiv.org/abs/2209.04013"/>
    <id>http://arxiv.org/abs/2209.04013</id>
    <updated>2022-09-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kazemi_S/0/1/0/all/0/1&quot;&gt;Seyed Mohammad Hussein Kazemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaezi_A/0/1/0/all/0/1&quot;&gt;Arash Vaezi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghodsi_M/0/1/0/all/0/1&quot;&gt;Mohammad Ghodsi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the problem of Trajectory Range Visibility, determining the
sub-trajectories on which two moving entities become mutually visible.
Specifically, we consider two moving entities with not necessarily equal
velocities and moving on a given piece-wise linear trajectory inside a simple
polygon. Deciding whether the entities can see one another with given constant
velocities, and assuming the trajectories only as line segments, was solved by
P. Eades et al. in 2020. However, we obtain stronger results and support
queries on constant velocities for non-constant complexity trajectories.
Namely, given a constant query velocity for a moving entity, we specify all
visible parts of the other entity&#39;s trajectory and all possible constant
velocities of the other entity to become visible. Regarding line-segment
trajectories, we obtain $\mathcal{O}(n \log n)$ time to specify all pairs of
mutually visible sub-trajectories s.t. $n$ is the number of vertices of the
polygon. Moreover, our results for a restricted case on non-constant complexity
trajectories yield $\mathcal{O}(n + m(\log m + \log n))$ time, in which $m$ is
the overall number of vertices of both trajectories. Regarding the unrestricted
case, we provide $\mathcal{O}(n \log n + m(\log m + \log n))$ running time. We
offer $\mathcal{O}(\log n)$ query time for line segment trajectories and
$\mathcal{O}(\log m + k)$ for the non-constant complexity ones s.t. $k$ is the
number of velocity ranges reported in the answer. Interestingly, our results
require only $\mathcal{O}(n + m)$ space for non-constant complexity
trajectories.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Separating bichromatic point sets in the plane by restricted orientation convex hulls</title>
    <link href="http://arxiv.org/abs/2209.04258"/>
    <id>http://arxiv.org/abs/2209.04258</id>
    <updated>2022-09-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alegria_C/0/1/0/all/0/1&quot;&gt;Carlos Alegr&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orden_D/0/1/0/all/0/1&quot;&gt;David Orden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seara_C/0/1/0/all/0/1&quot;&gt;Carlos Seara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urrutia_J/0/1/0/all/0/1&quot;&gt;Jorge Urrutia&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We explore the separability of point sets in the plane by a
restricted-orientation convex hull, which is an orientation-dependent, possibly
disconnected, and non-convex enclosing shape that generalizes the convex hull.
Let $R$ and $B$ be two disjoint sets of red and blue points in the plane, and
$\mathcal{O}$ be a set of $k \geq 2$ lines passing through the origin. We study
the problem of computing the set of orientations of the lines of $\mathcal{O}$
for which the $\mathcal{O}$-convex hull of $R$ contains no points of $B$.
&lt;/p&gt;
&lt;p&gt;For $k=2$ orthogonal lines we have the rectilinear convex hull. In optimal
$O(n \log n)$ time and $O(n)$ space, $n = \vert R \vert + \vert B \vert$, we
compute the set of rotation angles such that, after simultaneously rotating the
lines of $\mathcal{O}$ around the origin in the same direction, the rectilinear
convex hull of $R$ contains no points of $B$. We generalize this result to the
case where $\mathcal{O}$ is formed by $k \geq 2$ lines with arbitrary
orientations. In the counter-clockwise circular order of the lines of
$\mathcal{O}$, let $\alpha_i$ be the angle required to clockwise rotate the
$i$th line so it coincides with its successor. We solve the problem in this
case in $O(1/\Theta \cdot N \log N)$ time and $O(1/\Theta \cdot N)$ space,
where $\Theta = \min \{ \alpha_1,\ldots,\alpha_k \}$ and $N=\max\{k,\vert R
\vert + \vert B \vert \}$. We finally consider the case in which $\mathcal{O}$
is formed by $k=2$ lines, one of the lines is fixed, and the second line
rotates by an angle that goes from $0$ to $\pi$. We show that this last case
can also be solved in optimal $O(n\log n)$ time and $O(n)$ space, where $n =
\vert R \vert + \vert B \vert$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Tensor Reconstruction Beyond Constant Rank</title>
    <link href="http://arxiv.org/abs/2209.04177"/>
    <id>http://arxiv.org/abs/2209.04177</id>
    <updated>2022-09-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peleg_S/0/1/0/all/0/1&quot;&gt;Shir Peleg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shpilka_A/0/1/0/all/0/1&quot;&gt;Amir Shpilka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Volk_B/0/1/0/all/0/1&quot;&gt;Ben Lee Volk&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We give reconstruction algorithms for subclasses of depth-3 arithmetic
circuits. In particular, we obtain the first efficient algorithm for finding
tensor rank, and an optimal tensor decomposition as a sum of rank-one tensors,
when given black-box access to a tensor of super-constant rank. We obtain the
following results:
&lt;/p&gt;
&lt;p&gt;1. A deterministic algorithm that reconstructs polynomials computed by
$\Sigma^{[k]}\bigwedge^{[d]}\Sigma$ circuits in time $\mathsf{poly}(n,d,c)
\cdot \mathsf{poly}(k)^{k^{k^{10}}}$
&lt;/p&gt;
&lt;p&gt;2. A randomized algorithm that reconstructs polynomials computed by
multilinear $\Sigma^{k]}\prod^{[d]}\Sigma$ circuits in time
$\mathsf{poly}(n,d,c) \cdot k^{k^{k^{k^{O(k)}}}}$
&lt;/p&gt;
&lt;p&gt;3. A randomized algorithm that reconstructs polynomials computed by
set-multilinear $\Sigma^{k]}\prod^{[d]}\Sigma$ circuits in time
$\mathsf{poly}(n,d,c) \cdot k^{k^{k^{k^{O(k)}}}}$, where $c=\log q$ if
$\mathbb{F}=\mathbb{F}_q$ is a finite field, and $c$ equals the maximum bit
complexity of any coefficient of $f$ if $\mathbb{F}$ is infinite.
&lt;/p&gt;
&lt;p&gt;Prior to our work, polynomial time algorithms for the case when the rank,
$k$, is constant, were given by Bhargava, Saraf and Volkovich [BSV21].
&lt;/p&gt;
&lt;p&gt;Another contribution of this work is correcting an error from a paper of
Karnin and Shpilka [KS09] that affected Theorem 1.6 of [BSV21]. Consequently,
the results of [KS09, BSV21] continue to hold, with a slightly worse setting of
parameters. For fixing the error we study the relation between syntactic and
semantic ranks of $\Sigma\Pi\Sigma$ circuits.
&lt;/p&gt;
&lt;p&gt;We obtain our improvement by introducing a technique for learning rank
preserving coordinate-subspaces. [KS09] and [BSV21] tried all choices of
finding the &quot;correct&quot; coordinates, which led to having a fast growing function
of $k$ at the exponent of $n$. We find these spaces in time that is growing
fast with $k$, yet it is only a fixed polynomial in $n$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Proceedings of the 30th International Symposium on Graph Drawing and Network Visualization (GD 2022)</title>
    <link href="http://arxiv.org/abs/2209.04402"/>
    <id>http://arxiv.org/abs/2209.04402</id>
    <updated>2022-09-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angelini_P/0/1/0/all/0/1&quot;&gt;Patrizio Angelini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanxleden_R/0/1/0/all/0/1&quot;&gt;Reinhard von Hanxleden&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This is the arXiv index for the electronic proceedings of GD 2022, which is
held at the Tokyo Institute of Technology, Tokyo, Japan, on September 13 - 16,
2022. It contains the peer-reviewed and revised accepted papers with an
optional appendix. Proceedings (without appendices) are also to be published by
Springer in the Lecture Notes in Computer Science series.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Algorithms with More Granular Differential Privacy Guarantees</title>
    <link href="http://arxiv.org/abs/2209.04053"/>
    <id>http://arxiv.org/abs/2209.04053</id>
    <updated>2022-09-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghazi_B/0/1/0/all/0/1&quot;&gt;Badih Ghazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1&quot;&gt;Ravi Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1&quot;&gt;Pasin Manurangsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steinke_T/0/1/0/all/0/1&quot;&gt;Thomas Steinke&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Differential privacy is often applied with a privacy parameter that is larger
than the theory suggests is ideal; various informal justifications for
tolerating large privacy parameters have been proposed. In this work, we
consider partial differential privacy (DP), which allows quantifying the
privacy guarantee on a per-attribute basis. In this framework, we study several
basic data analysis and learning tasks, and design algorithms whose
per-attribute privacy parameter is smaller that the best possible privacy
parameter for the entire record of a person (i.e., all the attributes).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Non-convex Quadratic Programming Using Coherent Optical Networks</title>
    <link href="http://arxiv.org/abs/2209.04415"/>
    <id>http://arxiv.org/abs/2209.04415</id>
    <updated>2022-09-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Khosravi_F/0/1/0/all/0/1&quot;&gt;Farhad Khosravi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yildiz_U/0/1/0/all/0/1&quot;&gt;Ugur Yildiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Scherer_A/0/1/0/all/0/1&quot;&gt;Artur Scherer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ronagh_P/0/1/0/all/0/1&quot;&gt;Pooya Ronagh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We investigate the possibility of solving continuous non-convex optimization
problems using a network of interacting quantum optical oscillators. We propose
a native encoding of continuous variables in analog signals associated with the
quadrature operators of a set of quantum optical modes. Optical coupling of the
modes and noise introduced by vacuum fluctuations from external reservoirs or
by weak measurements of the modes are used to optically simulate a diffusion
process on a set of continuous random variables. The process is run
sufficiently long for it to relax into the steady state of an energy potential
defined on a continuous domain. As a first demonstration, we numerically
benchmark solving box-constrained quadratic programming (BoxQP) problems using
these settings. We consider delay-line and measurement-feedback variants of the
experiment. Our benchmarking results demonstrate that in both cases the optical
network is capable of solving BoxQP problems over three orders of magnitude
faster than a state-of-the-art classical heuristic.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">David Eppstein: Comparing distances along lines</title>
    <link href="https://11011110.github.io/blog/2022/09/10/comparing-distances-lines.html"/>
    <id>https://11011110.github.io/blog/2022/09/10/comparing-distances-lines</id>
    <updated>2022-09-10T17:26:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;I’ve written here several times about &lt;a href=&quot;https://en.wikipedia.org/wiki/Gilbert_tessellation&quot;&gt;Gilbert tessellations&lt;/a&gt;, most recently in &lt;a href=&quot;/blog/2021/11/02/gilbert-tessellations-cellular.html&quot;&gt;last year’s post about cellular automata that naturally generate them&lt;/a&gt;. These are polygonal subdivisions of the plane, generated from the tracks of particles moving at the same speed, where the particles start as oppositely-moving pairs with random locations and directions, and continue moving until they crash into the track of another particle. Here’s Wikipedia’s illustration of these things, generated in 2012 by Claudio Rocchini:&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;&lt;a href=&quot;https://commons.wikimedia.org/wiki/File:Gilbert_tessellation.svg&quot;&gt;&lt;img src=&quot;/blog/assets/2018/Gilbert-tessellation.svg&quot; alt=&quot;A Gilbert tessellation, by Claudio Rocchini&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Suppose someone gives you a picture like this and tells you it’s a Gilbert tessellation, like I just did. How can you tell that it’s genuine? The starting positions of the particles are not marked on the picture, so what needs to be done is to infer their locations (or a system of points that could be their locations) and to check that particles, starting at those locations and moving along the lines, crash in the order that the picture shows. Wherever two segments intersect in the picture, one of them ends, and it must be the case that the starting position on the segment that ends is farther away than the starting position on the other segment. Otherwise, it would have been the other particle that crashed and the other segment that ended.&lt;/p&gt;

&lt;p&gt;One can set up a big system of inequalities where each variable describes the starting position of one of the particles, for instance by giving its distance from one end of its segment. Each inequality comes from an intersection of two segments and asks for the particle on one segment to be farther than the particle on the other segment. The distance between two positions \(x\) and \(y\) on the same segment, parameterized linearly, is &lt;span style=&quot;white-space:nowrap&quot;&gt;just \(\vert x-y\vert\).&lt;/span&gt; So when a particle on &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(j\)&lt;/span&gt; crashes into a track on &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(i\)&lt;/span&gt; we get an inequality like&lt;/p&gt;

\[\vert x_i-e_{ij}\vert\le \vert x_j-e_{ji}\vert,\]

&lt;p&gt;where \(x_i\) is the starting positions of the particle on &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(i\),&lt;/span&gt; \(e_i\) is the known position on &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(i\)&lt;/span&gt; of its intersection with &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(j\),&lt;/span&gt; \(\vert x_i-e_{ij}\vert\) is the distance from the starting position to the intersection, and the smaller distance for the particle on &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(i\)&lt;/span&gt; means that it gets to the intersection first, causing the other particle to crash into its track. We also have some inequalities specifying that each starting position lies between the endpoints of its line segment. This almost looks like a linear program (or rather a linear programming feasability problem, with only linear constraints but no objective function), but the absolute values make it nonlinear. We can get rid of them by two tricks:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Because the left absolute value occurs on the left hand side of a &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\le\) constraint,&lt;/span&gt; it is equivalent to replace it by two constraints, one for each choice of sign:&lt;/p&gt;

\[x_i-e_{ij}\le \vert x_j-e_{ji}\vert,\]

    &lt;p&gt;and&lt;/p&gt;

\[e_{ij}-x_i\le \vert x_j-e_{ji}\vert.\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Because &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(j\)&lt;/span&gt; ends at its intersection with &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(i\),&lt;/span&gt; we know on which side of the intersection to find the starting &lt;span style=&quot;white-space:nowrap&quot;&gt;point \(x_j\),&lt;/span&gt; and therefore, we know the sign &lt;span style=&quot;white-space:nowrap&quot;&gt;of \(x_j-e_{ji}\).&lt;/span&gt; We can use this knowledge to replace \(\vert x_j-e_{ji}\vert\) by either \(x_j-e_{ji}\) or \(e_{ji}-x_j\) (whichever of these two expressions is guaranteed to be non-negative), eliminating the right absolute value.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once these replacements have been made, we have a linear program with two variables per inequality, which can be solved in (strongly) polynomial time.&lt;/p&gt;

&lt;p&gt;But all this made me wonder: can we always turn a system of inequaties between linear distances like this into a linear program? Suppose we have an arbitrary system of variables \(x_i\) and an arbitrary system of &lt;span style=&quot;white-space:nowrap&quot;&gt;inequalities \(\vert x_i-e_{ij}\vert\le \vert x_j-e_{ji}\vert\),&lt;/span&gt; not coming from Gilbert tessellation recognition. Can we determine whether such a system has a solution, efficiently? Can we maybe turn any system of inequalities like this into a linear program, and solve it that way?&lt;/p&gt;

&lt;p&gt;No! The problem is &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\mathsf{NP}\)-complete.&lt;/span&gt; The illustration below shows the key gadget, a system of six inequalities for two variables (each shown with a small blue double wedge in the plane pointing towards the points that obey the inequality). These inequalities have only the three red points shown as their solutions. You might want only one inequality per pair of variables, but in that case you can get the same effect by replacing each inequality by a pair of inequalities involving an additional dummy variable. The &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\mathsf{NP}\)-completeness&lt;/span&gt; proof is a reduction from graph 3-coloring that translates each vertex into one of these gadgets, and represents the color of a vertex by the choice of which red point is used to solve these inequalities. I haven’t shown the edge gadgets, but it’s easy to find more inequalities to use for a pair of vertices, to force them to have different red points as their solutions. For instance, the &lt;span style=&quot;white-space:nowrap&quot;&gt;inequality \(\vert x_i\vert\ge\vert y_j-1\vert\)&lt;/span&gt; fails only for two vertices that both use the same red point \((0,0)\).&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;/blog/assets/2022/vertex-gadget.svg&quot; alt=&quot;Vertex gadget for reduction from 3-coloring to linear distance comparison, consisting of six inequalities abs(x) ≤ abs(y-4), abs(x+2) ≥ abs(y-2), abs(x-2) ≥ abs(y-2), abs(x+1) ≥ abs(y+1), abs(x-1) ≥ abs(y+1), and abs(x) ≤ abs(y+2), that force the two variables (x,y) to have one of the three combinations of values (3,1), (-3,1), or (0,0)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So somehow, the geometry of Gilbert tessellations is essential for the ability to convert their recognition problem into a linear program, and solve it efficiently.&lt;/p&gt;

&lt;p&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108977122069764388&quot;&gt;Discuss on Mastodon&lt;/a&gt;)&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By David Eppstein&lt;/p&gt;
  </content>
    <author>
      <name>David Eppstein</name>
      <uri>https://11011110.github.io/blog/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Decentralized Thoughts: Provable Broadcast</title>
    <link href="https://decentralizedthoughts.github.io/2022-09-10-provable-broadcast/"/>
    <id>https://decentralizedthoughts.github.io/2022-09-10-provable-broadcast/</id>
    <updated>2022-09-10T12:00:00+00:00</updated>
    <content type="html" xml:lang="en">
    We explore a family of broadcast protocols in the authenticated setting in which a designated sender wants to create a delivery-certificate of its input value. After describing the base protocol we call Provable Broadcast ($PB$), we explore the surprising power of simply running $PB$ two times in a row, then...
  </content>
    <author>
      <name>Decentralized Thoughts</name>
      <uri>https://decentralizedthoughts.github.io</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: faculty at University of Oxford (apply by December 14, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/09/09/faculty-at-university-of-oxford-apply-by-december-14-2022/"/>
    <id>http://cstheory-jobs.org/2022/09/09/faculty-at-university-of-oxford-apply-by-december-14-2022/</id>
    <updated>2022-09-09T09:25:08+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Oxford University’s Computer Science Department is hiring four new faculty. The positions are open to all areas of computer science and the closing date is 12 noon on 14 December 2022.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.cs.ox.ac.uk/aboutus/vacancies/vacancy-faculty-hiring.html&quot;&gt;https://www.cs.ox.ac.uk/aboutus/vacancies/vacancy-faculty-hiring.html&lt;/a&gt;&lt;br /&gt;
Email: hr@cs.ox.ac.uk&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-125 |  Tensor Reconstruction Beyond Constant Rank | 

	Shir Peleg, 

	Amir Shpilka, 

	Ben Lee Volk</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/125"/>
    <id>https://eccc.weizmann.ac.il/report/2022/125</id>
    <updated>2022-09-09T09:12:30+00:00</updated>
    <content type="html" xml:lang="en">
    We give reconstruction algorithms for subclasses of depth-$3$ arithmetic circuits. In particular, we obtain the first efficient algorithm for finding tensor rank, and an optimal tensor decomposition as a sum of rank-one tensors, when given black-box access to a tensor of super-constant rank.  Specifically, we obtain the following results:

1. A deterministic algorithm that reconstructs polynomials computed by $\Sigma^{[k]}\bigwedge^{[d]}\Sigma$ circuits in time $\mathrm{poly}(n,d,c) \cdot \mathrm{poly}(k)^{k^{k^{10}}}$,
2. A randomized algorithm that reconstructs polynomials computed by multilinear $\Sigma^{[k]}\prod^{[d]}\Sigma$ circuits in time $\mathrm{poly}(n,d,c) \cdot k^{k^{k^{k^{O(k)}}}}$, 
3. A randomized algorithm that reconstructs polynomials computed by set-multilinear $\Sigma^{[k]}\prod^{[d]}\Sigma$ circuits in time $\mathrm{poly}(n,d,c) \cdot k^{k^{k^{k^{O(k)}}}}$,

where $c=\log q$ if $\mathbb{F}=\mathbb{F}_q$ is a finite field, and $c$ equals the maximum bit complexity of any coefficient of $f$ if $\mathbb{F}$ is infinite.
		
Prior to our work, polynomial time algorithms for the case when the rank, $k$, is constant, were given by Bhargava, Saraf and Volkovich ([BSV21]). 
		
Another contribution of this work is correcting an error from a paper of Karnin and Shpilka [KS09] (with some loss in parameters) that also affected Theorem 1.6 of [BSV21]. Consequently, the results of [KS09, BSV21] continue to hold, with a slightly worse setting of parameters. For fixing the error we systematically study the relation between syntactic  and semantic notions of rank of $\Sigma\Pi\Sigma$ circuits, and the corresponding partitions of such circuits. 
		
We obtain our improved running time by introducing a technique for learning rank preserving coordinate-subspaces. Both [KS09] and [BSV21] tried all choices of finding the &amp;quot;correct&amp;quot; coordinates, which, due to the size of the set, led to having a fast growing function of $k$ at the exponent of $n$. We manage to find these spaces in time that is still growing fast with $k$, yet it is only a fixed polynomial in $n$.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-124 |  On Interactive Proofs of Proximity with Proof-Oblivious Queries | 

	Oded Goldreich, 

	Guy Rothblum, 

	Tal Skverer</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/124"/>
    <id>https://eccc.weizmann.ac.il/report/2022/124</id>
    <updated>2022-09-09T08:31:15+00:00</updated>
    <content type="html" xml:lang="en">
    Interactive proofs of proximity (IPPs) offer ultra-fast
approximate verification of assertions regarding their input,
where ultra-fast means that only a small portion of the input is read
and approximate verification is analogous to the notion of
approximate decision that underlies property testing.
Specifically, in an IPP, the prover can make the verifier
accept each input in the property, but cannot fool the verifier
into accepting an input that is far from the property
(except for with small probability).

The verifier in an IPP system engages in two very different types 
of activities: interacting with an untrusted prover, and querying its input. 
The definition allows for arbitrary coordination between these two activities, 
but keeping them separate is both conceptually interesting 
and necessary for important applications 
such as addressing temporal considerations 
(i.e., at what time is each of the services available)
and facilitating the construction of zero-knowledge schemes. 
In this work we embark on a systematic study of IPPs 
with proof-oblivious queries, where the queries should not be affected 
by the interaction with the prover. 
We assign the query and interaction activities to separate modules, 
and consider different limitations on their coordination.

The most strict limitation requires these activities to
be totally isolated from one another; they just feed
their views to a separate deciding module. 
We show that such systems can be efficiently emulated by standard testers.

Going to the other extreme, we only disallow information
to flow from the interacting module to the querying module,
but allow free information flow in the other direction.
We show that extremely efficient one-round (i.e., two-message) systems 
of such type can be used to verify properties that are extremely
hard to test (without the help of a prover).
That is, the complexity of verifying can be polylogarithmic in the complexity of testing.
This stands in contrast the MAPs (viewed as $1/2$-round systems)
in which proof-oblivious queries are as limited as our isolated model.

Our focus is on an intermediate model that allows
shared randomness among the querying and interacting modules 
but no information flow between them. 
In this case we show 
that 1-round systems are efficiently emulated by standard testers 
but $3/2$-round systems of extremely low complexity 
exist for properties that are extremely hard to test. 
One additional result about this model is that it can
efficiently emulate any IPP for any property of low-degree polynomials.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


</feed>
