<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Theory of Computing Report</title>
  <link rel="self" href=""/>
  <link href=""/>
  <id></id>
  <updated></updated>
  <generator uri="http://feedreader.github.io/">Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]</generator>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-137 |  On blocky ranks of matrices | 

	Daniel Avraham , 

	Amir Yehudayoff</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/137"/>
    <id>https://eccc.weizmann.ac.il/report/2022/137</id>
    <updated>2022-09-27T12:24:21+00:00</updated>
    <content type="html" xml:lang="en">
    A matrix is blocky if it is a blowup of a permutation matrix. The blocky rank of a matrix M is the minimum number of blocky matrices that linearly span M. Hambardzumyan, Hatami and Hatami defined blocky rank and showed that it is connected to communication complexity and operator theory. We describe additional connections to circuit complexity and combinatorics, and we prove upper and lower bounds on blocky rank in various contexts.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: Is the complexity of approximating Vertex Cover of degree 3 open?</title>
    <link href="http://blog.computationalcomplexity.org/2022/09/is-complexity-of-vertex-cover-of-degree.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-1313340574525713217</id>
    <updated>2022-09-27T02:02:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&amp;nbsp;RECALL:&lt;/p&gt;&lt;p&gt;A max-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that&lt;/p&gt;&lt;p&gt;&amp;nbsp;ALG(\epsilon) \ge (1-\epsilon)f(x).&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;A min-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that&lt;/p&gt;&lt;p&gt;&amp;nbsp;ALG(\epsilon) \le (1+\epsilon)f(x).&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;(Note that the poly can depend on epsilon so it may be something like n^{1/epsilon}.)&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;MAX3SAT is, given a formula with \le 3 literals per clause, find an assignment&lt;/p&gt;&lt;p&gt;that maximized the number of clauses satisfied.&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;VCB-a is Vertex cover where graphs have degree \le a&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;The following are known:&lt;/p&gt;&lt;p&gt;0) MAX3SAT is in APX.&lt;/p&gt;&lt;p&gt;1) The PCP paper,&amp;nbsp;&lt;a href=&quot;https://doi.org/10.1145/278298.278306&quot;&gt;here&lt;/a&gt;, showed that if MAX3SAT has a PTAS then P=NP.&lt;/p&gt;&lt;p&gt;2) Papadimitriou and Yannakakis (&lt;a href=&quot;https://doi.org/10.1016/0022-0000(91)90023-X&quot;&gt;here&lt;/a&gt;)&amp;nbsp; had showed much earlier that MAX3SAT \le VCB-4 with an approx preserving reduction.&lt;/p&gt;&lt;p&gt;3) From (1) and (2) we have that VCB-4 has a PTAS then P=NP. (VC is in APX by an easy 2-approx).&lt;/p&gt;&lt;p&gt;4) Clearly VCB-2 is in P.&lt;/p&gt;&lt;p&gt;The following seems to be open, though if you know otherwise pleae leave a comment:&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;Is VCB-3 a) in P? b) NPC? (ADDED LATER- NPC- See comments.)&amp;nbsp;&lt;/p&gt;&lt;p&gt;Is the following true: if VCB-3 has a PTAS then P=NP.&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;NOTE- all of the above is true for Ind Set-4 and Dom Set-4. So that leads to more open problems.&lt;/p&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;p class=&quot;authors&quot;&gt;By gasarch&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: A characterization of functions over the integers computable in polynomial time using discrete differential equations</title>
    <link href="http://arxiv.org/abs/2209.12168"/>
    <id>http://arxiv.org/abs/2209.12168</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bournez_O/0/1/0/all/0/1&quot;&gt;Olivier Bournez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durand_A/0/1/0/all/0/1&quot;&gt;Arnaud Durand&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper studies the expressive and computational power of discrete
Ordinary Differential Equations (ODEs), a.k.a. (Ordinary) Difference Equations.
It presents a new framework using these equations as a central tool for
computation and algorithm design. We present the general theory of discrete
ODEs for computation theory, we illustrate this with various examples of
algorithms, and we provide several implicit characterizations of complexity and
computability classes.
&lt;/p&gt;
&lt;p&gt;The proposed framework presents an original point of view on complexity and
computation classes. It unifies several constructions that have been proposed
for characterizing these classes including classical approaches in implicit
complexity using restricted recursion schemes, as well as recent
characterizations of computability and complexity by classes of continuous
ordinary differential equations. It also helps understanding the relationships
between analog computations and classical discrete models of computation
theory.
&lt;/p&gt;
&lt;p&gt;At a more technical point of view, this paper points out the fundamental role
of linear (discrete) ODEs and classical ODE tools such as changes of variables
to capture computability and complexity measures, or as a tool for programming
many algorithms.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret</title>
    <link href="http://arxiv.org/abs/2209.11817"/>
    <id>http://arxiv.org/abs/2209.11817</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1&quot;&gt;Matthew Jones&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1&quot;&gt;Huy L&amp;#xea; Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thy Nguyen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Recently a multi-agent variant of the classical multi-armed bandit was
proposed to tackle fairness issues in online learning. Inspired by a long line
of work in social choice and economics, the goal is to optimize the Nash social
welfare instead of the total utility. Unfortunately previous algorithms either
are not efficient or achieve sub-optimal regret in terms of the number of
rounds $T$. We propose a new efficient algorithm with lower regret than even
previous inefficient ones. For $N$ agents, $K$ arms, and $T$ rounds, our
approach has a regret bound of $\tilde{O}(\sqrt{NKT} + NK)$. This is an
improvement to the previous approach, which has regret bound of $\tilde{O}(
\min(NK, \sqrt{N} K^{3/2})\sqrt{T})$. We also complement our efficient
algorithm with an inefficient approach with $\tilde{O}(\sqrt{KT} + N^2K)$
regret. The experimental findings confirm the effectiveness of our efficient
algorithm compared to the previous approaches.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: The Online Knapsack Problem with Departures</title>
    <link href="http://arxiv.org/abs/2209.11934"/>
    <id>http://arxiv.org/abs/2209.11934</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1&quot;&gt;Bo Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajiesmaili_M/0/1/0/all/0/1&quot;&gt;Mohammad Hajiesmaili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1&quot;&gt;Adam Wierman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1&quot;&gt;John C.S. Lui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Towsley_D/0/1/0/all/0/1&quot;&gt;Don Towsley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsang_D/0/1/0/all/0/1&quot;&gt;Danny H.K. Tsang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The online knapsack problem is a classic online resource allocation problem
in networking and operations research. Its basic version studies how to pack
online arriving items of different sizes and values into a capacity-limited
knapsack. In this paper, we study a general version that includes item
departures, while also considering multiple knapsacks and multi-dimensional
item sizes. We design a threshold-based online algorithm and prove that the
algorithm can achieve order-optimal competitive ratios. Beyond worst-case
performance guarantees, we also aim to achieve near-optimal average performance
under typical instances. Towards this goal, we propose a data-driven online
algorithm that learns within a policy-class that guarantees a worst-case
performance bound. In trace-driven experiments, we show that our data-driven
algorithm outperforms other benchmark algorithms in an application of online
knapsack to job scheduling for cloud computing.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Online Admission Control and Rebalancing in Payment Channel Networks</title>
    <link href="http://arxiv.org/abs/2209.11936"/>
    <id>http://arxiv.org/abs/2209.11936</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bastankhah_M/0/1/0/all/0/1&quot;&gt;Mahsa Bastankhah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_K/0/1/0/all/0/1&quot;&gt;Krishnendu Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maddah_Ali_M/0/1/0/all/0/1&quot;&gt;Mohammad Ali Maddah-Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1&quot;&gt;Stefan Schmid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svoboda_J/0/1/0/all/0/1&quot;&gt;Jakub Svoboda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeo_M/0/1/0/all/0/1&quot;&gt;Michelle Yeo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Payment channel networks (PCNs) are a promising technology to improve the
scalability of cryptocurrencies. PCNs, however, face the challenge that the
frequent usage of certain routes may deplete channels in one direction, and
hence prevent further transactions. In order to reap the full potential of
PCNs, recharging and rebalancing mechanisms are required to provision channels,
as well as an admission control logic to decide which transactions to reject in
case capacity is insufficient. This paper presents a formal model of this
optimisation problem. In particular, we consider an online algorithms
perspective, where transactions arrive over time in an unpredictable manner.
Our main contributions are competitive online algorithms which come with
provable guarantees over time. We empirically evaluate our algorithms on
randomly generated transactions to compare the average performance of our
algorithms to our theoretical bounds. We also show how this model and approach
differs from related problems in classic communication networks.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Non-monotonic Resource Utilization in the Bandits with Knapsacks Problem</title>
    <link href="http://arxiv.org/abs/2209.12013"/>
    <id>http://arxiv.org/abs/2209.12013</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1&quot;&gt;Raunak Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleinberg_R/0/1/0/all/0/1&quot;&gt;Robert Kleinberg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Bandits with knapsacks (BwK) is an influential model of sequential
decision-making under uncertainty that incorporates resource consumption
constraints. In each round, the decision-maker observes an outcome consisting
of a reward and a vector of nonnegative resource consumptions, and the budget
of each resource is decremented by its consumption. In this paper we introduce
a natural generalization of the stochastic BwK problem that allows
non-monotonic resource utilization. In each round, the decision-maker observes
an outcome consisting of a reward and a vector of resource drifts that can be
positive, negative or zero, and the budget of each resource is incremented by
its drift. Our main result is a Markov decision process (MDP) policy that has
constant regret against a linear programming (LP) relaxation when the
decision-maker knows the true outcome distributions. We build upon this to
develop a learning algorithm that has logarithmic regret against the same LP
relaxation when the decision-maker does not know the true outcome
distributions. We also present a reduction from BwK to our model that shows our
regret bound matches existing results.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improving the Bounds of the Online Dynamic Power Management Problem</title>
    <link href="http://arxiv.org/abs/2209.12021"/>
    <id>http://arxiv.org/abs/2209.12021</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Ya-Chun Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iwama_K/0/1/0/all/0/1&quot;&gt;Kazuo Iwama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1&quot;&gt;Chung-Shou Liao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We investigate the {\em power-down mechanism} which decides when a machine
transitions between states such that the total energy consumption,
characterized by execution cost, idle cost and switching cost, is minimized. In
contrast to most of the previous studies on the offline model, we focus on the
online model in which a sequence of jobs with their release time, execution
time and deadline, arrive in an online fashion. More precisely, we exploit a
different switching on and off strategy and present an upper bound of 3, and
further show a lower bound of 2.1, in a dual-machine model, introduced by Chen
et al. in 2014 [STACS 2014: 226-238], both of which beat the currently best
result.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Twin-width V: linear minors, modular counting, and matrix multiplication</title>
    <link href="http://arxiv.org/abs/2209.12023"/>
    <id>http://arxiv.org/abs/2209.12023</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonnet_E/0/1/0/all/0/1&quot;&gt;&amp;#xc9;douard Bonnet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giocanti_U/0/1/0/all/0/1&quot;&gt;Ugo Giocanti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendez_P/0/1/0/all/0/1&quot;&gt;Patrice Ossona de Mendez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomasse_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phan Thomass&amp;#xe9;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We continue developing the theory around the twin-width of totally ordered
binary structures, initiated in the previous paper of the series. We first
introduce the notion of parity and linear minors of a matrix, which consists of
iteratively replacing consecutive rows or consecutive columns with a linear
combination of them. We show that a matrix class has bounded twin-width if and
only if its linear-minor closure does not contain all matrices. We observe that
the fixed-parameter tractable algorithm for first-order model checking on
structures given with an $O(1)$-sequence (certificate of bounded twin-width)
and the fact that first-order transductions of bounded twin-width classes have
bounded twin-width, both established in Twin-width I, extend to first-order
logic with modular counting quantifiers. We make explicit a win-win argument
obtained as a by-product of Twin-width IV, and somewhat similar to
bidimensionality, that we call rank-bidimensionality. Armed with the
above-mentioned extension to modular counting, we show that the twin-width of
the product of two conformal matrices $A, B$ over a finite field is bounded by
a function of the twin-width of $A$, of $B$, and of the size of the field.
Furthermore, if $A$ and $B$ are $n \times n$ matrices of twin-width $d$ over
$\mathbb F_q$, we show that $AB$ can be computed in time $O_{d,q}(n^2 \log n)$.
We finally present an ad hoc algorithm to efficiently multiply two matrices of
bounded twin-width, with a single-exponential dependence in the twin-width
bound: If the inputs are given in a compact tree-like form, called
twin-decomposition (of width $d$), then two $n \times n$ matrices $A, B$ over
$\mathbb F_2$, a twin-decomposition of $AB$ with width $2^{d+o(d)}$ can be
computed in time $4^{d+o(d)}n$ (resp. $4^{d+o(d)}n^{1+\varepsilon}$), and
entries queried in doubly-logarithmic (resp. constant) time.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Compressing bipartite graphs with a dual reordering scheme</title>
    <link href="http://arxiv.org/abs/2209.12062"/>
    <id>http://arxiv.org/abs/2209.12062</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Danisch_M/0/1/0/all/0/1&quot;&gt;Maximilien Danisch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panagiotas_I/0/1/0/all/0/1&quot;&gt;Ioannis Panagiotas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabourier_L/0/1/0/all/0/1&quot;&gt;Lionel Tabourier&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In order to manage massive graphs in practice, it is often necessary to
resort to graph compression, which aims at reducing the memory used when
storing and processing the graph. Efficient compression methods have been
proposed in the literature, especially for web graphs. In most cases, they are
combined with a vertex reordering pre-processing step which significantly
improves the compression rate. However, these techniques are not as efficient
when considering other kinds of graphs. In this paper, we focus on the class of
bipartite graphs and adapt the vertex reordering phase to their specific
structure by proposing a dual reordering scheme. By reordering each group of
vertices in the purpose of minimizing a specific score, we show that we can
reach better compression rates. We also suggest that this approach can be
further refined to make the node orderings more adapted to the compression
phase that follows the ordering phase.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Augmentation based Approximation Algorithms for Flexible Network Design</title>
    <link href="http://arxiv.org/abs/2209.12273"/>
    <id>http://arxiv.org/abs/2209.12273</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chekuri_C/0/1/0/all/0/1&quot;&gt;Chandra Chekuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1&quot;&gt;Rhea Jain&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Adjiashvili introduced network design in a non-uniform fault model: the edge
set of a given graph is partitioned into safe and unsafe edges. A vertex pair
$(s,t)$ is $(p,q)$-flex-connected if $s$ and $t$ have $p$ edge-connectivity
even after the removal of any $q$ unsafe edges. Given a graph $G$, the goal is
to choose a min-cost subgraph $H$ of $G$ that has desired flex-connectivity for
a given set of vertex pairs. This model generalizes the well-studied
edge-connectivity based network design, however, even special cases are
provably much harder to approximate.
&lt;/p&gt;
&lt;p&gt;The approximability of network design in this model has been mainly studied
for two settings of interest: (i) single pair setting under the names FTP and
FTF (fault tolerant path and fault tolerant flow), (ii) spanning setting under
the name FGC (flexible graph connectivity). There have been several positive
results in these papers. However, despite similarity to the well-known network
design problems, this new model has been challenging to design approximation
algorithms for, especially when $p,q \ge 2$. We obtain two results that advance
our understanding of algorithm design in this model.
&lt;/p&gt;
&lt;p&gt;1. We obtain a $5$-approximation for the $(2,2)$-flex-connectivity for a
single pair $(s,t)$. Previously no non-trivial approximation was known for this
setting.
&lt;/p&gt;
&lt;p&gt;2. We obtain $O(p)$ approximation for $(p,2)$ and $(p,3)$-FGC for any $p \ge
1$, and for $(p,4)$-FGC for any even $p$. We obtain an $O(q)$-approximation for
$(2,q)$-FGC for any $q \ge 1$. Previously only a $O(q \log n)$-approximation
was known for these settings.
&lt;/p&gt;
&lt;p&gt;Our results are obtained via the augmentation framework where we identify a
structured way to use the well-known $2$-approximation for covering uncrossable
families of cuts. Our analysis also proves corresponding integrality gap bounds
on an LP relaxation that we formulate.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Constant-delay enumeration for SLP-compressed documents</title>
    <link href="http://arxiv.org/abs/2209.12301"/>
    <id>http://arxiv.org/abs/2209.12301</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munoz_M/0/1/0/all/0/1&quot;&gt;Mart&amp;#xed;n Mu&amp;#xf1;oz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riveros_C/0/1/0/all/0/1&quot;&gt;Cristian Riveros&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the problem of enumerating results from a query over a compressed
document. The model we use for compression are straight-line programs (SLPs),
which are defined by a context-free grammar that produces a single string. For
our queries we use a model called Annotated Automata, an extension of regular
automata that allows annotations on letters. This model extends the notion of
Regular Spanners as it allows arbitrarily long outputs. Our main result is an
algorithm which evaluates such a query by enumerating all results with
output-linear delay after a preprocessing phase which takes linear time on the
size of the SLP, and cubic time over the size of the automaton. This is an
improvement over Schmid and Schweikardt&#39;s result, which, with the same
preprocessing time, enumerates with a delay which is logarithmic on the size of
the uncompressed document. We achieve this through a persistent data structure
named Enumerable Compact Sets with Shifts which guarantees output-linear delay
under certain restrictions. These results imply constant-delay enumeration
algorithms in the context of regular spanners. Further, we use an extension of
annotated automata which utilizes succinctly encoded annotations to save an
exponential factor from previous results that dealt with constant-delay
enumeration over vset automata. Lastly, we extend our results in the same
fashion Schmid and Schweikardt did to allow complex document editing while
maintaining the constant-delay guarantee.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Random graph matching at Otter&#39;s threshold via counting chandeliers</title>
    <link href="http://arxiv.org/abs/2209.12313"/>
    <id>http://arxiv.org/abs/2209.12313</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1&quot;&gt;Cheng Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yihong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiaming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Sophie H. Yu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We propose an efficient algorithm for graph matching based on similarity
scores constructed from counting a certain family of weighted trees rooted at
each vertex. For two Erd\H{o}s-R\&#39;enyi graphs $\mathcal{G}(n,q)$ whose edges
are correlated through a latent vertex correspondence, we show that this
algorithm correctly matches all but a vanishing fraction of the vertices with
high probability, provided that $nq\to\infty$ and the edge correlation
coefficient $\rho$ satisfies $\rho^2&amp;gt;\alpha \approx 0.338$, where $\alpha$ is
Otter&#39;s tree-counting constant. Moreover, this almost exact matching can be
made exact under an extra condition that is information-theoretically
necessary. This is the first polynomial-time graph matching algorithm that
succeeds at an explicit constant correlation and applies to both sparse and
dense graphs. In comparison, previous methods either require $\rho=1-o(1)$ or
are restricted to sparse graphs.
&lt;/p&gt;
&lt;p&gt;The crux of the algorithm is a carefully curated family of rooted trees
called chandeliers, which allows effective extraction of the graph correlation
from the counts of the same tree while suppressing the undesirable correlation
between those of different trees.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Package Delivery Using Drones with Restricted Movement Areas</title>
    <link href="http://arxiv.org/abs/2209.12314"/>
    <id>http://arxiv.org/abs/2209.12314</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erlebach_T/0/1/0/all/0/1&quot;&gt;Thomas Erlebach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_K/0/1/0/all/0/1&quot;&gt;Kelin Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spieksma_F/0/1/0/all/0/1&quot;&gt;Frits C.R. Spieksma&lt;/a&gt;&lt;/p&gt;&lt;p&gt;For the problem of delivering a package from a source node to a destination
node in a graph using a set of drones, we study the setting where the movements
of each drone are restricted to a certain subgraph of the given graph. We
consider the objectives of minimizing the delivery time (problem DDT) and of
minimizing the total energy consumption (problem DDC). For general graphs, we
show a strong inapproximability result and a matching approximation algorithm
for DDT as well as NP-hardness and a 2-approximation algorithm for DDC. For the
special case of a path, we show that DDT is NP-hard if the drones have
different speeds. For trees, we give optimal algorithms under the assumption
that all drones have the same speed or the same energy consumption rate. The
results for trees extend to arbitrary graphs if the subgraph of each drone is
isometric.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Tree decompositions with bounded independence number: beyond independent sets</title>
    <link href="http://arxiv.org/abs/2209.12315"/>
    <id>http://arxiv.org/abs/2209.12315</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milanic_M/0/1/0/all/0/1&quot;&gt;Martin Milani&amp;#x10d;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rzazewski_P/0/1/0/all/0/1&quot;&gt;Pawe&amp;#x142; Rz&amp;#x105;&amp;#x17c;ewski&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We continue the study of graph classes in which the treewidth can only be
large due to the presence of a large clique, and, more specifically, of graph
classes with bounded tree-independence number. In [Dallard, Milani\v{c}, and
\v{S}torgel, Treewidth versus clique number. {II}. Tree-independence number,
2022], it was shown that the Maximum Weight Independent Packing problem, which
is a common generalization of the Independent Set and Induced Matching
problems, can be solved in polynomial time provided that the input graph is
given along with a tree decomposition with bounded independence number. We
provide further examples of algorithmic problems that can be solved in
polynomial time under this assumption. This includes, for all even positive
integers $d$, the problem of packing subgraphs at distance at least $d$
(generalizing the Maximum Weight Independent Packing problem) and the problem
of finding a large induced sparse subgraph satisfying an arbitrary but fixed
property expressible in counting monadic second-order logic. As part of our
approach, we generalize some classical results on powers of chordal graphs to
the context of general graphs and their tree-independence numbers.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On the Optimal Linear Contraction Order for Tree Tensor Networks</title>
    <link href="http://arxiv.org/abs/2209.12332"/>
    <id>http://arxiv.org/abs/2209.12332</id>
    <updated>2022-09-27T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Stoian_M/0/1/0/all/0/1&quot;&gt;Mihail Stoian&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Tensor networks are nowadays the backbone of classical simulations of quantum
many-body systems and quantum circuits. Most tensor methods rely on the fact
that we can eventually contract the tensor network to obtain the final result.
While the contraction operation itself is trivial, its execution time is highly
dependent on the order in which the contractions are performed. To this end,
one tries to find beforehand an optimal order in which the contractions should
be performed. However, there is a drawback: the general problem of finding the
optimal contraction order is NP-complete. Therefore, one must settle for a
mixture of exponential algorithms for small problems, e.g., $n \leq 20$, and
otherwise hope for good contraction orders. For this reason, previous research
has focused on the latter part, trying to find better heuristics.
&lt;/p&gt;
&lt;p&gt;In this work, we take a more conservative approach and show that tree tensor
networks accept optimal linear contraction orders. Beyond the optimality
results, we adapt two join ordering techniques that can build on our work to
guarantee near-optimal orders for arbitrary tensor networks.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: The complexity of unsupervised learning of lexicographic preferences</title>
    <link href="http://arxiv.org/abs/2209.11505"/>
    <id>http://arxiv.org/abs/2209.11505</id>
    <updated>2022-09-26T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fargier_H/0/1/0/all/0/1&quot;&gt;H&amp;#xe9;l&amp;#xe8;ne Fargier&lt;/a&gt; (IRIT-ADRIA, ANITI), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gimenez_P/0/1/0/all/0/1&quot;&gt;Pierre-Fran&amp;#xe7;ois Gimenez&lt;/a&gt; (CIDRE), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mengin_J/0/1/0/all/0/1&quot;&gt;J&amp;#xe9;r&amp;#xf4;me Mengin&lt;/a&gt; (IRIT-ADRIA, ANITI), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1&quot;&gt;Bao Ngoc Le Nguyen&lt;/a&gt; (INSA Toulouse)&lt;/p&gt;&lt;p&gt;This paper considers the task of learning users&#39; preferences on a
combinatorial set of alternatives, as generally used by online configurators,
for example. In many settings, only a set of selected alternatives during past
interactions is available to the learner. Fargier et al. [2018] propose an
approach to learn, in such a setting, a model of the users&#39; preferences that
ranks previously chosen alternatives as high as possible; and an algorithm to
learn, in this setting, a particular model of preferences: lexicographic
preferences trees (LP-trees). In this paper, we study complexity-theoretical
problems related to this approach. We give an upper bound on the sample
complexity of learning an LP-tree, which is logarithmic in the number of
attributes. We also prove that computing the LP tree that minimises the
empirical risk can be done in polynomial time when restricted to the class of
linear LP-trees.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: An Algebraic-Geometry Approach to Prime Factorization</title>
    <link href="http://arxiv.org/abs/2209.11650"/>
    <id>http://arxiv.org/abs/2209.11650</id>
    <updated>2022-09-26T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montina_A/0/1/0/all/0/1&quot;&gt;Alberto Montina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_S/0/1/0/all/0/1&quot;&gt;Stefan Wolf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;New algorithms for prime factorization that outperform the existing ones or
take advantage of particular properties of the prime factors can have a
practical impact on present implementations of cryptographic algorithms that
rely on the complexity of factorization. Currently used keys are chosen on the
basis of the present algorithmic knowledge and, thus, can potentially be
subject to future breaches. For this reason, it is worth to investigate new
approaches which have the potentiality of giving a computational advantage. The
problem has also relevance in quantum computation, as an efficient quantum
algorithm for prime factorization already exists. Thus, better classical
asymptotic complexity can provide a better understanding of the advantages
offered by quantum computers. In this paper, we reduce the factorization
problem to the search of points of parametrizable varieties, in particular
curves, over finite fields. The varieties are required to have an arbitrarily
large number of intersection points with some hypersurface over the base field.
For a subexponential or poly- nomial factoring complexity, the number of
parameters have to scale sublinearly in the space dimension n and the
complexity of computing a point given the parameters has to be subexponential
or polynomial, respectively. We outline a procedure for building these
varieties, which is illustrated with two constructions. In one case, we show
that there are varieties whose points can be evaluated efficiently given a
number of parameters not greater than n/2. In the other case, the bound is
dropped to n/3. Incidentally, the first construction resembles a kind of
retro-causal model. Retro-causality is considered one possible explanation of
quantum weirdness.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Piercing Diametral Disks Induced by Edges of Maximum Spanning Tree</title>
    <link href="http://arxiv.org/abs/2209.11260"/>
    <id>http://arxiv.org/abs/2209.11260</id>
    <updated>2022-09-26T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abu_Affash_A/0/1/0/all/0/1&quot;&gt;A. Karim Abu-Affash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carmi_P/0/1/0/all/0/1&quot;&gt;Paz Carmi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maman_M/0/1/0/all/0/1&quot;&gt;Meytal Maman&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $P$ be a set of points in the plane and let $T$ be a maximum-weight
spanning tree of $P$. For an edge $(p,q)$, let $D_{pq}$ be the diametral disk
induced by $(p,q)$, i.e., the disk having the segment $\overline{pq}$ as its
diameter. Let $\cal{D_T}$ be the set of the diametral disks induced by the
edges of $T$. In this paper, we show that one point is sufficient to pierce all
the disks in $\cal{D_T}$, thus, the set $\cal{D_T}$ is Helly. Actually, we show
that the center of the smallest enclosing circle of $P$ is contained in all the
disks of $\cal{D_T}$, and thus the piercing point can be computed in linear
time.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: An extension to VORO++ for multithreaded computation of Voronoi cells</title>
    <link href="http://arxiv.org/abs/2209.11606"/>
    <id>http://arxiv.org/abs/2209.11606</id>
    <updated>2022-09-26T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jiayin Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lazar_E/0/1/0/all/0/1&quot;&gt;Emanuel A. Lazar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Rycroft_C/0/1/0/all/0/1&quot;&gt;Chris H. Rycroft&lt;/a&gt;&lt;/p&gt;&lt;p&gt;VORO++ is a software library written in C++ for computing the Voronoi
tessellation, a technique in computational geometry that is widely used for
analyzing systems of particles. VORO++ was released in 2009 and is based on
computing the Voronoi cell for each particle individually. Here, we take
advantage of modern computer hardware, and extend the original serial version
to allow for multithreaded computation of Voronoi cells via the OpenMP
application programming interface. We test the performance of the code, and
demonstrate that we can achieve parallel efficiencies greater than 95% in many
cases. The multithreaded extension follows standard OpenMP programming
paradigms, allowing it to be incorporated into other programs. We provide an
example of this using the VoroTop software library, performing a multithreaded
Voronoi cell topology analysis of up to 102.4 million particles.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: From String Detection to Orthogonal Vector Problem</title>
    <link href="http://arxiv.org/abs/2209.11452"/>
    <id>http://arxiv.org/abs/2209.11452</id>
    <updated>2022-09-26T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yunhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zheng_T/0/1/0/all/0/1&quot;&gt;Tianyuan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Horesh_L/0/1/0/all/0/1&quot;&gt;Lior Horesh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Considering Grover&#39;s Search Algorithm (GSA) with the standard diffuser stage
applied, we revisit the $3$-qubit unique String Detection Problem (SDP) and
extend the algorithm to $4$-qubit SDP with multiple winners. We then
investigate unstructured search problems with non-uniform distributions and
define the Orthogonal Vector Problem (OVP) under quantum settings. Although no
numerically stable results is reached under the original GSA framework, we
provide intuition behind our implementation and further observations on OVP. We
further perform a special case analysis under the modified GSA framework which
aims to stabilize the final measurement under arbitrary initial distribution.
Based on the result of the analysis, we generalize the initial condition under
which neither the original framework nor the modification works. Instead of
utilizing GSA, we also propose a short-depth circuit that can calculate the
orthogonal pair for a given vector represented as a binary string with constant
runtime.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Local Distributed Rounding: Generalized to MIS, Matching, Set Cover, and Beyond</title>
    <link href="http://arxiv.org/abs/2209.11651"/>
    <id>http://arxiv.org/abs/2209.11651</id>
    <updated>2022-09-26T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faour_S/0/1/0/all/0/1&quot;&gt;Salwa Faour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1&quot;&gt;Mohsen Ghaffari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grunau_C/0/1/0/all/0/1&quot;&gt;Christoph Grunau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuhn_F/0/1/0/all/0/1&quot;&gt;Fabian Kuhn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rozhon_V/0/1/0/all/0/1&quot;&gt;V&amp;#xe1;clav Rozho&amp;#x148;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We develop a general deterministic distributed method for locally rounding
fractional solutions of graph problems for which the analysis can be broken
down into analyzing pairs of vertices. Roughly speaking, the method can
transform fractional/probabilistic label assignments of the vertices into
integral/deterministic label assignments for the vertices, while approximately
preserving a potential function that is a linear combination of functions, each
of which depends on at most two vertices (subject to some conditions usually
satisfied in pairwise analyses). The method unifies and significantly
generalizes prior work on deterministic local rounding techniques [Ghaffari,
Kuhn FOCS&#39;21; Harris FOCS&#39;19; Fischer, Ghaffari, Kuhn FOCS&#39;17; Fischer DISC&#39;17]
to obtain polylogarithmic-time deterministic distributed solutions for
combinatorial graph problems. Our general rounding result enables us to locally
and efficiently derandomize a range of distributed algorithms for local graph
problems, including maximal independent set (MIS), maximum-weight independent
set approximation, and minimum-cost set cover approximation. As a highlight, we
in particular obtain a deterministic $O(\log^2\Delta\cdot\log n)$-round
algorithm for computing an MIS in the LOCAL model and an almost as efficient
$O(\log^2\Delta\cdot\log\log\Delta\cdot\log n)$-round deterministic MIS
algorithm in the CONGEST model. As a result, the best known deterministic
distributed time complexity of the four most widely studied distributed
symmetry breaking problems (MIS, maximal matching, $(\Delta+1)$-vertex
coloring, and $(2\Delta-1)$-edge coloring) is now $O(\log^2\Delta\cdot\log n)$.
Our new MIS algorithm is also the first direct polylogarithmic-time
deterministic distributed MIS algorithm, which is not based on network
decomposition.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improved Distributed Network Decomposition, Hitting Sets, and Spanners, via Derandomization</title>
    <link href="http://arxiv.org/abs/2209.11669"/>
    <id>http://arxiv.org/abs/2209.11669</id>
    <updated>2022-09-26T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1&quot;&gt;Mohsen Ghaffari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grunau_C/0/1/0/all/0/1&quot;&gt;Christoph Grunau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haeupler_B/0/1/0/all/0/1&quot;&gt;Bernhard Haeupler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilchi_S/0/1/0/all/0/1&quot;&gt;Saeed Ilchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rozhon_V/0/1/0/all/0/1&quot;&gt;V&amp;#xe1;clav Rozho&amp;#x148;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper presents significantly improved deterministic algorithms for some
of the key problems in the area of distributed graph algorithms, including
network decomposition, hitting sets, and spanners. As the main ingredient in
these results, we develop novel randomized distributed algorithms that we can
analyze using only pairwise independence, and we can thus derandomize
efficiently. As our most prominent end-result, we obtain a deterministic
construction for $O(\log n)$-color $O(\log n \cdot \log\log\log n)$-strong
diameter network decomposition in $\tilde{O}(\log^3 n)$ rounds. This is the
first construction that achieves almost $\log n$ in both parameters, and it
improves on a recent line of exciting progress on deterministic distributed
network decompositions [Rozho\v{n}, Ghaffari STOC&#39;20; Ghaffari, Grunau,
Rozho\v{n} SODA&#39;21; Chang, Ghaffari PODC&#39;21; Elkin, Haeupler, Rozho\v{n},
Grunau FOCS&#39;22].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Emanuele Viola: Getting started with OpenGL and C++</title>
    <link href="https://emanueleviola.wordpress.com/2022/09/25/getting-started-with-opengl-and-c/"/>
    <id>http://emanueleviola.wordpress.com/?p=1077</id>
    <updated>2022-09-25T23:45:43+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Below is a template that shows a fractal plant that you can modify with the keys z,w,s.  Getting this to work was not straightforward, but the idea is that now you can just have fun and start your videogame.  The code is not meant to be optimized at all, but simple.  It&amp;#8217;s pretty much self-explanatory, basically you can just replace the call to drawFrac in display to show whatever you want, and you handle key strokes in the idle function.  I only tested it on Linux.&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;a href=&quot;https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png&quot;&gt;&lt;img data-attachment-id=&quot;1080&quot; data-permalink=&quot;https://emanueleviola.wordpress.com/2022/09/25/getting-started-with-opengl-and-c/screenshot-from-2022-09-25-19-37-42/&quot; data-orig-file=&quot;https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png&quot; data-orig-size=&quot;1369,873&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;screenshot-from-2022-09-25-19-37-42&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=300&quot; data-large-file=&quot;https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=640&quot; src=&quot;https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=1024&quot; alt=&quot;&quot; class=&quot;wp-image-1080&quot; srcset=&quot;https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=1024 1024w, https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=150 150w, https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=300 300w, https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=768 768w, https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png 1369w&quot; sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;/*
This is a template to get started with OpenGL (which needs to be installed)
To compile: g++ GLtemplate.c++ -o GLtemplate -lglut -lGLU -lGL
To run: ./GLtemplate

It shows a fractal plant that you can modify with the keys z,w,s

*/

#include &amp;lt;GL/glut.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;math.h&amp;gt;

GLfloat userAngle = M_PI/2, userLength = 0.5;

//Keyboard code.  keyStates&amp;#091;x] is true if x is pressed.

bool keyStates&amp;#091;256];     //Key state values

void keyPressed (unsigned char key, int x, int y) { keyStates&amp;#091;key] = true;  }
void keyUp      (unsigned char key, int x, int y) { keyStates&amp;#091;key] = false; }

void idle() {
  if (keyStates&amp;#091;&#39;z&#39;]) {userAngle += 0.01;}
  if (keyStates&amp;#091;&#39;w&#39;]) {userLength += 0.01;}
  if (keyStates&amp;#091;&#39;s&#39;]) {userLength -= 0.01; if (userLength &amp;lt; 0) userLength = 0;}
}

/* Draws a plant from x,y with first piece length l, and angle a
The window has coordinates from (-1,-1) to (1,1).  The center is 0,0.
*/

void drawFrac(GLfloat x,GLfloat y,GLfloat l, GLfloat a) {
  if ( l &amp;lt; 0.001 )
    return;

  glColor3f(0, l*30, 0);
  glLineWidth(l*10);  //Must be before glBegin(GL_LINES)

  glBegin(GL_LINES);

  glVertex2d(x,y);
  glVertex2d(x+cos(a)*l,y+sin(a)*l);

  glEnd();

  drawFrac(x+cos(a)*l*0.3,y+sin(a)*l*0.3,l*0.3,a+M_PI/4);
  drawFrac(x+cos(a)*l*0.6,y+sin(a)*l*0.6,l*0.4,a-M_PI/4);

  drawFrac(x+cos(a)*l,y+sin(a)*l,l*0.5,a+M_PI/4);
  drawFrac(x+cos(a)*l,y+sin(a)*l,l*0.5,a-M_PI/4);
}

//This is the function that draws everything on the screen
void display() {
  glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); //Clear screen

  /* Draw whatever you need here */
  drawFrac(0,0,userLength,userAngle);

  glutSwapBuffers();
  glutPostRedisplay();
}

int main(int argc, char** argv)
{
    glutInit(&amp;amp;argc, argv);
    glutInitDisplayMode(GLUT_SINGLE);
    glutInitWindowSize(1000, 1000);
    glutInitWindowPosition(0,0);
    glutCreateWindow(&quot;GLtemplate&quot;);
    glutDisplayFunc(display);
    glutIdleFunc(idle);
    glutKeyboardUpFunc(keyUp);
    glutKeyboardFunc(keyPressed);

    glutMainLoop();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;authors&quot;&gt;By Manu&lt;/p&gt;
  </content>
    <author>
      <name>Emanuele Viola</name>
      <uri>https://emanueleviola.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-136 |  Rounds vs Communication Tradeoffs for Maximal Independent Sets | 

	Sepehr Assadi, 

	Gillat Kol, 

	Zhijun Zhang</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/136"/>
    <id>https://eccc.weizmann.ac.il/report/2022/136</id>
    <updated>2022-09-25T06:24:48+00:00</updated>
    <content type="html" xml:lang="en">
    We consider the problem of finding a maximal independent set (MIS) in the shared blackboard communication model with vertex-partitioned inputs. There are $n$ players corresponding to vertices of an undirected graph, and each player sees the edges incident on its vertex -- this way, each edge is known by both its endpoints and is thus shared by two players. The players communicate in simultaneous rounds by posting their messages on a shared blackboard visible to all players, with the goal of computing an MIS of the graph. While the MIS problem is well studied in other distributed models, and while shared blackboard is, perhaps, the simplest broadcast model, lower bounds for our problem were only known against one-round protocols.

We present a lower bound on the round-communication tradeoff for computing an MIS in this model. Specifically, we show that when $r$ rounds of interaction are allowed, at least one player needs to communicate $\Omega(n^{1/20^{r+1}})$ bits. In particular, with logarithmic bandwidth, finding an MIS requires $\Omega(\log\log{n})$ rounds. This lower bound can be compared with the algorithm of Ghaffari, Gouleakis, Konrad, Mitrovi ?c, and Rubinfeld [PODC 2018] that solves MIS in $O(\log\log{n})$ rounds but with a logarithmic bandwidth for an average player. Additionally, our lower bound further extends to the closely related problem of maximal bipartite matching.

The presence of edge-sharing gives the algorithms in our model a surprising power and numerous algorithmic results exploiting this power are known. For a similar reason, proving lower bounds in this model is much more challenging, as this sharing in the players&amp;#39; inputs prohibits the use of standard number-in-hand communication complexity arguments. Thus, to prove our results, we devise a new round elimination framework, which we call partial-input embedding, that may also be useful in future work for proving round-sensitive lower bounds in the presence of shared inputs.

Finally, we discuss several implications of our results to multi-round (adaptive) distributed sketching algorithms, broadcast congested clique, and to the welfare maximization problem in two-sided matching markets.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-135 |  Decision Tree Complexity versus Block Sensitivity and Degree | 

	Swagato Sanyal, 

	Supartha Poddar, 

	Rahul Chugh</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/135"/>
    <id>https://eccc.weizmann.ac.il/report/2022/135</id>
    <updated>2022-09-25T06:22:55+00:00</updated>
    <content type="html" xml:lang="en">
    Relations between the decision tree complexity and various other complexity measures of Boolean functions is a thriving topic of research in computational complexity. While decision tree complexityis long known to be polynomially related with many other measures, the optimal exponents of many of these relations are not known. It is known that decision tree complexity is bounded above by the cube of block sensitivity, and the cube of polynomial degree. However, the widest separation between decision tree complexity and each of block sensitivity and degree that is witnessed by known Boolean functions is quadratic.

Proving quadratic relations between these measures wouldresolve several open questions in decision tree complexity. For example, we get a tight relationbetween decisiontree complexityand square of randomizeddecision tree complexity and a tightrelationbetween zero-error randomized decision tree complexity and square of fractional block sensitivity, resolving an open question raised by Aaronson. In this work, we investigate thetightnessof the existing cubic upper bounds.

We improve the cubic upper bounds for many interesting classes of Boolean functions. We show that for graph properties and for functions with a constant number of alternations, both of the cubic upper bounds can be improved to quadratic. We define a class of Boolean functions, which we call the zebra functions, that comprises Boolean functions where each monotone path from $0^n$ to $1^n$ has an equal number of alternations. This class contains the symmetric and monotone functions as its subclasses. We show that for any zebra function, decision tree complexity is at most the square of block sensitivity, and certificate complexity is at most the square of degree.

Finally, we show using a lifting theorem of communication complexity by G{\&amp;quot;{o}}{\&amp;quot;{o}}s, Pitassi and Watson that the task of proving an improved upper bound on the decision tree complexity for all functions is in a sense equivalent to the potentially easier task of proving a similar upper bound on communication complexity for each bi-partition of the input variables, for all functions. In particular, this implies that to bound the decision tree complexity it suffices to bound smaller measures like parity decision tree complexity, subcube decision tree complexity and decision tree rank, that are defined in terms of models that can be efficiently simulated by communication protocols.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-134 |  Some Games on Turing Machines and Power from Random Strings | 

	Alexey Milovanov, 

	Greg McLellan</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/134"/>
    <id>https://eccc.weizmann.ac.il/report/2022/134</id>
    <updated>2022-09-25T06:21:39+00:00</updated>
    <content type="html" xml:lang="en">
    Denote by $R$ the set of strings with high Kolmogorov complexity. In [E. Allender, H. Buhrman, M. Kouck\&amp;#39;y, D. van Melkebeek, and D. Ronneburger.
Power from random strings.
\emph{SIAM Journal on Computing}, 35:1467--1493, 2006.] the idea of using $R$ as an oracle for resource-bounded computation models was presented. This idea was later developed in several others papers.
We prove new lower bounds for $Q^R_{tt}$ and $Q^R_{sa}$:
- Oblivious-NP is subset of $Q^R_{tt}$;
- Oblivious-MA is subset of $Q^R_{sa}$.

Here $Q$ means quazi-polynomial-time; ``sa&amp;#39;&amp;#39; means sub-adaptive
reduction - a new type of reduction that we introduce. This type of reduction is not weaker than truth-table reduction and is not stronger than Turing reduction.

Also we prove upper bounds for BBP^R_{tt} and P^R_{sa} following [E. Allender, L. Friedman, and W. Gasarch. Limits on the computational power of random
strings.]:

P^R_{sa} is subset of EXP
BBP^R_{tt} is subset of AEXP(poly).

Here AEXP(poly) is the class of languages decidable in exponential time by an alternating Turing machine that switches from an existential to a universal state or vice versa at most polynomial times.


Finally we analyze some games that originate in [E. Allender, L. Friedman, and W. Gasarch. Limits on the computational power of random
strings.]. We prove completeness of these games. These results show that methods in this can not prove better upper bounds for P^R, NP^R and P^R_{tt} than known.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Open-Rank Professor of Computer Science at Pomona College (apply by October 15, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/09/23/open-rank-professor-of-computer-science-at-pomona-college-apply-by-october-15-2022/"/>
    <id>http://cstheory-jobs.org/2022/09/23/open-rank-professor-of-computer-science-at-pomona-college-apply-by-october-15-2022/</id>
    <updated>2022-09-23T17:09:49+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Pomona College seeks applications for two Open-Rank (assistant, associate, or full) Professor of Computer Science positions, to begin on July 1, 2023. All subfields of computer science will be considered. Candidates should have a broad background in computer science, be excellent teachers, have an active research program, and be excited about directing undergraduate research.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://academicjobsonline.org/ajo/jobs/22190&quot;&gt;https://academicjobsonline.org/ajo/jobs/22190&lt;/a&gt;&lt;br /&gt;
Email: cssearch@pomona.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Solving the General Case of Rank-3 Maker-Breaker Games in Polynomial Time</title>
    <link href="http://arxiv.org/abs/2209.11202"/>
    <id>http://arxiv.org/abs/2209.11202</id>
    <updated>2022-09-23T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bahack_L/0/1/0/all/0/1&quot;&gt;Lear Bahack&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A rank-3 Maker-Breaker game is played on a hypergraph in which all hyperedges
are sets of at most 3 vertices. The two players of the game, called Maker and
Breaker, move alternately. On his turn, maker chooses a vertex to be withdrawn
from all hyperedges, while Breaker on her turn chooses a vertex and delete all
the hyperedges containing that vertex. Maker wins when by the end of his turn
some hyperedge is completely covered, i.e. the last remaining vertex of that
hyperedge is withdrawn. Breaker wins when by the end of her turn, all
hyperedges have been deleted.
&lt;/p&gt;
&lt;p&gt;Solving a Maker-Breaker game is the computational problem of choosing an
optimal move, or equivalently, deciding which player has a winning strategy in
a configuration. The complexity of solving two degenerate cases of rank-3 games
has been proven before to be polynomial. In this paper, we show that the
general case of rank-3 Maker-Breaker games is also solvable in polynomial time.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Hyperstable Sets with Voting and Algorithmic Hardness Applications</title>
    <link href="http://arxiv.org/abs/2209.11216"/>
    <id>http://arxiv.org/abs/2209.11216</id>
    <updated>2022-09-23T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Heilman_S/0/1/0/all/0/1&quot;&gt;Steven Heilman&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The noise stability of a Euclidean set $A$ with correlation $\rho$ is the
probability that $(X,Y)\in A\times A$, where $X,Y$ are standard Gaussian random
vectors with correlation $\rho\in(0,1)$. It is well-known that a Euclidean set
of fixed Gaussian volume that maximizes noise stability must be a half space.
&lt;/p&gt;
&lt;p&gt;For a partition of Euclidean space into $m&amp;gt;2$ parts each of Gaussian measure
$1/m$, it is still unknown what sets maximize the sum of their noise
stabilities. In this work, we classify partitions maximizing noise stability
that are also critical points for the derivative of noise stability with
respect to $\rho$. We call a partition satisfying these conditions hyperstable.
Uner the assumption that a maximizing partition is hyperstable, we prove:
&lt;/p&gt;
&lt;p&gt;* a (conditional) version of the Plurality is Stablest Conjecture for $3$ or
$4$ candidates.
&lt;/p&gt;
&lt;p&gt;* a (conditional) sharp Unique Games Hardness result for MAX-m-CUT for $m=3$
or $4$
&lt;/p&gt;
&lt;p&gt;* a (conditional) version of the Propeller Conjecture of Khot and Naor for
$4$ sets.
&lt;/p&gt;
&lt;p&gt;We also show that a symmetric set that is hyperstable must be star-shaped.
&lt;/p&gt;
&lt;p&gt;For partitions of Euclidean space into $m&amp;gt;2$ parts of fixed (but perhaps
unequal) Gaussian measure, the hyperstable property can only be satisfied when
all of the parts have Gaussian measure $1/m$. So, as our main contribution, we
have identified a possible strategy for proving the full Plurality is Stablest
Conjecture and the full sharp hardness for MAX-m-CUT: to prove both statements,
it suffices to show that sets maximizing noise stability are hyperstable. This
last point is crucial since any proof of the Plurality is Stablest Conjecture
must use a property that is special to partitions of sets into equal measures,
since the conjecture is false in the unequal measure case.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Output Mode Switching for Parallel Five-bar Manipulators Using a Graph-based Path Planner</title>
    <link href="http://arxiv.org/abs/2209.10743"/>
    <id>http://arxiv.org/abs/2209.10743</id>
    <updated>2022-09-23T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edwards_P/0/1/0/all/0/1&quot;&gt;Parker B. Edwards&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baskar_A/0/1/0/all/0/1&quot;&gt;Aravind Baskar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hills_C/0/1/0/all/0/1&quot;&gt;Caroline Hills&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plecnik_M/0/1/0/all/0/1&quot;&gt;Mark Plecnik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hauenstein_J/0/1/0/all/0/1&quot;&gt;Jonathan D. Hauenstein&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The configuration manifolds of parallel manipulators exhibit more
nonlinearity than serial manipulators. Qualitatively, they can be seen to
possess extra folds. By projecting such manifolds onto spaces of engineering
relevance, such as an output workspace or an input actuator space, these folds
cast edges that exhibit nonsmooth behavior. For example, inside the global
workspace bounds of a five-bar linkage appear several local workspace bounds
that only constrain certain output modes of the mechanism. The presence of such
boundaries, which manifest in both input and output projections, serve as a
source of confusion when these projections are studied exclusively instead of
the configuration manifold itself. Particularly, the design of nonsymmetric
parallel manipulators has been confounded by the presence of exotic projections
in their input and output spaces. In this paper, we represent the configuration
space with a radius graph, then weight each edge by solving an optimization
problem using homotopy continuation to quantify transmission quality. We then
employ a graph path planner to approximate geodesics between configuration
points that avoid regions of low transmission quality. Our methodology
automatically generates paths capable of transitioning between non-neighboring
output modes, a motion which involves osculating multiple workspace boundaries
(local, global, or both). We apply our technique to two nonsymmetric five-bar
examples that demonstrate how transmission properties and other characteristics
of the workspace can be selected by switching output modes.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Maths, Computation and Flamenco: overview and challenges</title>
    <link href="http://arxiv.org/abs/2209.10970"/>
    <id>http://arxiv.org/abs/2209.10970</id>
    <updated>2022-09-23T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9;-Miguel D&amp;#xed;az-B&amp;#xe1;&amp;#xf1;ez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kroher_N/0/1/0/all/0/1&quot;&gt;Nadine Kroher&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Flamenco is a rich performance-oriented art music genre from Southern Spain
which attracts a growing community of aficionados around the globe. Due to its
improvisational and expressive nature, its unique musical characteristics, and
the fact that the genre is largely undocumented, flamenco poses a number of
interesting mathematical and computational challenges. Most existing approaches
in Musical Information Retrieval (MIR) were developed in the context of popular
or classical music and do often not generalize well to non-Western music
traditions, in particular when the underlying music theoretical assumptions do
not hold for these genres. Over the recent decade, a number of computational
problems related to the automatic analysis of flamenco music have been defined
and several methods addressing a variety of musical aspects have been proposed.
This paper provides an overview of the challenges which arise in the context of
computational analysis of flamenco music and outlines an overview of existing
approaches.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Uniform Reliability for Unbounded Homomorphism-Closed Graph Queries</title>
    <link href="http://arxiv.org/abs/2209.11177"/>
    <id>http://arxiv.org/abs/2209.11177</id>
    <updated>2022-09-23T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amarilli_A/0/1/0/all/0/1&quot;&gt;Antoine Amarilli&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the uniform query reliability problem, which asks, for a fixed
Boolean query Q, given an instance I, how many subinstances of I satisfy Q.
Equivalently, this is a restricted case of Boolean query evaluation on
tuple-independent probabilistic databases where all facts must have probability
1/2. We focus on graph signatures, and on queries closed under homomorphisms.
We show that for any such query that is unbounded, i.e., not equivalent to a
union of conjunctive queries, the uniform reliability problem is #P-hard. This
recaptures the hardness, e.g., of s-t connectedness, which counts how many
subgraphs of an input graph have a path between a source and a sink.
&lt;/p&gt;
&lt;p&gt;This new hardness result on uniform reliability strengthens our earlier
hardness result on probabilistic query evaluation for unbounded
homomorphism-closed queries (ICDT&#39;20). Indeed, our earlier proof crucially used
facts with probability 1, so it did not apply to the unweighted case. The new
proof presented in this paper avoids this; it uses our recent hardness result
on uniform reliability for non-hierarchical conjunctive queries without
self-joins (ICDT&#39;21), along with new techniques.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Efficiently Reconfiguring a Connected Swarm of Labeled Robots</title>
    <link href="http://arxiv.org/abs/2209.11028"/>
    <id>http://arxiv.org/abs/2209.11028</id>
    <updated>2022-09-23T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fekete_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe1;ndor P. Fekete&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kramer_P/0/1/0/all/0/1&quot;&gt;Peter Kramer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rieck_C/0/1/0/all/0/1&quot;&gt;Christian Rieck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheffer_C/0/1/0/all/0/1&quot;&gt;Christian Scheffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_A/0/1/0/all/0/1&quot;&gt;Arne Schmidt&lt;/a&gt;&lt;/p&gt;&lt;p&gt;When considering motion planning for a swarm of $n$ labeled robots, we need
to rearrange a given start configuration into a desired target configuration
via a sequence of parallel, continuous, collision-free robot motions. The
objective is to reach the new configuration in a minimum amount of time; an
important constraint is to keep the swarm connected at all times. Problems of
this type have been considered before, with recent notable results achieving
constant stretch for not necessarily connected reconfiguration: If mapping the
start configuration to the target configuration requires a maximum Manhattan
distance of $d$, the total duration of an overall schedule can be bounded to
$\mathcal{O}(d)$, which is optimal up to constant factors. However, constant
stretch could only be achieved if disconnected reconfiguration is allowed, or
for scaled configurations (which arise by increasing all dimensions of a given
object by the same multiplicative factor) of unlabeled robots.
&lt;/p&gt;
&lt;p&gt;We resolve these major open problems by (1) establishing a lower bound of
$\Omega(\sqrt{n})$ for connected, labeled reconfiguration and, most
importantly, by (2) proving that for scaled arrangements, constant stretch for
connected reconfiguration can be achieved. In addition, we show that (3) it is
NP-hard to decide whether a makespan of 2 can be achieved, while it is possible
to check in polynomial time whether a makespan of 1 can be achieved.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Learning-Augmented Algorithms for Online Linear and Semidefinite Programming</title>
    <link href="http://arxiv.org/abs/2209.10614"/>
    <id>http://arxiv.org/abs/2209.10614</id>
    <updated>2022-09-23T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grigorescu_E/0/1/0/all/0/1&quot;&gt;Elena Grigorescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1&quot;&gt;Young-San Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1&quot;&gt;Sandeep Silwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1&quot;&gt;Maoyuan Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Samson Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Semidefinite programming (SDP) is a unifying framework that generalizes both
linear programming and quadratically-constrained quadratic programming, while
also yielding efficient solvers, both in theory and in practice. However, there
exist known impossibility results for approximating the optimal solution when
constraints for covering SDPs arrive in an online fashion. In this paper, we
study online covering linear and semidefinite programs in which the algorithm
is augmented with advice from a possibly erroneous predictor. We show that if
the predictor is accurate, we can efficiently bypass these impossibility
results and achieve a constant-factor approximation to the optimal solution,
i.e., consistency. On the other hand, if the predictor is inaccurate, under
some technical conditions, we achieve results that match both the classical
optimal upper bounds and the tight lower bounds up to constant factors, i.e.,
robustness.
&lt;/p&gt;
&lt;p&gt;More broadly, we introduce a framework that extends both (1) the online set
cover problem augmented with machine-learning predictors, studied by Bamas,
Maggiori, and Svensson (NeurIPS 2020), and (2) the online covering SDP problem,
initiated by Elad, Kale, and Naor (ICALP 2016). Specifically, we obtain general
online learning-augmented algorithms for covering linear programs with
fractional advice and constraints, and initiate the study of learning-augmented
algorithms for covering SDP problems.
&lt;/p&gt;
&lt;p&gt;Our techniques are based on the primal-dual framework of Buchbinder and Naor
(Mathematics of Operations Research, 34, 2009) and can be further adjusted to
handle constraints where the variables lie in a bounded region, i.e., box
constraints.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A cubic algorithm for computing the Hermite normal form of a nonsingular integer matrix</title>
    <link href="http://arxiv.org/abs/2209.10685"/>
    <id>http://arxiv.org/abs/2209.10685</id>
    <updated>2022-09-23T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Birmpilis_S/0/1/0/all/0/1&quot;&gt;Stavros Birmpilis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Labahn_G/0/1/0/all/0/1&quot;&gt;George Labahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Storjohann_A/0/1/0/all/0/1&quot;&gt;Arne Storjohann&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A Las Vegas randomized algorithm is given to compute the Hermite normal form
of a nonsingular integer matrix $A$ of dimension $n$. The algorithm uses
quadratic integer multiplication and cubic matrix multiplication and has
running time bounded by $O(n^3 (\log n + \log ||A||)^2(\log n)^2)$ bit
operations, where $||A||= \max_{ij} |A_{ij}|$ denotes the largest entry of $A$
in absolute value. A variant of the algorithm that uses pseudo-linear integer
multiplication is given that has running time $(n^3 \log ||A||)^{1+o(1)}$ bit
operations, where the exponent $&quot;+o(1)&quot;$ captures additional factors $c_1 (\log
n)^{c_2} (\log \log ||A||)^{c_3}$ for positive real constants $c_1,c_2,c_3$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Popular Edges with Critical Nodes</title>
    <link href="http://arxiv.org/abs/2209.10805"/>
    <id>http://arxiv.org/abs/2209.10805</id>
    <updated>2022-09-23T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_K/0/1/0/all/0/1&quot;&gt;Kushagra Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nimbhorkar_P/0/1/0/all/0/1&quot;&gt;Prajakta Nimbhorkar&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the popular edge problem, the input is a bipartite graph $G = (A \cup
B,E)$ where $A$ and $B$ denote a set of men and a set of women respectively,
and each vertex in $A\cup B$ has a strict preference ordering over its
neighbours. A matching $M$ in $G$ is said to be {\em popular} if there is no
other matching $M&#39;$ such that the number of vertices that prefer $M&#39;$ to $M$ is
more than the number of vertices that prefer $M$ to $M&#39;$. The goal is to
determine, whether a given edge $e$ belongs to some popular matching in $G$. A
polynomial-time algorithm for this problem appears in \cite{CK18}. We consider
the popular edge problem when some men or women are prioritized or critical. A
matching that matches all the critical nodes is termed as a feasible matching.
It follows from \cite{Kavitha14,Kavitha21,NNRS21,NN17} that, when $G$ admits a
feasible matching, there always exists a matching that is popular among all
feasible matchings. We give a polynomial-time algorithm for the popular edge
problem in the presence of critical men or women. We also show that an
analogous result does not hold in the many-to-one setting, which is known as
the Hospital-Residents Problem in literature, even when there are no critical
nodes.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Canadian Traveller Problem with Predictions</title>
    <link href="http://arxiv.org/abs/2209.11100"/>
    <id>http://arxiv.org/abs/2209.11100</id>
    <updated>2022-09-23T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bampis_E/0/1/0/all/0/1&quot;&gt;Evripidis Bampis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Escoffier_B/0/1/0/all/0/1&quot;&gt;Bruno Escoffier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xefteris_M/0/1/0/all/0/1&quot;&gt;Michalis Xefteris&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work, we consider the $k$-Canadian Traveller Problem ($k$-CTP) under
the learning-augmented framework proposed by Lykouris &amp;amp; Vassilvitskii. $k$-CTP
is a generalization of the shortest path problem, and involves a traveller who
knows the entire graph in advance and wishes to find the shortest route from a
source vertex $s$ to a destination vertex $t$, but discovers online that some
edges (up to $k$) are blocked once reaching them. A potentially imperfect
predictor gives us the number and the locations of the blocked edges.
&lt;/p&gt;
&lt;p&gt;We present a deterministic and a randomized online algorithm for the
learning-augmented $k$-CTP that achieve a tradeoff between consistency (quality
of the solution when the prediction is correct) and robustness (quality of the
solution when there are errors in the prediction). Moreover, we prove a
matching lower bound for the deterministic case establishing that the tradeoff
between consistency and robustness is optimal, and show a lower bound for the
randomized algorithm. Finally, we prove several deterministic and randomized
lower bounds on the competitive ratio of $k$-CTP depending on the prediction
error, and complement them, in most cases, with matching upper bounds.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Approximating $(p,2)$ flexible graph connectivity via the primal-dual method</title>
    <link href="http://arxiv.org/abs/2209.11209"/>
    <id>http://arxiv.org/abs/2209.11209</id>
    <updated>2022-09-23T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_I/0/1/0/all/0/1&quot;&gt;Ishan Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheriyan_J/0/1/0/all/0/1&quot;&gt;Joseph Cheriyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grout_L/0/1/0/all/0/1&quot;&gt;Logan Grout&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibrahimpur_S/0/1/0/all/0/1&quot;&gt;Sharat Ibrahimpur&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the Flexible Graph Connectivity model (denoted FGC) introduced by
Adjiashvili, Hommelsheim and M\&quot;uhlenthaler (IPCO 2020, Mathematical
Programming 2021), and its generalization, $(p,q)$-FGC, where $p \geq 1$ and $q
\geq 0$ are integers, introduced by Boyd et al.\ (FSTTCS 2021). In the
$(p,q)$-FGC model, we have an undirected connected graph $G=(V,E)$,
non-negative costs $c$ on the edges, and a partition $(\mathcal{S},
\mathcal{U})$ of $E$ into a set of safe edges $\mathcal{S}$ and a set of unsafe
edges $\mathcal{U}$. A subset $F \subseteq E$ of edges is called feasible if
for any set $F&#39;\subseteq\mathcal{U}$ with $|F&#39;| \leq q$, the subgraph $(V, F
\setminus F&#39;)$ is $p$-edge connected. The goal is to find a feasible edge-set
of minimum cost.
&lt;/p&gt;
&lt;p&gt;For the special case of $(p,q)$-FGC when $q = 2$, we give an $O(1)$
approximation algorithm, thus improving on the logarithmic approximation ratio
of Boyd et al. (FSTTCS 2021). Our algorithm is based on the primal-dual method
for covering an uncrossable family, due to Williamson et al. (Combinatorica
1995). We conclude by studying weakly uncrossable families, which are a
generalization of the well-known notion of an uncrossable family.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Faculty at Claremont McKenna College (apply by November 15, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/09/22/faculty-at-claremont-mckenna-college-apply-by-november-15-2022/"/>
    <id>http://cstheory-jobs.org/2022/09/22/faculty-at-claremont-mckenna-college-apply-by-november-15-2022/</id>
    <updated>2022-09-22T17:40:49+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The Department of Mathematical Sciences at Claremont McKenna College invites applications for a tenure-track position, at the assistant professor level, in Probability, Statistics, and Statistical Computing.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.mathjobs.org/jobs/list/20279&quot;&gt;https://www.mathjobs.org/jobs/list/20279&lt;/a&gt;&lt;br /&gt;
Email: sarah.cannon@cmc.edu; Ckao@claremontmckenna.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Tenure track assistant professor at CUNYs Baruch College (apply by November 7, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/09/22/tenure-track-assistant-professor-at-cunys-baruch-college-apply-by-november-7-2022/"/>
    <id>http://cstheory-jobs.org/2022/09/22/tenure-track-assistant-professor-at-cunys-baruch-college-apply-by-november-7-2022/</id>
    <updated>2022-09-22T17:00:15+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Baruch College, part of CUNY, lies at the heart of Manhattan. It is regularly ranked as the country&amp;#8217;s top college for social mobility. Since Baruch College was traditionally CUNY&amp;#8217;s business school, it did not include Computer Science. Our computer science major will start in August 2023. We are hiring professors that will help shape and grow computer science at Baruch.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://geometrynyc.wixsite.com/csjobs&quot;&gt;https://geometrynyc.wixsite.com/csjobs&lt;/a&gt;&lt;br /&gt;
Email: warren.gordon@baruch.cuny.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Richard Lipton: Cheating at ChessNot Again</title>
    <link href="https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/"/>
    <id>https://rjlipton.wpcomstaging.com/?p=20420</id>
    <updated>2022-09-22T03:59:28+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;font color=&quot;#0044cc&quot;&gt;&lt;br /&gt;
&lt;em&gt;Play the opening like a book, the middle game like a magician, and the end game like a machine &amp;#8212; Rudolf Spielmann&lt;/em&gt;&lt;br /&gt;
&lt;font color=&quot;#000000&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/kenglenveagh/&quot; rel=&quot;attachment wp-att-20422&quot;&gt;&lt;img data-attachment-id=&quot;20422&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/kenglenveagh/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenGlenveagh.jpeg?fit=185%2C272&amp;amp;ssl=1&quot; data-orig-size=&quot;185,272&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;KenGlenveagh&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenGlenveagh.jpeg?fit=185%2C272&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenGlenveagh.jpeg?fit=185%2C272&amp;amp;ssl=1&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenGlenveagh.jpeg?resize=123%2C181&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;123&quot; height=&quot;181&quot; class=&quot;alignright wp-image-20422&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
Kenneth Regan is my dear friend and co-writer of this blog. He obtained his doctorate&amp;#8212;technically D.Phil not PhD&amp;#8212;in 1986 for a thesis titled &lt;em&gt;On the Separation of Complexity Classes&lt;/em&gt; from the University of Oxford under Dominic Welsh. He has, however, been enmeshed this month in a story quite separate from complexity classes.&lt;/p&gt;
&lt;p&gt;
It was Ken&amp;#8217;s birthday just last week and we wish him many more.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Cheating at Chess &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Ken was the 1977 US Junior co-champion and once held the record of youngest USCF Master since Bobby Fischer. He holds the title of International Master with a rating of 2372. Ken is perhaps the strongest chess player ever with a doctorate in complexity theory.&lt;/p&gt;
&lt;p&gt;
He is certainly the world best at &lt;i&gt;both&lt;/i&gt; complexity theory and cheating at chess. Ken is one of the leading experts in detecting cheating in games played in real tournaments. &lt;/p&gt;
&lt;p&gt;
He has, however, been occupied by a major story that erupted after the world champion, Magnus Carlsen, lost to the American teenager and bottom-rated participant Hans Niemann in the third round of the Sinquefield Cup in St. Louis. The next day, Labor Day, Carlsen abruptly withdrew from the tournament with no explanation beyond a cryptic &lt;a href=&quot;https://twitter.com/MagnusCarlsen/status/1566848734616555523&quot;&gt;tweet&lt;/a&gt;. This was widely regarded as an insinuation of some kind of cheating.  Ken was involved daily monitoring the event and was cited in a subsequent &lt;a href=&quot;https://grandchesstour.org/blog/2022-sinquefield-cup-chief-arbiter&#39;s-statement&quot;&gt;press release&lt;/a&gt; as having found nothing amiss. &lt;/p&gt;
&lt;p&gt;
Nevertheless&amp;#8212;really &lt;i&gt;everthemore&lt;/i&gt;&amp;#8212;this has sparked renewed discussion of cheating at chess and measures to protect tournaments at all levels. Let&amp;#8217;s go into that.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Detecting Cheating &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
How does one cheat at chess? Imagine Bob is playing a game in a live chess tournament. Bob is a strong player but is not nearly as strong as his opponent Ted. How does Bob cheat?&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/two-2/&quot; rel=&quot;attachment wp-att-20423&quot;&gt;&lt;img data-attachment-id=&quot;20423&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/two-2/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/two.jpeg?fit=273%2C184&amp;amp;ssl=1&quot; data-orig-size=&quot;273,184&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;two&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/two.jpeg?fit=273%2C184&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/two.jpeg?fit=273%2C184&amp;amp;ssl=1&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/two.jpeg?resize=273%2C184&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;273&quot; height=&quot;184&quot; class=&quot;aligncenter size-full wp-image-20423&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
The basic idea is quite simple: Bob uses a computer program &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P}&quot; class=&quot;latex&quot; /&gt; to make moves for him. He types Ted&amp;#8217;s moves into &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P}&quot; class=&quot;latex&quot; /&gt; and then makes its moves. The reason this is so powerful is that the ranking of the computer program &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P}&quot; class=&quot;latex&quot; /&gt; is likely much higher than Ted&amp;#8217;s. It could be ranked at 3000 or even higher. This means that Bob is likely to not lose to Ted but perhaps even beat him. &lt;/p&gt;
&lt;p&gt;
The challenge for Bob to cheat in this manner is that he must ask the program &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P}&quot; class=&quot;latex&quot; /&gt; for its moves without being detected. Bob is not allowed to have a digital device like a phone or a laptop to ask the program &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P}&quot; class=&quot;latex&quot; /&gt; for its next move. This is the challenge that Bob, the cheater, is faced with. He must enter Ted&amp;#8217;s last move and then follow &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P}&quot; class=&quot;latex&quot; /&gt;&amp;#8216;s move without it being noticed that he invoked the program &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P}&quot; class=&quot;latex&quot; /&gt;. This is the challenge that the cheater must solve.&lt;/p&gt;
&lt;p&gt;
The cheater may be able to send the moves to the program &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P}&quot; class=&quot;latex&quot; /&gt; in various ways. In some cases Bob has been found to use some hidden device to get this information to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P}&quot; class=&quot;latex&quot; /&gt;. He also may use clever ways to get the moves from &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P}&quot; class=&quot;latex&quot; /&gt;. &lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Why Is Detection Hard? &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Ken is one of the world&amp;#8217;s foremost experts on using predictive analytics to help detect computer-assisted cheating in chess tournaments. Why is this hard? There are several reasons that this is difficult: But the central point is expressed by Alexander &lt;a href=&quot;https://en.wikipedia.org/wiki/Alexander_Grischuk&quot;&gt;Grischuk&lt;/a&gt; who notes that &amp;#8220;only a very stupid Bob who stubbornly plays the computer&amp;#8217;s first line&amp;#8221; is likely to get detected.&lt;/p&gt;
&lt;p&gt;
Let&amp;#8217;s examine what Grischuk means. Bob as above is trying to use &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P}&quot; class=&quot;latex&quot; /&gt;&amp;#8216;s moves to defeat Ted. Grischuk&amp;#8217;s point is that Bob is stupid if he blindly uses the first move that the program &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P}&quot; class=&quot;latex&quot; /&gt; suggests. Programs often suggest more than one move that is safe to play. This makes detection much harder. &lt;/p&gt;
&lt;p&gt;
An even more powerful point is that what if Bob consults more than one program. Perhaps Bob checks the top moves from several programs &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7BP_1%2C+P_2%2C+%5Cdots%2C+P_6%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{P_1, P_2, &amp;#92;dots, P_6}&quot; class=&quot;latex&quot; /&gt;. This could make the detection of his cheating even more difficult. &lt;/p&gt;
&lt;p&gt;
Bob could use similar ideas to make the detection that he is consulting a program even more complicated. This is why Ken&amp;#8217;s checking to see if cheating occurred is so difficult. He tries to stay ahead on the detection end. For instance, his model is not predicated on identifying which program was used, and the provisionally-deployed ideas explored with his students &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2019/11/29/predicating-predictivity/&quot;&gt;here&lt;/a&gt; quantify departure from human predictivity apart from any programs.&lt;/p&gt;
&lt;p&gt;
Consult &lt;a href=&quot;https://katv.com/news/nation-world/chess-grandmaster-accused-of-using-sex-toy-to-cheat-win-against-worlds-top-player-hans-niemann-magnus-carlsen-anal-beads-cheating-ai-artificial-intellegence&quot;&gt;this&lt;/a&gt; for a recent claim that Niemann used &lt;a href=&quot;https://www.cosmopolitan.com/sex-love/a12274254/anal-beads-how-to/&quot;&gt;anal beads&lt;/a&gt; to signal moves. Even Elon Musk &lt;a href=&quot;https://futurism.com/the-byte/elon-musk-sex-toy-chess&quot;&gt;raised&lt;/a&gt; this possibility. Just an extreme example of why detecting cheating is tough.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Losing in Translation &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
The chess story took another twist when Carlsen and Niemann faced each other on Monday in the Julius Baer Generations Cup, an online tournament sponsored by Carlsen&amp;#8217;s own organization. Carlsen played one move and then resigned the game&amp;#8212;again giving no comment. Much effort has been expended in trying to translate exactly what Carlsen meant by losing in this manner.&lt;/p&gt;
&lt;p&gt;
Two years ago, a &lt;a href=&quot;https://www.theguardian.com/sport/2020/oct/16/chesss-cheating-crisis-paranoia-has-become-the-culture&quot;&gt;story&lt;/a&gt; in the &lt;em&gt;Guardian&lt;/em&gt; newspaper subtitled &amp;#8220;paranoia has become the culture&amp;#8221; featured Ken and efforts to avert cheating in tournaments that were moved online on account of the pandemic. Its quoting Ken included an example of translation from English to &lt;em&gt;English&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; &amp;#8220;The pandemic has brought me as much work in a single day as I have had in a year previously,&amp;#8221; said Prof Kenneth Regan, an international chess master and computer scientist whose model is relied on by the sport&amp;#8217;s governing body, &lt;a href=&quot;https://www.fide.com&quot;&gt;FIDE&lt;/a&gt;, to detect suspicious patterns of play. &amp;#8220;It has ruined my sabbatical.&amp;#8221; &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
What Ken actually said was, &amp;#8220;It ate my sabbatical.&amp;#8221; &lt;/p&gt;
&lt;p&gt;
Now Ken was mentioned in the &lt;em&gt;Guardian&lt;/em&gt; &lt;a href=&quot;https://www.theguardian.com/sport/2022/sep/20/carlsen-v-niemann-the-cheating-row-that-is-rocking-chess-explained&quot;&gt;yesterday&lt;/a&gt; and again &lt;a href=&quot;https://www.theguardian.com/sport/2022/sep/21/magnus-carlsen-v-hans-niemann-world-champion-resigns-after-one-move-chess-julius-baer-generation-cup&quot;&gt;today&lt;/a&gt;. Today&amp;#8217;s mention linked a longer &lt;a href=&quot;https://en.chessbase.com/post/is-hans-niemann-cheating-world-renowned-expert-ken-regan-analyzes&quot;&gt;article&lt;/a&gt; on the ChessBase site explaining his methods and conclusions to date. Ken may have more to say after the developments&amp;#8212;and ongoing media contacts&amp;#8212;settle down. &lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/kenoffice/&quot; rel=&quot;attachment wp-att-20424&quot;&gt;&lt;img data-attachment-id=&quot;20424&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2022/09/21/cheating-at-chess-not-again/kenoffice/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenOffice.jpeg?fit=264%2C191&amp;amp;ssl=1&quot; data-orig-size=&quot;264,191&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;KenOffice&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenOffice.jpeg?fit=264%2C191&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenOffice.jpeg?fit=264%2C191&amp;amp;ssl=1&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/09/KenOffice.jpeg?resize=264%2C191&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;264&quot; height=&quot;191&quot; class=&quot;aligncenter size-full wp-image-20424&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Open Problems &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
How will chess come out of the current controversies? I hope Ken had a happy birthday in the meantime.&lt;/p&gt;
&lt;p&gt;
&lt;p class=&quot;authors&quot;&gt;By rjlipton&lt;/p&gt;
  </content>
    <author>
      <name>Richard Lipton</name>
      <uri>https://rjlipton.wpcomstaging.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Capturing Bisimulation-Invariant Exponential-Time Complexity Classes</title>
    <link href="http://arxiv.org/abs/2209.10311"/>
    <id>http://arxiv.org/abs/2209.10311</id>
    <updated>2022-09-22T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruse_F/0/1/0/all/0/1&quot;&gt;Florian Bruse&lt;/a&gt; (University of Kassel, Kassel, Germany), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kronenberger_D/0/1/0/all/0/1&quot;&gt;David Kronenberger&lt;/a&gt; (University of Kassel, Kassel, Germany), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lange_M/0/1/0/all/0/1&quot;&gt;Martin Lange&lt;/a&gt; (University of Kassel, Kassel, Germany)&lt;/p&gt;&lt;p&gt;Otto&#39;s Theorem characterises the bisimulation-invariant PTIME queries over
graphs as exactly those that can be formulated in the polyadic mu-calculus,
hinging on the Immerman-Vardi Theorem which characterises PTIME (over ordered
structures) by First-Order Logic with least fixpoints. This connection has been
extended to characterise bisimulation-invariant EXPTIME by an extension of the
polyadic mu-calculus with functions on predicates, making use of Immerman&#39;s
characterisation of EXPTIME by Second-Order Logic with least fixpoints. In this
paper we show that the bisimulation-invariant versions of all classes in the
exponential time hierarchy have logical counterparts which arise as extensions
of the polyadic mu-calculus by higher-order functions. This makes use of the
characterisation of k-EXPTIME by Higher-Order Logic (of order k+1) with least
fixpoints, due to Freire and Martins.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Schema-Based Automata Determinization</title>
    <link href="http://arxiv.org/abs/2209.10312"/>
    <id>http://arxiv.org/abs/2209.10312</id>
    <updated>2022-09-22T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niehren_J/0/1/0/all/0/1&quot;&gt;Joachim Niehren&lt;/a&gt; (Inria, Universit&amp;#xe9; de Lille, France), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sakho_M/0/1/0/all/0/1&quot;&gt;Momar Sakho&lt;/a&gt; (Inria, Universit&amp;#xe9; de Lille, France), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serhali_A/0/1/0/all/0/1&quot;&gt;Antonio Al Serhali&lt;/a&gt; (Inria, Universit&amp;#xe9; de Lille, France)&lt;/p&gt;&lt;p&gt;We propose an algorithm for schema-based determinization of finite automata
on words and of step-wise hedge automata on nested words. The idea is to
integrate schema-based cleaning directly into automata determinization. We
prove the correctness of our new algorithm and show that it is alway smore
efficient than standard determinization followed by schema-based cleaning. Our
implementation permits to obtain a small deterministic automaton for an example
of an XPath query, where standard determinization yields a huge stepwise hedge
automaton for which schema-based cleaning runs out of memory.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: BQP is not in NP</title>
    <link href="http://arxiv.org/abs/2209.10398"/>
    <id>http://arxiv.org/abs/2209.10398</id>
    <updated>2022-09-22T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Librande_J/0/1/0/all/0/1&quot;&gt;Jonah Librande&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Quantum computers are widely believed have an advantage over classical
computers, and some have even published some empirical evidence that this is
the case. However, these publications do not include a rigorous proof of this
advantage, which would have to minimally state that the class of problems
decidable by a quantum computer in polynomial time, BQP, contains problems that
are not in the class of problems decidable by a classical computer with similar
time bounds, P. Here, I provide the proof of a stronger result that implies
this result: BQP contains problems that lie beyond the much larger classical
computing class NP. This proves that quantum computation is able to efficiently
solve problems which are far beyond the capabilities of classical computers.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Downward Self-Reducibility in TFNP</title>
    <link href="http://arxiv.org/abs/2209.10509"/>
    <id>http://arxiv.org/abs/2209.10509</id>
    <updated>2022-09-22T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harsha_P/0/1/0/all/0/1&quot;&gt;Prahladh Harsha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitropolsky_D/0/1/0/all/0/1&quot;&gt;Daniel Mitropolsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosen_A/0/1/0/all/0/1&quot;&gt;Alon Rosen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A problem is \emph{downward self-reducible} if it can be solved efficiently
given an oracle that returns solutions for strictly smaller instances. In the
decisional landscape, downward self-reducibility is well studied and it is
known that all downward self-reducible problems are in \textsc{PSPACE}. In this
paper, we initiate the study of downward self-reducible search problems which
are guaranteed to have a solution -- that is, the downward self-reducible
problems in \textsc{TFNP}. We show that most natural $\PLS$-complete problems
are downward self-reducible and any downward self-reducible problem in
\textsc{TFNP} is contained in \textsc{PLS}. Furthermore, if the downward
self-reducible problem is in \textsc{UTFNP} (i.e. it has a unique solution),
then it is actually contained in \textsc{CLS}. This implies that if integer
factoring is \emph{downward self-reducible} then it is in fact in \textsc{CLS},
suggesting that no efficient factoring algorithm exists using the factorization
of smaller numbers.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: The Dispersive Art Gallery Problem</title>
    <link href="http://arxiv.org/abs/2209.10291"/>
    <id>http://arxiv.org/abs/2209.10291</id>
    <updated>2022-09-22T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rieck_C/0/1/0/all/0/1&quot;&gt;Christian Rieck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheffer_C/0/1/0/all/0/1&quot;&gt;Christian Scheffer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce a new variant of the art gallery problem that comes from safety
issues. In this variant we are not interested in guard sets of smallest
cardinality, but in guard sets with largest possible distances between these
guards. To the best of our knowledge, this variant has not been considered
before.We call it the Dispersive Art Gallery Problem. In particular, in the
dispersive art gallery problem we are given a polygon $\mathcal{P}$ and a real
number $\ell$, and want to decide whether $\mathcal{P}$ has a guard set such
that every pair of guards in this set is at least a distance of $\ell$ apart.
&lt;/p&gt;
&lt;p&gt;In this paper, we study the vertex guard variant of this problem for the
class of polyominoes. We consider rectangular visibility and distances as
geodesics in the $L_1$-metric. Our results are as follows. We give a (simple)
thin polyomino such that every guard set has minimum pairwise distances of at
most $3$. On the positive side, we describe an algorithm that computes guard
sets for simple polyominoes that match this upper bound, i.e., the algorithm
constructs worst-case optimal solutions. We also study the computational
complexity of computing guard sets that maximize the smallest distance between
all pairs of guards within the guard sets. We prove that deciding whether there
exists a guard set realizing a minimum pairwise distance for all pairs of
guards of at least $5$ in a given polyomino is NP-complete.
&lt;/p&gt;
&lt;p&gt;We were also able to find an optimal dynamic programming approach that
computes a guard set that maximizes the minimum pairwise distance between
guards in tree-shaped polyominoes, i.e., computes optimal solutions. Because
the shapes constructed in the NP-hardness reduction are thin as well (but have
holes), this result completes the case for thin polyominoes.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Efficient inspection of underground galleries using k robots with limited energy</title>
    <link href="http://arxiv.org/abs/2209.10400"/>
    <id>http://arxiv.org/abs/2209.10400</id>
    <updated>2022-09-22T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bereg_S/0/1/0/all/0/1&quot;&gt;Sergey Bereg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caraballo_L/0/1/0/all/0/1&quot;&gt;L. Evaristo Caraballo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Miguel D&amp;#xed;az-B&amp;#xe1;&amp;#xf1;ez&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the problem of optimally inspecting an underground (underwater)
gallery with k agents. We consider a gallery with a single opening and with a
tree topology rooted at the opening. Due to the small diameter of the pipes
(caves), the agents are small robots with limited autonomy and there is a
supply station at the gallery&#39;s opening. Therefore, they are initially placed
at the root and periodically need to return to the supply station. Our goal is
to design off-line strategies to efficiently cover the tree with $k$ small
robots. We consider two objective functions: the covering time (maximum
collective time) and the covering distance (total traveled distance). The
maximum collective time is the maximum time spent by a robot needs to finish
its assigned task (assuming that all the robots start at the same time); the
total traveled distance is the sum of the lengths of all the covering walks.
Since the problems are intractable for big trees, we propose approximation
algorithms. Both efficiency and accuracy of the suboptimal solutions are
empirically showed for random trees through intensive numerical experiments.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Characterizing the Decidability of Finite State Automata Team Games with Communication</title>
    <link href="http://arxiv.org/abs/2209.10324"/>
    <id>http://arxiv.org/abs/2209.10324</id>
    <updated>2022-09-22T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coulombe_M/0/1/0/all/0/1&quot;&gt;Michael Coulombe&lt;/a&gt; (Massachusetts Institute of Technology), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lynch_J/0/1/0/all/0/1&quot;&gt;Jayson Lynch&lt;/a&gt; (Cheriton School of Computer Science, University of Waterloo)&lt;/p&gt;&lt;p&gt;In this paper we define a new model of limited communication for multiplayer
team games of imperfect information. We prove that the Team DFA Game and Team
Formula Game, which have bounded state, remain undecidable when players have a
rate of communication which is less than the rate at which they make moves in
the game. We also show that meeting this communication threshold causes these
games to be decidable.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Parametric Synthesis of Computational Circuits for Complex Quantum Algorithms</title>
    <link href="http://arxiv.org/abs/2209.09903"/>
    <id>http://arxiv.org/abs/2209.09903</id>
    <updated>2022-09-22T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pronin_C/0/1/0/all/0/1&quot;&gt;Cesar Borisovich Pronin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ostroukh_A/0/1/0/all/0/1&quot;&gt;Andrey Vladimirovich Ostroukh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;At the moment, quantum circuits are created mainly by manually placing logic
elements on lines that symbolize quantum bits. The purpose of creating Quantum
Circuit Synthesizer &quot;Naginata&quot; was due to the fact that even with a slight
increase in the number of operations in a quantum algorithm, leads to the
significant increase in size of the corresponding quantum circuit. This causes
serious difficulties both in creating and debugging these quantum circuits. The
purpose of our quantum synthesizer is enabling users an opportunity to
implement quantum algorithms using higher-level commands. This is achieved by
creating generic blocks for frequently used operations such as: the adder,
multiplier, digital comparator (comparison operator), etc. Thus, the user could
implement a quantum algorithm by using these generic blocks, and the quantum
synthesizer would create a suitable circuit for this algorithm, in a format
that is supported by the chosen quantum computation environment. This approach
greatly simplifies the processes of development and debugging a quantum
algorithm. The proposed approach for implementing quantum algorithms has a
potential application in the field of machine learning, in this regard, we
provided an example of creating a circuit for training a simple neural network.
Neural networks have a significant impact on the technological development of
the transport and road complex, and there is a potential for improving the
reliability and efficiency of their learning process by utilizing quantum
computation, through the introduction of quantum computing.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


</feed>
