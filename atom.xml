<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Theory of Computing Report</title>
  <link rel="self" href=""/>
  <link href=""/>
  <id></id>
  <updated></updated>
  <generator uri="http://feedreader.github.io/">Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]</generator>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Littlewood-Richardson coefficients and Kostka number</title>
    <link href="http://arxiv.org/abs/2211.10669"/>
    <id>http://arxiv.org/abs/2211.10669</id>
    <updated>2022-11-22T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shrivastava_S/0/1/0/all/0/1&quot;&gt;Sagar Shrivastava&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Littlewood-Richardson (LR) coefficients and Kostka Numbers appear in
representation theory and combinatorics related to GLn . It is known that
Kostka numbers can be represented as special Littlewood-Rischardson
coefficient. In this paper, we show how one can represent LR coefficient in
terms of Kostka numbers, and use the formulation to give a polynomial time
algorithm for the same, hence showing that they belong to the same class of
decision problems.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Prophet-Inequalities over Time</title>
    <link href="http://arxiv.org/abs/2211.10471"/>
    <id>http://arxiv.org/abs/2211.10471</id>
    <updated>2022-11-22T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abels_A/0/1/0/all/0/1&quot;&gt;Andreas Abels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pitschmann_E/0/1/0/all/0/1&quot;&gt;Elias Pitschmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmand_D/0/1/0/all/0/1&quot;&gt;Daniel Schmand&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we introduce an over-time variant of the well-known
prophet-inequality with i.i.d. random variables. Instead of stopping with one
realized value at some point in the process, we decide for each step how long
we select the value. Then we cannot select another value until this period is
over. The goal is to maximize the expectation of the sum of selected values. We
describe the structure of the optimal stopping rule and give upper and lower
bounds on the prophet-inequality. - Which, in online algorithms terminology,
corresponds to bounds on the competitive ratio of an online algorithm.
&lt;/p&gt;
&lt;p&gt;We give a surprisingly simple algorithm with a single threshold that results
in a prophet-inequality of $\approx 0.396$ for all input lengths $n$.
Additionally, as our main result, we present a more advanced algorithm
resulting in a prophet-inequality of $\approx 0.598$ when the number of steps
tends to infinity. We complement our results by an upper bound that shows that
the best possible prophet-inequality is at most $1/\varphi \approx 0.618$,
where $\varphi$ denotes the golden ratio. As part of the proof, we give an
advanced bound on the weighted mediant.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Efficient Determinant Maximization for All Matroids</title>
    <link href="http://arxiv.org/abs/2211.10507"/>
    <id>http://arxiv.org/abs/2211.10507</id>
    <updated>2022-11-22T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_A/0/1/0/all/0/1&quot;&gt;Adam Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laddha_A/0/1/0/all/0/1&quot;&gt;Aditi Laddha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pittu_M/0/1/0/all/0/1&quot;&gt;Madhusudhan Pittu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1&quot;&gt;Mohit Singh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Determinant maximization provides an elegant generalization of problems in
many areas, including convex geometry, statistics, machine learning, fair
allocation of goods, and network design. In an instance of the determinant
maximization problem, we are given a collection of vectors $v_1,\ldots, v_n \in
\mathbb{R}^d$, and the goal is to pick a subset $S\subseteq [n]$ of given
vectors to maximize the determinant of the matrix $\sum_{i \in S} v_iv_i^\top$,
where the picked set of vectors $S$ must satisfy some combinatorial constraint
such as cardinality constraint ($|S| \leq k$) or matroid constraint ($S$ is a
basis of a matroid defined on $[n]$).
&lt;/p&gt;
&lt;p&gt;In this work, we give a combinatorial algorithm for the determinant
maximization problem under a matroid constraint that achieves
$O(d^{O(d)})$-approximation for any matroid of rank $r\geq d$. This complements
the recent result of~\cite{BrownLPST22} that achieves a similar bound for
matroids of rank $r\leq d$, relying on a geometric interpretation of the
determinant. Our result matches the best-known estimation
algorithms~\cite{madan2020maximizing} for the problem, which could estimate the
objective value but could not give an approximate solution with a similar
guarantee. Our work follows the framework developed by~\cite{BrownLPST22} of
using matroid intersection based algorithms for determinant maximization. To
overcome the lack of a simple geometric interpretation of the objective when $r
\geq d$, our approach combines ideas from combinatorial optimization with
algebraic properties of the determinant. We also critically use the properties
of a convex programming relaxation of the problem introduced
by~\cite{madan2020maximizing}.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: PIM-tree: A Skew-resistant Index for Processing-in-Memory</title>
    <link href="http://arxiv.org/abs/2211.10516"/>
    <id>http://arxiv.org/abs/2211.10516</id>
    <updated>2022-11-22T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_H/0/1/0/all/0/1&quot;&gt;Hongbo Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yiwei Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blelloch_G/0/1/0/all/0/1&quot;&gt;Guy E. Blelloch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1&quot;&gt;Laxman Dhulipala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1&quot;&gt;Yan Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGuffey_C/0/1/0/all/0/1&quot;&gt;Charles McGuffey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gibbons_P/0/1/0/all/0/1&quot;&gt;Phillip B. Gibbons&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The performance of today&#39;s in-memory indexes is bottlenecked by the memory
latency/bandwidth wall. Processing-in-memory (PIM) is an emerging approach that
potentially mitigates this bottleneck, by enabling low-latency memory access
whose aggregate memory bandwidth scales with the number of PIM nodes. There is
an inherent tension, however, between minimizing inter-node communication and
achieving load balance in PIM systems, in the presence of workload skew. This
paper presents PIM-tree, an ordered index for PIM systems that achieves both
low communication and high load balance, regardless of the degree of skew in
the data and the queries. Our skew-resistant index is based on a novel division
of labor between the multi-core host CPU and the PIM nodes, which leverages the
strengths of each. We introduce push-pull search, which dynamically decides
whether to push queries to a PIM-tree node (CPU -&amp;gt; PIM-node) or pull the node&#39;s
keys back to the CPU (PIM-node -&amp;gt; CPU) based on workload skew. Combined with
other PIM-friendly optimizations (shadow subtrees and chunked skip lists), our
PIM-tree provides high-throughput, (guaranteed) low communication, and
(guaranteed) high load balance, for batches of point queries, updates, and
range scans.
&lt;/p&gt;
&lt;p&gt;We implement the PIM-tree structure, in addition to prior proposed PIM
indexes, on the latest PIM system from UPMEM, with 32 CPU cores and 2048 PIM
nodes. On workloads with 500 million keys and batches of one million queries,
the throughput using PIM-trees is up to 69.7x and 59.1x higher than the two
best prior methods. As far as we know these are the first implementations of an
ordered index on a real PIM system.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A Distanced Matching Game, Decremental APSP in Expanders, and Faster Deterministic Algorithms for Graph Cut Problems</title>
    <link href="http://arxiv.org/abs/2211.10556"/>
    <id>http://arxiv.org/abs/2211.10556</id>
    <updated>2022-11-22T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chuzhoy_J/0/1/0/all/0/1&quot;&gt;Julia Chuzhoy&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Expander graphs play a central role in graph theory and algorithms. With a
number of powerful algorithmic tools developed around them, such as the
Cut-Matching game, expander pruning, expander decomposition, and algorithms for
decremental All-Pairs Shortest Paths (APSP) in expanders, to name just a few,
the use of expanders in the design of graph algorithms has become ubiquitous.
Specific applications of interest to us are fast deterministic algorithms for
cut problems in static graphs, and algorithms for dynamic distance-based graph
problems, such as APSP.
&lt;/p&gt;
&lt;p&gt;Unfortunately, the use of expanders in these settings incurs a number of
drawbacks. For example, the best currently known algorithm for decremental APSP
in constant-degree expanders can only achieve a $(\log
n)^{O(1/\epsilon^2)}$-approximation with $n^{1+O(\epsilon)}$ total update time
for any $\epsilon$. All currently known algorithms for the Cut Player in the
Cut-Matching game are either randomized, or provide rather weak guarantees.
This, in turn, leads to somewhat weak algorithmic guarantees for several
central cut problems: for example, the best current almost linear time
deterministic algorithm for Sparsest Cut can only achieve approximation factor
$(\log n)^{\omega(1)}$. Lastly, when relying on expanders in distance-based
problems, such as dynamic APSP, via current methods, it seems inevitable that
one has to settle for approximation factors that are at least $\Omega(\log n)$.
&lt;/p&gt;
&lt;p&gt;In this paper we propose the use of well-connected graphs, and introduce a
new algorithmic toolkit for such graphs that, in a sense, mirrors the above
mentioned algorithmic tools for expanders. One of these new tools is the
Distanced Matching game, an analogue of the Cut-Matching game for
well-connected graphs. We demonstrate the power of these new tools by obtaining
better results for several of the problems mentioned above.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Differential Privacy from Locally Adjustable Graph Algorithms: $k$-Core Decomposition, Low Out-Degree Ordering, and Densest Subgraphs</title>
    <link href="http://arxiv.org/abs/2211.10887"/>
    <id>http://arxiv.org/abs/2211.10887</id>
    <updated>2022-11-22T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1&quot;&gt;Laxman Dhulipala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Quanquan C. Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raskhodnikova_S/0/1/0/all/0/1&quot;&gt;Sofya Raskhodnikova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jessica Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shun_J/0/1/0/all/0/1&quot;&gt;Julian Shun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Shangdi Yu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Differentially private algorithms allow large-scale data analytics while
preserving user privacy. Designing such algorithms for graph data is gaining
importance with the growth of large networks that model various (sensitive)
relationships between individuals. While there exists a rich history of
important literature in this space, to the best of our knowledge, no results
formalize a relationship between certain parallel and distributed graph
algorithms and differentially private graph analysis. In this paper, we define
\emph{locally adjustable} graph algorithms and show that algorithms of this
type can be transformed into differentially private algorithms.
&lt;/p&gt;
&lt;p&gt;Our formalization is motivated by a set of results that we present in the
central and local models of differential privacy for a number of problems,
including $k$-core decomposition, low out-degree ordering, and densest
subgraphs. First, we design an $\varepsilon$-edge differentially private (DP)
algorithm that returns a subset of nodes that induce a subgraph of density at
least $\frac{D^*}{1+\eta} - O\left(\text{poly}(\log n)/\varepsilon\right),$
where $D^*$ is the density of the densest subgraph in the input graph (for any
constant $\eta &amp;gt; 0$). This algorithm achieves a two-fold improvement on the
multiplicative approximation factor of the previously best-known private
densest subgraph algorithms while maintaining a near-linear runtime.
&lt;/p&gt;
&lt;p&gt;Then, we present an $\varepsilon$-locally edge differentially private (LEDP)
algorithm for $k$-core decompositions. Our LEDP algorithm provides approximates
the core numbers (for any constant $\eta &amp;gt; 0$) with $(2+\eta)$ multiplicative
and $O\left(\text{poly}\left(\log n\right)/\varepsilon\right)$ additive error.
This is the first differentially private algorithm that outputs private
$k$-core decomposition statistics.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Faculty position at CS  department,   Boston University  (apply by December 2, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/11/21/faculty-position-at-cs-department-boston-university-apply-by-december-2-2022/"/>
    <id>http://cstheory-jobs.org/2022/11/21/faculty-position-at-cs-department-boston-university-apply-by-december-2-2022/</id>
    <updated>2022-11-21T21:26:41+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Two tenure-track assistant professorships beginning July 1, 2023. Strong applicants in all areas of computer science are encouraged to apply, particularly in theory of computation, algorithms, and systems. Applicants working on foundational, methodological, or use-inspired AI research are encouraged to apply to the AI cluster hire initiative.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.bu.edu/cs/2022/10/04/bu-cs-invites-applications-for-new-faculty-members-2022/&quot;&gt;https://www.bu.edu/cs/2022/10/04/bu-cs-invites-applications-for-new-faculty-members-2022/&lt;/a&gt;&lt;br /&gt;
Email: canetti@bu.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Faculty at Rutgers University (New Brunswick) (apply by January 3, 2023)</title>
    <link href="https://cstheory-jobs.org/2022/11/21/faculty-at-rutgers-university-new-brunswick-apply-by-january-3-2023/"/>
    <id>http://cstheory-jobs.org/2022/11/21/faculty-at-rutgers-university-new-brunswick-apply-by-january-3-2023/</id>
    <updated>2022-11-21T19:14:14+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The Computer Science Department at Rutgers University, New Brunswick NJ, invites applications for multiple tenure-track/tenured. We invite applications from candidates specializing in any area of CS, and welcome applicants with interdisciplinary approaches. We are especially interested in Algorithms, Machine Learning and Data Science, High-performance Computing and Scalable Systems.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://jobs.rutgers.edu/postings/183703&quot;&gt;https://jobs.rutgers.edu/postings/183703&lt;/a&gt;&lt;br /&gt;
Email: hiring-committee@cs.rutgers.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: A Celebration of Juris</title>
    <link href="http://blog.computationalcomplexity.org/2022/11/a-celebration-of-juris.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-5196164101457278361</id>
    <updated>2022-11-21T14:52:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;/p&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxWze7urg3GUKNZRP8vI4maCWwNHi1JQkVcFCRfLas3dZQbmvYZz4jLurkuCXLAiLOFmKXjg7QAFHh5iNwt2vCR4ONgOSIHSBRpw1cC0rQjCvm9bKSSREiDMmPRLK8N3xtg9la8HCM7yr1iOTwP9v4FWv1eYhwGAQoF6JrbXlEZvw8LR-kug/s4080/PXL_20221104_140728676.jpg&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;3072&quot; data-original-width=&quot;4080&quot; height=&quot;241&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxWze7urg3GUKNZRP8vI4maCWwNHi1JQkVcFCRfLas3dZQbmvYZz4jLurkuCXLAiLOFmKXjg7QAFHh5iNwt2vCR4ONgOSIHSBRpw1cC0rQjCvm9bKSSREiDMmPRLK8N3xtg9la8HCM7yr1iOTwP9v4FWv1eYhwGAQoF6JrbXlEZvw8LR-kug/s320/PXL_20221104_140728676.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;On November 4th I travelled to my undergraduate alma mater Cornell for a &lt;a href=&quot;https://cis.cornell.edu/bowers-cis-community-celebrates-life-juris-hartmanis&quot;&gt;Celebration of the Life and Career of Juris Hartmanis&lt;/a&gt;&amp;nbsp;who &lt;a href=&quot;https://blog.computationalcomplexity.org/2022/08/the-godfather-of-complexity.html&quot;&gt;passed away&lt;/a&gt; in July. The workshop attracted many Cornell faculty and students, many of Hartmanis&#39; former colleague and students, grad and undergrad, as well as his family. For the most part, the talks did not focus on technical content but rather memories of the great man.&amp;nbsp;&lt;p&gt;&lt;/p&gt;&lt;p&gt;I &lt;a href=&quot;https://www.youtube.com/watch?v=ACxU-90O-ag&amp;amp;t=2768s&quot;&gt;talked about&lt;/a&gt;&amp;nbsp;how Hartmanis founded the field of Computational Complexity and brought me into it. Herbert Lin &lt;a href=&quot;https://www.youtube.com/watch?v=QKW_GalI31o&amp;amp;t=2900s&quot;&gt;told the story&lt;/a&gt; behind &lt;a href=&quot;https://www.google.com/books/edition/Computing_the_Future/tYBQAAAAMAAJ&quot;&gt;Computing the Future&lt;/a&gt;, a 1992 agenda for the future of computer science led by Hartmanis and the challenge to the report by John McCarthy, one of the founders of AI. Should the agenda of computer science be solely in the hands of academic computer scientists, or should it take into account its role in the larger scientific and world-wide community? We still face these questions today.&lt;/p&gt;&lt;p&gt;Ryan Williams gave &lt;a href=&quot;https://www.youtube.com/watch?v=ACxU-90O-ag&amp;amp;t=10350s&quot;&gt;a powerful talk&lt;/a&gt;&amp;nbsp;about how Hartmanis personally intervened to ensure Ryan had a future in complexity. We are all better off for that.&lt;/p&gt;&lt;p&gt;After the workshop, Ryan and I walked around the campus and Collegetown reminiscing on how things have changed in the two decades since Ryan was an undergrad and the four decades (!) since I was. Most of the bars and restaurants have disappeared. The Arts quad is mostly the same, while the engineering building have been mostly rebuilt. There&#39;s a &lt;a href=&quot;https://www.engineering.cornell.edu/magazine/features/gates-hall-new-home-cis&quot;&gt;new computer science building&lt;/a&gt; with &lt;a href=&quot;https://ithacavoice.com/2022/05/cornell-plans-new-computer-science-building-on-hoy-field/&quot;&gt;another on the way&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&lt;p&gt;I stayed in town to catch the Cornell football game the next day, as I once was on that field playing tuba for the marching band. They tore down the west stands to put up a parking lot and the east stands were sparsely filled watching Penn dominate the game.&lt;/p&gt;&lt;p&gt;Good bye Juris. You created a discipline, started one of the first CS departments, and plotted the future of both computational complexity and computer science as a whole. A master and commander indeed.&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Computational Short Cuts in Infinite Domain Constraint Satisfaction</title>
    <link href="http://arxiv.org/abs/2211.10144"/>
    <id>http://arxiv.org/abs/2211.10144</id>
    <updated>2022-11-21T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jonsson_P/0/1/0/all/0/1&quot;&gt;Peter Jonsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lagerkvist_V/0/1/0/all/0/1&quot;&gt;Victor Lagerkvist&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ordyniak_S/0/1/0/all/0/1&quot;&gt;Sebastian Ordyniak&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A backdoor in a finite-domain CSP instance is a set of variables where each
possible instantiation moves the instance into a polynomial-time solvable
class. Backdoors have found many applications in artificial intelligence and
elsewhere, and the algorithmic problem of finding such backdoors has
consequently been intensively studied. Sioutis and Janhunen (Proc. 42nd German
Conference on AI (KI-2019)) have proposed a generalised backdoor concept
suitable for infinite-domain CSP instances over binary constraints. We
generalise their concept into a large class of CSPs that allow for higher-arity
constraints. We show that this kind of infinite-domain backdoors have many of
the positive computational properties that finite-domain backdoors have: the
associated computational problems are fixed-parameter tractable whenever the
underlying constraint language is finite. On the other hand, we show that
infinite languages make the problems considerably harder: the general backdoor
detection problem is W[2]-hard and fixed-parameter tractability is ruled out
under standard complexity-theoretic assumptions. We demonstrate that backdoors
may have suboptimal behaviour on binary constraints -- this is detrimental from
an AI perspective where binary constraints are predominant in, for instance,
spatiotemporal applications. In response to this, we introduce sidedoors as an
alternative to backdoors. The fundamental computational problems for sidedoors
remain fixed-parameter tractable for finite constraint language (possibly also
containing non-binary relations). Moreover, the sidedoor approach has appealing
computational properties that sometimes leads to faster algorithms than the
backdoor approach.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Crossing and intersecting families of geometric graphs on point sets</title>
    <link href="http://arxiv.org/abs/2211.09904"/>
    <id>http://arxiv.org/abs/2211.09904</id>
    <updated>2022-11-21T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Alvarez_Rebollar_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Luis &amp;#xc1;lvarez-Rebollar&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cravioto_Lagos_J/0/1/0/all/0/1&quot;&gt;Jorge Cravioto-Lagos&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Marin_N/0/1/0/all/0/1&quot;&gt;Nestaly Mar&amp;#xed;n&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sole_Pi_O/0/1/0/all/0/1&quot;&gt;Oriol Sol&amp;#xe9;-Pi&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Urrutia_J/0/1/0/all/0/1&quot;&gt;Jorge Urrutia&lt;/a&gt; (4) ((1) Posgrado en Ciencias Matem&amp;#xe1;ticas, UNAM and Departamento de Ciencias B&amp;#xe1;sicas, Instituto Tecnol&amp;#xf3;gico de Zit&amp;#xe1;cuaro, (2) Posgrado en Ciencia e Ingenier&amp;#xed;a de la Computaci&amp;#xf3;n, UNAM, (3) Facultad de Ciencias, UNAM, (4) Instituto de Matem&amp;#xe1;ticas, UNAM)&lt;/p&gt;&lt;p&gt;Let $S$ be a set of $n$ points in the plane in general position. Two line
segments connecting pairs of points of $S$ cross if they have an interior point
in common. Two vertex disjoint geometric graphs with vertices in $S$ cross if
there are two edges, one from each graph, which cross. A set of vertex disjoint
geometric graphs with vertices in $S$ is called mutually crossing if any two of
them cross.
&lt;/p&gt;
&lt;p&gt;We show that there exists a constant $c$ such that from any family of $n$
mutually crossing triangles, one can always obtain a family of at least $n^c$
mutually crossing $2$-paths (each of which is the result of deleting an edge
from one of the triangles) and then provide an example that implies that $c$
cannot be taken to be larger than $2/3$. For every $n$ we determine the maximum
number of crossings that a Hamiltonian cycle on a set of $n$ points might have.
Next, we construct a point set whose longest perfect matching contains no
crossings. We also consider edges consisting of a horizontal and a vertical
line segment joining pairs of points of $S$, which we call elbows, and prove
that in any point set $S$ there exists a family of $\lfloor n/4 \rfloor$ vertex
disjoint mutually crossing elbows. Additionally, we show a point set that
admits no more than $n/3$ mutually crossing elbows.
&lt;/p&gt;
&lt;p&gt;Finally we study intersecting families of graphs, which are not necessarily
vertex disjoint. A set of edge disjoint graphs with vertices in $S$ is called
an intersecting family if for any two graphs in the set we can choose an edge
in each of them such that they cross. We prove a conjecture by Lara and
Rubio-Montiel, namely, that any set $S$ of $n$ points in general position
admits a family of intersecting triangles with a quadratic number of elements.
&lt;/p&gt;
&lt;p&gt;Some other results are obtained throughout this work.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Optimal Algorithms for Linear Algebra in the Current Matrix Multiplication Time</title>
    <link href="http://arxiv.org/abs/2211.09964"/>
    <id>http://arxiv.org/abs/2211.09964</id>
    <updated>2022-11-21T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cherapanamjeri_Y/0/1/0/all/0/1&quot;&gt;Yeshwanth Cherapanamjeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1&quot;&gt;Sandeep Silwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1&quot;&gt;David P. Woodruff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Samson Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study fundamental problems in linear algebra, such as finding a maximal
linearly independent subset of rows or columns (a basis), solving linear
regression, or computing a subspace embedding. For these problems, we consider
input matrices $\mathbf{A}\in\mathbb{R}^{n\times d}$ with $n &amp;gt; d$. The input
can be read in $\text{nnz}(\mathbf{A})$ time, which denotes the number of
nonzero entries of $\mathbf{A}$. In this paper, we show that beyond the time
required to read the input matrix, these fundamental linear algebra problems
can be solved in $d^{\omega}$ time, i.e., where $\omega \approx 2.37$ is the
current matrix-multiplication exponent.
&lt;/p&gt;
&lt;p&gt;To do so, we introduce a constant-factor subspace embedding with the optimal
$m=\mathcal{O}(d)$ number of rows, and which can be applied in time
$\mathcal{O}\left(\frac{\text{nnz}(\mathbf{A})}{\alpha}\right) + d^{2 +
\alpha}\text{poly}(\log d)$ for any trade-off parameter $\alpha&amp;gt;0$, tightening
a recent result by Chepurko et. al. [SODA 2022] that achieves an
$\exp(\text{poly}(\log\log n))$ distortion with $m=d\cdot\text{poly}(\log\log
d)$ rows in
$\mathcal{O}\left(\frac{\text{nnz}(\mathbf{A})}{\alpha}+d^{2+\alpha+o(1)}\right)$
time. Our subspace embedding uses a recently shown property of stacked
Subsampled Randomized Hadamard Transforms (SRHT), which actually increase the
input dimension, to &quot;spread&quot; the mass of an input vector among a large number
of coordinates, followed by random sampling. To control the effects of random
sampling, we use fast semidefinite programming to reweight the rows. We then
use our constant-factor subspace embedding to give the first optimal runtime
algorithms for finding a maximal linearly independent subset of columns,
regression, and leverage score sampling. To do so, we also introduce a novel
subroutine that iteratively grows a set of independent rows, which may be of
independent interest.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Listing 4-Cycles</title>
    <link href="http://arxiv.org/abs/2211.10022"/>
    <id>http://arxiv.org/abs/2211.10022</id>
    <updated>2022-11-21T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abboud_A/0/1/0/all/0/1&quot;&gt;Amir Abboud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoury_S/0/1/0/all/0/1&quot;&gt;Seri Khoury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leibowitz_O/0/1/0/all/0/1&quot;&gt;Oree Leibowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Safier_R/0/1/0/all/0/1&quot;&gt;Ron Safier&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this note we present an algorithm that lists all $4$-cycles in a graph in
time $\tilde{O}(\min(n^2,m^{4/3})+t)$ where $t$ is their number. Notably, this
separates $4$-cycle listing from triangle-listing, since the latter has a
$(\min(n^3,m^{3/2})+t)^{1-o(1)}$ lower bound under the $3$-SUM Conjecture.
&lt;/p&gt;
&lt;p&gt;Our upper bound is conditionally tight because (1) $O(n^2,m^{4/3})$ is the
best known bound for detecting if the graph has any $4$-cycle, and (2) it
matches a recent $(\min(n^3,m^{3/2})+t)^{1-o(1)}$ $3$-SUM lower bound for
enumeration algorithms.
&lt;/p&gt;
&lt;p&gt;The latter lower bound was proved very recently by Abboud, Bringmann, and
Fischer [arXiv, 2022] and independently by Jin and Xu [arXiv, 2022].
&lt;/p&gt;
&lt;p&gt;In an independent work, Jin and Xu [arXiv, 2022] also present an algorithm
with the same time bound.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: The communication cost of security and privacy in federated frequency estimation</title>
    <link href="http://arxiv.org/abs/2211.10041"/>
    <id>http://arxiv.org/abs/2211.10041</id>
    <updated>2022-11-21T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei-Ning Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozgur_A/0/1/0/all/0/1&quot;&gt;Ayfer &amp;#xd6;zg&amp;#xfc;r&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cormode_G/0/1/0/all/0/1&quot;&gt;Graham Cormode&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bharadwaj_A/0/1/0/all/0/1&quot;&gt;Akash Bharadwaj&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the federated frequency estimation problem, where each user holds
a private item $X_i$ from a size-$d$ domain and a server aims to estimate the
empirical frequency (i.e., histogram) of $n$ items with $n \ll d$. Without any
security and privacy considerations, each user can communicate its item to the
server by using $\log d$ bits. A naive application of secure aggregation
protocols would, however, require $d\log n$ bits per user. Can we reduce the
communication needed for secure aggregation, and does security come with a
fundamental cost in communication?
&lt;/p&gt;
&lt;p&gt;In this paper, we develop an information-theoretic model for secure
aggregation that allows us to characterize the fundamental cost of security and
privacy in terms of communication. We show that with security (and without
privacy) $\Omega\left( n \log d \right)$ bits per user are necessary and
sufficient to allow the server to compute the frequency distribution. This is
significantly smaller than the $d\log n$ bits per user needed by the naive
scheme, but significantly higher than the $\log d$ bits per user needed without
security. To achieve differential privacy, we construct a linear scheme based
on a noisy sketch which locally perturbs the data and does not require a
trusted server (a.k.a. distributed differential privacy). We analyze this
scheme under $\ell_2$ and $\ell_\infty$ loss. By using our
information-theoretic framework, we show that the scheme achieves the optimal
accuracy-privacy trade-off with optimal communication cost, while matching the
performance in the centralized case where data is stored in the central server.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Identifying Correlation in Stream of Samples</title>
    <link href="http://arxiv.org/abs/2211.10137"/>
    <id>http://arxiv.org/abs/2211.10137</id>
    <updated>2022-11-21T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1&quot;&gt;Zhenhao Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hao Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Identifying independence between two random variables or correlated given
their samples has been a fundamental problem in Statistics. However, how to do
so in a space-efficient way if the number of states is large is not quite
well-studied.
&lt;/p&gt;
&lt;p&gt;We propose a new, simple counter matrix algorithm, which utilize hash
functions and a compressed counter matrix to give an unbiased estimate of the
$\ell_2$ independence metric. With $\mathcal{O}(\epsilon^{-4}\log\delta^{-1})$
(very loose bound) space, we can guarantee $1\pm\epsilon$ multiplicative error
with probability at least $1-\delta$. We also provide a comparison of our
algorithm with the state-of-the-art sketching of sketches algorithm and show
that our algorithm is effective, and actually faster and at least 2 times more
space-efficient.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improved Approximations for Unrelated Machine Scheduling</title>
    <link href="http://arxiv.org/abs/2211.10398"/>
    <id>http://arxiv.org/abs/2211.10398</id>
    <updated>2022-11-21T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Im_S/0/1/0/all/0/1&quot;&gt;Sungjin Im&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shi Li&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We revisit two well-studied scheduling problems in the unrelated machines
setting where each job can have a different processing time on each machine.
For minimizing total weighted completion time we give a 1.45-approximation,
which improves upon the previous 1.488-approximation [Im and Shadloo SODA
2020]. The key technical ingredient in this improvement lies in a new rounding
scheme that gives strong negative correlation with less restrictions. For
minimizing $L_k$-norms of machine loads, inspired by [Kalaitzis et al. SODA
2017], we give better approximation algorithms. In particular we give a $\sqrt
{4/3}$-approximation for the $L_2$-norm which improves upon the former $\sqrt
2$-approximations due to [Azar-Epstein STOC 2005] and [Kumar et al. JACM 2009].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Scott Aaronson: Reform AI Alignment</title>
    <link href="https://scottaaronson.blog/?p=6821"/>
    <id>https://scottaaronson.blog/?p=6821</id>
    <updated>2022-11-20T20:44:33+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Nearly halfway into my year at OpenAI, still reeling from the FTX collapse, I feel like it&amp;#8217;s finally time to start blogging my AI safety thoughts&amp;#8212;starting with a little appetizer course today, more substantial fare to come.&lt;/p&gt;



&lt;p&gt;Many people claim that AI alignment is little more a modern eschatological religion&amp;#8212;with prophets, an end-times prophecy, sacred scriptures, and even a god (albeit, one who doesn&amp;#8217;t exist quite yet).  The obvious response to that claim is that, while there&amp;#8217;s some truth to it, &amp;#8220;religions&amp;#8221; based around technology are a little different from the old kind, because technological progress &lt;em&gt;actually happens&lt;/em&gt; regardless of whether you believe in it.&lt;/p&gt;



&lt;p&gt;I mean, the Internet is sort of like the old concept of the collective unconscious, except that it actually exists and you&amp;#8217;re using it right now.  Airplanes and spacecraft are kind of like the ancient dream of Icarus&amp;#8212;except, again, for the actually existing part.  Today GPT-3 and DALL-E2 and LaMDA and AlphaTensor exist, as they didn&amp;#8217;t two years ago, and one has to try to project forward to what their vastly-larger successors will be doing a decade from now.  Though some of my colleagues are still in denial about it, I regard the fact that such systems will have transformative effects on civilization, comparable to or greater than those of the Internet itself, as &amp;#8220;already baked in&amp;#8221;&amp;#8212;as just the mainstream position, not even a question anymore.  That doesn&amp;#8217;t mean that future AIs are going to convert the earth into paperclips, or give us eternal life in a simulated utopia.  But their story &lt;em&gt;will&lt;/em&gt; be a central part of the story of this century.&lt;/p&gt;



&lt;p&gt;Which brings me to a second response.  If AI alignment is a religion, it’s now large and established enough to have a thriving &amp;#8220;Reform&amp;#8221; branch, in addition to the original &amp;#8220;Orthodox&amp;#8221; branch epitomized by Eliezer Yudkowsky and &lt;a href=&quot;https://intelligence.org/&quot;&gt;MIRI&lt;/a&gt;.  As far as I can tell, this Reform branch now counts among its members a large fraction of the AI safety researchers now working in academia and industry.  (I’ll leave the formation of a Conservative branch of AI alignment, which reacts against the Reform branch by moving &lt;em&gt;slightly&lt;/em&gt; back in the direction of the Orthodox branch, as a problem for the future — to say nothing of Reconstructionist or Marxist branches.)&lt;/p&gt;



&lt;p&gt;Here’s an incomplete but hopefully representative list of the differences in doctrine between Orthodox and Reform AI Risk:&lt;/p&gt;



&lt;p&gt;(1) Orthodox AI-riskers tend to believe that humanity will survive or be destroyed based on the actions of a few elite engineers over the next decade or two.  Everything else&amp;#8212;climate change, droughts, the future of US democracy, war over Ukraine and maybe Taiwan&amp;#8212;fades into insignificance except insofar as it affects those engineers.&lt;/p&gt;



&lt;p&gt;We Reform AI-riskers, by contrast, believe that AI might well pose civilizational risks in the coming century, but so does all the other stuff, and it&amp;#8217;s all tied together.  An invasion of Taiwan might change which world power gets access to TSMC GPUs.  Almost everything affects which entities pursue the AI scaling frontier and whether they&amp;#8217;re cooperating or competing to be first.&lt;/p&gt;



&lt;p&gt;(2) Orthodox AI-riskers believe that public outreach has limited value: most people can&amp;#8217;t understand this issue anyway, and will need to be saved from AI despite themselves.&lt;/p&gt;



&lt;p&gt;We Reform AI-riskers believe that trying to get a broad swath of the public on board with one&amp;#8217;s preferred AI policy is something close to a deontological imperative.&lt;/p&gt;



&lt;p&gt;(3) Orthodox AI-riskers worry almost entirely about an agentic, misaligned AI that deceives humans while it works to destroy them, along the way to maximizing its strange utility function.&lt;/p&gt;



&lt;p&gt;We Reform&amp;nbsp;AI-riskers entertain that possibility, but we worry at least as much about powerful AIs that are weaponized by bad humans, which we expect to pose existential risks much earlier in any case.&lt;/p&gt;



&lt;p&gt;(4) Orthodox AI-riskers have limited interest in AI safety research applicable to actually-existing systems (LaMDA, GPT-3, DALL-E2, etc.), seeing the dangers posed by those systems as basically trivial compared to the looming danger of a misaligned agentic AI.&lt;/p&gt;



&lt;p&gt;We Reform&amp;nbsp;AI-riskers see research on actually-existing systems as one of the only ways to get feedback from the world about which&amp;nbsp;AI&amp;nbsp;safety&amp;nbsp;ideas are or aren&amp;#8217;t promising.&lt;/p&gt;



&lt;p&gt;(5) Orthodox AI-riskers worry most about the &amp;#8220;FOOM&amp;#8221; scenario, where some AI might cross a threshold from innocuous-looking to plotting to kill all humans in the space of hours or days.&lt;/p&gt;



&lt;p&gt;We Reform&amp;nbsp;AI-riskers worry most about the &amp;#8220;slow-moving trainwreck&amp;#8221; scenario, where (just like with climate change) well-informed people can see the writing on the wall decades ahead, but just can&amp;#8217;t line up everyone&amp;#8217;s incentives to prevent it.&lt;/p&gt;



&lt;p&gt;(6) Orthodox AI-riskers talk a lot about a &amp;#8220;pivotal act&amp;#8221; to prevent a misaligned AI from ever being developed, which might involve (e.g.) using an aligned AI to impose a worldwide surveillance regime.&lt;/p&gt;



&lt;p&gt;We Reform&amp;nbsp;AI-riskers worry more about such an act causing the very calamity that it was intended to prevent.&lt;/p&gt;



&lt;p&gt;(7) Orthodox AI-riskers feel a strong need to repudiate the norms of mainstream science, seeing them as too slow-moving to react in time to the existential danger of AI.&lt;/p&gt;



&lt;p&gt;We Reform&amp;nbsp;AI-riskers feel a strong need to get mainstream science on board with the&amp;nbsp;AI&amp;nbsp;safety&amp;nbsp;program.&lt;/p&gt;



&lt;p&gt;(8) Orthodox AI-riskers are maximalists about the power of pure, unaided superintelligence to just figure out how to commandeer whatever physical resources it needs to take over the world (for example, by messaging some lab over the Internet, and tricking it into manufacturing nanobots that will do the superintelligence&amp;#8217;s bidding).&lt;/p&gt;



&lt;p&gt;We Reform AI-riskers believe that, here just like in high school, there are limits to the power of pure intelligence to achieve one&amp;#8217;s goals.  We&amp;#8217;d expect even an agentic, misaligned AI, if such existed, to need a stable power source, robust interfaces to the physical world, and probably allied humans before it posed much of an existential threat.&lt;/p&gt;



&lt;p&gt;What have I missed?&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </content>
    <author>
      <name>Scott Aaronson</name>
      <uri>https://scottaaronson.blog</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-164 |  Learning versus Pseudorandom Generators in Constant Parallel Time | 

	Shuichi Hirahara, 

	Mikito Nanashima</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/164"/>
    <id>https://eccc.weizmann.ac.il/report/2022/164</id>
    <updated>2022-11-20T11:26:40+00:00</updated>
    <content type="html" xml:lang="en">
    A polynomial-stretch pseudorandom generator (PPRG) in NC$^0$ (i.e., constant parallel time) is one of the most important cryptographic primitives, especially for constructing highly efficient cryptography and indistinguishability obfuscation. The celebrated work (Applebaum, Ishai, and Kushilevitz, SIAM Journal on Computing, 2006) on randomized encodings yields the characterization of sublinear-stretch pseudorandom generators in NC$^0$ by the existence of logspace-computable one-way functions, but characterizing PPRGs in NC$^0$ seems out of reach at present. Therefore, it is natural to ask which sort of hardness notion is essential for constructing PPRGs in NC$^0$. Particularly, to the best of our knowledge, all the previously known candidates for PPRGs in NC$^0$ follow only one framework based on Goldreich&amp;#39;s one-way function. 
		
In this paper, we present a new learning-theoretic characterization for PPRGs in NC$^0$ and related classes. Specifically, we consider the average-case hardness of learning for well-studied classes in parameterized settings, where the number of samples is restricted to fixed-parameter tractable (FPT), and show that the following are equivalent:
	(i) The existence of (a collection of) PPRGs in NC$^0$.
	(ii) The average-case hardness of learning sparse $\mathbb{F}_2$-polynomials on a sparse example distribution and an NC$^0$-samplable target distribution (i.e., a distribution on target functions).
	(iii) The average-case hardness of learning Fourier-sparse functions on a sparse example distribution and an NC$^0$-samplable target distribution.
	(iv) The average-case hardness of learning constant-depth parity decision trees on a sparse example distribution and an NC$^0$-samplable target distribution.
Furthermore, we characterize a (single) PPRG in $\oplus$-NC$^0$ by the average-case hardness of learning constant-degree $\mathbb{F}_2$-polynomials on a uniform example distribution with FPT samples. Based on our results, we propose new candidates for PPRGs in NC$^0$ and related classes under a hardness assumption on a natural learning problem. An important property of PPRGs in NC$^0$ constructed in our framework is that the output bits are computed by various predicates; thus, it seems to resist an attack that depends on a specific property of one fixed predicate.
	
Conceptually, the main contribution of this study is to formalize a theory of FPT dualization of concept classes, which yields a meta-theorem for the first result. For the second result on PPRGs in $\oplus$-NC$^0$, we use a different technique of pseudorandom $\mathbb{F}_2$-polynomials.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-163 |  Random Walks on Rotating Expanders | 

	Gil Cohen, 

	Gal Maor</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/163"/>
    <id>https://eccc.weizmann.ac.il/report/2022/163</id>
    <updated>2022-11-20T09:05:18+00:00</updated>
    <content type="html" xml:lang="en">
    Random walks on expanders are a powerful tool which found applications in many areas of theoretical computer science, and beyond. However, they come with an inherent cost -- the spectral expansion of the corresponding power graph deteriorates at a rate that is exponential in the length of the walk. As an example, when $G$ is a $d$-regular Ramanujan graph, the power graph $G^t$ has spectral expansion $2^{\Omega(t)} \sqrt{D}$, where $D = d^t$ is the regularity of $G^t$, thus, $G^t$ is $2^{\Omega(t)}$ away from being Ramanujan. This exponential blowup manifests itself in many applications.

In this work we bypass this barrier by permuting the vertices of the given graph after each random step. We prove that there exists a sequence of permutations for which the spectral expansion deteriorates by only a linear factor in $t$. In the Ramanujan case this yields an expansion of $O(t \sqrt{D})$. We stress that the permutations are tailor-made to the graph at hand and require no randomness to generate.

Our proof, which holds for all sufficiently high girth graphs, makes heavy use of the powerful framework of finite free probability and interlacing families that was developed in a seminal sequence of works by Marcus, Spielman and Srivastava.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Decentralized Thoughts: On PBFT from Locked Broadcast</title>
    <link href="https://decentralizedthoughts.github.io/2022-11-20-pbft-via-locked-braodcast/"/>
    <id>https://decentralizedthoughts.github.io/2022-11-20-pbft-via-locked-braodcast/</id>
    <updated>2022-11-20T09:00:00+00:00</updated>
    <content type="html" xml:lang="en">
    We describe a variation of the authenticated version of PBFT using Locked Broadcast that follows a similar path as our previous post on Paxos using Recoverable Broadcast. I call this protocol linear PBFT and variants of it are used by SBFT and Tusk. A later post will show how to...
  </content>
    <author>
      <name>Decentralized Thoughts</name>
      <uri>https://decentralizedthoughts.github.io</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-162 |  Directed Isoperimetric Theorems for Boolean Functions on the Hypergrid and an $\widetilde{O}(n\sqrt{d})$ Monotonicity Tester | 

	Hadley Black, 

	Deeparnab Chakrabarty, 

	C. Seshadhri</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/162"/>
    <id>https://eccc.weizmann.ac.il/report/2022/162</id>
    <updated>2022-11-20T05:41:10+00:00</updated>
    <content type="html" xml:lang="en">
    The problem of testing monotonicity for Boolean functions on the hypergrid, $f:[n]^d \to \{0,1\}$ is a classic topic in property testing. When $n=2$, the domain is the hypercube. For the hypercube case, a breakthrough result of Khot-Minzer-Safra (FOCS 2015) gave a non-adaptive, one-sided tester making $\widetilde{O}(\varepsilon^{-2}\sqrt{d})$ queries. Up to polylog $d$ and $\varepsilon$ factors, this bound matches the $\widetilde{\Omega}(\sqrt{d})$-query non-adaptive lower bound (Chen-De-Servedio-Tan (STOC 2015), Chen-Waingarten-Xie (STOC 2017)). For any $n &amp;gt; 2$, the optimal non-adaptive complexity was unknown. A previous result of the authors achieves a $\widetilde{O}(d^{5/6})$-query upper bound (SODA 2020), quite far from the $\sqrt{d}$ bound for the hypercube.

In this paper, we resolve the non-adaptive complexity of monotonicity testing for all constant $n$, up to $\text{poly}(\varepsilon^{-1}\log d)$ factors. Specifically, we give a non-adaptive, one-sided monotonicity tester making $\widetilde{O}(\varepsilon^{-2}n\sqrt{d})$ queries. From a technical standpoint, we prove new directed isoperimetric theorems over the hypergrid $[n]^d$. These results generalize the celebrated directed Talagrand inequalities that were only known for the hypercube.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-161 |  Towards Multi-Pass Streaming Lower Bounds for Optimal Approximation of Max-Cut | 

	Raghuvansh Saxena, 

	Lijie Chen, 

	Gillat Kol, 

	Dmitry Paramonov, 

	Zhao Song, 

	Huacheng Yu</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/161"/>
    <id>https://eccc.weizmann.ac.il/report/2022/161</id>
    <updated>2022-11-20T05:39:49+00:00</updated>
    <content type="html" xml:lang="en">
    We consider the Max-Cut problem, asking how much space is needed by a streaming algorithm in order to estimate the value of the maximum cut in a graph. This problem has been extensively studied over the last decade, and we now have a near-optimal lower bound for one-pass streaming algorithms, showing that they require linear space to guarantee a better-than-$2$ approximation [KKS15, KK19]. The result relies on a lower bound for the cycle-finding problem, showing that it is hard for a one-pass streaming algorithm to find a cycle in a union of matchings.

The end-goal of our research is to prove a similar lower for multi-pass streaming algorithms that guarantee a better-than-$2$ approximation for Max-Cut, a highly challenging open problem. In this paper, we take a significant step in this direction, showing that even $o(\log n)$-pass streaming algorithms need $n^{\Omega(1)}$ space to solve the cycle-finding problem. Our proof is quite involved, dividing the cycles in the graph into &amp;quot;short&amp;quot; and &amp;quot;long&amp;quot; cycles, and using tailor-made lower bound techniques to handle each case.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-160 |  The Geometry of Rounding | 

	Jason Vander Woude, 

	Peter Dixon, 

	A.  Pavan, 

	Jamie Radcliffe, 

	N. V. Vinodchandran</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/160"/>
    <id>https://eccc.weizmann.ac.il/report/2022/160</id>
    <updated>2022-11-20T05:38:52+00:00</updated>
    <content type="html" xml:lang="en">
    Rounding has proven to be a fundamental tool in theoretical computer science. By observing that rounding and partitioning of $\mathbb{R}^d$ are equivalent, we introduce the following natural partition problem which we call the secluded hypercube partition problem: Given $k\in\mathbb{N}$ (ideally small) and $\epsilon&amp;gt;0$ (ideally large), is there a partition of $\mathbb{R}^d$ with unit hypercubes such that for every point $\vec{p} \in \mathbb{R}^d$, its closed $\epsilon$-neighborhood (in the $\ell_{\infty}$  norm) intersects at most $k$ hypercubes?

We undertake a comprehensive study of this partition problem. We prove that for every $d\in\mathbb{N}$, there is an explicit (and efficiently computable) hypercube partition of $\mathbb{R}^d$ with $k = d+1$ and $\epsilon = \frac{1}{2d}$. We complement this construction by proving that the value of $k=d+1$ is the best possible (for any $\epsilon$) for a broad class of &amp;quot;reasonable&amp;quot; partitions including hypercube partitions. We also investigate the optimality of the parameter $\epsilon$ and prove that any partition in this broad class that has $k=d+1$, must have $\epsilon\leq\frac{1}{2\sqrt{d}}$. These bounds imply limitations of certain deterministic rounding schemes existing in the literature. Furthermore, this general bound is based on the currently known lower bounds for the dissection number of the cube, and improvements to this bound will yield improvements to our bounds.

While our work is motivated by the desire to understand rounding algorithms, one of our main conceptual contributions is the introduction of the secluded hypercube partition problem, which fits well with a long history of investigations by mathematicians on various hypercube partitions/tilings of Euclidean  space.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Decentralized Thoughts: From Single-Shot Consensus to State Machine Replication</title>
    <link href="https://decentralizedthoughts.github.io/2022-11-19-from-single-shot-to-smr/"/>
    <id>https://decentralizedthoughts.github.io/2022-11-19-from-single-shot-to-smr/</id>
    <updated>2022-11-19T09:00:00+00:00</updated>
    <content type="html" xml:lang="en">
    In this post we explore the path from Single-Shot Consensus, via Write-Once Registers, to Log Replication, and finally to State Machine Replication. We begin by defining all four problems assuming minority omission failures and partial synchrony. This post continues our previous post on Paxos from Recoverable Broadcast. (Single-Shot) Consensus In...
  </content>
    <author>
      <name>Decentralized Thoughts</name>
      <uri>https://decentralizedthoughts.github.io</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-159 |  Deep Neural Networks: The Missing Complexity Parameter | 

	Songhua He, 

	Periklis Papakonstantinou</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/159"/>
    <id>https://eccc.weizmann.ac.il/report/2022/159</id>
    <updated>2022-11-18T19:13:20+00:00</updated>
    <content type="html" xml:lang="en">
    Deep neural networks are the dominant machine learning model. We show that this model is missing a crucial complexity parameter. Today, the standard neural network (NN) model is a circuit whose gates (neurons) are ReLU units. The complexity of a NN is quantified by the depth (number of layers) and the size (number of neurons = depth times width). This work shows that this alone is insufficient, resulting in NNs with unreasonable computing power. We show that the correct way to talk about the size complexity of a NN is beside the number of neurons to consider the precision (or magnitude) of the weights of the ReLU units. The main message of this work is that if the precision of the weights is not considered in the complexity of the NN then one can engineer weights to &amp;quot;buy&amp;quot; exponentially many neurons for free. In summary, we make three theoretical contributions, potentially affecting many theoretical works on NNs.

1. Every function $f:\{0,1\}^n\to\{0,1\}$ can be computed with $O(\sqrt{2^n})$ many neurons and constant fan-in per neuron; i.e.~exponential times less than Shannon&amp;#39;s classic lower bound for usual combinatorial circuits. 

2. We give a new definition of circuit size that takes into account the precision/magnitude of the weights. Under this new definition of size we asymptotically match Shannon&amp;#39;s bound for NNs.

3. We complement the above results showing that P-uniform NNs decide exactly P.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-158 |  Query Complexity of Inversion Minimization on Trees | 

	Ivan Hu, 

	Dieter van Melkebeek, 

	Andrew Morgan</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/158"/>
    <id>https://eccc.weizmann.ac.il/report/2022/158</id>
    <updated>2022-11-18T15:57:57+00:00</updated>
    <content type="html" xml:lang="en">
    We consider the following computational problem: Given a rooted tree and a ranking of its leaves, what is the minimum number of inversions of the leaves that can be attained by ordering the tree? This variation of the well-known problem of counting inversions in arrays originated in mathematical psychology. It has the evaluation of the Mann-Whitney statistic for detecting differences between distributions as a special case. 

We study the complexity of the problem in the comparison-query model, the standard model for problems like sorting, selection, and heap construction. The complexity depends heavily on the shape of the tree: for trees of unit depth, the problem is trivial; for many other shapes, we establish lower bounds close to the strongest known in the model, namely the lower bound of $\log_2(n!)$ for sorting $n$ items. For trees with $n$ leaves we show, in increasing order of closeness to the sorting lower bound:
(a) $\log_2((\alpha(1-\alpha)n)!) - O(\log n)$ queries are needed whenever the tree has a subtree that contains a fraction $\alpha$ of the leaves. This implies a lower bound of $\log_2((\frac{k}{(k+1)^2}n)!) - O(\log n)$ for trees of degree $k$.
(b) $\log_2(n!) - O(\log n)$ queries are needed in case the tree is binary. 
(c) $\log_2(n!) - O(k \log k)$ queries are needed for certain classes of trees of degree $k$, including perfect trees with even $k$.

The lower bounds are obtained by developing two novel techniques for a generic problem $\Pi$ in the comparison-query model and applying them to inversion minimization on trees. Both techniques can be described in terms of the Cayley graph of the symmetric group with adjacent-rank transpositions as the generating set, or equivalently, in terms of the edge graph of the permutahedron, the polytope spanned by all permutations of the vector $(1,2,\dots,n)$. Consider the subgraph consisting of the edges between vertices with the same value under $\Pi$. We show that the size of any decision tree for $\Pi$ must be at least:
(i) the number of connected components of this subgraph, and
(ii) the factorial of the average degree of the complementary subgraph, divided by $n$.

Lower bounds on query complexity then follow by taking the base-2 logarithm. Technique (i) represents a discrete analog of a classical technique in algebraic complexity and allows us to establish (c) and a tight lower bound for counting cross inversions, as well as unify several of the known lower bounds in the comparison-query model. Technique (ii) represents an analog of sensitivity arguments in Boolean complexity and allows us to establish (a) and (b). 

Along the way to proving (b), we derive a tight upper bound on the maximum probability of the distribution of cross inversions, which is the distribution of the Mann-Whitney statistic in the case of the null hypothesis. Up to normalization the probabilities alternately appear in the literature as the coefficients of polynomials formed by the Gaussian binomial coefficients, also known as Gaussian polynomials.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Scott Aaronson: WINNERS of the Scott Aaronson Grant for Advanced Precollege STEM Education!</title>
    <link href="https://scottaaronson.blog/?p=6818"/>
    <id>https://scottaaronson.blog/?p=6818</id>
    <updated>2022-11-18T08:01:17+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;I&amp;#8217;m thrilled to be able to interrupt your regular depressing programming for 100% happy news.&lt;/p&gt;



&lt;p&gt;Some readers will remember that, back in September, I &lt;a href=&quot;https://scottaaronson.blog/?p=6678&quot;&gt;announced&lt;/a&gt; that an unnamed charitable foundation had asked my advice on how best to donate $250,000 for advanced precollege STEM education.  So, just like the &lt;a href=&quot;https://scottaaronson.blog/?p=6232&quot;&gt;previous time&lt;/a&gt; I got such a request, from Jaan Tallinn&amp;#8217;s &lt;a href=&quot;https://survivalandflourishing.fund/&quot;&gt;Survival and Flourishing Fund&lt;/a&gt;, I decided to do a call for proposals on &lt;em&gt;Shtetl-Optimized&lt;/em&gt; before passing along my recommendations.&lt;/p&gt;



&lt;p&gt;I can now reveal that the generous foundation, this time around, was the &lt;a href=&quot;https://www.packard.org/&quot;&gt;Packard Foundation&lt;/a&gt;.  Indeed, the idea and initial inquiries to me came directly from &lt;a href=&quot;https://www.packard.org/about-the-foundation/our-people/bio/david-orr/&quot;&gt;Dave Orr&lt;/a&gt;: the chair of the foundation, grandson of Hewlett-Packard cofounder &lt;a href=&quot;https://en.wikipedia.org/wiki/David_Packard&quot;&gt;David Packard&lt;/a&gt;, and (so I learned) longtime &lt;em&gt;Shtetl-Optimized&lt;/em&gt; reader.&lt;/p&gt;



&lt;p&gt;I can &lt;em&gt;also&lt;/em&gt; now reveal the results.  I was honored to get more than a dozen excellent applications.  After carefully considering all of them, I passed along four finalists to the Packard Foundation, which preferred to award the entire allotment to a single program if possible.  After more discussion and research, the Foundation then actually decided on &lt;em&gt;two&lt;/em&gt; winners:&lt;/p&gt;



&lt;ul&gt;
&lt;li&gt;$225,000 for general support to &lt;a href=&quot;https://promys.org/&quot;&gt;PROMYS&lt;/a&gt;: the long-running, world-renowned summer math camp for high-school students, which (among other things) is in the process of launching a new branch in India.  While I ended up at &lt;a href=&quot;https://www.mathcamp.org/&quot;&gt;Canada/USA Mathcamp&lt;/a&gt; (which I supported in my &lt;a href=&quot;https://scottaaronson.blog/?p=6256&quot;&gt;first grant round&lt;/a&gt;) rather than PROMYS, I knew all about and admired PROMYS even back when I was the right age to attend it.  I&amp;#8217;m thrilled to be able to play a small role in its expansion.&lt;/li&gt;
&lt;/ul&gt;



&lt;ul&gt;
&lt;li&gt;$30,000 for general support to &lt;a href=&quot;https://www.addiscoder.com/&quot;&gt;AddisCoder&lt;/a&gt;: the phenomenal program that introduces Ethiopian high-schoolers to programming and algorithms.  AddisCoder was founded by UC Berkeley theoretical computer science professor and longtime friend-of-the-blog &lt;a href=&quot;https://people.eecs.berkeley.edu/~minilek/&quot;&gt;Jelani Nelson&lt;/a&gt;, and &lt;em&gt;also&lt;/em&gt; received $30,000 in my &lt;a href=&quot;https://scottaaronson.blog/?p=6256&quot;&gt;first grant round&lt;/a&gt;.  Jelani and his co-organizers will be pressing ahead with AddisCoder despite political conflict in Ethiopia including a recently-concluded &lt;a href=&quot;https://en.wikipedia.org/wiki/Tigray_War&quot;&gt;civil war&lt;/a&gt;.  I&amp;#8217;m humbled if I can make even the tiniest difference.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Thanks so much to the Packard Foundation, and to Packard&amp;#8217;s talented program officers, directors, and associates&amp;#8212;especially Laura Sullivan, Jean Ries, and Prithi Trivedi&amp;#8212;for their hard work to make this happen.  Thanks so much also to everyone who applied.  While I wish we could&amp;#8217;ve funded everyone, I&amp;#8217;ve learned a lot about programs to which I&amp;#8217;d like to steer future support &lt;strong&gt;(other prospective benefactors: please email me!!)&lt;/strong&gt;, &lt;em&gt;and&lt;/em&gt; to which I&amp;#8217;d like to steer kids: my own, once they&amp;#8217;re old enough, and other kids of my acquaintance.&lt;/p&gt;



&lt;p&gt;I feel good that, in the tiny, underfunded world of accelerated STEM education, the $255,000 that Packard is donating will already make a difference.  But of course, $255,000 is only a thousandth of $255 million, which is a thousandth of $255 billion.  Perhaps I could earn the latter sort of sums, to donate to STEM education or any other cause, by (for example) starting my own cryptocurrency exchange.  I hope my readers will forgive me for not having chosen that route, expected-utility-maximization arguments be damned.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </content>
    <author>
      <name>Scott Aaronson</name>
      <uri>https://scottaaronson.blog</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Improved Monotonicity Testers via Hypercube Embeddings</title>
    <link href="http://arxiv.org/abs/2211.09229"/>
    <id>http://arxiv.org/abs/2211.09229</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braverman_M/0/1/0/all/0/1&quot;&gt;Mark Braverman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khot_S/0/1/0/all/0/1&quot;&gt;Subhash Khot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kindler_G/0/1/0/all/0/1&quot;&gt;Guy Kindler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minzer_D/0/1/0/all/0/1&quot;&gt;Dor Minzer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show improved monotonicity testers for the Boolean hypercube under the
$p$-biased measure, as well as over the hypergrid $[m]^n$. Our results are:
&lt;/p&gt;
&lt;p&gt;1. For any $p\in (0,1)$, for the $p$-biased hypercube we show a non-adaptive
tester that makes $\tilde{O}(\sqrt{n}/\varepsilon^2)$ queries, accepts monotone
functions with probability $1$ and rejects functions that are $\varepsilon$-far
from monotone with probability at least $2/3$.
&lt;/p&gt;
&lt;p&gt;2. For all $m\in\mathbb{N}$, we show an
$\tilde{O}(\sqrt{n}m^3/\varepsilon^2)$ query monotonicity tester over $[m]^n$.
&lt;/p&gt;
&lt;p&gt;We also establish corresponding directed isoperimetric inequalities in these
domains. Previously, the best known tester due to Black, Chakrabarty and
Seshadhri had $\Omega(n^{5/6})$ query complexity. Our results are optimal up to
poly-logarithmic factors and the dependency on $m$.
&lt;/p&gt;
&lt;p&gt;Our proof uses a notion of monotone embeddings of measures into the Boolean
hypercube that can be used to reduce the problem of monotonicity testing over
an arbitrary product domains to the Boolean cube. The embedding maps a function
over a product domain of dimension $n$ into a function over a Boolean cube of a
larger dimension $n&#39;$, while preserving its distance from being monotone; an
embedding is considered efficient if $n&#39;$ is not much larger than $n$, and we
show how to construct efficient embeddings in the above mentioned settings.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Approaching the Soundness Barrier: A Near Optimal Analysis of the Cube versus Cube Test</title>
    <link href="http://arxiv.org/abs/2211.09341"/>
    <id>http://arxiv.org/abs/2211.09341</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minzer_D/0/1/0/all/0/1&quot;&gt;Dor Minzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1&quot;&gt;Kai Zheng&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Cube versus Cube test is a variant of the well-known Plane versus Plane
test of Raz and Safra, in which to each $3$-dimensional affine subspace $C$ of
$\mathbb{F}_q^n$, a polynomial of degree at most $d$, $T(C)$, is assigned in a
somewhat locally consistent manner: taking two cubes $C_1, C_2$ that intersect
in a plane uniformly at random, the probability that $T(C_1)$ and $T(C_2)$
agree on $C_1\cap C_2$ is at least some $\epsilon$. An element of interest is
the soundness threshold of this test, i.e. the smallest value of $\epsilon$,
such that this amount of local consistency implies a global structure; namely,
that there is a global degree $d$ function $g$ such that $g|_{C} \equiv T(C)$
for at least $\Omega(\epsilon)$ fraction of the cubes.
&lt;/p&gt;
&lt;p&gt;We show that the cube versus cube low degree test has soundness ${\sf
poly}(d)/q$. This result achieves the optimal dependence on $q$ for soundness
in low degree testing and improves upon previous soundness results of ${\sf
poly}(d)/q^{1/2}$ due to Bhangale, Dinur and Navon.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Unique-Neighbor-Like Expansion and Group-Independent Cosystolic Expansion</title>
    <link href="http://arxiv.org/abs/2211.09482"/>
    <id>http://arxiv.org/abs/2211.09482</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaufman_T/0/1/0/all/0/1&quot;&gt;Tali Kaufman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mass_D/0/1/0/all/0/1&quot;&gt;David Mass&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In recent years, high dimensional expanders have been found to have a variety
of applications in theoretical computer science, such as efficient CSPs
approximations, improved sampling and list-decoding algorithms, and more.
Within that, an important high dimensional expansion notion is \emph{cosystolic
expansion}, which has found applications in the construction of efficiently
decodable quantum codes and in proving lower bounds for CSPs.
&lt;/p&gt;
&lt;p&gt;Cosystolic expansion is considered with systems of equations over a group
where the variables and equations correspond to faces of the complex. Previous
works that studied cosystolic expansion were tailored to the specific group
$\mathbb{F}_2$. In particular, Kaufman, Kazhdan and Lubotzky (FOCS 2014), and
Evra and Kaufman (STOC 2016) in their breakthrough works, who solved a famous
open question of Gromov, have studied a notion which we term ``parity&#39;&#39;
expansion for small sets. They showed that small sets of $k$-faces have
proportionally many $(k+1)$-faces that contain \emph{an odd number} of
$k$-faces from the set. Parity expansion for small sets could be used to imply
cosystolic expansion only over $\mathbb{F}_2$.
&lt;/p&gt;
&lt;p&gt;In this work we introduce a stronger \emph{unique-neighbor-like} expansion
for small sets. We show that small sets of $k$-faces have proportionally many
$(k+1)$-faces that contain \emph{exactly one} $k$-face from the set. This
notion is fundamentally stronger than parity expansion and cannot be implied by
previous works.
&lt;/p&gt;
&lt;p&gt;We then show, utilizing the new unique-neighbor-like expansion notion
introduced in this work, that cosystolic expansion can be made
\emph{group-independent}, i.e., unique-neighbor-like expansion for small sets
implies cosystolic expansion \emph{over any group}.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Double Balanced Sets in High Dimensional Expanders</title>
    <link href="http://arxiv.org/abs/2211.09485"/>
    <id>http://arxiv.org/abs/2211.09485</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaufman_T/0/1/0/all/0/1&quot;&gt;Tali Kaufman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mass_D/0/1/0/all/0/1&quot;&gt;David Mass&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Recent works have shown that expansion of pseudorandom sets is of great
importance. However, all current works on pseudorandom sets are limited only to
product (or approximate product) spaces, where Fourier Analysis methods could
be applied. In this work we ask the natural question whether pseudorandom sets
are relevant in domains where Fourier Analysis methods cannot be applied, e.g.,
one-sided local spectral expanders.
&lt;/p&gt;
&lt;p&gt;We take the first step in the path of answering this question. We put forward
a new definition for pseudorandom sets, which we call ``double balanced sets&#39;&#39;.
We demonstrate the strength of our new definition by showing that small double
balanced sets in one-sided local spectral expanders have very strong expansion
properties, such as unique-neighbor-like expansion. We further show that
cohomologies in cosystolic expanders are double balanced, and use the newly
derived strong expansion properties of double balanced sets in order to obtain
an exponential improvement over the current state of the art lower bound on
their minimal distance.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Cooperative 2D Reconfiguration using Spatio-Temporal Planning and Load Transferring</title>
    <link href="http://arxiv.org/abs/2211.09198"/>
    <id>http://arxiv.org/abs/2211.09198</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_J/0/1/0/all/0/1&quot;&gt;Javier Garcia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yannuzzi_M/0/1/0/all/0/1&quot;&gt;Michael Yannuzzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kramer_P/0/1/0/all/0/1&quot;&gt;Peter Kramer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rieck_C/0/1/0/all/0/1&quot;&gt;Christian Rieck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fekete_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe1;ndor P. Fekete&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Becker_A/0/1/0/all/0/1&quot;&gt;Aaron T. Becker&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present progress on the problem of reconfiguring a 2D arrangement of
building material by a cooperative set of robots. These robots are subjected to
the constraints of avoiding obstacles and maintaining connectivity of the
structure. We develop two reconfiguration methods, one based on spatio-temporal
planning, and one based on target swapping. Both methods achieve coordinated
motion of robots by avoiding deadlocks and maintaining all constraints. Both
methods also increase efficiency by reducing the amount of waiting times and
lowering combined travel costs. The resulting progress is validated by
simulations that also scale the number of robots.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Covering and packing with homothets of limited capacity</title>
    <link href="http://arxiv.org/abs/2211.09328"/>
    <id>http://arxiv.org/abs/2211.09328</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pi_O/0/1/0/all/0/1&quot;&gt;Oriol Sol&amp;#xe9; Pi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This work revolves around the two following questions: Given a convex body
$C\subset\mathbb{R}^d$, a positive integer $k$ and a finite set
$S\subset\mathbb{R}^d$ (or a finite $\mu$ Borel measure in $\mathbb{R}^d$), how
many homothets of $C$ are required to cover $S$ if no homothet is allowed to
cover more than $k$ points of $S$ (or have measure more than $k$)? how many
homothets of $C$ can be packed if each of them must cover at least $k$ points
of $S$ (or have measure at least $k$)? We prove that, so long as $S$ is not too
degenerate, the answer to both questions is $\Theta_d(\frac{|S|}{k})$, where
the hidden constant is independent of $d$, this is clearly best possible up to
a multiplicative constant. Analogous results hold in the case of measures. Then
we introduce a generalization of the standard covering and packing densities of
a convex body $C$ to Borel measure spaces in $\mathbb{R}^d$ and, using the
aforementioned bounds, we show that they are bounded from above and below,
respectively, by functions of $d$. As an intermediate result, we give a simple
proof the existence of weak $\epsilon$-nets of size $O(\frac{1}{\epsilon})$ for
the range space induced by all homothets of $C$. Following some recent work in
discrete geometry, we investigate the case $d=k=2$ in greater detail. We also
provide polynomial time algorithms for constructing a packing/covering
exhibiting the $\Theta_d(\frac{|S|}{k})$ bound mentioned above in the case that
$C$ is an Euclidean ball. Finally, it is shown that if $C$ is a square then it
is NP-hard to decide whether $S$ can be covered by $\frac{|S|}{4}$ squares
containing $4$ points each.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Rounding via Low Dimensional Embeddings</title>
    <link href="http://arxiv.org/abs/2211.09729"/>
    <id>http://arxiv.org/abs/2211.09729</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braverman_M/0/1/0/all/0/1&quot;&gt;Mark Braverman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minzer_D/0/1/0/all/0/1&quot;&gt;Dor Minzer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A regular graph $G = (V,E)$ is an $(\varepsilon,\gamma)$ small-set expander
if for any set of vertices of fractional size at most $\varepsilon$, at least
$\gamma$ of the edges that are adjacent to it go outside. In this paper, we
give a unified approach to several known complexity-theoretic results on
small-set expanders. In particular, we show:
&lt;/p&gt;
&lt;p&gt;1. Max-Cut: we show that if a regular graph $G = (V,E)$ is an
$(\varepsilon,\gamma)$ small-set expander that contains a cut of fractional
size at least $1-\delta$, then one can find in $G$ a cut of fractional size at
least $1-O\left(\frac{\delta}{\varepsilon\gamma^6}\right)$ in polynomial time.
&lt;/p&gt;
&lt;p&gt;2. Improved spectral partitioning, Cheeger&#39;s inequality and the parallel
repetition theorem over small-set expanders. The general form of each one of
these results involves square-root loss that comes from certain rounding
procedure, and we show how this can be avoided over small set expanders.
&lt;/p&gt;
&lt;p&gt;Our main idea is to project a high dimensional vector solution into a
low-dimensional space while roughly maintaining $\ell_2^2$ distances, and then
perform a pre-processing step using low-dimensional geometry and the properties
of $\ell_2^2$ distances over it. This pre-processing leverages the small-set
expansion property of the graph to transform a vector valued solution to a
different vector valued solution with additional structural properties, which
give rise to more efficient integral-solution rounding schemes.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: (Re)packing Equal Disks into Rectangle</title>
    <link href="http://arxiv.org/abs/2211.09603"/>
    <id>http://arxiv.org/abs/2211.09603</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fomin_F/0/1/0/all/0/1&quot;&gt;Fedor V. Fomin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golovach_P/0/1/0/all/0/1&quot;&gt;Petr A. Golovach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inamdar_T/0/1/0/all/0/1&quot;&gt;Tanmay Inamdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1&quot;&gt;Saket Saurabh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zehavi_M/0/1/0/all/0/1&quot;&gt;Meirav Zehavi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The problem of packing of equal disks (or circles) into a rectangle is a
fundamental geometric problem. (By a packing here we mean an arrangement of
disks in a rectangle without overlapping.) We consider the following
algorithmic generalization of the equal disk packing problem. In this problem,
for a given packing of equal disks into a rectangle, the question is whether by
changing positions of a small number of disks, we can allocate space for
packing more disks. More formally, in the repacking problem, for a given set of
$n$ equal disks packed into a rectangle and integers $k$ and $h$, we ask
whether it is possible by changing positions of at most $h$ disks to pack $n+k$
disks. Thus the problem of packing equal disks is the special case of our
problem with $n=h=0$.
&lt;/p&gt;
&lt;p&gt;While the computational complexity of packing equal disks into a rectangle
remains open, we prove that the repacking problem is NP-hard already for $h=0$.
Our main algorithmic contribution is an algorithm that solves the repacking
problem in time $(h+k)^{O(h+k)}\cdot |I|^{O(1)}$, where $I$ is the input size.
That is, the problem is fixed-parameter tractable parameterized by $k$ and $h$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On the complexity of implementing Trotter steps</title>
    <link href="http://arxiv.org/abs/2211.09133"/>
    <id>http://arxiv.org/abs/2211.09133</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Low_G/0/1/0/all/0/1&quot;&gt;Guang Hao Low&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Su_Y/0/1/0/all/0/1&quot;&gt;Yuan Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Tong_Y/0/1/0/all/0/1&quot;&gt;Yu Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Tran_M/0/1/0/all/0/1&quot;&gt;Minh C. Tran&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Quantum dynamics can be simulated on a quantum computer by exponentiating
elementary terms from the Hamiltonian in a sequential manner. However, such an
implementation of Trotter steps has gate complexity depending on the total
Hamiltonian term number, comparing unfavorably to algorithms using more
advanced techniques. We develop methods to perform faster Trotter steps with
complexity sublinear in the number of terms. We achieve this for a class of
Hamiltonians whose interaction strength decays with distance according to power
law. Our methods include one based on a recursive block encoding and one based
on an average-cost simulation, overcoming the normalization-factor barrier of
these advanced quantum simulation techniques. We also realize faster Trotter
steps when certain blocks of Hamiltonian coefficients have low rank. Combining
with a tighter error analysis, we show that it suffices to use
$\left(\eta^{1/3}n^{1/3}+\frac{n^{2/3}}{\eta^{2/3}}\right)n^{1+o(1)}$ gates to
simulate uniform electron gas with $n$ spin orbitals and $\eta$ electrons in
second quantization in real space, asymptotically improving over the best
previous work. We obtain an analogous result when the external potential of
nuclei is introduced under the Born-Oppenheimer approximation. We prove a
circuit lower bound when the Hamiltonian coefficients take a continuum range of
values, showing that generic $n$-qubit $2$-local Hamiltonians with commuting
terms require at least $\Omega(n^2)$ gates to evolve with accuracy
$\epsilon=\Omega(1/poly(n))$ for time $t=\Omega(\epsilon)$. Our proof is based
on a gate-efficient reduction from the approximate synthesis of diagonal
unitaries within the Hamming weight-$2$ subspace, which may be of independent
interest. Our result thus suggests the use of Hamiltonian structural properties
as both necessary and sufficient to implement Trotter steps with lower gate
complexity.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On the Power of Learning-Augmented BSTs</title>
    <link href="http://arxiv.org/abs/2211.09251"/>
    <id>http://arxiv.org/abs/2211.09251</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jingbang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Li Chen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present the first Learning-Augmented Binary Search Tree(BST) that attains
Static Optimality and Working-Set Bound given rough predictions. Following the
recent studies in algorithms with predictions and learned index structures,
Lin, Luo, and Woodruff (ICML 2022) introduced the concept of Learning-Augmented
BSTs, which aim to improve BSTs with learned advice. Unfortunately, their
construction gives only static optimality under strong assumptions on the
input.
&lt;/p&gt;
&lt;p&gt;In this paper, we present a simple BST maintenance scheme that benefits from
learned advice. With proper predictions, the scheme achieves Static Optimality
and Working-Set Bound, respectively, which are important performance measures
for BSTs. Moreover, the scheme is robust to prediction errors and makes no
assumption on the input.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Near-Optimal Distributed Computation of Small Vertex Cuts</title>
    <link href="http://arxiv.org/abs/2211.09415"/>
    <id>http://arxiv.org/abs/2211.09415</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parter_M/0/1/0/all/0/1&quot;&gt;Merav Parter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petruschka_A/0/1/0/all/0/1&quot;&gt;Asaf Petruschka&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present near-optimal algorithms for detecting small vertex cuts in the
CONGEST model of distributed computing. Despite extensive research in this
area, our understanding of the vertex connectivity of a graph is still
incomplete, especially in the distributed setting. To this date, all
distributed algorithms for detecting cut vertices suffer from an inherent
dependency in the maximum degree of the graph, $\Delta$. Hence, in particular,
there is no truly sub-linear time algorithm for this problem, not even for
detecting a single cut vertex. We take a new algorithmic approach for vertex
connectivity which allows us to bypass the existing $\Delta$ barrier. As a
warm-up to our approach, we show a simple $\widetilde{O}(D)$-round randomized
algorithm for computing all cut vertices in a $D$-diameter $n$-vertex graph.
This improves upon the $O(D+\Delta/\log n)$-round algorithm of [Pritchard and
Thurimella, ICALP 2008]. Our key technical contribution is an
$\widetilde{O}(D)$-round randomized algorithm for computing all cut pairs in
the graph, improving upon the state-of-the-art $O(\Delta \cdot D)^4$-round
algorithm by [Parter, DISC &#39;19]. Note that even for the considerably simpler
setting of edge cuts, currently $\widetilde{O}(D)$-round algorithms are known
only for detecting pairs of cut edges. Our approach is based on employing the
well-known linear graph sketching technique [Ahn, Guha and McGregor, SODA 2012]
along with the heavy-light tree decomposition of [Sleator and Tarjan, STOC
1981]. Combining this with a careful characterization of the survivable
subgraphs, allows us to determine the connectivity of $G \setminus \{x,y\}$ for
every pair $x,y \in V$, using $\widetilde{O}(D)$-rounds. We believe that the
tools provided in this paper are useful for omitting the $\Delta$-dependency
even for larger cut values.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Incremental Approximate Maximum Flow in $m^{1/2+o(1)}$ update time</title>
    <link href="http://arxiv.org/abs/2211.09606"/>
    <id>http://arxiv.org/abs/2211.09606</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goranci_G/0/1/0/all/0/1&quot;&gt;Gramoz Goranci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1&quot;&gt;Monika Henzinger&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show an $(1+\epsilon)$-approximation algorithm for maintaining maximum
$s$-$t$ flow under $m$ edge insertions in $m^{1/2+o(1)} \epsilon^{-1/2}$
amortized update time for directed, unweighted graphs. This constitutes the
first sublinear dynamic maximum flow algorithm in general sparse graphs with
arbitrarily good approximation guarantee.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A (simple) classical algorithm for estimating Betti numbers</title>
    <link href="http://arxiv.org/abs/2211.09618"/>
    <id>http://arxiv.org/abs/2211.09618</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Apers_S/0/1/0/all/0/1&quot;&gt;Simon Apers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1&quot;&gt;Sayantan Sen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szabo_D/0/1/0/all/0/1&quot;&gt;D&amp;#xe1;niel Szab&amp;#xf3;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We describe a simple algorithm for estimating the $k$-th normalized Betti
number of a simplicial complex over $n$ elements using the path integral Monte
Carlo method. For a general simplicial complex, the running time of our
algorithm is $n^{O(\frac{1}{\gamma}\log\frac{1}{\varepsilon})}$ with $\gamma$
measuring the spectral gap of the combinatorial Laplacian and $\varepsilon \in
(0,1)$ the additive precision. In the case of a clique complex, the running
time of our algorithm improves to
$(n/\lambda_{\max})^{O(\frac{1}{\gamma}\log\frac{1}{\varepsilon})}$ with
$\lambda_{\max} \geq k$ the maximum eigenvalue of the combinatorial Laplacian.
Our algorithm provides a classical benchmark for a line of quantum algorithms
for estimating Betti numbers, and it matches their running time on clique
complexes when the spectral gap is constant and $k \in \Omega(n)$ or
$\lambda_{\max} \in \Omega(n)$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Minimum Path Cover in Parameterized Linear Time</title>
    <link href="http://arxiv.org/abs/2211.09659"/>
    <id>http://arxiv.org/abs/2211.09659</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caceres_M/0/1/0/all/0/1&quot;&gt;Manuel Caceres&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cairo_M/0/1/0/all/0/1&quot;&gt;Massimo Cairo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mumey_B/0/1/0/all/0/1&quot;&gt;Brendan Mumey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rizzi_R/0/1/0/all/0/1&quot;&gt;Romeo Rizzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomescu_A/0/1/0/all/0/1&quot;&gt;Alexandru I. Tomescu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A minimum path cover (MPC) of a directed acyclic graph (DAG) $G = (V,E)$ is a
minimum-size set of paths that together cover all the vertices of the DAG.
Computing an MPC is a basic polynomial problem, dating back to Dilworth&#39;s and
Fulkerson&#39;s results in the 1950s. Since the size $k$ of an MPC (also known as
the width) can be small in practical applications, research has also studied
algorithms whose running time is parameterized on $k$.
&lt;/p&gt;
&lt;p&gt;We obtain a new MPC parameterized algorithm for DAGs running in time
$O(k^2|V| + |E|)$. Our algorithm is the first solving the problem in
parameterized linear time. Additionally, we obtain an edge sparsification
algorithm preserving the width of a DAG but reducing $|E|$ to less than $2|V|$.
This algorithm runs in time $O(k^2|V|)$ and requires an MPC of a DAG as input,
thus its total running time is the same as the running time of our MPC
algorithm.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Features for the 0-1 knapsack problem based on inclusionwise maximal solutions</title>
    <link href="http://arxiv.org/abs/2211.09665"/>
    <id>http://arxiv.org/abs/2211.09665</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jooken_J/0/1/0/all/0/1&quot;&gt;Jorik Jooken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leyman_P/0/1/0/all/0/1&quot;&gt;Pieter Leyman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Causmaecker_P/0/1/0/all/0/1&quot;&gt;Patrick De Causmaecker&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Decades of research on the 0-1 knapsack problem led to very efficient
algorithms that are able to quickly solve large problem instances to
optimality. This prompted researchers to also investigate whether relatively
small problem instances exist that are hard for existing solvers and
investigate which features characterize their hardness. Previously the authors
proposed a new class of hard 0-1 knapsack problem instances and demonstrated
that the properties of so-called inclusionwise maximal solutions (IMSs) can be
important hardness indicators for this class. In the current paper, we
formulate several new computationally challenging problems related to the IMSs
of arbitrary 0-1 knapsack problem instances. Based on generalizations of
previous work and new structural results about IMSs, we formulate polynomial
and pseudopolynomial time algorithms for solving these problems. From this we
derive a set of 14 computationally expensive features, which we calculate for
two large datasets on a supercomputer in approximately 540 CPU-hours. We show
that the proposed features contain important information related to the
empirical hardness of a problem instance that was missing in earlier features
from the literature by training machine learning models that can accurately
predict the empirical hardness of a wide variety of 0-1 knapsack problem
instances. Using the instance space analysis methodology, we also show that
hard 0-1 knapsack problem instances are clustered together around a relatively
dense region of the instance space and several features behave differently in
the easy and hard parts of the instance space.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Extensions of the $(p,q)$-Flexible-Graph-Connectivity model</title>
    <link href="http://arxiv.org/abs/2211.09747"/>
    <id>http://arxiv.org/abs/2211.09747</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_I/0/1/0/all/0/1&quot;&gt;Ishan Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheriyan_J/0/1/0/all/0/1&quot;&gt;Joseph Cheriyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grout_L/0/1/0/all/0/1&quot;&gt;Logan Grout&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibrahimpur_S/0/1/0/all/0/1&quot;&gt;Sharat Ibrahimpur&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present approximation algorithms for network design problems in some
models related to the $(p,q)$-FGC model. Adjiashvili, Hommelsheim and
M\&quot;uhlenthaler introduced the model of Flexible Graph Connectivity that we
denote by FGC. Boyd, Cheriyan, Haddadan and Ibrahimpur introduced a
generalization of FGC. Let $p\geq 1$ and $q\geq 0$ be integers. In an instance
of the $(p,q)$-Flexible Graph Connectivity problem, denoted $(p,q)$-FGC, we
have an undirected connected graph $G = (V,E)$, a partition of $E$ into a set
of safe edges and a set of unsafe edges, and nonnegative costs
$c\in\mathbb{R}_{\geq0}^E$ on the edges. A subset $F \subseteq E$ of edges is
feasible for the $(p,q)$-FGC problem if for any set of unsafe edges, $F&#39;$, with
$|F&#39;|\leq q$, the subgraph $(V, F \setminus F&#39;)$ is $p$-edge connected. The
algorithmic goal is to find a feasible edge-set $F$ that minimizes $c(F) =
\sum_{e \in F} c_e$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Cheeger Inequalities for Directed Graphs and Hypergraphs Using Reweighted Eigenvalues</title>
    <link href="http://arxiv.org/abs/2211.09776"/>
    <id>http://arxiv.org/abs/2211.09776</id>
    <updated>2022-11-18T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lau_L/0/1/0/all/0/1&quot;&gt;Lap Chi Lau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tung_K/0/1/0/all/0/1&quot;&gt;Kam Chuen Tung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Robert Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We derive Cheeger inequalities for directed graphs and hypergraphs using the
reweighted eigenvalue approach that was recently developed for vertex expansion
in undirected graphs [OZ22,KLT22,JPV22]. The goal is to develop a new spectral
theory for directed graphs and an alternative spectral theory for hypergraphs.
&lt;/p&gt;
&lt;p&gt;The first main result is a Cheeger inequality relating the vertex expansion
$\vec{\psi}(G)$ of a directed graph $G$ to the vertex-capacitated maximum
reweighted second eigenvalue $\vec{\lambda}_2^{v*}$: \[ \vec{\lambda}_2^{v*}
\lesssim \vec{\psi}(G) \lesssim \sqrt{\vec{\lambda}_2^{v*} \cdot \log
(\Delta/\vec{\lambda}_2^{v*})}. \] This provides a combinatorial
characterization of the fastest mixing time of a directed graph by vertex
expansion, and builds a new connection between reweighted eigenvalued, vertex
expansion, and fastest mixing time for directed graphs.
&lt;/p&gt;
&lt;p&gt;The second main result is a stronger Cheeger inequality relating the edge
conductance $\vec{\phi}(G)$ of a directed graph $G$ to the edge-capacitated
maximum reweighted second eigenvalue $\vec{\lambda}_2^{e*}$: \[
\vec{\lambda}_2^{e*} \lesssim \vec{\phi}(G) \lesssim \sqrt{\vec{\lambda}_2^{e*}
\cdot \log (1/\vec{\lambda}_2^{e*})}. \] This provides a certificate for a
directed graph to be an expander and a spectral algorithm to find a sparse cut
in a directed graph, playing a similar role as Cheeger&#39;s inequality in
certifying graph expansion and in the spectral partitioning algorithm for
undirected graphs.
&lt;/p&gt;
&lt;p&gt;We also use this reweighted eigenvalue approach to derive the improved
Cheeger inequality for directed graphs, and furthermore to derive several
Cheeger inequalities for hypergraphs that match and improve the existing
results in [Lou15,CLTZ18]. These are supporting results that this provides a
unifying approach to lift the spectral theory for undirected graphs to more
general settings.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Gil Kalai: Amazing: Justin Gilmer gave a constant lower bound for the union-closed sets conjecture</title>
    <link href="https://gilkalai.wordpress.com/2022/11/17/amazing-justin-gilmer-gave-a-constant-lower-bound-for-the-union-closed-sets-conjecture/"/>
    <id>http://gilkalai.wordpress.com/?p=23540</id>
    <updated>2022-11-17T20:47:56+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Frankl&amp;#8217;s conjecture (aka the union closed sets conjecture) asserts that if &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ccal+F&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ccal+F&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ccal+F&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;cal F&quot; class=&quot;latex&quot; /&gt; is a family of subsets of [n] (=: &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cn+%5C%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cn+%5C%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cn+%5C%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;{1,2,&amp;#92;dots,n &amp;#92;}&quot; class=&quot;latex&quot; /&gt;) which is closed under union then there is an element &lt;img src=&quot;https://s0.wp.com/latex.php?latex=k&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=k&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;k&quot; class=&quot;latex&quot; /&gt; such that&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7C%5C%7BS+%5Cin+%7B%5Ccal+F%7D%3A+k+%5Cin+S%5C%7D%7C+%5Cge+%5Cfrac+%7B1%7D%7B2%7D%7C%7B%5Ccal+F%7D%7C.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%7C%5C%7BS+%5Cin+%7B%5Ccal+F%7D%3A+k+%5Cin+S%5C%7D%7C+%5Cge+%5Cfrac+%7B1%7D%7B2%7D%7C%7B%5Ccal+F%7D%7C.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7C%5C%7BS+%5Cin+%7B%5Ccal+F%7D%3A+k+%5Cin+S%5C%7D%7C+%5Cge+%5Cfrac+%7B1%7D%7B2%7D%7C%7B%5Ccal+F%7D%7C.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;|&amp;#92;{S &amp;#92;in {&amp;#92;cal F}: k &amp;#92;in S&amp;#92;}| &amp;#92;ge &amp;#92;frac {1}{2}|{&amp;#92;cal F}|.&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Justin Gilmer just proved an amazing weaker form of the conjecture asserting that there always exists an element &lt;img src=&quot;https://s0.wp.com/latex.php?latex=k&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=k&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;k&quot; class=&quot;latex&quot; /&gt; such that&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7C%5C%7BS+%5Cin+%7B%5Ccal+F%7D%3A+k+%5Cin+S%5C%7D%7C+%5Cge%C2%A0+0.01+%7C%7B%5Ccal+F%7D%7C.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%7C%5C%7BS+%5Cin+%7B%5Ccal+F%7D%3A+k+%5Cin+S%5C%7D%7C+%5Cge%C2%A0+0.01+%7C%7B%5Ccal+F%7D%7C.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7C%5C%7BS+%5Cin+%7B%5Ccal+F%7D%3A+k+%5Cin+S%5C%7D%7C+%5Cge%C2%A0+0.01+%7C%7B%5Ccal+F%7D%7C.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;|&amp;#92;{S &amp;#92;in {&amp;#92;cal F}: k &amp;#92;in S&amp;#92;}| &amp;#92;ge  0.01 |{&amp;#92;cal F}|.&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p&gt;This is am amazing progress! Congratulations, Justin.&lt;/p&gt;
&lt;p&gt;The breakthrough paper, just posted on the arXiv is:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2211.09055&quot;&gt;A constant lower bound for the union-closed sets conjecture&lt;/a&gt; by Justin Gilmer&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; We show that for any union-closed family  &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D+%5Csubseteq+2%5E%7B%5Bn%5D%7D%2C+%5Cmathcal%7BF%7D+%5Cneq+%5C%7B%5Cemptyset%5C%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D+%5Csubseteq+2%5E%7B%5Bn%5D%7D%2C+%5Cmathcal%7BF%7D+%5Cneq+%5C%7B%5Cemptyset%5C%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D+%5Csubseteq+2%5E%7B%5Bn%5D%7D%2C+%5Cmathcal%7BF%7D+%5Cneq+%5C%7B%5Cemptyset%5C%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;mathcal{F} &amp;#92;subseteq 2^{[n]}, &amp;#92;mathcal{F} &amp;#92;neq &amp;#92;{&amp;#92;emptyset&amp;#92;}&quot; class=&quot;latex&quot; /&gt; there exists an &lt;img src=&quot;https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;i &amp;#92;in [n]&quot; class=&quot;latex&quot; /&gt;  which is contained in a &lt;span id=&quot;MathJax-Element-3-Frame&quot; class=&quot;MathJax&quot;&gt;&lt;span id=&quot;MathJax-Span-29&quot; class=&quot;math&quot;&gt;&lt;span id=&quot;MathJax-Span-30&quot; class=&quot;mrow&quot;&gt;&lt;span id=&quot;MathJax-Span-31&quot; class=&quot;mn&quot;&gt;0.01&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; fraction of the sets in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmathcal+F&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmathcal+F&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal+F&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;mathcal F&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;This is the first known constant lower bound, and improves upon the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog_2%28%5Cmathcal%7BF%7D%7C%29%5E%7B-1%7D%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog_2%28%5Cmathcal%7BF%7D%7C%29%5E%7B-1%7D%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog_2%28%5Cmathcal%7BF%7D%7C%29%5E%7B-1%7D%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;Omega(&amp;#92;log_2(&amp;#92;mathcal{F}|)^{-1})&quot; class=&quot;latex&quot; /&gt; bounds of Knill and Wójick.&lt;/p&gt;
&lt;p&gt;Our result follows from an information theoretic strengthening of the conjecture. Specifically, we show that if &lt;img src=&quot;https://s0.wp.com/latex.php?latex=A%2CB&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=A%2CB&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%2CB&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;A,B&quot; class=&quot;latex&quot; /&gt; are independent samples from a distribution over subsets of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;[n]&quot; class=&quot;latex&quot; /&gt;  such that &lt;img src=&quot;https://s0.wp.com/latex.php?latex=Pr%5Bi+%5Cin+A%5D+%3C+0.01&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=Pr%5Bi+%5Cin+A%5D+%3C+0.01&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Pr%5Bi+%5Cin+A%5D+%3C+0.01&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;Pr[i &amp;#92;in A] &amp;lt; 0.01&quot; class=&quot;latex&quot; /&gt; for all &lt;span id=&quot;MathJax-Element-9-Frame&quot; class=&quot;MathJax&quot;&gt;&lt;span id=&quot;MathJax-Span-83&quot; class=&quot;math&quot;&gt;&lt;span id=&quot;MathJax-Span-84&quot; class=&quot;mrow&quot;&gt;&lt;span id=&quot;MathJax-Span-85&quot; class=&quot;mi&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=i&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=i&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;i&quot; class=&quot;latex&quot; /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and &lt;img src=&quot;https://s0.wp.com/latex.php?latex=H%28A%29%3E0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=H%28A%29%3E0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28A%29%3E0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;H(A)&amp;gt;0&quot; class=&quot;latex&quot; /&gt;, then &lt;img src=&quot;https://s0.wp.com/latex.php?latex=H%28A+%5Ccup+B%29%3E+H%28A%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=H%28A+%5Ccup+B%29%3E+H%28A%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28A+%5Ccup+B%29%3E+H%28A%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;H(A &amp;#92;cup B)&amp;gt; H(A)&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;______&lt;/p&gt;
&lt;p&gt;Mike Saks who first told me about the breakthrough wrote &amp;#8220;the bound comes from a simple clever idea (using information theory) and 5 pages of gentle technical calculations.&amp;#8221; (I thank Mike, Ryan &lt;span class=&quot;gI&quot;&gt;&lt;span class=&quot;qu&quot; role=&quot;gridcell&quot;&gt;&lt;span class=&quot;gD&quot;&gt;Alweiss, and Nati Linial who wrote me about it.) &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We mentioned Frankl&amp;#8217;s conjecture several times including &lt;a href=&quot;https://gilkalai.wordpress.com/2008/04/29/hello-world/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://gilkalai.wordpress.com/2017/12/26/ilam-karpas-frankls-conjecture-for-large-families/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://gilkalai.wordpress.com/2018/03/09/frankls-conjecture-for-large-families-ilan-karpas-proof/&quot;&gt;here&lt;/a&gt;, and &lt;a href=&quot;https://gilkalai.wordpress.com/2021/01/29/possible-future-polymath-projects-2009-2021/&quot;&gt;here&lt;/a&gt;. &lt;a href=&quot;https://gowers.wordpress.com/category/polymath11/&quot;&gt;Polymath11&lt;/a&gt; on Tim Gowers&amp;#8217;s blog was devoted to the conjecture. Below the fold: What it will take to prove the conjecture in its full strength and another beautiful conjecture by Peter Frankl.&lt;/p&gt;
&lt;p&gt;&lt;span id=&quot;more-23540&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;What is the limit of Gilmer&amp;#8217;s method and what it will take to prove the Frankl conjecture&lt;/h3&gt;
&lt;p&gt;Justin Gilmer&amp;#8217;s mentions that proving a tight bout for Lemma 1 in the paper will push the 0.01 bound to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cfrac%7B3-%5Csqrt+5%7D%7B2%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cfrac%7B3-%5Csqrt+5%7D%7B2%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac%7B3-%5Csqrt+5%7D%7B2%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;frac{3-&amp;#92;sqrt 5}{2}&quot; class=&quot;latex&quot; /&gt;=&lt;span id=&quot;cwos&quot; class=&quot;qv3Wpe&quot; dir=&quot;ltr&quot;&gt;0.381966&amp;#8230; . He also presents an appealing information-theoretic strengthening of the conjecture which may consist of a path toward a proof. &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;Another beautiful conjecture by Peter Frankl&lt;/h3&gt;
&lt;p&gt;To face a possible risk that Frankl&amp;#8217;s &amp;#8220;union closed&amp;#8221; conjecture will be solved here is another beautiful conjecture by Peter Frankl.&lt;/p&gt;
&lt;p&gt;A family of sets is convex if whenever &lt;img src=&quot;https://s0.wp.com/latex.php?latex=A+%5Csubset+B+%5Csubset+C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=A+%5Csubset+B+%5Csubset+C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A+%5Csubset+B+%5Csubset+C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;A &amp;#92;subset B &amp;#92;subset C&quot; class=&quot;latex&quot; /&gt; and &lt;img src=&quot;https://s0.wp.com/latex.php?latex=A%2CC+%5Cin+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=A%2CC+%5Cin+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%2CC+%5Cin+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;A,C &amp;#92;in {&amp;#92;cal F}&quot; class=&quot;latex&quot; /&gt; then also &lt;img src=&quot;https://s0.wp.com/latex.php?latex=B+%5Cin+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=B+%5Cin+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B+%5Cin+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;B &amp;#92;in {&amp;#92;cal F}&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;Conjecture (&lt;strong&gt;P. Frankl&lt;/strong&gt;):  Let &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;{&amp;#92;cal F}&quot; class=&quot;latex&quot; /&gt; be a convex family of subsets of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;[n]&quot; class=&quot;latex&quot; /&gt;. Then there exists an antichain &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Ccal+G%7D+%5Csubset+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%7B%5Ccal+G%7D+%5Csubset+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Ccal+G%7D+%5Csubset+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;{&amp;#92;cal G} &amp;#92;subset {&amp;#92;cal F}&quot; class=&quot;latex&quot; /&gt; such that&lt;/p&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7C%7B%5Ccal+G%7D%7C%2F%7C%7B%5Ccal+F%7D%7C+%5Cge+%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D%2F2%5En.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%7C%7B%5Ccal+G%7D%7C%2F%7C%7B%5Ccal+F%7D%7C+%5Cge+%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D%2F2%5En.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7C%7B%5Ccal+G%7D%7C%2F%7C%7B%5Ccal+F%7D%7C+%5Cge+%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D%2F2%5En.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;|{&amp;#92;cal G}|/|{&amp;#92;cal F}| &amp;#92;ge {{n} &amp;#92;choose {[n/2]}}/2^n.&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Gil Kalai&lt;/p&gt;
  </content>
    <author>
      <name>Gil Kalai</name>
      <uri>https://gilkalai.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: Fall Jobs Post 2022</title>
    <link href="http://blog.computationalcomplexity.org/2022/11/fall-jobs-post-2022.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-1774067265916943204</id>
    <updated>2022-11-17T14:44:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;In the fall I try to make my predictions on the faculty job market for the spring. The outlook this year is hazy as we have two forces pushing in opposite directions.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Most of the largest tech companies are having layoffs and hiring freezes amidst a recession, higher expenses and a drop in revenue from cloud and advertising. Meanwhile computing has never had a more exciting (or scary) year of advances, particularly in generative AI. I can&#39;t remember such a dichotomy in the past. In the downturn after the 2008 financial crisis computing wasn&#39;t particularly exciting as the cloud, smart phones and machine learning were then just nascent technologies.&lt;/p&gt;&lt;p&gt;We&#39;ll probably have more competition in the academic job market as many new PhDs may decide to look at academic positions because of limited opportunities in large tech companies. We might even see a reverse migration from industry to academia from those who now might see universities as a safe haven.&lt;/p&gt;&lt;p&gt;What about the students? Will they still come in droves driven by the excitement in computing or get scared off by the downturn in the tech industry. They shouldn&#39;t worry--the market should turn around by the time they graduate and even today there are plenty of tech jobs in smaller and midsize tech companies as well as companies that deal with data, which is pretty much every company.&lt;/p&gt;&lt;p&gt;But perception matters more than reality. If students do stay away that might reduce pressure to grow CS departments.&lt;/p&gt;&lt;p&gt;Onto my usual advice. Give yourself a good virtual face. Have a well-designed web page with access to all your job materials and papers. Maintain your Google Scholar page. Add yourself to the CRA&#39;s&amp;nbsp;&lt;a href=&quot;https://cra.org/cv-database/&quot;&gt;CV database&lt;/a&gt;. Find a way to stand out, perhaps a short video describing your research.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Best source for finding jobs are the ads from the&amp;nbsp;&lt;a href=&quot;https://cra.org/ads/&quot;&gt;CRA&lt;/a&gt;&amp;nbsp;and the&amp;nbsp;&lt;a href=&quot;https://jobs.acm.org/&quot;&gt;ACM&lt;/a&gt;. For theoretical computer science specific postdoc and faculty positions check out&amp;nbsp;&lt;a href=&quot;https://cstheory-jobs.org/&quot;&gt;TCS Jobs&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a href=&quot;http://dmatheorynet.blogspot.com/&quot;&gt;Theory Announcements&lt;/a&gt;. If you have jobs to announce, please post to the above and/or feel free to leave a comment on this post. Even if you don&#39;t see an ad for a specific school they may still be hiring, check out their website or email someone at the department. You&#39;ll never know if you don&#39;t ask.&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Senior Faculty Position at Williams College (apply by December 1, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/11/17/senior-faculty-position-at-williams-college-apply-by-december-1-2022/"/>
    <id>http://cstheory-jobs.org/2022/11/17/senior-faculty-position-at-williams-college-apply-by-december-1-2022/</id>
    <updated>2022-11-17T14:11:06+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The Department of Computer Science at Williams College invites applications for a tenured faculty position at the associate or full professor level beginning July 1, 2023. We welcome candidates from all areas of computer science who can contribute to the vibrancy of our academic community through their research, teaching, and service.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://apply.interfolio.com/111662&quot;&gt;https://apply.interfolio.com/111662&lt;/a&gt;&lt;br /&gt;
Email: cshiring@williams.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Postdocs at Max Planck Institute for Informatics (apply by December 31, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/11/17/postdocs-at-max-planck-institute-for-informatics-apply-by-december-31-2022/"/>
    <id>http://cstheory-jobs.org/2022/11/17/postdocs-at-max-planck-institute-for-informatics-apply-by-december-31-2022/</id>
    <updated>2022-11-17T13:29:17+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;We are looking for applicants from all areas of algorithms and complexity, including related areas like mathematical optimization, distributed computing, and algorithms engineering. Postdoctoral fellowships are available at the algorithms and complexity department for two years through the Guest Program of our institute.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;http://www.mpi-inf.mpg.de/d1postdoc&quot;&gt;http://www.mpi-inf.mpg.de/d1postdoc&lt;/a&gt;&lt;br /&gt;
Email: d1office@mpi-inf.mpg.de&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Postdoc position in algorithms at University of Warwick (apply by December 6, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/11/17/postdoc-position-in-algorithms-at-university-of-warwick-apply-by-december-6-2022/"/>
    <id>http://cstheory-jobs.org/2022/11/17/postdoc-position-in-algorithms-at-university-of-warwick-apply-by-december-6-2022/</id>
    <updated>2022-11-17T08:54:03+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;In connection with a research grant of Dr. Ramanujan Sridharan and Prof. Graham Cormode at University of Warwick, UK, we are seeking excellent candidates for a postdoctoral fellow position in the area of design and analysis of parameterized and approximation algorithms.&lt;br /&gt;
The position is for 18 months and start date can be negotiated (preferably by March 2023).&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://tinyurl.com/ksz8rjfa&quot;&gt;https://tinyurl.com/ksz8rjfa&lt;/a&gt;&lt;br /&gt;
Email: r.maadapuzhi-sridharan@warwick.ac.uk&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Scott Aaronson: Sneerers</title>
    <link href="https://scottaaronson.blog/?p=6813"/>
    <id>https://scottaaronson.blog/?p=6813</id>
    <updated>2022-11-17T01:48:08+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;In the past few weeks, I&amp;#8217;ve learned two ways to think about online sneerers that have been helping me tremendously, and that I wanted to share in case they&amp;#8217;re helpful to others:&lt;/p&gt;



&lt;p&gt;First, they&amp;#8217;re like a train in a movie that&amp;#8217;s barreling directly towards the camera. If you haven&amp;#8217;t yet internalized how the medium works, absolutely terrifying! Run from the theater! If you &lt;em&gt;have&lt;/em&gt; internalized it, though, you can sit and watch without even flinching.&lt;/p&gt;



&lt;p&gt;Second, the sneerers are like alligators&amp;#8212;and about as likely to be moved by your appeals to reason and empathy. But if, like me, you&amp;#8217;re lucky enough to have a loving family, friends, colleagues, and a nigh-uncancellable career, then it&amp;#8217;s as though you&amp;#8217;re standing on a bridge high above, looking down at the gators as they snap their jaws at you uselessly. There&amp;#8217;s &lt;em&gt;really&lt;/em&gt; no moral or intellectual obligation to go down to the swamp to wrestle them.  If they mean to attack you, let them at least come up to the bridge.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </content>
    <author>
      <name>Scott Aaronson</name>
      <uri>https://scottaaronson.blog</uri>
    </author>
  </entry>


</feed>
