<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Theory of Computing Report</title>
  <link rel="self" href=""/>
  <link href=""/>
  <id></id>
  <updated></updated>
  <generator uri="http://feedreader.github.io/">Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]</generator>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-130 |  A Borsuk-Ulam lower bound for sign-rank and its application | 

	Hamed Hatami, 

	Kaave Hosseini, 

	Xiang Meng</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/130"/>
    <id>https://eccc.weizmann.ac.il/report/2022/130</id>
    <updated>2022-09-16T02:54:31+00:00</updated>
    <content type="html" xml:lang="en">
    We introduce a new topological argument based on the Borsuk-Ulam theorem to prove a lower bound on sign-rank.  

      This result implies the strongest possible separation between randomized and unbounded-error communication complexity. More precisely, we show that for a particular range of parameters, the randomized communication complexity of the Gap Hamming Distance problem is $O(1)$ while its unbounded-error communication complexity is  $\Omega(\log(n))$. 
     
 Previously, it was unknown whether the unbounded-error communication complexity could be asymptotically larger than the randomized communication complexity.
    
In connection to learning theory, we prove that,  despite its learnability properties, the class of large margin half-spaces in $\mathbb{R}^d$ is genuinely high-dimensional, i.e., it cannot be embedded in $\mathbb{R}^{d-1}$. This result is closely related to a recent conjecture of Alon, Hanneke, Holzman, and Moran (FOCS 2021) about the VC dimension of this class.
    
Our final application is to the theory of dimension reductions. The Johnson-Lindenstrauss theorem implies that any set of $N$ unit vectors is embeddable in dimension  $O(\gamma^{-2}\log N)$ without altering the signs of those pairwise inner products that have absolute values at least $\gamma&amp;gt;0$.  Our result establishes the tightness of this bound, which answers a question of Linial, Mendelson, Schechtman, and Shraibman (Combinatorica, 27(2007)) in the case of partial functions.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: How Much Structure Is Needed for Huge Quantum Speedups?</title>
    <link href="http://arxiv.org/abs/2209.06930"/>
    <id>http://arxiv.org/abs/2209.06930</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Aaronson_S/0/1/0/all/0/1&quot;&gt;Scott Aaronson&lt;/a&gt;&lt;/p&gt;&lt;p&gt;I survey, for a general scientific audience, three decades of research into
which sorts of problems admit exponential speedups via quantum computers --
from the classics (like the algorithms of Simon and Shor), to the breakthrough
of Yamakawa and Zhandry from April 2022. I discuss both the quantum circuit
model, which is what we ultimately care about in practice but where our
knowledge is radically incomplete, and the so-called oracle or black-box or
query complexity model, where we&#39;ve managed to achieve a much more thorough
understanding that then informs our conjectures about the circuit model. I
discuss the strengths and weaknesses of switching attention to sampling tasks,
as was done in the recent quantum supremacy experiments. I make some skeptical
remarks about widely-repeated claims of exponential quantum speedups for
practical machine learning and optimization problems. Through many examples, I
try to convey the &quot;law of conservation of weirdness,&quot; according to which every
problem admitting an exponential quantum speedup must have some unusual
property to allow the amplitude to be concentrated on the unknown right
answer(s).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: The Complexity Classes of Hamming Distance Recoverable Robust Problems</title>
    <link href="http://arxiv.org/abs/2209.06939"/>
    <id>http://arxiv.org/abs/2209.06939</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grune_C/0/1/0/all/0/1&quot;&gt;Christoph Gr&amp;#xfc;ne&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the well-known complexity class NP, many combinatorial problems can be
found, whose optimization counterpart are important for many practical
settings. Those problems usually consider full knowledge about the input and
optimize on this specific input. In a practical setting, however, uncertainty
in the input data is a usual phenomenon, whereby this is normally not covered
in optimization versions of NP problems. One concept to model the uncertainty
in the input data, is \textit{recoverable robustness}. In this setting, a
solution on the input is calculated, whereby a possible recovery to a good
solution should be guaranteed, whenever uncertainty manifests itself. That is,
a solution $\texttt{s}_0$ for the base scenario $\textsf{S}_0$ as well as a
solution \texttt{s} for every possible scenario of scenario set \textsf{S} has
to be calculated. In other words, not only solution $\texttt{s}_0$ for instance
$\textsf{S}_0$ is calculated but solutions \texttt{s} for all scenarios from
\textsf{S} are prepared to correct possible errors through uncertainty. This
paper introduces a specific concept of recoverable robust problems: Hamming
Distance Recoverable Robust Problems. In this setting, solutions $\texttt{s}_0$
and \texttt{s} have to be calculated, such that $\texttt{s}_0$ and \texttt{s}
may only differ in at most $\kappa$ elements. That is, one can recover from a
harmful scenario by choosing a different solution, which is not too far away
from the first solution. This paper surveys the complexity of Hamming distance
recoverable robust version of optimization problems, typically found in NP for
different types of scenarios. The complexity is primarily situated in the lower
levels of the polynomial hierarchy. The main contribution of the paper is that
recoverable robust problems with compression-encoded scenarios and $m \in
\mathbb{N}$ recoveries are $\Sigma^P_{2m+1}$-complete.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: On Power Set Axiom</title>
    <link href="http://arxiv.org/abs/2209.07497"/>
    <id>http://arxiv.org/abs/2209.07497</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levin_L/0/1/0/all/0/1&quot;&gt;Leonid A. Levin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Usual math sets have special types: countable, compact, open, occasionally
Borel, rarely projective, etc. Generic sets dependent on Power Set axiom appear
mostly in esoteric areas, ST logic, etc. Dropping that Axiom may greatly
simplify the foundations of mainstream math. Meanwhile dependence on it of a
theorem is worth noting, as dependence on Choice often is.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Stochastic strategies for patrolling a terrain with a synchronized multi-robot system</title>
    <link href="http://arxiv.org/abs/2209.06968"/>
    <id>http://arxiv.org/abs/2209.06968</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caraballo_L/0/1/0/all/0/1&quot;&gt;Luis E. Caraballo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; M. D&amp;#xed;az-B&amp;#xe1;&amp;#xf1;ez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fabila_Monroy_R/0/1/0/all/0/1&quot;&gt;Ruy Fabila-Monroy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hidalgo_Toscan_C/0/1/0/all/0/1&quot;&gt;Carlos Hidalgo-Toscan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A group of cooperative aerial robots can be deployed to efficiently patrol a
terrain, in which each robot flies around an assigned area and shares
information with the neighbors periodically in order to protect or supervise
it. To ensure robustness, previous works on these synchronized systems propose
sending a robot to the neighboring area in case it detects a failure. In order
to deal with unpredictability and to improve on the efficiency in the
deterministic patrolling scheme, this paper proposes random strategies to cover
the areas distributed among the agents. First, a theoretical study of the
stochastic process is addressed in this paper for two metrics: the \emph{idle
time}, the expected time between two consecutive observations of any point of
the terrain and the \emph{isolation time}, the expected time that a robot is
without communication with any other robot. After that, the random strategies
are experimentally compared with the deterministic strategy adding another
metric: the \emph{broadcast time}, the expected time elapsed from the moment a
robot emits a message until it is received by all the other robots of the team.
The simulations show that theoretical results are in good agreement with the
simulations and the random strategies outperform the behavior obtained with the
deterministic protocol proposed in the literature.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Spectral Total-Variation Processing of Shapes -- Theory and Applications</title>
    <link href="http://arxiv.org/abs/2209.07517"/>
    <id>http://arxiv.org/abs/2209.07517</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brokman_J/0/1/0/all/0/1&quot;&gt;Jonathan Brokman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burger_M/0/1/0/all/0/1&quot;&gt;Martin Burger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilboa_G/0/1/0/all/0/1&quot;&gt;Guy Gilboa&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work we present a comprehensive analysis of total variation (TV) on
non Euclidean domains and its eigenfunctions. We specifically address
parameterized surfaces, a natural representation of the shapes used in 3D
graphics. Our work sheds new light on the celebrated Beltrami and Anisotropic
TV flows, and explains experimental findings from recent years on shape
spectral TV [Fumero et al. 2020] and adaptive anisotropic spectral TV [Biton
and Gilboa 2022]. A new notion of convexity on manifolds is derived, by
characterizing structures that are stable throughout the TV flow, performed on
manifolds. We further propose a time efficient nonlinear and non Euclidean
spectral framework for shape processing that is based on zero homogeneous
flows, and propose three different such methods. Each method satisfies distinct
characteristics, demonstrated through smoothing, enhancing and exaggerating
filters.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Multiway Powersort</title>
    <link href="http://arxiv.org/abs/2209.06909"/>
    <id>http://arxiv.org/abs/2209.06909</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gelling_W/0/1/0/all/0/1&quot;&gt;William Cawley Gelling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nebel_M/0/1/0/all/0/1&quot;&gt;Markus E. Nebel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_B/0/1/0/all/0/1&quot;&gt;Benjamin Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wild_S/0/1/0/all/0/1&quot;&gt;Sebastian Wild&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Powersort (Munro &amp;amp; Wild, ESA2018) has recently replaced Timsort&#39;s suboptimal
merge policy in the CPython reference implementation of Python, as well as in
PyPy and further libraries. We present a stable mergesort variant, Multiway
Powersort, that exploits existing runs and finds nearly-optimal merging orders
for k-way merges with negligible overhead. As observed with Multiway Quicksort
(Kushagra et al., ALENEX 2014; Aum\&quot;uller &amp;amp; Dietzfelbinger, TALG 2016; Wild,
PhD thesis 2016) and the inclusion of Dual-Pivot Quicksort in the Java runtime
library, memory transfers increasingly determine the cost of internal sorting.
We demonstrate that our 4-way Powersort implementation can achieve substantial
speedups over standard (2-way) Powersort and other stable sorting methods
without compromising the optimally run-adaptive performance of Powersort.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Algorithms and Lower Bounds for Replacement Paths under Multiple Edge Failures</title>
    <link href="http://arxiv.org/abs/2209.07016"/>
    <id>http://arxiv.org/abs/2209.07016</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williams_V/0/1/0/all/0/1&quot;&gt;Virginia Vassilevska Williams&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woldeghebriel_E/0/1/0/all/0/1&quot;&gt;Eyob Woldeghebriel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yinzhan Xu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper considers a natural fault-tolerant shortest paths problem: for
some constant integer $f$, given a directed weighted graph with no negative
cycles and two fixed vertices $s$ and $t$, compute (either explicitly or
implicitly) for every tuple of $f$ edges, the distance from $s$ to $t$ if these
edges fail. We call this problem $f$-Fault Replacement Paths ($f$FRP).
&lt;/p&gt;
&lt;p&gt;We first present an $\tilde{O}(n^3)$ time algorithm for $2$FRP in $n$-vertex
directed graphs with arbitrary edge weights and no negative cycles. As $2$FRP
is a generalization of the well-studied Replacement Paths problem (RP) that
asks for the distances between $s$ and $t$ for any single edge failure, $2$FRP
is at least as hard as RP. Since RP in graphs with arbitrary weights is
equivalent in a fine-grained sense to All-Pairs Shortest Paths (APSP)
[Vassilevska Williams and Williams FOCS&#39;10, J.~ACM&#39;18], $2$FRP is at least as
hard as APSP, and thus a substantially subcubic time algorithm in the number of
vertices for $2$FRP would be a breakthrough. Therefore, our algorithm in
$\tilde{O}(n^3)$ time is conditionally nearly optimal. Our algorithm implies an
$\tilde{O}(n^{f+1})$ time algorithm for the $f$FRP problem, giving the first
improvement over the straightforward $O(n^{f+2})$ time algorithm.
&lt;/p&gt;
&lt;p&gt;Then we focus on the restriction of $2$FRP to graphs with small integer
weights bounded by $M$ in absolute values. Using fast rectangular matrix
multiplication, we obtain a randomized algorithm that runs in
$\tilde{O}(M^{2/3}n^{2.9153})$ time. This implies an improvement over our
$\tilde{O}(n^{f+1})$ time arbitrary weight algorithm for all $f&amp;gt;1$. We also
present a data structure variant of the algorithm that can trade off
pre-processing and query time. In addition to the algebraic algorithms, we also
give an $n^{8/3-o(1)}$ conditional lower bound for combinatorial $2$FRP
algorithms in directed unweighted graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Almost Ramanujan Expanders from Arbitrary Expanders via Operator Amplification</title>
    <link href="http://arxiv.org/abs/2209.07024"/>
    <id>http://arxiv.org/abs/2209.07024</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeronimo_F/0/1/0/all/0/1&quot;&gt;Fernando Granha Jeronimo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mittal_T/0/1/0/all/0/1&quot;&gt;Tushant Mittal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Sourya Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wigderson_A/0/1/0/all/0/1&quot;&gt;Avi Wigderson&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We give an efficient algorithm that transforms any bounded degree expander
graph into another that achieves almost optimal (namely, near-quadratic, $d
\leq 1/\lambda^{2+o(1)}$) trade-off between (any desired) spectral expansion
$\lambda$ and degree $d$. Furthermore, the algorithm is local: every vertex can
compute its new neighbors as a subset of its original neighborhood of radius
$O(\log(1/\lambda))$. The optimal quadratic trade-off is known as the Ramanujan
bound, so our construction gives almost Ramanujan expanders from arbitrary
expanders.
&lt;/p&gt;
&lt;p&gt;The locality of the transformation preserves structural properties of the
original graph, and thus has many consequences. Applied to Cayley graphs, our
transformation shows that any expanding finite group has almost Ramanujan
expanding generators. Similarly, one can obtain almost optimal explicit
constructions of quantum expanders, dimension expanders, monotone expanders,
etc., from existing (suboptimal) constructions of such objects. Another
consequence is a &quot;derandomized&quot; random walk on the original (suboptimal)
expander with almost optimal convergence rate. Our transformation also applies
when the degree is not bounded or the expansion is not constant.
&lt;/p&gt;
&lt;p&gt;We obtain our results by a generalization of Ta-Shma&#39;s technique in his
breakthrough paper [STOC 2017], used to obtain explicit almost optimal binary
codes. Specifically, our spectral amplification extends Ta-Shma&#39;s analysis of
bias amplification from scalars to matrices of arbitrary dimension in a very
natural way. Curiously, while Ta-Shma&#39;s explicit bias amplification
derandomizes a well-known probabilistic argument (underlying the
Gilbert--Varshamov bound), there seems to be no known probabilistic (or other
existential) way of achieving our explicit (&quot;high-dimensional&quot;) spectral
amplification.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Concurrent Size</title>
    <link href="http://arxiv.org/abs/2209.07100"/>
    <id>http://arxiv.org/abs/2209.07100</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sela_G/0/1/0/all/0/1&quot;&gt;Gal Sela&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petrank_E/0/1/0/all/0/1&quot;&gt;Erez Petrank&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The size of a data structure (i.e., the number of elements in it) is a widely
used property of a data set. However, for concurrent programs, obtaining a
correct size efficiently is non-trivial. In fact, the literature does not offer
a mechanism to obtain a correct (linearizable) size of a concurrent data set
without resorting to inefficient solutions, such as taking a full snapshot of
the data structure to count the elements, or acquiring one global lock in all
update and size operations. This paper presents a methodology for adding a
concurrent linearizable size operation to sets and dictionaries with a
relatively low performance overhead. Theoretically, the proposed size operation
is wait-free with asymptotic complexity linear in the number of threads
(independently of data-structure size). Practically, we evaluated the
performance overhead by adding size to various concurrent data structures in
Java$-$a skip list, a hash table and a tree. The proposed linearizable size
operation executes faster by orders of magnitude compared to the existing
option of taking a snapshot, while incurring a throughput loss of $1\%-20\%$ on
the original data structure&#39;s operations.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Multicalibrated Regression for Downstream Fairness</title>
    <link href="http://arxiv.org/abs/2209.07312"/>
    <id>http://arxiv.org/abs/2209.07312</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Globus_Harris_I/0/1/0/all/0/1&quot;&gt;Ira Globus-Harris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1&quot;&gt;Varun Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_C/0/1/0/all/0/1&quot;&gt;Christopher Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kearns_M/0/1/0/all/0/1&quot;&gt;Michael Kearns&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morgenstern_J/0/1/0/all/0/1&quot;&gt;Jamie Morgenstern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1&quot;&gt;Aaron Roth&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show how to take a regression function $\hat{f}$ that is appropriately
``multicalibrated&#39;&#39; and efficiently post-process it into an approximately error
minimizing classifier satisfying a large variety of fairness constraints. The
post-processing requires no labeled data, and only a modest amount of unlabeled
data and computation. The computational and sample complexity requirements of
computing $\hat f$ are comparable to the requirements for solving a single fair
learning task optimally, but it can in fact be used to solve many different
downstream fairness-constrained learning problems efficiently. Our
post-processing method easily handles intersecting groups, generalizing prior
work on post-processing regression functions to satisfy fairness constraints
that only applied to disjoint groups. Our work extends recent work showing that
multicalibrated regression functions are ``omnipredictors&#39;&#39; (i.e. can be
post-processed to optimally solve unconstrained ERM problems) to constrained
optimization.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Envy-freeness in 3D Hedonic Games</title>
    <link href="http://arxiv.org/abs/2209.07440"/>
    <id>http://arxiv.org/abs/2209.07440</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cseh_A/0/1/0/all/0/1&quot;&gt;&amp;#xc1;gnes Cseh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McKay_M/0/1/0/all/0/1&quot;&gt;Michael McKay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manlove_D/0/1/0/all/0/1&quot;&gt;David Manlove&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the problem of partitioning a set of agents into coalitions based on
the agents&#39; additively separable preferences, which can also be viewed as a
hedonic game. We apply three successively weaker solution concepts, namely
envy-freeness, weakly justified envy-freeness, and justified envy-freeness.
&lt;/p&gt;
&lt;p&gt;In a model in which coalitions may have any size, trivial solutions exist for
these concepts, which provides a strong motivation for placing restrictions on
coalition size. In this paper, we require feasible coalitions to have size
three. We study the existence of partitions that are envy-free, weakly
justified envy-free, and justified envy-free, and the computational complexity
of finding such partitions, if they exist.
&lt;/p&gt;
&lt;p&gt;We present a comprehensive complexity classification, in terms of the
restrictions placed on the agents&#39; preferences. From this, we identify a
general trend that for the three successively weaker solution concepts,
existence and polynomial-time solvability hold under successively weaker
restrictions.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Omnipredictors for Constrained Optimization</title>
    <link href="http://arxiv.org/abs/2209.07463"/>
    <id>http://arxiv.org/abs/2209.07463</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1&quot;&gt;Lunjia Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Livni_Navon_I/0/1/0/all/0/1&quot;&gt;Inbal Livni-Navon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reingold_O/0/1/0/all/0/1&quot;&gt;Omer Reingold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chutong Yang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The notion of omnipredictors (Gopalan, Kalai, Reingold, Sharan and Wieder
ITCS 2021), suggested a new paradigm for loss minimization. Rather than
learning a predictor based on a known loss function, omnipredictors can easily
be post-processed to minimize any one of a rich family of loss functions
compared with the loss of a class $C$. It has been shown that such
omnipredictors exist and are implied (for all convex and Lipschitz loss
functions) by the notion of multicalibration from the algorithmic fairness
literature. Nevertheless, it is often the case that the action selected must
obey some additional constraints (such as capacity or parity constraints). In
itself, the original notion of omnipredictors does not apply in this
well-motivated and heavily studied the context of constrained loss
minimization.
&lt;/p&gt;
&lt;p&gt;In this paper, we introduce omnipredictors for constrained optimization and
study their complexity and implications. The notion that we introduce allows
the learner to be unaware of the loss function that will be later assigned as
well as the constraints that will be later imposed, as long as the
subpopulations that are used to define these constraints are known.
&lt;/p&gt;
&lt;p&gt;The paper shows how to obtain omnipredictors for constrained optimization
problems, relying on appropriate variants of multicalibration. For some
interesting constraints and general loss functions and for general constraints
and some interesting loss functions, we show how omnipredictors are implied by
a variant of multicalibration that is similar in complexity to standard
multicalibration. We demonstrate that in the general case, standard
multicalibration is insufficient and show that omnipredictors are implied by
multicalibration with respect to a class containing all the level sets of
hypotheses in $C$. We also investigate the implications when the constraints
are group fairness notions.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On (Random-order) Online Contention Resolution Schemes for the Matching Polytope of (Bipartite) Graphs</title>
    <link href="http://arxiv.org/abs/2209.07520"/>
    <id>http://arxiv.org/abs/2209.07520</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+MacRury_C/0/1/0/all/0/1&quot;&gt;Calum MacRury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1&quot;&gt;Will Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grammel_N/0/1/0/all/0/1&quot;&gt;Nathaniel Grammel&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present new results for online contention resolution schemes for the
matching polytope of graphs, in the random-order (RCRS) and adversarial (OCRS)
arrival models. Our results include improved selectability guarantees (i.e.,
lower bounds), as well as new impossibility results (i.e., upper bounds). By
well-known reductions to the prophet (secretary) matching problem, a
$c$-selectable OCRS (RCRS) implies a $c$-competitive algorithm for adversarial
(random order) edge arrivals. Similar reductions are also known for the
query-commit matching problem. For the adversarial arrival model, we present a
new analysis of the OCRS of Ezra et al.~(EC, 2020). We show that this scheme is
$0.344$-selectable for general graphs and $0.349$-selectable for bipartite
graphs, improving on the previous $0.337$ selectability result for this
algorithm. We also show that the selectability of this scheme cannot be greater
than $0.361$ for general graphs and $0.382$ for bipartite graphs. We further
show that no OCRS can achieve a selectability greater than $0.4$ for general
graphs, and $0.433$ for bipartite graphs.
&lt;/p&gt;
&lt;p&gt;For random-order arrivals, we present two attenuation-based schemes which use
new attenuation functions. Our first RCRS is $0.474$-selectable for general
graphs, and our second is $0.476$-selectable for bipartite graphs. These
results improve upon the recent $0.45$ (and $0.456$) selectability results for
general graphs (respectively, bipartite graphs) due to Pollner et al.~(EC,
2022). On general graphs, our 0.474-selectable RCRS provides the best known
positive result even for offline contention resolution, and also for the
correlation gap. We conclude by proving a fundamental upper bound of 0.5 on the
selectability of RCRS, using bipartite graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: $\tilde{O}(n+\mathrm{poly}(k))$-time Algorithm for Bounded Tree Edit Distance</title>
    <link href="http://arxiv.org/abs/2209.07524"/>
    <id>http://arxiv.org/abs/2209.07524</id>
    <updated>2022-09-16T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1&quot;&gt;Debarati Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilbert_J/0/1/0/all/0/1&quot;&gt;Jacob Gilbert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajiaghayi_M/0/1/0/all/0/1&quot;&gt;MohammadTaghi Hajiaghayi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kociumaka_T/0/1/0/all/0/1&quot;&gt;Tomasz Kociumaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_B/0/1/0/all/0/1&quot;&gt;Barna Saha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saleh_H/0/1/0/all/0/1&quot;&gt;Hamed Saleh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Computing the edit distance of two strings is one of the most basic problems
in computer science and combinatorial optimization. Tree edit distance is a
natural generalization of edit distance in which the task is to compute a
measure of dissimilarity between two (unweighted) rooted trees with node
labels. Perhaps the most notable recent application of tree edit distance is in
NoSQL big databases, such as MongoDB, where each row of the database is a JSON
document represented as a labeled rooted tree, and finding dissimilarity
between two rows is a basic operation. Until recently, the fastest algorithm
for tree edit distance ran in cubic time (Demaine, Mozes, Rossman, Weimann;
TALG&#39;10); however, Mao (FOCS&#39;21) broke the cubic barrier for the tree edit
distance problem using fast matrix multiplication.
&lt;/p&gt;
&lt;p&gt;Given a parameter $k$ as an upper bound on the distance, an $O(n+k^2)$-time
algorithm for edit distance has been known since the 1980s due to the works of
Myers (Algorithmica&#39;86) and Landau and Vishkin (JCSS&#39;88). The existence of an
$\tilde{O}(n+\mathrm{poly}(k))$-time algorithm for tree edit distance has been
posed as an open question, e.g., by Akmal and Jin (ICALP&#39;21), who gave a
state-of-the-art $\tilde{O}(nk^2)$-time algorithm. In this paper, we answer
this question positively.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">David Eppstein: Linkage</title>
    <link href="https://11011110.github.io/blog/2022/09/15/linkage.html"/>
    <id>https://11011110.github.io/blog/2022/09/15/linkage</id>
    <updated>2022-09-15T22:36:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Lithophanes, a 19th-century art medium involving backlit translucent engravings, &lt;a href=&quot;https://arstechnica.com/science/2022/08/19th-century-art-form-revived-to-make-tactile-science-graphics-for-the-blind/&quot;&gt;revived via 3d printing as a single format for scientific images that blind people can read by feeling and sighted people can see&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108927524393418764&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://doi.org/10.1126/sciadv.abq2640&quot;&gt;original research paper&lt;/a&gt;).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A quick “not a Reuleaux triangle” link: &lt;a href=&quot;https://www.instructables.com/Lego-Triangle/&quot;&gt;Lego triangles&lt;/a&gt;, incorrectly embellished as &lt;a href=&quot;https://makezine.com/article/maker-news/lego-reuleaux-triangles/&quot;&gt;Lego Reuleaux triangles&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108933430914328377&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; The second link even goes on to say “I don’t think [they] are quite convex enough to be proper Reuleaux triangles”. And in this it’s correct, if “convex” is interpreted to mean “bulgy”. You can tell because the corners are right angles. Proper Reuleaux triangles would have \(120^\circ\) corners.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;As part of a search for real-world applications of combinatorial design theory, Jeremy Kun asks: “&lt;a href=&quot;https://mathstodon.xyz/@j2kun/108936354352902797&quot;&gt;What is the authoritative text on combinatorial designs, anyway?&lt;/a&gt;” I suspect that the shakeup in the area caused by Peter Keevash’s use of the probabilistic method has caused what used to be the authoritative texts to become obsolete.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://youtube.com/shorts/KYMYshbhKcw&quot;&gt;Squaring the circle illusion&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@henryseg/108940642070353471&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; Henry Segerman 3d-prints a shape that, when rotated \(180^\circ\), changes appearance from a circle to a square. With the same area in the viewing frame, even.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Finding a vertex-to-vertex and edge-to-edge mapping (“homomorphism”) from an input directed graph to a fixed oriented tree or cycle can be either polynomial-time or &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\mathsf{NP}\)-complete,&lt;/span&gt; depending on the target. But &lt;a href=&quot;https://cstheory.stackexchange.com/questions/33836/complexity-of-digraph-homomorphism-to-an-oriented-cycle&quot;&gt;the targets for which it is &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\mathsf{NP}\)-complete&lt;/span&gt; are surprisingly complicated!&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108950099488030475&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;)&lt;/span&gt;  &lt;a href=&quot;https://arxiv.org/abs/2205.07528&quot;&gt;A recent search&lt;/a&gt; found the smallest hard tree to have &lt;span style=&quot;white-space:nowrap&quot;&gt;\(20\) vertices,&lt;/span&gt; and the smallest hard cycle to &lt;span style=&quot;white-space:nowrap&quot;&gt;have \(26\).&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tamal Dey and Yusu Wang have a new graduate-level textbook on computational topology &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108953135639829468&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;):&lt;/span&gt; &lt;em&gt;&lt;a href=&quot;https://www.cs.purdue.edu/homes/tamaldey/book/CTDAbook/CTDAbook.pdf&quot;&gt;Computational Topology for Data Analysis&lt;/a&gt;&lt;/em&gt; (&lt;a href=&quot;https://doi.org/10.1017/9781009099950&quot;&gt;Cambridge University Press, 2022&lt;/a&gt;). &lt;a href=&quot;https://www.maa.org/press/maa-reviews/computational-topology-for-data-analysis&quot;&gt;Ellen Gasparovic reviews it for the MAA&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://web.archive.org/web/20220908210937/https://www.nytimes.com/interactive/2022/09/08/world/europe/succession-royal-family.html&quot;&gt;In case anyone else is looking for a topical real-world example of a depth-first traversal of a tree&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108965503136254522&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Chegg stops pretending not to have coursework-cheating as their main business; &lt;a href=&quot;https://www.chronicle.com/article/some-students-use-chegg-to-cheat-the-site-has-stopped-helping-colleges-catch-them&quot;&gt;will no longer cooperate with university cheating investigations&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108970379605304595&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.math.brown.edu/reschwar/PosterPappus/pappus.png&quot;&gt;Schwartz’s Pappus fractal&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108972366289751471&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;http://www.math.brown.edu/reschwar/PosterPappus/pappus.pdf&quot;&gt;explanation&lt;/a&gt;). Start with two separate lines of three points \(abc\) &lt;span style=&quot;white-space:nowrap&quot;&gt;and \(ABC\).&lt;/span&gt; By &lt;a href=&quot;https://en.wikipedia.org/wiki/Pappus%27s_hexagon_theorem&quot;&gt;Pappus’s theorem&lt;/a&gt; the diagonal crossing points &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\alpha=aB\cdot Ab\),&lt;/span&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\beta=aC\cdot Ac\),&lt;/span&gt; and \(\gamma=bC\cdot Bc\) form another line of three &lt;span style=&quot;white-space:nowrap&quot;&gt;points \(\alpha\beta\gamma\).&lt;/span&gt; Now recurse with \(abc\) &lt;span style=&quot;white-space:nowrap&quot;&gt;and \(\alpha\beta\gamma\),&lt;/span&gt; and again with \(\alpha\beta\gamma\) &lt;span style=&quot;white-space:nowrap&quot;&gt;and \(ABC\).&lt;/span&gt; You get a nice lightning-bolt fractal shape.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/html/2209.04402&quot;&gt;This year’s &lt;em&gt;Graph Drawing&lt;/em&gt; conference proceedings are online&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108982719390301261&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt;  As in past years, they’re using a system where the proceedings are published both on arXiv and in Springer LNCS.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://ris.utwente.nl/ws/portalfiles/portal/275927505/3e2a9e5b2fad237a3d35f36fa2c5f44552f2.pdf&quot;&gt;An analysis of online exam-proctoring tool Proctorio finds it completely ineffective at catching cheaters&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108984339518916646&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://news.ycombinator.com/item?id=32744976&quot;&gt;via&lt;/a&gt;). “The use of online proctoring is therefore best compared to taking a placebo: it has some positive influence, not because it works but because people believe that it works … policy makers would do well to balance the cost of deploying it (which can be
considerable) against the marginal benefits of this placebo effect.”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://langorigami.com/publication/paper-pentasia-an-aperiodic-surface-in-modular-origami/&quot;&gt;Lang’s paper pentasia&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108995556838713267&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; The kite and dart Penrose tiling lifts to a surface in 3d with two equilateral triangles per tile, overhanging for the darts. Robert Lang made these nice physical models. Explanations by &lt;a href=&quot;https://link.springer.com/article/10.1007/s00283-021-10088-4&quot;&gt;Barry Cipra on the 1993 discovery of this surface with Conway&lt;/a&gt; and &lt;a href=&quot;https://langorigami.com/wp-content/uploads/2015/09/paper-pentasia.pdf&quot;&gt;Lang and Barry Hayes, also on a related 3d surface for the rhombic Penrose tiling&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Three more new Wikipedia Good Articles &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108998160700266138&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;):&lt;/span&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Euclidean_minimum_spanning_tree&quot;&gt;Euclidean minimum spanning tree&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Doyle_spiral&quot;&gt;Doyle spiral&lt;/a&gt;, spiraling circle packings in which each circle is surrounded by a ring of six tangent circles&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Laves_graph&quot;&gt;Laves graph&lt;/a&gt;, a highly-symmetric 3-regular infinite graph in 3d&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;An algorithmic version of &lt;a href=&quot;en.wikipedia.org/wiki/Mantel&#39;s theorem&quot;&gt;Mantel’s theorem&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109004244575186009&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;):&lt;/span&gt; If an &lt;span style=&quot;white-space:nowrap&quot;&gt;\(n\)-vertex&lt;/span&gt; graph has more than &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\bigl\lfloor\tfrac{n^2}{4}\bigr\rfloor\) edges&lt;/span&gt; then we can find a triangle in it in linear time.&lt;/p&gt;

    &lt;p&gt;&lt;em&gt;Proof:&lt;/em&gt; Delete min-degree vertices, maintaining the edge excess, until the remaining \(k\) vertices all have &lt;span style=&quot;white-space:nowrap&quot;&gt;degree \(\ge\tfrac{k}{2}\).&lt;/span&gt; If &lt;span style=&quot;white-space:nowrap&quot;&gt;\(k\) is odd,&lt;/span&gt; all &lt;span style=&quot;white-space:nowrap&quot;&gt;have \(\ge \tfrac{k+1}{2}\);&lt;/span&gt; if &lt;span style=&quot;white-space:nowrap&quot;&gt;\(k\) is even,&lt;/span&gt; at least one &lt;span style=&quot;white-space:nowrap&quot;&gt;has \(\ge \tfrac{k}{2}+1\).&lt;/span&gt; Then a max-degree vertex and any neighbor have together &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\ge k+1\) incidences,&lt;/span&gt; so by the pigeonhole principle they have a common neighbor forming a &lt;span style=&quot;white-space:nowrap&quot;&gt;triangle. \(\Box\)&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;authors&quot;&gt;By David Eppstein&lt;/p&gt;
  </content>
    <author>
      <name>David Eppstein</name>
      <uri>https://11011110.github.io/blog/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: PostDoc at Technion faculty of Computer Science (Israel) (apply by October 31, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/09/15/postdoc-at-technion-faculty-of-computer-science-israel-apply-by-october-31-2022/"/>
    <id>http://cstheory-jobs.org/2022/09/15/postdoc-at-technion-faculty-of-computer-science-israel-apply-by-october-31-2022/</id>
    <updated>2022-09-15T21:13:46+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Looking for a PostDoc interested in the area of sublinear algorithms and property testing, for up to four years. PhD applications will also be considered.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://eldar.cswp.cs.technion.ac.il/positions/&quot;&gt;https://eldar.cswp.cs.technion.ac.il/positions/&lt;/a&gt;&lt;br /&gt;
Email: eldar@cs.technion.ac.il&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: Monarachy: A Problem with Definitions</title>
    <link href="http://blog.computationalcomplexity.org/2022/09/monarachy-problem-with-definitions.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-6674583717006469349</id>
    <updated>2022-09-15T20:41:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&amp;nbsp;As I am sure you know, Queen Elizabeth II passed away at the age of 96 recently.&amp;nbsp; I am not a royal-watcher, but I am a royal-watcher-watcher. That is, the question of why people care about the lives of these people intrigues me. A few notes&lt;/p&gt;&lt;p&gt;1) Was she a &lt;i&gt;good Queen?&lt;/i&gt; People tend to think so; however, since the job is somewhat ill-defined its hard to say.&amp;nbsp;&lt;/p&gt;&lt;p&gt;2) The Queen is supposed to be above politics (she does not vote- I was surprised to find out that legally she can, but she really can&#39;t). We know very few of Queen Elizabeth II&#39;s opinions on political events. But the notion of &lt;i&gt;political &lt;/i&gt;is not well defined. One would think that if she did an appeal for people to take the COVID vax that would not be political, but somehow it is (I do not know if she did such an appeal). King Charles III believes in global warming and that we need to do something about it. This again should not be political but is.&amp;nbsp;&lt;/p&gt;&lt;p&gt;3) She is the second longest reigning Monarch. First is King Louis XIV who first became king at the age of 4. I had a blog complaining about this&amp;nbsp;&lt;a href=&quot;https://blog.computationalcomplexity.org/2022/05/queen-elizabeth-is-3rd-longest-reigning.html&quot;&gt;here&lt;/a&gt;. However, there is a more interesting point I want to make. From the first to the last day of King Louis XIV reign not much had changed. Technology, politics, other things just didn&#39;t change much. By contrast the world changed A LOT between Queen Elizabeth II first and last day:&lt;/p&gt;&lt;p&gt;a) The British were an important power in 1952. Less so now.&lt;/p&gt;&lt;p&gt;b) When her father died she was in Kenya and it took 4 hours to get the news to her. Now that would be immediate.&amp;nbsp;&lt;/p&gt;&lt;p&gt;c) Divorce was considered bad in 1952 and is why King Edmond VIII could not be king (he wanted to marry a twice-divorced women whose ex-husbands were still alive). And now three of the Queen&#39;s children have been divorced.&lt;/p&gt;&lt;p&gt;d) Gay people.. enough said. There has even been a royal gay wedding, see&amp;nbsp;&lt;a href=&quot;https://www.dailymail.co.uk/news/article-5849971/Royal-familys-gay-wedding-story-Queens-cousin-Lord-Ivar-Mountbatten.html&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Black people (can&#39;t call them African-Americans), Women,... you fill it in.&amp;nbsp;&lt;/p&gt;&lt;p&gt;e) When Charles wanted to get married it seemed to be important that he marry a virgin. We cannot imagine this mentality anymore. When Prince William and Kate got married they were already living together and this was NOT an issue for ANYONE. I looked up what the Church of England thought of it and all I got was some very bland comments like &lt;i&gt;That&#39;s what young people do nowadays.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;3) Is the monarchy a good thing? As an American I feel I do not have a right to an opinion. If the citizens of the United Kingdom approve of the monarch (polls show they do) then who am I do tell them they are wrong? Even so, lets look at reasons for it&lt;/p&gt;&lt;p&gt;a) Tourism. It has been said that the Monarchy leads to MONEY from tourism. So it is worth the price? Nobody seems to know and it would be hard to tell. However, I don&#39;t think the citizens of the United Kingdom view&amp;nbsp; money as the reason for Monarchy. The American analog is giving Disneyland tax breaks to be in Florida which generates jobs. I doubt they think of the Monarchy in those mundane transactional terms.&amp;nbsp;&lt;/p&gt;&lt;p&gt;b) CS Lewis said&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Where men are forbidden to honour a king they honour millionaires, athletes, or film stars instead: even famous prostitutes and gangsters. For spiritual nature, like bodily nature, will be served; deny it food and it will gobble poison.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;This is&amp;nbsp; bit odd- they must all pretend to like the monarchy to make it work. A long time ago when Charles and Dianna were both having affairs, 80% of the citizens the United Kingdom thought that was okay so long as they are discrete so &lt;i&gt;the people&lt;/i&gt;&amp;nbsp;don&#39;t find out. But- those ARE the people.&lt;/p&gt;&lt;p&gt;Also odd- CS Lewis was a theologian and a&amp;nbsp; believing Christian; however, his comment above can apply to God as well as to Kings.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;br /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By gasarch&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-129 |  Binary Codes with Resilience Beyond 1/4 via Interaction | 

	Klim Efremenko, 

	Gillat Kol, 

	Raghuvansh Saxena, 

	Zhijun Zhang</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/129"/>
    <id>https://eccc.weizmann.ac.il/report/2022/129</id>
    <updated>2022-09-15T19:10:17+00:00</updated>
    <content type="html" xml:lang="en">
    In the reliable transmission problem, a sender, Alice, wishes to transmit a bit-string x to a remote receiver, Bob, over a binary channel with adversarial noise. The solution to this problem is to encode x using an error correcting code. As it is long known that the distance of binary codes is at most 1/2, reliable transmission is possible only if the channel corrupts (flips) at most a 1/4-fraction of the communicated bits.
We revisit the reliable transmission problem in the two-way setting, where both Alice and Bob can send bits to each other. Our main result is the construction of two-way error correcting codes that are resilient to a constant fraction of corruptions strictly larger than 1/4. Moreover, our code has constant rate and requires Bob to only send one short message. We mention that our result resolves an open problem by Haeupler, Kamath, and Velingker [APPROX-RANDOM, 2015] and by Gupta, Kalai, and Zhang [STOC, 2022].
Curiously, our new two-way code requires a fresh perspective on classical error correcting codes: While classical codes have only one distance guarantee for all pairs of codewords (i.e., the minimum distance), we construct codes where the distance between a pair of codewords depends on the “compatibility” of the messages they encode. We also prove that such codes are necessary for our result.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Structure and Complexity of Graphical Designs for Weighted Graphs through Eigenpolytopes</title>
    <link href="http://arxiv.org/abs/2209.06349"/>
    <id>http://arxiv.org/abs/2209.06349</id>
    <updated>2022-09-15T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Babecki_C/0/1/0/all/0/1&quot;&gt;Catherine Babecki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shiroma_D/0/1/0/all/0/1&quot;&gt;David Shiroma&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We extend the theory of graphical designs, which are quadrature rules for
graphs, to positively weighted graphs. Through Gale duality for polytopes, we
show that there is a bijection between graphical designs and the faces of
eigenpolytopes associated to the graph. This bijection proves the existence of
graphical designs with positive quadrature weights, and upper bounds the size
of a graphical design. We further show that any combinatorial polytope appears
as the eigenpolytope of a positively weighted graph. Through this universality,
we establish two complexity results for graphical designs: it is strongly
NP-complete to determine if there is a graphical design smaller than the
mentioned upper bound, and it is #P-complete to count the number of minimal
graphical designs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Red Blue Set Cover Problem on Axis-Parallel Hyperplanes and Other Objects</title>
    <link href="http://arxiv.org/abs/2209.06661"/>
    <id>http://arxiv.org/abs/2209.06661</id>
    <updated>2022-09-15T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abidha_V/0/1/0/all/0/1&quot;&gt;V P Abidha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashok_P/0/1/0/all/0/1&quot;&gt;Pradeesha Ashok&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a universe $\mathcal{U}=R \cup B$ of a finite set of red elements $R$,
and a finite set of blue elements $B$ and a family $\mathcal{F}$ of subsets of
$\mathcal{U}$, the \RBSC problem is to find a subset $\mathcal{F}&#39;$ of
$\mathcal{F}$ that covers all blue elements of $B$ and minimum number of red
elements from $R$.
&lt;/p&gt;
&lt;p&gt;We prove that the \RBSC problem is NP-hard even when $R$ and $B$ respectively
are sets of red and blue points in ${\rm I\!R}^2$ and the sets in $\mathcal{F}$
are defined by axis-parallel lines i.e, every set is a maximal set of points
with the same $x$ or $y$ coordinate.
&lt;/p&gt;
&lt;p&gt;We then study the parameterized complexity of a generalization of this
problem, where $\mathcal{U}$ is a set of points in ${\rm I\!R}^d$ and
$\mathcal{F}$ is a collection of set of axis-parallel hyperplanes in ${\rm
I\!R}^d$, under different parameterizations. For every parameter, we show that
the problem is fixed-parameter tractable and also show the existence of a
polynomial kernel.
&lt;/p&gt;
&lt;p&gt;We further consider the \RBSC problem for some special types of rectangles in
${\rm I\!R}^2$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Scheduling Algorithms for Federated Learning with Minimal Energy Consumption</title>
    <link href="http://arxiv.org/abs/2209.06210"/>
    <id>http://arxiv.org/abs/2209.06210</id>
    <updated>2022-09-15T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilla_L/0/1/0/all/0/1&quot;&gt;La&amp;#xe9;rcio Lima Pilla&lt;/a&gt; (STORM)&lt;/p&gt;&lt;p&gt;Federated Learning (FL) has opened the opportunity for collaboratively
training machine learning models on heterogeneous mobile or Edge devices while
keeping local data private.With an increase in its adoption, a growing concern
is related to its economic and environmental cost (as is also the case for
other machine learning techniques).Unfortunately, little work has been done to
optimize its energy consumption or emissions of carbon dioxide or equivalents,
as energy minimization is usually left as a secondary objective.In this paper,
we investigate the problem of minimizing the energy consumption of FL training
on heterogeneous devices by controlling the workload distribution.We model this
as the Minimal Cost FL Schedule problem, a total cost minimization problem with
identical, independent, and atomic tasks that have to be assigned to
heterogeneous resources with arbitrary cost functions.We propose a
pseudo-polynomial optimal solution to the problem based on the previously
unexplored Multiple-Choice Minimum-Cost Maximal Knapsack Packing Problem.We
also provide four algorithms for scenarios where cost functions are
monotonically increasing and follow the same behavior.These solutions are
likewise applicable on the minimization of other kinds of costs, and in other
one-dimensional data partition problems.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Algorithmic (Semi-)Conjugacy via Koopman Operator Theory</title>
    <link href="http://arxiv.org/abs/2209.06374"/>
    <id>http://arxiv.org/abs/2209.06374</id>
    <updated>2022-09-15T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Redman_W/0/1/0/all/0/1&quot;&gt;William T. Redman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fonoberova_M/0/1/0/all/0/1&quot;&gt;Maria Fonoberova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohr_R/0/1/0/all/0/1&quot;&gt;Ryan Mohr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kevrekidis_I/0/1/0/all/0/1&quot;&gt;Ioannis G. Kevrekidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mezic_I/0/1/0/all/0/1&quot;&gt;Igor Mezi&amp;#x107;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Iterative algorithms are of utmost importance in decision and control. With
an ever growing number of algorithms being developed, distributed, and
proprietarized, there is a similarly growing need for methods that can provide
classification and comparison. By viewing iterative algorithms as discrete-time
dynamical systems, we leverage Koopman operator theory to identify
(semi-)conjugacies between algorithms using their spectral properties. This
provides a general framework with which to classify and compare algorithms.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Performance Evaluation of Parallel Algorithms</title>
    <link href="http://arxiv.org/abs/2209.06450"/>
    <id>http://arxiv.org/abs/2209.06450</id>
    <updated>2022-09-15T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anireh_D/0/1/0/all/0/1&quot;&gt;Donald Ene Vincent Ike Anireh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Evaluating how well a whole system or set of subsystems performs is one of
the primary objectives of performance testing. We can tell via performance
assessment if the architecture implementation meets the design objectives.
Performance evaluations of several parallel algorithms are compared in this
study. Both theoretical and experimental methods are used in performance
assessment as a subdiscipline in computer science. The parallel method
outperforms its sequential counterpart in terms of throughput. The parallel
algorithm&#39;s performance (speedup) is examined, as shown in the result.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Parameterized algorithms for node connectivity augmentation problems</title>
    <link href="http://arxiv.org/abs/2209.06695"/>
    <id>http://arxiv.org/abs/2209.06695</id>
    <updated>2022-09-15T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nutov_Z/0/1/0/all/0/1&quot;&gt;Zeev Nutov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A graph $G$ is $k$-out-connected from its node $s$ if it contains $k$
internally disjoint $sv$-paths to every node $v$; $G$ is $k$-connected if it is
$k$-out-connected from every node. In connectivity augmentation problems the
goal is to augment a graph $G_0=(V,E_0)$ by a minimum costs edge set $J$ such
that $G_0 \cup J$ has higher connectivity than $G_0$. In the
$k$-Out-Connectivity Augmentation ($k$-OCA) problem, $G_0$ is
$(k-1)$-out-connected from $s$ and $G_0 \cup J$ should be $k$-out-connected
from $s$; in the $k$-Connectivity Augmentation ($k$-CA) problem $G_0$ is
$(k-1)$-connected and $G_0 \cup J$ should be $k$-connected. The parameterized
complexity status of these problems was open even for $k=3$ and unit costs. We
will show that $k$-OCA and $3$-CA can be solved in time $9^p \cdot n^{O(1)}$,
where $p$ is the size of an optimal solution. Our paper is the first that shows
fixed parameter tractability of a $k$-node-connectivity augmentation problem
with high values of $k$. We will also consider the $(2,k)$-Connectivity
Augmentation problem where $G_0$ is $(k-1)$-edge-connected and $G_0 \cup J$
should be both $k$-edge-connected and $2$-connected. We will show that this
problem can be solved in time $9^p \cdot n^{O(1)}$, and for unit costs
approximated within $1.892$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Emanuele Viola: Myth creation: The switching lemma</title>
    <link href="https://emanueleviola.wordpress.com/2022/09/14/myth-creation-the-switching-lemma/"/>
    <id>http://emanueleviola.wordpress.com/?p=1056</id>
    <updated>2022-09-14T17:11:22+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;!--?xml version=&quot;1.0&quot; encoding=&quot;iso-8859-1&quot; ?--&gt; &lt;!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd--&gt; &lt;!-- html,xhtml,-css,NoFonts --&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;The history of science is littered with anecdotes about misplaced credit. Because it does not matter if it was A or B who did it; it only matters if it was I or not I. In this spirit I am starting a series of posts about such misplaced credit, which I hesitated before calling more colorfully &amp;#8220;myth creation.&amp;#8221; Before starting, I want to make absolutely clear that I am in no way criticizing the works themselves or their authors. In fact, many are among my favorites. Moreover, at least in the examples I have in mind right now, the authors do place their work in the appropriate context with the use of citations etc. My only point is the credit that the work has received within and without our community (typically due to inertia and snowball effects rather than anything else).&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Of course, at some level this doesn’t matter. You can call Chebichev’s polynomials rainbow sprinkles and the math doesn’t change. And yet at some other level maybe it does matter a little, for science isn’t yet a purely robotic activity. With these posts I will advertise unpopular points of views that might be useful, for example to researchers who are junior or from different communities.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;
&lt;h3 class=&quot;sectionHead&quot;&gt;The switching lemma&lt;/h3&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;
&lt;div class=&quot;quote&quot;&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;em&gt;I must admit I had a good run &lt;/em&gt;&amp;#8212; Johan Hastad (privately to the blogger)&lt;/p&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Random restrictions have been used in complexity theory since at least the 60’s &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XSubbotovskaya61&quot;&gt;Sub61&lt;/a&gt;]&lt;/span&gt;. The first dramatic use in the context of AC0 is due to &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XFSS84&quot;&gt;FSS84&lt;/a&gt;, &lt;a href=&quot;#XAjt83&quot;&gt;Ajt83&lt;/a&gt;]&lt;/span&gt;. These works proved a &lt;em&gt;switching lemma&lt;/em&gt; the amazing fact that a DNF gets simplified by a random restriction to the point that it can be written as a CNF, so you can collapse layers and induct. (An exposition is given below.) Using it, they proved super-polynomial lower bounds for AC0. The proof in &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XFSS84&quot;&gt;FSS84&lt;/a&gt;]&lt;/span&gt; is very nice, and if I want to get a quick intuition of why switching is at all possible, I often go back to it. &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XAjt83&quot;&gt;Ajt83&lt;/a&gt;]&lt;/span&gt; is also a brilliant paper, and long, unavailable online for free, filled with a logical notation which makes some people twitch. The first symbol of the title says it all, and may be the most obscene ever chosen:&lt;/p&gt;
&lt;div style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5CSigma+_%7B1%7D%5E%7B1%7D.+%5Cend%7Baligned%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5CSigma+_%7B1%7D%5E%7B1%7D.+%5Cend%7Baligned%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5CSigma+_%7B1%7D%5E%7B1%7D.+%5Cend%7Baligned%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;begin{aligned} &amp;#92;Sigma _{1}^{1}. &amp;#92;end{aligned}&quot; class=&quot;latex&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Subsequently, &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XYao85&quot;&gt;Yao85&lt;/a&gt;]&lt;/span&gt; proved exponential lower bounds of the form &lt;img src=&quot;https://s0.wp.com/latex.php?latex=2%5E%7Bn%5E%7Bc%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=2%5E%7Bn%5E%7Bc%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%5E%7Bc%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;2^{n^{c}}&quot; class=&quot;latex&quot; /&gt;, with a refined analysis of the switching lemma. The bounds are tight, except for the constant &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; which depends on the depth of the circuit. Finally, the star of this post &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;conf/stoc/Hastad86&quot;&gt;Has86&lt;/a&gt;, &lt;a href=&quot;#XHas87&quot;&gt;Has87&lt;/a&gt;]&lt;/span&gt; obtained &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c%3D1%2F%28depth-1%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c%3D1%2F%28depth-1%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%3D1%2F%28depth-1%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c=1/(depth-1)&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Yao’s paper doesn’t quite state that a DNF can be written exactly as a CNF, but it states that it can be approximated. Hastad’s work is the first to prove that a DNF can be written as a CNF, and in this sense his statement is cleaner than Yao’s. However, Yao’s paper states explicitly that a small circuit, after being hit by a restriction, can be set to constant by fixing few more bits.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;The modern formulation of the switching lemma says that a DNF can be written as a &lt;em&gt;shallow decision tree&lt;/em&gt; (and hence a small CNF). This formulation in terms of decision trees is actually not explicit in Hastad’s work. Beame, in his primer &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XBea94&quot;&gt;Bea94&lt;/a&gt;]&lt;/span&gt;, credits Cai with this idea and mentions several researchers noted Hastad’s proof works in this way.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Another switching lemma trivia is that the proof in Hastad’s thesis is actually due to Boppana; Hastad’s original argument &amp;#8212; of which apparently no written record exists &amp;#8212; was closer to Razborov’s later proof.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;So, let’s recap. Random restrictions are already in &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XSubbotovskaya61&quot;&gt;Sub61&lt;/a&gt;]&lt;/span&gt;. The idea of switching is already in &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XFSS84&quot;&gt;FSS84&lt;/a&gt;, &lt;a href=&quot;#XAjt83&quot;&gt;Ajt83&lt;/a&gt;]&lt;/span&gt;. You already had three analyses of these ideas, two giving superpolynomial lower bounds and one &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XYao85&quot;&gt;Yao85&lt;/a&gt;]&lt;/span&gt; giving exponential. The formulation in terms of decision trees isn’t in &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XHas87&quot;&gt;Has87&lt;/a&gt;]&lt;/span&gt;, and the proof that appears in &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XHas87&quot;&gt;Has87&lt;/a&gt;]&lt;/span&gt; is due to Boppana.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Still, I would guess &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XHas87&quot;&gt;Has87&lt;/a&gt;]&lt;/span&gt; is more well known than all the other works above combined. &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XYao85&quot;&gt;Yao85&lt;/a&gt;]&lt;/span&gt; did have a following at the time &amp;#8212; I think it appeared in the pop news. But hey &amp;#8212; have you ever heard of Yao’s switching lemma?&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;The current citation counts offer mixed support for my thesis:&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;FSS: 1351&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Y: 732&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;H &amp;#8211; paper &amp;#8220;Almost optimal&amp;#8230;:&amp;#8221; 867&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;H &amp;#8211; thesis: 582&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;But it is very hard to use citation information. The two H citations overlap, and papers are cited for various reasons. For example FSS got a ton of citations for the connection to oracles (which has nothing to do with switching lemmas).&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Instead it’s instructive to note the type of citations that you can find in the literature:&lt;/p&gt;
&lt;div class=&quot;quote&quot;&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;em&gt;Hastad’s switching lemma is a cornerstone of circuit complexity&lt;/em&gt; [No mention of FSS, A, Y]&lt;/p&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;
&lt;div class=&quot;quote&quot;&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;em&gt;Hastad‘s Switching Lemma is one of the gems of computational complexity&lt;/em&gt; [Notes below in passing it builds on FSS, A, Y]&lt;/p&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;The wikipedia entry is also telling:&lt;/p&gt;
&lt;table class=&quot;quotation&quot; border=&quot;0&quot; cellspacing=&quot;15&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;div class=&quot;quotation&quot;&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;em&gt;In computational complexity theory, Hastad’s switching lemma is a key tool for proving lower bounds on the size of constant-depth Boolean circuits. Using the switching lemma, Johan Hastad (1987) showed that.&lt;/em&gt;.. [No mention of FSS,A,Y]&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I think that 99% of the contribution of this line of research is the &lt;em&gt;amazing idea&lt;/em&gt; that random restrictions simplify a DNF so that you can write it as a CNF and collapse. 90% of the rest is analyzing this to get superpolynomial lower bounds. And 90% of whatever is left is analyzing this to get exponential lower bounds.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Going back to something I mentioned at the beginning, I want to emphasize that Hastad during talks makes a point of reminding the audience that the idea of random restrictions is due to Sipser, and of Boppana’s contribution. And I also would like to thank him for his help with this post.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;OK &amp;#8212; so maybe this is so, but it must then be the case that &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XHas87&quot;&gt;Has87&lt;/a&gt;]&lt;/span&gt; is the final word on this stuff, like the ultimate tightest analysis that kills the problem. Actually, it is not tight in some regimes of interest, and several cool works of past and recent times address that. In the end, I can only think of one reason why &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XHas87&quot;&gt;Has87&lt;/a&gt;]&lt;/span&gt; entered the mythology in ways that other works did not, the reason that I carefully sidestepped while composing this post: å.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Perhaps one reason behind the aura of the switching lemma is that it’s hard to find examples. It would be nice to read: If you have this extreme DNF here’s what happens, on the other hand for this other extreme DNF here’s what happens, and in general this always works and here’s the switching lemma. &lt;em&gt;Examples are forever&lt;/em&gt; – Erdos. Instead the switching lemma is typically presented as &lt;em&gt;blam&lt;/em&gt;!: an example-free encoding argument which feels &lt;em&gt;deus ex machina&lt;/em&gt;, as in this &lt;a href=&quot;https://arxiv.org/abs/2202.05651&quot;&gt;crisp presentation by Thapen&lt;/a&gt;. For a little more discussion, I liked &lt;a href=&quot;https://www.cse.cuhk.edu.hk/~andrejb/csci5170/notes/19L02.pdf&quot;&gt;Bogdanov’s lecture notes&lt;/a&gt;. Next I give a slightly different exposition of the encoding argument.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;b&gt;The simplest case: Or of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; bits&lt;/b&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Here the circuit &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C&quot; class=&quot;latex&quot; /&gt; is simply the Or of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; bits &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;x_{1},x_{2},&amp;#92;ldots ,x_{n}&quot; class=&quot;latex&quot; /&gt;. This and the next case can be analyzed in more familiar ways, but the benefit of the encoding argument presented next is that it will extend to the general case more easily&amp;#8230; arguably. Anyway, it’s also just fun to learn a different argument.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;So, let’s take a random restriction &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt; with exactly &lt;img src=&quot;https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;s&quot; class=&quot;latex&quot; /&gt; stars. Some of the bits may become &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;, others &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;, and others yet may remain unfixed, i.e., assigned to stars. Those that become &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt; you can ignore, while if some become &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt; then the whole circuit becomes &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;We will show that the number of restrictions for which the restricted circuit &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; requires decision trees of depth &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cge+d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cge+d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;ge d&quot; class=&quot;latex&quot; /&gt; is small. To accomplish this, we are going to encode/map such restrictions using/to a restriction&amp;#8230; with no stars (that is, just a 0/1 assignment to the variables). The gain is clear: just think of a restriction with zero stars versus a restriction with one star. The latter are more by a factor about the number &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; of variables.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;A critical observation is that we only want to encode restrictions for which &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; requires large depth. So &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt; does not map any variable to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;, for else the Or is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt; which has decision trees of depth &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;The way we are going to encode &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt; is this: &lt;em&gt;Simply replace the stars with ones&lt;/em&gt;. To go back, replace the ones with stars. We are using the ones in the encoding to “signal” where the stars are.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Hence, the number of bad restrictions is at most &lt;img src=&quot;https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;2^{n}&quot; class=&quot;latex&quot; /&gt;, which is tiny compared to the number &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cbinom+%7Bn%7D%7Bs%7D2%5E%7Bn-s%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cbinom+%7Bn%7D%7Bs%7D2%5E%7Bn-s%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbinom+%7Bn%7D%7Bs%7D2%5E%7Bn-s%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;binom {n}{s}2^{n-s}&quot; class=&quot;latex&quot; /&gt; of restrictions with &lt;img src=&quot;https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;s&quot; class=&quot;latex&quot; /&gt; stars.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;b&gt;The medium case: Or of functions on disjoint inputs&lt;/b&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Instead of working with DNFs, I will consider a circuit &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C&quot; class=&quot;latex&quot; /&gt; which is the Or of arbitrary functions &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f_%7Bi%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=f_%7Bi%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7Bi%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;f_{i}&quot; class=&quot;latex&quot; /&gt; each on &lt;img src=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;w&quot; class=&quot;latex&quot; /&gt; bits. You can immediately get this formulation from the usual one for DNFs, but I still find it a little useful since otherwise you might think there is something special about DNFs. What &lt;em&gt;is &lt;/em&gt;special is that you take the Or of the functions, and we will exploit this again shortly.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;In this warm-up case, we start with functions on &lt;em&gt;disjoint&lt;/em&gt; inputs. So, again, let’s take a random restriction &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt; with exactly &lt;img src=&quot;https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;s&quot; class=&quot;latex&quot; /&gt; stars. Some of the functions may become &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;, others &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;, and others yet may remain unfixed. Those that become &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt; you can ignore, while if some become &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt; then the whole circuit becomes &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;As before, we will show that the number of restrictions for which the restricted circuit &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; requires decision trees of depth &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cge+d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cge+d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;ge d&quot; class=&quot;latex&quot; /&gt; is small. To accomplish this, we are going to encode/map such restrictions using/to a restriction with just &lt;img src=&quot;https://s0.wp.com/latex.php?latex=s-d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=s-d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s-d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;s-d&quot; class=&quot;latex&quot; /&gt; stars, plus a little more information. As we saw already, the gain in reducing the number of stars is clear. In particular, standard calculations show that saving &lt;img src=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;d&quot; class=&quot;latex&quot; /&gt; stars reduces the number of restrictions by a factor &lt;img src=&quot;https://s0.wp.com/latex.php?latex=O%28s%2Fn%29%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=O%28s%2Fn%29%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28s%2Fn%29%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;O(s/n)^{d}&quot; class=&quot;latex&quot; /&gt;. The auxiliary information will give us a factor of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=w%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=w%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;w^{d}&quot; class=&quot;latex&quot; /&gt;, leading to the familiar bound &lt;img src=&quot;https://s0.wp.com/latex.php?latex=O%28ws%2Fn%29%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=O%28ws%2Fn%29%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28ws%2Fn%29%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;O(ws/n)^{d}&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;As before, recall that we only want to encode restrictions for which &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; requires large depth. So no function in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;, for else the circuit is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt; and has decision trees of depth &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;. Also, you have &lt;img src=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;d&quot; class=&quot;latex&quot; /&gt; stars among inputs to functions that are unfixed (i.e., not even fixed to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;), for else again you can compute the function reading less than &lt;img src=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;d&quot; class=&quot;latex&quot; /&gt; bits. Because the functions are unfixed, there is a setting for those &lt;img src=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;d&quot; class=&quot;latex&quot; /&gt; stars (and possibly a few more stars – that would only help the argument) that make the corresponding functions &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;. We are going to pick precisely that setting in our restriction &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+%27&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+%27&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+%27&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &amp;#039;&quot; class=&quot;latex&quot; /&gt; with &lt;img src=&quot;https://s0.wp.com/latex.php?latex=s-d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=s-d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s-d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;s-d&quot; class=&quot;latex&quot; /&gt; stars. This allows us to “signal” which functions had inputs with the stars we are saving (namely, those that are the constant &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;). To completely recover &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt;, we simply add extra information to indicate where the stars were. The saving here is that we only have to say where the stars are among &lt;img src=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;w&quot; class=&quot;latex&quot; /&gt; symbols, not &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;b&gt;The general case: Or of functions on any subset of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;w&quot; class=&quot;latex&quot; /&gt; bits&lt;/b&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;First, the number of functions does not play a role, so you can think you have functions on any possible subset of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;w&quot; class=&quot;latex&quot; /&gt; bits, where some functions may be constant. The idea is the same, except we have to be slightly more careful because when we set values for the stars in one function we may also affect other functions. The idea is simply to fix one function at the time. Specifically, starting with &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt;, consider the first function &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;f&quot; class=&quot;latex&quot; /&gt; that’s not made constant by &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt;. So the inputs to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;f&quot; class=&quot;latex&quot; /&gt; have some stars. As before, let us replace the stars with constants that make the function &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;f&quot; class=&quot;latex&quot; /&gt; equal to the constant 1, and append the extra information that allows us to recover where these stars were in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;We’d like to repeat the argument. Note however we only have guarantees about &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt;, not &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; with some stars replaced with constants that make &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;f&quot; class=&quot;latex&quot; /&gt; equal to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;. We also can’t just jump to the 2nd function that’s not constant in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt;, since the “signal” fixing for that might clash with the fixing for the first – this is where the overlap in inputs makes things slightly more involved. Instead, because &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; required decision tree depth at least &lt;img src=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;d&quot; class=&quot;latex&quot; /&gt;, we note there have to be some assignments to the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;m&quot; class=&quot;latex&quot; /&gt; stars in the input to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;f&quot; class=&quot;latex&quot; /&gt; so that the resulting, further restricted circuit still requires decision tree depth &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cge+d-m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cge+d-m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+d-m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;ge d-m&quot; class=&quot;latex&quot; /&gt; (else &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; has decision trees of depth &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%3Cd&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%3Cd&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%3Cd&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;lt;d&quot; class=&quot;latex&quot; /&gt;).  We append this assignment to the auxiliary information and we continue the argument using the further restricted circuit.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;
&lt;h3 class=&quot;likesectionHead&quot;&gt;&lt;a id=&quot;x1-30001&quot;&gt;&lt;/a&gt;References&lt;/h3&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;
&lt;div class=&quot;thebibliography&quot;&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [Ajt83] &lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XAjt83&quot;&gt;&lt;/a&gt;Mikl�s Ajtai. &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;Sigma &amp;#92;sp {1}&amp;#92;sb {1}&quot; class=&quot;latex&quot; /&gt;-formulae on finite structures. Annals of Pure and Applied Logic, 24(1):1–48, 1983.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [Bea94]&lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XBea94&quot;&gt;&lt;/a&gt;Paul Beame. A switching lemma primer. Technical Report UW-CSE-95-07-01, Department of Computer Science and Engineering, University of Washington, November 1994. Available from &lt;a href=&quot;http://www.cs.washington.edu/homes/beame/&quot; rel=&quot;nofollow&quot;&gt;http://www.cs.washington.edu/homes/beame/&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [FSS84]&lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XFSS84&quot;&gt;&lt;/a&gt;Merrick L. Furst, James B. Saxe, and Michael Sipser. Parity, circuits, and the polynomial-time hierarchy. Mathematical Systems Theory, 17(1):13–27, 1984.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [Has86]&lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XDBLP:conf/stoc/Hastad86&quot;&gt;&lt;/a&gt;Johan H�stad. Almost optimal lower bounds for small depth circuits. In Juris Hartmanis, editor, Proceedings of the 18th Annual ACM Symposium on Theory of Computing, May 28-30, 1986, Berkeley, California, USA, pages 6–20. ACM, 1986.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [H�s87]&lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XHas87&quot;&gt;&lt;/a&gt;Johan H�stad. Computational limitations of small-depth circuits. MIT Press, 1987.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [Sub61]&lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XSubbotovskaya61&quot;&gt;&lt;/a&gt;B. A. Subbotovskaya. Realizations of linear functions by formulas using +, *, -. Soviet Mathematics-Doklady, 2:110–112, 1961.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [Yao85]&lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XYao85&quot;&gt;&lt;/a&gt;Andrew Yao. Separating the polynomial-time hierarchy by oracles. In 26th IEEE Symp. on Foundations of Computer Science (FOCS), pages 1–10, 1985.&lt;/p&gt;
&lt;/div&gt;
&lt;p class=&quot;authors&quot;&gt;By Manu&lt;/p&gt;
  </content>
    <author>
      <name>Emanuele Viola</name>
      <uri>https://emanueleviola.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Scott Aaronson: I had a dream</title>
    <link href="https://scottaaronson.blog/?p=6718"/>
    <id>https://scottaaronson.blog/?p=6718</id>
    <updated>2022-09-14T16:52:05+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;As I slept fitfully, still recovering from COVID, I had one of the more interesting dreams of my life:&lt;/p&gt;



&lt;p&gt;I was desperately trying to finish some PowerPoint slides in time to give a talk. Uncharacteristically for me, one of the slides displayed actual code. This was a dream, so nothing was as clear as I&amp;#8217;d like, but the code did &lt;em&gt;something&lt;/em&gt; vaguely reminiscent of &lt;a href=&quot;https://scottaaronson.blog/?p=710&quot;&gt;Rosser’s Theorem&lt;/a&gt;—e.g., enumerating all proofs in ZFC until it finds the lexicographically first proof or disproof of a certain statement, then branching into cases depending on whether it&amp;#8217;s a proof or a disproof. In any case, it was simple enough to fit on one slide.&lt;/p&gt;



&lt;p&gt;Suddenly, though, my whole presentation was deleted. Everything was ruined!&lt;/p&gt;



&lt;p&gt;One of the developers of PowerPoint happened to be right there in the lecture hall (of course!), so I confronted him with my laptop and angrily demanded an explanation. He said that I must have triggered the section of Microsoft Office that tries to detect and prevent any discussion of logical paradoxes that are too dangerous for humankind—the ones that would cause people to realize that our entire universe is just an illusion, a sandbox being run inside an AI, a glitch-prone Matrix. He said it patronizingly, as if it should&amp;#8217;ve been obvious: &amp;#8220;you and I both know that the Paradoxes are not to be talked about, so why would you be so &lt;em&gt;stupid&lt;/em&gt; as to put one in your presentation?&amp;#8221;&lt;/p&gt;



&lt;p&gt;My reaction was to jab my finger in the guy’s face, shove him, scream, and curse him out. At that moment, I wasn’t concerned in the slightest about the universe being an illusion, or about glitches in the Matrix. I was concerned about my embarrassment when I’d be called in 10 minutes to give my talk and would have nothing to show.&lt;/p&gt;



&lt;p&gt;My last thought, before I woke with a start, was to wonder whether Greg Kuperberg was right and I should give my presentations in &lt;a href=&quot;https://en.wikipedia.org/wiki/Beamer_(LaTeX)&quot;&gt;Beamer&lt;/a&gt;, or some other open-source software, and then I wouldn’t have had this problem.&lt;/p&gt;



&lt;p&gt;A coda: I woke a bit after 7AM Central and started to write this down. But then&amp;#8212;this is now real life (!)&amp;#8212;I saw an email saying that a dozen people were waiting for me in a conference room in Europe for an important Zoom meeting. We&amp;#8217;d gotten the time zones wrong; I&amp;#8217;d thought that it wasn&amp;#8217;t until 8AM my time. If not for this dream causing me to wake up, I would&amp;#8217;ve missed the meeting entirely.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </content>
    <author>
      <name>Scott Aaronson</name>
      <uri>https://scottaaronson.blog</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Windows on Theory: Quick reminders: masters, postdocs, faculty, etc.</title>
    <link href="https://windowsontheory.org/2022/09/14/quick-reminders-masters-postdocs-faculty-etc/"/>
    <id>http://windowsontheory.org/?p=8452</id>
    <updated>2022-09-14T13:50:02+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;As we&amp;#8217;re getting closer to the season when undergraduate students are considering graduate school, and graduate students are considering the next steps such as postdoc or faculty positions,  I wanted to remind people of two resources for such positions: the &lt;a href=&quot;https://cstheory-jobs.org/&quot;&gt;TCS jobs&lt;/a&gt; and &lt;a href=&quot;https://www.cs.princeton.edu/~smattw/masters/masters.html&quot;&gt;crowd-sourced masters&lt;/a&gt; pages. &lt;/p&gt;



&lt;p&gt;The process and market for both graduate studies and faculty positions (at least in the US) is fairly standard, with more or less a common timeline, and general ideas of where to look for positions (universities&amp;#8217; websites are always a good start, as are the websites of &lt;a href=&quot;https://jobs.acm.org/jobs/products/&quot;&gt;ACM&lt;/a&gt; and &lt;a href=&quot;https://cra.org/ads/&quot;&gt;CRA&lt;/a&gt;).  Even so, it&amp;#8217;s not always clear which areas a university is searching for at any given year, and also these resources are very US-centric, while many great places are located outside the US.&lt;/p&gt;



&lt;p&gt;The &lt;strong&gt;postdoc market&lt;/strong&gt; is much more &amp;#8220;ad hoc&amp;#8221;. Some places such as the &lt;a href=&quot;https://simons.berkeley.edu/programs/participate&quot;&gt;Simons institute&lt;/a&gt; and the &lt;a href=&quot;https://www.ias.edu/math/csdm/postdocs&quot;&gt;IAS&lt;/a&gt; search for postdocs yearly and have several positions. (Our own &lt;a href=&quot;https://www.harvard.edu/kempner-institute/&quot;&gt;Kempner Institute&lt;/a&gt; will also be having regular searches after it launches this year.)  But in many other cases, postdoc positions are with an individual researcher that might have availability only every few years, which makes it harder for candidates to find out about this.  For such positions, the &lt;a href=&quot;https://cstheory-jobs.org/&quot;&gt;&lt;strong&gt;Theoretical Computer Science jobs&lt;/strong&gt;&lt;/a&gt; page is a great way to both advertise any position you have to offer, as well as find out about opportunities.  Please post any postdoc or faculty positions relevant to TCS in your institution, as well as advertise it to your students as a place to look for jobs.&lt;/p&gt;



&lt;p&gt;Finding information about &lt;strong&gt;research-oriented Masters programs&lt;/strong&gt; is also sometimes challenging. In the US it&amp;#8217;s common for students to apply straight to a Ph.D from undergraduate, and Masters programs are often intended more for professional development. But, as I &lt;a href=&quot;https://windowsontheory.org/2018/02/20/research-masters/&quot;&gt;wrote in the past,&lt;/a&gt; &lt;em&gt;research-oriented&lt;/em&gt; Masters programs can actually be a great fit for many students. A Ph.D is a huge commitment on both the student and advisor side. If you have not had a chance to do research during your undergraduate studies,  it may be better to start with a Masters before taking such a commitment. Some research Masters programs do not charge any tuition, and several offer a stipend. To post and look for such opportunities, see the &lt;a href=&quot;https://www.cs.princeton.edu/~smattw/masters/masters.html&quot;&gt;&lt;strong&gt;crowdsourced TCS research masters website&lt;/strong&gt;&lt;/a&gt;, managed by Aviad Rubinstein and Matt Weinberg.&lt;/p&gt;



&lt;p&gt;If there are other great resources or opportunities, please post them in the comments!&lt;/p&gt;



&lt;p&gt;In particular, the resources above are geared for theoretical CS. If you have suggestions of analogous resources for other fields, please post them as well.&lt;/p&gt;



&lt;p&gt; &lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Boaz Barak&lt;/p&gt;
  </content>
    <author>
      <name>Windows on Theory</name>
      <uri>https://windowsontheory.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: On bounded depth proofs for Tseitin formulas on the grid; revisited</title>
    <link href="http://arxiv.org/abs/2209.05839"/>
    <id>http://arxiv.org/abs/2209.05839</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+H%5Cr%7Ba%7Dstad_J/0/1/0/all/0/1&quot;&gt;Johan H&amp;#xe5;stad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Risse_K/0/1/0/all/0/1&quot;&gt;Kilian Risse&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study Frege proofs using depth-$d$ Boolean formulas for the Tseitin
contradiction on $n \times n$ grids. We prove that if each line in the proof is
of size $M$ then the number of lines is exponential in $n/(\log M)^{O(d)}$.
This strengthens a recent result of Pitassi et al. [PRT22]. The key technical
step is a multi-switching lemma extending the switching lemma of H\r{a}stad
[H\r{a}s20] for a space of restrictions related to the Tseitin contradiction.
The strengthened lemma also allows us to improve the lower bound for standard
proof size of bounded depth Frege refutations from exponential in $\tilde
\Omega (n^{1/59d})$ to exponential in $\tilde \Omega (n^{1/(2d-1)})$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: What is a combinatorial interpretation?</title>
    <link href="http://arxiv.org/abs/2209.06142"/>
    <id>http://arxiv.org/abs/2209.06142</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pak_I/0/1/0/all/0/1&quot;&gt;Igor Pak&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this survey we discuss the notion of combinatorial interpretation in the
context of Algebraic Combinatorics and related areas. We approach the subject
from the Computational Complexity perspective. We review many examples, state a
workable definition, discuss many open problems, and present recent results on
the subject.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Topological Measures for Pattern quantification of Impact Centers in Piezo Vibration Striking Treatment (PVST)</title>
    <link href="http://arxiv.org/abs/2209.05531"/>
    <id>http://arxiv.org/abs/2209.05531</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yesilli_M/0/1/0/all/0/1&quot;&gt;Melih C. Yesilli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chumley_M/0/1/0/all/0/1&quot;&gt;Max M. Chumley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jisheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khasawneh_F/0/1/0/all/0/1&quot;&gt;Firas A. Khasawneh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yang Guo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Surface texture influences wear and tribological properties of manufactured
parts, and it plays a critical role in end-user products. Therefore,
quantifying the order or structure of a manufactured surface provides important
information on the quality and life expectancy of the product. Although texture
can be intentionally introduced to enhance aesthetics or to satisfy a design
function, sometimes it is an inevitable byproduct of surface treatment
processes such as Piezo Vibration Striking Treatment (PVST). Measures of order
for surfaces have been characterized using statistical, spectral, and geometric
approaches. For nearly hexagonal lattices, topological tools have also been
used to measure the surface order. This paper utilizes tools from Topological
Data Analysis for quantifying the impact centers&#39; pattern in PVST. We compute
measures of order based on optical digital microscope images of surfaces
treated using PVST. These measures are applied to the grid obtained from
estimating the centers of tool impacts, and they quantify the grid&#39;s deviations
from the nominal one. Our results show that TDA provides a convenient framework
for the characterization of pattern type that bypasses some limitations of
existing tools such as difficult manual processing of the data and the need for
an expert user to analyze and interpret the surface images.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Rectilinear Convex Hull of Points in 3D</title>
    <link href="http://arxiv.org/abs/2209.06020"/>
    <id>http://arxiv.org/abs/2209.06020</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Lantero_P/0/1/0/all/0/1&quot;&gt;Pablo P&amp;#xe9;rez-Lantero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seara_C/0/1/0/all/0/1&quot;&gt;Carlos Seara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urrutia_J/0/1/0/all/0/1&quot;&gt;Jorge Urrutia&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $P$ be a set of $n$ points in $\mathbb{R}^3$ in general position, and let
$RCH(P)$ be the rectilinear convex hull of $P$. In this paper we obtain an
optimal $O(n\log n)$-time and $O(n)$-space algorithm to compute $RCH(P)$. We
also obtain an efficient $O(n\log^2 n)$-time and $O(n\log n)$-space algorithm
to compute and maintain the set of vertices of the rectilinear convex hull of
$P$ as we rotate $\mathbb R^3$ around the $z$-axis. Finally we study some
properties of the rectilinear convex hulls of point sets in $\mathbb{R}^3$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Recovery from Non-Decomposable Distance Oracles</title>
    <link href="http://arxiv.org/abs/2209.05676"/>
    <id>http://arxiv.org/abs/2209.05676</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zhuangfei Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xinda Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1&quot;&gt;David P. Woodruff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hongyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shufan Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A line of work has looked at the problem of recovering an input from distance
queries. In this setting, there is an unknown sequence $s \in \{0,1\}^{\leq
n}$, and one chooses a set of queries $y \in \{0,1\}^{\mathcal{O}(n)}$ and
receives $d(s,y)$ for a distance function $d$. The goal is to make as few
queries as possible to recover $s$. Although this problem is well-studied for
decomposable distances, i.e., distances of the form $d(s,y) = \sum_{i=1}^n
f(s_i, y_i)$ for some function $f$, which includes the important cases of
Hamming distance, $\ell_p$-norms, and $M$-estimators, to the best of our
knowledge this problem has not been studied for non-decomposable distances, for
which there are important special cases such as edit distance, dynamic time
warping (DTW), Frechet distance, earth mover&#39;s distance, and so on. We initiate
the study and develop a general framework for such distances. Interestingly,
for some distances such as DTW or Frechet, exact recovery of the sequence $s$
is provably impossible, and so we show by allowing the characters in $y$ to be
drawn from a slightly larger alphabet this then becomes possible. In a number
of cases we obtain optimal or near-optimal query complexity. We also study the
role of adaptivity for a number of different distance functions. One motivation
for understanding non-adaptivity is that the query sequence can be fixed and
the distances of the input to the queries provide a non-linear embedding of the
input, which can be used in downstream applications involving, e.g., neural
networks for natural language processing.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Unsplittable Euclidean Capacitated Vehicle Routing: A $(2+\epsilon)$-Approximation Algorithm</title>
    <link href="http://arxiv.org/abs/2209.05520"/>
    <id>http://arxiv.org/abs/2209.05520</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grandoni_F/0/1/0/all/0/1&quot;&gt;Fabrizio Grandoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathieu_C/0/1/0/all/0/1&quot;&gt;Claire Mathieu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hang Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the unsplittable capacitated vehicle routing problem, we are given a
metric space with a vertex called depot and a set of vertices called terminals.
Each terminal is associated with a positive demand between 0 and 1. The goal is
to find a minimum length collection of tours starting and ending at the depot
such that the demand of each terminal is covered by a single tour (i.e., the
demand cannot be split), and the total demand of the terminals in each tour
does not exceed the capacity of 1.
&lt;/p&gt;
&lt;p&gt;Our main result is a polynomial-time $(2+\epsilon)$-approximation algorithm
for this problem in the two-dimensional Euclidean plane, i.e., for the special
case where the terminals and the depot are associated with points in the
Euclidean plane and their distances are defined accordingly. This improves on
recent work by Blauth, Traub, and Vygen [IPCO&#39;21] and Friggstad, Mousavi,
Rahgoshay, and Salavatipour [IPCO&#39;22].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A Note on the Quickest Minimum Cost Transshipment Problem</title>
    <link href="http://arxiv.org/abs/2209.05558"/>
    <id>http://arxiv.org/abs/2209.05558</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skutella_M/0/1/0/all/0/1&quot;&gt;Martin Skutella&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Klinz and Woeginger (1995) prove that the minimum cost quickest flow problem
is NP-hard. On the other hand, the quickest minimum cost flow problem can be
solved efficiently via a straightforward reduction to the quickest flow problem
without costs. More generally, we show how the quickest minimum cost
transshipment problem can be reduced to the efficiently solvable quickest
transshipment problem, thus adding another mosaic tile to the rich complexity
landscape of flows over time.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: An Improved Lower Bound for Matroid Intersection Prophet Inequalities</title>
    <link href="http://arxiv.org/abs/2209.05614"/>
    <id>http://arxiv.org/abs/2209.05614</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxena_R/0/1/0/all/0/1&quot;&gt;Raghuvansh R. Saxena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velusamy_S/0/1/0/all/0/1&quot;&gt;Santhoshini Velusamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinberg_S/0/1/0/all/0/1&quot;&gt;S. Matthew Weinberg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider prophet inequalities subject to feasibility constraints that are
the intersection of $q$ matroids. The best-known algorithms achieve a
$\Theta(q)$-approximation, even when restricted to instances that are the
intersection of $q$ partition matroids, and with i.i.d.~Bernoulli random
variables. The previous best-known lower bound is $\Theta(\sqrt{q})$ due to a
simple construction of [Kleinberg-Weinberg STOC 2012] (which uses
i.i.d.~Bernoulli random variables, and writes the construction as the
intersection of partition matroids).
&lt;/p&gt;
&lt;p&gt;We establish an improved lower bound of $q^{1/2+\Omega(1/\log \log q)}$ by
writing the construction of [Kleinberg-Weinberg STOC 2012] as the intersection
of asymptotically fewer partition matroids. We accomplish this via an improved
upper bound on the product dimension of a graph with $p^p$ disjoint cliques of
size $p$, using recent techniques developed in [Alon-Alweiss European Journal
of Combinatorics 2020].
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Space Optimal Vertex Cover in Dynamic Streams</title>
    <link href="http://arxiv.org/abs/2209.05623"/>
    <id>http://arxiv.org/abs/2209.05623</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naidu_K/0/1/0/all/0/1&quot;&gt;Kheeran K. Naidu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_V/0/1/0/all/0/1&quot;&gt;Vihan Shah&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We optimally resolve the space complexity for the problem of finding an
$\alpha$-approximate minimum vertex cover ($\alpha$MVC) in dynamic graph
streams. We give a randomised algorithm for $\alpha$MVC which uses
$O(n^2/\alpha^2)$ bits of space matching Dark and Konrad&#39;s lower bound [CCC
2020] up to constant factors. By computing a random greedy matching, we
identify `easy&#39; instances of the problem which can trivially be solved by
returning the entire vertex set. The remaining `hard&#39; instances, then have
sparse induced subgraphs which we exploit to get our space savings and solve
$\alpha$MVC.
&lt;/p&gt;
&lt;p&gt;Achieving this type of optimality result is crucial for providing a complete
understanding of a problem, and it has been gaining interest within the dynamic
graph streaming community. For connectivity, Nelson and Yu [SODA 2019] improved
the lower bound showing that $\Omega(n \log^3 n)$ bits of space is necessary
while Ahn, Guha, and McGregor [SODA 2012] have shown that $O(n \log^3 n)$ bits
is sufficient. For finding an $\alpha$-approximate maximum matching, the upper
bound was improved by Assadi and Shah [ITCS 2022] showing that
$O(n^2/\alpha^3)$ bits is sufficient while Dark and Konrad [CCC 2020] have
shown that $\Omega(n^2/\alpha^3)$ bits is necessary. The space complexity,
however, remains unresolved for many other dynamic graph streaming problems
where further improvements can still be made. \end{abstract}
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Fast Algorithms for Monotone Lower Subsets of Kronecker Least Squares Problems</title>
    <link href="http://arxiv.org/abs/2209.05662"/>
    <id>http://arxiv.org/abs/2209.05662</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Malik_O/0/1/0/all/0/1&quot;&gt;Osman Asif Malik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yiming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cheng_N/0/1/0/all/0/1&quot;&gt;Nuojin Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Becker_S/0/1/0/all/0/1&quot;&gt;Stephen Becker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Doostan_A/0/1/0/all/0/1&quot;&gt;Alireza Doostan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Narayan_A/0/1/0/all/0/1&quot;&gt;Akil Narayan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Approximate solutions to large least squares problems can be computed
efficiently using leverage score-based row-sketches, but directly computing the
leverage scores, or sampling according to them with naive methods, still
requires an expensive manipulation and processing of the design matrix. In this
paper we develop efficient leverage score-based sampling methods for matrices
with certain Kronecker product-type structure; in particular we consider
matrices that are monotone lower column subsets of Kronecker product matrices.
Our discussion is general, encompassing least squares problems on infinite
domains, in which case matrices formally have infinitely many rows. We briefly
survey leverage score-based sampling guarantees from the numerical linear
algebra and approximation theory communities, and follow this with efficient
algorithms for sampling when the design matrix has Kronecker-type structure.
Our numerical examples confirm that sketches based on exact leverage score
sampling for our class of structured matrices achieve superior residual
compared to approximate leverage score sampling methods.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A Hash Table Without Hash Functions, and How to Get the Most Out of Your Random Bits</title>
    <link href="http://arxiv.org/abs/2209.06038"/>
    <id>http://arxiv.org/abs/2209.06038</id>
    <updated>2022-09-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuszmaul_W/0/1/0/all/0/1&quot;&gt;William Kuszmaul&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper considers the basic question of how efficiently can a
constant-time hash table, storing $n$ $\Theta(\log n)$-bit key/value pairs,
make use of its random bits? That is, how many random bits does a hash table
need to offer constant-time operations with probability $1 - 1 / \poly(n)$?
And, if the number of random bits is unrestricted, then what is the
highest-probability guarantee that a hash table can offer?
&lt;/p&gt;
&lt;p&gt;Past work on these questions has been bottlenecked by limitations of the
known families of hash functions. The hash tables that achieve failure
probabilities $1 / \poly(n)$ use at least $\tilde{\Omega}(\log^2 n)$ random
bits, which is the number of random bits needed to create hash functions with
$\tilde{\Omega}(\log n)$-wise independence. And the only hash tables to achieve
failure probabilities less than $1 / 2^{\polylog n}$ require access to
fully-random hash functions -- if the same hash tables are implemented using
the known explicit families of hash functions, their failure probabilities
become $1 / \poly(n)$.
&lt;/p&gt;
&lt;p&gt;To get around these obstacles, we show how to construct a randomized data
structure that has the same guarantees as a hash table, but that \emph{avoids
the direct use of hash functions}. Building on this, we are then able to give
nearly optimal solutions to both problems described above: we construct a hash
table using $\tilde{O}(\log n)$ random bits that achieves failure-probability
$1 / \poly(n)$; and we construct a hash table using $O(n)$ random bits that
achieves failure probability $1 / n^{n^{1 - \epsilon}}$ for an arbitrary
positive constant $\epsilon$.
&lt;/p&gt;
&lt;p&gt;Finally, if the keys/values are $(1 + \Theta(1)) \log n$ bits each, then we
show that the above guarantees can even be achieved by \emph{succinct
dictionaries}, that is, by dictionaries that use space within a $1 + o(1)$
factor of the information-theoretic optimum.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-128 |  PPP-Completeness and Extremal Combinatorics | 

	Romain Bourneuf, 

	Lukáš Folwarczný, 

	Pavel Hubacek, 

	Alon Rosen, 

	Nikolaj Schwartzbach</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/128"/>
    <id>https://eccc.weizmann.ac.il/report/2022/128</id>
    <updated>2022-09-13T17:22:41+00:00</updated>
    <content type="html" xml:lang="en">
    Many classical theorems in combinatorics establish the emergence of substructures within sufficiently large collections of objects. Well-known examples are Ramsey&amp;#39;s theorem on monochromatic subgraphs and the Erdos-Rado sunflower lemma. Implicit versions of the corresponding total search problems are known to be PWPP-hard; here &amp;quot;implicit&amp;quot; means that the collection is represented by a poly-sized circuit inducing an exponentially large number of objects.

We show that several other well-known  theorems from extremal combinatorics - including Erdos-Ko-Rado, Sperner, and Cayley&amp;#39;s formula - give rise to complete problems for PWPP and PPP. This is in contrast to the Ramsey and Erdos-Rado problems, for which establishing inclusion in PWPP has remained elusive. Besides significantly expanding the set of problems that are complete for PWPP and PPP, our work identifies some key properties of combinatorial proofs of existence that can give rise to completeness for these classes.

Our completeness results rely on efficient encodings for which finding collisions allows extracting the desired substructure. These encodings are made possible by the tightness of the bounds for the problems at hand (tighter than what is known for Ramsey&amp;#39;s theorem and the sunflower lemma). Previous techniques for proving bounds in TFNP invariably made use of structured algorithms. Such algorithms are not known to exist for the theorems considered in this work, as their proofs &amp;quot;from the book&amp;quot; are non-constructive.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-127 |  Kolmogorov Complexity Characterizes Statistical Zero Knowledge | 

	Eric Allender, 

	Shuichi Hirahara, 

	Harsha Tirumala</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/127"/>
    <id>https://eccc.weizmann.ac.il/report/2022/127</id>
    <updated>2022-09-13T17:21:12+00:00</updated>
    <content type="html" xml:lang="en">
    We show that a decidable promise problem has a non-interactive statistical zero-knowledge proof system if and only if it is randomly reducible to a promise problem for Kolmogorov-random strings, with a superlogarithmic additive approximation term.  This extends recent work by Saks and Santhanam (CCC 2022).  We build on this to give new characterizations of Statistical Zero Knowledge (SZK), as well as the related classes NISZK_L and SZK_L.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-126 |  An Invitation to the Promise Constraint Satisfaction Problem | 

	Andrei Krokhin, 

	Jakub Opršal</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/126"/>
    <id>https://eccc.weizmann.ac.il/report/2022/126</id>
    <updated>2022-09-13T16:54:09+00:00</updated>
    <content type="html" xml:lang="en">
    The study of the complexity of the constraint satisfaction problem (CSP), centred around the Feder-Vardi Dichotomy Conjecture, has been very prominent in the last two decades. After a long concerted effort and many partial results, the Dichotomy Conjecture has been proved in 2017 independently by Bulatov and Zhuk.

At about the same time, a vast generalisation of CSP, called promise CSP, has started to gain prominence. In this survey, we explain the importance of promise CSP and highlight many new very interesting features that the study of promise CSP has brought to light. The complexity classification quest for the promise CSP is wide open, and we argue that, despite the promise CSP being more general, this quest is rather more accessible to a wide range of researchers than the dichotomy-led study of the CSP has been.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: On Identity Testing and Noncommutative Rank Computation over the Free Skew Field</title>
    <link href="http://arxiv.org/abs/2209.04797"/>
    <id>http://arxiv.org/abs/2209.04797</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arvind_V/0/1/0/all/0/1&quot;&gt;V. Arvind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1&quot;&gt;Abhranil Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosal_U/0/1/0/all/0/1&quot;&gt;Utsab Ghosal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukhopadhyay_P/0/1/0/all/0/1&quot;&gt;Partha Mukhopadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramya_C/0/1/0/all/0/1&quot;&gt;C. Ramya&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The identity testing of rational formulas (RIT) in the free skew field
efficiently reduces to computing the rank of a matrix whose entries are linear
polynomials in noncommuting variables\cite{HW15}. This rank computation problem
has deterministic polynomial-time white-box algorithms \cite{GGOW16, IQS18} and
a randomized polynomial-time algorithm in the black-box setting \cite{DM17}. In
this paper, we propose a new approach for efficient derandomization of
\emph{black-box} RIT. Additionally, we obtain results for matrix rank
computation over the free skew field, and construct efficient linear pencil
representations for a new class of rational expressions. More precisely, we
show the following results:
&lt;/p&gt;
&lt;p&gt;1. Under the hardness assumption that the ABP (algebraic branching program)
complexity of every polynomial identity for the $k\times k$ matrix algebra is
$2^{\Omega(k)}$ \cite{BW05}, we obtain a subexponential-time black-box
algorithm for RIT in almost general setting. This can be seen as the first
&quot;hardness implies derandomization&quot; type theorem for rational formulas.
&lt;/p&gt;
&lt;p&gt;2. We show that the noncommutative rank of any matrix over the free skew
field whose entries have small linear pencil representations can be computed in
deterministic polynomial time. Prior to this, an efficient rank computation was
only known for matrices with noncommutative formulas as entries\cite{GGOW20}.
As special cases of our algorithm, we obtain the first deterministic
polynomial-time algorithms for rank computation of matrices whose entries are
noncommutative ABPs or rational formulas.
&lt;/p&gt;
&lt;p&gt;3. Motivated by the definition given by Bergman\cite{Ber76}, we define a new
class that contains noncommutative ABPs and rational formulas. We obtain a
polynomial-size linear pencil representation for this class. As a by-product,
we obtain a white-box deterministic polynomial-time identity testing algorithm
for the class.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: PPP-Completeness and Extremal Combinatorics</title>
    <link href="http://arxiv.org/abs/2209.04827"/>
    <id>http://arxiv.org/abs/2209.04827</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bourneuf_R/0/1/0/all/0/1&quot;&gt;Romain Bourneuf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Folwarczny_L/0/1/0/all/0/1&quot;&gt;Luk&amp;#xe1;&amp;#x161; Folwarczn&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hubacek_P/0/1/0/all/0/1&quot;&gt;Pavel Hub&amp;#xe1;&amp;#x10d;ek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosen_A/0/1/0/all/0/1&quot;&gt;Alon Rosen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartzbach_N/0/1/0/all/0/1&quot;&gt;Nikolaj Ignatieff Schwartzbach&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Many classical theorems in combinatorics establish the emergence of
substructures within sufficiently large collections of objects. Well-known
examples are Ramsey&#39;s theorem on monochromatic subgraphs and the Erd\H{o}s-Rado
sunflower lemma. Implicit versions of the corresponding total search problems
are known to be PWPP-hard; here &quot;implici&quot; means that the collection is
represented by a poly-sized circuit inducing an exponentially large number of
objects.
&lt;/p&gt;
&lt;p&gt;We show that several other well-known theorems from extremal combinatorics -
including Erd\H{o}s-Ko-Rado, Sperner, and Cayley&#39;s formula - give rise to
complete problems for PWPP and PPP. This is in contrast to the Ramsey and
Erd\H{o}s-Rado problems, for which establishing inclusion in PWPP has remained
elusive. Besides significantly expanding the set of problems that are complete
for PWPP and PPP, our work identifies some key properties of combinatorial
proofs of existence that can give rise to completeness for these classes.
&lt;/p&gt;
&lt;p&gt;Our completeness results rely on efficient encodings for which finding
collisions allows extracting the desired substructure. These encodings are made
possible by the tightness of the bounds for the problems at hand (tighter than
what is known for Ramsey&#39;s theorem and the sunflower lemma). Previous
techniques for proving bounds in TFNP invariably made use of structured
algorithms. Such algorithms are not known to exist for the theorems considered
in this work, as their proofs &quot;from the book&quot; are non-constructive.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: The Complexity and Expressive Power of Second-Order Extended Logic</title>
    <link href="http://arxiv.org/abs/2209.04837"/>
    <id>http://arxiv.org/abs/2209.04837</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1&quot;&gt;Shiguang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xishun Zhao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the expressive powers of SO-HORN$^{*}$, SO-HORN$^{r}$ and
SO-HORN$^{*r}$ on all finite structures. We show that SO-HORN$^{r}$,
SO-HORN$^{*r}$, FO(LFP) coincide with each other and SO-HORN$^{*}$ is proper
sublogic of SO-HORN$^{r}$. To prove this result, we introduce the notions of
DATALOG$^{*}$ program, DATALOG$^{r}$ program and their stratified versions,
S-DATALOG$^{*}$ program and S-DATALOG$^{r}$ program. It is shown that, on all
structures, DATALOG$^{r}$ and S-DATALOG$^{r}$ are equivalent and DATALOG$^{*}$
is a proper sublogic of DATALOG$^{r}$. SO-HORN$^{*}$ and SO-HORN$^{r}$ can be
treated as the negations of DATALOG$^{*}$ and DATALOG$^{r}$, respectively. We
also show that SO-EHORN$^{r}$ logic which is an extended version of SO-HORN
captures co-NP on all finite structures.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: On The Computational Complexity of Self-Attention</title>
    <link href="http://arxiv.org/abs/2209.04881"/>
    <id>http://arxiv.org/abs/2209.04881</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keles_F/0/1/0/all/0/1&quot;&gt;Feyza Duman Keles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wijewardena_P/0/1/0/all/0/1&quot;&gt;Pruthuvi Mahesakya Wijewardena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hegde_C/0/1/0/all/0/1&quot;&gt;Chinmay Hegde&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Transformer architectures have led to remarkable progress in many
state-of-art applications. However, despite their successes, modern
transformers rely on the self-attention mechanism, whose time- and
space-complexity is quadratic in the length of the input. Several approaches
have been proposed to speed up self-attention mechanisms to achieve
sub-quadratic running time; however, the large majority of these works are not
accompanied by rigorous error guarantees. In this work, we establish lower
bounds on the computational complexity of self-attention in a number of
scenarios. We prove that the time complexity of self-attention is necessarily
quadratic in the input length, unless the Strong Exponential Time Hypothesis
(SETH) is false. This argument holds even if the attention computation is
performed only approximately, and for a variety of attention mechanisms. As a
complement to our lower bounds, we show that it is indeed possible to
approximate dot-product self-attention using finite Taylor series in
linear-time, at the cost of having an exponential dependence on the polynomial
order.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Nearly all $k$-SAT functions are unate</title>
    <link href="http://arxiv.org/abs/2209.04894"/>
    <id>http://arxiv.org/abs/2209.04894</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Balogh_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf3;zsef Balogh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dong_D/0/1/0/all/0/1&quot;&gt;Dingding Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lidicky_B/0/1/0/all/0/1&quot;&gt;Bernard Lidick&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mani_N/0/1/0/all/0/1&quot;&gt;Nitya Mani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yufei Zhao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We prove that $1-o(1)$ fraction of all $k$-SAT functions on $n$ Boolean
variables are unate (i.e., monotone after first negating some variables), for
any fixed positive integer $k$ and as $n \to \infty$. This resolves a
conjecture by Bollob\&#39;as, Brightwell, and Leader from 2003.
&lt;/p&gt;
&lt;p&gt;This paper is the second half of a two-part work solving the problem. The
first part, by Dong, Mani, and Zhao, reduces the conjecture to a Tur\&#39;an
problem on partially directed hypergraphs. In this paper we solve this Tur\&#39;an
problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Gradient-Free Methods for Deterministic and Stochastic Nonsmooth Nonconvex Optimization</title>
    <link href="http://arxiv.org/abs/2209.05045"/>
    <id>http://arxiv.org/abs/2209.05045</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tianyi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zheng_Z/0/1/0/all/0/1&quot;&gt;Zeyu Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Nonsmooth nonconvex optimization problems broadly emerge in machine learning
and business decision making, whereas two core challenges impede the
development of efficient solution methods with finite-time convergence
guarantee: the lack of computationally tractable optimality criterion and the
lack of computationally powerful oracles. The contributions of this paper are
two-fold. First, we establish the relationship between the celebrated Goldstein
subdifferential~\citep{Goldstein-1977-Optimization} and uniform smoothing,
thereby providing the basis and intuition for the design of gradient-free
methods that guarantee the finite-time convergence to a set of Goldstein
stationary points. Second, we propose the gradient-free method (GFM) and
stochastic GFM for solving a class of nonsmooth nonconvex optimization problems
and prove that both of them can return a $(\delta,\epsilon)$-Goldstein
stationary point of a Lipschitz function $f$ at an expected convergence rate at
$O(d^{3/2}\delta^{-1}\epsilon^{-4})$ where $d$ is the problem dimension.
Two-phase versions of GFM and SGFM are also proposed and proven to achieve
improved large-deviation results. Finally, we demonstrate the effectiveness of
2-SGFM on training ReLU neural networks with the \textsc{Minst} dataset.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Localization with Few Distance Measurements</title>
    <link href="http://arxiv.org/abs/2209.04838"/>
    <id>http://arxiv.org/abs/2209.04838</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Halperin_D/0/1/0/all/0/1&quot;&gt;Dan Halperin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LaValle_S/0/1/0/all/0/1&quot;&gt;Steven M. LaValle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ugav_B/0/1/0/all/0/1&quot;&gt;Barak Ugav&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a polygon $W$, a depth sensor placed at point $p=(x,y)$ inside $W$ and
oriented in direction $\theta$ measures the distance $d=h(x,y,\theta)$ between
$p$ and the closest point on the boundary of $W$ along a ray emanating from $p$
in direction $\theta$. We study the following problem: Give a polygon $W$,
possibly with holes, with $n$ vertices, preprocess it such that given a query
real value $d\geq 0$, one can efficiently compute the preimage $h^{-1}(d)$,
namely determine all the possible poses (positions and orientations) of a depth
sensor placed in $W$ that would yield the reading $d$. We employ a
decomposition of $W\times S^1$, which is an extension of the celebrated
trapezoidal decomposition, and which we call rotational trapezoidal
decomposition and present an efficient data structure, which computes the
preimage in an output-sensitive fashion relative to this decomposition: if $k$
cells of the decomposition contribute to the final result, we will report them
in $O(k+1)$ time, after $O(n^2\log n)$ preprocessing time and using $O(n^2)$
storage space. We also analyze the shape of the projection of the preimage onto
the polygon $W$; this projection describes the portion of $W$ where the sensor
could have been placed. Furthermore, we obtain analogous results for the more
useful case (narrowing down the set of possible poses), where the sensor
performs two depth measurement from the same point $p$, one in direction
$\theta$ and the other in direction $\theta+\pi$. While localizations problems
in robotics are often carried out by exploring the full visibility polygon of a
sensor placed at a fixed point of the environment, the approach that we propose
here opens the door to sufficing with only few depth measurements, which is
advantageous as it allows for usage of inexpensive sensors and could also lead
to savings in storage and communication costs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Structured $(\min,+)$-Convolution And Its Applications For The Shortest Vector, Closest Vector, and Separable Nonlinear Knapsack Problems</title>
    <link href="http://arxiv.org/abs/2209.04812"/>
    <id>http://arxiv.org/abs/2209.04812</id>
    <updated>2022-09-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gribanov_D/0/1/0/all/0/1&quot;&gt;D. V. Gribanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malyshev_D/0/1/0/all/0/1&quot;&gt;D. S. Malyshev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shumilov_I/0/1/0/all/0/1&quot;&gt;I. A. Shumilov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work we consider the problem of computing the $(\min, +)$-convolution
of two sequences $a$ and $b$ of lengths $n$ and $m$, respectively, where $n
\geq m$. We assume that $a$ is arbitrary, but $b_i = f(i)$, where $f(x) \colon
[0,m) \to \mathbb{R}$ is a function with one of the following properties:
&lt;/p&gt;
&lt;p&gt;1. the linear case, when $f(x) =\beta + \alpha \cdot x$;
&lt;/p&gt;
&lt;p&gt;2. the monotone case, when $f(i+1) \geq f(i)$, for any $i$;
&lt;/p&gt;
&lt;p&gt;3. the convex case, when $f(i+1) - f(i) \geq f(i) - f(i-1)$, for any $i$;
&lt;/p&gt;
&lt;p&gt;4. the concave case, when $f(i+1) - f(i) \leq f(i) - f(i-1)$, for any $i$;
&lt;/p&gt;
&lt;p&gt;5. the piece-wise linear case, when $f(x)$ consist of $p$ linear pieces;
&lt;/p&gt;
&lt;p&gt;6. the polynomial case, when $f \in \mathbb{Z}^d[x]$, for some fixed $d$.
&lt;/p&gt;
&lt;p&gt;To the best of our knowledge, the cases 4-6 were not considered in literature
before. We develop true sub-quadratic algorithms for them.
&lt;/p&gt;
&lt;p&gt;We apply our results to the knapsack problem with a separable nonlinear
objective function, shortest lattice vector, and closest lattice vector
problems.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


</feed>
