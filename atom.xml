<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Theory of Computing Report</title>
  <link rel="self" href=""/>
  <link href=""/>
  <id></id>
  <updated></updated>
  <generator uri="http://feedreader.github.io/">Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]</generator>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-140 |  Commitments to Quantum States | 

	Sam Gunn, 

	Nathan Ju, 

	Fermi Ma, 

	Mark Zhandry</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/140"/>
    <id>https://eccc.weizmann.ac.il/report/2022/140</id>
    <updated>2022-10-16T06:07:10+00:00</updated>
    <content type="html" xml:lang="en">
    What does it mean to commit to a quantum state? In this work, we propose a simple answer: a commitment to quantum messages is binding if, after the commit phase, the committed state is hidden from the sender&amp;#39;s view. We accompany this new definition with several instantiations. We build the first non-interactive succinct quantum state commitments, which can be seen as an analogue of collision-resistant hashing for quantum messages. We also show that hiding quantum state commitments (QSCs) are implied by any commitment scheme for classical messages. All of our constructions can be based on quantum-cryptographic assumptions that are implied by but are potentially weaker than one-way functions.

Commitments to quantum states open the door to many new cryptographic possibilities. Our flagship application of a succinct QSC is a quantum-communication version of Kilian&amp;#39;s succinct arguments for any language that has quantum PCPs with constant error and polylogarithmic locality. Plugging in the PCP theorem, this yields succinct arguments for NP under significantly weaker assumptions than required classically; moreover, if the quantum PCP conjecture holds, this extends to QMA. At the heart of our security proof is a new rewinding technique for extracting quantum information.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Windows on Theory: Swiss TCS winter school,  CCC 2023 call for papers</title>
    <link href="https://windowsontheory.org/2022/10/16/swiss-tcs-winter-school-ccc-2023-call-for-papers/"/>
    <id>http://windowsontheory.org/?p=8459</id>
    <updated>2022-10-16T04:15:51+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;em&gt;[Guest post by David Steurer, both the speakers and the location seem amazing! &amp;#8211;Boaz]&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;br&gt;The &lt;strong&gt;Swiss Winter School on Theoretical Computer Science &lt;/strong&gt;(Jan 29  &amp;#8211; Feb 3 2023, &lt;a rel=&quot;noreferrer noopener&quot; href=&quot;https://theory.epfl.ch/WinterSchool2023/&quot; target=&quot;_blank&quot;&gt;https://theory.epfl.ch/WinterSchool2023/&lt;/a&gt;)  will be the second installment in a series of annual winter schools jointly organized by EPFL and ETH Zurich (the first installment happened in 2020).&lt;br&gt;The goal of the school is to educate outstanding international PhD students about exciting recent developments in  theoretical computer science.&lt;/p&gt;



&lt;p&gt;&lt;br&gt;The winter school will be held in Zinal, a mountain village in the Swiss Alps that has a long tradition of hosting academic workshops and that allows for nice excursions and stimulating discussions in a relaxed atmosphere.&lt;/p&gt;



&lt;p&gt;This year’s installment features an exciting trinity of speakers:&lt;br&gt;Rasmus Kyng (ETH Zurich), Yin Tat Lee (University of Washington), and Ryan Williams (MIT).&lt;/p&gt;



&lt;p&gt;For full consideration, applications must be submitted by&amp;nbsp;November 1st 2022.&lt;br&gt;Notifications will be sent by&amp;nbsp;November 7th.&lt;br&gt;The application form is available at&amp;nbsp;&lt;a href=&quot;https://theory.epfl.ch/WinterSchool2023/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;https://theory.epfl.ch/WinterSchool2023/&lt;/a&gt;.&lt;/p&gt;



&lt;p&gt;The winter school is organized by Mika Goos (EPFL), Michael Kapralov (EPFL), Rasmus Kyng (ETH Zurich), David Steurer (ETH Zurich), Ola Svennson (EPFL).&lt;/p&gt;



&lt;p&gt;&lt;/p&gt;



&lt;p&gt;Also Amit Chakrabarti tells me that the Call for Papers for the &lt;strong&gt;Computational Complexity Conference (CCC) 2023&lt;/strong&gt; is now out on &lt;a href=&quot;https://www.computationalcomplexity.org/Archive/2023/cfp.php&quot; rel=&quot;nofollow&quot;&gt;https://www.computationalcomplexity.org/Archive/2023/cfp.php&lt;/a&gt; . Deadline is &lt;strong&gt;Friday, February 10, 2023, 23:59 AoE&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Boaz Barak&lt;/p&gt;
  </content>
    <author>
      <name>Windows on Theory</name>
      <uri>https://windowsontheory.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-139 |  On the VNP-hardness of Some Monomial Symmetric Polynomials | 

	Nutan Limaye, 

	Srikanth Srinivasan, 

	Radu Curticapean</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/139"/>
    <id>https://eccc.weizmann.ac.il/report/2022/139</id>
    <updated>2022-10-15T22:02:30+00:00</updated>
    <content type="html" xml:lang="en">
    A polynomial $P\in F[x_1,\ldots,x_n]$ is said to be symmetric if it is invariant under any permutation of its input variables. The study of symmetric polynomials is a classical topic in mathematics, specifically in algebraic combinatorics and representation theory. More recently, they have been studied in several works in computer science, especially in algebraic complexity theory.
		
		In this paper, we prove the computational hardness of one of the most basic kinds of symmetric polynomials: the $monomial$ $symmetric$ $polynomials$, which are obtained by summing all distinct permutations of a single monomial. This family of symmetric functions is a natural basis for the space of symmetric polynomials (over any field), and generalizes many well-studied families such as the elementary symmetric polynomials and the power-sum symmetric polynomials.
		
		We show that certain families of monomial symmetric polynomials are $VNP$-$complete$ with respect to oracle reductions. This stands in stark contrast to the case of elementary and power symmetric polynomials, both of which have constant-depth circuits of polynomial size.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">David Eppstein: Linkage</title>
    <link href="https://11011110.github.io/blog/2022/10/15/linkage.html"/>
    <id>https://11011110.github.io/blog/2022/10/15/linkage</id>
    <updated>2022-10-15T17:24:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://actu.epfl.ch/news/age-old-technique-enhanced-by-computer-modeling/&quot;&gt;Ultralightweight pavilion made from woven bamboo strips, aided by modern computer modeling&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109097228519637153&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; Not very good for keeping sun or rain off in the form shown, but I imagine one could stretch a membrane over it if that were the goal.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://support.google.com/photos/thread/180787712/corrupted-photos&quot;&gt;Corruption in old images stored in Google Photos&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109104810612333424&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://news.ycombinator.com/item?id=32970623&quot;&gt;via&lt;/a&gt;). Let this be a reminder that if you care about the permanence and stability of your data, keep a safe copy on media you own and control, not on someone else’s machine on the cloud somewhere.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;“&lt;a href=&quot;https://www.aaup.org/news/university-idaho-should-rescind-guidance-speech-about-abortion&quot;&gt;The University of Idaho administration has abandoned its duty to uphold the mission of the institution and signaled to all the world that the university is no longer committed to academic freedom&lt;/a&gt;” &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109108400913458700&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; according to The American Association of University Professors. The context is a memo sent out by the university’s lawyers requesting faculty to “remain neutral on the topic of abortion”; for more on that, see &lt;em&gt;Inside Higher Ed&lt;/em&gt;’s &lt;a href=&quot;https://www.insidehighered.com/news/2022/09/27/university-tells-professors-stay-neutral-abortion&quot;&gt;story&lt;/a&gt; and &lt;a href=&quot;https://www.insidehighered.com/quicktakes/2022/09/30/aaup-u-idaho-should-rescind-guidance-abortion-speech&quot;&gt;editorial&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.computationalcomplexity.org/2022/10/is-it-okay-for-paper-or-book-to-say-for.html&quot;&gt;Gasarch asks for advice on whether it’s acceptable for an academic publication to cite Wikipedia&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109113654779787003&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; Comments concern stability of Wikipedia articles, but that’s easy: every article has “cite this page” in the toolbar with sample citations that permalink stable versions. The bigger issue is the purpose of the citation. As background reading: fine. As credit for a figure: necessary. For a technical result: you should probably follow the references to a more-primary source.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.deepmind.com/blog/discovering-novel-algorithms-with-alphatensor&quot;&gt;Computer search for faster matrix multiplication algorithms&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@j2kun/109116859743991084&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://cp4space.hatsya.com/2022/10/06/matrix-multiplication-update/&quot;&gt;see also&lt;/a&gt;).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In place of the prime numbers, consider &lt;a href=&quot;http://oeis.org/A050376&quot;&gt;the numbers \(p^{2^k}\) for \(p\) prime and integer \(i\ge 0\)&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109119821643711856&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; Each positive integer has a unique factorization into a product of these without repetition. For example,&lt;/p&gt;

\[21600 = 2\cdot 3\cdot 9\cdot 16\cdot 25.\]

    &lt;p&gt;They are called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Fermi%E2%80%93Dirac_prime&quot;&gt;Fermi–Dirac primes&lt;/a&gt; because of an analogy to fermions and bosons from physics: like bosons, primes can appear repeatedly in an energy level (prime factorization), but these numbers appear only once.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I linked to &lt;a href=&quot;https://arxiv.org/abs/2205.09102&quot;&gt;Milman and Neeman’s preprint on the triple bubble conjecture&lt;/a&gt; &lt;a href=&quot;/blog/2022/06/30/linkage.html&quot;&gt;last June&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109131239935449901&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; but now &lt;a href=&quot;https://www.quantamagazine.org/monumental-math-proof-solves-triple-bubble-problem-and-more-20221006/&quot;&gt;&lt;em&gt;Quanta&lt;/em&gt; has a popularized explainer of it&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://amathr.org/an-aperiodic-set-of-eleven-wang-tiles/&quot;&gt;An aperiodic set of 11 Wang tiles&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109136741064182404&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; Wang tiles are edge-colored squares that tile the plane as a grid, without rotation and with matching edges. B. Durand and A. Shen explain a result of E. Jeandel and M. Rao from a &lt;a href=&quot;https://arxiv.org/abs/1506.06492&quot;&gt;2015 preprint&lt;/a&gt; and &lt;a href=&quot;https://amathr.org/an-aperiodic-set-of-eleven-wang-tiles/&quot;&gt;2021 journal publication&lt;/a&gt; using a computer search to prove that sets of 11 Wang tiles with 4 colors (but no fewer of either) can force the tiling to be aperiodic.&lt;/p&gt;

    &lt;p&gt;The first link is on the site of an organization led by people who have publicly opposed mandatory statements of support for diversity or inclusiveness, and the organization itself conspicuously lacks any statement of support for those values. This led to some discussion on Mathstodon over whether we should link to even purely-mathematical content by these people. &lt;a href=&quot;https://mathstodon.xyz/@11011110/109144568072282691&quot;&gt;My position is that it would be a mistake to shun them&lt;/a&gt;. I think their position that mathematics can and should be above such concerns is naive and overly idealistic, but we cannot find solutions to societal problems such as institutionalized discrimination if we shut down free and open discussions of alternatives by banning anyone at the slightest misstep from the political orthodoxy of the minute. Also, doing so would strengthen their position by playing into their storyline of good mathematics getting pushed aside for political reasons. As I wrote in the linked comment, “Let’s not be the monsters they think we are.”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://planetofthepaul.com/wikipedia-download-usb-flash/&quot;&gt;How to make yourself a copy of Wikipedia on a flash drive, usable offline&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109142543607772779&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://news.ycombinator.com/item?id=33114107&quot;&gt;via&lt;/a&gt;).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://gafferongames.com/post/shape_of_the_go_stone/&quot;&gt;The shape of a Go stone&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109147037847419575&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;):&lt;/span&gt; A project from 2013 to create “a physically accurate computer simulation of a Go board and stones” starts by trying to understand the shape of the stones, settling on an intersection between two balls, modified by using a torus to bevel the sharp edge where they meet. Which sort of looks right, but &lt;a href=&quot;https://forums.online-go.com/t/the-shape-of-the-stones/27557&quot;&gt;a 2020 discussion suggests that a more accurate model needs to take into account how real Go stones are made&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=a-767WnbaCQ&quot;&gt;Percolation: a Mathematical Phase Transition&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109153531832896359&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; One of many recent mathematics exposition videos from the “Summer of Math Exposition 2”; this one is mostly about the bond percolation on an infinite square grid, the study of the connectivity of random subgraphs of the grid. There’s &lt;a href=&quot;https://www.metafilter.com/196698/Summer-of-Math-Exposition-2&quot;&gt;a more complete listing of the other videos on Metafilter&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://uxdesign.cc/how-apple-makes-you-think-green-bubbles-gross-e03b52b12fed&quot;&gt;Intentionally-bad and anti-accessible user interface design by Apple, in order to undercut the competition&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109156160184481951&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://boingboing.net/2022/10/12/apple-intentionally-made-the-green-chat-bubbles-of-android-text-messages-look-gross.html&quot;&gt;via&lt;/a&gt;, &lt;a href=&quot;https://news.ycombinator.com/item?id=33176668&quot;&gt;via2&lt;/a&gt;).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/mathjax/MathJax-src/releases/tag/4.0.0-alpha.1&quot;&gt;MathJax 4.0.0-alpha.1 now available&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109165272680486533&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://groups.google.com/g/mathjax-users/c/WhMiWK9Ld7k?pli=1&quot;&gt;via&lt;/a&gt;, &lt;a href=&quot;https://www.ams.org/news?news_id=7098&quot;&gt;via2&lt;/a&gt;). Because it’s still an alpha-test version, it’s probably not the right time to switch unless you really need the new features (more fonts, better line breaking, html within math expressions).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.boristhebrave.com/2021/05/23/triangle-grids/&quot;&gt;An appreciation of triangular grids&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@jsiehler/109166889958867986&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Interesting_number_paradox&quot;&gt;The interesting number paradox&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109173873212315062&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;)&lt;/span&gt; is the argument that there cannot be a smallest uninteresting natural number, because that property would make it interesting. I had thought that it dated from &lt;a href=&quot;https://www.jstor.org/stable/24942039&quot;&gt;a 1958 “Mathematical Games” column by Martin Gardner in &lt;em&gt;Scientific American&lt;/em&gt;&lt;/a&gt;, but now another Wikipedia editor has found an earlier reference, &lt;a href=&quot;https://doi.org/10.2307/2305682&quot;&gt;a 1945 letter to the American Mathematical Monthly by Edwin F. Bechenbach&lt;/a&gt; (see bottom of last page of link).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;authors&quot;&gt;By David Eppstein&lt;/p&gt;
  </content>
    <author>
      <name>David Eppstein</name>
      <uri>https://11011110.github.io/blog/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Gil Kalai: Bo’az Klartag and  Joseph Lehec: The Slice Conjecture Up to Polylogarithmic Factor!</title>
    <link href="https://gilkalai.wordpress.com/2022/10/15/boaz-klartag-and-joseph-lehec-the-slice-conjecture-up-to-polylogarithmic-factor/"/>
    <id>http://gilkalai.wordpress.com/?p=23414</id>
    <updated>2022-10-15T15:50:56+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;img data-attachment-id=&quot;23425&quot; data-permalink=&quot;https://gilkalai.wordpress.com/2022/10/15/boaz-klartag-and-joseph-lehec-the-slice-conjecture-up-to-polylogarithmic-factor/boazjoseph/&quot; data-orig-file=&quot;https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png&quot; data-orig-size=&quot;860,380&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;BoazJoseph&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=300&quot; data-large-file=&quot;https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=640&quot; class=&quot;alignnone size-full wp-image-23425&quot; src=&quot;https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=640&quot; alt=&quot;BoazJoseph&quot; srcset=&quot;https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=640 640w, https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=150 150w, https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=300 300w, https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=768 768w, https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png 860w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;   /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;&lt;strong&gt;Bo&amp;#8217;az Klartag (right) and Joseph Lehec (left)&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In December 2020, &lt;a href=&quot;https://gilkalai.wordpress.com/2020/12/21/to-cheer-you-up-in-difficult-times-15-yuansi-chen-achieved-a-major-breakthrough-on-bourgains-slicing-problem-and-the-kannan-lovasz-and-simonovits-conjecture/&quot;&gt;we reported on Yuansi Chen breakthrough result&lt;/a&gt; on Bourgain&amp;#8217;s alicing problem and the Kannan Lovasz Simonovits conjecture. It is a pleasure to report on a further fantastic progress on these problems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bourgain&amp;#8217;s slicing problem (1984):&lt;/strong&gt;  Is there &lt;em&gt;c &amp;gt; 0&lt;/em&gt; such that for any dimension n and any centrally symmetric convex body &lt;em&gt;K ⊆&lt;/em&gt; &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;mathbb R^n&quot; class=&quot;latex&quot; /&gt; of volume one, there exists a hyperplane &lt;em&gt;H&lt;/em&gt; such that the&lt;em&gt; (n − 1)-&lt;/em&gt;dimensional volume of &lt;em&gt;K ∩ H&lt;/em&gt; is at least &lt;em&gt;c&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;Some time ago we reported on Yuansi Chen&amp;#8217;s startling result that c can be taken as &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n%5E%7B-o%281%29%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n%5E%7B-o%281%29%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B-o%281%29%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n^{-o(1)}&quot; class=&quot;latex&quot; /&gt;. More precisely, Chen proved:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem (Chen, 2021):&lt;/strong&gt; For any dimension n and any centrally symmetric convex body &lt;em&gt;K ⊆&lt;/em&gt; &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;mathbb R^n&quot; class=&quot;latex&quot; /&gt; of volume one, there exists a hyperplane &lt;em&gt;H&lt;/em&gt; such that the&lt;em&gt; (n − 1)-&lt;/em&gt;dimensional volume of &lt;em&gt;K ∩ H&lt;/em&gt; is at least &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cfrac+%7B1%7D%7BL_n%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cfrac+%7B1%7D%7BL_n%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac+%7B1%7D%7BL_n%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;frac {1}{L_n}&quot; class=&quot;latex&quot; /&gt; where&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=L_n%3DC+%5Cexp+%28+%5Csqrt+%7B%5Clog+n%7D+%5Csqrt+%7B3%5Clog+%5Clog+n%7D+%29.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=L_n%3DC+%5Cexp+%28+%5Csqrt+%7B%5Clog+n%7D+%5Csqrt+%7B3%5Clog+%5Clog+n%7D+%29.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L_n%3DC+%5Cexp+%28+%5Csqrt+%7B%5Clog+n%7D+%5Csqrt+%7B3%5Clog+%5Clog+n%7D+%29.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;L_n=C &amp;#92;exp ( &amp;#92;sqrt {&amp;#92;log n} &amp;#92;sqrt {3&amp;#92;log &amp;#92;log n} ).&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2203.15551&quot;&gt;A major improvement was recently achieved by  Bo&amp;#8217;az Klartag and Joseph Lehec&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem (Klartag and Lehec, 2022):&lt;/strong&gt; For any dimension n and any centrally symmetric convex body &lt;em&gt;K ⊆&lt;/em&gt; &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;mathbb R^n&quot; class=&quot;latex&quot; /&gt; of volume one, there exists a hyperplane &lt;em&gt;H&lt;/em&gt; such that the&lt;em&gt; (n − 1)-&lt;/em&gt;dimensional volume of &lt;em&gt;K ∩ H&lt;/em&gt; is at least &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cfrac+%7B1%7D%7BL_n%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cfrac+%7B1%7D%7BL_n%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac+%7B1%7D%7BL_n%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;frac {1}{L_n}&quot; class=&quot;latex&quot; /&gt; where&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=L_n+%3D+C+%28%5Clog+n%29%5E4.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=L_n+%3D+C+%28%5Clog+n%29%5E4.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L_n+%3D+C+%28%5Clog+n%29%5E4.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;L_n = C (&amp;#92;log n)^4.&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Klartag and Lehec&amp;#8217;s argument (as Chen&amp;#8217;s earlier argument) relies on Ronen Eldan’s stochastic localization, with a new ingredients being the functional-analytic approach from a paper by Klartag and Eli Putterman&lt;/p&gt;
&lt;p&gt;This is fantastic progress. Congratulations Bo&amp;#8217;az and Joseph!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; I was happy to learn that Arun Jambulapati, Yin Tat Lee, and Santosh S. Vempala further improved &lt;a href=&quot;https://arxiv.org/abs/2208.11644&quot;&gt;in this paper&lt;/a&gt; the exponent from 4 to 2.2226.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Gil Kalai&lt;/p&gt;
  </content>
    <author>
      <name>Gil Kalai</name>
      <uri>https://gilkalai.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Gil Kalai: Alef’s Corner: “It won’t work, sorry”</title>
    <link href="https://gilkalai.wordpress.com/2022/10/14/alefs-corner-it-wont-work-sorry/"/>
    <id>http://gilkalai.wordpress.com/?p=23386</id>
    <updated>2022-10-14T11:04:22+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;img data-attachment-id=&quot;23387&quot; data-permalink=&quot;https://gilkalai.wordpress.com/2022/10/14/alefs-corner-it-wont-work-sorry/giliwnw/&quot; data-orig-file=&quot;https://gilkalai.files.wordpress.com/2022/10/giliwnw.png&quot; data-orig-size=&quot;2100,2100&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;gilIWNW&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=300&quot; data-large-file=&quot;https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=640&quot; class=&quot;alignnone size-full wp-image-23387&quot; src=&quot;https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=640&quot; alt=&quot;gilIWNW&quot; srcset=&quot;https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=640 640w, https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=1280 1280w, https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=150 150w, https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=300 300w, https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=768 768w, https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=1024 1024w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;   /&gt;&lt;/p&gt;
&lt;p&gt;Alef thanks Nicolas Curien for the triangulation. &lt;a href=&quot;https://gilkalai.wordpress.com/tag/alefs-corner/&quot;&gt;Click here for other posts with Alef&amp;#8217;s art.&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Gil Kalai&lt;/p&gt;
  </content>
    <author>
      <name>Gil Kalai</name>
      <uri>https://gilkalai.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: The Fine-Grained Complexity of Graph Homomorphism Parameterized by Clique-Width</title>
    <link href="http://arxiv.org/abs/2210.06845"/>
    <id>http://arxiv.org/abs/2210.06845</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganian_R/0/1/0/all/0/1&quot;&gt;Robert Ganian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamm_T/0/1/0/all/0/1&quot;&gt;Thekla Hamm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korchemna_V/0/1/0/all/0/1&quot;&gt;Viktoriia Korchemna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Okrasa_K/0/1/0/all/0/1&quot;&gt;Karolina Okrasa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simonov_K/0/1/0/all/0/1&quot;&gt;Kirill Simonov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The generic homomorphism problem, which asks whether an input graph $G$
admits a homomorphism into a fixed target graph $H$, has been widely studied in
the literature. In this article, we provide a fine-grained complexity
classification of the running time of the homomorphism problem with respect to
the clique-width of $G$ (denoted $\operatorname{cw}$) for virtually all choices
of $H$ under the Strong Exponential Time Hypothesis. In particular, we identify
a property of $H$ called the signature number $s(H)$ and show that for each
$H$, the homomorphism problem can be solved in time
$\mathcal{O}^*(s(H)^{\operatorname{cw}})$. Crucially, we then show that this
algorithm can be used to obtain essentially tight upper bounds. Specifically,
we provide a reduction that yields matching lower bounds for each $H$ that is
either a projective core or a graph admitting a factorization with additional
properties -- allowing us to cover all possible target graphs under
long-standing conjectures.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Hard to Detect Factors of Univariate Integer Polynomials</title>
    <link href="http://arxiv.org/abs/2210.07030"/>
    <id>http://arxiv.org/abs/2210.07030</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dennunzio_A/0/1/0/all/0/1&quot;&gt;Alberto Dennunzio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Formenti_E/0/1/0/all/0/1&quot;&gt;Enrico Formenti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Margara_L/0/1/0/all/0/1&quot;&gt;Luciano Margara&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We investigate the computational complexity of deciding whether a given
univariate integer polynomial p(x) has a factor q(x) satisfying specific
additional constraints. When the only constraint imposed on q(x) is to have a
degree smaller than the degree of p(x) and greater than zero, the problem is
equivalent to testing the irreducibility of p(x) and then it is solvable in
polynomial time. We prove that deciding whether a given monic univariate
integer polynomial has factors satisfying additional properties may lead to
NP-complete problems in the strong sense. In particular, given any constant
value k in Z, we prove that it is NP-complete in the strong sense to detect the
existence of a factor that returns a prescribed value when evaluated at x=k or
to detect the existence of a pair of factors - whose product is equal to the
original polynomial - that return the same value when evaluated at x=k.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Towards Uniform Certification in QBF</title>
    <link href="http://arxiv.org/abs/2210.07085"/>
    <id>http://arxiv.org/abs/2210.07085</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chew_L/0/1/0/all/0/1&quot;&gt;Leroy Chew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Slivovsky_F/0/1/0/all/0/1&quot;&gt;Friedrich Slivovsky&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We pioneer a new technique that allows us to prove a multitude of previously
open simulations in QBF proof complexity. In particular, we show that extended
QBF Frege p-simulates clausal proof systems such as IR-Calculus, IRM-Calculus,
Long-Distance Q-Resolution, and Merge Resolution. These results are obtained by
taking a technique of Beyersdorff et al. (JACM 2020) that turns strategy
extraction into simulation and combining it with new local strategy extraction
arguments.
&lt;/p&gt;
&lt;p&gt;This approach leads to simulations that are carried out mainly in
propositional logic, with minimal use of the QBF rules. Our proofs therefore
provide a new, largely propositional interpretation of the simulated systems.
We argue that these results strengthen the case for uniform certification in
QBF solving, since many QBF proof systems now fall into place underneath
extended QBF Frege.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Computing the Best Case Energy Complexity of Satisfying Assignments in Monotone Circuits</title>
    <link href="http://arxiv.org/abs/2210.06739"/>
    <id>http://arxiv.org/abs/2210.06739</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1&quot;&gt;Janio Carlos Nascimento Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Souza_U/0/1/0/all/0/1&quot;&gt;U&amp;#xe9;verton S. Souza&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Measures of circuit complexity are usually analyzed to ensure the computation
of Boolean functions with economy and efficiency. One of these measures is
energy complexity, which is related to the number of gates that output true in
a circuit for an assignment. The idea behind energy complexity comes from the
counting of `firing&#39; neurons in a natural neural network. The initial model is
based on threshold circuits, but recent works also have analyzed the energy
complexity of traditional Boolean circuits. In this work, we discuss the time
complexity needed to compute the best-case energy complexity among satisfying
assignments of a monotone Boolean circuit, and we call such a problem as
MinEC$^+_M$. In the MinEC$^+_M$ problem, we are given a monotone Boolean
circuit $C$, a positive integer $k$ and asked to determine whether there is a
satisfying assignment $X$ for $C$ such that $EC(C,X) \leq k$, where $EC(C,X)$
is the number of gates that output true in $C$ according to the assignment $X$.
We prove that MinEC$^+_M$ is NP-complete even when the input monotone circuit
is planar. Besides, we show that the problem is W[1]-hard but in XP when
parameterized by the size of the solution. In contrast, we show that when the
size of the solution and the genus of the input circuit are aggregated
parameters, the MinEC$^+_M$ problem becomes fixed-parameter tractable.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Efficient Algorithms for Obnoxious Facility Location on a Line Segment or Circle</title>
    <link href="http://arxiv.org/abs/2210.07146"/>
    <id>http://arxiv.org/abs/2210.07146</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Bowei Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study different restricted variations of the obnoxious facility location
problem on a plane. The first is the constrained obnoxious facility location on
a line segment (COFL-Line) problem. We provide an efficient algorithm for this
problem that executes in $O(n ^ 2 \log k + n \log k \log (n^2 + k))$ time. Our
result improves on the best known result of $O((nk)^2 \log(nk) + (n + k) \log
(nk))$ time obtained by Singireddy and Basappa\cite{singireddy2022dispersing}.
We also study the same problem where the facilities must be placed on a given
circle (the constrained obnoxious facility location on a circle (COFL-Circ)
problem). We provide an efficient algorithm for this problem that executes in
$O(n ^ 2 \log k + n \log k \log (n^2 + k))$ time. Our result improves on the
best known result of $O((nk)^2 \log(nk) + (n + k) \log (nk))$ time obtained by
Singireddy and Basappa\cite{singireddy2022dispersing}. The third problem we
study is the min-sum obnoxious facility location (MOFL) problem.We provide an
efficient algorithm that executes in $O(nk\cdot \alpha(nk) \log^3 {nk})$ time,
where $\alpha(.)$ is the inverse Ackermann function. The best known previous
result is an $O(n^3k)$ time obtained by Singireddy and
Basappa\cite{singireddy2022dispersing}.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Exact and approximation algorithms for sensor placement against DDoS attacks</title>
    <link href="http://arxiv.org/abs/2210.06559"/>
    <id>http://arxiv.org/abs/2210.06559</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Junosza_Szaniawski_K/0/1/0/all/0/1&quot;&gt;Konstanty Junosza-Szaniawski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nogalski_D/0/1/0/all/0/1&quot;&gt;Dariusz Nogalski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rzazewski_P/0/1/0/all/0/1&quot;&gt;Pawe&amp;#x142; Rz&amp;#x105;&amp;#x17c;ewski&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a DDoS attack (Distributed Denial of Service), an attacker gains control
of many network users through a virus. Then the controlled users send many
requests to a victim, leading to its resources being depleted. DDoS attacks are
hard to defend because of their distributed nature, large scale and various
attack techniques. One possible mode of defense is to place sensors in a
network that can detect and stop an unwanted request. However, such sensors are
expensive so there is a natural question as to the minimum number of sensors
and the optimal placement required to get the necessary level of safety.
Presented below are two mixed integer models for optimal sensor placement
against DDoS attacks. Both models lead to a trade-off between the number of
deployed sensors and the volume of uncontrolled flow. Since the above placement
problems are NP-hard, two efficient heuristics are designed, implemented and
compared experimentally with exact mixed integer linear programming solvers.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Sample Constrained Treatment Effect Estimation</title>
    <link href="http://arxiv.org/abs/2210.06594"/>
    <id>http://arxiv.org/abs/2210.06594</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Addanki_R/0/1/0/all/0/1&quot;&gt;Raghavendra Addanki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arbour_D/0/1/0/all/0/1&quot;&gt;David Arbour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1&quot;&gt;Tung Mai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1&quot;&gt;Cameron Musco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1&quot;&gt;Anup Rao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Treatment effect estimation is a fundamental problem in causal inference. We
focus on designing efficient randomized controlled trials, to accurately
estimate the effect of some treatment on a population of $n$ individuals. In
particular, we study sample-constrained treatment effect estimation, where we
must select a subset of $s \ll n$ individuals from the population to experiment
on. This subset must be further partitioned into treatment and control groups.
Algorithms for partitioning the entire population into treatment and control
groups, or for choosing a single representative subset, have been well-studied.
The key challenge in our setting is jointly choosing a representative subset
and a partition for that set.
&lt;/p&gt;
&lt;p&gt;We focus on both individual and average treatment effect estimation, under a
linear effects model. We give provably efficient experimental designs and
corresponding estimators, by identifying connections to discrepancy
minimization and leverage-score-based sampling used in randomized numerical
linear algebra. Our theoretical results obtain a smooth transition to known
guarantees when $s$ equals the population size. We also empirically demonstrate
the performance of our algorithms.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On the Minimum Cycle Cover problem on graphs with bounded co-degeneracy</title>
    <link href="http://arxiv.org/abs/2210.06703"/>
    <id>http://arxiv.org/abs/2210.06703</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duarte_G/0/1/0/all/0/1&quot;&gt;Gabriel L. Duarte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Souza_U/0/1/0/all/0/1&quot;&gt;U&amp;#xe9;verton S. Souza&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In 2021, Duarte, Oliveira, and Souza [MFCS 2021] showed some problems that
are FPT when parameterized by the treewidth of the complement graph (called
co-treewidth). Since the degeneracy of a graph is at most its treewidth, they
also introduced the study of co-degeneracy (the degeneracy of the complement
graph) as a parameter. In 1976, Bondy and Chv\&#39;{a}tal [DM 1976] introduced the
notion of closure of a graph: let $\ell$ be an integer; the $(n+\ell)$-closure,
$\operatorname{cl}_{n+\ell}(G)$, of a graph $G$ with $n$ vertices is obtained
from $G$ by recursively adding an edge between pairs of nonadjacent vertices
whose degree sum is at least $n+\ell$ until no such pair remains. A graph
property $\Upsilon$ defined on all graphs of order $n$ is said to be
$(n+\ell)$-stable if for any graph $G$ of order $n$ that does not satisfy
$\Upsilon$, the fact that $uv$ is not an edge of $G$ and that $G+uv$ satisfies
$\Upsilon$ implies $d(u)+d(v)&amp;lt; n+\ell$. Duarte et al. [MFCS 2021] developed an
algorithmic framework for co-degeneracy parameterization based on the notion of
closures for solving problems that are $(n+\ell)$-stable for some $\ell$
bounded by a function of the co-degeneracy. In this paper, we first determine
the stability of the property of having a bounded cycle cover. After that,
combining the framework of Duarte et al. [MFCS 2021] with some results of
Jansen, Kozma, and Nederlof [WG 2019], we obtain a $2^{\mathcal{O}(k)}\cdot
n^{\mathcal{O}(1)}$-time algorithm for Minimum Cycle Cover on graphs with
co-degeneracy at most $k$, which generalizes Duarte et al. [MFCS 2021] and
Jansen et al. [WG 2019] results concerning the Hamiltonian Cycle problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Perfect matching cuts partitioning a graph into complementary subgraphs</title>
    <link href="http://arxiv.org/abs/2210.06714"/>
    <id>http://arxiv.org/abs/2210.06714</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castonguay_D/0/1/0/all/0/1&quot;&gt;Diane Castonguay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coelho_E/0/1/0/all/0/1&quot;&gt;Erika M. M. Coelho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coelho_H/0/1/0/all/0/1&quot;&gt;Hebert Coelho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nascimento_J/0/1/0/all/0/1&quot;&gt;Julliano R. Nascimento&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Souza_U/0/1/0/all/0/1&quot;&gt;U&amp;#xe9;verton S. Souza&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In Partition Into Complementary Subgraphs (Comp-Sub) we are given a graph
$G=(V,E)$, and an edge set property $\Pi$, and asked whether $G$ can be
decomposed into two graphs, $H$ and its complement $\overline{H}$, for some
graph $H$, in such a way that the edge cut $[V(H),V(\overline{H})]$ satisfies
the property $\Pi$. Motivated by previous work, we consider Comp-Sub($\Pi$)
when the property $\Pi=\mathcal{PM}$ specifies that the edge cut of the
decomposition is a perfect matching. We prove that Comp-Sub($\mathcal{PM}$) is
GI-hard when the graph $G$ is $\{C_{k\geq 7}, \overline{C}_{k\geq 7} \}$-free.
On the other hand, we show that Comp-Sub($\mathcal{PM}$) is polynomial-time
solvable on $hole$-free graphs and on $P_5$-free graphs. Furthermore, we
present characterizations of Comp-Sub($\mathcal{PM}$) on chordal,
distance-hereditary, and extended $P_4$-laden graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: On the Efficient Implementation of High Accuracy Optimality of Profile Maximum Likelihood</title>
    <link href="http://arxiv.org/abs/2210.06728"/>
    <id>http://arxiv.org/abs/2210.06728</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Charikar_M/0/1/0/all/0/1&quot;&gt;Moses Charikar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiang_Z/0/1/0/all/0/1&quot;&gt;Zhihao Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shiragur_K/0/1/0/all/0/1&quot;&gt;Kirankumar Shiragur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sidford_A/0/1/0/all/0/1&quot;&gt;Aaron Sidford&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We provide an efficient unified plug-in approach for estimating symmetric
properties of distributions given $n$ independent samples. Our estimator is
based on profile-maximum-likelihood (PML) and is sample optimal for estimating
various symmetric properties when the estimation error $\epsilon \gg n^{-1/3}$.
This result improves upon the previous best accuracy threshold of $\epsilon \gg
n^{-1/4}$ achievable by polynomial time computable PML-based universal
estimators [ACSS21, ACSS20]. Our estimator reaches a theoretical limit for
universal symmetric property estimation as [Han21] shows that a broad class of
universal estimators (containing many well known approaches including ours)
cannot be sample optimal for every $1$-Lipschitz property when $\epsilon \ll
n^{-1/3}$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: An $\alpha$-regret analysis of Adversarial Bilateral Trade</title>
    <link href="http://arxiv.org/abs/2210.06846"/>
    <id>http://arxiv.org/abs/2210.06846</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azar_Y/0/1/0/all/0/1&quot;&gt;Yossi Azar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fiat_A/0/1/0/all/0/1&quot;&gt;Amos Fiat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1&quot;&gt;Federico Fusco&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study sequential bilateral trade where sellers and buyers valuations are
completely arbitrary (i.e., determined by an adversary). Sellers and buyers are
strategic agents with private valuations for the good and the goal is to design
a mechanism that maximizes efficiency (or gain from trade) while being
incentive compatible, individually rational and budget balanced. In this paper
we consider gain from trade which is harder to approximate than social welfare.
&lt;/p&gt;
&lt;p&gt;We consider a variety of feedback scenarios and distinguish the cases where
the mechanism posts one price and when it can post different prices for buyer
and seller. We show several surprising results about the separation between the
different scenarios. In particular we show that (a) it is impossible to achieve
sublinear $\alpha$-regret for any $\alpha&amp;lt;2$, (b) but with full feedback
sublinear $2$-regret is achievable (c) with a single price and partial feedback
one cannot get sublinear $\alpha$ regret for any constant $\alpha$ (d)
nevertheless, posting two prices even with one-bit feedback achieves sublinear
$2$-regret, and (e) there is a provable separation in the $2$-regret bounds
between full and partial feedback.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Beeping Shortest Paths via Hypergraph Bipartite Decomposition</title>
    <link href="http://arxiv.org/abs/2210.06882"/>
    <id>http://arxiv.org/abs/2210.06882</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dufoulon_F/0/1/0/all/0/1&quot;&gt;Fabien Dufoulon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emek_Y/0/1/0/all/0/1&quot;&gt;Yuval Emek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gelles_R/0/1/0/all/0/1&quot;&gt;Ran Gelles&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Constructing a shortest path between two network nodes is a fundamental task
in distributed computing. This work develops schemes for the construction of
shortest paths in randomized beeping networks between a predetermined source
node and an arbitrary set of destination nodes. Our first scheme constructs a
(single) shortest path to an arbitrary destination in $O (D \log\log n + \log^3
n)$ rounds with high probability. Our second scheme constructs multiple
shortest paths, one per each destination, in $O (D \log^2 n + \log^3 n)$ rounds
with high probability.
&lt;/p&gt;
&lt;p&gt;The key technique behind the aforementioned schemes is a novel decomposition
of hypergraphs into bipartite hypergraphs. Namely, we show how to partition the
hyperedge set of a hypergraph $H = (V_H, E_H)$ into $k = \Theta (\log^2 n)$
disjoint subsets $F_1 \cup \cdots \cup F_k = E_H$ such that the
(sub-)hypergraph $(V_H, F_i)$ is bipartite in the sense that there exists a
vertex subset $U \subseteq V$ such that $|U \cap e| = 1$ for every $e \in F_i$.
This decomposition turns out to be instrumental in speeding up shortest path
constructions under the beeping model.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Delta-Closure Structure for Studying Data Distribution</title>
    <link href="http://arxiv.org/abs/2210.06926"/>
    <id>http://arxiv.org/abs/2210.06926</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buzmakov_A/0/1/0/all/0/1&quot;&gt;Aleksey Buzmakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makhalova_T/0/1/0/all/0/1&quot;&gt;Tatiana Makhalova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuznetsov_S/0/1/0/all/0/1&quot;&gt;Sergei O. Kuznetsov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Napoli_A/0/1/0/all/0/1&quot;&gt;Amedeo Napoli&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we revisit pattern mining and study the distribution
underlying a binary dataset thanks to the closure structure which is based on
passkeys, i.e., minimum generators in equivalence classes robust to noise. We
introduce $\Delta$-closedness, a generalization of the closure operator, where
$\Delta$ measures how a closed set differs from its upper neighbors in the
partial order induced by closure. A $\Delta$-class of equivalence includes
minimum and maximum elements and allows us to characterize the distribution
underlying the data. Moreover, the set of $\Delta$-classes of equivalence can
be partitioned into the so-called $\Delta$-closure structure. In particular, a
$\Delta$-class of equivalence with a high level demonstrates correlations among
many attributes, which are supported by more observations when $\Delta$ is
large. In the experiments, we study the $\Delta$-closure structure of several
real-world datasets and show that this structure is very stable for large
$\Delta$ and does not substantially depend on the data sampling used for the
analysis.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Online matching with delays and stochastic arrival times</title>
    <link href="http://arxiv.org/abs/2210.07018"/>
    <id>http://arxiv.org/abs/2210.07018</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mari_M/0/1/0/all/0/1&quot;&gt;Mathieu Mari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pawlowski_M/0/1/0/all/0/1&quot;&gt;Micha&amp;#x142; Paw&amp;#x142;owski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1&quot;&gt;Runtian Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sankowski_P/0/1/0/all/0/1&quot;&gt;Piotr Sankowski&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper presents a new research direction for the Min-cost Perfect
Matching with Delays (MPMD) - a problem introduced by Emek et al. (STOC&#39;16). In
the original version of this problem, we are given an $n$-point metric space,
where requests arrive in an online fashion. The goal is to minimise the
matching cost for an even number of requests. However, contrary to traditional
online matching problems, a request does not have to be paired immediately at
the time of its arrival. Instead, the decision of whether to match a request
can be postponed for time $t$ at a delay cost of $t$. For this reason, the goal
of the MPMD is to minimise the overall sum of distance and delay costs.
Interestingly, for adversarially generated requests, no online algorithm can
achieve a competitive ratio better than $O(\log n/\log \log n)$ (Ashlagi et
al., APPROX/RANDOM&#39;17).
&lt;/p&gt;
&lt;p&gt;Here, we consider a stochastic version of the MPMD problem where the input
requests follow a Poisson arrival process. For such a problem, we show that the
above lower bound can be improved by presenting two deterministic online
algorithms, which, in expectation, are constant-competitive. The first one is a
simple greedy algorithm that matches any two requests once the sum of their
delay costs exceeds their connection cost, i.e., the distance between them. The
second algorithm builds on the tools used to analyse the first one in order to
obtain even better performance guarantees. This result is rather surprising as
the greedy approach for the adversarial model achieves a competitive ratio of
$\Omega(m^{\log \frac{3}{2}+\varepsilon})$, where $m$ denotes the number of
requests served (Azar et al., TOCS&#39;20). Finally, we prove that it is possible
to obtain similar results for the general case when the delay cost follows an
arbitrary positive and non-decreasing function, as well as for the MPMD variant
with penalties to clear pending requests.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Threshold Treewidth and Hypertree Width</title>
    <link href="http://arxiv.org/abs/2210.07040"/>
    <id>http://arxiv.org/abs/2210.07040</id>
    <updated>2022-10-14T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schidler_A/0/1/0/all/0/1&quot;&gt;Andre Schidler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganian_R/0/1/0/all/0/1&quot;&gt;Robert Ganian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sorge_M/0/1/0/all/0/1&quot;&gt;Manuel Sorge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szeider_S/0/1/0/all/0/1&quot;&gt;Stefan Szeider&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Treewidth and hypertree width have proven to be highly successful structural
parameters in the context of the Constraint Satisfaction Problem (CSP). When
either of these parameters is bounded by a constant, then CSP becomes solvable
in polynomial time. However, here the order of the polynomial in the running
time depends on the width, and this is known to be unavoidable; therefore, the
problem is not fixed-parameter tractable parameterized by either of these width
measures. Here we introduce an enhancement of tree and hypertree width through
a novel notion of thresholds, allowing the associated decompositions to take
into account information about the computational costs associated with solving
the given CSP instance. Aside from introducing these notions, we obtain
efficient theoretical as well as empirical algorithms for computing threshold
treewidth and hypertree width and show that these parameters give rise to
fixed-parameter algorithms for CSP as well as other, more general problems. We
complement our theoretical results with experimental evaluations in terms of
heuristics as well as exact methods based on SAT/SMT encodings.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: How Not to Pass a Polygraph Test</title>
    <link href="http://blog.computationalcomplexity.org/2022/10/how-not-to-pass-polygraph-test.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-892869288985190689</id>
    <updated>2022-10-13T13:34:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbVRkVbxq4nkOBNugqs01If78vjWowLhCCowXwEXkJCHuST_xZVWQApkTScjld0Z8sDgxwU_R6AwWsKPB4gbiKYW--3TkWtcpZGV4N2skRt7tW2XvxBi5VRjWQKZcqigp8Ewp18q6MrZQUUq_Y09300z8muVgiVskef70PibPTlUGGb08V_w/s300/meet-the-parents-original-300x189.jpg&quot; imageanchor=&quot;1&quot; style=&quot;clear: left; float: left; margin-bottom: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;189&quot; data-original-width=&quot;300&quot; height=&quot;189&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbVRkVbxq4nkOBNugqs01If78vjWowLhCCowXwEXkJCHuST_xZVWQApkTScjld0Z8sDgxwU_R6AwWsKPB4gbiKYW--3TkWtcpZGV4N2skRt7tW2XvxBi5VRjWQKZcqigp8Ewp18q6MrZQUUq_Y09300z8muVgiVskef70PibPTlUGGb08V_w/s1600/meet-the-parents-original-300x189.jpg&quot; width=&quot;300&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;Many years ago I was asked to serve on an advisory board for an organization that did confidential research. To be on the board I had to have US top secret clearance. The first step was filling out a lengthy form which asked deep details about every aspect of my life. Then there were the interviews with myself and many people I interacted with, especially internationally, and I have many international colleagues. Eventually I got passed these steps.&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;The final step required taking a polygraph (lie-detector) test. So I flew to Baltimore to visit a non-descript office building near the airport. I failed the test. Twice more I went to Baltimore and failed those tests as well.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Just to be clear, I never tried to falsify or hide information on these tests. In one case I was asked &quot;Do you live in Atlanta?&quot; I said no. The person administering the test stopped and said I put my address down as Atlanta. I said my mailing address was Atlanta but (at the time) I lived just north of the border in Sandy Springs. She said I should use Atlanta for the test, in other words I should lie. The test didn&#39;t go well after that.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In another case, I was asked if I was ever arrested. For the record, I have never been arrested but the answer came up as inconclusive. The administrator, different than before, trusted the machine more than me and the rest of the day didn&#39;t go well.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Perhaps the test wasn&#39;t meant to just test whether I was telling the truth, but also my ability to keep a secret. At least that would make more sense why I failed three times. More likely I took questions too literally, a product of a mathematician&#39;s mind.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;I never joined the advisory board but that wasn&#39;t the worst of it. In 2014 the Chinese hacked into the US Office of Personnel Management taking information from, among others, those who applied for security clearance. It&#39;s the main reason I keep security freezes with the credit bureaus.&lt;/div&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Unitary property testing lower bounds by polynomials</title>
    <link href="http://arxiv.org/abs/2210.05885"/>
    <id>http://arxiv.org/abs/2210.05885</id>
    <updated>2022-10-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+She_A/0/1/0/all/0/1&quot;&gt;Adrian She&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yuen_H/0/1/0/all/0/1&quot;&gt;Henry Yuen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study unitary property testing, where a quantum algorithm is given query
access to a black-box unitary and has to decide whether it satisfies some
property. In addition to containing the standard quantum query complexity model
(where the unitary encodes a binary string) as a special case, this model
contains &quot;inherently quantum&quot; problems that have no classical analogue.
Characterizing the query complexity of these problems requires new algorithmic
techniques and lower bound methods.
&lt;/p&gt;
&lt;p&gt;Our main contribution is a generalized polynomial method for unitary property
testing problems. By leveraging connections with invariant theory, we apply
this method to obtain lower bounds on problems such as determining recurrence
times of unitaries, approximating the dimension of a marked subspace, and
approximating the entanglement entropy of a marked state. We also present a
unitary property testing-based approach towards an oracle separation between
$\mathsf{QMA}$ and $\mathsf{QMA(2)}$, a long standing question in quantum
complexity theory.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: A Note on Reachability and Distance Oracles for Transmission Graphs</title>
    <link href="http://arxiv.org/abs/2210.05788"/>
    <id>http://arxiv.org/abs/2210.05788</id>
    <updated>2022-10-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berg_M/0/1/0/all/0/1&quot;&gt;Mark de Berg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $P$ be a set of $n$ points in the plane, where each point $p\in P$ has a
transmission radius $r(p)&amp;gt;0$. The transmission graph defined by $P$ and the
given radii, denoted by $\mathcal{G}_{\mathrm{tr}}(P)$, is the directed graph
whose nodes are the points in $P$ and that contains the arcs $(p,q)$ such that
$|pq|\leq r(p)$.
&lt;/p&gt;
&lt;p&gt;An and Oh [Algorithmica 2022] presented a reachability oracle for
transmission graphs. Their oracle uses $O(n^{5/3})$ storage and, given two
query points $s,t\in P$, can decide in $O(n^{2/3})$ time if there is a path
from $s$ to $t$ in $\mathcal{G}_{\mathrm{tr}}(P)$. We show that the
clique-based separators introduced by De Berg \emph{et al.} [SICOMP 2020] can
be used to improve the storage of the oracle to $O(n\sqrt{n})$ and the query
time to $O(\sqrt{n})$. Our oracle can be extended to approximate distance
queries: we can construct, for a given parameter $\varepsilon&amp;gt;0$, an oracle
that uses $O((n/\varepsilon)\sqrt{n}\log n)$ storage and that can report in
$O((\sqrt{n}/\varepsilon)\log n)$ time a value $d_{\mathrm{hop}}^*(s,t)$
satisfying $d_{\mathrm{hop}}(s,t) \leq d_{\mathrm{hop}}^*(s,t) &amp;lt;
(1+\varepsilon)\cdot d_{\mathrm{hop}}(s,t) + 1$, where $d_{\mathrm{hop}}(s,t)$
is the hop-distance from $s$ to $t$. We also show how to extend the oracle to
so-called continuous queries, where the target point $t$ can be any point in
the plane.
&lt;/p&gt;
&lt;p&gt;To obtain an efficient preprocessing algorithm, we show that a clique-based
separator of a set~$F$ of convex fat objects in $\Bbb{R}^d$ can be constructed
in $O(n\log n)$ time.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Pattern Characterization Using Topological Data Analysis: Application to Piezo Vibration Striking Treatment</title>
    <link href="http://arxiv.org/abs/2210.06333"/>
    <id>http://arxiv.org/abs/2210.06333</id>
    <updated>2022-10-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chumley_M/0/1/0/all/0/1&quot;&gt;Max M. Chumley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yesilli_M/0/1/0/all/0/1&quot;&gt;Melih C. Yesilli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jisheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khasawneh_F/0/1/0/all/0/1&quot;&gt;Firas A. Khasawneh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yang Guo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Quantifying patterns in visual or tactile textures provides important
information about the process or phenomena that generated these patterns. In
manufacturing, these patterns can be intentionally introduced as a design
feature, or they can be a byproduct of a specific process. Since surface
texture has significant impact on the mechanical properties and the longevity
of the workpiece, it is important to develop tools for quantifying surface
patterns and, when applicable, comparing them to their nominal counterparts.
While existing tools may be able to indicate the existence of a pattern, they
typically do not provide more information about the pattern structure, or how
much it deviates from a nominal pattern. Further, prior works do not provide
automatic or algorithmic approaches for quantifying other pattern
characteristics such as depths&#39; consistency, and variations in the pattern
motifs at different level sets. This paper leverages persistent homology from
Topological Data Analysis (TDA) to derive noise-robust scores for quantifying
motifs&#39; depth and roundness in a pattern. Specifically, sublevel persistence is
used to derive scores that quantify the consistency of indentation depths at
any level set in Piezo Vibration Striking Treatment (PVST) surfaces. Moreover,
we combine sublevel persistence with the distance transform to quantify the
consistency of the indentation radii, and to compare them with the nominal
ones. Although the tool in our PVST experiments had a semi-spherical profile,
we present a generalization of our approach to tools/motifs of arbitrary shapes
thus making our method applicable to other pattern-generating manufacturing
processes.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: The Power of Two Matrices in Spectral Algorithms</title>
    <link href="http://arxiv.org/abs/2210.05893"/>
    <id>http://arxiv.org/abs/2210.05893</id>
    <updated>2022-10-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dhara_S/0/1/0/all/0/1&quot;&gt;Souvik Dhara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gaudio_J/0/1/0/all/0/1&quot;&gt;Julia Gaudio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mossel_E/0/1/0/all/0/1&quot;&gt;Elchanan Mossel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sandon_C/0/1/0/all/0/1&quot;&gt;Colin Sandon&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Spectral algorithms are some of the main tools in optimization and inference
problems on graphs. Typically, the graph is encoded as a matrix and
eigenvectors and eigenvalues of the matrix are then used to solve the given
graph problem. Spectral algorithms have been successfully used for graph
partitioning, hidden clique recovery and graph coloring. In this paper, we
study the power of spectral algorithms using two matrices in a graph
partitioning problem. We use two different matrices resulting from two
different encodings of the same graph and then combine the spectral information
coming from these two matrices.
&lt;/p&gt;
&lt;p&gt;We analyze a two matrix spectral algorithm for the problem of identifying
latent community structure in large random graphs. In particular, we consider
the problem of recovering community assignments exactly in the censored
stochastic block model, where each edge status is revealed independently with
some probability. We show that spectral algorithms based on two matrices are
optimal and succeed in recovering communities up to the information theory
threshold. On the other hand, we show that for most choices of the parameters,
any spectral algorithm based on one matrix is suboptimal. This is in contrast
to our prior works (2022a, 2022b) which showed that for the symmetric
Stochastic Block Model and the Planted Dense Subgraph problem, spectral
algorithm based on one matrix achieve the information theory threshold. Of
independent interest, we provide more general geometric conditions for the
(sub)-optimality of spectral algorithms, that are also applicable to cases when
there are more than two communities.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Resolving the Approximability of Offline and Online Non-monotone DR-Submodular Maximization over General Convex Sets</title>
    <link href="http://arxiv.org/abs/2210.05965"/>
    <id>http://arxiv.org/abs/2210.05965</id>
    <updated>2022-10-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mualem_L/0/1/0/all/0/1&quot;&gt;Loay Mualem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldman_M/0/1/0/all/0/1&quot;&gt;Moran Feldman&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In recent years, maximization of DR-submodular continuous functions became an
important research field, with many real-worlds applications in the domains of
machine learning, communication systems, operation research and economics. Most
of the works in this field study maximization subject to down-closed convex set
constraints due to an inapproximability result by Vondr\&#39;ak (2013). However,
Durr et al. (2021) showed that one can bypass this inapproximability by proving
approximation ratios that are functions of $m$, the minimum
$\ell_{\infty}$-norm of any feasible vector. Given this observation, it is
possible to get results for maximizing a DR-submodular function subject to
general convex set constraints, which has led to multiple works on this
problem. The most recent of which is a polynomial time $\tfrac{1}{4}(1 -
m)$-approximation offline algorithm due to Du (2022). However, only a
sub-exponential time $\tfrac{1}{3\sqrt{3}}(1 - m)$-approximation algorithm is
known for the corresponding online problem. In this work, we present a
polynomial time online algorithm matching the $\tfrac{1}{4}(1 -
m)$-approximation of the state-of-the-art offline algorithm. We also present an
inapproximability result showing that our online algorithm and Du&#39;s (2022)
offline algorithm are both optimal in a strong sense. Finally, we study the
empirical performance of our algorithm and the algorithm of Du (which was only
theoretically studied previously), and show that they consistently outperform
previously suggested algorithms on revenue maximization, location summarization
and quadratic programming applications.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Clustering Embedding Tables, Without First Learning Them</title>
    <link href="http://arxiv.org/abs/2210.05974"/>
    <id>http://arxiv.org/abs/2210.05974</id>
    <updated>2022-10-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsang_H/0/1/0/all/0/1&quot;&gt;Henry Ling-Hei Tsang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahle_T/0/1/0/all/0/1&quot;&gt;Thomas Dybdahl Ahle&lt;/a&gt;&lt;/p&gt;&lt;p&gt;To work with categorical features, machine learning systems employ embedding
tables. These tables can become exceedingly large in modern recommendation
systems, necessitating the development of new methods for fitting them in
memory, even during training.
&lt;/p&gt;
&lt;p&gt;Some of the most successful methods for table compression are Product- and
Residual Vector Quantization (Gray &amp;amp; Neuhoff, 1998). These methods replace
table rows with references to k-means clustered &quot;codewords.&quot; Unfortunately,
this means they must first know the table before compressing it, so they can
only save memory during inference, not training. Recent work has used
hashing-based approaches to minimize memory usage during training, but the
compression obtained is inferior to that obtained by &quot;post-training&quot;
quantization.
&lt;/p&gt;
&lt;p&gt;We show that the best of both worlds may be obtained by combining techniques
based on hashing and clustering. By first training a hashing-based &quot;sketch&quot;,
then clustering it, and then training the clustered quantization, our method
achieves compression ratios close to those of post-training quantization with
the training time memory reductions of hashing-based methods.
&lt;/p&gt;
&lt;p&gt;We show experimentally that our method provides better compression and/or
accuracy that previous methods, and we prove that our method always converges
to the optimal embedding table for least-squares training.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A nearly optimal randomized algorithm for explorable heap selection</title>
    <link href="http://arxiv.org/abs/2210.05982"/>
    <id>http://arxiv.org/abs/2210.05982</id>
    <updated>2022-10-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borst_S/0/1/0/all/0/1&quot;&gt;Sander Borst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dadush_D/0/1/0/all/0/1&quot;&gt;Daniel Dadush&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huiberts_S/0/1/0/all/0/1&quot;&gt;Sophie Huiberts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kashaev_D/0/1/0/all/0/1&quot;&gt;Danish Kashaev&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Explorable heap selection is the problem of selecting the $n$th smallest
value in a binary heap. The key values can only be accessed by traversing
through the underlying infinite binary tree, and the complexity of the
algorithm is measured by the total distance traveled in the tree (each edge has
unit cost). This problem was originally proposed as a model to study search
strategies for the branch-and-bound algorithm with storage restrictions by
Karp, Saks and Widgerson (FOCS &#39;86), who gave deterministic and randomized
$n\cdot \exp(O(\sqrt{\log{n}}))$ time algorithms using $O(\log(n)^{2.5})$ and
$O(\sqrt{\log n})$ space respectively. We present a new randomized algorithm
with running time $O(n\log(n)^3)$ using $O(\log n)$ space, substantially
improving the previous best randomized running time at the expense of slightly
increased space usage. We also show an $\Omega(\log(n)n/\log(\log(n)))$ for any
algorithm that solves the problem in the same amount of space, indicating that
our algorithm is nearly optimal.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Fast Convergence to Unanimity in Dense Erd\H{o}s-R\&#39;enyi Graphs</title>
    <link href="http://arxiv.org/abs/2210.05992"/>
    <id>http://arxiv.org/abs/2210.05992</id>
    <updated>2022-10-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tamir_R/0/1/0/all/0/1&quot;&gt;Ran Tamir&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Majority dynamics on the binomial Erd\H{o}s-R\&#39;enyi graph $\mathsf{G}(n,p)$
with $p=\lambda/\sqrt{n}$ is studied. In this process, each vertex has a state
in $\{0,1\}$ and at each round, every vertex adopts the state of the majority
of its neighbors, retaining its state in the case of a tie. It was conjectured
by Benjamini et al. and proved by Fountoulakis et al. that this process reaches
unanimity with high probability in at most four rounds. By adding some extra
randomness and allowing the underlying graph to be drawn anew in each
communication round, we improve on their result and prove that this process
reaches consensus in only three communication rounds with probability
approaching $1$ as $n$ grows to infinity. We also provide a converse result,
showing that three rounds are not only sufficient, but also necessary.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Non-smooth and H\&quot;older-smooth Submodular Maximization</title>
    <link href="http://arxiv.org/abs/2210.06061"/>
    <id>http://arxiv.org/abs/2210.06061</id>
    <updated>2022-10-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Duksang Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ho_Nguyen_N/0/1/0/all/0/1&quot;&gt;Nam Ho-Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Dabeen Lee&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the problem of maximizing a continuous DR-submodular function that
is not necessarily smooth. We prove that the continuous greedy algorithm
achieves an $[(1-1/e)\text{OPT}-\epsilon]$ guarantee when the function is
monotone and H\&quot;older-smooth, meaning that it admits a H\&quot;older-continuous
gradient. For functions that are non-differentiable or non-smooth, we propose a
variant of the mirror-prox algorithm that attains an
$[(1/2)\text{OPT}-\epsilon]$ guarantee. We apply our algorithmic frameworks to
robust submodular maximization and distrbituionally robust submodular
maximization under Wasserstein ambiguity. In particular, the mirror-prox method
applies to robust submodular maximization to obtain a single feasible solution
whose value is at least $(1/2)\text{OPT}-\epsilon$. For distributionally robust
maximization under Wasserstein ambiguity, we deduce and work over a
submodular-convex maximin reformulation whose objective function is
H\&quot;older-smooth, for which we may apply both the continuous greedy method and
the mirror-prox method.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Differentially Private Bootstrap: New Privacy Analysis and Inference Strategies</title>
    <link href="http://arxiv.org/abs/2210.06140"/>
    <id>http://arxiv.org/abs/2210.06140</id>
    <updated>2022-10-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhanyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1&quot;&gt;Guang Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Awan_J/0/1/0/all/0/1&quot;&gt;Jordan Awan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Differential private (DP) mechanisms protect individual-level information by
introducing randomness into the statistical analysis procedure. While there are
now many DP tools for various statistical problems, there is still a lack of
general techniques to understand the sampling distribution of a DP estimator,
which is crucial for uncertainty quantification in statistical inference. We
analyze a DP bootstrap procedure that releases multiple private bootstrap
estimates to infer the sampling distribution and construct confidence
intervals. Our privacy analysis includes new results on the privacy cost of a
single DP bootstrap estimate applicable to incorporate arbitrary DP mechanisms
and identifies some misuses of the bootstrap in the existing literature. We
show that the release of $B$ DP bootstrap estimates from mechanisms satisfying
$(\mu/\sqrt{(2-2/\mathrm{e})B})$-Gaussian DP asymptotically satisfies
$\mu$-Gaussian DP as $B$ goes to infinity. We also develop a statistical
procedure based on the DP bootstrap estimates to correctly infer the sampling
distribution using techniques related to the deconvolution of probability
measures, an approach which is novel in analyzing DP procedures. From our
density estimate, we construct confidence intervals and compare them to
existing methods through simulations and real-world experiments using the 2016
Canada Census Public Use Microdata. The coverage of our private confidence
intervals achieves the nominal confidence level, while other methods fail to
meet this guarantee.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Quantum Optimisation for Continuous Multivariable Functions by a Structured Search</title>
    <link href="http://arxiv.org/abs/2210.06227"/>
    <id>http://arxiv.org/abs/2210.06227</id>
    <updated>2022-10-13T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Matwiejew_E/0/1/0/all/0/1&quot;&gt;Edric Matwiejew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pye_J/0/1/0/all/0/1&quot;&gt;Jason Pye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jingbo B. Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Solving optimisation problems is a promising near-term application of quantum
computers. Quantum variational algorithms leverage quantum superposition and
entanglement to optimise over exponentially large solution spaces using an
alternating sequence of classically tunable unitaries. However, prior work has
primarily addressed discrete optimisation problems. In addition, these
algorithms have been designed generally under the assumption of an unstructured
solution space, which constrains their speedup to the theoretical limits for
the unstructured Grover&#39;s quantum search algorithm. In this paper, we show that
quantum variational algorithms can efficiently optimise continuous
multivariable functions by exploiting general structural properties of a
discretised continuous solution space with a convergence that exceeds the
limits of an unstructured quantum search. We introduce the Quantum
Multivariable Optimisation Algorithm (QMOA) and demonstrate its advantage over
pre-existing methods, particularly when optimising high-dimensional and
oscillatory functions.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Scott Aaronson: Explanation-Gödel and Plausibility-Gödel</title>
    <link href="https://scottaaronson.blog/?p=6754"/>
    <id>https://scottaaronson.blog/?p=6754</id>
    <updated>2022-10-12T21:52:31+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Here&amp;#8217;s an observation that&amp;#8217;s mathematically trivial but might not be widely appreciated.  In kindergarten, we all learned Gödel&amp;#8217;s First &lt;a href=&quot;https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems&quot;&gt;Incompleteness Theorem&lt;/a&gt;, which given a formal system F, constructs an arithmetical encoding of&lt;/p&gt;



&lt;p&gt;G(F) = &amp;#8220;This sentence is not provable in F.&amp;#8221;&lt;/p&gt;



&lt;p&gt;If G(F) is true, then it&amp;#8217;s an example of a true arithmetical sentence that&amp;#8217;s unprovable in F.  If, on the other hand, G(F) is false, then it&amp;#8217;s provable, which means that F isn&amp;#8217;t arithmetically sound.  Therefore F is either incomplete or unsound.&lt;/p&gt;



&lt;p&gt;Many have objected: &amp;#8220;but despite Gödel&amp;#8217;s Theorem, it&amp;#8217;s still easy to &lt;em&gt;explain &lt;/em&gt;why G(F) is true.  In fact, the argument above basically already did it!”&lt;/p&gt;



&lt;p&gt;[Note: Please stop leaving comments explaining to me that G(F) follows from F’s consistency.  I understand that: the “heuristic” part of the argument &lt;em&gt;is&lt;/em&gt; F’s consistency!  I made a pedagogical choice to elide that, which nerd-sniping has now rendered untenable.]&lt;/p&gt;



&lt;p&gt;You might make a more general point: there are many, many mathematical statements for which we currently lack a proof, but we do seem to have a fully convincing heuristic explanation: one that &amp;#8220;proves the statement to physics standards of rigor.&amp;#8221;  For example:&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Twin_prime&quot;&gt;Twin Primes Conjecture&lt;/a&gt; (there are infinitely many primes p for which p+2 is also prime).  &lt;/li&gt;&lt;li&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Collatz_conjecture&quot;&gt;Collatz Conjecture&lt;/a&gt; (the iterative process that maps each positive integer n to n/2 if n is even, or to 3n+1 if n is odd, eventually reaches 1 regardless of which n you start at).  &lt;/li&gt;&lt;li&gt;π is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Normal_number&quot;&gt;normal number&lt;/a&gt; (or even just: the digits 0-9 all occur with equal limiting frequencies in the decimal expansion of π).&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://math.stackexchange.com/questions/159350/why-is-it-hard-to-prove-whether-pie-is-an-irrational-number&quot;&gt;π+e&lt;/a&gt; is irrational.&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;And so on.  No one has any idea how to prove any of the above statements&amp;#8212;and yet, just on statistical grounds, it seems clear that it would require a ludicrous conspiracy to make any of them false.&lt;/p&gt;



&lt;p&gt;Conversely, one could argue that there are statements for which we &lt;em&gt;do&lt;/em&gt; have a proof, even though we lack a &amp;#8220;convincing explanation&amp;#8221; for the statements&amp;#8217; truth.  Maybe the &lt;a href=&quot;https://en.wikipedia.org/wiki/Four_color_theorem&quot;&gt;Four-Color Theorem&lt;/a&gt; or &lt;a href=&quot;https://en.wikipedia.org/wiki/Kepler_conjecture&quot;&gt;Hales&amp;#8217;s Theorem&lt;/a&gt;, for which every known proof requires a massive computer enumeration of cases, belong to this class.  Other people might argue that, given a proof, an explanation could always be extracted with enough time and effort, though resolving this dispute won&amp;#8217;t matter for what follows.&lt;/p&gt;



&lt;p&gt;You might hope that, even if some true mathematical statements can&amp;#8217;t be &lt;em&gt;proved&lt;/em&gt;, every true statement might nevertheless have a &lt;em&gt;convincing heuristic explanation&lt;/em&gt;.  Alas, a trivial adaptation of Gödel&amp;#8217;s Theorem shows that, if (1) heuristic explanations are to be checkable by computer, and (2) only true statements are to have convincing heuristic explanations, then this isn&amp;#8217;t possible either.  I mean, let E be a program that accepts or rejects proposed heuristic explanations, for statements like the Twin Prime Conjecture or the Collatz Conjecture.  Then construct the sentence&lt;/p&gt;



&lt;p&gt;S(E) = &amp;#8220;This sentence has no convincing heuristic explanation accepted by E.&amp;#8221;&lt;/p&gt;



&lt;p&gt;If S(E) is true, then it&amp;#8217;s an example of a true arithmetical statement without &lt;em&gt;even&lt;/em&gt; a convincing heuristic explanation for its truth (!).  If, on the other hand, S(E) is false, then there&amp;#8217;s a convincing heuristic explanation of its truth, which means that something has gone wrong.&lt;/p&gt;



&lt;p&gt;What&amp;#8217;s happening, of course, is that given the two conditions we imposed, our &amp;#8220;heuristic explanation system&amp;#8221; &lt;em&gt;was&lt;/em&gt; a proof system, even though we didn&amp;#8217;t call it one.  This is my point, though: when we use the word &amp;#8220;proof,&amp;#8221; it normally invokes a specific image, of a sequence of statements that marches from axioms to a theorem, with each statement following from the preceding ones by rigid inference rules like those of first-order logic.  None of that, however, plays any direct role in the proof of the Incompleteness Theorem, which cares only about soundness (inability to prove falsehoods) and checkability by a computer (what, with hindsight, Gödel&amp;#8217;s &amp;#8220;arithmetization of syntax&amp;#8221; was all about).  The logic works for &amp;#8220;heuristic explanations&amp;#8221; too.&lt;/p&gt;



&lt;p&gt;Now we come to something that I picked up from my former student (and now AI alignment leader) &lt;a href=&quot;https://paulfchristiano.com/&quot;&gt;Paul Christiano&lt;/a&gt;, on a recent trip to the Bay Area, and which I share with Paul&amp;#8217;s kind permission.  Having learned that there&amp;#8217;s no way to mechanize even heuristic explanations for all the true statements of arithmetic, we could set our sights lower still, and ask about mere &lt;em&gt;plausibility arguments&lt;/em&gt;&amp;#8212;arguments that might be overturned on further reflection.  Is there some sense in which every true mathematical statement at least has a good plausibility argument?&lt;/p&gt;



&lt;p&gt;Maybe you see where this is going.  Letting P be a program that accepts or rejects proposed plausibility arguments, we can construct&lt;/p&gt;



&lt;p&gt;S(P) = &amp;#8220;This sentence has no argument for its plausibility accepted by P.&amp;#8221;&lt;/p&gt;



&lt;p&gt;If S(P) is true, then it&amp;#8217;s an example of a true arithmetical statement without even a plausibility argument for its truth (!).  If, on the other hand, S(P) is false, then there &lt;em&gt;is&lt;/em&gt; a plausibility argument for it.  By itself, this is &lt;em&gt;not at all&lt;/em&gt; a fatal problem: all sorts of false statements (IP≠PSPACE, switching doors doesn&amp;#8217;t matter in &lt;a href=&quot;https://en.wikipedia.org/wiki/Monty_Hall_problem&quot;&gt;Monty Hall&lt;/a&gt;, Trump couldn&amp;#8217;t possibly become president&amp;#8230;) have had decent plausibility arguments.  Having said that, it&amp;#8217;s pretty strange that you can have a plausibility argument that&amp;#8217;s immediately contradicted by its own existence!  This rules out some properties that you might want your &amp;#8220;plausibility system&amp;#8221; to have, although maybe a plausibility system exists that&amp;#8217;s still nontrivial and that has weaker properties.&lt;/p&gt;



&lt;p&gt;Anyway, I don&amp;#8217;t know where I&amp;#8217;m going with this, or even why I posted it, but I hope you enjoyed it!  And maybe there&amp;#8217;s something to be discovered in this direction.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </content>
    <author>
      <name>Scott Aaronson</name>
      <uri>https://scottaaronson.blog</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Postdoc researcher at ENS Paris (apply by October 31, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/10/12/postdoc-researcher-at-ens-paris-apply-by-october-31-2022/"/>
    <id>http://cstheory-jobs.org/2022/10/12/postdoc-researcher-at-ens-paris-apply-by-october-31-2022/</id>
    <updated>2022-10-12T14:44:31+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The PARSe project funded by ANR (France) opens one postdoc position at ENS Paris, hosted by Tatiana Starikovskaya. The postdoc researcher will contribute efficient tools for processing large-scale, noisy string data. The post will require a high level of expertise in areas which may include but not be limited to string algorithms and streaming / property testing algorithms.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://euraxess.ec.europa.eu/jobs/842793&quot;&gt;https://euraxess.ec.europa.eu/jobs/842793&lt;/a&gt;&lt;br /&gt;
Email: starikovskaya@di.ens.fr&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Parameterized Approaches to Orthogonal Compaction</title>
    <link href="http://arxiv.org/abs/2210.05019"/>
    <id>http://arxiv.org/abs/2210.05019</id>
    <updated>2022-10-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Didimo_W/0/1/0/all/0/1&quot;&gt;Walter Didimo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1&quot;&gt;Siddharth Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kindermann_P/0/1/0/all/0/1&quot;&gt;Philipp Kindermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liotta_G/0/1/0/all/0/1&quot;&gt;Giuseppe Liotta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolff_A/0/1/0/all/0/1&quot;&gt;Alexander Wolff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zehavi_M/0/1/0/all/0/1&quot;&gt;Meirav Zehavi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Orthogonal graph drawings are used in applications such as UML diagrams, VLSI
layout, cable plans, and metro maps. We focus on drawing planar graphs and
assume that we are given an \emph{orthogonal representation} that describes the
desired shape, but not the exact coordinates of a drawing. Our aim is to
compute an orthogonal drawing on the grid that has minimum area among all grid
drawings that adhere to the given orthogonal representation.
&lt;/p&gt;
&lt;p&gt;This problem is called orthogonal compaction (OC) and is known to be NP-hard,
even for orthogonal representations of cycles [Evans et al., 2022]. We
investigate the complexity of OC with respect to several parameters. Among
others, we show that OC is fixed-parameter tractable with respect to the most
natural of these parameters, namely, the number of \emph{kitty corners} of the
orthogonal representation: the presence of pairs of kitty corners in an
orthogonal representation makes the OC problem hard. Informally speaking, a
pair of kitty corners is a pair of reflex corners of a face that point at each
other. Accordingly, the number of kitty corners is the number of corners that
are involved in some pair of kitty corners.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Crack Modeling via Minimum-Weight Surfaces in 3d Voronoi Diagrams</title>
    <link href="http://arxiv.org/abs/2210.05093"/>
    <id>http://arxiv.org/abs/2210.05093</id>
    <updated>2022-10-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_C/0/1/0/all/0/1&quot;&gt;Christian Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Redenbach_C/0/1/0/all/0/1&quot;&gt;Claudia Redenbach&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Shortest paths play an important role in mathematical modeling and image
processing. Usually, shortest path problems are formulated on planar graphs
that consist of vertices and weighted arcs. In this context, one is interested
in finding a path of minimum weight from a start vertex to an end vertex. The
concept of minimum-weight surfaces extends shortest paths to 3d. The
minimum-weight surface problem is formulated on a cellular complex with
weighted facets. A cycle on the arcs of the complex serves as input and one is
interested in finding a surface of minimum weight bounded by that cycle. In
practice, minimum-weight surfaces can be used to segment 3d images. Vice versa,
it is possible to use them as a modeling tool for geometric structures such as
cracks. In this work, we present an approach for using minimum-weight surfaces
in bounded Voronoi diagrams to generate synthetic 3d images of cracks.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Persistence Diagram Bundles: A Multidimensional Generalization of Vineyards</title>
    <link href="http://arxiv.org/abs/2210.05124"/>
    <id>http://arxiv.org/abs/2210.05124</id>
    <updated>2022-10-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hickok_A/0/1/0/all/0/1&quot;&gt;Abigail Hickok&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A persistence diagram (PD) summarizes the persistent homology of a
filtration. I introduce the concept of a persistence diagram bundle, which is
the space of PDs associated with a fibered filtration function (a set $\{f_t:
\mathcal{K}^t \to \mathbb{R}\}_{t \in \mathcal{T}}$ of filtrations
parameterized by a topological space $\mathcal{T}$). Special cases include
vineyards, the persistent homology transform, and fibered barcodes of
multiparameter persistence modules. I prove that if $\mathcal{T}$ is a compact
$n$-dimensional manifold, then for generic fibered filtration functions,
$\mathcal{T}$ is stratified such that within each $n$-dimensional stratum $S$,
there is a single PD &quot;template&quot; (a list of birth and death simplices) that can
be used to obtain $PD(f_t)$ for any $t \in S$. I also show that not every local
section can be extended to a global section. Consequently, the points in the
PDs do not typically trace out separate manifolds as $t \in \mathcal{T}$
varies; this is unlike a vineyard, in which the points in the PDs trace out
curves (&quot;vines&quot;).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Morphing Planar Graph Drawings Through 3D</title>
    <link href="http://arxiv.org/abs/2210.05384"/>
    <id>http://arxiv.org/abs/2210.05384</id>
    <updated>2022-10-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buchin_K/0/1/0/all/0/1&quot;&gt;Kevin Buchin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_W/0/1/0/all/0/1&quot;&gt;Will Evans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frati_F/0/1/0/all/0/1&quot;&gt;Fabrizio Frati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kostitsyna_I/0/1/0/all/0/1&quot;&gt;Irina Kostitsyna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loffler_M/0/1/0/all/0/1&quot;&gt;Maarten L&amp;#xf6;ffler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ophelders_T/0/1/0/all/0/1&quot;&gt;Tim Ophelders&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolff_A/0/1/0/all/0/1&quot;&gt;Alexander Wolff&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we investigate crossing-free 3D morphs between planar
straight-line drawings. We show that, for any two (not necessarily
topologically equivalent) planar straight-line drawings of an $n$-vertex planar
graph, there exists a piecewise-linear crossing-free 3D morph with $O(n^2)$
steps that transforms one drawing into the other. We also give some evidence
why it is difficult to obtain a linear lower bound (which exists in 2D) for the
number of steps of a crossing-free 3D morph.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Hierarchical Categories in Colored Searching</title>
    <link href="http://arxiv.org/abs/2210.05403"/>
    <id>http://arxiv.org/abs/2210.05403</id>
    <updated>2022-10-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Afshani_P/0/1/0/all/0/1&quot;&gt;Peyman Afshani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Killman_R/0/1/0/all/0/1&quot;&gt;Rasmus Killman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1&quot;&gt;Kasper Green Larsen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In colored range counting (CRC), the input is a set of points where each
point is assigned a ``color&#39;&#39; (or a ``category&#39;&#39;) and the goal is to store them
in a data structure such that the number of distinct categories inside a given
query range can be counted efficiently. CRC has strong motivations as it allows
data structure to deal with categorical data. However, colors (i.e., the
categories) in the CRC problem do not have any internal structure, whereas this
is not the case for many datasets in practice where hierarchical categories
exists or where a single input belongs to multiple categories. Motivated by
these, we consider variants of the problem where such structures can be
represented. We define two variants of the problem called hierarchical range
counting (HCC) and sub-category colored range counting (SCRC) and consider
hierarchical structures that can either be a DAG or a tree. We show that the
two problems on some special trees are in fact equivalent to other well-known
problems in the literature. Based on these, we also give efficient data
structures when the underlying hierarchy can be represented as a tree. We show
a conditional lower bound for the general case when the existing hierarchy can
be any DAG, through reductions from the orthogonal vectors problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: A Hierarchical Grouping Algorithm for the Multi-Vehicle Dial-a-Ride Problem</title>
    <link href="http://arxiv.org/abs/2210.05000"/>
    <id>http://arxiv.org/abs/2210.05000</id>
    <updated>2022-10-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_K/0/1/0/all/0/1&quot;&gt;Kelin Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Florio_A/0/1/0/all/0/1&quot;&gt;Alexandre M. Florio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1&quot;&gt;Syamantak Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1&quot;&gt;Xiangyu Guo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Ride-sharing is an essential aspect of modern urban mobility. In this paper,
we consider a classical problem in ride-sharing - the Multi-Vehicle Dial-a-Ride
Problem (Multi-Vehicle DaRP). Given a fleet of vehicles with a fixed capacity
stationed at various locations and a set of ride requests specified by origins
and destinations, the goal is to serve all requests such that no vehicle is
assigned more passengers than its capacity at any point along its trip. We
propose an algorithm HRA, which is the first non-trivial approximation
algorithm for the Multi-Vehicle DaRP. The main technical contribution is to
reduce the Multi-Vehicle DaRP to a certain capacitated partitioning problem,
which we solve using a novel hierarchical grouping algorithm. Experimental
results show that the vehicle routes produced by our algorithm not only exhibit
less total travel distance compared to state-of-the-art baselines, but also
enjoy a small in-transit latency, which crucially relates to riders&#39; traveling
times. This suggests that HRA enhances rider experience while being
energy-efficient.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Evaluation of the Quality of Exercises for the Data Structures&#39; eTextbook and Find the Difficult Topics Using Item Response Theory and Logged Data Analysis</title>
    <link href="http://arxiv.org/abs/2210.05294"/>
    <id>http://arxiv.org/abs/2210.05294</id>
    <updated>2022-10-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elrahman_A/0/1/0/all/0/1&quot;&gt;Ahmed Abd Elrahman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soliman_T/0/1/0/all/0/1&quot;&gt;Taysir Hassan A Soliman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farghally_M/0/1/0/all/0/1&quot;&gt;Mohammed F. Farghally&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taloba_A/0/1/0/all/0/1&quot;&gt;Ahmed I. Taloba&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The growing dependence on eTextbooks and Massive Open Online Courses (MOOCs)
has led to an increase in the amount of students&#39; learning data. By carefully
analyzing this data, educators can identify difficult exercises, and evaluate
the quality of the exercises when teaching a particular topic. In this study,
an analysis of log data from the use of a semester of the OpenDSA eTextbook was
offered to identify the most difficult data structure course exercises and to
evaluate the quality of the course exercises. Our study is based on analyzing
students&#39; responses to the course exercises. To identify the difficult
exercises, we applied two different approaches, the first of which involved
analyzing student responses to exercises using item response theory (IRT)
analysis and a latent trait model (LTM) technique, and the second involved
determining which exercises were more difficult based on how students
interacted with them. We computed different measures for every exercise such
that difficulty level, trial and error, and hint ratio. We generated an item
characteristics curve, item information curve, and test information function
for each exercise. To evaluate the quality of the exercises, we applied the IRT
analysis to the students&#39; responses to the exercises and, we computed the
difficulty and discrimination index for each exercise. We classified whether
the exercise is good or poor based on these two measures. Our findings showed
that the exercises that related to algorithm analysis topics represented most
of the difficult exercises that students struggle with, and there existing six
exercises out of 56 exercises are classified as poor exercises which could be
rejected or improved. Some of these poor exercises do not differentiate between
students with different abilities; the others give preference to low-ability
students to answer these exercises over high-ability students.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Enhancing Branch-and-Bound for Multi-Objective 0-1 Programming</title>
    <link href="http://arxiv.org/abs/2210.05385"/>
    <id>http://arxiv.org/abs/2210.05385</id>
    <updated>2022-10-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Forget_N/0/1/0/all/0/1&quot;&gt;Nicolas Forget&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parragh_S/0/1/0/all/0/1&quot;&gt;Sophie N. Parragh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the bi-objective branch-and-bound literature, a key ingredient is
objective branching, i.e. to create smaller and disjoint sub-problems in the
objective space, obtained from the partial dominance of the lower bound set by
the upper bound set. When considering three or more objective functions,
however, applying objective branching becomes more complex, and its benefit has
so far been unclear. In this paper, we investigate several ingredients which
allow to better exploit objective branching in a multi-objective setting. We
extend the idea of probing to multiple objectives, enhance it in several ways,
and show that when coupled with objective branching, it results in significant
speed-ups in terms of CPU times. We also investigate cut generation based on
the objective branching constraints. Besides, we generalize the best-bound idea
for node selection to multiple objectives and we show that the proposed rules
outperform the, in the multi-objective literature, commonly employed
depth-first and breadth-first strategies. We also analyze problem specific
branching rules. We test the proposed ideas on available benchmark instances
for three problem classes with three and four objectives, namely the
capacitated facility location problem, the uncapacitated facility location
problem, and the knapsack problem. Our enhanced multi-objective
branch-and-bound algorithm outperforms the best existing branch-and-bound based
approach and is the first to obtain competitive and even slightly better
results than a state-of-the-art objective space search method on a subset of
the problem classes.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Parallel solutions for preemptive makespan scheduling on two identical machines</title>
    <link href="http://arxiv.org/abs/2210.05543"/>
    <id>http://arxiv.org/abs/2210.05543</id>
    <updated>2022-10-12T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Epstein_L/0/1/0/all/0/1&quot;&gt;Leah Epstein&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider online preemptive scheduling of jobs arriving one by one, to be
assigned to two identical machines, with the goal of makespan minimization. We
study the effect of selecting the best solution out of two independent
solutions constructed in parallel in an online fashion. Two cases are analyzed,
where one case is purely online, and in the other one jobs are presented sorted
by non-increasing sizes. We show that using two solutions rather than one
improves the performance significantly, but that an optimal solution cannot be
obtained for any constant number of solutions constructed in parallel. Our
algorithms have the best possible competitive ratios out of algorithms for each
one of the classes.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Property Testing Review: News for September 2022</title>
    <link href="https://ptreview.sublinear.info/2022/10/news-for-september-2022/"/>
    <id>https://ptreview.sublinear.info/?p=1763</id>
    <updated>2022-10-11T23:31:03+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Apologies for the delay! Another quiet month in the property testing world, with only one paper (that we found). If we missed any, let us know in the comments!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;On Interactive Proofs of Proximity with Proof-Oblivious Queries&lt;/strong&gt;, by Oded Goldreich, Guy Rothblum, and Tal Skverer (&lt;a href=&quot;https://eccc.weizmann.ac.il/report/2022/124/&quot;&gt;ECCC&lt;/a&gt;). Interactive Proofs of Proximity (IPPs) are the &amp;#8220;interactive&amp;#8221; version of property testers, where the algorithm can both query the input and interact with an all-knowing (but untrusted) prover. In this work, the authors study the power of a specific and natural type of &amp;#8220;adaptivity&amp;#8221; for IPPs, asking what happens when the choice of queries and the interaction with the prover are independent, or restricted. That is, what happens when these two aspects of the IPP algorithm are in separate &amp;#8220;modules&amp;#8221;? Can we still test various properties as efficiently? The paper proves various results in under several models (=restrictions between the two &amp;#8220;modules&amp;#8221;), focusing on the intermediate restriction where the two modules (queries to the input and interaction with the prover) are separate (no interaction), but have access to shared randomness.&lt;/p&gt;



&lt;p&gt;&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Clement Canonne&lt;/p&gt;
  </content>
    <author>
      <name>Property Testing Review</name>
      <uri>https://ptreview.sublinear.info</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Principal Researcher (postdoctoral) at The University of Chicago (apply by January 14, 2023)</title>
    <link href="https://cstheory-jobs.org/2022/10/11/principal-researcher-postdoctoral-at-the-university-of-chicago-apply-by-january-14-2023/"/>
    <id>http://cstheory-jobs.org/2022/10/11/principal-researcher-postdoctoral-at-the-university-of-chicago-apply-by-january-14-2023/</id>
    <updated>2022-10-11T19:39:19+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The candidate will be given the opportunity to pursue a broad research agenda with Prof. Bryon Aragam at the intersection of statistics and machine learning and will ideally have a background in at least one of the following areas: latent variable models, deep generative models, causal inference, nonparametric statistics, learning theory, or graphical models.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.chicagobooth.edu/-/media/faculty/research-professional-program/job-ads/2022-23/principal_researcher_aragam_announcement_2022.pdf&quot;&gt;https://www.chicagobooth.edu/-/media/faculty/research-professional-program/job-ads/2022-23/principal_researcher_aragam_announcement_2022.pdf&lt;/a&gt;&lt;br /&gt;
Email: bryon@chicagobooth.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Gil Kalai: Test Your intuition 51</title>
    <link href="https://gilkalai.wordpress.com/2022/10/11/test-your-intuition-51/"/>
    <id>http://gilkalai.wordpress.com/?p=23377</id>
    <updated>2022-10-11T09:05:53+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;/p&gt;



&lt;p&gt;&lt;/p&gt;


&lt;p&gt;Suppose that &lt;img src=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;K&quot; class=&quot;latex&quot; /&gt; and &lt;img src=&quot;https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;L&quot; class=&quot;latex&quot; /&gt; are two compact convex sets in space. Suppose that &lt;img src=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;K&quot; class=&quot;latex&quot; /&gt; &lt;span style=&quot;color:#0000ff;&quot;&gt;&lt;strong&gt;contains&lt;/strong&gt;&lt;/span&gt; &lt;img src=&quot;https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;L&quot; class=&quot;latex&quot; /&gt;. Now consider two quantities&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=X&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=X&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;X&quot; class=&quot;latex&quot; /&gt; is the average volume of a simplex forms by four points in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;K&quot; class=&quot;latex&quot; /&gt; drawn uniformly at random.&lt;/li&gt;
&lt;li&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=Y&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=Y&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;Y&quot; class=&quot;latex&quot; /&gt; is the average volume of a simplex forms by four points in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;L&quot; class=&quot;latex&quot; /&gt; drawn uniformly at random.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;TYI: Is it always the case that X ≥ Y?&lt;/h3&gt;&lt;p class=&quot;authors&quot;&gt;By Gil Kalai&lt;/p&gt;
  </content>
    <author>
      <name>Gil Kalai</name>
      <uri>https://gilkalai.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Postdoc  at Technion (apply by December 31, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/10/11/postdoc-at-technion-apply-by-december-31-2022/"/>
    <id>http://cstheory-jobs.org/2022/10/11/postdoc-at-technion-apply-by-december-31-2022/</id>
    <updated>2022-10-11T08:13:20+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;Candidates with a strong publication record in top venues in distributed computing (broadly interpreted) or algorithms in general are welcome to apply. To apply, send the following to Mrs. Hila Mizrahi at hilamiz@cs.technion.ac.il: 1. CV (PDF)&lt;br /&gt;
2. 1-2 page research statement (PDF)&lt;br /&gt;
3. Contact details of 3 references (email plaintext)&lt;br /&gt;
4. Expected graduation date, if applicable (email plaintext)&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://ckeren.net.technion.ac.il/&quot;&gt;https://ckeren.net.technion.ac.il/&lt;/a&gt;&lt;br /&gt;
Email: hilamiz@cs.technion.ac.il&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Edge deletion to tree-like graph classes</title>
    <link href="http://arxiv.org/abs/2210.03839"/>
    <id>http://arxiv.org/abs/2210.03839</id>
    <updated>2022-10-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koch_I/0/1/0/all/0/1&quot;&gt;Ivo Koch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pardal_N/0/1/0/all/0/1&quot;&gt;Nina Pardal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_V/0/1/0/all/0/1&quot;&gt;Vinicius Fernandes dos Santos&lt;/a&gt;&lt;/p&gt;&lt;p&gt;For a fixed property (graph class) $\Pi$, given a graph $G$ and an integer
$k$, the $\Pi$-deletion problem consists in deciding if we can turn $G$ into a
graph with the property $\Pi$ by deleting at most $k$ edges of $G$. The
$\Pi$-deletion problem is known to be NP-hard for most of the well-studied
graph classes (such as chordal, interval, bipartite, planar, comparability and
permutation graphs, among others), with the notable exception of trees.
Motivated by this fact, in this work we study the deletion problem for some
classes close to trees. We obtain NP-hardness results for several classes of
sparse graphs, for which we prove that deletion is hard even when the input is
a bipartite graph. In addition, we give sufficient structural conditions for
the graph class $\Pi$ for NP-hardness. In the case of deletion to cactus, we
show that the problem becomes tractable when the input is chordal, and we give
polynomial-time algorithms for quasi-threshold graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Automata Equipped with Auxiliary Data Structures and Regular Realizability Problems</title>
    <link href="http://arxiv.org/abs/2210.03934"/>
    <id>http://arxiv.org/abs/2210.03934</id>
    <updated>2022-10-11T00:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rubtsov_A/0/1/0/all/0/1&quot;&gt;Alexander Rubtsov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vyalyi_M/0/1/0/all/0/1&quot;&gt;Mikhail Vyalyi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider general computational models: one-way and two-way finite
automata, and logarithmic space Turing machines, all equipped with an auxiliary
data structure (ADS). The definition of an ADS is based on the language of
protocols of work with the ADS. We describe the connection of automata-based
models with ``Balloon automata&#39;&#39; that are another general formalization of
automata equipped with an ADS presented by Hopcroft and Ullman in 1967.
&lt;/p&gt;
&lt;p&gt;This definition establishes the connection between the non-emptiness problem
for one-way automata with ADS, languages recognizable by nondeterministic
log-space Turing machines equipped with the same ADS, and a regular
realizability problem (NRR) for the language of ADS&#39; protocols. The NRR problem
is to verify whether the regular language on the input has a non-empty
intersection with the language of protocols. The computational complexity of
these problems (and languages) is the same up to log-space reductions.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


</feed>
