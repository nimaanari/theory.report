<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Theory of Computing Report</title>
  <link rel="self" href=""/>
  <link href=""/>
  <id></id>
  <updated></updated>
  <generator uri="http://feedreader.github.io/">Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]</generator>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Quantum Cryptography in Algorithmica</title>
    <link href="http://arxiv.org/abs/2212.00879"/>
    <id>http://arxiv.org/abs/2212.00879</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kretschmer_W/0/1/0/all/0/1&quot;&gt;William Kretschmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Qian_L/0/1/0/all/0/1&quot;&gt;Luowen Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sinha_M/0/1/0/all/0/1&quot;&gt;Makrand Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Tal_A/0/1/0/all/0/1&quot;&gt;Avishay Tal&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We construct a classical oracle relative to which $\mathsf{P} = \mathsf{NP}$
yet single-copy secure pseudorandom quantum states exist. In the language of
Impagliazzo&#39;s five worlds, this is a construction of pseudorandom states in
&quot;Algorithmica,&quot; and hence shows that in a black-box setting, quantum
cryptography based on pseudorandom states is possible even if one-way functions
do not exist. As a consequence, we demonstrate that there exists a property of
a cryptographic hash function that simultaneously (1) suffices to construct
pseudorandom states, (2) holds for a random oracle, and (3) is independent of
$\mathsf{P}$ vs. $\mathsf{NP}$ in the black-box setting. We also introduce a
conjecture that would generalize our results to multi-copy secure pseudorandom
states.
&lt;/p&gt;
&lt;p&gt;We build on the recent construction by Aaronson, Ingram, and Kretschmer (CCC
2022) of an oracle relative to which $\mathsf{P} = \mathsf{NP}$ but
$\mathsf{BQP} \neq \mathsf{QCMA}$, based on hardness of the OR $\circ$
Forrelation problem. Our proof also introduces a new discretely-defined variant
of the Forrelation distribution, for which we prove pseudorandomness against
$\mathsf{AC^0}$ circuits. This variant may be of independent interest.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Identifying the reach from high-dimensional point cloud data with connections to r-convexity</title>
    <link href="http://arxiv.org/abs/2212.01013"/>
    <id>http://arxiv.org/abs/2212.01013</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cotsakis_R/0/1/0/all/0/1&quot;&gt;Ryan Cotsakis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The convexity of a set can be generalized to the two weaker notions of reach
and $r$-convexity; both describe the regularity of a set&#39;s boundary. In this
article, these two notions are shown to be equivalent for closed subsets of
$\mathbb{R}^d$ with $C^1$ smooth, $(d-1)$-dimensional boundary. In the general
case, for closed subsets of $\mathbb{R}^d$, we detail a new characterization of
the reach in terms of the distance-to-set function applied to midpoints of
pairs of points in the set. For compact subsets of $\mathbb{R}^d$, we provide
methods of approximating the reach and $r$-convexity based on high-dimensional
point cloud data. These methods are intuitive and highly tractable, and produce
upper bounds that converge to the respective quantities as the density of the
point cloud is increased. Simulation studies suggest that the rates at which
the approximation methods converge correspond to those established
theoretically.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: The medial axis of closed bounded sets is Lipschitz stable with respect to the Hausdorff distance under ambient diffeomorphisms</title>
    <link href="http://arxiv.org/abs/2212.01118"/>
    <id>http://arxiv.org/abs/2212.01118</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kourimska_H/0/1/0/all/0/1&quot;&gt;Hana Dal Poz Kou&amp;#x159;imsk&amp;#xe1;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lieutier_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; Lieutier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wintraecken_M/0/1/0/all/0/1&quot;&gt;Mathijs Wintraecken&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We prove that the medial axis of closed sets is Hausdorff stable in the
following sense: Let $\mathcal{S} \subseteq \mathbb{R}^d$ be (fixed) closed set
(that contains a bounding sphere). Consider the space of $C^{1,1}$
diffeomorphisms of $\mathbb{R}^d$ to itself, which keep the bounding sphere
invariant. The map from this space of diffeomorphisms (endowed with some Banach
norm) to the space of closed subsets of $\mathbb{R}^d$ (endowed with the
Hausdorff distance), mapping a diffeomorphism $F$ to the closure of the medial
axis of $F(\mathcal{S})$, is Lipschitz. This extends a previous stability
result of Chazal and Soufflet on the stability of the medial axis of $C^2$
manifolds under $C^2$ ambient diffeomorphisms.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Sometimes Two Irrational Guards are Needed</title>
    <link href="http://arxiv.org/abs/2212.01211"/>
    <id>http://arxiv.org/abs/2212.01211</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meijer_L/0/1/0/all/0/1&quot;&gt;Lucas Meijer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miltzow_T/0/1/0/all/0/1&quot;&gt;Tillmann Miltzow&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the art gallery problem, we are given a closed polygon $P$, with rational
coordinates and an integer $k$. We are asked whether it is possible to find a
set (of guards) $G$ of size $k$ such that any point $p\in P$ is seen by a point
in $G$. We say two points $p$, $q$ see each other if the line segment $pq$ is
contained inside $P$. It was shown by Abrahamsen, Adamaszek, and Miltzow that
there is a polygon that can be guarded with three guards, but requires four
guards if the guards are required to have rational coordinates. In other words,
an optimal solution of size three might need to be irrational. We show that an
optimal solution of size two might need to be irrational. Note that it is
well-known that any polygon that can be guarded with one guard has an optimal
guard placement with rational coordinates. Hence, our work closes the gap on
when irrational guards are possible to occur.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Disjoint faces in simple drawings of the complete graph and topological Heilbronn problems</title>
    <link href="http://arxiv.org/abs/2212.01311"/>
    <id>http://arxiv.org/abs/2212.01311</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hubard_A/0/1/0/all/0/1&quot;&gt;Alfredo Hubard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Suk_A/0/1/0/all/0/1&quot;&gt;Andrew Suk&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a complete simple topological graph $G$, a $k$-face generated by $G$ is
the open bounded region enclosed by the edges of a non-self-intersecting
$k$-cycle in $G$. Interestingly, there are complete simple topological graphs
with the property that every odd face it generates contains the origin. In this
paper, we show that every complete $n$-vertex simple topological graph
generates at least $\Omega(n^{1/3})$ pairwise disjoint 4-faces. As an immediate
corollary, every complete simple topological graph on $n$ vertices drawn in the
unit square generates a 4-face with area at most $O(n^{-1/3})$. Finally, we
investigate a $\mathbb Z_2$ variant of Heilbronn triangle problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Trie-Compressed Intersectable Sets</title>
    <link href="http://arxiv.org/abs/2212.00946"/>
    <id>http://arxiv.org/abs/2212.00946</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arroyuelo_D/0/1/0/all/0/1&quot;&gt;Diego Arroyuelo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castillo_J/0/1/0/all/0/1&quot;&gt;Juan Pablo Castillo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce space- and time-efficient algorithms and data structures for the
offline set intersection problem. We show that a sorted integer set $S
\subseteq [0{..}u)$ of $n$ elements can be represented using compressed space
while supporting $k$-way intersections in adaptive
$O(k\delta\lg{\!(u/\delta)})$ time, $\delta$ being the alternation measure
introduced by Barbay and Kenyon. Our experimental results suggest that our
approaches are competitive in practice, outperforming the most efficient
alternatives (Partitioned Elias-Fano indexes, Roaring Bitmaps, and Recursive
Universe Partitioning (RUP)) in several scenarios, offering in general relevant
space-time trade-offs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Bin Packing with Partition Matroid can be Approximated within $o(OPT)$ Bins</title>
    <link href="http://arxiv.org/abs/2212.01025"/>
    <id>http://arxiv.org/abs/2212.01025</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doron_Arad_I/0/1/0/all/0/1&quot;&gt;Ilan Doron-Arad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulik_A/0/1/0/all/0/1&quot;&gt;Ariel Kulik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shachnai_H/0/1/0/all/0/1&quot;&gt;Hadas Shachnai&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the Bin Packing problem with a partition matroid constraint. The
input is a set of items of sizes in $(0,1]$, and a partition matroid over the
items. The goal is to pack all items in a minimum number of unit-size bins,
such that each bin forms an independent set in the matroid. The problem is a
generalization of both Group Bin Packing and Bin Packing with Cardinality
Constraints. Bin Packing with Partition Matroid naturally arises in resource
allocation to ensure fault tolerance and security, as well as in harvesting
computing capacity. Our main result is a polynomial-time algorithm that packs
the items in $OPT + o(OPT)$ bins, where OPT is the minimum number of bins
required for packing the given instance. This matches the best known result for
the classic Bin Packing problem up to the function hidden by o(OPT). As special
cases, our result improves upon the existing APTAS for Group Bin Packing and
generalizes the AFTPAS for Bin Packing with Cardinality Constraints. Our
approach is based on rounding a solution for a configuration-LP formulation of
the problem. The rounding takes a novel point of view of prototypes in which
items are interpreted as placeholders for other items and applies fractional
grouping to modify a fractional solution (prototype) into one having nice
integrality properties.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Computing the optimal BWT of very large string collections</title>
    <link href="http://arxiv.org/abs/2212.01156"/>
    <id>http://arxiv.org/abs/2212.01156</id>
    <updated>2022-12-05T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cenzato_D/0/1/0/all/0/1&quot;&gt;Davide Cenzato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerrini_V/0/1/0/all/0/1&quot;&gt;Veronica Guerrini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liptak_Z/0/1/0/all/0/1&quot;&gt;Zsuzsanna Lipt&amp;#xe1;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosone_G/0/1/0/all/0/1&quot;&gt;Giovanna Rosone&lt;/a&gt;&lt;/p&gt;&lt;p&gt;It is known that the exact form of the Burrows-Wheeler-Transform (BWT) of a
string collection depends, in most implementations, on the input order of the
strings in the collection. Reordering strings of an input collection affects
the number of equal-letter runs $r$, arguably the most important parameter of
BWT-based data structures, such as the FM-index or the $r$-index. Bentley,
Gibney, and Thankachan [ESA 2020] introduced a linear-time algorithm for
computing the permutation of the input collection which yields the minimum
number of runs of the resulting BWT.
&lt;/p&gt;
&lt;p&gt;In this paper, we present the first tool that guarantees a
Burrows-Wheeler-Transform with minimum number of runs (optBWT), by combining i)
an algorithm that builds the BWT from a string collection (either SAIS-based
[Cenzato et al., SPIRE 2021] or BCR [Bauer et al., CPM 2011]); ii) the SAP
array data structure introduced in [Cox et al., Bioinformatics, 2012]; and iii)
the algorithm by Bentley et al.
&lt;/p&gt;
&lt;p&gt;We present results both on real-life and simulated data, showing that the
improvement achieved in terms of $r$ with respect to the input order is
significant and the overhead created by the computation of the optimal BWT
negligible, making our tool competitive with other tools for BWT-computation in
terms of running time and space usage. In particular, on real data the optBWT
obtains up to 31 times fewer runs with only a $1.39\times$ slowdown.
&lt;/p&gt;
&lt;p&gt;Source code is available at https://github.com/davidecenzato/optimalBWT.git.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-176 |  The power of the Binary Value Principle | 

	Yaroslav Alekseev, 

	Edward Hirsch</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/176"/>
    <id>https://eccc.weizmann.ac.il/report/2022/176</id>
    <updated>2022-12-04T04:21:35+00:00</updated>
    <content type="html" xml:lang="en">
    The (extended) Binary Value Principle (eBVP, the equation $\sum x_i 2^{i-1} = -k$ for $k &amp;gt; 0$
and in the presence of $x_i^2=x_i$) has received a lot of attention recently, several lower
bounds have been proved for it [Alekseev et al 20, Alekseev 21, Part and Tzameret 21]. 
Also it has been shown [Alekseev et al 20] that the 
probabilistically verifiable Ideal Proof System (IPS) [Grochow and Pitassi 18] together with eBVP
polynomially simulates a similar semialgebraic proof system. In this paper we consider
Polynomial Calculus with the algebraic version of Tseitin’s extension rule (Ext-PC). Contrary
to IPS, this is a Cook--Reckhow proof system. We show that in this context eBVP still allows
to simulate similar semialgebraic systems. We also prove that it allows to simulate the
Square Root Rule [Grigoriev and Hirsch 03], which is in sharp contrast with the result of [Alekseev 21] that shows
an exponential lower bound on the size of Ext-PC derivations of the Binary Value Principle
from its square. On the other hand, we demonstrate that eBVP probably does not help in
proving exponential lower bounds for Boolean formulas: we show that an Ext-PC (even with
the Square Root Rule) derivation of any unsatisfiable Boolean formula in CNF from eBVP
must be of exponential size.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-175 |  Derandomization Under Different Resource Constraints | 

	Samuel Epstein</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/175"/>
    <id>https://eccc.weizmann.ac.il/report/2022/175</id>
    <updated>2022-12-04T04:19:03+00:00</updated>
    <content type="html" xml:lang="en">
    We provide another proof to the EL Theorem. We show the tradeoff between compressibility of codebooks and their communication capacity. A resource bounded version of the EL Theorem is proven. This is used to prove three instances of resource bounded derandomization.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-174 |  Noisy Radio Network Lower Bounds Via Noiseless Beeping Lower Bounds | 

	Raghuvansh Saxena, 

	Gillat Kol, 

	Klim Efremenko, 

	Dmitry Paramonov</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/174"/>
    <id>https://eccc.weizmann.ac.il/report/2022/174</id>
    <updated>2022-12-04T04:13:34+00:00</updated>
    <content type="html" xml:lang="en">
    Much of today&amp;#39;s communication is carried out over large wireless systems with different input-output behaviors. In this work, we compare the power of central abstractions of wireless communication through the general notion of boolean symmetric $f$-channels: In every round of the $f$-channel, each of its $n$ parties decides to either broadcast or not, and the channel outputs $f(m)$, where $m$ is the number of broadcasting parties.

Our first result is that the well studied beeping channel, where $f$ is the threshold-$1$ function, is not stronger than any other $f$-channel. To this end, we design a protocol over the $f$-channel and prove that any protocol that simulates it over the beeping channel blows up the round complexity by a factor of $\Omega(\log n)$. Our lower bound technique may be of independent interest, as it essentially generalizes the popular fooling set technique by exploiting a &amp;quot;local&amp;quot; relaxation of combinatorial rectangles.

Curiously, while this result shows the limitations of a noiseless channel, namely, the beeping channel, we are able to use it to show the limitations of the noisy version of many other channels. This includes the extensively studied single-hop radio network model with collisions-as-silence (CAS), which is equivalent to the $f$-channel with $f(m)=1$ iff $m=1$.

In particular, our second and main result, obtained from the first, shows that converting CAS protocols to noise resilient ones may incur a large performance overhead, i.e., no constant rate interactive code exists. To this end, we design a CAS protocol and prove that any protocol that simulates it over the noisy CAS model with correlated stochastic noise, blows up the round complexity by a factor of $\Omega(\log n)$. We mention that the $\Omega(\log n)$ overhead in both our results is tight.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">TOC for Fairness: Our 2023 Postdoc Program is up</title>
    <link href="https://toc4fairness.org/our-2023-postdoc-program-is-up/"/>
    <id>https://toc4fairness.org/?p=2387</id>
    <updated>2022-12-03T19:20:43+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;/p&gt;



&lt;p&gt;The &lt;a href=&quot;https://toc4fairness.org/&quot; data-type=&quot;URL&quot; data-id=&quot;https://toc4fairness.org/&quot;&gt;Simons collaboration on the theory of algorithmic fairness&lt;/a&gt; is excited to announce &lt;a href=&quot;https://toc4fairness.org/postdoc-opportunities/&quot; data-type=&quot;URL&quot; data-id=&quot;https://toc4fairness.org/postdoc-opportunities/&quot;&gt;our new postdoc program&lt;/a&gt;. We are seeking strong candidates from a diverse set of academic backgrounds and personal experiences who want to work with one or more of the PIs on algorithmic fairness and responsible computing more broadly. We expect to be extending multiple offers.  &lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Omer Reingold&lt;/p&gt;
  </content>
    <author>
      <name>TOC for Fairness</name>
      <uri>https://toc4fairness.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Postdoc in combinatorial optimization at University of Copenhagen (apply by January 15, 2023)</title>
    <link href="https://cstheory-jobs.org/2022/12/03/postdoc-in-combinatorial-optimization-at-university-of-copenhagen-apply-by-january-15-2023/"/>
    <id>http://cstheory-jobs.org/2022/12/03/postdoc-in-combinatorial-optimization-at-university-of-copenhagen-apply-by-january-15-2023/</id>
    <updated>2022-12-03T11:49:30+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The CS department at the University of Copenhagen invites applications for postdoc positions in combinatorial optimization. The application deadline is January 15. See &lt;a href=&quot;http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230115.html&quot;&gt;http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230115.html&lt;/a&gt; for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to jn@di.ku.dk.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230115.html&quot;&gt;http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230115.html&lt;/a&gt;&lt;br /&gt;
Email: jn@di.ku.dk&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">TCS+ Seminar Series: TCS+ “Test of Time” talk: Wednesday, December 7 — Ronitt Rubinfeld, MIT and Tel Aviv University</title>
    <link href="https://tcsplus.wordpress.com/2022/12/03/tcs-test-of-time-talk-wednesday-december-7-ronitt-rubinfeld-mit-and-tel-aviv-university/"/>
    <id>http://tcsplus.wordpress.com/?p=658</id>
    <updated>2022-12-03T05:33:48+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;&lt;/p&gt;


&lt;p&gt;The next TCS+ talk will take place this coming Wednesday, December 7th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). &lt;a href=&quot;https://people.csail.mit.edu/ronitt/&quot;&gt;&lt;strong&gt;Ronitt Rubinfeld&lt;/strong&gt;&lt;/a&gt; from MIT and Tel Aviv University will give our very first &amp;#8220;Test of Time&amp;#8221; talk, titled &amp;#8220;&lt;em&gt;A Comedy of Errors&lt;/em&gt;&amp;#8221; (abstract below).&lt;/p&gt;
&lt;p&gt;You can reserve a spot as an individual or a group to join us live by signing up on &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/next-tcs-talk&quot;&gt;the online form&lt;/a&gt;. Registration is &lt;em&gt;not&lt;/em&gt; required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/past-talks&quot;&gt;on our website&lt;/a&gt; afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/suggest-a-talk&quot;&gt;suggest&lt;/a&gt; a possible topic or speaker, please see &lt;a href=&quot;https://sites.google.com/view/tcsplus/&quot;&gt;the website&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;Abstract: In the late 1980s, a new model of &amp;#8220;Program Checking&amp;#8221; was put forth by Blum and Kannan in order to prevail over errors in programs. With that as a starting point, several lines of research developed &amp;#8212; including one that eventually morphed into the area of sublinear time algorithms. Along the way, errors were made and others were detected. We will recount a personal view of the arbitrary nature of this process and place it in historical context.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The talk will be followed by an unrecorded &amp;#8220;Ask Me Anything&amp;#8221; (AMA) session.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;&lt;p class=&quot;authors&quot;&gt;By plustcs&lt;/p&gt;
  </content>
    <author>
      <name>TCS+ Seminar Series</name>
      <uri>https://tcsplus.wordpress.com</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Simons-Berkeley Research Fellowships at Simons Institute (apply by December 15, 2022)</title>
    <link href="https://cstheory-jobs.org/2022/12/03/simons-berkeley-research-fellowships-at-simons-institute-apply-by-december-15-2022/"/>
    <id>http://cstheory-jobs.org/2022/12/03/simons-berkeley-research-fellowships-at-simons-institute-apply-by-december-15-2022/</id>
    <updated>2022-12-03T02:40:31+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;[Deadline Reminder] The Simons Institute for the Theory of Computing invites applications for Simons-Berkeley Research Fellowships for the Summer 2023, Fall 2023, and Spring 2024 semesters. The deadline for receipt of applications is December 15, 2022.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications&quot;&gt;https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications&lt;/a&gt;&lt;br /&gt;
Email: simonsvisitorservices@berkeley.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Scott Aaronson: Google&amp;#8217;s Sycamore chip: no wormholes, no superfast classical simulation either</title>
    <link href="https://scottaaronson.blog/?p=6871"/>
    <id>https://scottaaronson.blog/?p=6871</id>
    <updated>2022-12-02T23:04:15+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;div class=&quot;wp-block-image&quot;&gt;
&lt;figure class=&quot;aligncenter size-large&quot;&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://www.scottaaronson.com/sycamore.jpg&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;This is going to be one of the many &lt;em&gt;Shtetl-Optimized&lt;/em&gt; posts that I didn&amp;#8217;t feel like writing, but was given no choice but to write.&lt;/p&gt;



&lt;p&gt;News, social media, and my inbox have been abuzz with two claims about Google&amp;#8217;s Sycamore quantum processor, the one that now has 72 superconducting qubits.&lt;/p&gt;



&lt;p&gt;The first claim is that Sycamore created a wormhole (!)&amp;#8212;a historic feat possible only with a quantum computer.  See for example the &lt;em&gt;&lt;a href=&quot;https://www.nytimes.com/2022/11/30/science/physics-wormhole-quantum-computer.html&quot;&gt;New York Times&lt;/a&gt;&lt;/em&gt; and &lt;em&gt;&lt;a href=&quot;https://www.quantamagazine.org/physicists-create-a-wormhole-using-a-quantum-computer-20221130/&quot;&gt;Quanta&lt;/a&gt;&lt;/em&gt; and &lt;em&gt;&lt;a href=&quot;https://arstechnica.com/science/2022/12/no-physicists-didnt-make-a-real-wormhole-what-they-did-was-still-pretty-cool/&quot;&gt;Ars Technica&lt;/a&gt;&lt;/em&gt; and &lt;em&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-022-03832-z&quot;&gt;Nature&lt;/a&gt;&lt;/em&gt; (and of course, the &lt;a href=&quot;https://www.nature.com/articles/s41586-022-05424-3&quot;&gt;actual paper&lt;/a&gt;), as well as &lt;a href=&quot;https://www.math.columbia.edu/~woit/wordpress/?p=13181&quot;&gt;Peter Woit&amp;#8217;s blog&lt;/a&gt; and &lt;a href=&quot;https://chadorzel.substack.com/p/wormhole-to-2006&quot;&gt;Chad Orzel&amp;#8217;s blog&lt;/a&gt;.&lt;/p&gt;



&lt;p&gt;The second claim is that Sycamore&amp;#8217;s pretensions to quantum supremacy have been refuted.  The latter claim is based on &lt;a href=&quot;https://arxiv.org/abs/2211.03999&quot;&gt;this recent preprint&lt;/a&gt; by Dorit Aharonov, Xun Gao, Zeph Landau, Yunchao Liu, and Umesh Vazirani.  No one&amp;#8212;least of all me!&amp;#8212;doubts that these authors have proved a strong new technical result, solving a significant open problem in the theory of noisy random circuit sampling.  On the other hand, it might be less obvious how to interpret their result and put it in context.  See also a &lt;a href=&quot;https://www.youtube.com/watch?v=zDnA1gu4QO0&quot;&gt;YouTube video&lt;/a&gt; of Yunchao speaking about the new result at this week&amp;#8217;s Simons Institute Quantum Colloquium, and of a panel discussion afterwards, where Yunchao, Umesh Vazirani, Adam Bouland, Sergio Boixo, and your humble blogger discuss what it means.&lt;/p&gt;



&lt;p&gt;On their face, the two claims about Sycamore might seem to be in tension.  After all, if Sycamore can&amp;#8217;t do anything beyond what a classical computer can do, then how exactly did it &lt;em&gt;bend the topology of spacetime&lt;/em&gt;?&lt;/p&gt;



&lt;p&gt;I submit that neither claim is true.  On the one hand, Sycamore did not &amp;#8220;create a wormhole.&amp;#8221;  On the other hand, it remains pretty hard to simulate with a classical computer, as far as anyone knows.  To summarize, then, our knowledge of what Sycamore can and can&amp;#8217;t do remains much the same as last week or last month!&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;Let&amp;#8217;s start with the wormhole thing.  I can&amp;#8217;t really improve over how I put it in Dennis Overbye&amp;#8217;s &lt;em&gt;NYT&lt;/em&gt; piece:&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;“The most important thing I’d want New York Times readers to understand is this,” Scott Aaronson, a quantum computing expert at the University of Texas in Austin, wrote in an email. “If this experiment has brought a wormhole into actual physical existence, then a strong case could be made that you, too, bring a wormhole into actual physical existence every time you sketch one with pen and paper.”&lt;/p&gt;
&lt;/blockquote&gt;



&lt;p&gt;More broadly, Overbye&amp;#8217;s &lt;em&gt;NYT&lt;/em&gt; piece explains with admirable clarity what this experiment did and didn&amp;#8217;t do&amp;#8212;leaving only the question &amp;#8220;wait &amp;#8230; if that&amp;#8217;s all that&amp;#8217;s going on here, then why is it being written up in the &lt;em&gt;NYT&lt;/em&gt;??&amp;#8221;  This is a rare case where, in my opinion, the &lt;em&gt;NYT&lt;/em&gt; did a much better job than &lt;em&gt;Quanta&lt;/em&gt;, which unequivocally accepted and amplified the &amp;#8220;QC creates a wormhole&amp;#8221; framing.&lt;/p&gt;



&lt;p&gt;Alright, but what&amp;#8217;s the actual basis for the &amp;#8220;QC creates a wormhole&amp;#8221; claim, for those who don&amp;#8217;t want to leave this blog to read about it?  Well, the authors used 9 of Sycamore&amp;#8217;s 72 qubits to do a crude simulation of something called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sachdev%E2%80%93Ye%E2%80%93Kitaev_model&quot;&gt;SYK (Sachdev-Ye-Kitaev) model&lt;/a&gt;.  SYK has become popular as a toy model for quantum gravity.  In particular, it has a holographic dual description, which can indeed involve a spacetime with one or more wormholes.  So, they ran a quantum circuit that crudely modelled the SYK dual of a scenario with information sent through a wormhole.  They then confirmed that the circuit did what it was supposed to do&amp;#8212;i.e., what they’d already classically calculated that it &lt;em&gt;would&lt;/em&gt; do.&lt;/p&gt;



&lt;p&gt;So, the objection is obvious: if someone simulates a black hole on their classical computer, they don&amp;#8217;t say they thereby &amp;#8220;created a black hole.&amp;#8221;  Or if they do, journalists don&amp;#8217;t uncritically repeat the claim.  Why should the standards be different just because we&amp;#8217;re talking about a quantum computer rather than a classical one?&lt;/p&gt;



&lt;p&gt;Did we at least &lt;em&gt;learn anything new&lt;/em&gt; about SYK wormholes from the simulation?  Alas, not really, because 9 qubits take a mere 2&lt;sup&gt;9&lt;/sup&gt;=512 complex numbers to specify their wavefunction, and are therefore trivial to simulate on a laptop.  There&amp;#8217;s some argument in the paper that, if the simulation were scaled up to (say) 100 qubits, then maybe we &lt;em&gt;would&lt;/em&gt; learn something new about SYK.  Even then, however, we&amp;#8217;d mostly learn about certain corrections that arise &lt;em&gt;because&lt;/em&gt; the simulation was being done with &amp;#8220;only&amp;#8221; n=100 qubits, rather than in the n→∞ limit where SYK is rigorously understood.  But while those corrections, arising when n is &amp;#8220;neither too large nor too small,&amp;#8221; would surely be interesting to specialists, they&amp;#8217;d have no obvious bearing on the prospects for creating real physical wormholes in our universe.&lt;/p&gt;



&lt;p&gt;And yet, this is not a sensationalistic misunderstanding invented by journalists.  Some prominent quantum gravity theorists themselves&amp;#8212;including some of my close friends and collaborators&amp;#8212;persist in talking about the simulated SYK wormhole as &amp;#8220;actually being&amp;#8221; a wormhole.  What are they thinking?&lt;/p&gt;



&lt;p&gt;Daniel Harlow explained the thinking to me as follows (he stresses that he&amp;#8217;s explaining it, not necessarily endorsing it).  If you had two entangled quantum computers, one on Earth and the other in the Andromeda galaxy, and if they were both simulating SYK, and if Alice on Earth and Bob in Andromeda both &lt;em&gt;uploaded their own brains into their respective quantum simulations&lt;/em&gt;, then it seems possible that the simulated Alice and Bob could have the experience of jumping into a wormhole and meeting each other in the middle.  Granted, they couldn&amp;#8217;t get a message back &lt;em&gt;out&lt;/em&gt; from the wormhole, at least not without &amp;#8220;going the long way,&amp;#8221; which could happen only at the speed of light&amp;#8212;so only simulated-Alice and simulated-Bob themselves could ever &lt;em&gt;test&lt;/em&gt; this prediction.  Nevertheless, &lt;em&gt;if true&lt;/em&gt;, I suppose some would treat it as grounds for regarding a quantum simulation of SYK as &amp;#8220;more real&amp;#8221; or &amp;#8220;more wormholey&amp;#8221; than a classical simulation.&lt;/p&gt;



&lt;p&gt;Of course, this scenario depends on strong assumptions not merely about quantum gravity, but &lt;em&gt;also&lt;/em&gt; about the metaphysics of consciousness!  And I&amp;#8217;d &lt;em&gt;still&lt;/em&gt; prefer to call it a simulated wormhole for simulated people.&lt;/p&gt;



&lt;p&gt;For completeness, here&amp;#8217;s Harlow&amp;#8217;s passage from the &lt;em&gt;NYT&lt;/em&gt; article:&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;Daniel Harlow, a physicist at M.I.T. who was not involved in the experiment, noted that the experiment was based on a model of quantum gravity that was so simple, and unrealistic, that it could just as well have been studied using a pencil and paper.&lt;/p&gt;



&lt;p&gt;“So I’d say that this doesn’t teach us anything about quantum gravity that we didn’t already know,” Dr. Harlow wrote in an email. “On the other hand, I think it is exciting as a technical achievement, because if we can’t even do this (and until now we couldn’t), then simulating more interesting quantum gravity theories would CERTAINLY be off the table.” Developing computers big enough to do so might take 10 or 15 years, he added.&lt;/p&gt;
&lt;/blockquote&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;Alright, let&amp;#8217;s move on to the claim that quantum supremacy has been refuted.  What Aharonov et al. actually show in their &lt;a href=&quot;https://arxiv.org/abs/2211.03999&quot;&gt;new work&lt;/a&gt;, building on &lt;a href=&quot;https://arxiv.org/abs/1810.03176&quot;&gt;earlier work by Gao and Duan&lt;/a&gt;, is that Random Circuit Sampling, with a constant rate of noise per gate and no error-correction, can&amp;#8217;t provide a &lt;em&gt;scalable&lt;/em&gt; approach to quantum supremacy.  Or more precisely: as the number of qubits n goes to infinity, and assuming you&amp;#8217;re in the &amp;#8220;anti-concentration regime&amp;#8221; (which in practice probably means: the depth of your quantum circuit is at least ~log(n)), there&amp;#8217;s a classical algorithm to approximately sample the quantum circuit&amp;#8217;s output distribution in poly(n) time (albeit, not yet a practical algorithm).&lt;/p&gt;



&lt;p&gt;Here&amp;#8217;s what&amp;#8217;s crucial to understand: this is &lt;em&gt;100% consistent&lt;/em&gt; with what those of us working on quantum supremacy had assumed since at least 2016!  We &lt;em&gt;knew&lt;/em&gt; that if you tried to scale Random Circuit Sampling to 200 or 500 or 1000 qubits, while you also increased the circuit depth proportionately, the signal-to-noise ratio would become exponentially small, meaning that your quantum speedup would disappear.  That&amp;#8217;s why, from the very beginning, we targeted the &amp;#8220;practical&amp;#8221; regime of 50-100 qubits: a regime where&lt;/p&gt;



&lt;ol&gt;
&lt;li&gt;you can still see explicitly that you&amp;#8217;re exploiting a 2&lt;sup&gt;50&lt;/sup&gt;&amp;#8211; or 2&lt;sup&gt;100&lt;/sup&gt;-dimensional Hilbert space for computational advantage, thereby confirming one of the main predictions of quantum computing theory, but&lt;/li&gt;



&lt;li&gt;you &lt;em&gt;also&lt;/em&gt; have a signal that (as it turned out) is large enough to see with heroic effort.  &lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;To their credit, Aharonov et al. explain all this perfectly clearly in their abstract and introduction.  I&amp;#8217;m just worried that &lt;em&gt;others&lt;/em&gt; aren&amp;#8217;t reading their paper as carefully as they should be!&lt;/p&gt;



&lt;p&gt;So then, what&amp;#8217;s the new advance in the Aharonov et al. paper?  Well, there had been some hope that circuit depth ~log(n) might be a sweet spot, where an exponential quantum speedup might both exist &lt;em&gt;and&lt;/em&gt; survive constant noise, even in the asymptotic limit of n→∞ qubits.  Nothing in Google&amp;#8217;s or USTC&amp;#8217;s actual Random Circuit Sampling experiments depended on that hope, but it would&amp;#8217;ve been nice if it were true.  What Aharonov et al. have now done is to kill that hope, using powerful techniques involving summing over Feynman paths in the Pauli basis.&lt;/p&gt;



&lt;p&gt;Stepping back, what &lt;em&gt;is&lt;/em&gt; the current status of quantum supremacy based on Random Circuit Sampling?  I would say it&amp;#8217;s still standing, but more precariously than I&amp;#8217;d like&amp;#8212;underscoring the need for new and better quantum supremacy experiments.  In more detail, &lt;a href=&quot;https://arxiv.org/abs/2111.03011&quot;&gt;Pan, Chen, and Zhang&lt;/a&gt; have shown how to simulate Google&amp;#8217;s 53-qubit Sycamore chip classically, using what I estimated to be 100-1000X the electricity cost of running the quantum computer itself (&lt;em&gt;including&lt;/em&gt; the dilution refrigerator!).  Approaching from the problem from a different angle, &lt;a href=&quot;https://arxiv.org/abs/2112.01657&quot;&gt;Gao et al.&lt;/a&gt; have given a polynomial-time classical algorithm for spoofing Google&amp;#8217;s Linear Cross-Entropy Benchmark (LXEB)&amp;#8212;&lt;em&gt;but&lt;/em&gt; their algorithm can currently achieve only about 10% of the excess in LXEB that Google&amp;#8217;s experiment found.&lt;/p&gt;



&lt;p&gt;So, though it&amp;#8217;s been under sustained attack from multiple directions these past few years, I&amp;#8217;d say that the flag of quantum supremacy yet waves.  The Extended Church-Turing Thesis is still on thin ice.  The wormhole is still open.  Wait &amp;#8230; &lt;em&gt;no&lt;/em&gt; &amp;#8230; that&amp;#8217;s not what I meant to write&amp;#8230;&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;/mark&gt;With this post, as with future science posts, &lt;em&gt;all off-topic comments will be ruthlessly left in moderation&lt;/em&gt;.  Yes, even if the comments &amp;#8220;create their own reality&amp;#8221; full of anger and disappointment that I talked about what I talked about, instead of what the commenter wanted me to talk about.  Even if merely &lt;em&gt;refuting&lt;/em&gt; the comments would require me to give in and talk about their preferred topics after all.  Please stop.  This is a wormholes-&amp;#8216;n-supremacy post.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </content>
    <author>
      <name>Scott Aaronson</name>
      <uri>https://scottaaronson.blog</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-173 |  On Disperser/Lifting Properties of the Index and Inner-Product Functions | 

	Sajin Koroth, 

	Paul Beame</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/173"/>
    <id>https://eccc.weizmann.ac.il/report/2022/173</id>
    <updated>2022-12-02T22:55:23+00:00</updated>
    <content type="html" xml:lang="en">
    Query-to-communication lifting theorems, which connect the query complexity of a Boolean function to the communication complexity of an associated `lifted&amp;#39; function obtained by composing the function with many copies of another function known as a gadget, have been instrumental in resolving many open questions in computational complexity. Several important complexity questions could be resolved if we could make substantial improvements in the input size required for lifting with the Index function, from its current near-linear size down to polylogarithmic in the number of inputs $N$ of the original function or, ideally, constant. The near-linear size bound was shown by Lovett, Meka, Mertz, Pitassi and Zhang using a recent breakthrough improvement on the Sunflower Lemma to show that a certain graph associated with the Index function of near-linear size is a disperser. They also stated a conjecture about the Index function that is essential for further improvements in the size required for lifting with Index using current techniques. In this paper we prove the following;
  1) The conjecture of Lovett et al. is false when the size of the Index gadget is $\log N-\omega(1)$.
  2) Also, the Inner-Product function, which satisfies the disperser property at size $O(\log N)$, does not have this property when its size is  $\log N-\omega(1)$.
  3) Nonetheless, using Index gadgets of size at least 4, we prove a lifting theorem for a restricted class of communication protocols in which one of the players is limited to sending parities of its inputs.
  4) Using the ideas from this lifting theorem, we derive a strong lifting theorem from decision tree size to parity decision tree size. We use this to derive a general lifting theorem in proof complexity from tree-resolution size to tree-like $Res(\oplus)$ refutation size, which yields many new exponential lower bounds on such proofs.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">ECCC Papers: TR22-172 |  Lifting to Parity Decision Trees Via Stifling | 

	Arkadev Chattopadhyay, 

	Nikhil Mande, 

	Swagato Sanyal, 

	Suhail Sherif</title>
    <link href="https://eccc.weizmann.ac.il/report/2022/172"/>
    <id>https://eccc.weizmann.ac.il/report/2022/172</id>
    <updated>2022-12-02T22:16:33+00:00</updated>
    <content type="html" xml:lang="en">
    We show that the deterministic decision tree complexity of a (partial) function or relation $f$ lifts to the deterministic parity decision tree (PDT) size complexity of the composed function/relation $f \circ g$ as long as the gadget $g$ satisfies a property that we call stifling. We observe that several simple gadgets of constant size, like Indexing on 3 input bits, Inner Product on 4 input bits, Majority on 3 input bits and random functions, satisfy this property. It can be shown that existing randomized communication lifting theorems ([Göös, Pitassi, Watson. SICOMP&amp;#39;20], [Chattopadhyay et al. SICOMP&amp;#39;21]) imply PDT-size lifting. However there are two shortcomings of this approach: first they lift randomized decision tree complexity of $f$, which could be exponentially smaller than its deterministic counterpart when either $f$ is a partial function or even a total search problem. Second, the size of the gadgets in such lifting theorems are as large as logarithmic in the size of the input to $f$. Reducing the gadget size to a constant is an important open problem at the frontier of current research.

Our result shows that even a random constant-size gadget does enable lifting to PDT size. Further, it also yields the first systematic way of turning lower bounds on the width of tree-like resolution proofs of the unsatisfiability of constant-width CNF formulas to lower bounds on the size of tree-like proofs in the resolution with parity system, i.e., $\mathrm{Res}$($\oplus$), of the unsatisfiability of closely related constant-width CNF formulas.
  </content>
    <author>
      <name>ECCC Papers</name>
      <uri>https://eccc.weizmann.ac.il/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: The Smoothed Complexity of Policy Iteration for Markov Decision Processes</title>
    <link href="http://arxiv.org/abs/2212.00083"/>
    <id>http://arxiv.org/abs/2212.00083</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christ_M/0/1/0/all/0/1&quot;&gt;Miranda Christ&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yannakakis_M/0/1/0/all/0/1&quot;&gt;Mihalis Yannakakis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show subexponential lower bounds (i.e., $2^{\Omega (n^c)}$) on the
smoothed complexity of the classical Howard&#39;s Policy Iteration algorithm for
Markov Decision Processes. The bounds hold for the total reward and the average
reward criteria. The constructions are robust in the sense that the
subexponential bound holds not only on the average for independent random
perturbations of the MDP parameters (transition probabilities and rewards), but
for all arbitrary perturbations within an inverse polynomial range. We show
also an exponential lower bound on the worst-case complexity for the simple
reachability objective.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: On the power of nonstandard quantum oracles</title>
    <link href="http://arxiv.org/abs/2212.00098"/>
    <id>http://arxiv.org/abs/2212.00098</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Bassirian_R/0/1/0/all/0/1&quot;&gt;Roozbeh Bassirian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Fefferman_B/0/1/0/all/0/1&quot;&gt;Bill Fefferman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Marwaha_K/0/1/0/all/0/1&quot;&gt;Kunal Marwaha&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study how the choices made when designing an oracle affect the complexity
of quantum property testing problems defined relative to this oracle. We encode
a regular graph of even degree as an invertible function $f$, and present $f$
in different oracle models. We first give a one-query QMA protocol to test if a
graph encoded in $f$ has a small disconnected subset. We then use
representation theory to show that no classical witness can help a quantum
verifier efficiently decide this problem relative to an in-place oracle.
Perhaps surprisingly, a simple modification to the standard oracle prevents a
quantum verifier from efficiently deciding this problem, even with access to an
unbounded witness.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Hit-and-run mixing via localization schemes</title>
    <link href="http://arxiv.org/abs/2212.00297"/>
    <id>http://arxiv.org/abs/2212.00297</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuansi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Eldan_R/0/1/0/all/0/1&quot;&gt;Ronen Eldan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We analyze the hit-and-run algorithm for sampling uniformly from an isotropic
convex body $K$ in $n$ dimensions. We show that the algorithm mixes in time
$\tilde{O}(n^2/ \psi_n^2)$, where $\psi_n$ is the smallest isoperimetric
constant for any isotropic logconcave distribution, also known as the
Kannan-Lovasz-Simonovits (KLS) constant. Our bound improves upon previous
bounds of the form $\tilde{O}(n^2 R^2/r^2)$, which depend on the ratio $R/r$ of
the radii of the circumscribed and inscribed balls of $K$, gaining a factor of
$n$ in the case of isotropic convex bodies. Consequently, our result gives a
mixing time estimate for the hit-and-run which matches the state-of-the-art
bounds for the ball walk. Our main proof technique is based on an annealing of
localization schemes introduced in Chen and Eldan (2022), which allows us to
reduce the problem to the analysis of the mixing time on truncated Gaussian
distributions.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Complexity Blowup for Solutions of the Laplace and the Diffusion Equation</title>
    <link href="http://arxiv.org/abs/2212.00693"/>
    <id>http://arxiv.org/abs/2212.00693</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bacho_A/0/1/0/all/0/1&quot;&gt;Aras Bacho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boche_H/0/1/0/all/0/1&quot;&gt;Holger Boche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1&quot;&gt;Gitta Kutyniok&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we investigate the computational complexity of solutions to
the Laplace and the diffusion equation. We show that for a certain class of
initial-boundary value problems of the Laplace and the diffusion equation, the
solution operator is unbounded as a mapping from the space of polynomial-time
computable functions into itself in the sense that there exists polynomial-time
(Turing) computable input data such that the solution is not polynomial-time
computable, unless $FP=\#P$. In this case, we can, in general, not simulate the
solution of the Laplace or the diffusion equation on a digital computer without
having a complexity blowup, i.e., the computation time for obtaining an
approximation of the solution with up to a finite number of significant digits
grows exponentially in the number of digits. This shows that the computational
complexity of the solution operator is intrinsically high, independent of the
numerical algorithm that is used to obtain a solution. This indicates that
there is a fundamental problem in computing a solution on a digital hardware.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Experimental Observations of the Topology of Convolutional Neural Network Activations</title>
    <link href="http://arxiv.org/abs/2212.00222"/>
    <id>http://arxiv.org/abs/2212.00222</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Purvine_E/0/1/0/all/0/1&quot;&gt;Emilie Purvine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1&quot;&gt;Davis Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jefferson_B/0/1/0/all/0/1&quot;&gt;Brett Jefferson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joslyn_C/0/1/0/all/0/1&quot;&gt;Cliff Joslyn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Praggastis_B/0/1/0/all/0/1&quot;&gt;Brenda Praggastis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rathore_A/0/1/0/all/0/1&quot;&gt;Archit Rathore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shapiro_M/0/1/0/all/0/1&quot;&gt;Madelyn Shapiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Youjia Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Topological data analysis (TDA) is a branch of computational mathematics,
bridging algebraic topology and data science, that provides compact,
noise-robust representations of complex structures. Deep neural networks (DNNs)
learn millions of parameters associated with a series of transformations
defined by the model architecture, resulting in high-dimensional,
difficult-to-interpret internal representations of input data. As DNNs become
more ubiquitous across multiple sectors of our society, there is increasing
recognition that mathematical methods are needed to aid analysts, researchers,
and practitioners in understanding and interpreting how these models&#39; internal
representations relate to the final classification. In this paper, we apply
cutting edge techniques from TDA with the goal of gaining insight into the
interpretability of convolutional neural networks used for image
classification. We use two common TDA approaches to explore several methods for
modeling hidden-layer activations as high-dimensional point clouds, and provide
experimental evidence that these point clouds capture valuable structural
information about the model&#39;s process. First, we demonstrate that a distance
metric based on persistent homology can be used to quantify meaningful
differences between layers, and we discuss these distances in the broader
context of existing representational similarity metrics for neural network
interpretability. Second, we show that a mapper graph can provide semantic
insight into how these models organize hierarchical class knowledge at each
layer. These observations demonstrate that TDA is a useful tool to help deep
learning practitioners unlock the hidden structures of their models.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Tutte Embeddings of Tetrahedral Meshes</title>
    <link href="http://arxiv.org/abs/2212.00452"/>
    <id>http://arxiv.org/abs/2212.00452</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alexa_M/0/1/0/all/0/1&quot;&gt;Marc Alexa&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Tutte&#39;s embedding theorem states that every 3-connected graph without a $K_5$
or $K_{3,3}$ minor (i.e. a planar graph) is embedded in the plane if the outer
face is in convex position and the interior vertices are convex combinations of
their neighbors. We show that this result extends to simply connected
tetrahedral meshes in a natural way: for the tetrahedral mesh to be embedded if
the outer polyhedron is in convex position and the interior vertices are convex
combination of their neighbors it is sufficient (but not necessary) that the
graph of the tetrahedral mesh contains no $K_6$ and no $K_{3,3,1}$, and all
triangles incident on three boundary vertices are boundary triangles.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: (No) Quantum space-time tradeoff for USTCON</title>
    <link href="http://arxiv.org/abs/2212.00094"/>
    <id>http://arxiv.org/abs/2212.00094</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Apers_S/0/1/0/all/0/1&quot;&gt;Simon Apers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jeffery_S/0/1/0/all/0/1&quot;&gt;Stacey Jeffery&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pass_G/0/1/0/all/0/1&quot;&gt;Galina Pass&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Walter_M/0/1/0/all/0/1&quot;&gt;Michael Walter&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Undirected $st$-connectivity is important both for its applications in
network problems, and for its theoretical connections with logspace complexity.
Classically, a long line of work led to a time-space tradeoff of
$T=\tilde{O}(n^2/S)$ for any $S$ such that $S=\Omega(\log (n))$ and
$S=O(n^2/m)$. Surprisingly, we show that quantumly there is no nontrivial
time-space tradeoff: there is a quantum algorithm that achieves both optimal
time $\tilde{O}(n)$ and space $O(\log (n))$ simultaneously. This improves on
previous results, which required either $O(\log (n))$ space and
$\tilde{O}(n^{1.5})$ time, or $\tilde{O}(n)$ space and time. To complement
this, we show that there is a nontrivial time-space tradeoff when given a lower
bound on the spectral gap of a corresponding random walk.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Sublinear Algorithms for $(1.5+\epsilon)$-Approximate Matching</title>
    <link href="http://arxiv.org/abs/2212.00189"/>
    <id>http://arxiv.org/abs/2212.00189</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1&quot;&gt;Sayan Bhattacharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiss_P/0/1/0/all/0/1&quot;&gt;Peter Kiss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saranurak_T/0/1/0/all/0/1&quot;&gt;Thatchaphol Saranurak&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study sublinear time algorithms for estimating the size of maximum
matching. After a long line of research, the problem was finally settled by
Behnezhad [FOCS&#39;22], in the regime where one is willing to pay an approximation
factor of $2$. Very recently, Behnezhad et al.[SODA&#39;23] improved the
approximation factor to $(2-\frac{1}{2^{O(1/\gamma)}})$ using $n^{1+\gamma}$
time. This improvement over the factor $2$ is, however, minuscule and they
asked if even $1.99$-approximation is possible in $n^{2-\Omega(1)}$ time. We
give a strong affirmative answer to this open problem by showing
$(1.5+\epsilon)$-approximation algorithms that run in
$n^{2-\Theta(\epsilon^{2})}$ time. Our approach is conceptually simple and
diverges from all previous sublinear-time matching algorithms: we show a
sublinear time algorithm for computing a variant of the edge-degree constrained
subgraph (EDCS), a concept that has previously been exploited in dynamic
[Bernstein Stein ICALP&#39;15, SODA&#39;16], distributed [Assadi et al. SODA&#39;19] and
streaming [Bernstein ICALP&#39;20] settings, but never before in the sublinear
setting. Independent work: Behnezhad, Roghani and Rubinstein [BRR&#39;23]
independently showed sublinear algorithms similar to our Theorem 1.2 in both
adjacency list and matrix models. Furthermore, in [BRR&#39;23], they show
additional results on strictly better-than-1.5 approximate matching algorithms
in both upper and lower bound sides.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: AC-Band: A Combinatorial Bandit-Based Approach to Algorithm Configuration</title>
    <link href="http://arxiv.org/abs/2212.00333"/>
    <id>http://arxiv.org/abs/2212.00333</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brandt_J/0/1/0/all/0/1&quot;&gt;Jasmin Brandt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schede_E/0/1/0/all/0/1&quot;&gt;Elias Schede&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengs_V/0/1/0/all/0/1&quot;&gt;Viktor Bengs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haddenhorst_B/0/1/0/all/0/1&quot;&gt;Bj&amp;#xf6;rn Haddenhorst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hullermeier_E/0/1/0/all/0/1&quot;&gt;Eyke H&amp;#xfc;llermeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tierney_K/0/1/0/all/0/1&quot;&gt;Kevin Tierney&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the algorithm configuration (AC) problem, in which one seeks to find
an optimal parameter configuration of a given target algorithm in an automated
way. Recently, there has been significant progress in designing AC approaches
that satisfy strong theoretical guarantees. However, a significant gap still
remains between the practical performance of these approaches and
state-of-the-art heuristic methods. To this end, we introduce AC-Band, a
general approach for the AC problem based on multi-armed bandits that provides
theoretical guarantees while exhibiting strong practical performance. We show
that AC-Band requires significantly less computation time than other AC
approaches providing theoretical guarantees while still yielding high-quality
configurations.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Tight Conditional Lower Bounds for Vertex Connectivity Problems</title>
    <link href="http://arxiv.org/abs/2212.00359"/>
    <id>http://arxiv.org/abs/2212.00359</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zhiyi Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1&quot;&gt;Yaowei Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saranurak_T/0/1/0/all/0/1&quot;&gt;Thatchaphol Saranurak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Benyu Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the fine-grained complexity of graph connectivity problems in
unweighted undirected graphs. Recent development shows that all variants of
edge connectivity problems, including single-source-single-sink, global,
Steiner, single-source, and all-pairs connectivity, are solvable in
$m^{1+o(1)}$ time, collapsing the complexity of these problems into the
almost-linear-time regime. While, historically, vertex connectivity has been
much harder, the recent results showed that both single-source-single-sink and
global vertex connectivity can be solved in $m^{1+o(1)}$ time, raising the hope
of putting all variants of vertex connectivity problems into the
almost-linear-time regime too.
&lt;/p&gt;
&lt;p&gt;We show that this hope is impossible, assuming conjectures on finding
4-cliques. Moreover, we essentially settle the complexity landscape by giving
tight bounds for combinatorial algorithms in dense graphs. There are three
separate regimes: (1) all-pairs and Steiner vertex connectivity have complexity
$\hat{\Theta}(n^{4})$, (2) single-source vertex connectivity has complexity
$\hat{\Theta}(n^{3})$, and (3) single-source-single-sink and global vertex
connectivity have complexity $\hat{\Theta}(n^{2})$. For graphs with general
density, we obtain tight bounds of $\hat{\Theta}(m^{2})$,
$\hat{\Theta}(m^{1.5})$, $\hat{\Theta}(m)$, respectively, assuming Gomory-Hu
trees for element connectivity can be computed in almost-linear time.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: An Improved Time-Efficient Approximate Kernelization for Connected Treedepth Deletion Set</title>
    <link href="http://arxiv.org/abs/2212.00418"/>
    <id>http://arxiv.org/abs/2212.00418</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eiben_E/0/1/0/all/0/1&quot;&gt;Eduard Eiben&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumdar_D/0/1/0/all/0/1&quot;&gt;Diptapriyo Majumdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramanujan_M/0/1/0/all/0/1&quot;&gt;M. S. Ramanujan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the CONNECTED \eta-TREEDEPTH DELETION problem where the input
instance is an undireted graph G = (V, E) and an integer k. The objective is to
decide if G has a set S \subseteq V(G) of at most k vertices such that G - S
has treedepth at most \eta and G[S] is connected. As this problem naturally
generalizes the well-known CONNECTED VERTEX COVER, when parameterized by
solution size k, the CONNECTED \eta-TREEDEPTH DELETION does not admit
polynomial kernel unless NP \subseteq coNP/poly. This motivates us to design an
approximate kernel of polynomial size for this problem. In this paper, we show
that for every 0 &amp;lt; \epsilon &amp;lt;= 1, CONNECTED \eta-TREEDEPTH DELETION SET admits
a (1+\epsilon)-approximate kernel with O(k^{2^{\eta + 1/\epsilon}}) vertices,
i.e. a polynomial-sized approximate kernelization scheme (PSAKS).
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Subquadratic Weighted Matroid Intersection Under Rank Oracles</title>
    <link href="http://arxiv.org/abs/2212.00508"/>
    <id>http://arxiv.org/abs/2212.00508</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_T/0/1/0/all/0/1&quot;&gt;Ta-Wei Tu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given two matroids $\mathcal{M}_1 = (V, \mathcal{I}_1)$ and $\mathcal{M}_2 =
(V, \mathcal{I}_2)$ over an $n$-element integer-weighted ground set $V$, the
weighted matroid intersection problem aims to find a common independent set
$S^{*} \in \mathcal{I}_1 \cap \mathcal{I}_2$ maximizing the weight of $S^{*}$.
In this paper, we present a simple deterministic algorithm for weighted matroid
intersection using $\tilde{O}(nr^{3/4}\log{W})$ rank queries, where $r$ is the
size of the largest intersection of $\mathcal{M}_1$ and $\mathcal{M}_2$ and $W$
is the maximum weight. This improves upon the best previously known
$\tilde{O}(nr\log{W})$ algorithm given by Lee, Sidford, and Wong [FOCS&#39;15], and
is the first subquadratic algorithm for polynomially-bounded weights under the
standard independence or rank oracle models. The main contribution of this
paper is an efficient algorithm that computes shortest-path trees in weighted
exchange graphs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: POSTER: Unexpected Scaling in Path Copying Trees</title>
    <link href="http://arxiv.org/abs/2212.00521"/>
    <id>http://arxiv.org/abs/2212.00521</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kokorin_I/0/1/0/all/0/1&quot;&gt;Ilya Kokorin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fedorov_A/0/1/0/all/0/1&quot;&gt;Alexander Fedorov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_T/0/1/0/all/0/1&quot;&gt;Trevor Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aksenov_V/0/1/0/all/0/1&quot;&gt;Vitaly Aksenov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Although a wide variety of handcrafted concurrent data structures have been
proposed, there is considerable interest in universal approaches (henceforth
called Universal Constructions or UCs) for building concurrent data structures.
These approaches (semi-)automatically convert a sequential data structure into
a concurrent one. The simplest approach uses locks that protect a sequential
data structure and allow only one process to access it at a time. The resulting
data structures use locks, and hence are blocking. Most work on UCs instead
focuses on obtaining non-blocking progress guarantees such as
obstruction-freedom, lock-freedom, or wait-freedom. Many non-blocking UCs have
appeared. Key examples include the seminal wait-free UC by Herlihy, a
NUMA-aware UC by Yi et al., and an efficient UC for large objects by Fatourou
et al.
&lt;/p&gt;
&lt;p&gt;We borrow ideas from persistent data structures and multi-version concurrency
control (MVCC), most notably path copying, and use them to implement concurrent
versions of sequential persistent data structures. Despite our expectation that
our data structures would not scale under write-heavy workloads, they scale in
practice. We confirm this scaling analytically in our model with private
per-process caches.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Sub-quadratic Algorithms for Kernel Matrices via Kernel Density Estimation</title>
    <link href="http://arxiv.org/abs/2212.00642"/>
    <id>http://arxiv.org/abs/2212.00642</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bakshi_A/0/1/0/all/0/1&quot;&gt;Ainesh Bakshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Indyk_P/0/1/0/all/0/1&quot;&gt;Piotr Indyk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kacham_P/0/1/0/all/0/1&quot;&gt;Praneeth Kacham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1&quot;&gt;Sandeep Silwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Samson Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Kernel matrices, as well as weighted graphs represented by them, are
ubiquitous objects in machine learning, statistics and other related fields.
The main drawback of using kernel methods (learning and inference using kernel
matrices) is efficiency -- given $n$ input points, most kernel-based algorithms
need to materialize the full $n \times n$ kernel matrix before performing any
subsequent computation, thus incurring $\Omega(n^2)$ runtime. Breaking this
quadratic barrier for various problems has therefore, been a subject of
extensive research efforts.
&lt;/p&gt;
&lt;p&gt;We break the quadratic barrier and obtain $\textit{subquadratic}$ time
algorithms for several fundamental linear-algebraic and graph processing
primitives, including approximating the top eigenvalue and eigenvector,
spectral sparsification, solving linear systems, local clustering, low-rank
approximation, arboricity estimation and counting weighted triangles. We build
on the recent Kernel Density Estimation framework, which (after preprocessing
in time subquadratic in $n$) can return estimates of row/column sums of the
kernel matrix. In particular, we develop efficient reductions from
$\textit{weighted vertex}$ and $\textit{weighted edge sampling}$ on kernel
graphs, $\textit{simulating random walks}$ on kernel graphs, and
$\textit{importance sampling}$ on matrices to Kernel Density Estimation and
show that we can generate samples from these distributions in
$\textit{sublinear}$ (in the support of the distribution) time. Our reductions
are the central ingredient in each of our applications and we believe they may
be of independent interest. We empirically demonstrate the efficacy of our
algorithms on low-rank approximation (LRA) and spectral sparsification, where
we observe a $\textbf{9x}$ decrease in the number of kernel evaluations over
baselines for LRA and a $\textbf{41x}$ reduction in the graph size for spectral
sparsification.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Clustering What Matters: Optimal Approximation for Clustering with Outliers</title>
    <link href="http://arxiv.org/abs/2212.00696"/>
    <id>http://arxiv.org/abs/2212.00696</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1&quot;&gt;Akanksha Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inamdar_T/0/1/0/all/0/1&quot;&gt;Tanmay Inamdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1&quot;&gt;Saket Saurabh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1&quot;&gt;Jie Xue&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Clustering with outliers is one of the most fundamental problems in Computer
Science. Given a set $X$ of $n$ points and two integers $k$ and $m$, the
clustering with outliers aims to exclude $m$ points from $X$ and partition the
remaining points into $k$ clusters that minimizes a certain cost function. In
this paper, we give a general approach for solving clustering with outliers,
which results in a fixed-parameter tractable (FPT) algorithm in $k$ and $m$,
that almost matches the approximation ratio for its outlier-free counterpart.
As a corollary, we obtain FPT approximation algorithms with optimal
approximation ratios for $k$-Median and $k$-Means with outliers in general
metrics. We also exhibit more applications of our approach to other variants of
the problem that impose additional constraints on the clustering, such as
fairness or matroid constraints.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Fully-Dynamic Decision Trees</title>
    <link href="http://arxiv.org/abs/2212.00778"/>
    <id>http://arxiv.org/abs/2212.00778</id>
    <updated>2022-12-02T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bressan_M/0/1/0/all/0/1&quot;&gt;Marco Bressan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damay_G/0/1/0/all/0/1&quot;&gt;Gabriel Damay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sozio_M/0/1/0/all/0/1&quot;&gt;Mauro Sozio&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We develop the first fully dynamic algorithm that maintains a decision tree
over an arbitrary sequence of insertions and deletions of labeled examples.
Given $\epsilon &amp;gt; 0$ our algorithm guarantees that, at every point in time,
every node of the decision tree uses a split with Gini gain within an additive
$\epsilon$ of the optimum. For real-valued features the algorithm has an
amortized running time per insertion/deletion of $O\big(\frac{d \log^3
n}{\epsilon^2}\big)$, which improves to $O\big(\frac{d \log^2
n}{\epsilon}\big)$ for binary or categorical features, while it uses space $O(n
d)$, where $n$ is the maximum number of examples at any point in time and $d$
is the number of features. Our algorithm is nearly optimal, as we show that any
algorithm with similar guarantees uses amortized running time $\Omega(d)$ and
space $\tilde{\Omega} (n d)$. We complement our theoretical results with an
extensive experimental evaluation on real-world data, showing the effectiveness
of our algorithm.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">Computational Complexity: How do we keep the community connected?</title>
    <link href="http://blog.computationalcomplexity.org/2022/12/how-do-we-keep-community-connected.html"/>
    <id>tag:blogger.com,1999:blog-3722233.post-4202676814033172170</id>
    <updated>2022-12-01T16:37:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;A colleague said how they enjoyed watching the &lt;a href=&quot;https://blog.computationalcomplexity.org/2022/11/should-you-quit-twitter-and-texas.html&quot;&gt;collapse of Twitter&lt;/a&gt; under Elon Musk. But I use Twitter to keep connected to the CS community. In Twitter I hear not only new results but ones that excite particular people. I watch the debate between those who see ML as revolutionary and those who see ML as revolting. I see the issues that our community worries about and those that they celebrate. I follow people as they progress in their careers or outright change them. Mostly it just makes me feel part of an academic community that goes beyond my own institution.&amp;nbsp;&lt;/p&gt;&lt;p&gt;A bit surprisingly, so far Twitter hasn&#39;t collapsed. But it could and I expect many of my followers and those I follow spend less time there. I set up a Mastodon account&amp;nbsp;&lt;a href=&quot;https://fediscience.org/@fortnow&quot;&gt;@fortnow@fediscience.org&lt;/a&gt;&amp;nbsp;but not much happens over there, though feel free to tell me who I should be following. There are many other social networks but none that bring us as a field together.&lt;/p&gt;&lt;p&gt;Blog posts and their comments play a role but not like they used to. There&#39;s&amp;nbsp;&lt;a href=&quot;https://cstheory.stackexchange.com/&quot;&gt;CS Theory StackExchange&lt;/a&gt;&amp;nbsp;which has some good (and not so good) technical discussions but we don&#39;t really have conversations there.&amp;nbsp;&lt;/p&gt;&lt;p&gt;How about conferences now that researchers are (mostly) willing to attend in person? Since conferences in CS are the primary publication venue, we have too many meetings and many won&#39;t go, or at least won&#39;t go in person, if they don&#39;t have a paper in the conference.&lt;/p&gt;&lt;p&gt;So, &lt;a href=&quot;https://blog.computationalcomplexity.org/2008/07/games.html&quot;&gt;once again&lt;/a&gt;, I suggest a big theory conference we hold every four years that everyone who&#39;s anyone will make sure to attend. Hey, it works for the World Cup.&amp;nbsp;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </content>
    <author>
      <name>Computational Complexity</name>
      <uri>http://blog.computationalcomplexity.org/</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Optimizing sparse fermionic Hamiltonians</title>
    <link href="http://arxiv.org/abs/2211.16518"/>
    <id>http://arxiv.org/abs/2211.16518</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Herasymenko_Y/0/1/0/all/0/1&quot;&gt;Yaroslav Herasymenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Stroeks_M/0/1/0/all/0/1&quot;&gt;Maarten Stroeks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Helsen_J/0/1/0/all/0/1&quot;&gt;Jonas Helsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Terhal_B/0/1/0/all/0/1&quot;&gt;Barbara Terhal&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the problem of approximating the ground state energy of a
fermionic Hamiltonian using a Gaussian state. In sharp contrast to the dense
case (Hastings &amp;amp; O&#39;Donnell, 2022), we prove that strictly $q$-local
$\rm{\textit{sparse}}$ fermionic Hamiltonians have a constant Gaussian
approximation ratio; the result holds for any connectivity and interaction
strengths. Sparsity means that each fermion participates in a bounded number of
interactions, and strictly $q$-local means that each term involves exactly $q$
fermionic (Majorana) operators. We extend our proof to give a constant Gaussian
approximation ratio for sparse fermionic Hamiltonians with both quartic and
quadratic terms. With additional work, we also prove a constant Gaussian
approximation ratio for the so-called sparse SYK model with strictly $4$-local
interactions (sparse SYK-4 model). In each setting we show that the Gaussian
state can be efficiently determined. Finally, we prove that the $O(n^{-1/2})$
Gaussian approximation ratio for the normal (dense) SYK-$4$ model extends to
SYK-$q$ for even $q&amp;gt;4$, with an approximation ratio of $O(n^{1/2 - q/4})$. Our
results identify non-sparseness as the prime reason that the SYK-4 model can
fail to have a constant approximation ratio.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Post-Quantum $\kappa$-to-1 Trapdoor Claw-free Functions from Extrapolated Dihedral Cosets</title>
    <link href="http://arxiv.org/abs/2211.16993"/>
    <id>http://arxiv.org/abs/2211.16993</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1&quot;&gt;Xingyu Yan&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Licheng Wang&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1&quot;&gt;Weiqiang Wen&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Ziyi Li&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suo_J/0/1/0/all/0/1&quot;&gt;Jingwen Suo&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_L/0/1/0/all/0/1&quot;&gt;Lize Gu&lt;/a&gt; (1) ((1) State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China. (2) School of Cyberspace Science and Technology, Beijing Institute of Technology, Beijing, 100081, China. (3) LTCI, Telecom Paris, Institut Polytechnique de Paris, Paris, France. (4) State Key Laboratory of Information Security, Institute of Information Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China.)&lt;/p&gt;&lt;p&gt;Noisy Trapdoor Claw-free functions (NTCF) as powerful post-quantum
cryptographic tools can efficiently constrain actions of untrusted quantum
devices. Recently, Brakerski et al. at FOCS 2018 showed a remarkable use of
NTCF for a classically verifiable proof of quantumness and also derived a
protocol for cryptographically certifiable quantum randomness generation.
However, the original NTCF used in their work is essentially 2-to-1 one-way
function, namely NTCF$^1_2$, which greatly limits the rate of randomness
generation.
&lt;/p&gt;
&lt;p&gt;In this work, we attempt to further extend the NTCF$^1_2$ to achieve a
$\kappa$-to-1 function with poly-bounded preimage size. Specifically, we focus
on a significant extrapolation of NTCF$^1_2$ by drawing on extrapolated
dihedral cosets, giving a model of NTCF$^1_{\kappa}$ with $\kappa = poly(n)$.
Then, we present an efficient construction of NTCF$^1_{\kappa}$ under the
well-known quantum hardness of the Learning with Errors (QLWE) assumption. As a
byproduct, our work manifests an interesting connection between the NTCF$^1_2$
(resp. NTCF$^1_{\kappa}$) and the Dihedral Coset States (resp. Extrapolated
Dihedral Coset States). Finally, we give a similar interactive protocol for
proving quantumness from the NTCF$^1_{\kappa}$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Opinion Evolution among friends and foes: the deterministic Majority Rule - extended abstract</title>
    <link href="http://arxiv.org/abs/2211.17159"/>
    <id>http://arxiv.org/abs/2211.17159</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ianni_M/0/1/0/all/0/1&quot;&gt;Miriam Di Ianni&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The influence of the social relationships of an individual on the
individual&#39;s opinions (about a topic, a product, or whatever else) is a well
known phenomenon and it has been widely studied. This paper considers a network
of positive (i.e. trusting) or negative (distrusting) social relationships
where every individual has an initial positive or negative opinion (about a
topic, a product, or whatever else) that changes over time, at discrete
time-steps, due to the influences each individual gets from its neighbors.
Here, the influence of a trusted neighbor is consistent with the neighbor&#39;s
opinion, while the influence of an untrusted neighbor is opposite to the
neighbor&#39;s opinion. This extended abstract introduces the local threshold-based
opinion dynamics and, after stating the computational complexity of some
natural reachability problems arising in this setting when individuals change
their opinions according to the opinions of the majority of their neighbors,
proves an upper bound on the number of opinion configurations met by a
symmetric positive-only relationships network evolving according to any of such
models, which is polynomial in the size of the network. This generalizes a
result in [Krishnendu Chatterjee, Rasmus Ibsen-Jensen, Isma\&quot;el Jecker, and
Jakub Svoboda, &quot;Simplified Game of Life: Algorithms and Complexity&quot;, 45th
International Symposium on Mathematical Foundations of Computer Science (MFCS
2020)]
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: On Disperser/Lifting Properties of the Index and Inner-Product Functions</title>
    <link href="http://arxiv.org/abs/2211.17211"/>
    <id>http://arxiv.org/abs/2211.17211</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beame_P/0/1/0/all/0/1&quot;&gt;Paul Beame&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koroth_S/0/1/0/all/0/1&quot;&gt;Sajin Koroth&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Query-to-communication lifting theorems, which connect the query complexity
of a Boolean function to the communication complexity of an associated `lifted&#39;
function obtained by composing the function with many copies of another
function known as a gadget, have been instrumental in resolving many open
questions in computational complexity. Several important complexity questions
could be resolved if we could make substantial improvements in the input size
required for lifting with the Index function, from its current near-linear size
down to polylogarithmic in the number of inputs $N$ of the original function
or, ideally, constant. The near-linear size bound was shown by Lovett, Meka,
Mertz, Pitassi and Zhang using a recent breakthrough improvement on the
Sunflower Lemma to show that a certain graph associated with the Index function
of near-linear size is a disperser. They also stated a conjecture about the
Index function that is essential for further improvements in the size required
for lifting with Index using current techniques. In this paper we prove the
following;
&lt;/p&gt;
&lt;p&gt;1) The conjecture of Lovett et al. is false when the size of the Index gadget
is $\log N-\omega(1)$.
&lt;/p&gt;
&lt;p&gt;2) Also, the Inner-Product function, which satisfies the disperser property
at size $O(\log N)$, does not have this property when its size is $\log
N-\omega(1)$.
&lt;/p&gt;
&lt;p&gt;3) Nonetheless, using Index gadgets of size at least 4, we prove a lifting
theorem for a restricted class of communication protocols in which one of the
players is limited to sending parities of its inputs.
&lt;/p&gt;
&lt;p&gt;4) Using the ideas from this lifting theorem, we derive a strong lifting
theorem from decision tree size to parity decision tree size. We use this to
derive a general lifting theorem in proof complexity from tree-resolution size
to tree-like $Res(\oplus)$ refutation size, which yields many new exponential
lower bounds on such proofs.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Complexity: Lifting to Parity Decision Trees Via Stifling</title>
    <link href="http://arxiv.org/abs/2211.17214"/>
    <id>http://arxiv.org/abs/2211.17214</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chattopadhyay_A/0/1/0/all/0/1&quot;&gt;Arkadev Chattopadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mande_N/0/1/0/all/0/1&quot;&gt;Nikhil S. Mande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanyal_S/0/1/0/all/0/1&quot;&gt;Swagato Sanyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sherif_S/0/1/0/all/0/1&quot;&gt;Suhail Sherif&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that the deterministic decision tree complexity of a (partial)
function or relation $f$ lifts to the deterministic parity decision tree (PDT)
size complexity of the composed function/relation $f \circ g$ as long as the
gadget $g$ satisfies a property that we call stifling. We observe that several
simple gadgets of constant size, like Indexing on 3 input bits, Inner Product
on 4 input bits, Majority on 3 input bits and random functions, satisfy this
property. It can be shown that existing randomized communication lifting
theorems ([G\&quot;{o}\&quot;{o}s, Pitassi, Watson. SICOMP&#39;20], [Chattopadhyay et al.
SICOMP&#39;21]) imply PDT-size lifting. However there are two shortcomings of this
approach: first they lift randomized decision tree complexity of $f$, which
could be exponentially smaller than its deterministic counterpart when either
$f$ is a partial function or even a total search problem. Second, the size of
the gadgets in such lifting theorems are as large as logarithmic in the size of
the input to $f$. Reducing the gadget size to a constant is an important open
problem at the frontier of current research.
&lt;/p&gt;
&lt;p&gt;Our result shows that even a random constant-size gadget does enable lifting
to PDT size. Further, it also yields the first systematic way of turning lower
bounds on the width of tree-like resolution proofs of the unsatisfiability of
constant-width CNF formulas to lower bounds on the size of tree-like proofs in
the resolution with parity system, i.e., $\textit{Res}$($\oplus$), of the
unsatisfiability of closely related constant-width CNF formulas.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Complexity</name>
      <uri>https://arxiv.org/list/cs.CC/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Computational Geometry: Approximating robot reachable space using convex polytopes</title>
    <link href="http://arxiv.org/abs/2211.17054"/>
    <id>http://arxiv.org/abs/2211.17054</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skuric_A/0/1/0/all/0/1&quot;&gt;Antun Skuric&lt;/a&gt; (AUCTUS), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Padois_V/0/1/0/all/0/1&quot;&gt;Vincent Padois&lt;/a&gt; (AUCTUS), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daney_D/0/1/0/all/0/1&quot;&gt;David Daney&lt;/a&gt; (AUCTUS, IMS)&lt;/p&gt;&lt;p&gt;This paper presents an approach for approximating the reachable space of
robotic manipulators based on convex polytopes. The proposed approach predicts
the reachable space over a given time horizon based on the robot&#39;s actuation
limits and kinematic constraints. The approach is furthermore extended to
integrate the robot&#39;s environment, assuming it can be expressed in a form of
linear constraints, and to account for the robot&#39;s link geometry.The accuracy
of the proposed method is evaluated using simulations of robot&#39;s nonlinear
dynamics and it is compared against the cartesian space limits, usually
provided by manufacturers in standard datasheets.The accuracy analysis results
show that the proposed method has good performance for the time horizons up to
250ms, encapsulating most of the simulated robot&#39;s reachable space while
maintaining comparable volume. For a 7 dof robot, the method has an average
execution time of 50ms, independent of the horizon time, potentially enabling
real-time applications.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Computational Geometry</name>
      <uri>https://arxiv.org/list/cs.CG/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Improved Smoothed Analysis of 2-Opt for the Euclidean TSP</title>
    <link href="http://arxiv.org/abs/2211.16908"/>
    <id>http://arxiv.org/abs/2211.16908</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manthey_B/0/1/0/all/0/1&quot;&gt;Bodo Manthey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rhijn_J/0/1/0/all/0/1&quot;&gt;Jesse van Rhijn&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The 2-opt heuristic is a simple local search heuristic for the Travelling
Salesperson Problem (TSP). Although it usually performs well in practice, its
worst-case running time is poor. Attempts to reconcile this difference have
used smoothed analysis, in which adversarial instances are perturbed
probabilistically.
&lt;/p&gt;
&lt;p&gt;We are interested in the classical model of smoothed analysis for the
Euclidean TSP, in which the perturbations are Gaussian. This model was
previously used by Manthey \&amp;amp; Veenstra, who obtained smoothed complexity bounds
polynomial in $n$, the dimension $d$, and the perturbation strength
$\sigma^{-1}$. However, their analysis only works for $d \geq 4$. The only
previous analysis for $d \leq 3$ was performed by Englert, R\&quot;oglin \&amp;amp;
V\&quot;ocking, who used a different perturbation model which can be translated to
Gaussian perturbations. Their model yields bounds polynomial in $n$ and
$\sigma^{-d}$, and super-exponential in $d$.
&lt;/p&gt;
&lt;p&gt;As no direct analysis existed for Gaussian perturbations that yields
polynomial bounds for all $d$, we perform this missing analysis. Along the way,
we improve all existing smoothed complexity bounds for Euclidean 2-opt.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Internal Closedness and von Neumann-Morgenstern Stability in Matching Theory: Structures and Complexity</title>
    <link href="http://arxiv.org/abs/2211.17050"/>
    <id>http://arxiv.org/abs/2211.17050</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Faenza_Y/0/1/0/all/0/1&quot;&gt;Yuri Faenza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Stein_C/0/1/0/all/0/1&quot;&gt;Clifford Stein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wan_J/0/1/0/all/0/1&quot;&gt;Jia Wan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $G$ be a graph and suppose we are given, for each $v \in V(G)$, a strict
ordering of the neighbors of $v$. A set of matchings $\mathcal{M}$ of $G$ is
called internally stable if there are no matchings $M,M&#39; \in \mathcal{M}$ such
that an edge of $M$ blocks $M&#39;$. The sets of stable matchings and of von
Neumann-Morgenstern stable matchings are examples of internally stable sets of
matching.
&lt;/p&gt;
&lt;p&gt;In this paper, we introduce and study, in both the marriage and the roommate
case, inclusionwise maximal internally stable sets of matchings. We call those
sets internally closed. By building on known and newly developed algebraic
structures associated to sets of matchings, we investigate the complexity of
deciding if a set of matchings is internally closed, and if it is von
Neumann-Morgenstern stable.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Batching and Optimal Multi-stage Bipartite Allocations</title>
    <link href="http://arxiv.org/abs/2211.16581"/>
    <id>http://arxiv.org/abs/2211.16581</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yiding Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niazadeh_R/0/1/0/all/0/1&quot;&gt;Rad Niazadeh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In several applications of real-time matching of demand to supply in online
marketplaces, the platform allows for some latency to batch the demand and
improve the efficiency. Motivated by these applications, we study the optimal
trade-off between batching and inefficiency under adversarial arrival. As our
base model, we consider K-stage variants of the vertex weighted b-matching in
the adversarial setting, where online vertices arrive stage-wise and in K
batches -- in contrast to online arrival. Our main result for this problem is
an optimal (1-(1-1/K)^K)- competitive (fractional) matching algorithm,
improving the classic (1-1/e) competitive ratio bound known for its online
variant (Mehta et al., 2007; Aggarwal et al., 2011). We also extend this result
to the rich model of multi-stage configuration allocation with free-disposals
(Devanur et al., 2016), which is motivated by the display advertising in video
streaming platforms.
&lt;/p&gt;
&lt;p&gt;Our main technique is developing tools to vary the trade-off between
&quot;greedy-ness&quot; and &quot;hedging&quot; of the algorithm across stages. We rely on a
particular family of convex-programming based matchings that distribute the
demand in a specifically balanced way among supply in different stages, while
carefully modifying the balancedness of the resulting matching across stages.
More precisely, we identify a sequence of polynomials with decreasing degrees
to be used as strictly concave regularizers of the maximum weight matching
linear program to form these convex programs. At each stage, our algorithm
returns the corresponding regularized optimal solution as the matching of this
stage (by solving the convex program). Using structural properties of these
convex programs and recursively connecting the regularizers together, we
develop a new multi-stage primal-dual framework to analyze the competitive
ratio. We further show this algorithm is optimally competitive.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Approximating binary longest common subsequence in near-linear time</title>
    <link href="http://arxiv.org/abs/2211.16660"/>
    <id>http://arxiv.org/abs/2211.16660</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xiaoyu He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Ray Li&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Longest Common Subsequence (LCS) is a fundamental string similarity
measure, and computing the LCS of two strings is a classic algorithms question.
A textbook dynamic programming algorithm gives an exact algorithm in quadratic
time, and this is essentially best possible under plausible fine-grained
complexity assumptions, so a natural problem is to find faster approximation
algorithms. When the inputs are two binary strings, there is a simple
$\frac{1}{2}$-approximation in linear time: compute the longest common all-0s
or all-1s subsequence. It has been open whether a better approximation is
possible even in truly subquadratic time. Rubinstein and Song showed that the
answer is yes under the assumption that the two input strings have equal
lengths. We settle the question, generalizing their result to unequal length
strings, proving that, for any $\varepsilon&amp;gt;0$, there exists $\delta&amp;gt;0$ and a
$(\frac{1}{2}+\delta)$-approximation algorithm for binary LCS that runs in
$n^{1+\varepsilon}$ time. As a consequence of our result and a result of Akmal
and Vassilevska-Williams, for any $\varepsilon&amp;gt;0$, there exists a
$(\frac{1}{q}+\delta)$-approximation for LCS over $q$-ary strings in
$n^{1+\varepsilon}$ time.
&lt;/p&gt;
&lt;p&gt;Our techniques build on the recent work of Guruswami, He, and Li who proved
new bounds for error-correcting codes tolerating deletion errors. They prove a
combinatorial &quot;structure lemma&quot; for strings which classifies them according to
their oscillation patterns. We prove and use an algorithmic generalization of
this structure lemma, which may be of independent interest.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Approximate minimum cuts and their enumeration</title>
    <link href="http://arxiv.org/abs/2211.16747"/>
    <id>http://arxiv.org/abs/2211.16747</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beideman_C/0/1/0/all/0/1&quot;&gt;Calvin Beideman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandrasekaran_K/0/1/0/all/0/1&quot;&gt;Karthekeyan Chandrasekaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Weihang Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that every $\alpha$-approximate minimum cut in a connected graph is
the unique minimum $(S,T)$-terminal cut for some subsets $S$ and $T$ of
vertices each of size at most $\lfloor2\alpha\rfloor+1$. This leads to an
alternative proof that the number of $\alpha$-approximate minimum cuts in a
$n$-vertex connected graph is $n^{O(\alpha)}$ and they can all be enumerated in
deterministic polynomial time for constant $\alpha$.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Gapped String Indexing in Subquadratic Space and Sublinear Query Time</title>
    <link href="http://arxiv.org/abs/2211.16860"/>
    <id>http://arxiv.org/abs/2211.16860</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bille_P/0/1/0/all/0/1&quot;&gt;Philip Bille&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gortz_I/0/1/0/all/0/1&quot;&gt;Inge Li G&amp;#xf8;rtz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lewenstein_M/0/1/0/all/0/1&quot;&gt;Moshe Lewenstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pissis_S/0/1/0/all/0/1&quot;&gt;Solon P. Pissis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1&quot;&gt;Eva Rotenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steiner_T/0/1/0/all/0/1&quot;&gt;Teresa Anna Steiner&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In Gapped String Indexing, the goal is to compactly represent a string $S$ of
length $n$ such that given queries consisting of two strings $P_1$ and $P_2$,
called patterns, and an integer interval $[\alpha, \beta]$, called gap range,
we can quickly find occurrences of $P_1$ and $P_2$ in $S$ with distance in
$[\alpha, \beta]$. Due to the many applications of this fundamental problem in
computational biology and elsewhere, there is a great body of work for
restricted or parameterised variants of the problem. However, for the general
problem statement, no improvements upon the trivial $\mathcal{O}(n)$-space
$\mathcal{O}(n)$-query time or $\Omega(n^2)$-space $\mathcal{\tilde{O}}(|P_1| +
|P_2| + \mathrm{occ})$-query time solutions were known so far. We break this
barrier obtaining interesting trade-offs with polynomially subquadratic space
and polynomially sublinear query time. In particular, we show that, for every
$0\leq \delta \leq 1$, there is a data structure for Gapped String Indexing
with either $\mathcal{\tilde{O}}(n^{2-\delta/3})$ or
$\mathcal{\tilde{O}}(n^{3-2\delta})$ space and $\mathcal{\tilde{O}}(|P_1| +
|P_2| + n^{\delta}\cdot (\mathrm{occ}+1))$ query time, where $\mathrm{occ}$ is
the number of reported occurrences. As a new fundamental tool towards obtaining
our main result, we introduce the Shifted Set Intersection problem: preprocess
a collection of sets $S_1, \ldots, S_k$ of integers such that given queries
consisting of three integers $i,j,s$, we can quickly output YES if and only if
there exist $a \in S_i$ and $b \in S_j$ with $a+s = b$. We start by showing
that the Shifted Set Intersection problem is equivalent to the indexing variant
of 3SUM (3SUM Indexing) [Golovnev et al., STOC 2020]. Via several steps of
reduction we then show that the Gapped String Indexing problem reduces to
polylogarithmically many instances of the Shifted Set Intersection problem.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Fair Ranking with Noisy Protected Attributes</title>
    <link href="http://arxiv.org/abs/2211.17067"/>
    <id>http://arxiv.org/abs/2211.17067</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehrotra_A/0/1/0/all/0/1&quot;&gt;Anay Mehrotra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1&quot;&gt;Nisheeth K. Vishnoi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The fair-ranking problem, which asks to rank a given set of items to maximize
utility subject to group fairness constraints, has received attention in the
fairness, information retrieval, and machine learning literature. Recent works,
however, observe that errors in socially-salient (including protected)
attributes of items can significantly undermine fairness guarantees of existing
fair-ranking algorithms and raise the problem of mitigating the effect of such
errors. We study the fair-ranking problem under a model where socially-salient
attributes of items are randomly and independently perturbed. We present a
fair-ranking framework that incorporates group fairness requirements along with
probabilistic information about perturbations in socially-salient attributes.
We provide provable guarantees on the fairness and utility attainable by our
framework and show that it is information-theoretically impossible to
significantly beat these guarantees. Our framework works for multiple
non-disjoint attributes and a general class of fairness constraints that
includes proportional and equal representation. Empirically, we observe that,
compared to baselines, our algorithm outputs rankings with higher fairness, and
has a similar or better fairness-utility trade-off compared to baselines.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">arXiv: Data Structures and Algorithms: Nonmonontone submodular maximization under routing constraints</title>
    <link href="http://arxiv.org/abs/2211.17131"/>
    <id>http://arxiv.org/abs/2211.17131</id>
    <updated>2022-12-01T01:30:00+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haotian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Rao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zewei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1&quot;&gt;Guodong Sun&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In machine learning and big data, the optimization objectives based on
set-cover, entropy, diversity, influence, feature selection, etc. are commonly
modeled as submodular functions. Submodular (function) maximization is
generally NP-hard, even in the absence of constraints. Recently, submodular
maximization has been successfully investigated for the settings where the
objective function is monotone or the constraint is computation-tractable.
However, maximizing nonmonotone submodular function with complex constraints is
not yet well-understood. In this paper, we consider the nonmonotone submodular
maximization with a cost budget or feasibility constraint (especially from
route planning) that is generally NP-hard to evaluate. Such a problem is common
for machine learning, big data, and robotics. This problem is NP-hard, and on
top of that, its constraint evaluation is also NP-hard, which adds an
additional layer of complexity. So far, few studies have been devoted to
proposing effective solutions, making this problem currently unclear. In this
paper, we first propose an iterated greedy algorithm, which yields an
approximation solution. Then we develop the proof machinery that shows our
algorithm is a bi-criterion approximation algorithm: it can achieve a
constant-factor approximation to the optimal algorithm, while keeping the
over-budget tightly bounded. We also explore practical considerations of
achieving a trade-off between time complexity and over-budget. Finally, we
conduct numeric experiments on two concrete examples, and show our design&#39;s
efficacy in practical settings.
&lt;/p&gt;
  </content>
    <author>
      <name>arXiv: Data Structures and Algorithms</name>
      <uri>https://arxiv.org/list/cs.DS/recent</uri>
    </author>
  </entry>


  <entry xml:lang="en">
    <title type="html" xml:lang="en">CCI: jobs: Assistant, Associate, or Full Professor (Search 2) at University of California – San Diego (apply by January 1, 2023)</title>
    <link href="https://cstheory-jobs.org/2022/11/30/assistant-associate-or-full-professor-search-2-at-university-of-california-san-diego-apply-by-january-1-2023/"/>
    <id>http://cstheory-jobs.org/2022/11/30/assistant-associate-or-full-professor-search-2-at-university-of-california-san-diego-apply-by-january-1-2023/</id>
    <updated>2022-11-30T23:22:09+00:00</updated>
    <content type="html" xml:lang="en">
    &lt;p&gt;The UC San Diego Department of Computer Science and Engineering (CSE) invites applications for multiple tenure-track faculty positions at the Assistant Professor or tenured faculty positions at the Associate, or Full Professor rank. The department is looking for exceptional candidates in all areas of Computer Science and Engineering.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://cse.ucsd.edu/administration/human-resources/recruitment/faculty-positions&quot;&gt;https://cse.ucsd.edu/administration/human-resources/recruitment/faculty-positions&lt;/a&gt;&lt;br /&gt;
Email: nherrera@eng.ucsd.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </content>
    <author>
      <name>CCI: jobs</name>
      <uri>https://cstheory-jobs.org</uri>
    </author>
  </entry>


</feed>
